From 1d8270e6b5085b3f04cc055490534d918aab28db Mon Sep 17 00:00:00 2001
From: "Ooi, Joyce" <joyce.ooi@intel.com>
Date: Fri, 29 Nov 2019 12:03:52 +0000
Subject: [PATCH 126/151] net: ethernet: altera: add DMA support for Intel FPGA
 QSE driver

commit  f0a465933ce975537a9b32530dfbd00fe991eb30 from
https://github.com/altera-opensource/linux-socfpga.git
branch is socfpga-5.4.64-lts

This patch adds a DMA support for Intel FPGA Quad Speed Ethernet (QSE)
driver. It also includes commonizing DMA with existing Altera TSE
driver.

Signed-off-by: Ooi, Joyce <joyce.ooi@intel.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
Integrated-by: Jun Zhang <jun.zhang@windriver.com>
---
 drivers/net/ethernet/altera/altera_eth_dma.c  | 193 ++++++++++++++++
 drivers/net/ethernet/altera/altera_eth_dma.h  | 138 ++++++++++++
 drivers/net/ethernet/altera/altera_msgdma.c   |  34 +--
 drivers/net/ethernet/altera/altera_msgdma.h   |  45 ++--
 .../altera/altera_msgdma_prefetcher.c         |  44 ++--
 .../altera/altera_msgdma_prefetcher.h         |  48 ++--
 drivers/net/ethernet/altera/altera_sgdma.c    | 124 +++++-----
 drivers/net/ethernet/altera/altera_sgdma.h    |  47 ++--
 drivers/net/ethernet/altera/altera_tse.h      |  74 +-----
 .../net/ethernet/altera/altera_tse_ethtool.c  |   1 +
 drivers/net/ethernet/altera/altera_tse_main.c | 212 +++++++++---------
 drivers/net/ethernet/altera/altera_utils.c    |   1 +
 12 files changed, 634 insertions(+), 327 deletions(-)
 create mode 100644 drivers/net/ethernet/altera/altera_eth_dma.c
 create mode 100644 drivers/net/ethernet/altera/altera_eth_dma.h

diff --git a/drivers/net/ethernet/altera/altera_eth_dma.c b/drivers/net/ethernet/altera/altera_eth_dma.c
new file mode 100644
index 000000000000..f91aa921b9af
--- /dev/null
+++ b/drivers/net/ethernet/altera/altera_eth_dma.c
@@ -0,0 +1,193 @@
+// SPDX-License-Identifier: GPL-2.0
+/* DMA support for Intel FPGA Quad-Speed Ethernet MAC driver
+ * Copyright (C) 2019 Intel Corporation. All rights reserved
+ *
+ * Contributors:
+ *   Dalon Westergreen
+ *   Thomas Chou
+ *   Ian Abbott
+ *   Yuriy Kozlov
+ *   Tobias Klauser
+ *   Andriy Smolskyy
+ *   Roman Bulgakov
+ *   Dmytro Mytarchuk
+ *   Matthew Gerlach
+ *   Joyce Ooi
+ */
+
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/module.h>
+
+#include "altera_eth_dma.h"
+#include "altera_utils.h"
+
+/* Probe DMA
+ */
+int altera_eth_dma_probe(struct platform_device *pdev,
+			 struct altera_dma_private *priv,
+			 enum altera_dma_type type)
+{
+	int ret = -ENODEV;
+	struct resource *dma_res;
+	void __iomem *descmap;
+
+	/* xSGDMA Rx Dispatcher address space */
+	ret = request_and_map(pdev, "rx_csr", &dma_res,
+			      &priv->rx_dma_csr);
+	if (ret)
+		goto err;
+
+	if (netif_msg_probe(priv))
+		dev_info(&pdev->dev, "\tDMA RX CSR at 0x%08lx\n",
+			 (unsigned long)dma_res->start);
+
+	/* mSGDMA Tx Dispatcher address space */
+	ret = request_and_map(pdev, "tx_csr", &dma_res,
+			      &priv->tx_dma_csr);
+	if (ret)
+		goto err;
+
+	if (netif_msg_probe(priv))
+		dev_info(&pdev->dev, "\tDMA TX CSR at 0x%08lx\n",
+			 (unsigned long)dma_res->start);
+
+	switch (type) {
+	case ALTERA_DTYPE_SGDMA:
+		/* Get the mapped address to the SGDMA descriptor memory */
+		ret = request_and_map(pdev, "s1", &dma_res, &descmap);
+		if (ret)
+			break;
+
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tDMA Desc Mem at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		/* Start of that memory is for transmit descriptors */
+		priv->tx_dma_desc = descmap;
+
+		/* First half is for tx descriptors, other half for tx */
+		priv->txdescmem = resource_size(dma_res) / 2;
+
+		priv->txdescmem_busaddr = (dma_addr_t)dma_res->start;
+
+		priv->rx_dma_desc = (void __iomem *)((uintptr_t)(descmap +
+						     priv->txdescmem));
+		priv->rxdescmem = resource_size(dma_res) / 2;
+		priv->rxdescmem_busaddr = dma_res->start;
+		priv->rxdescmem_busaddr += priv->txdescmem;
+
+		if (upper_32_bits(priv->rxdescmem_busaddr))
+			ret = -EINVAL;
+
+		if (upper_32_bits(priv->txdescmem_busaddr))
+			ret = -EINVAL;
+		break;
+	case ALTERA_DTYPE_MSGDMA:
+		ret = request_and_map(pdev, "rx_resp", &dma_res,
+				      &priv->rx_dma_resp);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tRX Resp Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		ret = request_and_map(pdev, "tx_desc", &dma_res,
+				      &priv->tx_dma_desc);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tTX Desc Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		priv->txdescmem = resource_size(dma_res);
+		priv->txdescmem_busaddr = dma_res->start;
+
+		ret = request_and_map(pdev, "rx_desc", &dma_res,
+				      &priv->rx_dma_desc);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tRX Desc Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		priv->rxdescmem = resource_size(dma_res);
+		priv->rxdescmem_busaddr = dma_res->start;
+		break;
+	case ALTERA_DTYPE_MSGDMA_PTP:
+		ret = request_and_map(pdev, "rx_desc", &dma_res,
+				      &priv->rx_dma_desc);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tRX Desc Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		priv->rxdescmem = resource_size(dma_res);
+		priv->rxdescmem_busaddr = dma_res->start;
+
+		ret = request_and_map(pdev, "rx_resp", &dma_res,
+				      &priv->rx_dma_resp);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tRX Resp Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		ret = request_and_map(pdev, "tx_desc", &dma_res,
+				      &priv->tx_dma_desc);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tTX Desc Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+
+		priv->txdescmem = resource_size(dma_res);
+		priv->txdescmem_busaddr = dma_res->start;
+
+		ret = request_and_map(pdev, "tx_resp", &dma_res,
+				      &priv->tx_dma_resp);
+		if (ret)
+			break;
+		if (netif_msg_probe(priv))
+			dev_info(&pdev->dev, "\tTX Resp Slave at 0x%08lx\n",
+				 (unsigned long)dma_res->start);
+		break;
+	case ALTERA_DTYPE_MSGDMA_PREF:
+		/* mSGDMA Rx Prefetcher address space */
+		ret = request_and_map(pdev, "rx_pref", &dma_res,
+				      &priv->rx_pref_csr);
+		if (ret)
+			break;
+
+		/* mSGDMA Tx Prefetcher address space */
+		ret = request_and_map(pdev, "tx_pref", &dma_res,
+				      &priv->tx_pref_csr);
+		if (ret)
+			break;
+
+		/* get prefetcher rx poll frequency from device tree */
+		if (of_property_read_u32(pdev->dev.of_node,
+					 "rx-poll-freq",
+					 &priv->rx_poll_freq)) {
+			dev_info(&pdev->dev, "Defaulting RX Poll Frequency to 128\n");
+			priv->rx_poll_freq = 128;
+		}
+
+		/* get prefetcher rx poll frequency from device tree */
+		if (of_property_read_u32(pdev->dev.of_node,
+					 "tx-poll-freq",
+					 &priv->tx_poll_freq)) {
+			dev_info(&pdev->dev, "Defaulting TX Poll Frequency to 128\n");
+			priv->tx_poll_freq = 128;
+		}
+		break;
+	default:
+		ret = -ENODEV;
+		break;
+	}
+err:
+	return ret;
+};
+EXPORT_SYMBOL_GPL(altera_eth_dma_probe);
+MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/altera/altera_eth_dma.h b/drivers/net/ethernet/altera/altera_eth_dma.h
new file mode 100644
index 000000000000..c231d95c7417
--- /dev/null
+++ b/drivers/net/ethernet/altera/altera_eth_dma.h
@@ -0,0 +1,138 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* DMA support for Intel FPGA Quad-Speed Ethernet MAC driver
+ * Copyright (C) 2019 Intel Corporation. All rights reserved
+ *
+ * Contributors:
+ *   Dalon Westergreen
+ *   Thomas Chou
+ *   Ian Abbott
+ *   Yuriy Kozlov
+ *   Tobias Klauser
+ *   Andriy Smolskyy
+ *   Roman Bulgakov
+ *   Dmytro Mytarchuk
+ *   Matthew Gerlach
+ *   Joyce Ooi
+ */
+
+#ifndef __ALTERA_ETH_DMA_H__
+#define __ALTERA_ETH_DMA_H__
+
+#include <linux/bitops.h>
+#include <linux/list.h>
+#include <linux/netdevice.h>
+#include <linux/platform_device.h>
+
+#define ALTERA_TSE_SW_RESET_WATCHDOG_CNTR	10000
+
+struct altera_dma_private {
+	struct net_device *dev;
+	struct device *device;
+
+	/* mSGDMA Rx Dispatcher address space */
+	void __iomem *rx_dma_csr;
+	void __iomem *rx_dma_desc;
+	void __iomem *rx_dma_resp;
+
+	/* mSGDMA Tx Dispatcher address space */
+	void __iomem *tx_dma_csr;
+	void __iomem *tx_dma_desc;
+	void __iomem *tx_dma_resp;
+
+	/* mSGDMA Rx Prefecher address space */
+	void __iomem *rx_pref_csr;
+	struct msgdma_pref_extended_desc *pref_rxdesc;
+	dma_addr_t pref_rxdescphys;
+	u32 pref_rx_prod;
+
+	/* mSGDMA Tx Prefecher address space */
+	void __iomem *tx_pref_csr;
+	struct msgdma_pref_extended_desc *pref_txdesc;
+	dma_addr_t pref_txdescphys;
+	u32 rx_poll_freq;
+	u32 tx_poll_freq;
+
+	/* Rx buffers queue */
+	struct altera_dma_buffer *rx_ring;
+	u32 rx_cons;
+	u32 rx_prod;
+	u32 rx_ring_size;
+	u32 rx_dma_buf_sz;
+
+	/* Tx ring buffer */
+	struct altera_dma_buffer *tx_ring;
+	u32 tx_prod;
+	u32 tx_cons;
+	u32 tx_ring_size;
+
+	/* Descriptor memory info for managing SGDMA */
+	u32 txdescmem;
+	u32 rxdescmem;
+	dma_addr_t rxdescmem_busaddr;
+	dma_addr_t txdescmem_busaddr;
+	u32 txctrlreg;
+	u32 rxctrlreg;
+	dma_addr_t rxdescphys;
+	dma_addr_t txdescphys;
+
+	struct list_head txlisthd;
+	struct list_head rxlisthd;
+
+	int hwts_tx_en;
+	int hwts_rx_en;
+
+	/* ethtool msglvl option */
+	u32 msg_enable;
+};
+
+/* Wrapper around a pointer to a socket buffer,
+ * so a DMA handle can be stored along with the buffer
+ */
+struct altera_dma_buffer {
+	struct list_head lh;
+	struct sk_buff *skb;
+	dma_addr_t dma_addr;
+	u32 len;
+	int mapped_as_page;
+};
+
+enum altera_dma_type {
+	ALTERA_DTYPE_SGDMA = 1,
+	ALTERA_DTYPE_MSGDMA = 2,
+	ALTERA_DTYPE_MSGDMA_PTP = 3,
+	ALTERA_DTYPE_MSGDMA_PREF = 4,
+};
+
+struct altera_dma_resp {
+	u32 status;
+	u32 external_resp[4];
+};
+
+/* standard DMA interface for SGDMA and MSGDMA */
+struct altera_dmaops {
+	enum altera_dma_type altera_dtype;
+	int dmamask;
+	void (*reset_dma)(struct altera_dma_private *priv);
+	void (*enable_txirq)(struct altera_dma_private *priv);
+	void (*enable_rxirq)(struct altera_dma_private *priv);
+	void (*disable_txirq)(struct altera_dma_private *priv);
+	void (*disable_rxirq)(struct altera_dma_private *priv);
+	void (*clear_txirq)(struct altera_dma_private *priv);
+	void (*clear_rxirq)(struct altera_dma_private *priv);
+	int (*tx_buffer)(struct altera_dma_private *priv,
+			 struct altera_dma_buffer *buffer);
+	u32 (*tx_completions)(struct altera_dma_private *priv);
+	void (*add_rx_desc)(struct altera_dma_private *priv,
+			    struct altera_dma_buffer *buffer);
+	u32 (*get_rx_status)(struct altera_dma_private *priv);
+	int (*init_dma)(struct altera_dma_private *priv);
+	void (*uninit_dma)(struct altera_dma_private *priv);
+	void (*start_rxdma)(struct altera_dma_private *priv);
+	void (*start_txdma)(struct altera_dma_private *priv);
+};
+
+int altera_eth_dma_probe(struct platform_device *pdev,
+			 struct altera_dma_private *priv,
+			 enum altera_dma_type type);
+
+#endif /* __ALTERA_ETH_DMA_H__ */
diff --git a/drivers/net/ethernet/altera/altera_msgdma.c b/drivers/net/ethernet/altera/altera_msgdma.c
index ac68151a7f47..399315dc4363 100644
--- a/drivers/net/ethernet/altera/altera_msgdma.c
+++ b/drivers/net/ethernet/altera/altera_msgdma.c
@@ -5,25 +5,25 @@
 
 #include <linux/netdevice.h>
 #include "altera_utils.h"
-#include "altera_tse.h"
+#include "altera_eth_dma.h"
 #include "altera_msgdmahw.h"
 #include "altera_msgdma.h"
 
 /* No initialization work to do for MSGDMA */
-int msgdma_initialize(struct altera_tse_private *priv)
+int msgdma_initialize(struct altera_dma_private *priv)
 {
 	return 0;
 }
 
-void msgdma_uninitialize(struct altera_tse_private *priv)
+void msgdma_uninitialize(struct altera_dma_private *priv)
 {
 }
 
-void msgdma_start_rxdma(struct altera_tse_private *priv)
+void msgdma_start_rxdma(struct altera_dma_private *priv)
 {
 }
 
-void msgdma_reset(struct altera_tse_private *priv)
+void msgdma_reset(struct altera_dma_private *priv)
 {
 	int counter;
 
@@ -71,43 +71,43 @@ void msgdma_reset(struct altera_tse_private *priv)
 	csrwr32(MSGDMA_CSR_STAT_MASK, priv->tx_dma_csr, msgdma_csroffs(status));
 }
 
-void msgdma_disable_rxirq(struct altera_tse_private *priv)
+void msgdma_disable_rxirq(struct altera_dma_private *priv)
 {
 	tse_clear_bit(priv->rx_dma_csr, msgdma_csroffs(control),
 		      MSGDMA_CSR_CTL_GLOBAL_INTR);
 }
 
-void msgdma_enable_rxirq(struct altera_tse_private *priv)
+void msgdma_enable_rxirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->rx_dma_csr, msgdma_csroffs(control),
 		    MSGDMA_CSR_CTL_GLOBAL_INTR);
 }
 
-void msgdma_disable_txirq(struct altera_tse_private *priv)
+void msgdma_disable_txirq(struct altera_dma_private *priv)
 {
 	tse_clear_bit(priv->tx_dma_csr, msgdma_csroffs(control),
 		      MSGDMA_CSR_CTL_GLOBAL_INTR);
 }
 
-void msgdma_enable_txirq(struct altera_tse_private *priv)
+void msgdma_enable_txirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->tx_dma_csr, msgdma_csroffs(control),
 		    MSGDMA_CSR_CTL_GLOBAL_INTR);
 }
 
-void msgdma_clear_rxirq(struct altera_tse_private *priv)
+void msgdma_clear_rxirq(struct altera_dma_private *priv)
 {
 	csrwr32(MSGDMA_CSR_STAT_IRQ, priv->rx_dma_csr, msgdma_csroffs(status));
 }
 
-void msgdma_clear_txirq(struct altera_tse_private *priv)
+void msgdma_clear_txirq(struct altera_dma_private *priv)
 {
 	csrwr32(MSGDMA_CSR_STAT_IRQ, priv->tx_dma_csr, msgdma_csroffs(status));
 }
 
 /* return 0 to indicate transmit is pending */
-netdev_tx_t
-msgdma_tx_buffer(struct altera_tse_private *priv, struct tse_buffer *buffer)
+netdev_tx_t msgdma_tx_buffer(struct altera_dma_private *priv,
+			     struct altera_dma_buffer *buffer)
 {
 	csrwr32(lower_32_bits(buffer->dma_addr), priv->tx_dma_desc,
 		msgdma_descroffs(read_addr_lo));
@@ -124,7 +124,7 @@ msgdma_tx_buffer(struct altera_tse_private *priv, struct tse_buffer *buffer)
 	return NETDEV_TX_OK;
 }
 
-u32 msgdma_tx_completions(struct altera_tse_private *priv)
+u32 msgdma_tx_completions(struct altera_dma_private *priv)
 {
 	u32 ready = 0;
 	u32 inuse;
@@ -150,8 +150,8 @@ u32 msgdma_tx_completions(struct altera_tse_private *priv)
 
 /* Put buffer to the mSGDMA RX FIFO
  */
-void msgdma_add_rx_desc(struct altera_tse_private *priv,
-			struct tse_buffer *rxbuffer)
+void msgdma_add_rx_desc(struct altera_dma_private *priv,
+			struct altera_dma_buffer *rxbuffer)
 {
 	u32 len = priv->rx_dma_buf_sz;
 	dma_addr_t dma_addr = rxbuffer->dma_addr;
@@ -177,7 +177,7 @@ void msgdma_add_rx_desc(struct altera_tse_private *priv,
 /* status is returned on upper 16 bits,
  * length is returned in lower 16 bits
  */
-u32 msgdma_rx_status(struct altera_tse_private *priv)
+u32 msgdma_rx_status(struct altera_dma_private *priv)
 {
 	u32 rxstatus = 0;
 	u32 pktlength;
diff --git a/drivers/net/ethernet/altera/altera_msgdma.h b/drivers/net/ethernet/altera/altera_msgdma.h
index d816b24dfa7f..378738f86a09 100644
--- a/drivers/net/ethernet/altera/altera_msgdma.h
+++ b/drivers/net/ethernet/altera/altera_msgdma.h
@@ -1,26 +1,37 @@
-/* SPDX-License-Identifier: GPL-2.0-only */
 /* Altera TSE SGDMA and MSGDMA Linux driver
  * Copyright (C) 2014 Altera Corporation. All rights reserved
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #ifndef __ALTERA_MSGDMA_H__
 #define __ALTERA_MSGDMA_H__
 
-void msgdma_reset(struct altera_tse_private *priv);
-void msgdma_enable_txirq(struct altera_tse_private *priv);
-void msgdma_enable_rxirq(struct altera_tse_private *priv);
-void msgdma_disable_rxirq(struct altera_tse_private *priv);
-void msgdma_disable_txirq(struct altera_tse_private *priv);
-void msgdma_clear_rxirq(struct altera_tse_private *priv);
-void msgdma_clear_txirq(struct altera_tse_private *priv);
-u32 msgdma_tx_completions(struct altera_tse_private *priv);
-void msgdma_add_rx_desc(struct altera_tse_private *priv,
-			struct tse_buffer *buffer);
-netdev_tx_t msgdma_tx_buffer(struct altera_tse_private *priv,
-			     struct tse_buffer *buffer);
-u32 msgdma_rx_status(struct altera_tse_private *priv);
-int msgdma_initialize(struct altera_tse_private *priv);
-void msgdma_uninitialize(struct altera_tse_private *priv);
-void msgdma_start_rxdma(struct altera_tse_private *priv);
+void msgdma_reset(struct altera_dma_private *priv);
+void msgdma_enable_txirq(struct altera_dma_private *priv);
+void msgdma_enable_rxirq(struct altera_dma_private *priv);
+void msgdma_disable_rxirq(struct altera_dma_private *priv);
+void msgdma_disable_txirq(struct altera_dma_private *priv);
+void msgdma_clear_rxirq(struct altera_dma_private *priv);
+void msgdma_clear_txirq(struct altera_dma_private *priv);
+u32 msgdma_tx_completions(struct altera_dma_private *priv);
+void msgdma_add_rx_desc(struct altera_dma_private *priv,
+			struct altera_dma_buffer *buffer);
+netdev_tx_t msgdma_tx_buffer(struct altera_dma_private *priv,
+			     struct altera_dma_buffer *buffer);
+u32 msgdma_rx_status(struct altera_dma_private *priv);
+int msgdma_initialize(struct altera_dma_private *priv);
+void msgdma_uninitialize(struct altera_dma_private *priv);
+void msgdma_start_rxdma(struct altera_dma_private *priv);
 
 #endif /*  __ALTERA_MSGDMA_H__ */
diff --git a/drivers/net/ethernet/altera/altera_msgdma_prefetcher.c b/drivers/net/ethernet/altera/altera_msgdma_prefetcher.c
index e8cd4d04730d..7eea4537a607 100644
--- a/drivers/net/ethernet/altera/altera_msgdma_prefetcher.c
+++ b/drivers/net/ethernet/altera/altera_msgdma_prefetcher.c
@@ -9,14 +9,14 @@
 #include <linux/list.h>
 #include <linux/netdevice.h>
 #include <linux/net_tstamp.h>
-#include "altera_tse.h"
+#include "altera_eth_dma.h"
 #include "altera_msgdma.h"
 #include "altera_msgdmahw.h"
 #include "altera_msgdma_prefetcher.h"
 #include "altera_msgdmahw_prefetcher.h"
 #include "altera_utils.h"
 
-int msgdma_pref_initialize(struct altera_tse_private *priv)
+int msgdma_pref_initialize(struct altera_dma_private *priv)
 {
 	int i;
 	struct msgdma_pref_extended_desc *rx_descs;
@@ -94,11 +94,11 @@ int msgdma_pref_initialize(struct altera_tse_private *priv)
 	}
 
 	if (netif_msg_ifup(priv))
-		netdev_info(priv->dev, "%s: RX Desc mem at 0x%x\n", __func__,
+		netdev_info(priv->dev, "%s: RX Desc mem at 0x%llx\n", __func__,
 			    priv->pref_rxdescphys);
 
 	if (netif_msg_ifup(priv))
-		netdev_info(priv->dev, "%s: TX Desc mem at 0x%x\n", __func__,
+		netdev_info(priv->dev, "%s: TX Desc mem at 0x%llx\n", __func__,
 			    priv->pref_txdescphys);
 
 	return 0;
@@ -112,7 +112,7 @@ int msgdma_pref_initialize(struct altera_tse_private *priv)
 	return -ENOMEM;
 }
 
-void msgdma_pref_uninitialize(struct altera_tse_private *priv)
+void msgdma_pref_uninitialize(struct altera_dma_private *priv)
 {
 	if (priv->pref_rxdesc)
 		dma_free_coherent(priv->device,
@@ -127,37 +127,37 @@ void msgdma_pref_uninitialize(struct altera_tse_private *priv)
 				  priv->pref_txdesc, priv->pref_txdescphys);
 }
 
-void msgdma_pref_enable_txirq(struct altera_tse_private *priv)
+void msgdma_pref_enable_txirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->tx_pref_csr, msgdma_pref_csroffs(control),
 		    MSGDMA_PREF_CTL_GLOBAL_INTR);
 }
 
-void msgdma_pref_disable_txirq(struct altera_tse_private *priv)
+void msgdma_pref_disable_txirq(struct altera_dma_private *priv)
 {
 	tse_clear_bit(priv->tx_pref_csr, msgdma_pref_csroffs(control),
 		      MSGDMA_PREF_CTL_GLOBAL_INTR);
 }
 
-void msgdma_pref_clear_txirq(struct altera_tse_private *priv)
+void msgdma_pref_clear_txirq(struct altera_dma_private *priv)
 {
 	csrwr32(MSGDMA_PREF_STAT_IRQ, priv->tx_pref_csr,
 		msgdma_pref_csroffs(status));
 }
 
-void msgdma_pref_enable_rxirq(struct altera_tse_private *priv)
+void msgdma_pref_enable_rxirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->rx_pref_csr, msgdma_pref_csroffs(control),
 		    MSGDMA_PREF_CTL_GLOBAL_INTR);
 }
 
-void msgdma_pref_disable_rxirq(struct altera_tse_private *priv)
+void msgdma_pref_disable_rxirq(struct altera_dma_private *priv)
 {
 	tse_clear_bit(priv->rx_pref_csr, msgdma_pref_csroffs(control),
 		      MSGDMA_PREF_CTL_GLOBAL_INTR);
 }
 
-void msgdma_pref_clear_rxirq(struct altera_tse_private *priv)
+void msgdma_pref_clear_rxirq(struct altera_dma_private *priv)
 {
 	csrwr32(MSGDMA_PREF_STAT_IRQ, priv->rx_pref_csr,
 		msgdma_pref_csroffs(status));
@@ -185,8 +185,8 @@ static u64 timestamp_to_ns(struct msgdma_pref_extended_desc *desc)
  *   -> this should never be called when a descriptor isn't available
  */
 
-netdev_tx_t msgdma_pref_tx_buffer(struct altera_tse_private *priv,
-				  struct tse_buffer *buffer)
+netdev_tx_t msgdma_pref_tx_buffer(struct altera_dma_private *priv,
+				  struct altera_dma_buffer *buffer)
 {
 	u32 desc_entry = priv->tx_prod % (priv->tx_ring_size * 2);
 	struct msgdma_pref_extended_desc *tx_descs = priv->pref_txdesc;
@@ -215,7 +215,7 @@ netdev_tx_t msgdma_pref_tx_buffer(struct altera_tse_private *priv,
 	return NETDEV_TX_OK;
 }
 
-u32 msgdma_pref_tx_completions(struct altera_tse_private *priv)
+u32 msgdma_pref_tx_completions(struct altera_dma_private *priv)
 {
 	u32 control;
 	u32 ready = 0;
@@ -224,7 +224,7 @@ u32 msgdma_pref_tx_completions(struct altera_tse_private *priv)
 	u32 ringsize = priv->tx_ring_size;
 	u64 ns = 0;
 	struct msgdma_pref_extended_desc *cur;
-	struct tse_buffer *tx_buff;
+	struct altera_dma_buffer *tx_buff;
 	struct skb_shared_hwtstamps shhwtstamp;
 	int i;
 
@@ -269,7 +269,7 @@ u32 msgdma_pref_tx_completions(struct altera_tse_private *priv)
 	return ready;
 }
 
-void msgdma_pref_reset(struct altera_tse_private *priv)
+void msgdma_pref_reset(struct altera_dma_private *priv)
 {
 	int counter;
 
@@ -326,7 +326,7 @@ void msgdma_pref_reset(struct altera_tse_private *priv)
 }
 
 /* Setup the RX and TX prefetchers to poll the descriptor chain */
-void msgdma_pref_start_rxdma(struct altera_tse_private *priv)
+void msgdma_pref_start_rxdma(struct altera_dma_private *priv)
 {
 	csrwr32(priv->rx_poll_freq, priv->rx_pref_csr,
 		msgdma_pref_csroffs(desc_poll_freq));
@@ -338,7 +338,7 @@ void msgdma_pref_start_rxdma(struct altera_tse_private *priv)
 		    MSGDMA_PREF_CTL_DESC_POLL_EN | MSGDMA_PREF_CTL_RUN);
 }
 
-void msgdma_pref_start_txdma(struct altera_tse_private *priv)
+void msgdma_pref_start_txdma(struct altera_dma_private *priv)
 {
 	csrwr32(priv->tx_poll_freq, priv->tx_pref_csr,
 		msgdma_pref_csroffs(desc_poll_freq));
@@ -353,8 +353,8 @@ void msgdma_pref_start_txdma(struct altera_tse_private *priv)
 /* Add MSGDMA Prefetcher Descriptor to descriptor list
  *   -> This should never be called when a descriptor isn't available
  */
-void msgdma_pref_add_rx_desc(struct altera_tse_private *priv,
-			     struct tse_buffer *rxbuffer)
+void msgdma_pref_add_rx_desc(struct altera_dma_private *priv,
+			     struct altera_dma_buffer *rxbuffer)
 {
 	struct msgdma_pref_extended_desc *rx_descs = priv->pref_rxdesc;
 	u32 desc_entry = priv->pref_rx_prod % (priv->rx_ring_size * 2);
@@ -386,7 +386,7 @@ void msgdma_pref_add_rx_desc(struct altera_tse_private *priv,
 	}
 }
 
-u32 msgdma_pref_rx_status(struct altera_tse_private *priv)
+u32 msgdma_pref_rx_status(struct altera_dma_private *priv)
 {
 	u32 rxstatus = 0;
 	u32 pktlength;
@@ -396,7 +396,7 @@ u32 msgdma_pref_rx_status(struct altera_tse_private *priv)
 	u32 desc_entry = priv->rx_prod % (priv->rx_ring_size * 2);
 	struct msgdma_pref_extended_desc *rx_descs = priv->pref_rxdesc;
 	struct skb_shared_hwtstamps *shhwtstamp = NULL;
-	struct tse_buffer *rx_buff = priv->rx_ring;
+	struct altera_dma_buffer *rx_buff = priv->rx_ring;
 
 	/* if the current entry is not owned by hardware, process it */
 	if (!(rx_descs[desc_entry].desc_control
diff --git a/drivers/net/ethernet/altera/altera_msgdma_prefetcher.h b/drivers/net/ethernet/altera/altera_msgdma_prefetcher.h
index 6507c2805a05..5b634f3f90e4 100644
--- a/drivers/net/ethernet/altera/altera_msgdma_prefetcher.h
+++ b/drivers/net/ethernet/altera/altera_msgdma_prefetcher.h
@@ -1,30 +1,38 @@
 /* SPDX-License-Identifier: GPL-2.0 */
 /* MSGDMA Prefetcher driver for Altera ethernet devices
  *
- * Copyright (C) 2020 Intel Corporation. All rights reserved.
- * Author(s):
- *   Dalon Westergreen <dalon.westergreen@intel.com>
+ * Copyright (C) 2020 Intel Corporation.
+ * Contributors:
+ *   Dalon Westergreen
+ *   Thomas Chou
+ *   Ian Abbott
+ *   Yuriy Kozlov
+ *   Tobias Klauser
+ *   Andriy Smolskyy
+ *   Roman Bulgakov
+ *   Dmytro Mytarchuk
+ *   Matthew Gerlach
  */
 
 #ifndef __ALTERA_PREF_MSGDMA_H__
 #define __ALTERA_PREF_MSGDMA_H__
 
-void msgdma_pref_reset(struct altera_tse_private *priv);
-void msgdma_pref_enable_txirq(struct altera_tse_private *priv);
-void msgdma_pref_enable_rxirq(struct altera_tse_private *priv);
-void msgdma_pref_disable_rxirq(struct altera_tse_private *priv);
-void msgdma_pref_disable_txirq(struct altera_tse_private *priv);
-void msgdma_pref_clear_rxirq(struct altera_tse_private *priv);
-void msgdma_pref_clear_txirq(struct altera_tse_private *priv);
-u32 msgdma_pref_tx_completions(struct altera_tse_private *priv);
-void msgdma_pref_add_rx_desc(struct altera_tse_private *priv,
-			     struct tse_buffer *buffer);
-netdev_tx_t msgdma_pref_tx_buffer(struct altera_tse_private *priv,
-				  struct tse_buffer *buffer);
-u32 msgdma_pref_rx_status(struct altera_tse_private *priv);
-int msgdma_pref_initialize(struct altera_tse_private *priv);
-void msgdma_pref_uninitialize(struct altera_tse_private *priv);
-void msgdma_pref_start_rxdma(struct altera_tse_private *priv);
-void msgdma_pref_start_txdma(struct altera_tse_private *priv);
+void msgdma_pref_reset(struct altera_dma_private *priv);
+void msgdma_pref_enable_txirq(struct altera_dma_private *priv);
+void msgdma_pref_enable_rxirq(struct altera_dma_private *priv);
+void msgdma_pref_disable_rxirq(struct altera_dma_private *priv);
+void msgdma_pref_disable_txirq(struct altera_dma_private *priv);
+void msgdma_pref_clear_rxirq(struct altera_dma_private *priv);
+void msgdma_pref_clear_txirq(struct altera_dma_private *priv);
+u32 msgdma_pref_tx_completions(struct altera_dma_private *priv);
+void msgdma_pref_add_rx_desc(struct altera_dma_private *priv,
+			     struct altera_dma_buffer *buffer);
+int msgdma_pref_tx_buffer(struct altera_dma_private *priv,
+			  struct altera_dma_buffer *buffer);
+u32 msgdma_pref_rx_status(struct altera_dma_private *priv);
+int msgdma_pref_initialize(struct altera_dma_private *priv);
+void msgdma_pref_uninitialize(struct altera_dma_private *priv);
+void msgdma_pref_start_rxdma(struct altera_dma_private *priv);
+void msgdma_pref_start_txdma(struct altera_dma_private *priv);
 
 #endif /*  __ALTERA_PREF_MSGDMA_H__ */
diff --git a/drivers/net/ethernet/altera/altera_sgdma.c b/drivers/net/ethernet/altera/altera_sgdma.c
index 6898ec682425..526a73d33d41 100644
--- a/drivers/net/ethernet/altera/altera_sgdma.c
+++ b/drivers/net/ethernet/altera/altera_sgdma.c
@@ -6,7 +6,7 @@
 #include <linux/list.h>
 #include <linux/netdevice.h>
 #include "altera_utils.h"
-#include "altera_tse.h"
+#include "altera_eth_dma.h"
 #include "altera_sgdmahw.h"
 #include "altera_sgdma.h"
 
@@ -20,39 +20,39 @@ static void sgdma_setup_descrip(struct sgdma_descrip __iomem *desc,
 				int rfixed,
 				int wfixed);
 
-static int sgdma_async_write(struct altera_tse_private *priv,
-			      struct sgdma_descrip __iomem *desc);
+static int sgdma_async_write(struct altera_dma_private *priv,
+			     struct sgdma_descrip __iomem *desc);
 
-static int sgdma_async_read(struct altera_tse_private *priv);
+static int sgdma_async_read(struct altera_dma_private *priv);
 
 static dma_addr_t
-sgdma_txphysaddr(struct altera_tse_private *priv,
+sgdma_txphysaddr(struct altera_dma_private *priv,
 		 struct sgdma_descrip __iomem *desc);
 
 static dma_addr_t
-sgdma_rxphysaddr(struct altera_tse_private *priv,
+sgdma_rxphysaddr(struct altera_dma_private *priv,
 		 struct sgdma_descrip __iomem *desc);
 
-static int sgdma_txbusy(struct altera_tse_private *priv);
+static int sgdma_txbusy(struct altera_dma_private *priv);
 
-static int sgdma_rxbusy(struct altera_tse_private *priv);
+static int sgdma_rxbusy(struct altera_dma_private *priv);
 
 static void
-queue_tx(struct altera_tse_private *priv, struct tse_buffer *buffer);
+queue_tx(struct altera_dma_private *priv, struct altera_dma_buffer *buffer);
 
 static void
-queue_rx(struct altera_tse_private *priv, struct tse_buffer *buffer);
+queue_rx(struct altera_dma_private *priv, struct altera_dma_buffer *buffer);
 
-static struct tse_buffer *
-dequeue_tx(struct altera_tse_private *priv);
+static struct altera_dma_buffer *
+dequeue_tx(struct altera_dma_private *priv);
 
-static struct tse_buffer *
-dequeue_rx(struct altera_tse_private *priv);
+static struct altera_dma_buffer *
+dequeue_rx(struct altera_dma_private *priv);
 
-static struct tse_buffer *
-queue_rx_peekhead(struct altera_tse_private *priv);
+static struct altera_dma_buffer *
+queue_rx_peekhead(struct altera_dma_private *priv);
 
-int sgdma_initialize(struct altera_tse_private *priv)
+int sgdma_initialize(struct altera_dma_private *priv)
 {
 	priv->txctrlreg = SGDMA_CTRLREG_ILASTD |
 		      SGDMA_CTRLREG_INTEN;
@@ -100,7 +100,7 @@ int sgdma_initialize(struct altera_tse_private *priv)
 	return 0;
 }
 
-void sgdma_uninitialize(struct altera_tse_private *priv)
+void sgdma_uninitialize(struct altera_dma_private *priv)
 {
 	if (priv->rxdescphys)
 		dma_unmap_single(priv->device, priv->rxdescphys,
@@ -114,7 +114,7 @@ void sgdma_uninitialize(struct altera_tse_private *priv)
 /* This function resets the SGDMA controller and clears the
  * descriptor memory used for transmits and receives.
  */
-void sgdma_reset(struct altera_tse_private *priv)
+void sgdma_reset(struct altera_dma_private *priv)
 {
 	/* Initialize descriptor memory to 0 */
 	memset_io(priv->tx_dma_desc, 0, priv->txdescmem);
@@ -132,29 +132,29 @@ void sgdma_reset(struct altera_tse_private *priv)
  * and disable
  */
 
-void sgdma_enable_rxirq(struct altera_tse_private *priv)
+void sgdma_enable_rxirq(struct altera_dma_private *priv)
 {
 }
 
-void sgdma_enable_txirq(struct altera_tse_private *priv)
+void sgdma_enable_txirq(struct altera_dma_private *priv)
 {
 }
 
-void sgdma_disable_rxirq(struct altera_tse_private *priv)
+void sgdma_disable_rxirq(struct altera_dma_private *priv)
 {
 }
 
-void sgdma_disable_txirq(struct altera_tse_private *priv)
+void sgdma_disable_txirq(struct altera_dma_private *priv)
 {
 }
 
-void sgdma_clear_rxirq(struct altera_tse_private *priv)
+void sgdma_clear_rxirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->rx_dma_csr, sgdma_csroffs(control),
 		    SGDMA_CTRLREG_CLRINT);
 }
 
-void sgdma_clear_txirq(struct altera_tse_private *priv)
+void sgdma_clear_txirq(struct altera_dma_private *priv)
 {
 	tse_set_bit(priv->tx_dma_csr, sgdma_csroffs(control),
 		    SGDMA_CTRLREG_CLRINT);
@@ -166,8 +166,8 @@ void sgdma_clear_txirq(struct altera_tse_private *priv)
  *   will now actually look at the code, so from now, 0 is good and return
  *   NETDEV_TX_BUSY when busy.
  */
-netdev_tx_t
-sgdma_tx_buffer(struct altera_tse_private *priv, struct tse_buffer *buffer)
+netdev_tx_t sgdma_tx_buffer(struct altera_dma_private *priv,
+			    struct altera_dma_buffer *buffer)
 {
 	struct sgdma_descrip __iomem *descbase =
 		(struct sgdma_descrip __iomem *)priv->tx_dma_desc;
@@ -203,7 +203,7 @@ sgdma_tx_buffer(struct altera_tse_private *priv, struct tse_buffer *buffer)
 
 /* tx_lock held to protect access to queued tx list
  */
-u32 sgdma_tx_completions(struct altera_tse_private *priv)
+u32 sgdma_tx_completions(struct altera_dma_private *priv)
 {
 	u32 ready = 0;
 
@@ -217,13 +217,13 @@ u32 sgdma_tx_completions(struct altera_tse_private *priv)
 	return ready;
 }
 
-void sgdma_start_rxdma(struct altera_tse_private *priv)
+void sgdma_start_rxdma(struct altera_dma_private *priv)
 {
 	sgdma_async_read(priv);
 }
 
-void sgdma_add_rx_desc(struct altera_tse_private *priv,
-		       struct tse_buffer *rxbuffer)
+void sgdma_add_rx_desc(struct altera_dma_private *priv,
+		       struct altera_dma_buffer *rxbuffer)
 {
 	queue_rx(priv, rxbuffer);
 }
@@ -231,12 +231,12 @@ void sgdma_add_rx_desc(struct altera_tse_private *priv,
 /* status is returned on upper 16 bits,
  * length is returned in lower 16 bits
  */
-u32 sgdma_rx_status(struct altera_tse_private *priv)
+u32 sgdma_rx_status(struct altera_dma_private *priv)
 {
 	struct sgdma_descrip __iomem *base =
 		(struct sgdma_descrip __iomem *)priv->rx_dma_desc;
 	struct sgdma_descrip __iomem *desc = NULL;
-	struct tse_buffer *rxbuffer = NULL;
+	struct altera_dma_buffer *rxbuffer = NULL;
 	unsigned int rxstatus = 0;
 
 	u32 sts = csrrd32(priv->rx_dma_csr, sgdma_csroffs(status));
@@ -339,14 +339,14 @@ static void sgdma_setup_descrip(struct sgdma_descrip __iomem *desc,
  * If read status indicate not busy and a status, restart the async
  * DMA read.
  */
-static int sgdma_async_read(struct altera_tse_private *priv)
+static int sgdma_async_read(struct altera_dma_private *priv)
 {
 	struct sgdma_descrip __iomem *descbase =
 		(struct sgdma_descrip __iomem *)priv->rx_dma_desc;
 
 	struct sgdma_descrip __iomem *cdesc = &descbase[0];
 	struct sgdma_descrip __iomem *ndesc = &descbase[1];
-	struct tse_buffer *rxbuffer = NULL;
+	struct altera_dma_buffer *rxbuffer = NULL;
 
 	if (!sgdma_rxbusy(priv)) {
 		rxbuffer = queue_rx_peekhead(priv);
@@ -384,7 +384,7 @@ static int sgdma_async_read(struct altera_tse_private *priv)
 	return 0;
 }
 
-static int sgdma_async_write(struct altera_tse_private *priv,
+static int sgdma_async_write(struct altera_dma_private *priv,
 			     struct sgdma_descrip __iomem *desc)
 {
 	if (sgdma_txbusy(priv))
@@ -409,7 +409,7 @@ static int sgdma_async_write(struct altera_tse_private *priv,
 }
 
 static dma_addr_t
-sgdma_txphysaddr(struct altera_tse_private *priv,
+sgdma_txphysaddr(struct altera_dma_private *priv,
 		 struct sgdma_descrip __iomem *desc)
 {
 	dma_addr_t paddr = priv->txdescmem_busaddr;
@@ -418,7 +418,7 @@ sgdma_txphysaddr(struct altera_tse_private *priv,
 }
 
 static dma_addr_t
-sgdma_rxphysaddr(struct altera_tse_private *priv,
+sgdma_rxphysaddr(struct altera_dma_private *priv,
 		 struct sgdma_descrip __iomem *desc)
 {
 	dma_addr_t paddr = priv->rxdescmem_busaddr;
@@ -443,70 +443,76 @@ sgdma_rxphysaddr(struct altera_tse_private *priv,
 		}							\
 	} while (0)
 
-/* adds a tse_buffer to the tail of a tx buffer list.
+/* adds a altera_dma_buffer to the tail of a tx buffer list.
  * assumes the caller is managing and holding a mutual exclusion
  * primitive to avoid simultaneous pushes/pops to the list.
  */
 static void
-queue_tx(struct altera_tse_private *priv, struct tse_buffer *buffer)
+queue_tx(struct altera_dma_private *priv, struct altera_dma_buffer *buffer)
 {
 	list_add_tail(&buffer->lh, &priv->txlisthd);
 }
 
 
-/* adds a tse_buffer to the tail of a rx buffer list
+/* adds a altera_dma_buffer to the tail of a rx buffer list
  * assumes the caller is managing and holding a mutual exclusion
  * primitive to avoid simultaneous pushes/pops to the list.
  */
 static void
-queue_rx(struct altera_tse_private *priv, struct tse_buffer *buffer)
+queue_rx(struct altera_dma_private *priv, struct altera_dma_buffer *buffer)
 {
 	list_add_tail(&buffer->lh, &priv->rxlisthd);
 }
 
-/* dequeues a tse_buffer from the transmit buffer list, otherwise
+/* dequeues a altera_dma_buffer from the transmit buffer list, otherwise
  * returns NULL if empty.
  * assumes the caller is managing and holding a mutual exclusion
  * primitive to avoid simultaneous pushes/pops to the list.
  */
-static struct tse_buffer *
-dequeue_tx(struct altera_tse_private *priv)
+static struct altera_dma_buffer *
+dequeue_tx(struct altera_dma_private *priv)
 {
-	struct tse_buffer *buffer = NULL;
-	list_remove_head(&priv->txlisthd, buffer, struct tse_buffer, lh);
+	struct altera_dma_buffer *buffer = NULL;
+
+	list_remove_head(&priv->txlisthd, buffer, struct altera_dma_buffer, lh);
+
 	return buffer;
 }
 
-/* dequeues a tse_buffer from the receive buffer list, otherwise
+/* dequeues a altera_dma_buffer from the receive buffer list, otherwise
  * returns NULL if empty
  * assumes the caller is managing and holding a mutual exclusion
  * primitive to avoid simultaneous pushes/pops to the list.
  */
-static struct tse_buffer *
-dequeue_rx(struct altera_tse_private *priv)
+static struct altera_dma_buffer *
+dequeue_rx(struct altera_dma_private *priv)
 {
-	struct tse_buffer *buffer = NULL;
-	list_remove_head(&priv->rxlisthd, buffer, struct tse_buffer, lh);
+	struct altera_dma_buffer *buffer = NULL;
+
+	list_remove_head(&priv->rxlisthd, buffer, struct altera_dma_buffer, lh);
+
 	return buffer;
 }
 
-/* dequeues a tse_buffer from the receive buffer list, otherwise
+/* dequeues a altera_dma_buffer from the receive buffer list, otherwise
  * returns NULL if empty
  * assumes the caller is managing and holding a mutual exclusion
  * primitive to avoid simultaneous pushes/pops to the list while the
  * head is being examined.
  */
-static struct tse_buffer *
-queue_rx_peekhead(struct altera_tse_private *priv)
+static struct altera_dma_buffer *
+queue_rx_peekhead(struct altera_dma_private *priv)
 {
-	struct tse_buffer *buffer = NULL;
-	list_peek_head(&priv->rxlisthd, buffer, struct tse_buffer, lh);
+	struct altera_dma_buffer *buffer = NULL;
+
+	list_peek_head(&priv->rxlisthd, buffer, struct altera_dma_buffer, lh);
+
 	return buffer;
 }
 
 /* check and return rx sgdma status without polling
  */
-static int sgdma_rxbusy(struct altera_tse_private *priv)
+static int sgdma_rxbusy(struct altera_dma_private *priv)
 {
 	return csrrd32(priv->rx_dma_csr, sgdma_csroffs(status))
 		       & SGDMA_STSREG_BUSY;
@@ -515,7 +521,7 @@ static int sgdma_rxbusy(struct altera_tse_private *priv)
 /* waits for the tx sgdma to finish it's current operation, returns 0
  * when it transitions to nonbusy, returns 1 if the operation times out
  */
-static int sgdma_txbusy(struct altera_tse_private *priv)
+static int sgdma_txbusy(struct altera_dma_private *priv)
 {
 	int delay = 0;
 
diff --git a/drivers/net/ethernet/altera/altera_sgdma.h b/drivers/net/ethernet/altera/altera_sgdma.h
index 6a41833f0965..0a24a98eaf3b 100644
--- a/drivers/net/ethernet/altera/altera_sgdma.h
+++ b/drivers/net/ethernet/altera/altera_sgdma.h
@@ -1,27 +1,38 @@
-/* SPDX-License-Identifier: GPL-2.0-only */
 /* Altera TSE SGDMA and MSGDMA Linux driver
  * Copyright (C) 2014 Altera Corporation. All rights reserved
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #ifndef __ALTERA_SGDMA_H__
 #define __ALTERA_SGDMA_H__
 
-void sgdma_reset(struct altera_tse_private *priv);
-void sgdma_enable_txirq(struct altera_tse_private *priv);
-void sgdma_enable_rxirq(struct altera_tse_private *priv);
-void sgdma_disable_rxirq(struct altera_tse_private *priv);
-void sgdma_disable_txirq(struct altera_tse_private *priv);
-void sgdma_clear_rxirq(struct altera_tse_private *priv);
-void sgdma_clear_txirq(struct altera_tse_private *priv);
-netdev_tx_t sgdma_tx_buffer(struct altera_tse_private *priv,
-			    struct tse_buffer *buffer);
-u32 sgdma_tx_completions(struct altera_tse_private *priv);
-void sgdma_add_rx_desc(struct altera_tse_private *priv,
-		       struct tse_buffer *buffer);
-void sgdma_status(struct altera_tse_private *priv);
-u32 sgdma_rx_status(struct altera_tse_private *priv);
-int sgdma_initialize(struct altera_tse_private *priv);
-void sgdma_uninitialize(struct altera_tse_private *priv);
-void sgdma_start_rxdma(struct altera_tse_private *priv);
+void sgdma_reset(struct altera_dma_private *priv);
+void sgdma_enable_txirq(struct altera_dma_private *priv);
+void sgdma_enable_rxirq(struct altera_dma_private *priv);
+void sgdma_disable_rxirq(struct altera_dma_private *priv);
+void sgdma_disable_txirq(struct altera_dma_private *priv);
+void sgdma_clear_rxirq(struct altera_dma_private *priv);
+void sgdma_clear_txirq(struct altera_dma_private *priv);
+netdev_tx_t sgdma_tx_buffer(struct altera_dma_private *priv,
+			    struct altera_dma_buffer *buffer);
+u32 sgdma_tx_completions(struct altera_dma_private *priv);
+void sgdma_add_rx_desc(struct altera_dma_private *priv,
+		       struct altera_dma_buffer *buffer);
+void sgdma_status(struct altera_dma_private *priv);
+u32 sgdma_rx_status(struct altera_dma_private *priv);
+int sgdma_initialize(struct altera_dma_private *priv);
+void sgdma_uninitialize(struct altera_dma_private *priv);
+void sgdma_start_rxdma(struct altera_dma_private *priv);
 
 #endif /*  __ALTERA_SGDMA_H__ */
diff --git a/drivers/net/ethernet/altera/altera_tse.h b/drivers/net/ethernet/altera/altera_tse.h
index 35f99bfce4ef..25cd00ed78b1 100644
--- a/drivers/net/ethernet/altera/altera_tse.h
+++ b/drivers/net/ethernet/altera/altera_tse.h
@@ -367,46 +367,12 @@ struct altera_tse_mac {
 #define ALTERA_TSE_TX_CMD_STAT_TX_SHIFT16	BIT(18)
 #define ALTERA_TSE_RX_CMD_STAT_RX_SHIFT16	BIT(25)
 
-/* Wrapper around a pointer to a socket buffer,
- * so a DMA handle can be stored along with the buffer
- */
-struct tse_buffer {
-	struct list_head lh;
-	struct sk_buff *skb;
-	dma_addr_t dma_addr;
-	u32 len;
-	int mapped_as_page;
-};
-
 struct altera_tse_private;
 
 #define ALTERA_DTYPE_SGDMA 1
 #define ALTERA_DTYPE_MSGDMA 2
 #define ALTERA_DTYPE_MSGDMA_PREF 3
 
-/* standard DMA interface for SGDMA and MSGDMA */
-struct altera_dmaops {
-	int altera_dtype;
-	int dmamask;
-	void (*reset_dma)(struct altera_tse_private *priv);
-	void (*enable_txirq)(struct altera_tse_private *priv);
-	void (*enable_rxirq)(struct altera_tse_private *priv);
-	void (*disable_txirq)(struct altera_tse_private *priv);
-	void (*disable_rxirq)(struct altera_tse_private *priv);
-	void (*clear_txirq)(struct altera_tse_private *priv);
-	void (*clear_rxirq)(struct altera_tse_private *priv);
-	netdev_tx_t (*tx_buffer)(struct altera_tse_private *priv,
-				 struct tse_buffer *buffer);
-	u32 (*tx_completions)(struct altera_tse_private *priv);
-	void (*add_rx_desc)(struct altera_tse_private *priv,
-			    struct tse_buffer *buffer);
-	u32 (*get_rx_status)(struct altera_tse_private *priv);
-	int (*init_dma)(struct altera_tse_private *priv);
-	void (*uninit_dma)(struct altera_tse_private *priv);
-	void (*start_rxdma)(struct altera_tse_private *priv);
-	void (*start_txdma)(struct altera_tse_private *priv);
-};
-
 /* This structure is private to each device.
  */
 struct altera_tse_private {
@@ -417,50 +383,16 @@ struct altera_tse_private {
 	/* MAC address space */
 	struct altera_tse_mac __iomem *mac_dev;
 
+	/* Shared DMA structure */
+	struct altera_dma_private dma_priv;
+
 	/* TSE Revision */
 	u32	revision;
 
 	/* Shared PTP structure */
 	struct intel_fpga_tod_private ptp_priv;
-	int hwts_tx_en;
-	int hwts_rx_en;
 	u32 ptp_enable;
 
-	/* mSGDMA Rx Dispatcher address space */
-	void __iomem *rx_dma_csr;
-	void __iomem *rx_dma_desc;
-	void __iomem *rx_dma_resp;
-
-	/* mSGDMA Tx Dispatcher address space */
-	void __iomem *tx_dma_csr;
-	void __iomem *tx_dma_desc;
-
-	/* mSGDMA Rx Prefecher address space */
-	void __iomem *rx_pref_csr;
-	struct msgdma_pref_extended_desc *pref_rxdesc;
-	dma_addr_t pref_rxdescphys;
-	u32 pref_rx_prod;
-
-	/* mSGDMA Tx Prefecher address space */
-	void __iomem *tx_pref_csr;
-	struct msgdma_pref_extended_desc *pref_txdesc;
-	dma_addr_t pref_txdescphys;
-	u32 rx_poll_freq;
-	u32 tx_poll_freq;
-
-	/* Rx buffers queue */
-	struct tse_buffer *rx_ring;
-	u32 rx_cons;
-	u32 rx_prod;
-	u32 rx_ring_size;
-	u32 rx_dma_buf_sz;
-
-	/* Tx ring buffer */
-	struct tse_buffer *tx_ring;
-	u32 tx_prod;
-	u32 tx_cons;
-	u32 tx_ring_size;
-
 	/* Interrupts */
 	u32 tx_irq;
 	u32 rx_irq;
diff --git a/drivers/net/ethernet/altera/altera_tse_ethtool.c b/drivers/net/ethernet/altera/altera_tse_ethtool.c
index 01467c816a68..55fb46fb28d0 100644
--- a/drivers/net/ethernet/altera/altera_tse_ethtool.c
+++ b/drivers/net/ethernet/altera/altera_tse_ethtool.c
@@ -22,6 +22,7 @@
 #include <linux/net_tstamp.h>
 #include <linux/phy.h>
 
+#include "altera_eth_dma.h"
 #include "altera_tse.h"
 #include "altera_utils.h"
 
diff --git a/drivers/net/ethernet/altera/altera_tse_main.c b/drivers/net/ethernet/altera/altera_tse_main.c
index fcb53c79d708..6025c59653c0 100644
--- a/drivers/net/ethernet/altera/altera_tse_main.c
+++ b/drivers/net/ethernet/altera/altera_tse_main.c
@@ -40,6 +40,7 @@
 #include <asm/cacheflush.h>
 
 #include "altera_utils.h"
+#include "altera_eth_dma.h"
 #include "altera_tse.h"
 #include "altera_sgdma.h"
 #include "altera_msgdma.h"
@@ -79,7 +80,7 @@ MODULE_PARM_DESC(dma_tx_num, "Number of descriptors in the TX list");
 /* Allow network stack to resume queueing packets after we've
  * finished transmitting at least 1/4 of the packets in the queue.
  */
-#define TSE_TX_THRESH(x)	(x->tx_ring_size / 4)
+#define TSE_TX_THRESH(x)	((x)->dma_priv.tx_ring_size / 4)
 
 #define TXQUEUESTOP_THRESHHOLD	2
 
@@ -87,7 +88,8 @@ static const struct of_device_id altera_tse_ids[];
 
 static inline u32 tse_tx_avail(struct altera_tse_private *priv)
 {
-	return priv->tx_cons + priv->tx_ring_size - priv->tx_prod - 1;
+	return priv->dma_priv.tx_cons + priv->dma_priv.tx_ring_size
+		- priv->dma_priv.tx_prod - 1;
 }
 
 /* PCS Register read/write functions
@@ -213,7 +215,7 @@ static void altera_tse_mdio_destroy(struct net_device *dev)
 }
 
 static int tse_init_rx_buffer(struct altera_tse_private *priv,
-			      struct tse_buffer *rxbuffer, int len)
+			      struct altera_dma_buffer *rxbuffer, int len)
 {
 	rxbuffer->skb = netdev_alloc_skb_ip_align(priv->dev, len);
 	if (!rxbuffer->skb)
@@ -234,7 +236,7 @@ static int tse_init_rx_buffer(struct altera_tse_private *priv,
 }
 
 static void tse_free_rx_buffer(struct altera_tse_private *priv,
-			       struct tse_buffer *rxbuffer)
+			       struct altera_dma_buffer *rxbuffer)
 {
 	struct sk_buff *skb = rxbuffer->skb;
 	dma_addr_t dma_addr = rxbuffer->dma_addr;
@@ -253,7 +255,7 @@ static void tse_free_rx_buffer(struct altera_tse_private *priv,
 /* Unmap and free Tx buffer resources
  */
 static void tse_free_tx_buffer(struct altera_tse_private *priv,
-			       struct tse_buffer *buffer)
+			       struct altera_dma_buffer *buffer)
 {
 	if (buffer->dma_addr) {
 		if (buffer->mapped_as_page)
@@ -272,44 +274,46 @@ static void tse_free_tx_buffer(struct altera_tse_private *priv,
 
 static int alloc_init_skbufs(struct altera_tse_private *priv)
 {
-	unsigned int rx_descs = priv->rx_ring_size;
-	unsigned int tx_descs = priv->tx_ring_size;
+	unsigned int rx_descs = priv->dma_priv.rx_ring_size;
+	unsigned int tx_descs = priv->dma_priv.tx_ring_size;
 	int ret = -ENOMEM;
 	int i;
 
 	/* Create Rx ring buffer */
-	priv->rx_ring = kcalloc(rx_descs, sizeof(struct tse_buffer),
-				GFP_KERNEL);
-	if (!priv->rx_ring)
+	priv->dma_priv.rx_ring = kcalloc(rx_descs,
+					 sizeof(struct altera_dma_private),
+					 GFP_KERNEL);
+	if (!priv->dma_priv.rx_ring)
 		goto err_rx_ring;
 
 	/* Create Tx ring buffer */
-	priv->tx_ring = kcalloc(tx_descs, sizeof(struct tse_buffer),
-				GFP_KERNEL);
-	if (!priv->tx_ring)
+	priv->dma_priv.tx_ring = kcalloc(tx_descs,
+					 sizeof(struct altera_dma_private),
+					 GFP_KERNEL);
+	if (!priv->dma_priv.tx_ring)
 		goto err_tx_ring;
 
-	priv->tx_cons = 0;
-	priv->tx_prod = 0;
+	priv->dma_priv.tx_cons = 0;
+	priv->dma_priv.tx_prod = 0;
 
 	/* Init Rx ring */
 	for (i = 0; i < rx_descs; i++) {
-		ret = tse_init_rx_buffer(priv, &priv->rx_ring[i],
-					 priv->rx_dma_buf_sz);
+		ret = tse_init_rx_buffer(priv, &priv->dma_priv.rx_ring[i],
+					 priv->dma_priv.rx_dma_buf_sz);
 		if (ret)
 			goto err_init_rx_buffers;
 	}
 
-	priv->rx_cons = 0;
-	priv->rx_prod = 0;
+	priv->dma_priv.rx_cons = 0;
+	priv->dma_priv.rx_prod = 0;
 
 	return 0;
 err_init_rx_buffers:
 	while (--i >= 0)
-		tse_free_rx_buffer(priv, &priv->rx_ring[i]);
-	kfree(priv->tx_ring);
+		tse_free_rx_buffer(priv, &priv->dma_priv.rx_ring[i]);
+	kfree(priv->dma_priv.tx_ring);
 err_tx_ring:
-	kfree(priv->rx_ring);
+	kfree(priv->dma_priv.rx_ring);
 err_rx_ring:
 	return ret;
 }
@@ -317,37 +321,39 @@ static int alloc_init_skbufs(struct altera_tse_private *priv)
 static void free_skbufs(struct net_device *dev)
 {
 	struct altera_tse_private *priv = netdev_priv(dev);
-	unsigned int rx_descs = priv->rx_ring_size;
-	unsigned int tx_descs = priv->tx_ring_size;
+	unsigned int rx_descs = priv->dma_priv.rx_ring_size;
+	unsigned int tx_descs = priv->dma_priv.tx_ring_size;
 	int i;
 
 	/* Release the DMA TX/RX socket buffers */
 	for (i = 0; i < rx_descs; i++)
-		tse_free_rx_buffer(priv, &priv->rx_ring[i]);
+		tse_free_rx_buffer(priv, &priv->dma_priv.rx_ring[i]);
 	for (i = 0; i < tx_descs; i++)
-		tse_free_tx_buffer(priv, &priv->tx_ring[i]);
+		tse_free_tx_buffer(priv, &priv->dma_priv.tx_ring[i]);
 
 
-	kfree(priv->tx_ring);
+	kfree(priv->dma_priv.tx_ring);
 }
 
 /* Reallocate the skb for the reception process
  */
 static inline void tse_rx_refill(struct altera_tse_private *priv)
 {
-	unsigned int rxsize = priv->rx_ring_size;
+	unsigned int rxsize = priv->dma_priv.rx_ring_size;
 	unsigned int entry;
 	int ret;
 
-	for (; priv->rx_cons - priv->rx_prod > 0;
-			priv->rx_prod++) {
-		entry = priv->rx_prod % rxsize;
-		if (likely(priv->rx_ring[entry].skb == NULL)) {
-			ret = tse_init_rx_buffer(priv, &priv->rx_ring[entry],
-				priv->rx_dma_buf_sz);
+	for (; priv->dma_priv.rx_cons - priv->dma_priv.rx_prod > 0;
+			priv->dma_priv.rx_prod++) {
+		entry = priv->dma_priv.rx_prod % rxsize;
+		if (likely(priv->dma_priv.rx_ring[entry].skb == NULL)) {
+			ret = tse_init_rx_buffer(priv,
+				&priv->dma_priv.rx_ring[entry],
+				priv->dma_priv.rx_dma_buf_sz);
 			if (unlikely(ret != 0))
 				break;
-			priv->dmaops->add_rx_desc(priv, &priv->rx_ring[entry]);
+			priv->dmaops->add_rx_desc(&priv->dma_priv,
+					&priv->dma_priv.rx_ring[entry]);
 		}
 	}
 }
@@ -374,7 +380,8 @@ static int tse_rx(struct altera_tse_private *priv, int limit)
 	unsigned int count = 0;
 	unsigned int next_entry;
 	struct sk_buff *skb;
-	unsigned int entry = priv->rx_cons % priv->rx_ring_size;
+	unsigned int entry
+		= priv->dma_priv.rx_cons % priv->dma_priv.rx_ring_size;
 	u32 rxstatus;
 	u16 pktlength;
 	u16 pktstatus;
@@ -385,7 +392,7 @@ static int tse_rx(struct altera_tse_private *priv, int limit)
 	* (reading the last byte of the response pops the value from the fifo.)
 	*/
 	while ((count < limit) &&
-	       ((rxstatus = priv->dmaops->get_rx_status(priv)) != 0)) {
+	       ((rxstatus = priv->dmaops->get_rx_status(&priv->dma_priv)) != 0)) {
 		pktstatus = rxstatus >> 16;
 		pktlength = rxstatus & 0xffff;
 
@@ -401,9 +408,9 @@ static int tse_rx(struct altera_tse_private *priv, int limit)
 		pktlength -= 2;
 
 		count++;
-		next_entry = (++priv->rx_cons) % priv->rx_ring_size;
+		next_entry = (++priv->dma_priv.rx_cons) % priv->dma_priv.rx_ring_size;
 
-		skb = priv->rx_ring[entry].skb;
+		skb = priv->dma_priv.rx_ring[entry].skb;
 		if (unlikely(!skb)) {
 			netdev_err(priv->dev,
 				   "%s: Inconsistent Rx descriptor chain\n",
@@ -411,12 +418,14 @@ static int tse_rx(struct altera_tse_private *priv, int limit)
 			priv->dev->stats.rx_dropped++;
 			break;
 		}
-		priv->rx_ring[entry].skb = NULL;
+		priv->dma_priv.rx_ring[entry].skb = NULL;
 
 		skb_put(skb, pktlength);
 
-		dma_unmap_single(priv->device, priv->rx_ring[entry].dma_addr,
-				 priv->rx_ring[entry].len, DMA_FROM_DEVICE);
+		dma_unmap_single(priv->device,
+				 priv->dma_priv.rx_ring[entry].dma_addr,
+				 priv->dma_priv.rx_ring[entry].len,
+				 DMA_FROM_DEVICE);
 
 		if (netif_msg_pktdata(priv)) {
 			netdev_info(priv->dev, "frame received %d bytes\n",
@@ -447,30 +456,31 @@ static int tse_rx(struct altera_tse_private *priv, int limit)
  */
 static int tse_tx_complete(struct altera_tse_private *priv)
 {
-	unsigned int txsize = priv->tx_ring_size;
+	unsigned int txsize = priv->dma_priv.tx_ring_size;
 	u32 ready;
 	unsigned int entry;
-	struct tse_buffer *tx_buff;
+	struct altera_dma_buffer *tx_buff;
 	int txcomplete = 0;
 
 	spin_lock(&priv->tx_lock);
 
-	ready = priv->dmaops->tx_completions(priv);
+	ready = priv->dmaops->tx_completions(&priv->dma_priv);
 
 	/* Free sent buffers */
-	while (ready && (priv->tx_cons != priv->tx_prod)) {
-		entry = priv->tx_cons % txsize;
-		tx_buff = &priv->tx_ring[entry];
+	while (ready && (priv->dma_priv.tx_cons != priv->dma_priv.tx_prod)) {
+		entry = priv->dma_priv.tx_cons % txsize;
+		tx_buff = &priv->dma_priv.tx_ring[entry];
 
 		if (netif_msg_tx_done(priv))
 			netdev_dbg(priv->dev, "%s: curr %d, dirty %d\n",
-				   __func__, priv->tx_prod, priv->tx_cons);
+				   __func__, priv->dma_priv.tx_prod,
+				   priv->dma_priv.tx_cons);
 
 		if (likely(tx_buff->skb))
 			priv->dev->stats.tx_packets++;
 
 		tse_free_tx_buffer(priv, tx_buff);
-		priv->tx_cons++;
+		priv->dma_priv.tx_cons++;
 
 		txcomplete++;
 		ready--;
@@ -513,8 +523,8 @@ static int tse_poll(struct napi_struct *napi, int budget)
 			   rxcomplete, budget);
 
 		spin_lock_irqsave(&priv->rxdma_irq_lock, flags);
-		priv->dmaops->enable_rxirq(priv);
-		priv->dmaops->enable_txirq(priv);
+		priv->dmaops->enable_rxirq(&priv->dma_priv);
+		priv->dmaops->enable_txirq(&priv->dma_priv);
 		spin_unlock_irqrestore(&priv->rxdma_irq_lock, flags);
 	}
 	return rxcomplete;
@@ -535,14 +545,14 @@ static irqreturn_t altera_isr(int irq, void *dev_id)
 
 	spin_lock(&priv->rxdma_irq_lock);
 	/* reset IRQs */
-	priv->dmaops->clear_rxirq(priv);
-	priv->dmaops->clear_txirq(priv);
+	priv->dmaops->clear_rxirq(&priv->dma_priv);
+	priv->dmaops->clear_txirq(&priv->dma_priv);
 	spin_unlock(&priv->rxdma_irq_lock);
 
 	if (likely(napi_schedule_prep(&priv->napi))) {
 		spin_lock(&priv->rxdma_irq_lock);
-		priv->dmaops->disable_rxirq(priv);
-		priv->dmaops->disable_txirq(priv);
+		priv->dmaops->disable_rxirq(&priv->dma_priv);
+		priv->dmaops->disable_txirq(&priv->dma_priv);
 		spin_unlock(&priv->rxdma_irq_lock);
 		__napi_schedule(&priv->napi);
 	}
@@ -561,9 +571,9 @@ static irqreturn_t altera_isr(int irq, void *dev_id)
 static netdev_tx_t tse_start_xmit(struct sk_buff *skb, struct net_device *dev)
 {
 	struct altera_tse_private *priv = netdev_priv(dev);
-	unsigned int txsize = priv->tx_ring_size;
+	unsigned int txsize = priv->dma_priv.tx_ring_size;
 	unsigned int entry;
-	struct tse_buffer *buffer = NULL;
+	struct altera_dma_buffer *buffer = NULL;
 	int nfrags = skb_shinfo(skb)->nr_frags;
 	unsigned int nopaged_len = skb_headlen(skb);
 	enum netdev_tx ret = NETDEV_TX_OK;
@@ -584,8 +594,8 @@ static netdev_tx_t tse_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	}
 
 	/* Map the first skb fragment */
-	entry = priv->tx_prod % txsize;
-	buffer = &priv->tx_ring[entry];
+	entry = priv->dma_priv.tx_prod % txsize;
+	buffer = &priv->dma_priv.tx_ring[entry];
 
 	dma_addr = dma_map_single(priv->device, skb->data, nopaged_len,
 				  DMA_TO_DEVICE);
@@ -599,17 +609,17 @@ static netdev_tx_t tse_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	buffer->dma_addr = dma_addr;
 	buffer->len = nopaged_len;
 
-	ret = priv->dmaops->tx_buffer(priv, buffer);
+	ret = priv->dmaops->tx_buffer(&priv->dma_priv, buffer);
 	if (ret)
 		goto out;
 
 	if (unlikely((skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP) &&
-		     priv->hwts_tx_en))
+		     priv->dma_priv.hwts_tx_en))
 		skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
 	else
 		skb_tx_timestamp(skb);
 
-	priv->tx_prod++;
+	priv->dma_priv.tx_prod++;
 	dev->stats.tx_bytes += skb->len;
 
 	if (unlikely(tse_tx_avail(priv) <= TXQUEUESTOP_THRESHHOLD)) {
@@ -1163,11 +1173,11 @@ static int tse_open(struct net_device *dev)
 	unsigned long int flags;
 
 	/* set tx and rx ring size */
-	priv->rx_ring_size = dma_rx_num;
-	priv->tx_ring_size = dma_tx_num;
+	priv->dma_priv.rx_ring_size = dma_rx_num;
+	priv->dma_priv.tx_ring_size = dma_tx_num;
 
 	/* Reset and configure TSE MAC and probe associated PHY */
-	ret = priv->dmaops->init_dma(priv);
+	ret = priv->dmaops->init_dma(&priv->dma_priv);
 	if (ret != 0) {
 		netdev_err(dev, "Cannot initialize DMA\n");
 		goto phy_error;
@@ -1205,7 +1215,7 @@ static int tse_open(struct net_device *dev)
 		goto alloc_skbuf_error;
 	}
 
-	priv->dmaops->reset_dma(priv);
+	priv->dmaops->reset_dma(&priv->dma_priv);
 
 	/* Create and initialize the TX/RX descriptors chains. */
 	ret = alloc_init_skbufs(priv);
@@ -1235,12 +1245,13 @@ static int tse_open(struct net_device *dev)
 
 	/* Enable DMA interrupts */
 	spin_lock_irqsave(&priv->rxdma_irq_lock, flags);
-	priv->dmaops->enable_rxirq(priv);
-	priv->dmaops->enable_txirq(priv);
+	priv->dmaops->enable_rxirq(&priv->dma_priv);
+	priv->dmaops->enable_txirq(&priv->dma_priv);
 
 	/* Setup RX descriptor chain */
-	for (i = 0; i < priv->rx_ring_size; i++)
-		priv->dmaops->add_rx_desc(priv, &priv->rx_ring[i]);
+	for (i = 0; i < priv->dma_priv.rx_ring_size; i++)
+		priv->dmaops->add_rx_desc(&priv->dma_priv,
+					  &priv->dma_priv.rx_ring[i]);
 
 	spin_unlock_irqrestore(&priv->rxdma_irq_lock, flags);
 
@@ -1251,16 +1262,16 @@ static int tse_open(struct net_device *dev)
 	if (ret)
 		netdev_warn(dev, "Failed PTP initialization\n");
 
-	priv->hwts_tx_en = 0;
-	priv->hwts_rx_en = 0;
+	priv->dma_priv.hwts_tx_en = 0;
+	priv->dma_priv.hwts_rx_en = 0;
 
 	napi_enable(&priv->napi);
 	netif_start_queue(dev);
 
-	priv->dmaops->start_rxdma(priv);
+	priv->dmaops->start_rxdma(&priv->dma_priv);
 
 	if (priv->dmaops->start_txdma)
-		priv->dmaops->start_txdma(priv);
+		priv->dmaops->start_txdma(&priv->dma_priv);
 
 	/* Start MAC Rx/Tx */
 	spin_lock(&priv->mac_cfg_lock);
@@ -1295,8 +1306,8 @@ static int tse_shutdown(struct net_device *dev)
 
 	/* Disable DMA interrupts */
 	spin_lock_irqsave(&priv->rxdma_irq_lock, flags);
-	priv->dmaops->disable_rxirq(priv);
-	priv->dmaops->disable_txirq(priv);
+	priv->dmaops->disable_rxirq(&priv->dma_priv);
+	priv->dmaops->disable_txirq(&priv->dma_priv);
 	spin_unlock_irqrestore(&priv->rxdma_irq_lock, flags);
 
 	/* Free the IRQ lines */
@@ -1314,13 +1325,13 @@ static int tse_shutdown(struct net_device *dev)
 	 */
 	if (ret)
 		netdev_dbg(dev, "Cannot reset MAC core (error: %d)\n", ret);
-	priv->dmaops->reset_dma(priv);
+	priv->dmaops->reset_dma(&priv->dma_priv);
 	free_skbufs(dev);
 
 	spin_unlock(&priv->tx_lock);
 	spin_unlock(&priv->mac_cfg_lock);
 
-	priv->dmaops->uninit_dma(priv);
+	priv->dmaops->uninit_dma(&priv->dma_priv);
 
 	return 0;
 }
@@ -1349,10 +1360,10 @@ static int tse_do_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 
 		switch (config.tx_type) {
 		case HWTSTAMP_TX_OFF:
-			priv->hwts_tx_en = 0;
+			priv->dma_priv.hwts_tx_en = 0;
 			break;
 		case HWTSTAMP_TX_ON:
-			priv->hwts_tx_en = 1;
+			priv->dma_priv.hwts_tx_en = 1;
 			break;
 		default:
 			return -ERANGE;
@@ -1360,11 +1371,11 @@ static int tse_do_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 
 		switch (config.rx_filter) {
 		case HWTSTAMP_FILTER_NONE:
-			priv->hwts_rx_en = 0;
+			priv->dma_priv.hwts_rx_en = 0;
 			config.rx_filter = HWTSTAMP_FILTER_NONE;
 			break;
 		default:
-			priv->hwts_rx_en = 1;
+			priv->dma_priv.hwts_rx_en = 1;
 			config.rx_filter = HWTSTAMP_FILTER_ALL;
 			break;
 		}
@@ -1379,12 +1390,12 @@ static int tse_do_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 	if (cmd == SIOCGHWTSTAMP) {
 		config.flags = 0;
 
-		if (priv->hwts_tx_en)
+		if (priv->dma_priv.hwts_tx_en)
 			config.tx_type = HWTSTAMP_TX_ON;
 		else
 			config.tx_type = HWTSTAMP_TX_OFF;
 
-		if (priv->hwts_rx_en)
+		if (priv->dma_priv.hwts_rx_en)
 			config.rx_filter = HWTSTAMP_FILTER_ALL;
 		else
 			config.rx_filter = HWTSTAMP_FILTER_NONE;
@@ -1449,10 +1460,8 @@ static int altera_tse_probe(struct platform_device *pdev)
 	struct net_device *ndev;
 	int ret = -ENODEV;
 	struct resource *control_port;
-	struct resource *dma_res;
 	struct altera_tse_private *priv;
 	const unsigned char *macaddr;
-	void __iomem *descmap;
 	const struct of_device_id *of_id = NULL;
 
 	ndev = alloc_etherdev(sizeof(struct altera_tse_private));
@@ -1465,15 +1474,25 @@ static int altera_tse_probe(struct platform_device *pdev)
 
 	priv = netdev_priv(ndev);
 	priv->device = &pdev->dev;
+	priv->dma_priv.device = &pdev->dev;
 	priv->dev = ndev;
+	priv->dma_priv.dev = ndev;
 	priv->msg_enable = netif_msg_init(debug, default_msg_level);
+	priv->dma_priv.msg_enable = netif_msg_init(debug, default_msg_level);
 
 	of_id = of_match_device(altera_tse_ids, &pdev->dev);
 
 	if (of_id)
 		priv->dmaops = (struct altera_dmaops *)of_id->data;
 
-
+	/* Map DMA */
+	ret = altera_eth_dma_probe(pdev, &priv->dma_priv,
+				   priv->dmaops->altera_dtype);
+	if (ret) {
+		dev_err(&pdev->dev, "cannot map DMA\n");
+		goto err_free_netdev;
+	}
+#if 0
 	if (priv->dmaops &&
 	    priv->dmaops->altera_dtype == ALTERA_DTYPE_SGDMA) {
 		/* Get the mapped address to the SGDMA descriptor memory */
@@ -1561,6 +1580,7 @@ static int altera_tse_probe(struct platform_device *pdev)
 	} else {
 		goto err_free_netdev;
 	}
+#endif
 
 	if (!dma_set_mask(priv->device, DMA_BIT_MASK(priv->dmaops->dmamask)))
 		dma_set_coherent_mask(priv->device,
@@ -1576,20 +1596,6 @@ static int altera_tse_probe(struct platform_device *pdev)
 	if (ret)
 		goto err_free_netdev;
 
-	/* xSGDMA Rx Dispatcher address space */
-	ret = request_and_map(pdev, "rx_csr", &dma_res,
-			      &priv->rx_dma_csr);
-	if (ret)
-		goto err_free_netdev;
-
-
-	/* xSGDMA Tx Dispatcher address space */
-	ret = request_and_map(pdev, "tx_csr", &dma_res,
-			      &priv->tx_dma_csr);
-	if (ret)
-		goto err_free_netdev;
-
-
 	/* Rx IRQ */
 	priv->rx_irq = platform_get_irq_byname(pdev, "rx_irq");
 	if (priv->rx_irq == -ENXIO) {
@@ -1650,7 +1656,7 @@ static int altera_tse_probe(struct platform_device *pdev)
 	/* The DMA buffer size already accounts for an alignment bias
 	 * to avoid unaligned access exceptions for the NIOS processor,
 	 */
-	priv->rx_dma_buf_sz = ALTERA_RXDMABUFFER_SIZE;
+	priv->dma_priv.rx_dma_buf_sz = ALTERA_RXDMABUFFER_SIZE;
 
 	/* get default MAC address from device tree */
 	macaddr = of_get_mac_address(pdev->dev.of_node);
diff --git a/drivers/net/ethernet/altera/altera_utils.c b/drivers/net/ethernet/altera/altera_utils.c
index c9bc7d0ea02a..f235a08f875e 100644
--- a/drivers/net/ethernet/altera/altera_utils.c
+++ b/drivers/net/ethernet/altera/altera_utils.c
@@ -3,6 +3,7 @@
  * Copyright (C) 2014 Altera Corporation. All rights reserved
  */
 
+#include "altera_eth_dma.h"
 #include "altera_tse.h"
 #include "altera_utils.h"
 
-- 
2.26.1

