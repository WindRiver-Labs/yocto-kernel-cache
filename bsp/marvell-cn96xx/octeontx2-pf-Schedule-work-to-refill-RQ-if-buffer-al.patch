From da19c22478eb0d9a9555a6d4a2ed34b41b59438b Mon Sep 17 00:00:00 2001
From: Geetha sowjanya <gakula@marvell.com>
Date: Fri, 21 Jun 2019 11:42:54 +0530
Subject: [PATCH 080/138] octeontx2-pf: Schedule work to refill RQ if buffer
 alloc fails in atomic context.

commit 01864a44de70a1eda59f290e25dfe0535f933c5c from
git@git.assembla.com:cavium/WindRiver.linux.git

Receive buffer allocation in NAPI may fail to get free pages when system
is low on free memory. In such scenarios schedule a delayed work to alloc
Receive buffers in non-atomic context.

Change-Id: I5bfcd5f0a5e7e812fad9c7d4feceb41c9ddce1f8
Signed-off-by: Geetha sowjanya <gakula@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/11405
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../marvell/octeontx2/nic/otx2_common.c       | 52 +++++++++++++++++++
 .../marvell/octeontx2/nic/otx2_common.h       |  6 +++
 .../marvell/octeontx2/nic/otx2_txrx.c         | 34 ++++++++----
 .../marvell/octeontx2/nic/otx2_txrx.h         |  2 +
 4 files changed, 85 insertions(+), 9 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
index a2816b98323a..ff6a7782b68f 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
@@ -747,6 +747,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 	cq->rbpool = &qset->pool[pool_id];
 
 	cq->cq_idx = qidx;
+	cq->refill_task_sched = false;
 
 	/* Get memory to put this msg */
 	aq = otx2_mbox_alloc_msg_nix_aq_enq(&pfvf->mbox);
@@ -786,6 +787,45 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 	return otx2_sync_mbox_msg(&pfvf->mbox);
 }
 
+static void otx2_pool_refill_task(struct work_struct *work)
+{
+	struct otx2_cq_queue *cq;
+	struct otx2_pool *rbpool;
+	struct refill_work *wrk;
+	int qidx, free_ptrs = 0;
+	struct otx2_nic *pfvf;
+	s64 bufptr;
+
+	wrk = container_of(work, struct refill_work, pool_refill_work.work);
+	pfvf = wrk->pf;
+	qidx = wrk - pfvf->refill_wrk;
+	cq = &pfvf->qset.cq[qidx];
+	rbpool = cq->rbpool;
+	free_ptrs = cq->pool_ptrs;
+
+	while (cq->pool_ptrs) {
+		bufptr = otx2_alloc_rbuf(pfvf, rbpool, GFP_KERNEL);
+		if (bufptr <= 0) {
+			/* Schedule a WQ if we fails to free atleast half of the
+			 * pointers else enable napi for this RQ.
+			 */
+			if (!((free_ptrs - cq->pool_ptrs) > free_ptrs / 2)) {
+				struct delayed_work *dwork;
+
+				dwork = &wrk->pool_refill_work;
+				schedule_delayed_work(dwork,
+						      msecs_to_jiffies(100));
+			} else {
+				cq->refill_task_sched = false;
+			}
+			return;
+		}
+		otx2_aura_freeptr(pfvf, qidx, bufptr + OTX2_HEAD_ROOM);
+		cq->pool_ptrs--;
+	}
+	cq->refill_task_sched = false;
+}
+
 int otx2_config_nix_queues(struct otx2_nic *pfvf)
 {
 	int qidx, err;
@@ -815,6 +855,18 @@ int otx2_config_nix_queues(struct otx2_nic *pfvf)
 			return err;
 	}
 
+	/* Initialize work queue for receive buffer refill */
+
+	pfvf->refill_wrk = devm_kcalloc(pfvf->dev, pfvf->qset.cq_cnt,
+					sizeof(struct refill_work), GFP_KERNEL);
+	if (!pfvf->refill_wrk)
+		return -ENOMEM;
+
+	for (qidx = 0; qidx < pfvf->qset.cq_cnt; qidx++) {
+		pfvf->refill_wrk[qidx].pf = pfvf;
+		INIT_DELAYED_WORK(&pfvf->refill_wrk[qidx].pool_refill_work,
+				  otx2_pool_refill_task);
+	}
 	return 0;
 }
 
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
index a4f0decd4907..171510b55595 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
@@ -158,6 +158,11 @@ struct flr_work {
 	struct otx2_nic *pf;
 };
 
+struct refill_work {
+	struct delayed_work pool_refill_work;
+	struct otx2_nic *pf;
+};
+
 struct otx2_nic {
 	void __iomem		*reg_base;
 	struct pci_dev		*pdev;
@@ -195,6 +200,7 @@ struct otx2_nic {
 	struct list_head	flows;
 	struct workqueue_struct	*flr_wq;
 	struct flr_work		*flr_wrk;
+	struct refill_work	*refill_wrk;
 
 	u8			hw_rx_tstamp;
 	u8			hw_tx_tstamp;
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
index a210dd392a72..62f1e3167bfa 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
@@ -222,8 +222,7 @@ static inline void otx2_set_rxtstamp(struct otx2_nic *pfvf, struct sk_buff *skb)
 }
 
 static void otx2_rcv_pkt_handler(struct otx2_nic *pfvf,
-				 struct otx2_cq_queue *cq, void *cqe,
-				 int *pool_ptrs)
+				 struct otx2_cq_queue *cq, void *cqe)
 {
 	struct nix_cqe_hdr_s *cqe_hdr = (struct nix_cqe_hdr_s *)cqe;
 	struct otx2_qset *qset = &pfvf->qset;
@@ -295,7 +294,7 @@ static void otx2_rcv_pkt_handler(struct otx2_nic *pfvf,
 				otx2_skb_add_frag(pfvf, skb, *iova, len);
 			}
 			iova++;
-			(*pool_ptrs)++;
+			cq->pool_ptrs++;
 		}
 
 		/* When SEGS = 1, only one IOVA is followed by NIX_RX_SG_S.
@@ -344,9 +343,9 @@ static void otx2_rcv_pkt_handler(struct otx2_nic *pfvf,
 int otx2_napi_handler(struct otx2_cq_queue *cq,
 		      struct otx2_nic *pfvf, int budget)
 {
-	int tx_pkts = 0, tx_bytes = 0, pool_ptrs = 0;
 	struct otx2_pool *rbpool = cq->rbpool;
 	int processed_cqe = 0, workdone = 0;
+	int tx_pkts = 0, tx_bytes = 0;
 	struct nix_cqe_hdr_s *cqe_hdr;
 	struct netdev_queue *txq;
 	u64 cq_status;
@@ -398,7 +397,7 @@ int otx2_napi_handler(struct otx2_cq_queue *cq,
 		switch (cqe_hdr->cqe_type) {
 		case NIX_XQE_TYPE_RX:
 			/* Receive packet handler*/
-			otx2_rcv_pkt_handler(pfvf, cq, cqe_hdr, &pool_ptrs);
+			otx2_rcv_pkt_handler(pfvf, cq, cqe_hdr);
 			workdone++;
 			break;
 		case NIX_XQE_TYPE_SEND:
@@ -416,16 +415,28 @@ int otx2_napi_handler(struct otx2_cq_queue *cq,
 		netdev_tx_completed_queue(txq, tx_pkts, tx_bytes);
 	}
 
-	if (!pool_ptrs)
+	if (!cq->pool_ptrs)
 		return 0;
 
 	/* Refill pool with new buffers */
-	while (pool_ptrs) {
+	while (cq->pool_ptrs) {
 		bufptr = otx2_alloc_rbuf(pfvf, rbpool, GFP_ATOMIC);
-		if (bufptr <= 0)
+		if (bufptr <= 0) {
+			struct refill_work *work;
+			struct delayed_work *dwork;
+
+			work = &pfvf->refill_wrk[cq->cq_idx];
+			dwork = &work->pool_refill_work;
+			/* Schedule a task if no other task is running */
+			if (!cq->refill_task_sched) {
+				cq->refill_task_sched = true;
+				schedule_delayed_work(dwork,
+						      msecs_to_jiffies(100));
+			}
 			break;
+		}
 		otx2_aura_freeptr(pfvf, cq->cq_idx, bufptr + OTX2_HEAD_ROOM);
-		pool_ptrs--;
+		cq->pool_ptrs--;
 	}
 	otx2_get_page(rbpool);
 
@@ -452,6 +463,11 @@ int otx2_poll(struct napi_struct *napi, int budget)
 		cq = &qset->cq[cq_idx];
 		qcount = otx2_read64(pfvf, NIX_LF_CINTX_CNT(cq_poll->cint_idx));
 		qcount = (qcount >> 32) & 0xFFFF;
+		/* If the RQ refill WQ task is running, skip napi
+		 * scheduler for this queue.
+		 */
+		if (cq->refill_task_sched)
+			continue;
 		workdone += otx2_napi_handler(cq, pfvf, budget);
 		if (workdone && qcount == 1)
 			break;
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.h
index 411250a9456c..d6ca35951278 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.h
@@ -97,7 +97,9 @@ struct otx2_pool {
 struct otx2_cq_queue {
 	u8			cq_idx;
 	u8			cint_idx; /* CQ interrupt id */
+	u8			refill_task_sched;
 	u16			cqe_size;
+	u16			pool_ptrs;
 	u32			cqe_cnt;
 	u32			cq_head;
 	u32			cq_tail;
-- 
2.17.1

