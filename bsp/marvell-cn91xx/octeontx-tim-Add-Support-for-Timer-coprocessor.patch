From 648f14f772c76ed4bcde694d415cab648df146ae Mon Sep 17 00:00:00 2001
From: Tirumalesh Chalamarla <tchalamarla@caviumnetworks.com>
Date: Tue, 9 Oct 2018 00:40:21 +0300
Subject: [PATCH 0248/1051] octeontx-tim: Add Support for Timer coprocessor

Timer is used to schdule an event at a given time.
This will be useful for applications which works with TCP etc.

Signed-off-by: Yuri Tolstov <yuri.tolstov@cavium.com>
Signed-off-by: Tirumalesh Chalamarla <tchalamarla@caviumnetworks.com>
Signed-off-by: Yury Norov <ynorov@caviumnetworks.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/cavium/Kconfig           |   7 +
 .../ethernet/cavium/octeontx-83xx/Makefile    |   2 +
 .../net/ethernet/cavium/octeontx-83xx/tim.h   |  31 +
 .../cavium/octeontx-83xx/timpf_main.c         | 648 ++++++++++++++++++
 4 files changed, 688 insertions(+)
 create mode 100644 drivers/net/ethernet/cavium/octeontx-83xx/tim.h
 create mode 100644 drivers/net/ethernet/cavium/octeontx-83xx/timpf_main.c

diff --git a/drivers/net/ethernet/cavium/Kconfig b/drivers/net/ethernet/cavium/Kconfig
index a0e90ccb5dd3..d64a7628447c 100644
--- a/drivers/net/ethernet/cavium/Kconfig
+++ b/drivers/net/ethernet/cavium/Kconfig
@@ -155,6 +155,13 @@ config OCTEONTX_LBK
 	help
 	  Select this option to enable LBK.
 
+config OCTEONTX_TIM_PF
+	tristate "OcteonTX TIM physical function driver(TIM_PF)"
+	depends on 64BIT && OCTEONTX_RST
+	default y
+	help
+	  Select this option to enable TIM Physical function.
+
 config OCTEONTX
 	tristate "OcteonTX coprocessor maintanier"
 	depends on THUNDER_NIC_BGX && OCTEONTX_FPA_PF && OCTEONTX_SSO_PF
diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/Makefile b/drivers/net/ethernet/cavium/octeontx-83xx/Makefile
index 20d6b56e2798..ee7ed4e7d8e1 100644
--- a/drivers/net/ethernet/cavium/octeontx-83xx/Makefile
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/Makefile
@@ -9,6 +9,7 @@ obj-$(CONFIG_OCTEONTX_SSO_PF) += ssopf.o
 obj-$(CONFIG_OCTEONTX_SSOW_PF) += ssowpf.o
 obj-$(CONFIG_OCTEONTX_PKO_PF) += pkopf.o
 obj-$(CONFIG_OCTEONTX_LBK) += lbk.o
+obj-$(CONFIG_OCTEONTX_TIM_PF) += timpf.o
 obj-$(CONFIG_OCTEONTX) += octeontx.o
 
 fpapf-objs := fpapf_main.o
@@ -19,3 +20,4 @@ ssowpf-objs := ssowpf_main.o
 pkopf-objs := pkopf_main.o
 octeontx-objs := octeontx_main.o bgx.o
 lbk-objs := lbk_main.o
+timpf-objs := timpf_main.o
diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/tim.h b/drivers/net/ethernet/cavium/octeontx-83xx/tim.h
new file mode 100644
index 000000000000..973f81d7fcac
--- /dev/null
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/tim.h
@@ -0,0 +1,31 @@
+/*
+ * Copyright (C) 2017 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of version 2 of the GNU General Public License
+ * as published by the Free Software Foundation.
+ */
+
+#ifndef __TIM_H__
+#define __TIM_H__
+
+#include <linux/pci.h>
+#include <linux/types.h>
+#include "octeontx.h"
+
+struct timpf_com_s {
+	int (*create_domain)(u32 id, u16 domain_id, u32 num_vfs,
+			     struct octeontx_master_com_t *com, void *domain,
+		struct kobject *kobj, char *g_name);
+	int (*free_domain)(u32 id, u16 domain_id);
+	int (*reset_domain)(u32 id, u16 domain_id);
+	int (*receive_message)(u32 id, u16 domain_id, struct mbox_hdr *hdr,
+			       union mbox_data *req, union mbox_data *resp,
+			       void *mdata);
+	int (*get_vf_count)(u32 id);
+};
+
+extern struct timpf_com_s timpf_com;
+
+#endif /* __TIM_H__ */
+
diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/timpf_main.c b/drivers/net/ethernet/cavium/octeontx-83xx/timpf_main.c
new file mode 100644
index 000000000000..14b401eb109e
--- /dev/null
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/timpf_main.c
@@ -0,0 +1,648 @@
+/*
+ * Copyright (C) 2017 Cavium, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of version 2 of the GNU General Public License
+ * as published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/pci.h>
+#include <linux/random.h>
+
+#include "rst.h"
+#include "tim.h"
+
+#define DRV_NAME "octeontx-tim"
+#define DRV_VERSION "0.1"
+
+/* TIM PCI Device ID (See PCC_DEV_IDL_E in HRM) */
+#define PCI_DEVICE_ID_OCTEONTX_TIM_PF 0xA050
+#define TIM_VF_CFG_SIZE		0x100000
+#define TIM_VF_OFFSET(__x)	(0x10000000 | (TIM_VF_CFG_SIZE * (__x)))
+
+#define PCI_TIM_PF_CFG_BAR	0
+#define PCI_TIM_PF_MSIX_BAR	4
+#define TIM_PF_MSIX_COUNT	2
+
+#define TIM_DEV_PER_NODE	1
+#define TIM_VFS_PER_DEV		4
+
+#define TIM_RINGS_PER_DEV	TIM_VFS_PER_DEV
+#define TIM_RING_NODE_SHIFT	6 /* 2 pow(6) */
+#define TIM_RING_MASK		(TIM_RINGS_PER_DEV - 1)
+#define TIM_MAX_RINGS \
+	(TIM_RINGS_PER_DEV * TIM_DEV_PER_NODE * OCTTX_MAX_NODES)
+
+/* TIM PF CSR offsets (within a single TIM device) */
+#define TIM_REG_FLAGS		0x0
+#define TIM_BKT_SKIP_INT	0x30
+#define TIM_BKT_SKIP_INT_W1S	0x40
+#define TIM_ECCERR_INT		0x60
+#define TIM_ECCERR_INT_W1S	0x68
+#define TIM_DBG2		0xA0
+#define TIM_DBG3		0xA8
+#define TIM_FR_RN_CYCLES	0xC0
+#define TIM_BKT_SKIP_ENA_W1C	0x100
+#define TIM_BKT_SKIP_ENA_W1S	0x108
+#define TIM_ECCERR_ENA_W1C	0x110
+#define TIM_ECCERR_ENA_W1S	0x118
+#define TIM_ENG_ACTIVE(__x)	(0x1000 | ((__x) << 3))
+#define TIM_RING_CTL0(__x)	(0x2000 | ((__x) << 3))
+#define TIM_RING_CTL1(__x)	(0x2400 | ((__x) << 3))
+#define TIM_RING_CTL2(__x)	(0x2800 | ((__x) << 3))
+#define TIM_RING_GMCTL(__x)	(0x2A00 | ((__x) << 3))
+#define TIM_BKT_SKIP_INT_STATUS(__x)	(0x2C00 | ((__x) << 3))
+#define TIM_VRING_LATE(__x)	(0x2E00 | ((__x) << 3))
+
+/* TIM device configuration and control block */
+struct timpf_vf {
+	struct octeontx_pf_vf domain;
+	int vf_id;
+};
+
+struct timpf {
+	struct list_head list; /* List of TIM devices */
+	struct pci_dev *pdev;
+	void __iomem *reg_base;
+	struct msix_entry *msix_entries;
+	int id; /* Global/multinode TIM device ID (nod + TIM index).*/
+	int total_vfs;
+	int vfs_in_use;
+#define TIM_SRIOV_ENABLED 0x1
+	u32 flags;
+	struct timpf_vf vf[TIM_VFS_PER_DEV];
+};
+
+/* Global list of TIM devices and rings */
+static atomic_t tim_count = ATOMIC_INIT(0);
+static DEFINE_SPINLOCK(octeontx_tim_dev_lock);
+static LIST_HEAD(octeontx_tim_devices);
+
+/* Interface to the RST device */
+static struct rst_com_s *rst;
+
+static inline void tim_reg_write(struct timpf *tim, u64 offset, u64 val)
+{
+	writeq_relaxed(val, tim->reg_base + offset);
+}
+
+static inline u64 tim_reg_read(struct timpf *tim, u64 offset)
+{
+	return readq_relaxed(tim->reg_base + offset);
+}
+
+static inline int node_from_devid(int id)
+{
+	return id;
+}
+
+static inline int dev_from_devid(int id)
+{
+	return id;
+}
+
+static inline int ringid_is_valid(unsigned int ringid)
+{
+	return ringid < TIM_MAX_RINGS;
+}
+
+static inline int node_from_ringid(int ringid)
+{
+	return ringid >> TIM_RING_NODE_SHIFT;
+}
+
+static inline int ring_from_ringid(int ringid)
+{
+	return ringid & TIM_RING_MASK;
+}
+
+static struct timpf *tim_dev_from_id(int id)
+{
+	struct timpf *tim;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		if (tim->id == id) {
+			spin_unlock(&octeontx_tim_dev_lock);
+			return tim;
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return NULL;
+}
+
+static struct timpf *tim_dev_from_devid(int id, int domain_id, int devid)
+{
+	struct timpf *tim;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		if (node_from_devid(tim->id) == id &&
+		    dev_from_devid(tim->id) == devid) {
+			spin_unlock(&octeontx_tim_dev_lock);
+			return tim;
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return NULL;
+}
+
+static struct timpf *tim_dev_from_ringid(int id, int domain_id,
+					 int ringid, int *ring)
+{
+	int i;
+	struct timpf *tim;
+	struct timpf_vf *vf;
+	int node = node_from_ringid(ringid);
+
+	if (id != node || !ringid_is_valid(ringid))
+		return NULL;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		if (node_from_devid(tim->id) != id)
+			continue;
+		for (i = 0; i < tim->total_vfs; i++) {
+			vf = &tim->vf[i];
+			if (vf->domain.domain_id == domain_id &&
+			    vf->domain.subdomain_id == ringid) {
+				spin_unlock(&octeontx_tim_dev_lock);
+				*ring = ring_from_ringid(ringid);
+				return tim;
+			}
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return NULL;
+}
+
+/* Main MBOX message processing function.
+ */
+static int tim_pf_receive_message(u32 id, u16 domain_id, struct mbox_hdr *hdr,
+				  union mbox_data *req, union mbox_data *resp,
+				  void *mdata)
+{
+	struct timpf *tim;
+	int rc, ring; /* TIM device local ring index */
+
+	if (!mdata)
+		return -ENOMEM;
+
+	rc = 0;
+	switch (hdr->msg) {
+	case MBOX_TIM_DEV_INFO_GET: {
+		struct mbox_tim_dev_info *info = mdata;
+		int i;
+
+		tim = tim_dev_from_devid(id, domain_id, hdr->vfid);
+		if (!tim) {
+			rc = -EINVAL;
+			break;
+		}
+		for (i = 0; i < 4; i++)
+			info->eng_active[i] = tim_reg_read(tim,
+					TIM_ENG_ACTIVE(i));
+		info->tim_clk_freq = rst->get_sclk_freq(tim->id);
+		resp->data = sizeof(struct mbox_tim_dev_info);
+		/*make sure the writes are comitted*/
+		wmb();
+		break;
+	}
+	case MBOX_TIM_RING_INFO_GET: {
+		struct mbox_tim_ring_info *info = mdata;
+
+		tim = tim_dev_from_ringid(id, domain_id, hdr->vfid, &ring);
+		if (!tim) {
+			rc = -EINVAL;
+			break;
+		}
+		info->node = id;
+		info->ring_late = tim_reg_read(tim, TIM_VRING_LATE(ring));
+		resp->data = sizeof(struct mbox_tim_ring_info);
+		/*make sure the writes are comitted*/
+		wmb();
+		break;
+	}
+	case MBOX_TIM_RING_CONFIG_SET: {
+		struct mbox_tim_ring_conf *conf = mdata;
+
+		tim = tim_dev_from_ringid(id, domain_id, hdr->vfid, &ring);
+		if (!tim) {
+			rc = -EINVAL;
+			break;
+		}
+		tim_reg_write(tim, TIM_RING_CTL2(ring), conf->ctl2);
+		tim_reg_write(tim, TIM_RING_CTL0(ring), conf->ctl0);
+		tim_reg_write(tim, TIM_RING_CTL1(ring), conf->ctl1);
+		resp->data = 0;
+		break;
+	}
+	default:
+		rc = -EINVAL;
+		resp->data = 0;
+		break;
+	}
+	if (rc)
+		hdr->res_code = MBOX_RET_INVALID;
+	else
+		hdr->res_code = MBOX_RET_SUCCESS;
+	return rc;
+}
+
+void identify(struct timpf_vf *vf, u16 domain_id, u16 subdomain_id)
+{
+	u64 offs = 0x100; /* TIM_VRING_BASE */
+	u64 reg = MBOX_TIM_IDENT_CODE(domain_id, subdomain_id);
+
+	writeq_relaxed(reg, vf->domain.reg_base + offs);
+}
+
+/* Domain control functions.
+ */
+static int tim_pf_create_domain(u32 id, u16 domain_id, u32 num_vfs,
+				struct octeontx_master_com_t *com, void *domain,
+		struct kobject *kobj, char *g_name)
+{
+	struct timpf *tim = NULL;
+	struct timpf_vf *vf;
+	resource_size_t ba;
+	u64 reg, gmid;
+	int i, vf_idx = 0;
+	struct pci_dev *virtfn;
+
+	gmid = get_gmid(domain_id);
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		for (i = 0; i < tim->total_vfs; i++) {
+			vf = &tim->vf[i];
+			if (vf->domain.in_use)
+				continue;
+
+			ba = pci_resource_start(tim->pdev, PCI_TIM_PF_CFG_BAR);
+			ba += TIM_VF_OFFSET(i);
+			vf->domain.reg_base = ioremap(ba, TIM_VF_CFG_SIZE);
+			vf->domain.domain_id = domain_id;
+			vf->domain.subdomain_id = vf_idx;
+			vf->domain.gmid = get_gmid(domain_id);
+			vf->domain.master = com;
+			vf->domain.master_data = domain;
+			vf->domain.in_use = true;
+
+			reg = ((uint64_t)i + 1) << 16 /*STRM*/ | gmid; /*GMID*/
+			tim_reg_write(tim, TIM_RING_GMCTL(i), reg);
+
+			if (kobj && g_name) {
+				virtfn = pci_get_domain_bus_and_slot(
+						pci_domain_nr(tim->pdev->bus),
+						pci_iov_virtfn_bus(tim->pdev,
+								   i),
+						pci_iov_virtfn_devfn(
+						tim->pdev, i));
+				if (!virtfn)
+					break;
+
+				sysfs_add_link_to_group(kobj, g_name,
+							&virtfn->dev.kobj,
+					virtfn->dev.kobj.name);
+			}
+			identify(vf, domain_id, vf_idx);
+			vf_idx++;
+			if (vf_idx == num_vfs) {
+				tim->vfs_in_use += num_vfs;
+				break;
+			}
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return 0;
+}
+
+static int tim_pf_destroy_domain(u32 id, u16 domain_id)
+{
+	struct timpf *tim = NULL;
+	struct timpf_vf *vf;
+	u64 reg;
+	int i;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		for (i = 0; i < tim->total_vfs; i++) {
+			vf = &tim->vf[i];
+			if (vf->domain.in_use &&
+			    vf->domain.domain_id == domain_id) {
+				vf->domain.in_use = false;
+				/* Cleanup MMU info.*/
+				reg = tim_reg_read(tim, TIM_RING_GMCTL(i));
+				reg &= ~0xFFFFull; /*GMID*/
+				tim_reg_write(tim, TIM_RING_GMCTL(i), reg);
+			}
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return 0;
+}
+
+static int tim_ring_reset(struct timpf *tim, int ring)
+{
+	u64 reg;
+
+	/* Stop the ring and set the power-on defaults for CTL registers.*/
+	reg = tim_reg_read(tim, TIM_RING_CTL1(ring));
+	reg &= ~(1ull << 47); /*ENA*/
+	tim_reg_write(tim, TIM_RING_CTL1(ring), reg);
+	return 0;
+}
+
+static int tim_pf_reset_domain(u32 id, u16 domain_id)
+{
+	struct timpf *tim = NULL;
+	struct timpf_vf *vf;
+	int i, sdom;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(tim, &octeontx_tim_devices, list) {
+		for (i = 0; i < tim->total_vfs; i++) {
+			vf = &tim->vf[i];
+			sdom = vf->domain.subdomain_id;
+			if (vf->domain.in_use &&
+			    vf->domain.domain_id == domain_id) {
+				tim_ring_reset(tim, i);
+				identify(vf, domain_id, sdom);
+			}
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+	return 0;
+}
+
+static int tim_pf_get_vf_count(u32 id)
+{
+	struct timpf *tim;
+
+	tim = tim_dev_from_id(id);
+	if (!tim)
+		return 0;
+	return tim->total_vfs;
+}
+
+/* Interface with the main OCTEONTX driver.
+ */
+struct timpf_com_s timpf_com  = {
+	.create_domain = tim_pf_create_domain,
+	.free_domain = tim_pf_destroy_domain,
+	.reset_domain = tim_pf_reset_domain,
+	.receive_message = tim_pf_receive_message,
+	.get_vf_count = tim_pf_get_vf_count
+};
+EXPORT_SYMBOL(timpf_com);
+
+/* Driver startup initialization and shutdown functions.
+ */
+static int tim_init(struct timpf *tim)
+{
+	u64 reg;
+	int i;
+
+	/* Initialize TIM rings.*/
+	reg = (1ull << 48) |  /*LOCK_EN*/
+		(1ull << 44); /*ENA_LDWB*/
+	for (i = 0; i < TIM_RINGS_PER_DEV; i++) {
+		tim_reg_write(tim, TIM_RING_CTL1(i), reg);
+		tim_reg_write(tim, TIM_RING_CTL0(i), 0);
+		tim_reg_write(tim, TIM_RING_CTL2(i), 0);
+	}
+	/* Reset free running counter and enable TIM device.*/
+	reg = (1ull << 2)/*RESET*/ | 0x1ull; /*ENA_TIM*/
+	tim_reg_write(tim, TIM_REG_FLAGS, reg);
+
+	/* Initialize domain resources.*/
+	for (i = 0; i < TIM_VFS_PER_DEV; i++) {
+		tim->vf[i].domain.in_use = 0;
+		tim->vf[i].domain.master = NULL;
+		tim->vf[i].domain.master_data = NULL;
+	}
+	return 0;
+}
+
+static irqreturn_t tim_bkt_skip_intr_handler(int irq, void *tim_irq)
+{
+	struct timpf *tim = (struct timpf *)tim_irq;
+	u64 reg;
+
+	reg = tim_reg_read(tim, TIM_BKT_SKIP_INT);
+	dev_err(&tim->pdev->dev, "BKT_SKIP_INT: 0x%llx\n", reg);
+	tim_reg_write(tim, TIM_BKT_SKIP_INT, reg);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t tim_eccerr_intr_handler(int irq, void *tim_irq)
+{
+	struct timpf *tim = (struct timpf *)tim_irq;
+	u64 reg;
+
+	reg = tim_reg_read(tim, TIM_ECCERR_INT);
+	dev_err(&tim->pdev->dev, "ECCERR_INT: 0x%llx\n", reg);
+	tim_reg_write(tim, TIM_ECCERR_INT, reg);
+	return IRQ_HANDLED;
+}
+
+static struct intr_hand intr[TIM_PF_MSIX_COUNT] = {
+	{~0ull, "tim bkt skip", TIM_BKT_SKIP_ENA_W1C, TIM_BKT_SKIP_ENA_W1S,
+		tim_bkt_skip_intr_handler},
+	{~0ull, "tim eccerr", TIM_ECCERR_ENA_W1C, TIM_ECCERR_ENA_W1S,
+		tim_eccerr_intr_handler}
+};
+
+static void tim_irq_free(struct timpf *tim)
+{
+	int i;
+
+	/* Clear interrupts */
+	for (i = 0; i < TIM_PF_MSIX_COUNT; i++) {
+		tim_reg_write(tim, intr[i].coffset, intr[i].mask);
+		if (tim->msix_entries[i].vector)
+			free_irq(tim->msix_entries[i].vector, tim);
+	}
+	pci_disable_msix(tim->pdev);
+}
+
+static int tim_irq_init(struct timpf *tim)
+{
+	int i;
+	int ret = 0;
+
+	/* Clear interrupts */
+	for (i = 0; i < TIM_PF_MSIX_COUNT; i++)
+		tim_reg_write(tim, intr[i].coffset, intr[i].mask);
+
+	tim->msix_entries = devm_kzalloc(&tim->pdev->dev,
+		TIM_PF_MSIX_COUNT * sizeof(struct msix_entry), GFP_KERNEL);
+	if (!tim->msix_entries)
+		return -ENOMEM;
+
+	for (i = 0; i < TIM_PF_MSIX_COUNT; i++)
+		tim->msix_entries[i].entry = i;
+
+	ret = pci_enable_msix_exact(tim->pdev, tim->msix_entries, TIM_PF_MSIX_COUNT);
+	if (ret < 0) {
+		dev_err(&tim->pdev->dev, "Failed to enable TIM MSIX.\n");
+		return ret;
+	}
+	for (i = 0; i < TIM_PF_MSIX_COUNT; i++) {
+		ret = request_irq(tim->msix_entries[i].vector, intr[i].handler,
+				  0, intr[i].name, tim);
+		if (ret)
+			goto free_irq;
+	}
+	/* Enable interrupts */
+	for (i = 0; i < TIM_PF_MSIX_COUNT; i++)
+		tim_reg_write(tim, intr[i].soffset, intr[i].mask);
+	return 0;
+
+free_irq:
+	for (; i < TIM_PF_MSIX_COUNT; i++)
+		tim->msix_entries[i].vector = 0;
+	tim_irq_free(tim);
+	return ret;
+}
+
+static int tim_sriov_configure(struct pci_dev *pdev, int numvfs)
+{
+	struct timpf *tim = pci_get_drvdata(pdev);
+	int ret = -EBUSY;
+	int disable = 0;
+
+	if (tim->vfs_in_use != 0)
+		return ret;
+
+	ret = 0;
+	if (tim->flags & TIM_SRIOV_ENABLED)
+		disable = 1;
+
+	if (disable) {
+		pci_disable_sriov(pdev);
+		tim->flags &= ~TIM_SRIOV_ENABLED;
+		tim->total_vfs = 0;
+	}
+	if (numvfs > 0) {
+		ret = pci_enable_sriov(pdev, numvfs);
+		if (ret == 0) {
+			tim->flags |= TIM_SRIOV_ENABLED;
+			tim->total_vfs = numvfs;
+			ret = numvfs;
+		}
+	}
+	return ret;
+}
+
+static int tim_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	struct device *dev = &pdev->dev;
+	struct timpf *tim;
+	int err = -ENOMEM;
+
+	rst = try_then_request_module(symbol_get(rst_com), "rst");
+	if (!rst)
+		return -ENODEV;
+
+	tim = devm_kzalloc(dev, sizeof(*tim), GFP_KERNEL);
+	if (!tim)
+		return -ENOMEM;
+
+	pci_set_drvdata(pdev, tim);
+	tim->pdev = pdev;
+
+	err = pcim_enable_device(pdev);
+	if (err) {
+		dev_err(dev, "Failed to enable TIM PCI device\n");
+		return err;
+	}
+	err = pci_request_regions(pdev, DRV_NAME);
+	if (err) {
+		dev_err(dev, "TIM PCI request regions failed\n");
+		return err;
+	}
+	tim->reg_base = pcim_iomap(pdev, PCI_TIM_PF_CFG_BAR, 0);
+	if (!tim->reg_base) {
+		dev_err(dev, "Can't map TIM CFG space\n");
+		return -ENOMEM;
+	}
+	tim->id = atomic_add_return(1, &tim_count);
+	tim->id -= 1; /* Convert to 0-based */
+
+	err = tim_init(tim);
+	if (err < 0) {
+		dev_err(dev, "Failed to initialize TIM device.\n");
+		return err;
+	}
+	err = tim_irq_init(tim);
+	if (err) {
+		atomic_sub_return(1, &tim_count);
+		dev_err(dev, "Failed to init TIM interrupts\n");
+		return err;
+	}
+	INIT_LIST_HEAD(&tim->list);
+	spin_lock(&octeontx_tim_dev_lock);
+	list_add(&tim->list, &octeontx_tim_devices);
+	spin_unlock(&octeontx_tim_dev_lock);
+	return 0;
+}
+
+static void tim_remove(struct pci_dev *pdev)
+{
+	struct timpf *tim = pci_get_drvdata(pdev);
+	struct timpf *curr;
+
+	if (!tim)
+		return;
+
+	spin_lock(&octeontx_tim_dev_lock);
+	list_for_each_entry(curr, &octeontx_tim_devices, list) {
+		if (curr == tim) {
+			list_del(&tim->list);
+			break;
+		}
+	}
+	spin_unlock(&octeontx_tim_dev_lock);
+
+	tim_irq_free(tim);
+	tim_sriov_configure(pdev, 0);
+}
+
+static const struct pci_device_id tim_id_table[] = {
+	{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVICE_ID_OCTEONTX_TIM_PF) },
+	{ 0 } /* End of table */
+};
+
+static struct pci_driver tim_driver = {
+	.name = DRV_NAME,
+	.id_table = tim_id_table,
+	.probe = tim_probe,
+	.remove = tim_remove,
+	.sriov_configure = tim_sriov_configure,
+};
+
+MODULE_AUTHOR("Cavium");
+MODULE_DESCRIPTION("Cavium OCTEONTX TIM PF Driver");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION(DRV_VERSION);
+MODULE_DEVICE_TABLE(pci, tim_id_table);
+
+static int __init tim_init_module(void)
+{
+	pr_info("%s, ver %s\n", DRV_NAME, DRV_VERSION);
+
+	return pci_register_driver(&tim_driver);
+}
+
+static void __exit tim_cleanup_module(void)
+{
+	pci_unregister_driver(&tim_driver);
+}
+
+module_init(tim_init_module);
+module_exit(tim_cleanup_module);
+
-- 
2.17.1

