From 831b0be1cf522d92ce11baa366762caadaba7aa8 Mon Sep 17 00:00:00 2001
From: Ashwin Sekhar T K <asekhar@marvell.com>
Date: Sat, 11 Sep 2021 14:52:51 +0530
Subject: [PATCH 02/11] soc: marvell: hw_access: add support to read aura/pool
 context

commit e49ca3dcd5f9609cf3b874e8d6c170b74bcb5db8 from
git@git.assembla.com:cavium/WindRiver.linux.git

Add the capability in the hw_access driver to read npa aura/pool
context by sending a request to admin queue.

Signed-off-by: Ashwin Sekhar T K <asekhar@marvell.com>
Change-Id: Ia9083f2a1de2cb4839f5b4317085199bae39278b
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/61209
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Reviewed-by: Sunil Kovvuri Goutham <sgoutham@marvell.com>
Integrated-by: Abhishek Paliwal <paliwal.abhishek@windriver.com>
---
 drivers/soc/marvell/hw-access/hw_rw_access.c | 77 ++++++++++++++++----
 1 file changed, 64 insertions(+), 13 deletions(-)

diff --git a/drivers/soc/marvell/hw-access/hw_rw_access.c b/drivers/soc/marvell/hw-access/hw_rw_access.c
index 38bdfbe5ea89..ab355f0cd3f0 100644
--- a/drivers/soc/marvell/hw-access/hw_rw_access.c
+++ b/drivers/soc/marvell/hw-access/hw_rw_access.c
@@ -48,7 +48,10 @@ struct hw_reg_cfg {
 struct hw_ctx_cfg {
 	u16	blkaddr;
 	u16	pcifunc;
-	u16	qidx;
+	union {
+		u16	qidx;
+		u16	aura;
+	};
 	u8	ctype;
 	u8	op;
 };
@@ -169,23 +172,17 @@ hw_access_csr_write(void __iomem *regbase, unsigned long arg)
 }
 
 static int
-hw_access_ctx_read(struct rvu *rvu, unsigned long arg)
+hw_access_nix_ctx_read(struct rvu *rvu, struct hw_ctx_cfg *ctx_cfg,
+		       unsigned long arg)
 {
 	struct nix_aq_enq_req aq_req;
 	struct nix_aq_enq_rsp rsp;
-	struct hw_ctx_cfg ctx_cfg;
-
-	if (copy_from_user(&ctx_cfg, (struct hw_ctx_cfg *)arg,
-			   sizeof(struct hw_ctx_cfg))) {
-		pr_err("Write Fault in copy from user\n");
-		return -EFAULT;
-	}
 
 	memset(&aq_req, 0, sizeof(struct nix_aq_enq_req));
-	aq_req.hdr.pcifunc = ctx_cfg.pcifunc;
-	aq_req.ctype = ctx_cfg.ctype;
-	aq_req.op = ctx_cfg.op;
-	aq_req.qidx = ctx_cfg.qidx;
+	aq_req.hdr.pcifunc = ctx_cfg->pcifunc;
+	aq_req.ctype = ctx_cfg->ctype;
+	aq_req.op = ctx_cfg->op;
+	aq_req.qidx = ctx_cfg->qidx;
 
 	if (rvu_mbox_handler_nix_aq_enq(rvu, &aq_req, &rsp)) {
 		pr_err("Failed to read the context\n");
@@ -201,6 +198,60 @@ hw_access_ctx_read(struct rvu *rvu, unsigned long arg)
 	return 0;
 }
 
+static int
+hw_access_npa_ctx_read(struct rvu *rvu, struct hw_ctx_cfg *ctx_cfg,
+		       unsigned long arg)
+{
+	struct npa_aq_enq_req aq_req;
+	struct npa_aq_enq_rsp rsp;
+
+	memset(&aq_req, 0, sizeof(struct npa_aq_enq_req));
+	aq_req.hdr.pcifunc = ctx_cfg->pcifunc;
+	aq_req.ctype = ctx_cfg->ctype;
+	aq_req.op = ctx_cfg->op;
+	aq_req.aura_id = ctx_cfg->aura;
+
+	if (rvu_mbox_handler_npa_aq_enq(rvu, &aq_req, &rsp)) {
+		pr_err("Failed to read the npa context\n");
+		return -EINVAL;
+	}
+
+	if (copy_to_user((struct npa_aq_enq_rsp *)arg,
+			 &rsp, sizeof(struct npa_aq_enq_rsp))) {
+		pr_err("Fault in copy to user\n");
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
+static int
+hw_access_ctx_read(struct rvu *rvu, unsigned long arg)
+{
+	struct hw_ctx_cfg ctx_cfg;
+	int rc;
+
+	if (copy_from_user(&ctx_cfg, (struct hw_ctx_cfg *)arg,
+			   sizeof(struct hw_ctx_cfg))) {
+		pr_err("Write Fault in copy from user\n");
+		return -EFAULT;
+	}
+
+	switch (ctx_cfg.blkaddr) {
+	case BLKADDR_NIX0:
+	case BLKADDR_NIX1:
+		rc = hw_access_nix_ctx_read(rvu, &ctx_cfg, arg);
+		break;
+	case BLKADDR_NPA:
+		rc = hw_access_npa_ctx_read(rvu, &ctx_cfg, arg);
+		break;
+	default:
+		rc = -EINVAL;
+		break;
+	}
+	return rc;
+}
+
 static int
 hw_access_cgx_info(struct rvu *rvu, unsigned long arg)
 {
-- 
2.31.1

