From b2cd5268f2fe062fcadb1d7f14c7eefa6e88256a Mon Sep 17 00:00:00 2001
From: Srujana Challa <schalla@marvell.com>
Date: Mon, 31 May 2021 12:21:15 +0530
Subject: [PATCH 1576/1921] octeontx2-af: update inline ipsec mbox to support
 98xx

Updates inline ipsec mailbox messages(CPT_INLINE_IPSEC_CFG &
NIX_INLINE_IPSEC_CFG) to support new block cpt1 on 98xx.
This patch configures NIX_AF_LFX_RX_IPSEC_CFG0 register such
that NIX0 always selects CPT0 and NIX1 always selects CPT1 to
send the CPT instructions.

Signed-off-by: Srujana Challa <schalla@marvell.com>
Change-Id: I25ad2f67a4edbab36e74546ccf70944eb4e541b4
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/53085
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Reviewed-by: Nithin Kumar Dabilpuram <ndabilpuram@marvell.com>
Reviewed-by: Sunil Kovvuri Goutham <sgoutham@marvell.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 .../net/ethernet/marvell/octeontx2/af/mbox.h  |  2 +
 .../ethernet/marvell/octeontx2/af/rvu_cpt.c   | 13 ++++
 .../ethernet/marvell/octeontx2/af/rvu_nix.c   | 71 +++++++++++++------
 3 files changed, 65 insertions(+), 21 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/af/mbox.h b/drivers/net/ethernet/marvell/octeontx2/af/mbox.h
index 37e42370d255..17083987213b 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/mbox.h
+++ b/drivers/net/ethernet/marvell/octeontx2/af/mbox.h
@@ -1177,6 +1177,8 @@ struct nix_inline_ipsec_cfg {
 	struct {
 		u8 egrp;
 		u8 opcode;
+		u16 param1;
+		u16 param2;
 	} gen_cfg;
 	struct {
 		u16 cpt_pf_func;
diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c b/drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c
index 7f1a7302dd6e..859e25dc4d72 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c
@@ -353,6 +353,7 @@ static int cpt_inline_ipsec_cfg_inbound(struct rvu *rvu, int blkaddr, u8 cptlf,
 					struct cpt_inline_ipsec_cfg_msg *req)
 {
 	u16 sso_pf_func = req->sso_pf_func;
+	u8 nix_sel;
 	u64 val;
 
 	val = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));
@@ -367,11 +368,14 @@ static int cpt_inline_ipsec_cfg_inbound(struct rvu *rvu, int blkaddr, u8 cptlf,
 	if (sso_pf_func && !is_pffunc_map_valid(rvu, sso_pf_func, BLKTYPE_SSO))
 		return CPT_AF_ERR_SSO_PF_FUNC_INVALID;
 
+	nix_sel = (blkaddr == BLKADDR_CPT1) ? 1 : 0;
 	/* Set PF_FUNC_INST */
 	if (req->enable)
 		val |= BIT_ULL(9);
 	else
 		val &= ~BIT_ULL(9);
+
+	val |= (u64)nix_sel << 8;
 	rvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);
 
 	if (sso_pf_func) {
@@ -403,6 +407,8 @@ static int cpt_inline_ipsec_cfg_outbound(struct rvu *rvu, int blkaddr, u8 cptlf,
 					 struct cpt_inline_ipsec_cfg_msg *req)
 {
 	u16 nix_pf_func = req->nix_pf_func;
+	int nix_blkaddr;
+	u8 nix_sel;
 	u64 val;
 
 	val = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));
@@ -430,6 +436,13 @@ static int cpt_inline_ipsec_cfg_outbound(struct rvu *rvu, int blkaddr, u8 cptlf,
 		val = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf));
 		val |= (u64)nix_pf_func << 48;
 		rvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf), val);
+
+		nix_blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, nix_pf_func);
+		nix_sel = (nix_blkaddr == BLKADDR_NIX0) ? 0 : 1;
+
+		val = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));
+		val |= (u64)nix_sel << 8;
+		rvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);
 	}
 
 	return 0;
diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c b/drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c
index 611bbe4463eb..8c854b9a9cb3 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c
@@ -4594,46 +4594,71 @@ int rvu_mbox_handler_nix_set_vlan_tpid(struct rvu *rvu,
 	return 0;
 }
 
-int rvu_mbox_handler_nix_inline_ipsec_cfg(struct rvu *rvu,
-					  struct nix_inline_ipsec_cfg *req,
-					  struct msg_rsp *rsp)
-{
-	int blkaddr;
-	u64 val;
+#define IPSEC_GEN_CFG_EGRP    GENMASK_ULL(50, 48)
+#define IPSEC_GEN_CFG_OPCODE  GENMASK_ULL(47, 32)
+#define IPSEC_GEN_CFG_PARAM1  GENMASK_ULL(31, 16)
+#define IPSEC_GEN_CFG_PARAM2  GENMASK_ULL(15, 0)
 
-	if (!is_block_implemented(rvu->hw, BLKADDR_CPT0))
-		return 0;
+#define CPT_INST_QSEL_BLOCK   GENMASK_ULL(28, 24)
+#define CPT_INST_QSEL_PF_FUNC GENMASK_ULL(23, 8)
+#define CPT_INST_QSEL_SLOT    GENMASK_ULL(7, 0)
 
-	blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, 0);
-	if (blkaddr < 0)
-		return NIX_AF_ERR_AF_LF_INVALID;
+static void nix_inline_ipsec_cfg(struct rvu *rvu, struct nix_inline_ipsec_cfg *req,
+				 int blkaddr)
+{
+	u8 cpt_idx, cpt_blkaddr;
+	u64 val;
 
+	cpt_idx = (blkaddr == BLKADDR_NIX0) ? 0 : 1;
 	if (req->enable) {
 		/* Enable context prefetching */
 		if (!is_rvu_otx2(rvu))
 			val = BIT_ULL(51);
 
 		/* Set OPCODE and EGRP */
-		val |= (u64)req->gen_cfg.egrp << 48 |
-		      (u64)req->gen_cfg.opcode << 32;
+		val |= FIELD_PREP(IPSEC_GEN_CFG_EGRP, req->gen_cfg.egrp);
+		val |= FIELD_PREP(IPSEC_GEN_CFG_OPCODE, req->gen_cfg.opcode);
+		val |= FIELD_PREP(IPSEC_GEN_CFG_PARAM1, req->gen_cfg.param1);
+		val |= FIELD_PREP(IPSEC_GEN_CFG_PARAM2, req->gen_cfg.param2);
+
 		rvu_write64(rvu, blkaddr, NIX_AF_RX_IPSEC_GEN_CFG, val);
 
 		/* Set CPT queue for inline IPSec */
-		val = (u64)req->inst_qsel.cpt_pf_func << 8 |
-		      req->inst_qsel.cpt_slot;
+		val = FIELD_PREP(CPT_INST_QSEL_SLOT, req->inst_qsel.cpt_slot);
+		val |= FIELD_PREP(CPT_INST_QSEL_PF_FUNC,
+				  req->inst_qsel.cpt_pf_func);
 
-		if (!is_rvu_otx2(rvu))
-			val |= BLKADDR_CPT0 << 24;
-		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_INST_QSEL(0), val);
+		if (!is_rvu_otx2(rvu)) {
+			cpt_blkaddr = (cpt_idx == 0) ? BLKADDR_CPT0 :
+						       BLKADDR_CPT1;
+			val |= FIELD_PREP(CPT_INST_QSEL_BLOCK, cpt_blkaddr);
+		}
+
+		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_INST_QSEL(cpt_idx),
+			    val);
 
 		/* Set CPT credit */
-		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_CREDIT(0),
+		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_CREDIT(cpt_idx),
 			    req->cpt_credit);
 	} else {
 		rvu_write64(rvu, blkaddr, NIX_AF_RX_IPSEC_GEN_CFG, 0x0);
-		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_INST_QSEL(0), 0x0);
-		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_CREDIT(0), 0x3FFFFF);
+		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_INST_QSEL(cpt_idx),
+			    0x0);
+		rvu_write64(rvu, blkaddr, NIX_AF_RX_CPTX_CREDIT(cpt_idx),
+			    0x3FFFFF);
 	}
+}
+
+int rvu_mbox_handler_nix_inline_ipsec_cfg(struct rvu *rvu,
+					  struct nix_inline_ipsec_cfg *req,
+					  struct msg_rsp *rsp)
+{
+	if (!is_block_implemented(rvu->hw, BLKADDR_CPT0))
+		return 0;
+
+	nix_inline_ipsec_cfg(rvu, req, BLKADDR_NIX0);
+	if (is_block_implemented(rvu->hw, BLKADDR_CPT1))
+		nix_inline_ipsec_cfg(rvu, req, BLKADDR_NIX1);
 
 	return 0;
 }
@@ -4657,6 +4682,10 @@ struct rvu *rvu, struct nix_inline_ipsec_lf_cfg *req, struct msg_rsp *rsp)
 		      (u64)req->ipsec_cfg0.tag_const << 20 |
 		      (u64)req->ipsec_cfg0.sa_pow2_size << 16 |
 		      req->ipsec_cfg0.lenm1_max;
+
+		if (blkaddr == BLKADDR_NIX1)
+			val |= BIT_ULL(46);
+
 		rvu_write64(rvu, blkaddr, NIX_AF_LFX_RX_IPSEC_CFG0(lf), val);
 
 		/* Set SA_IDX_W and SA_IDX_MAX */
-- 
2.31.1

