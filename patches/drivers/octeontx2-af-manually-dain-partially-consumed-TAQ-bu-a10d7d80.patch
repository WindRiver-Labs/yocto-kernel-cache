From 6b6bc6b2a883c18b7d409aba4a697b24e8c59572 Mon Sep 17 00:00:00 2001
From: Pavan Nikhilesh <pbhagavatula@marvell.com>
Date: Fri, 1 Feb 2019 18:38:42 +0530
Subject: [PATCH 0031/1921] octeontx2-af: manually dain partially consumed TAQ
 buffers

When work is added to a HWGRP it is first buffered in TOAQ and based on
GETWORK pressure the work is moved along the pipeline. Each TAQ buffers
eleven addwork entries. Each HWGRP hold the TAQ buffer until with it
till it is completely used.
SSO doesn't release the partially consumed TAQ buffer used by HWGRP
when HWGRP is reset (SSO_AF_LF_HWGRP_RST). Workaround is to manually drain
the TAQ buffer through addwork-getwork loop till TAQ buffer is completely
consumed.

Change-Id: Ifda82a4317e7a66d4c61b4b7f665fca72a02956d
Signed-off-by: Pavan Nikhilesh <pbhagavatula@marvell.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 .../ethernet/marvell/octeontx2/af/rvu_reg.h   |  10 +
 .../ethernet/marvell/octeontx2/af/rvu_sso.c   | 177 ++++++++++++++++++
 2 files changed, 187 insertions(+)

diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_reg.h b/drivers/net/ethernet/marvell/octeontx2/af/rvu_reg.h
index 2971bd4c6fe8..010f1aed258a 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_reg.h
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_reg.h
@@ -404,6 +404,9 @@
 #define NIX_PRIV_LFX_INT_CFG		(0x8000020)
 #define NIX_AF_RVU_LF_CFG_DEBUG		(0x8000030)
 
+#define NIX_AF_LF_CFG_SHIFT		17
+#define NIX_AF_LF_SSO_PF_FUNC_SHIFT	16
+
 /* SSO */
 #define SSO_AF_CONST			(0x1000)
 #define SSO_AF_CONST1			(0x1008)
@@ -554,6 +557,7 @@
 #define SSOW_LF_GWS_INT			(0x100ull)
 #define SSOW_LF_GWS_INT_ENA_W1C		(0x118ull)
 #define SSOW_LF_GWS_TAG			(0x200ull)
+#define SSOW_LF_GWS_WQP			(0x210ull)
 #define SSOW_LF_GWS_OP_GET_WORK		(0x600ull)
 #define SSOW_LF_GWS_OP_SWTAG_FLUSH	(0x800ull)
 #define SSOW_LF_GWS_OP_DESCHED		(0x880ull)
@@ -581,6 +585,9 @@
 #define TIM_AF_RINGX_CTL1_ENA		BIT_ULL(47)
 #define TIM_AF_RINGX_CTL1_RCF_BUSY	BIT_ULL(50)
 
+#define TIM_AF_RING_GMCTL_SHIFT		3
+#define TIM_AF_RING_SSO_PF_FUNC_SHIFT	0
+
 /* CPT */
 #define CPT_AF_CONSTANTS0               (0x0ull)
 #define CPT_AF_CONSTANTS1               (0x1000ull)
@@ -639,6 +646,9 @@
 #define NDC_AF_BLK_RST                  (0x002F0)
 #define NPC_AF_BLK_RST                  (0x00040)
 
+#define CPT_AF_LF_CTL2_SHIFT		3
+#define CPT_AF_LF_SSO_PF_FUNC_SHIFT	32
+
 /* NPC */
 #define NPC_AF_CFG			(0x00000)
 #define NPC_AF_ACTIVE_PC		(0x00010)
diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_sso.c b/drivers/net/ethernet/marvell/octeontx2/af/rvu_sso.c
index 0d465d696f00..455c0f685916 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_sso.c
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_sso.c
@@ -71,6 +71,175 @@ static void rvu_sso_hwgrp_config_thresh(struct rvu *rvu, int blkaddr, int lf)
 			    SSO_AF_TAQ_ADD_RSVD_FREE_SHIFT);
 }
 
+static void rvu_sso_enable_aw_src(struct rvu *rvu, int lf_cnt, int sub_blkaddr,
+				  u64 addr, int *lf_arr, u16 pcifunc, u8 shift,
+				  u8 addr_off)
+{
+	u64 reg;
+	int lf;
+
+	for (lf = 0; lf < lf_cnt; lf++) {
+		reg = rvu_read64(rvu, sub_blkaddr, addr |
+				 lf_arr[lf] << addr_off);
+
+		reg |= ((u64)pcifunc << shift);
+		rvu_write64(rvu, sub_blkaddr, addr |
+				lf_arr[lf] << addr_off, reg);
+	}
+}
+
+static int rvu_sso_disable_aw_src(struct rvu *rvu, int **lf_arr,
+				  int sub_blkaddr, u8 shift, u8 addr_off,
+				  u16 pcifunc, u64 addr)
+{
+	struct rvu_hwinfo *hw = rvu->hw;
+	struct rvu_block *block;
+	int lf_cnt = 0, lf;
+	u64 reg;
+
+	if (sub_blkaddr >= 0) {
+		block = &hw->block[sub_blkaddr];
+		*lf_arr = kmalloc(block->lf.max * sizeof(int), GFP_KERNEL);
+		if (!*lf_arr)
+			return 0;
+
+		for (lf = 0; lf < block->lf.max; lf++) {
+			reg = rvu_read64(rvu, sub_blkaddr,
+					 addr | lf << addr_off);
+			if (((reg >> shift) & 0xFFFFul) != pcifunc)
+				continue;
+
+			reg &= ~(0xFFFFul << shift);
+			rvu_write64(rvu, sub_blkaddr, addr | lf << addr_off,
+				    reg);
+			(*lf_arr)[lf_cnt] = lf;
+			lf_cnt++;
+		}
+	}
+
+	return lf_cnt;
+}
+
+static void rvu_sso_ggrp_taq_flush(struct rvu *rvu, u16 pcifunc, int lf,
+				   int slot, int ssow_lf, u64 blkaddr,
+				   u64 ssow_blkaddr)
+{
+	int nix_lf_cnt, cpt_lf_cnt, tim_lf_cnt;
+	int *nix_lf, *cpt_lf, *tim_lf;
+	u64 reg, val;
+
+	/* Disable add work. */
+	rvu_write64(rvu, blkaddr, SSO_AF_BAR2_ALIASX(slot, SSO_LF_GGRP_QCTL),
+		    0);
+
+	/* Disable all sources of work. */
+	nix_lf = NULL;
+	nix_lf_cnt = rvu_sso_disable_aw_src(rvu, &nix_lf,
+					    rvu_get_blkaddr(rvu, BLKTYPE_NIX,
+							    0),
+					    NIX_AF_LF_SSO_PF_FUNC_SHIFT,
+					    NIX_AF_LF_CFG_SHIFT, pcifunc,
+					    NIX_AF_LFX_CFG(0));
+
+	cpt_lf = NULL;
+	cpt_lf_cnt = rvu_sso_disable_aw_src(rvu, &cpt_lf,
+					    rvu_get_blkaddr(rvu, BLKTYPE_CPT,
+							    0),
+					    CPT_AF_LF_SSO_PF_FUNC_SHIFT,
+					    CPT_AF_LF_CTL2_SHIFT, pcifunc,
+					    CPT_AF_LFX_CTL2(0));
+
+	tim_lf = NULL;
+	tim_lf_cnt = rvu_sso_disable_aw_src(rvu, &tim_lf,
+					    rvu_get_blkaddr(rvu, BLKTYPE_TIM,
+							    0),
+					    TIM_AF_RING_SSO_PF_FUNC_SHIFT,
+					    TIM_AF_RING_GMCTL_SHIFT, pcifunc,
+					    TIM_AF_RINGX_GMCTL(0));
+
+	/* ZIP and DPI blocks not yet implemented. */
+
+	/* Enable add work. */
+	rvu_write64(rvu, blkaddr, SSO_AF_BAR2_ALIASX(slot, SSO_LF_GGRP_QCTL),
+		    0x1);
+
+	/* Prepare WS for GW operations. */
+	do {
+		reg = rvu_read64(rvu, ssow_blkaddr,
+				 SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_TAG));
+	} while (reg & BIT_ULL(63));
+
+	if (reg & BIT_ULL(62))
+		rvu_write64(rvu, ssow_blkaddr,
+			    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_OP_DESCHED),
+			    0x0);
+	else if (((reg >> 32) & SSO_TT_EMPTY) != SSO_TT_EMPTY)
+		rvu_write64(rvu, ssow_blkaddr,
+			    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_OP_SWTAG_FLUSH),
+			    0x0);
+
+	rvu_write64(rvu, ssow_blkaddr,
+		    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_OP_GWC_INVAL), 0x0);
+	/* Drain TAQ. */
+	val = slot;
+	val |= BIT_ULL(18);
+	val |= BIT_ULL(16);
+
+	reg = rvu_read64(rvu, blkaddr, SSO_AF_HWGRPX_TAQ_THR(lf));
+	while ((reg >> 48) & 0x7FF) {
+		rvu_write64(rvu, blkaddr,
+			    SSO_AF_BAR2_ALIASX(lf, SSO_LF_GGRP_OP_ADD_WORK1),
+			    0x1 << 3);
+get_work:
+		rvu_write64(rvu, ssow_blkaddr,
+			    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_OP_GET_WORK),
+			    val);
+		do {
+			reg = rvu_read64(rvu, ssow_blkaddr,
+					 SSOW_AF_BAR2_ALIASX(0,
+							     SSOW_LF_GWS_TAG));
+		} while (reg & BIT_ULL(63));
+
+		if (!rvu_read64(rvu, ssow_blkaddr,
+				SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_WQP)))
+			goto get_work;
+
+		reg = rvu_read64(rvu, blkaddr, SSO_AF_HWGRPX_TAQ_THR(lf));
+	}
+
+	reg = rvu_read64(rvu, ssow_blkaddr,
+			 SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_TAG));
+	if (((reg >> 32) & SSO_TT_EMPTY) != SSO_TT_EMPTY)
+		rvu_write64(rvu, ssow_blkaddr,
+			    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_OP_SWTAG_FLUSH),
+			    0x0);
+
+	/* Disable add work. */
+	rvu_write64(rvu, blkaddr, SSO_AF_BAR2_ALIASX(slot, SSO_LF_GGRP_QCTL),
+		    0x0);
+
+	/* restore all sources of work. */
+	rvu_sso_enable_aw_src(rvu, nix_lf_cnt, rvu_get_blkaddr(rvu, BLKTYPE_NIX,
+							       0),
+			      NIX_AF_LFX_CFG(0), nix_lf, pcifunc,
+			      NIX_AF_LF_SSO_PF_FUNC_SHIFT,
+			      NIX_AF_LF_CFG_SHIFT);
+	rvu_sso_enable_aw_src(rvu, cpt_lf_cnt, rvu_get_blkaddr(rvu, BLKTYPE_CPT,
+							       0),
+			      CPT_AF_LFX_CTL2(0), cpt_lf, pcifunc,
+			      CPT_AF_LF_SSO_PF_FUNC_SHIFT,
+			      CPT_AF_LF_CTL2_SHIFT);
+	rvu_sso_enable_aw_src(rvu, tim_lf_cnt, rvu_get_blkaddr(rvu, BLKTYPE_TIM,
+							       0),
+			      TIM_AF_RINGX_GMCTL(0), tim_lf, pcifunc,
+			      TIM_AF_RING_SSO_PF_FUNC_SHIFT,
+			      TIM_AF_RING_GMCTL_SHIFT);
+
+	kfree(nix_lf);
+	kfree(cpt_lf);
+	kfree(tim_lf);
+}
+
 int rvu_sso_lf_teardown(struct rvu *rvu, u16 pcifunc, int lf, int slot)
 {
 	int ssow_lf, iue, blkaddr, ssow_blkaddr, err;
@@ -197,6 +366,14 @@ int rvu_sso_lf_teardown(struct rvu *rvu, u16 pcifunc, int lf, int slot)
 		cq_ds_cnt &= SSO_LF_GGRP_INT_CNT_MASK;
 	}
 
+	/* Due to the Errata 35432, SSO doesn't release the partially consumed
+	 * TAQ buffer used by HWGRP when HWGRP is reset. Use SW routine to
+	 * drain it manually.
+	 */
+	if (is_rvu_9xxx_A0(rvu))
+		rvu_sso_ggrp_taq_flush(rvu, pcifunc, lf, slot, ssow_lf, blkaddr,
+				       ssow_blkaddr);
+
 	rvu_write64(rvu, ssow_blkaddr,
 		    SSOW_AF_BAR2_ALIASX(0, SSOW_LF_GWS_NW_TIM), 0x0);
 
-- 
2.31.1

