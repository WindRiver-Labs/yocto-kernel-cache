From 699acbd4cfc0e929705adb527cf26ec527060927 Mon Sep 17 00:00:00 2001
From: Subbaraya Sundeep <sbhatta@marvell.com>
Date: Fri, 16 Oct 2020 14:46:00 +0530
Subject: [PATCH 666/767] octeontx2-pf: Add raw IPv4 and SCTP4 filters

This patch does the following:
Moves the flow related code to otx2_flow.c from
otx2_ethtool.c
Refactors the existing ipv4 code to separate
function otx2_prepare_ipv4_flow
Adds the raw IPv4 and SCTP4 ntuple filters.

ethtool commands:
ethtool -U eth0 flow-type ip4 dst-ip <addr> \
src-ip <addr> action <N>

ethtool -U eth0 flow-type sctp4 dst-ip <addr> \
src-ip <addr> src-port <N> dst-port <N> action <N>

Change-Id: I5c818d872047eddf8b51efcf643b48096dbea042
Signed-off-by: Subbaraya Sundeep <sbhatta@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/38177
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Integrated-by: Abhishek Paliwal <paliwal.abhishek@windriver.com>
---
 .../marvell/octeontx2/nic/otx2_common.h       |   3 -
 .../marvell/octeontx2/nic/otx2_ethtool.c      | 151 --------------
 .../marvell/octeontx2/nic/otx2_flows.c        | 195 ++++++++++++++++++
 3 files changed, 195 insertions(+), 154 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
index af5244f8f07e..7c229464cef7 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
@@ -783,9 +783,6 @@ int otx2_get_all_flows(struct otx2_nic *pfvf,
 int otx2_add_flow(struct otx2_nic *pfvf,
 		  struct ethtool_rx_flow_spec *fsp);
 int otx2_remove_flow(struct otx2_nic *pfvf, u32 location);
-int otx2_prepare_flow_request(struct ethtool_rx_flow_spec *fsp,
-			      struct npc_install_flow_req *req,
-			      struct otx2_nic *pfvf);
 int otx2_enable_rxvlan(struct otx2_nic *pf, bool enable);
 int otx2_enable_vf_vlan(struct otx2_nic *pf);
 int otx2_install_rxvlan_offload_flow(struct otx2_nic *pfvf);
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
index 3081aada3f81..1e0c050d1ba6 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
@@ -23,10 +23,6 @@
 #define DRV_VF_NAME	"octeontx2-nicvf"
 #define DRV_VF_VERSION	"1.0"
 
-#define OTX2_DEFAULT_ACTION	0x1
-#define FDSA_MAX_SPORT		32
-#define FDSA_SPORT_MASK         0xf8
-
 static struct cgx_fw_data *otx2_get_fwdata(struct otx2_nic *pfvf);
 
 static const char otx2_priv_flags_strings[][ETH_GSTRING_LEN] = {
@@ -680,153 +676,6 @@ static int otx2_get_rxnfc(struct net_device *dev,
 	return ret;
 }
 
-static void otx2_prepare_fdsa_flow_request(struct npc_install_flow_req *req,
-					   bool is_vlan)
-{
-	struct flow_msg *pmask = &req->mask;
-	struct flow_msg *pkt = &req->packet;
-
-	/* In FDSA tag srcport starts from b3..b7 */
-	if (!is_vlan) {
-		pkt->vlan_tci <<= 3;
-		pmask->vlan_tci = cpu_to_be16(FDSA_SPORT_MASK);
-	}
-	/* Strip FDSA tag */
-	req->features |= BIT_ULL(NPC_FDSA_VAL);
-	req->vtag0_valid = true;
-	req->vtag0_type = NIX_AF_LFX_RX_VTAG_TYPE6;
-	req->op = NIX_RX_ACTION_DEFAULT;
-}
-
-int otx2_prepare_flow_request(struct ethtool_rx_flow_spec *fsp,
-			      struct npc_install_flow_req *req,
-			      struct otx2_nic *pfvf)
-{
-	struct ethtool_tcpip4_spec *l4_mask = &fsp->m_u.tcp_ip4_spec;
-	struct ethtool_tcpip4_spec *l4_hdr = &fsp->h_u.tcp_ip4_spec;
-	struct ethhdr *eth_mask = &fsp->m_u.ether_spec;
-	struct ethhdr *eth_hdr = &fsp->h_u.ether_spec;
-	struct flow_msg *pmask = &req->mask;
-	struct flow_msg *pkt = &req->packet;
-	u32 flow_type;
-
-	flow_type = fsp->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT);
-	switch (flow_type) {
-	/* bits not set in mask are don't care */
-	case ETHER_FLOW:
-		if (!is_zero_ether_addr(eth_mask->h_source)) {
-			ether_addr_copy(pkt->smac, eth_hdr->h_source);
-			ether_addr_copy(pmask->smac, eth_mask->h_source);
-			req->features |= BIT_ULL(NPC_SMAC);
-		}
-		if (!is_zero_ether_addr(eth_mask->h_dest)) {
-			ether_addr_copy(pkt->dmac, eth_hdr->h_dest);
-			ether_addr_copy(pmask->dmac, eth_mask->h_dest);
-			req->features |= BIT_ULL(NPC_DMAC);
-		}
-		if (eth_mask->h_proto) {
-			memcpy(&pkt->etype, &eth_hdr->h_proto,
-			       sizeof(pkt->etype));
-			memcpy(&pmask->etype, &eth_mask->h_proto,
-			       sizeof(pmask->etype));
-			req->features |= BIT_ULL(NPC_ETYPE);
-		}
-		break;
-	case TCP_V4_FLOW:
-	case UDP_V4_FLOW:
-		if (l4_mask->ip4src) {
-			memcpy(&pkt->ip4src, &l4_hdr->ip4src,
-			       sizeof(pkt->ip4src));
-			memcpy(&pmask->ip4src, &l4_mask->ip4src,
-			       sizeof(pmask->ip4src));
-			req->features |= BIT_ULL(NPC_SIP_IPV4);
-		}
-		if (l4_mask->ip4dst) {
-			memcpy(&pkt->ip4dst, &l4_hdr->ip4dst,
-			       sizeof(pkt->ip4dst));
-			memcpy(&pmask->ip4dst, &l4_mask->ip4dst,
-			       sizeof(pmask->ip4dst));
-			req->features |= BIT_ULL(NPC_DIP_IPV4);
-		}
-		if (l4_mask->psrc) {
-			memcpy(&pkt->sport, &l4_hdr->psrc, sizeof(pkt->sport));
-			memcpy(&pmask->sport, &l4_mask->psrc,
-			       sizeof(pmask->sport));
-			if (flow_type == UDP_V4_FLOW)
-				req->features |= BIT_ULL(NPC_SPORT_UDP);
-			else
-				req->features |= BIT_ULL(NPC_SPORT_TCP);
-		}
-		if (l4_mask->pdst) {
-			memcpy(&pkt->dport, &l4_hdr->pdst, sizeof(pkt->dport));
-			memcpy(&pmask->dport, &l4_mask->pdst,
-			       sizeof(pmask->dport));
-			if (flow_type == UDP_V4_FLOW)
-				req->features |= BIT_ULL(NPC_DPORT_UDP);
-			else
-				req->features |= BIT_ULL(NPC_DPORT_TCP);
-		}
-		break;
-	default:
-		return -ENOTSUPP;
-	}
-	if (fsp->flow_type & FLOW_EXT) {
-		int skip_user_def = false;
-
-		if (fsp->m_ext.vlan_etype)
-			return -EINVAL;
-		if (fsp->m_ext.vlan_tci) {
-			if (fsp->m_ext.vlan_tci != cpu_to_be16(VLAN_VID_MASK))
-				return -EINVAL;
-			if (be16_to_cpu(fsp->h_ext.vlan_tci) >= VLAN_N_VID)
-				return -EINVAL;
-
-			memcpy(&pkt->vlan_tci, &fsp->h_ext.vlan_tci,
-			       sizeof(pkt->vlan_tci));
-			memcpy(&pmask->vlan_tci, &fsp->m_ext.vlan_tci,
-			       sizeof(pmask->vlan_tci));
-
-			if (pfvf->ethtool_flags & OTX2_PRIV_FLAG_FDSA_HDR) {
-				otx2_prepare_fdsa_flow_request(req, true);
-				skip_user_def = true;
-			} else {
-				req->features |= BIT_ULL(NPC_OUTER_VID);
-			}
-		}
-
-		if (fsp->m_ext.data[1] && !skip_user_def) {
-			if (pfvf->ethtool_flags & OTX2_PRIV_FLAG_FDSA_HDR) {
-				if (be32_to_cpu(fsp->h_ext.data[1]) >=
-						FDSA_MAX_SPORT)
-					return -EINVAL;
-
-				memcpy(&pkt->vlan_tci,
-				       (u8 *)&fsp->h_ext.data[1] + 2,
-				       sizeof(pkt->vlan_tci));
-				otx2_prepare_fdsa_flow_request(req, false);
-			} else if (fsp->h_ext.data[1] ==
-					cpu_to_be32(OTX2_DEFAULT_ACTION)) {
-				/* Not Drop/Direct to queue but use action
-				 * in default entry
-				 */
-				req->op = NIX_RX_ACTION_DEFAULT;
-			}
-		}
-	}
-
-	if (fsp->flow_type & FLOW_MAC_EXT &&
-	    !is_zero_ether_addr(fsp->m_ext.h_dest)) {
-		ether_addr_copy(pkt->dmac, fsp->h_ext.h_dest);
-		ether_addr_copy(pmask->dmac, fsp->m_ext.h_dest);
-		req->features |= BIT_ULL(NPC_DMAC);
-	}
-
-	if (!req->features)
-		return -ENOTSUPP;
-
-	return 0;
-}
-
 static int otx2_set_rxnfc(struct net_device *dev, struct ethtool_rxnfc *nfc)
 {
 	bool ntuple = !!(dev->features & NETIF_F_NTUPLE);
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
index 74897c2c97fc..e65f1b5a0bf1 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
@@ -18,6 +18,10 @@
 				 OTX2_MAX_UNICAST_FLOWS + \
 				 OTX2_MAX_VLAN_FLOWS)
 
+#define OTX2_DEFAULT_ACTION	0x1
+#define FDSA_MAX_SPORT		32
+#define FDSA_SPORT_MASK         0xf8
+
 struct otx2_flow {
 	struct ethtool_rx_flow_spec flow_spec;
 	struct list_head list;
@@ -304,6 +308,197 @@ int otx2_get_all_flows(struct otx2_nic *pfvf, struct ethtool_rxnfc *nfc,
 	return err;
 }
 
+static void otx2_prepare_fdsa_flow_request(struct npc_install_flow_req *req,
+					   bool is_vlan)
+{
+	struct flow_msg *pmask = &req->mask;
+	struct flow_msg *pkt = &req->packet;
+
+	/* In FDSA tag srcport starts from b3..b7 */
+	if (!is_vlan) {
+		pkt->vlan_tci <<= 3;
+		pmask->vlan_tci = cpu_to_be16(FDSA_SPORT_MASK);
+	}
+	/* Strip FDSA tag */
+	req->features |= BIT_ULL(NPC_FDSA_VAL);
+	req->vtag0_valid = true;
+	req->vtag0_type = NIX_AF_LFX_RX_VTAG_TYPE6;
+	req->op = NIX_RX_ACTION_DEFAULT;
+}
+
+static void otx2_prepare_ipv4_flow(struct ethtool_rx_flow_spec *fsp,
+				   struct npc_install_flow_req *req,
+				   u32 flow_type)
+{
+	struct ethtool_usrip4_spec *ipv4_usr_mask = &fsp->m_u.usr_ip4_spec;
+	struct ethtool_usrip4_spec *ipv4_usr_hdr = &fsp->h_u.usr_ip4_spec;
+	struct ethtool_tcpip4_spec *ipv4_l4_mask = &fsp->m_u.tcp_ip4_spec;
+	struct ethtool_tcpip4_spec *ipv4_l4_hdr = &fsp->h_u.tcp_ip4_spec;
+	struct flow_msg *pmask = &req->mask;
+	struct flow_msg *pkt = &req->packet;
+
+	switch (flow_type) {
+	case IP_USER_FLOW:
+		if (ipv4_usr_mask->ip4src) {
+			memcpy(&pkt->ip4src, &ipv4_usr_hdr->ip4src,
+			       sizeof(pkt->ip4src));
+			memcpy(&pmask->ip4src, &ipv4_usr_mask->ip4src,
+			       sizeof(pmask->ip4src));
+			req->features |= BIT_ULL(NPC_SIP_IPV4);
+		}
+		if (ipv4_usr_mask->ip4dst) {
+			memcpy(&pkt->ip4dst, &ipv4_usr_hdr->ip4dst,
+			       sizeof(pkt->ip4dst));
+			memcpy(&pmask->ip4dst, &ipv4_usr_mask->ip4dst,
+			       sizeof(pmask->ip4dst));
+			req->features |= BIT_ULL(NPC_DIP_IPV4);
+		}
+		break;
+	case TCP_V4_FLOW:
+	case UDP_V4_FLOW:
+	case SCTP_V4_FLOW:
+		if (ipv4_l4_mask->ip4src) {
+			memcpy(&pkt->ip4src, &ipv4_l4_hdr->ip4src,
+			       sizeof(pkt->ip4src));
+			memcpy(&pmask->ip4src, &ipv4_l4_mask->ip4src,
+			       sizeof(pmask->ip4src));
+			req->features |= BIT_ULL(NPC_SIP_IPV4);
+		}
+		if (ipv4_l4_mask->ip4dst) {
+			memcpy(&pkt->ip4dst, &ipv4_l4_hdr->ip4dst,
+			       sizeof(pkt->ip4dst));
+			memcpy(&pmask->ip4dst, &ipv4_l4_mask->ip4dst,
+			       sizeof(pmask->ip4dst));
+			req->features |= BIT_ULL(NPC_DIP_IPV4);
+		}
+		if (ipv4_l4_mask->psrc) {
+			memcpy(&pkt->sport, &ipv4_l4_hdr->psrc,
+			       sizeof(pkt->sport));
+			memcpy(&pmask->sport, &ipv4_l4_mask->psrc,
+			       sizeof(pmask->sport));
+			if (flow_type == UDP_V4_FLOW)
+				req->features |= BIT_ULL(NPC_SPORT_UDP);
+			else if (flow_type == TCP_V4_FLOW)
+				req->features |= BIT_ULL(NPC_SPORT_TCP);
+			else
+				req->features |= BIT_ULL(NPC_SPORT_SCTP);
+		}
+		if (ipv4_l4_mask->pdst) {
+			memcpy(&pkt->dport, &ipv4_l4_hdr->pdst,
+			       sizeof(pkt->dport));
+			memcpy(&pmask->dport, &ipv4_l4_mask->pdst,
+			       sizeof(pmask->dport));
+			if (flow_type == UDP_V4_FLOW)
+				req->features |= BIT_ULL(NPC_DPORT_UDP);
+			else if (flow_type == TCP_V4_FLOW)
+				req->features |= BIT_ULL(NPC_DPORT_TCP);
+			else
+				req->features |= BIT_ULL(NPC_DPORT_SCTP);
+		}
+		break;
+	default:
+		break;
+	}
+}
+
+static int otx2_prepare_flow_request(struct ethtool_rx_flow_spec *fsp,
+				     struct npc_install_flow_req *req,
+				     struct otx2_nic *pfvf)
+{
+	struct ethhdr *eth_mask = &fsp->m_u.ether_spec;
+	struct ethhdr *eth_hdr = &fsp->h_u.ether_spec;
+	struct flow_msg *pmask = &req->mask;
+	struct flow_msg *pkt = &req->packet;
+	u32 flow_type;
+
+	flow_type = fsp->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT);
+	switch (flow_type) {
+	/* bits not set in mask are don't care */
+	case ETHER_FLOW:
+		if (!is_zero_ether_addr(eth_mask->h_source)) {
+			ether_addr_copy(pkt->smac, eth_hdr->h_source);
+			ether_addr_copy(pmask->smac, eth_mask->h_source);
+			req->features |= BIT_ULL(NPC_SMAC);
+		}
+		if (!is_zero_ether_addr(eth_mask->h_dest)) {
+			ether_addr_copy(pkt->dmac, eth_hdr->h_dest);
+			ether_addr_copy(pmask->dmac, eth_mask->h_dest);
+			req->features |= BIT_ULL(NPC_DMAC);
+		}
+		if (eth_mask->h_proto) {
+			memcpy(&pkt->etype, &eth_hdr->h_proto,
+			       sizeof(pkt->etype));
+			memcpy(&pmask->etype, &eth_mask->h_proto,
+			       sizeof(pmask->etype));
+			req->features |= BIT_ULL(NPC_ETYPE);
+		}
+		break;
+	case IP_USER_FLOW:
+	case TCP_V4_FLOW:
+	case UDP_V4_FLOW:
+	case SCTP_V4_FLOW:
+		otx2_prepare_ipv4_flow(fsp, req, flow_type);
+		break;
+	default:
+		return -ENOTSUPP;
+	}
+	if (fsp->flow_type & FLOW_EXT) {
+		int skip_user_def = false;
+
+		if (fsp->m_ext.vlan_etype)
+			return -EINVAL;
+		if (fsp->m_ext.vlan_tci) {
+			if (fsp->m_ext.vlan_tci != cpu_to_be16(VLAN_VID_MASK))
+				return -EINVAL;
+			if (be16_to_cpu(fsp->h_ext.vlan_tci) >= VLAN_N_VID)
+				return -EINVAL;
+
+			memcpy(&pkt->vlan_tci, &fsp->h_ext.vlan_tci,
+			       sizeof(pkt->vlan_tci));
+			memcpy(&pmask->vlan_tci, &fsp->m_ext.vlan_tci,
+			       sizeof(pmask->vlan_tci));
+
+			if (pfvf->ethtool_flags & OTX2_PRIV_FLAG_FDSA_HDR) {
+				otx2_prepare_fdsa_flow_request(req, true);
+				skip_user_def = true;
+			} else {
+				req->features |= BIT_ULL(NPC_OUTER_VID);
+			}
+		}
+
+		if (fsp->m_ext.data[1] && !skip_user_def) {
+			if (pfvf->ethtool_flags & OTX2_PRIV_FLAG_FDSA_HDR) {
+				if (be32_to_cpu(fsp->h_ext.data[1]) >=
+						FDSA_MAX_SPORT)
+					return -EINVAL;
+
+				memcpy(&pkt->vlan_tci,
+				       (u8 *)&fsp->h_ext.data[1] + 2,
+				       sizeof(pkt->vlan_tci));
+				otx2_prepare_fdsa_flow_request(req, false);
+			} else if (fsp->h_ext.data[1] ==
+					cpu_to_be32(OTX2_DEFAULT_ACTION)) {
+				/* Not Drop/Direct to queue but use action
+				 * in default entry
+				 */
+				req->op = NIX_RX_ACTION_DEFAULT;
+			}
+		}
+	}
+
+	if (fsp->flow_type & FLOW_MAC_EXT &&
+	    !is_zero_ether_addr(fsp->m_ext.h_dest)) {
+		ether_addr_copy(pkt->dmac, fsp->h_ext.h_dest);
+		ether_addr_copy(pmask->dmac, fsp->m_ext.h_dest);
+		req->features |= BIT_ULL(NPC_DMAC);
+	}
+
+	if (!req->features)
+		return -ENOTSUPP;
+
+	return 0;
+}
+
 static int otx2_add_flow_msg(struct otx2_nic *pfvf, struct otx2_flow *flow)
 {
 	u64 ring_cookie = flow->flow_spec.ring_cookie;
-- 
2.31.1

