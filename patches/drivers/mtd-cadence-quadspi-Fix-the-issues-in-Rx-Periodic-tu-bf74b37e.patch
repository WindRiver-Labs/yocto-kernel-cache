From 66a892d29cf021e26fbeda9481f98fbe773c281b Mon Sep 17 00:00:00 2001
From: Sai Krishna Potthuri <lakshmi.sai.krishna.potthuri@xilinx.com>
Date: Mon, 30 Mar 2020 21:50:08 +0530
Subject: [PATCH 1294/1851] mtd: cadence-quadspi: Fix the issues in Rx Periodic
 tuning

commit 56e44ec1adb84407ce70cf498cb7f5104d60dc8e from
https://github.com/Xilinx/linux-xlnx.git

Use complete_all() for tuning_complete and request_complete to
avoid the timeout errors for mtd requests (read, write and erase)
and periodic tuning requests respectively.
This patch also taken care of acquiring request_complete lock before
checking the tuning complete to avoid tuning timeout.

Signed-off-by: Sai Krishna Potthuri <lakshmi.sai.krishna.potthuri@xilinx.com>
State: pending
Signed-off-by: Yaliang Wang <Yaliang.Wang@windriver.com>
---
 drivers/mtd/spi-nor/cadence-quadspi.c | 39 ++++++++++++++-------------
 1 file changed, 20 insertions(+), 19 deletions(-)

diff --git a/drivers/mtd/spi-nor/cadence-quadspi.c b/drivers/mtd/spi-nor/cadence-quadspi.c
index bd1acd855223..ce77a848af78 100644
--- a/drivers/mtd/spi-nor/cadence-quadspi.c
+++ b/drivers/mtd/spi-nor/cadence-quadspi.c
@@ -1217,16 +1217,16 @@ static ssize_t cqspi_write(struct spi_nor *nor, loff_t to,
 	struct cqspi_st *cqspi = f_pdata->cqspi;
 	int ret;
 
+	reinit_completion(&cqspi->request_complete);
+
 	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
-	    !delayed_work_pending(&nor->complete_work)) {
+	    !cqspi->tuning_complete.done) {
 		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
 			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
 			return -ETIMEDOUT;
 		}
 	}
 
-	reinit_completion(&cqspi->request_complete);
-
 	ret = cqspi_set_protocol(nor, 0);
 	if (ret)
 		return ret;
@@ -1326,16 +1326,16 @@ static ssize_t cqspi_read(struct spi_nor *nor, loff_t from,
 	int ret;
 	bool use_dma = true;
 
+	reinit_completion(&cqspi->request_complete);
+
 	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
-	    !delayed_work_pending(&nor->complete_work)) {
+	    !cqspi->tuning_complete.done) {
 		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
 			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
 			return -ETIMEDOUT;
 		}
 	}
 
-	reinit_completion(&cqspi->request_complete);
-
 	ret = cqspi_set_protocol(nor, 1);
 	if (ret)
 		return ret;
@@ -1375,16 +1375,16 @@ static int cqspi_erase(struct spi_nor *nor, loff_t offs)
 	struct cqspi_st *cqspi = f_pdata->cqspi;
 	int ret;
 
+	reinit_completion(&cqspi->request_complete);
+
 	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
-	    !delayed_work_pending(&nor->complete_work)) {
+	    !cqspi->tuning_complete.done) {
 		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
 			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
 			return -ETIMEDOUT;
 		}
 	}
 
-	reinit_completion(&cqspi->request_complete);
-
 	ret = cqspi_set_protocol(nor, 0);
 	if (ret)
 		return ret;
@@ -1425,17 +1425,16 @@ static int cqspi_read_reg(struct spi_nor *nor, u8 opcode, u8 *buf, int len)
 	struct cqspi_st *cqspi = f_pdata->cqspi;
 	int ret;
 
+	reinit_completion(&cqspi->request_complete);
+
 	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
-	    cqspi->request_complete.done &&
-	    !delayed_work_pending(&nor->complete_work)) {
+	    !cqspi->tuning_complete.done) {
 		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
 			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
 			return -ETIMEDOUT;
 		}
 	}
 
-	reinit_completion(&cqspi->request_complete);
-
 	ret = cqspi_set_protocol(nor, 0);
 	if (!ret) {
 		if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR)
@@ -1457,22 +1456,22 @@ static int cqspi_write_reg(struct spi_nor *nor, u8 opcode, u8 *buf, int len)
 	struct cqspi_st *cqspi = f_pdata->cqspi;
 	int ret;
 
+	reinit_completion(&cqspi->request_complete);
+
 	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
-	    cqspi->request_complete.done &&
-	    !delayed_work_pending(&nor->complete_work)) {
+	    !cqspi->tuning_complete.done) {
 		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
 			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
 			return -ETIMEDOUT;
 		}
 	}
 
-	reinit_completion(&cqspi->request_complete);
-
 	ret = cqspi_set_protocol(nor, 0);
 	if (!ret)
 		ret = cqspi_command_write(nor, opcode, buf, len);
 
-	complete(&cqspi->request_complete);
+	if (opcode != SPINOR_OP_WREN)
+		complete(&cqspi->request_complete);
 
 	return ret;
 }
@@ -1696,8 +1695,8 @@ static void cqspi_periodictuning(struct work_struct *work)
 
 	if (!cqspi->request_complete.done)
 		wait_for_completion(&cqspi->request_complete);
-	reinit_completion(&cqspi->tuning_complete);
 
+	reinit_completion(&cqspi->tuning_complete);
 	ret = cqspi_setdlldelay(nor);
 	complete_all(&cqspi->tuning_complete);
 	if (ret) {
@@ -2096,6 +2095,8 @@ static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)
 		ret = cqspi_setup_edgemode(nor);
 		if (ret)
 			goto err;
+		complete_all(&cqspi->tuning_complete);
+		complete_all(&cqspi->request_complete);
 		INIT_DELAYED_WORK(&nor->complete_work, cqspi_periodictuning);
 		schedule_delayed_work(&nor->complete_work,
 				msecs_to_jiffies(CQSPI_TUNING_PERIODICITY_MS));
-- 
2.31.1

