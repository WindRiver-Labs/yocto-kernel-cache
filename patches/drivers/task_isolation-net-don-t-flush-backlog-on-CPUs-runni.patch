From 5dda860d30b24a6f04e3fd581e41fa8913cb2149 Mon Sep 17 00:00:00 2001
From: Yuri Norov <ynorov@marvell.com>
Date: Thu, 27 Feb 2020 07:29:00 +0000
Subject: [PATCH 0880/1921] task_isolation: net: don't flush backlog on CPUs
 running isolated tasks

If CPU runs isolated task, there's no any backlog on it, and
so we don't need to flush it. Currently flush_all_backlogs()
enqueues corresponding work on all CPUs including ones that run
isolated tasks. It leads to breaking task isolation for nothing.

In this patch, backlog flushing is enqueued only on non-isolated CPUs.

Signed-off-by: Yuri Norov <ynorov@marvell.com>
[abelits@marvell.com: use safe task_isolation_on_cpu() implementation]
Signed-off-by: Alex Belits <abelits@marvell.com>

Change-Id: Ie05ae6c6efcf515d940240623ab96a23337cf01f
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/35445
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
(cherry picked from commit 4d45d5f2eb2537177e933e649725910c63c22d14)
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/35995
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/36010
Signed-off-by: Sunil Goutham <sgoutham@marvell.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 net/core/dev.c | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/net/core/dev.c b/net/core/dev.c
index cff7f1d91bf3..6d67eaeead43 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -74,6 +74,7 @@
 #include <linux/cpu.h>
 #include <linux/types.h>
 #include <linux/kernel.h>
+#include <linux/isolation.h>
 #include <linux/hash.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
@@ -5342,9 +5343,14 @@ static void flush_all_backlogs(void)
 
 	get_online_cpus();
 
-	for_each_online_cpu(cpu)
+	/* Synchronize low-level isolation flags */
+	smp_rmb();
+	for_each_online_cpu(cpu) {
+		if (task_isolation_on_cpu(cpu))
+			continue;
 		queue_work_on(cpu, system_highpri_wq,
 			      per_cpu_ptr(&flush_works, cpu));
+	}
 
 	for_each_online_cpu(cpu)
 		flush_work(per_cpu_ptr(&flush_works, cpu));
-- 
2.31.1

