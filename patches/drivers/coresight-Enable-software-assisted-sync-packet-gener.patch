From b3879384cebd856b8bcdb6c26228438c8bed5a93 Mon Sep 17 00:00:00 2001
From: Linu Cherian <lcherian@marvell.com>
Date: Thu, 23 Jan 2020 17:06:03 +0530
Subject: [PATCH 455/767] coresight: Enable software assisted sync packet
 generation

commit 95dd2b469b971006a3264ac0e815da4bcaeca820 from
git@git.assembla.com:cavium/WindRiver.linux.git

When ETM hardware doesn't implement the periodic trace sync packets,
enable sofware assisted sync packet generation with the help
of timer interrupts.

Software assisted sync packet generation can be either of
- global mode
	global sync insertion timer handlers runs only from
  	primary core
- percore mode
	sync insertion timer handler runs from each core

Along with that, added few informational prints related to
secure buffer allocation.

Change-Id: I2f6d8c64ddf5f7a9f29352ba2ecf37edbc7f1adf
Signed-off-by: Linu Cherian <lcherian@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/22247
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
[Kevin: Replace MIDR_IS_CPU_MODEL_RANGE with midr_is_cpu_model_range]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../coresight/coresight-etm4x-sysfs.c         |   9 +-
 drivers/hwtracing/coresight/coresight-etm4x.c |  83 +++++-
 drivers/hwtracing/coresight/coresight-etm4x.h |   4 +
 drivers/hwtracing/coresight/coresight-priv.h  |  36 +++
 .../hwtracing/coresight/coresight-quirks.c    |  71 +++++
 .../hwtracing/coresight/coresight-tmc-etr.c   | 254 ++++++++++++++++++
 drivers/hwtracing/coresight/coresight-tmc.c   |   7 +
 drivers/hwtracing/coresight/coresight-tmc.h   |  25 ++
 drivers/hwtracing/coresight/coresight.c       |  20 ++
 include/linux/coresight.h                     |  17 ++
 10 files changed, 522 insertions(+), 4 deletions(-)

diff --git a/drivers/hwtracing/coresight/coresight-etm4x-sysfs.c b/drivers/hwtracing/coresight/coresight-etm4x-sysfs.c
index 2d74e77f4e85..898e92a8d1ec 100644
--- a/drivers/hwtracing/coresight/coresight-etm4x-sysfs.c
+++ b/drivers/hwtracing/coresight/coresight-etm4x-sysfs.c
@@ -2084,8 +2084,15 @@ static u32 etmv4_cross_read(const struct device *dev, u32 offset)
 	/*
 	 * smp cross call ensures the CPU will be powered up before
 	 * accessing the ETMv4 trace core registers
+	 *
+	 * Note: When task isolation is enabled, the target cpu used
+	 * is always primary core and hence the above assumption of
+	 * cpu associated with the ETM being in powered up state during
+	 * register writes is not valid.
+	 * But on the other hand, using smp call ensures that atomicity is
+	 * not broken as well.
 	 */
-	smp_call_function_single(drvdata->cpu, do_smp_cross_read, &reg, 1);
+	smp_call_function_single(drvdata->rc_cpu, do_smp_cross_read, &reg, 1);
 
 	/*
 	 * OcteonTx2 h/w reports ETMv4.2 but it supports Ignore Packet
diff --git a/drivers/hwtracing/coresight/coresight-etm4x.c b/drivers/hwtracing/coresight/coresight-etm4x.c
index 5574cfa54056..c91b2ccffce1 100644
--- a/drivers/hwtracing/coresight/coresight-etm4x.c
+++ b/drivers/hwtracing/coresight/coresight-etm4x.c
@@ -84,6 +84,43 @@ struct etm4_enable_arg {
 	int rc;
 };
 
+/* Raw enable/disable APIs for ETM sync insertion */
+
+static void etm4_enable_raw(struct coresight_device *csdev)
+{
+	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
+
+	CS_UNLOCK(drvdata->base);
+
+	etm4_os_unlock(drvdata);
+
+	/* Enable the trace unit */
+	writel(1, drvdata->base + TRCPRGCTLR);
+
+	dsb(sy);
+	isb();
+
+	CS_LOCK(drvdata->base);
+}
+
+static void etm4_disable_raw(struct coresight_device *csdev)
+{
+	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
+
+	CS_UNLOCK(drvdata->base);
+	/*
+	 * Make sure everything completes before disabling, as recommended
+	 * by section 7.3.77 ("TRCVICTLR, ViewInst Main Control Register,
+	 * SSTATUS") of ARM IHI 0064D
+	 */
+	dsb(sy);
+	isb();
+
+	writel_relaxed(0x0, drvdata->base + TRCPRGCTLR);
+
+	CS_LOCK(drvdata->base);
+}
+
 static int etm4_enable_hw(struct etmv4_drvdata *drvdata)
 {
 	int i, rc;
@@ -197,6 +234,20 @@ static int etm4_enable_hw(struct etmv4_drvdata *drvdata)
 done:
 	CS_LOCK(drvdata->base);
 
+	/* For supporting SW sync insertion */
+	if (!is_etm_sync_mode_hw()) {
+		/* ETM sync insertions are gated in the
+		 * ETR timer handler based on hw state.
+		 */
+		drvdata->csdev->hw_state = USR_START;
+
+		/* Global timer handler not being associated with
+		 * a specific ETM core, need to know the current
+		 * list of active ETMs.
+		 */
+		coresight_etm_active_enable(drvdata->cpu);
+	}
+
 	dev_dbg(drvdata->dev, "cpu: %d enable smp call done: %d\n",
 		drvdata->cpu, rc);
 	return rc;
@@ -396,9 +447,16 @@ static int etm4_enable_sysfs(struct coresight_device *csdev)
 	/*
 	 * Executing etm4_enable_hw on the cpu whose ETM is being enabled
 	 * ensures that register writes occur when cpu is powered.
+	 *
+	 * Note: When task isolation is enabled, the target cpu used
+	 * is always primary core and hence the above assumption of
+	 * cpu associated with the ETM being in powered up state during
+	 * register writes is not valid.
+	 * But on the other hand, using smp call ensures that atomicity is
+	 * not broken as well.
 	 */
 	arg.drvdata = drvdata;
-	ret = smp_call_function_single(drvdata->cpu,
+	ret = smp_call_function_single(drvdata->rc_cpu,
 				       etm4_enable_hw_smp_call, &arg, 1);
 	if (!ret)
 		ret = arg.rc;
@@ -472,6 +530,12 @@ static void etm4_disable_hw(void *info)
 
 	CS_LOCK(drvdata->base);
 
+	/* For supporting SW sync insertion */
+	if (!is_etm_sync_mode_hw()) {
+		drvdata->csdev->hw_state = USR_STOP;
+		coresight_etm_active_disable(drvdata->cpu);
+	}
+
 	dev_dbg(drvdata->dev, "cpu: %d disable smp call done\n", drvdata->cpu);
 }
 
@@ -516,8 +580,15 @@ static void etm4_disable_sysfs(struct coresight_device *csdev)
 	/*
 	 * Executing etm4_disable_hw on the cpu whose ETM is being disabled
 	 * ensures that register writes occur when cpu is powered.
+	 *
+	 * Note: When task isolation is enabled, the target cpu used
+	 * is always primary core and hence the above assumption of
+	 * cpu associated with the ETM being in powered up state during
+	 * register writes is not valid.
+	 * But on the other hand, using smp call ensures that atomicity is
+	 * not broken as well.
 	 */
-	smp_call_function_single(drvdata->cpu, etm4_disable_hw, drvdata, 1);
+	smp_call_function_single(drvdata->rc_cpu, etm4_disable_hw, drvdata, 1);
 
 	spin_unlock(&drvdata->spinlock);
 	cpus_read_unlock();
@@ -558,6 +629,8 @@ static const struct coresight_ops_source etm4_source_ops = {
 	.trace_id	= etm4_trace_id,
 	.enable		= etm4_enable,
 	.disable	= etm4_disable,
+	.enable_raw	= etm4_enable_raw,
+	.disable_raw	= etm4_disable_raw,
 };
 
 static const struct coresight_ops etm4_cs_ops = {
@@ -1130,10 +1203,14 @@ static int etm4_probe(struct amba_device *adev, const struct amba_id *id)
 
 	drvdata->cpu = pdata ? pdata->cpu : 0;
 
+	/* Update the smp target cpu */
+	drvdata->rc_cpu = is_etm_sync_mode_sw_global() ? SYNC_GLOBAL_CORE :
+		drvdata->cpu;
+
 	cpus_read_lock();
 	etmdrvdata[drvdata->cpu] = drvdata;
 
-	if (smp_call_function_single(drvdata->cpu,
+	if (smp_call_function_single(drvdata->rc_cpu,
 				etm4_init_arch_data,  drvdata, 1))
 		dev_err(dev, "ETM arch init failed\n");
 
diff --git a/drivers/hwtracing/coresight/coresight-etm4x.h b/drivers/hwtracing/coresight/coresight-etm4x.h
index 210118ead59f..31dcd281cd69 100644
--- a/drivers/hwtracing/coresight/coresight-etm4x.h
+++ b/drivers/hwtracing/coresight/coresight-etm4x.h
@@ -291,6 +291,9 @@ struct etmv4_config {
  * @mode:	This tracer's mode, i.e sysFS, Perf or disabled.
  * @etm_options: Bitmask of options to manage ETMv4 Silicon issues
  * @cpu:        The cpu this component is affined to.
+ * @rc_cpu:	The cpu on which remote function calls can be run
+ *		In certain kernel configurations, some cores are not expected
+ *		to be interrupted and we need a fallback target cpu.
  * @arch:       ETM version number.
  * @nr_pe:	The number of processing entity available for tracing.
  * @nr_pe_cmp:	The number of processing entity comparator inputs that are
@@ -348,6 +351,7 @@ struct etmv4_drvdata {
 	local_t				mode;
 	u32				etm_options;
 	int				cpu;
+	int				rc_cpu;
 	u8				arch;
 	u8				nr_pe;
 	u8				nr_pe_cmp;
diff --git a/drivers/hwtracing/coresight/coresight-priv.h b/drivers/hwtracing/coresight/coresight-priv.h
index 6a796e739c78..fbcbac917eff 100644
--- a/drivers/hwtracing/coresight/coresight-priv.h
+++ b/drivers/hwtracing/coresight/coresight-priv.h
@@ -77,8 +77,37 @@ extern const u32 barrier_pkt[4];
 #define CSETR_QUIRK_BUFFSIZE_8BX	(0x1U << 0) /* 8 byte size multiplier */
 #define CSETR_QUIRK_SECURE_BUFF		(0x1U << 1) /* Trace buffer is Secure */
 #define CSETR_QUIRK_RESET_CTL_REG	(0x1U << 2) /* Reset CTL on reset */
+#define CSETM_QUIRK_SW_SYNC		(0x1U << 4) /* No Hardware sync */
 #define CSETM_QUIRK_TREAT_ETMv43	(0x1U << 5) /* ETMv4.2 as ETMv4.3 */
 
+/* ETM sync insertion modes
+ * 1. MODE_HW
+ *    Sync insertion is done by hardware without any software intervention
+ *
+ * 2. MODE_SW_GLOBAL
+ *    sync insertion runs from common timer handler on primary core
+ *
+ * 3. MODE_SW_PER_CORE
+ *    sync insertion runs from per core timer handler
+ *
+ * When hardware doesn't support sync insertion, we fall back to software based
+ * ones. Typically, GLOBAL mode would be preferred when the traced cores are
+ * running performance critical applications and cannot be interrupted,
+ * but at the same time there would be a small loss of trace data during the
+ * insertion sequence as well.
+ *
+ * For the sake of simplicity, in GLOBAL mode, common timer handler is
+ * always expected to run on primary core(core 0).
+ */
+#define SYNC_GLOBAL_CORE	0 /* Core 0 */
+
+enum etm_sync_mode {
+	SYNC_MODE_INVALID,
+	SYNC_MODE_HW,
+	SYNC_MODE_SW_GLOBAL,
+	SYNC_MODE_SW_PER_CORE,
+};
+
 enum etm_addr_type {
 	ETM_ADDR_TYPE_NONE,
 	ETM_ADDR_TYPE_SINGLE,
@@ -216,4 +245,11 @@ static inline void *coresight_get_uci_data(const struct amba_id *id)
 u32 coresight_get_etr_quirks(unsigned int id);
 u32 coresight_get_etm_quirks(unsigned int id);
 
+/* ETM software sync insertion */
+bool is_etm_sync_mode_hw(void);
+bool is_etm_sync_mode_sw_global(void);
+
+void coresight_etm_active_enable(int cpu);
+void coresight_etm_active_disable(int cpu);
+cpumask_t coresight_etm_active_list(void);
 #endif
diff --git a/drivers/hwtracing/coresight/coresight-quirks.c b/drivers/hwtracing/coresight/coresight-quirks.c
index 7f7e92eb62c7..dde5c0606c31 100644
--- a/drivers/hwtracing/coresight/coresight-quirks.c
+++ b/drivers/hwtracing/coresight/coresight-quirks.c
@@ -33,3 +33,74 @@ u32 coresight_get_etm_quirks(unsigned int id)
 
 	return options;
 }
+
+bool is_etm_has_hw_sync(void)
+{
+	/* Check if hardware supports sync insertion */
+	if (midr_is_cpu_model_range(read_cpuid_id(),
+				     MIDR_MRVL_OCTEONTX2_96XX,
+				     MIDR_CPU_VAR_REV(0, 0),
+				     MIDR_CPU_VAR_REV(3, 0)) ||
+	    midr_is_cpu_model_range(read_cpuid_id(),
+				     MIDR_MRVL_OCTEONTX2_95XX,
+				     MIDR_CPU_VAR_REV(0, 0),
+				     MIDR_CPU_VAR_REV(2, 0)))
+		return false;
+	else
+		return true;
+}
+
+/* APIs for choosing the sync insertion mode */
+static int coresight_get_etm_sync_mode(void)
+{
+	/* Check if hardware supports sync insertion */
+	if (is_etm_has_hw_sync())
+		return SYNC_MODE_HW;
+
+	/* Find the software based sync insertion mode */
+#ifdef CONFIG_TASK_ISOLATION
+	return SYNC_MODE_SW_GLOBAL;
+#else
+	return SYNC_MODE_SW_PER_CORE;
+#endif
+}
+
+/* APIs for enabling fixes for CSETR_QUIRK_SW_SYNC
+ *
+ * Note: Driver options are not used as done in other quirks,
+ * since the fix is spread across multiple(ETM/ETR) driver files.
+ */
+
+bool is_etm_sync_mode_hw(void)
+{
+	return coresight_get_etm_sync_mode() == SYNC_MODE_HW;
+}
+
+bool is_etm_sync_mode_sw_global(void)
+{
+	return coresight_get_etm_sync_mode() == SYNC_MODE_SW_GLOBAL;
+}
+
+/* Support functions for managing active ETM list used by
+ * global mode sync insertion.
+ *
+ * Note: It is assumed that all accessor functions
+ * on etm_active_list should be called in a atomic context
+ */
+
+static cpumask_t etm_active_list; /* Bitmap of active ETMs cpu wise */
+
+void coresight_etm_active_enable(int cpu)
+{
+	cpumask_set_cpu(cpu, &etm_active_list);
+}
+
+void coresight_etm_active_disable(int cpu)
+{
+	cpumask_clear_cpu(cpu, &etm_active_list);
+}
+
+cpumask_t coresight_etm_active_list(void)
+{
+	return etm_active_list;
+}
diff --git a/drivers/hwtracing/coresight/coresight-tmc-etr.c b/drivers/hwtracing/coresight/coresight-tmc-etr.c
index 0c2536ebdeb8..eee33b25b212 100644
--- a/drivers/hwtracing/coresight/coresight-tmc-etr.c
+++ b/drivers/hwtracing/coresight/coresight-tmc-etr.c
@@ -109,6 +109,222 @@ struct etr_sg_table {
 	dma_addr_t		hwaddr;
 };
 
+/* SW mode sync insertion interval
+ *
+ * Sync insertion interval for 1M is based on assumption of
+ * trace data generated at  4bits/cycle ,cycle period of 0.4 ns
+ * and atleast 4 syncs per buffer wrap.
+ *
+ * One limitation of fixing only 4 syncs per buffer wrap is that
+ * we might loose 1/4 of the initial buffer data due to lack of sync.
+ * But on the other hand, we could reduce the sync insertion frequency
+ * by increasing the buffer size which seems to be a good compromise.
+ */
+#define SYNC_TICK_NS_PER_MB 200000 /* 200us */
+#define SYNCS_PER_FILL 4
+
+/* Global mode timer management */
+
+/**
+ * struct tmc_etr_tsync_global - Global mode timer
+ * @drvdata_cpumap:	cpu to tmc drvdata map
+ * @timer:		global timer shared by all cores
+ * @tick:		gloabl timer tick period
+ * @active_count:	timer reference count
+ */
+static struct tmc_etr_tsync_global {
+	struct tmc_drvdata *drvdata_cpumap[NR_CPUS];
+	struct hrtimer	timer;
+	int active_count;
+	u64 tick;
+} tmc_etr_tsync_global;
+
+/* Accessor functions for tsync global */
+void tmc_etr_add_cpumap(struct tmc_drvdata *drvdata)
+{
+	tmc_etr_tsync_global.drvdata_cpumap[drvdata->cpu] = drvdata;
+}
+
+static inline struct tmc_drvdata *cpu_to_tmcdrvdata(int cpu)
+{
+	return tmc_etr_tsync_global.drvdata_cpumap[cpu];
+}
+
+static inline struct hrtimer *tmc_etr_tsync_global_timer(void)
+{
+	return &tmc_etr_tsync_global.timer;
+}
+
+static inline void tmc_etr_tsync_global_tick(u64 tick)
+{
+	tmc_etr_tsync_global.tick = tick;
+}
+
+/* Refernence counting is assumed to be always called from
+ * an atomic context.
+ */
+static inline int tmc_etr_tsync_global_addref(void)
+{
+	return ++tmc_etr_tsync_global.active_count;
+}
+
+static inline int tmc_etr_tsync_global_delref(void)
+{
+	return --tmc_etr_tsync_global.active_count;
+}
+
+/* Sync insertion API */
+static void tmc_etr_insert_sync(struct tmc_drvdata *drvdata)
+{
+	struct coresight_device *sdev = drvdata->etm_source;
+	struct etr_tsync_data *syncd = &drvdata->tsync_data;
+	int err = 0, len;
+	u64 rwp;
+
+	/* We have two contenders for ETM control.
+	 * 1. User initiated ETM control
+	 * 2. Timer sync initiated ETM control
+	 * They all run in an atomic context and that too in
+	 * the same core. Either on a core in which ETM is associated
+	 * or in the primary core thereby mutually exclusive.
+	 *
+	 * To avoid any sync insertion while ETM is disabled by
+	 * user, we rely on the device hw_state.
+	 * Like for example, hrtimer being in active state even
+	 * after ETM is disabled by user.
+	 */
+	if (sdev->hw_state != USR_START)
+		return;
+
+	rwp = tmc_read_rwp(drvdata);
+	if (!syncd->prev_rwp)
+		goto sync_insert;
+
+	if (syncd->prev_rwp <= rwp) {
+		len = rwp - syncd->prev_rwp;
+	} else { /* Buffer wrapped */
+		goto sync_insert;
+	}
+
+	/* Check if we reached buffer threshold */
+	if (len < syncd->len_thold)
+		goto skip_insert;
+
+	/* Software based sync insertion procedure */
+sync_insert:
+	/* Disable source */
+	if (likely(sdev && source_ops(sdev)->disable_raw))
+		source_ops(sdev)->disable_raw(sdev);
+	else
+		err = -EINVAL;
+
+	/* Enable source */
+	if (likely(sdev && source_ops(sdev)->enable_raw))
+		source_ops(sdev)->enable_raw(sdev);
+	else
+		err = -EINVAL;
+
+	if (!err) {
+		/* Mark the write pointer of sync insertion */
+		syncd->prev_rwp = tmc_read_rwp(drvdata);
+	}
+
+skip_insert:
+	return;
+}
+
+/* Timer handler APIs */
+
+static enum hrtimer_restart tmc_etr_timer_handler_percore(struct hrtimer *t)
+{
+	struct tmc_drvdata *drvdata;
+
+	drvdata = container_of(t, struct tmc_drvdata, timer);
+	hrtimer_forward_now(t, ns_to_ktime(drvdata->tsync_data.tick));
+	tmc_etr_insert_sync(drvdata);
+	return HRTIMER_RESTART;
+}
+
+static enum hrtimer_restart tmc_etr_timer_handler_global(struct hrtimer *t)
+{
+	cpumask_t active_mask;
+	int cpu;
+
+	hrtimer_forward_now(t, ns_to_ktime(tmc_etr_tsync_global.tick));
+
+	active_mask = coresight_etm_active_list();
+	/* Run sync insertions for all active ETMs */
+	for_each_cpu(cpu, &active_mask)
+		tmc_etr_insert_sync(cpu_to_tmcdrvdata(cpu));
+
+	return HRTIMER_RESTART;
+}
+
+/* Timer setup API common for both global and per core mode
+ *
+ * Global mode: Timer gets started only if its not active already.
+ *		Number of users managed by reference counting.
+ * Percore mode: Timer gets started always
+ *
+ * Always executed in an atomic context either in IPI handler
+ * on a remote core or with irqs disabled in the local core
+ */
+static void tmc_etr_timer_setup(void *data)
+{
+	struct tmc_drvdata *drvdata = data;
+	struct hrtimer *timer;
+	bool mode_global;
+	u64 tick;
+
+	tick = drvdata->tsync_data.tick;
+	mode_global = is_etm_sync_mode_sw_global();
+	if (mode_global) {
+		if (tmc_etr_tsync_global_addref() == 1) {
+			/* Start only if we are the first user */
+			tmc_etr_tsync_global_tick(tick); /* Configure tick */
+		} else {
+			dev_dbg(drvdata->dev, "global timer active already\n");
+			return;
+		}
+	}
+
+	timer = mode_global ?
+		tmc_etr_tsync_global_timer() : &drvdata->timer;
+	hrtimer_init(timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+	timer->function = mode_global ?
+		tmc_etr_timer_handler_global : tmc_etr_timer_handler_percore;
+	dev_dbg(drvdata->dev, "Starting sync timer, mode:%s period:%lld ns\n",
+		mode_global ? "global" : "percore", tick);
+	hrtimer_start(timer, ns_to_ktime(tick), HRTIMER_MODE_REL_PINNED);
+}
+
+/* Timer cancel API common for both global and per core mode
+ *
+ * Global mode: Timer gets cancelled only if there are no other users
+ * Percore mode: Timer gets cancelled always
+ *
+ * Always executed in an atomic context either in IPI handler
+ * on a remote core or with irqs disabled in the local core
+ */
+static void tmc_etr_timer_cancel(void *data)
+{
+	struct tmc_drvdata *drvdata = data;
+	struct hrtimer *timer;
+	bool mode_global;
+
+	mode_global = is_etm_sync_mode_sw_global();
+	if (mode_global) {
+		if (tmc_etr_tsync_global_delref() != 0) {
+			/* Nothing to do if we are not the last user */
+			return;
+		}
+	}
+
+	timer = mode_global ?
+		tmc_etr_tsync_global_timer() : &drvdata->timer;
+	hrtimer_cancel(timer);
+}
+
 /*
  * tmc_etr_sg_table_entries: Total number of table entries required to map
  * @nr_pages system pages.
@@ -1151,6 +1367,20 @@ static int tmc_enable_etr_sink_sysfs(struct coresight_device *csdev)
 	struct tmc_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 	struct etr_buf *sysfs_buf = NULL, *new_buf = NULL, *free_buf = NULL;
 
+	if (!is_etm_sync_mode_hw()) {
+		/* Calculate parameters for sync insertion */
+		drvdata->tsync_data.len_thold =
+			drvdata->size / (SYNCS_PER_FILL);
+		drvdata->tsync_data.tick =
+			(drvdata->size / SZ_1M) * SYNC_TICK_NS_PER_MB;
+		drvdata->tsync_data.prev_rwp = 0;
+		if (!drvdata->tsync_data.tick) {
+			drvdata->tsync_data.tick = SYNC_TICK_NS_PER_MB;
+			dev_warn(drvdata->dev,
+				 "Trace bufer size not sufficient, sync insertion can fail\n");
+		}
+	}
+
 	/*
 	 * If we are enabling the ETR from disabled state, we need to make
 	 * sure we have a buffer with the right size. The etr_buf is not reset
@@ -1206,6 +1436,10 @@ static int tmc_enable_etr_sink_sysfs(struct coresight_device *csdev)
 out:
 	spin_unlock_irqrestore(&drvdata->spinlock, flags);
 
+
+	if (!ret && !is_etm_sync_mode_hw())
+		smp_call_function_single(drvdata->rc_cpu, tmc_etr_timer_setup,
+					 drvdata, true);
 	/* Free memory outside the spinlock if need be */
 	if (free_buf)
 		tmc_etr_free_sysfs_buf(free_buf);
@@ -1656,16 +1890,36 @@ static int tmc_disable_etr_sink(struct coresight_device *csdev)
 
 	spin_unlock_irqrestore(&drvdata->spinlock, flags);
 
+	if (!is_etm_sync_mode_hw())
+		smp_call_function_single(drvdata->rc_cpu, tmc_etr_timer_cancel,
+					 drvdata, true);
+
 	dev_dbg(drvdata->dev, "TMC-ETR disabled\n");
 	return 0;
 }
 
+void tmc_register_source(struct coresight_device *csdev, void *source)
+{
+	struct tmc_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
+
+	drvdata->etm_source = source;
+}
+
+void tmc_unregister_source(struct coresight_device *csdev)
+{
+	struct tmc_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
+
+	drvdata->etm_source = NULL;
+}
+
 static const struct coresight_ops_sink tmc_etr_sink_ops = {
 	.enable		= tmc_enable_etr_sink,
 	.disable	= tmc_disable_etr_sink,
 	.alloc_buffer	= tmc_alloc_etr_buffer,
 	.update_buffer	= tmc_update_etr_buffer,
 	.free_buffer	= tmc_free_etr_buffer,
+	.register_source = tmc_register_source,
+	.unregister_source = tmc_unregister_source,
 };
 
 const struct coresight_ops tmc_etr_cs_ops = {
diff --git a/drivers/hwtracing/coresight/coresight-tmc.c b/drivers/hwtracing/coresight/coresight-tmc.c
index bbeb98bbf8b5..adc6233a8dd4 100644
--- a/drivers/hwtracing/coresight/coresight-tmc.c
+++ b/drivers/hwtracing/coresight/coresight-tmc.c
@@ -428,6 +428,13 @@ static int tmc_probe(struct amba_device *adev, const struct amba_id *id)
 	/* Enable fixes for Silicon issues */
 	drvdata->etr_options = coresight_get_etr_quirks(OCTEONTX_CN9XXX_ETR);
 
+	/* Update the smp target cpu */
+	drvdata->rc_cpu = is_etm_sync_mode_sw_global() ? SYNC_GLOBAL_CORE :
+		drvdata->cpu;
+	/* Used for SW sync insertion(global mode) */
+	if (!is_etm_sync_mode_hw())
+		tmc_etr_add_cpumap(drvdata);
+
 	devid = readl_relaxed(drvdata->base + CORESIGHT_DEVID);
 	drvdata->config_type = BMVAL(devid, 6, 7);
 	drvdata->memwidth = tmc_get_memwidth(devid);
diff --git a/drivers/hwtracing/coresight/coresight-tmc.h b/drivers/hwtracing/coresight/coresight-tmc.h
index e987145d44a3..5304c9167905 100644
--- a/drivers/hwtracing/coresight/coresight-tmc.h
+++ b/drivers/hwtracing/coresight/coresight-tmc.h
@@ -183,6 +183,20 @@ struct etr_buf {
 	void				*private;
 };
 
+/**
+ * struct etr_tsync_data - Timer based sync insertion data management
+ * @syncs_per_fill:	syncs inserted per buffer wrap
+ * @prev_rwp:		writepointer for the last sync insertion
+ * @len_thold:		Buffer length threshold for inserting syncs
+ * @tick:		Tick interval in ns
+ */
+struct etr_tsync_data {
+	int syncs_per_fill;
+	u64 prev_rwp;
+	u64 len_thold;
+	u64 tick;
+};
+
 /**
  * struct tmc_drvdata - specifics associated to an TMC component
  * @base:	memory mapped base address for this component.
@@ -209,6 +223,12 @@ struct etr_buf {
  * @sysfs_data:	SYSFS buffer for ETR.
  * @etr_options: Bitmask of options to manage Silicon issues
  * @cpu:	CPU id this component is associated with
+ * @rc_cpu:	The cpu on which remote function calls can be run
+ *		In certain kernel configurations, some cores are not expected
+ *		to be interrupted and we need a fallback target cpu.
+ * @etm_source:	ETM source associated with this ETR
+ * @etr_tsync_data: Timer based sync insertion data
+ * @timer:	Timer for initiating sync insertion
  */
 struct tmc_drvdata {
 	void __iomem		*base;
@@ -237,6 +257,10 @@ struct tmc_drvdata {
 	void			*perf_data;
 	u32			etr_options;
 	int			cpu;
+	int			rc_cpu;
+	void			*etm_source;
+	struct etr_tsync_data	tsync_data;
+	struct hrtimer		timer;
 };
 
 struct etr_buf_operations {
@@ -297,6 +321,7 @@ ssize_t tmc_etb_get_sysfs_trace(struct tmc_drvdata *drvdata,
 /* ETR functions */
 int tmc_read_prepare_etr(struct tmc_drvdata *drvdata);
 int tmc_read_unprepare_etr(struct tmc_drvdata *drvdata);
+void tmc_etr_add_cpumap(struct tmc_drvdata *drvdata);
 extern const struct coresight_ops tmc_etr_cs_ops;
 ssize_t tmc_etr_get_sysfs_trace(struct tmc_drvdata *drvdata,
 				loff_t pos, size_t len, char **bufpp);
diff --git a/drivers/hwtracing/coresight/coresight.c b/drivers/hwtracing/coresight/coresight.c
index 1fbf7e125b23..0d708682b3ad 100644
--- a/drivers/hwtracing/coresight/coresight.c
+++ b/drivers/hwtracing/coresight/coresight.c
@@ -20,6 +20,8 @@
 #include <linux/pm_runtime.h>
 
 #include "coresight-etm-perf.h"
+#include <asm/cputype.h>
+
 #include "coresight-priv.h"
 
 static DEFINE_MUTEX(coresight_mutex);
@@ -809,6 +811,13 @@ int coresight_enable(struct coresight_device *csdev)
 		goto out;
 	}
 
+	if (!is_etm_sync_mode_hw()) {
+		/* Add reference to source
+		 * Used by sync insertion logic in ETR driver
+		 */
+		sink_ops(sink)->register_source(sink, csdev);
+	}
+
 	path = coresight_build_path(csdev, sink);
 	if (IS_ERR(path)) {
 		pr_err("building path(s) failed\n");
@@ -860,6 +869,7 @@ EXPORT_SYMBOL_GPL(coresight_enable);
 void coresight_disable(struct coresight_device *csdev)
 {
 	int cpu, ret;
+	struct coresight_device *sink;
 	struct list_head *path = NULL;
 
 	mutex_lock(&coresight_mutex);
@@ -886,6 +896,16 @@ void coresight_disable(struct coresight_device *csdev)
 		break;
 	}
 
+	if (!is_etm_sync_mode_hw()) {
+		sink = coresight_get_enabled_sink(csdev, false);
+		if (!sink)
+			goto out;
+		/* Remove source reference
+		 * Used by sync insertion logic in ETR driver
+		 */
+		sink_ops(sink)->unregister_source(csdev);
+	}
+
 	coresight_disable_path(path);
 	coresight_release_path(path);
 
diff --git a/include/linux/coresight.h b/include/linux/coresight.h
index 62a520df8add..de23844dfdd7 100644
--- a/include/linux/coresight.h
+++ b/include/linux/coresight.h
@@ -140,6 +140,12 @@ struct coresight_connection {
 	struct coresight_device *child_dev;
 };
 
+enum hw_state {
+	USR_STOP,
+	SW_STOP,
+	USR_START,
+};
+
 /**
  * struct coresight_device - representation of a device as used by the framework
  * @conns:	array of coresight_connections associated to this component.
@@ -153,6 +159,7 @@ struct coresight_connection {
  * @refcnt:	keep track of what is in use.
  * @orphan:	true if the component has connections that haven't been linked.
  * @enable:	'true' if component is currently part of an active path.
+ * @hw_state:   state of hw
  * @activated:	'true' only if a _sink_ has been activated.  A sink can be
  *		activated but not yet enabled.  Enabling for a _sink_
  *		appens when a source has been selected for that it.
@@ -170,6 +177,7 @@ struct coresight_device {
 	bool orphan;
 	bool enable;	/* true only if configured as part of a path */
 	/* sink specific fields */
+	int hw_state;
 	bool activated;	/* true only if a sink is part of a path */
 	struct dev_ext_attribute *ea;
 };
@@ -189,6 +197,8 @@ struct coresight_device {
  * @alloc_buffer:	initialises perf's ring buffer for trace collection.
  * @free_buffer:	release memory allocated in @get_config.
  * @update_buffer:	update buffer pointers after a trace session.
+ * @register_source:	Add reference to source
+ * @unregister_source:	Remove reference to source
  */
 struct coresight_ops_sink {
 	int (*enable)(struct coresight_device *csdev, u32 mode, void *data);
@@ -200,6 +210,9 @@ struct coresight_ops_sink {
 	unsigned long (*update_buffer)(struct coresight_device *csdev,
 			      struct perf_output_handle *handle,
 			      void *sink_config);
+	void (*register_source)(struct coresight_device *sink_dev,
+				void *source);
+	void (*unregister_source)(struct coresight_device *sink_dev);
 };
 
 /**
@@ -222,6 +235,8 @@ struct coresight_ops_link {
  *		to the HW.
  * @enable:	enables tracing for a source.
  * @disable:	disables tracing for a source.
+ * @enable_raw:	Raw HW enable, without any other register configuration
+ * @disable_raw:Raw HW disable
  */
 struct coresight_ops_source {
 	int (*cpu_id)(struct coresight_device *csdev);
@@ -230,6 +245,8 @@ struct coresight_ops_source {
 		      struct perf_event *event,  u32 mode);
 	void (*disable)(struct coresight_device *csdev,
 			struct perf_event *event);
+	void (*enable_raw)(struct coresight_device *csdev);
+	void (*disable_raw)(struct coresight_device *csdev);
 };
 
 /**
-- 
2.31.1

