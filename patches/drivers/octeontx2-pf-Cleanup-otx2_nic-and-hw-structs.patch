From 307fa865ef7331e68b17e8c7aa3fe0b708c57da1 Mon Sep 17 00:00:00 2001
From: Sunil Goutham <sgoutham@marvell.com>
Date: Mon, 28 Oct 2019 22:31:09 +0530
Subject: [PATCH 395/767] octeontx2-pf: Cleanup otx2_nic and hw structs

commit b17de4c302b0e2faad7bbf4e970538713f35775e from
git@git.assembla.com:cavium/WindRiver.linux.git

Move HW related settings info fields to otx2_hw struct
and cleanup both otx2_nic and otx2_hw structs.

Change-Id: Ic142c188b310fe5d4833fe1a85f211deb436a2bc
Signed-off-by: Sunil Goutham <sgoutham@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/18007
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../marvell/octeontx2/nic/otx2_common.c       | 26 ++++----
 .../marvell/octeontx2/nic/otx2_common.h       | 60 ++++++++++---------
 .../marvell/octeontx2/nic/otx2_ethtool.c      | 38 ++++++------
 .../marvell/octeontx2/nic/otx2_flows.c        |  6 +-
 .../ethernet/marvell/octeontx2/nic/otx2_pf.c  |  4 +-
 5 files changed, 71 insertions(+), 63 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
index 5575f6971245..0145dcf068e7 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
@@ -338,9 +338,9 @@ void otx2_config_irq_coalescing(struct otx2_nic *pfvf, int qidx)
 	 * usecs, convert that to 100ns count.
 	 */
 	otx2_write64(pfvf, NIX_LF_CINTX_WAIT(qidx),
-		     ((u64)(pfvf->cq_time_wait * 10) << 48) |
-		     ((u64)pfvf->cq_qcount_wait << 32) |
-		     (pfvf->cq_ecount_wait - 1));
+		     ((u64)(pfvf->hw.cq_time_wait * 10) << 48) |
+		     ((u64)pfvf->hw.cq_qcount_wait << 32) |
+		     (pfvf->hw.cq_ecount_wait - 1));
 }
 
 dma_addr_t otx2_alloc_rbuf(struct otx2_nic *pfvf, struct otx2_pool *pool,
@@ -409,12 +409,12 @@ static int otx2_get_link(struct otx2_nic *pfvf)
 	u16 map;
 
 	/* cgx lmac link */
-	if (pfvf->tx_chan_base >= CGX_CHAN_BASE) {
-		map = pfvf->tx_chan_base & 0x7FF;
+	if (pfvf->hw.tx_chan_base >= CGX_CHAN_BASE) {
+		map = pfvf->hw.tx_chan_base & 0x7FF;
 		link = 4 * ((map >> 8) & 0xF) + ((map >> 4) & 0xF);
 	}
 	/* LBK channel */
-	if (pfvf->tx_chan_base < SDP_CHAN_BASE)
+	if (pfvf->hw.tx_chan_base < SDP_CHAN_BASE)
 		link = 12;
 
 	return link;
@@ -578,8 +578,8 @@ static int otx2_rq_init(struct otx2_nic *pfvf, u16 qidx, u16 lpb_aura)
 	aq->rq.qint_idx = 0;
 	aq->rq.lpb_drop_ena = 1; /* Enable RED dropping for AURA */
 	aq->rq.xqe_drop_ena = 1; /* Enable RED dropping for CQ/SSO */
-	aq->rq.xqe_pass = RQ_PASS_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
-	aq->rq.xqe_drop = RQ_DROP_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
+	aq->rq.xqe_pass = RQ_PASS_LVL_CQ(pfvf->hw.rq_skid, qset->rqe_cnt);
+	aq->rq.xqe_drop = RQ_DROP_LVL_CQ(pfvf->hw.rq_skid, qset->rqe_cnt);
 	aq->rq.lpb_aura_pass = RQ_PASS_LVL_AURA;
 	aq->rq.lpb_aura_drop = RQ_DROP_LVL_AURA;
 
@@ -650,7 +650,7 @@ static int otx2_sq_init(struct otx2_nic *pfvf, u16 qidx, u16 sqb_aura)
 	/* Only one SMQ is allocated, map all SQ's to that SMQ  */
 	aq->sq.smq = pfvf->hw.txschq_list[NIX_TXSCH_LVL_SMQ][0];
 	aq->sq.smq_rr_quantum = OTX2_MAX_MTU;
-	aq->sq.default_chan = pfvf->tx_chan_base;
+	aq->sq.default_chan = pfvf->hw.tx_chan_base;
 	aq->sq.sqe_stype = NIX_STYPE_STF; /* Cache SQB */
 	aq->sq.sqb_aura = sqb_aura;
 	aq->sq.sq_int_ena = NIX_SQINT_BITS;
@@ -718,7 +718,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 	aq->cq.avg_level = 255;
 
 	if (qidx < pfvf->hw.rx_queues) {
-		aq->cq.drop = RQ_DROP_LVL_CQ(pfvf->rq_skid, cq->cqe_cnt);
+		aq->cq.drop = RQ_DROP_LVL_CQ(pfvf->hw.rq_skid, cq->cqe_cnt);
 		aq->cq.drop_ena = 1;
 
 		/* Enable receive CQ backpressure */
@@ -726,7 +726,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 		aq->cq.bpid = pfvf->bpid[0];
 
 		/* Set backpressure level is same as cq pass level */
-		aq->cq.bp = RQ_PASS_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
+		aq->cq.bp = RQ_PASS_LVL_CQ(pfvf->hw.rq_skid, qset->rqe_cnt);
 	}
 
 	/* Fill AQ info */
@@ -1384,8 +1384,8 @@ void mbox_handler_nix_lf_alloc(struct otx2_nic *pfvf,
 			       struct nix_lf_alloc_rsp *rsp)
 {
 	pfvf->hw.sqb_size = rsp->sqb_size;
-	pfvf->rx_chan_base = rsp->rx_chan_base;
-	pfvf->tx_chan_base = rsp->tx_chan_base;
+	pfvf->hw.rx_chan_base = rsp->rx_chan_base;
+	pfvf->hw.tx_chan_base = rsp->tx_chan_base;
 	pfvf->hw.lso_tsov4_idx = rsp->lso_tsov4_idx;
 	pfvf->hw.lso_tsov6_idx = rsp->lso_tsov6_idx;
 }
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
index 81c4cf8cb22c..6cb8ee69aa1b 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
@@ -152,8 +152,6 @@ struct  mbox {
 struct otx2_hw {
 	struct pci_dev		*pdev;
 	struct otx2_rss_info	rss_info;
-	struct otx2_dev_stats	dev_stats;
-	struct otx2_drv_stats	drv_stats;
 	u16                     rx_queues;
 	u16                     tx_queues;
 	u16			max_queues;
@@ -166,20 +164,32 @@ struct otx2_hw {
 	u32			stack_pg_bytes; /* Size of stack page */
 	u16			sqb_size;
 
-	/* MSI-X*/
-	u16			npa_msixoff; /* Offset of NPA vectors */
-	u16			nix_msixoff; /* Offset of NIX vectors */
-	char			*irq_name;
-	cpumask_var_t           *affinity_mask;
-
-	u8			cint_cnt; /* CQ interrupt count */
+	/* NIX */
 	u16		txschq_list[NIX_TXSCH_LVL_CNT][MAX_TXSCHQ_PER_FUNC];
 
+	/* HW settings, coalescing etc */
+	u16			rx_chan_base;
+	u16			tx_chan_base;
+	u16			cq_qcount_wait;
+	u16			cq_ecount_wait;
+	u16			rq_skid;
+	u8			cq_time_wait;
+
 	/* For TSO segmentation */
 	u8			lso_tsov4_idx;
 	u8			lso_tsov6_idx;
 	u8			hw_tso;
 
+	/* MSI-X*/
+	u8			cint_cnt; /* CQ interrupt count */
+	u16			npa_msixoff; /* Offset of NPA vectors */
+	u16			nix_msixoff; /* Offset of NIX vectors */
+	char			*irq_name;
+	cpumask_var_t           *affinity_mask;
+
+	/* Stats */
+	struct otx2_dev_stats	dev_stats;
+	struct otx2_drv_stats	drv_stats;
 	u64			cgx_rx_stats[CGX_RX_STATS_COUNT];
 	u64			cgx_tx_stats[CGX_TX_STATS_COUNT];
 	u64			cgx_fec_corr_blks;
@@ -248,34 +258,30 @@ struct otx2_nic {
 	struct workqueue_struct *mbox_wq;
 	struct workqueue_struct *mbox_pfvf_wq;
 
-	u16			pcifunc;
-	u16			rx_chan_base;
-	u16			tx_chan_base;
-	u8			cq_time_wait;
-	u16			cq_qcount_wait;
-	u16			cq_ecount_wait;
-	u16			rq_skid;
-	u32			msg_enable;
-	struct work_struct	reset_task;
-	u64			reset_count;
 	u8			total_vfs;
+	u16			pcifunc; /* RVU PF_FUNC */
 	u16			bpid[NIX_MAX_BPID_CHAN];
+	struct otx2_ptp		*ptp;
 	struct otx2_vf_config	*vf_configs;
 	struct cgx_link_user_info linfo;
-	struct otx2_ptp		*ptp;
 
 	/* NPC MCAM */
 	u32			nr_flows;
 	u32                     ntuple_max_flows;
 	u16			entry_list[NPC_MAX_NONCONTIG_ENTRIES];
 	struct list_head	flows;
+	struct otx2_mac_table	*mac_table;
 
+	u64			reset_count;
+	struct work_struct	reset_task;
 	struct workqueue_struct	*flr_wq;
 	struct flr_work		*flr_wrk;
 	struct refill_work	*refill_wrk;
-	struct otx2_mac_table	*mac_table;
-	struct workqueue_struct	*otx2_ndo_wq;
 	struct work_struct	otx2_rx_mode_work;
+	struct workqueue_struct	*otx2_ndo_wq;
+
+	/* Ethtool stuff */
+	u32			msg_enable;
 
 #define OTX2_PRIV_FLAG_PAM4			BIT(0)
 #define OTX2_PRIV_FLAG_EDSA_HDR			BIT(1)
@@ -315,9 +321,9 @@ static inline void otx2_setup_dev_hw_settings(struct otx2_nic *pfvf)
 {
 	struct otx2_hw *hw = &pfvf->hw;
 
-	pfvf->cq_time_wait = CQ_TIMER_THRESH_DEFAULT;
-	pfvf->cq_ecount_wait = CQ_CQE_THRESH_DEFAULT;
-	pfvf->cq_qcount_wait = CQ_QCOUNT_DEFAULT;
+	pfvf->hw.cq_time_wait = CQ_TIMER_THRESH_DEFAULT;
+	pfvf->hw.cq_ecount_wait = CQ_CQE_THRESH_DEFAULT;
+	pfvf->hw.cq_qcount_wait = CQ_QCOUNT_DEFAULT;
 
 	hw->hw_tso = true;
 
@@ -326,11 +332,11 @@ static inline void otx2_setup_dev_hw_settings(struct otx2_nic *pfvf)
 	/* Due to HW issue previous silicons required minimum 600
 	 * unused CQE to avoid CQ overflow.
 	 */
-		pfvf->rq_skid = 600;
+		pfvf->hw.rq_skid = 600;
 		pfvf->qset.rqe_cnt = Q_COUNT(Q_SIZE_1K);
 	}
 	if (is_96xx_A0(pfvf->pdev))
-		pfvf->cq_qcount_wait = 0x0;
+		pfvf->hw.cq_qcount_wait = 0x0;
 }
 
 static inline void __iomem *otx2_get_regaddr(struct otx2_nic *nic, u64 offset)
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
index 84a0b34448b1..8f804effb352 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c
@@ -393,8 +393,8 @@ static int otx2_set_ringparam(struct net_device *netdev,
 	/* On some silicon variants a skid or reserved CQEs are
 	 * needed to avoid CQ overflow.
 	 */
-	if (rx_count < pfvf->rq_skid)
-		rx_count =  pfvf->rq_skid;
+	if (rx_count < pfvf->hw.rq_skid)
+		rx_count =  pfvf->hw.rq_skid;
 	rx_count = Q_COUNT(Q_SIZE(rx_count, 3));
 
 	/* Due pipelining impact minimum 2000 unused SQ CQE's
@@ -424,11 +424,12 @@ static int otx2_get_coalesce(struct net_device *netdev,
 			     struct ethtool_coalesce *cmd)
 {
 	struct otx2_nic *pfvf = netdev_priv(netdev);
+	struct otx2_hw *hw = &pfvf->hw;
 
-	cmd->rx_coalesce_usecs = pfvf->cq_time_wait;
-	cmd->rx_max_coalesced_frames = pfvf->cq_ecount_wait;
-	cmd->tx_coalesce_usecs = pfvf->cq_time_wait;
-	cmd->tx_max_coalesced_frames = pfvf->cq_ecount_wait;
+	cmd->rx_coalesce_usecs = hw->cq_time_wait;
+	cmd->rx_max_coalesced_frames = hw->cq_ecount_wait;
+	cmd->tx_coalesce_usecs = hw->cq_time_wait;
+	cmd->tx_max_coalesced_frames = hw->cq_ecount_wait;
 
 	return 0;
 }
@@ -437,6 +438,7 @@ static int otx2_set_coalesce(struct net_device *netdev,
 			     struct ethtool_coalesce *ec)
 {
 	struct otx2_nic *pfvf = netdev_priv(netdev);
+	struct otx2_hw *hw = &pfvf->hw;
 	int qidx;
 
 	if (ec->use_adaptive_rx_coalesce || ec->use_adaptive_tx_coalesce ||
@@ -464,13 +466,13 @@ static int otx2_set_coalesce(struct net_device *netdev,
 	/* Rx and Tx are mapped to same CQ, check which one
 	 * is changed, if both then choose the min.
 	 */
-	if (pfvf->cq_time_wait == ec->rx_coalesce_usecs)
-		pfvf->cq_time_wait = ec->tx_coalesce_usecs;
-	else if (pfvf->cq_time_wait == ec->tx_coalesce_usecs)
-		pfvf->cq_time_wait = ec->rx_coalesce_usecs;
+	if (hw->cq_time_wait == ec->rx_coalesce_usecs)
+		hw->cq_time_wait = ec->tx_coalesce_usecs;
+	else if (hw->cq_time_wait == ec->tx_coalesce_usecs)
+		hw->cq_time_wait = ec->rx_coalesce_usecs;
 	else
-		pfvf->cq_time_wait = min_t(u8, ec->rx_coalesce_usecs,
-					   ec->tx_coalesce_usecs);
+		hw->cq_time_wait = min_t(u8, ec->rx_coalesce_usecs,
+					 ec->tx_coalesce_usecs);
 
 	/* Max ecount_wait supported is 16bit,
 	 * so clamp the user given value to the range of 1 to 64k.
@@ -483,13 +485,13 @@ static int otx2_set_coalesce(struct net_device *netdev,
 	/* Rx and Tx are mapped to same CQ, check which one
 	 * is changed, if both then choose the min.
 	 */
-	if (pfvf->cq_ecount_wait == ec->rx_max_coalesced_frames)
-		pfvf->cq_ecount_wait = ec->tx_max_coalesced_frames;
-	else if (pfvf->cq_ecount_wait == ec->tx_max_coalesced_frames)
-		pfvf->cq_ecount_wait = ec->rx_max_coalesced_frames;
+	if (hw->cq_ecount_wait == ec->rx_max_coalesced_frames)
+		hw->cq_ecount_wait = ec->tx_max_coalesced_frames;
+	else if (hw->cq_ecount_wait == ec->tx_max_coalesced_frames)
+		hw->cq_ecount_wait = ec->rx_max_coalesced_frames;
 	else
-		pfvf->cq_ecount_wait = min_t(u16, ec->rx_max_coalesced_frames,
-					     ec->tx_max_coalesced_frames);
+		hw->cq_ecount_wait = min_t(u16, ec->rx_max_coalesced_frames,
+					   ec->tx_max_coalesced_frames);
 
 	if (netif_running(netdev)) {
 		for (qidx = 0; qidx < pfvf->hw.cint_cnt; qidx++)
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
index 1d4de95fcadf..96a4dbba25a3 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c
@@ -161,7 +161,7 @@ static int otx2_do_add_macfilter(struct otx2_nic *pf, const u8 *mac)
 	ether_addr_copy(req->packet.dmac, mac);
 	u64_to_ether_addr(0xffffffffffffull, req->mask.dmac);
 	req->features = BIT_ULL(NPC_DMAC);
-	req->channel = pf->rx_chan_base;
+	req->channel = pf->hw.rx_chan_base;
 	req->intf = NIX_INTF_RX;
 	req->op = NIX_RX_ACTION_DEFAULT;
 	req->set_cntr = 1;
@@ -313,7 +313,7 @@ static int otx2_add_flow_msg(struct otx2_nic *pfvf, struct otx2_flow *flow)
 	req->entry = flow->entry;
 	req->intf = NIX_INTF_RX;
 	req->set_cntr = 1;
-	req->channel = pfvf->rx_chan_base;
+	req->channel = pfvf->hw.rx_chan_base;
 	if (ring_cookie == RX_CLS_FLOW_DISC) {
 		req->op = NIX_RX_ACTIONOP_DROP;
 	} else {
@@ -522,7 +522,7 @@ static int otx2_install_rxvlan_offload_flow(struct otx2_nic *pfvf)
 	req->intf = NIX_INTF_RX;
 	ether_addr_copy(req->packet.dmac, pfvf->netdev->dev_addr);
 	u64_to_ether_addr(0xffffffffffffull, req->mask.dmac);
-	req->channel = pfvf->rx_chan_base;
+	req->channel = pfvf->hw.rx_chan_base;
 	req->op = NIX_RX_ACTION_DEFAULT;
 	req->features = BIT_ULL(NPC_OUTER_VID) | BIT_ULL(NPC_DMAC);
 	req->vtag0_valid = true;
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
index 7fb993a46eb1..e87a5a2cab68 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
@@ -1968,7 +1968,7 @@ static int otx2_do_set_vf_mac(struct otx2_nic *pf, int vf, const u8 *mac)
 	ether_addr_copy(req->packet.dmac, mac);
 	u64_to_ether_addr(0xffffffffffffull, req->mask.dmac);
 	req->features = BIT_ULL(NPC_DMAC);
-	req->channel = pf->rx_chan_base;
+	req->channel = pf->hw.rx_chan_base;
 	req->intf = NIX_INTF_RX;
 	req->default_rule = 1;
 	req->append = 1;
@@ -2014,7 +2014,7 @@ static int otx2_do_set_vf_vlan(struct otx2_nic *pf, int vf, u16 vlan, u8 qos)
 	req->packet.vlan_tci = htons(vlan);
 	req->mask.vlan_tci = htons(VLAN_VID_MASK);
 	req->features = BIT_ULL(NPC_OUTER_VID);
-	req->channel = pf->rx_chan_base;
+	req->channel = pf->hw.rx_chan_base;
 	req->intf = NIX_INTF_RX;
 	req->default_rule = 1;
 	req->append = 1;
-- 
2.31.1

