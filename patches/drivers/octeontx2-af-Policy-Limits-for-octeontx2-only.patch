From 07edb825b71876b2ae3669d2b3a58bc92d1fac6a Mon Sep 17 00:00:00 2001
From: George Cherian <george.cherian@marvell.com>
Date: Wed, 21 Oct 2020 16:44:26 +0530
Subject: [PATCH 0918/1921] octeontx2-af: Policy Limits for octeontx2 only

Policy limits will be applied only for octeontx2 family devices.
The current sysfs based method is not the ideal solution for limit
restrictions. This is not an upstreamable solution either.

The alternative method would be to use devlink. But as of today there
are limitations with the current devlink infratructure.
So resource limits are not applied for octeontx3 family.

Change-Id: Ic82ce9f6fc75469e8804efa28730ae4f134b1bda
Signed-off-by: George Cherian <george.cherian@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/kernel/linux/+/38660
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Signed-off-by: Sunil Goutham <sgoutham@marvell.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 .../marvell/octeontx2/af/rvu_validation.c     | 117 ++++++++++++++++++
 1 file changed, 117 insertions(+)

diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c b/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
index 47e0f9c64546..59786b70ea07 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
@@ -227,6 +227,108 @@ static int rvu_txsch_count_rsrc(struct rvu *rvu, int lvl, u16 pcifunc,
 	return count;
 }
 
+static int free_rsrc_cnt(struct rvu *rvu, struct msg_req *req,
+			 struct free_rsrcs_rsp *rsp)
+{
+	struct rvu_hwinfo *hw = rvu->hw;
+	u16 pcifunc = req->hdr.pcifunc;
+	struct rvu_block *block;
+	struct nix_txsch *txsch;
+	struct nix_hw *nix_hw;
+	int pf;
+
+	mutex_lock(&rvu->rsrc_lock);
+	pf = rvu_get_pf(pcifunc);
+
+	block = &hw->block[BLKADDR_NPA];
+	rsp->npa = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_NIX0];
+	rsp->nix = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_NIX1];
+	rsp->nix1 = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_SSO];
+	rsp->sso = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_SSOW];
+	rsp->ssow = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_TIM];
+	rsp->tim = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_CPT0];
+	rsp->cpt = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_CPT1];
+	rsp->cpt1 = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_REE0];
+	rsp->ree0 = rvu_rsrc_free_count(&block->lf);
+
+	block = &hw->block[BLKADDR_REE1];
+	rsp->ree1 = rvu_rsrc_free_count(&block->lf);
+
+	if (rvu->hw->cap.nix_fixed_txschq_mapping) {
+		rsp->schq[NIX_TXSCH_LVL_SMQ] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL4] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL3] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL2] = 1;
+		/* NIX1 */
+		if (!is_block_implemented(rvu->hw, BLKADDR_NIX1))
+			goto out;
+		rsp->schq_nix1[NIX_TXSCH_LVL_SMQ] = 1;
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL4] = 1;
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL3] = 1;
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL2] = 1;
+	} else {
+		nix_hw = get_nix_hw(hw, BLKADDR_NIX0);
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_SMQ];
+		rsp->schq[NIX_TXSCH_LVL_SMQ] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL4];
+		rsp->schq[NIX_TXSCH_LVL_TL4] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL3];
+		rsp->schq[NIX_TXSCH_LVL_TL3] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL2];
+		rsp->schq[NIX_TXSCH_LVL_TL2] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		if (!is_block_implemented(rvu->hw, BLKADDR_NIX1))
+			goto out;
+
+		nix_hw = get_nix_hw(hw, BLKADDR_NIX1);
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_SMQ];
+		rsp->schq_nix1[NIX_TXSCH_LVL_SMQ] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL4];
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL4] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL3];
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL3] =
+				rvu_rsrc_free_count(&txsch->schq);
+
+		txsch = &nix_hw->txsch[NIX_TXSCH_LVL_TL2];
+		rsp->schq_nix1[NIX_TXSCH_LVL_TL2] =
+				rvu_rsrc_free_count(&txsch->schq);
+	}
+
+	rsp->schq_nix1[NIX_TXSCH_LVL_TL1] = 1;
+out:
+	rsp->schq[NIX_TXSCH_LVL_TL1] = 1;
+	mutex_unlock(&rvu->rsrc_lock);
+
+	return 0;
+}
+
 int rvu_mbox_handler_free_rsrc_cnt(struct rvu *rvu, struct msg_req *req,
 				   struct free_rsrcs_rsp *rsp)
 {
@@ -237,6 +339,9 @@ int rvu_mbox_handler_free_rsrc_cnt(struct rvu *rvu, struct msg_req *req,
 	struct nix_hw *nix_hw;
 	int pf, curlfs;
 
+	if (!is_rvu_otx2(rvu))
+		return free_rsrc_cnt(rvu, req, rsp);
+
 	mutex_lock(&rvu->rsrc_lock);
 	pf = rvu_get_pf(pcifunc);
 
@@ -354,6 +459,9 @@ int rvu_check_txsch_policy(struct rvu *rvu, struct nix_txsch_alloc_req *req,
 	struct nix_hw *nix_hw;
 	int blkaddr;
 
+	if (!is_rvu_otx2(rvu))
+		return 0;
+
 	blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, pcifunc);
 	if (blkaddr < 0)
 		return blkaddr;
@@ -409,6 +517,9 @@ int rvu_check_rsrc_policy(struct rvu *rvu, struct rsrc_attach *req,
 	int pf = rvu_get_pf(pcifunc);
 	struct rvu_block *block;
 
+	if (!is_rvu_otx2(rvu))
+		return 0;
+
 	/* Only one NPA LF can be attached */
 	if (req->npalf) {
 		block = &hw->block[BLKADDR_NPA];
@@ -740,6 +851,9 @@ void rvu_policy_destroy(struct rvu *rvu)
 	struct rvu_pfvf *pf = NULL;
 	int i;
 
+	if (!is_rvu_otx2(rvu))
+		return;
+
 	quotas_free(rvu->pf_limits.sso);
 	quotas_free(rvu->pf_limits.ssow);
 	quotas_free(rvu->pf_limits.npa);
@@ -780,6 +894,9 @@ int rvu_policy_init(struct rvu *rvu)
 	int err = -EINVAL, i = 0;
 	u32 max = 0;
 
+	if (!is_rvu_otx2(rvu))
+		return 0;
+
 	if (!nix_hw)
 		goto error;
 
-- 
2.31.1

