From 4f0cffd1982a98b2f85658ae8dc8c50e1e907e69 Mon Sep 17 00:00:00 2001
From: Stanislaw Kardach <skardach@marvell.com>
Date: Thu, 13 Jun 2019 13:10:37 +0200
Subject: [PATCH 0205/1921] octeontx2-af: check TXSCHQ policy when needed

Due to hardware limitations, some particular versions of hardware cannot
support single NIX LF to have more than 1 TXSCHQ from each level
assigned. Therefore don't simplify policy checking for those cases
and do not allow user to modify limits for TXSCHQs.

Change-Id: I39ae949ac18c24534d8587346da67957a9f3b209
Signed-off-by: Stanislaw Kardach <skardach@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/10872
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 .../marvell/octeontx2/af/rvu_validation.c     | 77 ++++++++++++-------
 1 file changed, 51 insertions(+), 26 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c b/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
index 646b04dd3adb..4c180a9491f9 100644
--- a/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
+++ b/drivers/net/ethernet/marvell/octeontx2/af/rvu_validation.c
@@ -260,23 +260,34 @@ int rvu_mbox_handler_free_rsrc_cnt(struct rvu *rvu, struct msg_req *req,
 	curlfs = rvu_blk_count_rsrc(block, pcifunc, RVU_PFVF_PF_SHIFT);
 	rsp->cpt = rvu->pf_limits.cpt->a[pf].val - curlfs;
 
-	curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_SMQ, pcifunc,
-				      RVU_PFVF_PF_SHIFT);
-	rsp->schq[NIX_TXSCH_LVL_SMQ] = rvu->pf_limits.smq->a[pf].val - curlfs;
-
-	curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL4, pcifunc,
-				      RVU_PFVF_PF_SHIFT);
-	rsp->schq[NIX_TXSCH_LVL_TL4] = rvu->pf_limits.tl4->a[pf].val - curlfs;
-
-	curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL3, pcifunc,
-				      RVU_PFVF_PF_SHIFT);
-	rsp->schq[NIX_TXSCH_LVL_TL3] = rvu->pf_limits.tl3->a[pf].val - curlfs;
-
-	curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL2, pcifunc,
-				      RVU_PFVF_PF_SHIFT);
-	rsp->schq[NIX_TXSCH_LVL_TL2] = rvu->pf_limits.tl2->a[pf].val - curlfs;
-
-	//Two TL1s available (normal and express DMA)
+	if (rvu->hw->cap.nix_fixed_txschq_mapping) {
+		rsp->schq[NIX_TXSCH_LVL_SMQ] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL4] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL3] = 1;
+		rsp->schq[NIX_TXSCH_LVL_TL2] = 1;
+	} else {
+		curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_SMQ, pcifunc,
+					      RVU_PFVF_PF_SHIFT);
+		rsp->schq[NIX_TXSCH_LVL_SMQ] =
+			rvu->pf_limits.smq->a[pf].val - curlfs;
+
+		curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL4, pcifunc,
+					      RVU_PFVF_PF_SHIFT);
+		rsp->schq[NIX_TXSCH_LVL_TL4] =
+			rvu->pf_limits.tl4->a[pf].val - curlfs;
+
+		curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL3, pcifunc,
+					      RVU_PFVF_PF_SHIFT);
+		rsp->schq[NIX_TXSCH_LVL_TL3] =
+			rvu->pf_limits.tl3->a[pf].val - curlfs;
+
+		curlfs = rvu_txsch_count_rsrc(rvu, NIX_TXSCH_LVL_TL2, pcifunc,
+					      RVU_PFVF_PF_SHIFT);
+		rsp->schq[NIX_TXSCH_LVL_TL2] =
+			rvu->pf_limits.tl2->a[pf].val - curlfs;
+	}
+
+	/* Two TL1s available (normal and express DMA) */
 	rsp->schq[NIX_TXSCH_LVL_TL1] = 2;
 
 	mutex_unlock(&rvu->rsrc_lock);
@@ -466,6 +477,8 @@ static void rvu_set_default_limits(struct rvu *rvu)
 		case PCI_DEVID_OCTEONTX2_RVU_AF:
 			rvu->pf_limits.nix->a[i].val = totalvfs;
 			rvu->pf_limits.npa->a[i].val = totalvfs;
+			if (rvu->hw->cap.nix_fixed_txschq_mapping)
+				break;
 			rvu->pf_limits.smq->a[i].val =
 				nix_hw->txsch[NIX_TXSCH_LVL_SMQ].schq.max /
 				nix_rvus;
@@ -482,6 +495,8 @@ static void rvu_set_default_limits(struct rvu *rvu)
 		case PCI_DEVID_OCTEONTX2_RVU_PF:
 			rvu->pf_limits.nix->a[i].val = 1 + totalvfs;
 			rvu->pf_limits.npa->a[i].val = 1 + totalvfs;
+			if (rvu->hw->cap.nix_fixed_txschq_mapping)
+				break;
 			rvu->pf_limits.smq->a[i].val =
 				nix_hw->txsch[NIX_TXSCH_LVL_SMQ].schq.max /
 				nix_rvus;
@@ -589,6 +604,10 @@ static int rvu_create_limits_sysfs(struct rvu *rvu)
 			break;
 		}
 
+		/* In fixed TXSCHQ case each LF is assigned only 1 queue. */
+		if (rvu->hw->cap.nix_fixed_txschq_mapping)
+			continue;
+
 		if (quota_sysfs_create("smq", pf->limits_kobj, rvu->dev,
 				       &rvu->pf_limits.smq->a[i], pf)) {
 			dev_err(rvu->dev, "Failed to allocate quota for smq on %s\n",
@@ -637,11 +656,6 @@ void rvu_policy_destroy(struct rvu *rvu)
 	quotas_free(rvu->pf_limits.tim);
 	quotas_free(rvu->pf_limits.nix);
 
-	quotas_free(rvu->pf_limits.smq);
-	quotas_free(rvu->pf_limits.tl4);
-	quotas_free(rvu->pf_limits.tl3);
-	quotas_free(rvu->pf_limits.tl2);
-
 	rvu->pf_limits.sso = NULL;
 	rvu->pf_limits.ssow = NULL;
 	rvu->pf_limits.npa = NULL;
@@ -649,10 +663,17 @@ void rvu_policy_destroy(struct rvu *rvu)
 	rvu->pf_limits.tim = NULL;
 	rvu->pf_limits.nix = NULL;
 
-	rvu->pf_limits.smq = NULL;
-	rvu->pf_limits.tl4 = NULL;
-	rvu->pf_limits.tl3 = NULL;
-	rvu->pf_limits.tl2 = NULL;
+	if (rvu->hw->cap.nix_fixed_txschq_mapping) {
+		quotas_free(rvu->pf_limits.smq);
+		quotas_free(rvu->pf_limits.tl4);
+		quotas_free(rvu->pf_limits.tl3);
+		quotas_free(rvu->pf_limits.tl2);
+
+		rvu->pf_limits.smq = NULL;
+		rvu->pf_limits.tl4 = NULL;
+		rvu->pf_limits.tl3 = NULL;
+		rvu->pf_limits.tl2 = NULL;
+	}
 
 	for (i = 0; i < rvu->hw->total_pfs; i++) {
 		pf = &rvu->pf[i];
@@ -725,6 +746,9 @@ int rvu_policy_init(struct rvu *rvu)
 		goto error;
 	}
 
+	if (rvu->hw->cap.nix_fixed_txschq_mapping)
+		goto skip_txschq_limits;
+
 	max = nix_hw->txsch[NIX_TXSCH_LVL_SMQ].schq.max;
 	rvu->pf_limits.smq = quotas_alloc(hw->total_pfs, max, max, 0,
 					     &rvu->rsrc_lock, &pf_limit_ops);
@@ -761,6 +785,7 @@ int rvu_policy_init(struct rvu *rvu)
 		goto error;
 	}
 
+skip_txschq_limits:
 	for (i = 0; i < hw->total_pfs; i++)
 		rvu->pf[i].pdev =
 			pci_get_domain_bus_and_slot(pci_domain_nr(pdev->bus),
-- 
2.31.1

