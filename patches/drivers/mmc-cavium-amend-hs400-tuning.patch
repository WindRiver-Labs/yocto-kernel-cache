From 4810e8658b82d6604f2972af09c852ba98084073 Mon Sep 17 00:00:00 2001
From: Peter Swain <pswain@marvell.com>
Date: Mon, 3 Jun 2019 12:59:38 -0700
Subject: [PATCH 240/767] mmc: cavium: amend hs400 tuning

commit f71a73040c9c582b4e3d87ee543a80a71c64919b from
git@git.assembla.com:cavium/WindRiver.linux.git

cmd_out/data_out taps are fixed, depending on ios.timing
cmd_in/data_in taps are probed, as before

modparam tune=N adjusts tuning to (last_good_tap - N)
Default value of 2 is recommended,
old behavior can be restored with tune=0

Use CMD21 tuning where applicable

Move some _host properties to _slot, because they're actually
related to the current slot. This avoids mis-associating IRQ
events with the wrong conversation.

Optionally walk clock rate down by 12.5% on each tuning failure
Paranoid timing on DMA teardown: watch _DEBUG and DMA_INT[DONE]
to avoid attributing the final teardown event to wrong request

Change-Id: I46499cd96ed5ae41e57b41525eb7f86f986001de
Signed-off-by: Peter Swain <pswain@marvell.com>
Signed-off-by: Sujeet Baranwal <sbaranwal@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/8552
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/mmc/host/cavium-thunderx.c |  18 +++--
 drivers/mmc/host/cavium.c          | 124 +++++++++++++++++++----------
 drivers/mmc/host/cavium.h          |  10 ++-
 3 files changed, 100 insertions(+), 52 deletions(-)

diff --git a/drivers/mmc/host/cavium-thunderx.c b/drivers/mmc/host/cavium-thunderx.c
index 1cd410f82c64..81602975629f 100644
--- a/drivers/mmc/host/cavium-thunderx.c
+++ b/drivers/mmc/host/cavium-thunderx.c
@@ -32,6 +32,8 @@ static void thunder_mmc_int_enable(struct cvm_mmc_host *host, u64 val)
 {
 	writeq(val, host->base + MIO_EMM_INT(host));
 	writeq(val, host->base + MIO_EMM_INT_EN_SET(host));
+	writeq(MIO_EMM_DMA_INT_DMA,
+		host->dma_base + MIO_EMM_DMA_INT(host));
 }
 
 static int thunder_mmc_register_interrupts(struct cvm_mmc_host *host,
@@ -168,11 +170,14 @@ static int thunder_mmc_probe(struct pci_dev *pdev,
 	/*
 	 * Clear out any pending interrupts that may be left over from
 	 * bootloader. Writing 1 to the bits clears them.
+	 * Clear DMA FIFO after IRQ disable, then stub any dangling events
 	 */
-	writeq(0x1ff, host->base + MIO_EMM_INT(host));
-	writeq(0x1ff, host->base + MIO_EMM_DMA_INT_ENA_W1C(host));
-	/* Clear DMA FIFO */
-	writeq(BIT_ULL(16), host->base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(~0, host->base + MIO_EMM_INT(host));
+	writeq(~0, host->dma_base + MIO_EMM_DMA_INT_ENA_W1C(host));
+	writeq(~0, host->base + MIO_EMM_INT_EN_CLR(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(~0, host->dma_base + MIO_EMM_DMA_INT(host));
 
 	ret = thunder_mmc_register_interrupts(host, pdev);
 	if (ret)
@@ -234,8 +239,11 @@ static void thunder_mmc_remove(struct pci_dev *pdev)
 			cvm_mmc_of_slot_remove(host->slot[i]);
 
 	dma_cfg = readq(host->dma_base + MIO_EMM_DMA_CFG(host));
-	dma_cfg &= ~MIO_EMM_DMA_CFG_EN;
+	dma_cfg |= MIO_EMM_DMA_CFG_CLR;
 	writeq(dma_cfg, host->dma_base + MIO_EMM_DMA_CFG(host));
+	do {
+		dma_cfg = readq(host->dma_base + MIO_EMM_DMA_CFG(host));
+	} while (dma_cfg & MIO_EMM_DMA_CFG_EN);
 
 	clk_disable_unprepare(host->clk);
 }
diff --git a/drivers/mmc/host/cavium.c b/drivers/mmc/host/cavium.c
index b159d9736d83..3656c7186082 100644
--- a/drivers/mmc/host/cavium.c
+++ b/drivers/mmc/host/cavium.c
@@ -77,7 +77,7 @@ static struct cvm_mmc_cr_type cvm_mmc_cr_types[] = {
 	{1, 1},		/* CMD18 */
 	{2, 1},		/* CMD19 */
 	{2, 1},		/* CMD20 */
-	{1, 1},		/* CMD21 */
+	{0, 0},		/* CMD21 */
 	{0, 0},		/* CMD22 */
 	{0, 1},		/* CMD23 */
 	{2, 1},		/* CMD24 */
@@ -122,6 +122,10 @@ static struct cvm_mmc_cr_type cvm_mmc_cr_types[] = {
 	{0, 0}		/* CMD63 */
 };
 
+static int tapdance = 2;
+module_param(tapdance, int, 0644);
+MODULE_PARM_DESC(tapdance, "adjust bus-timing: (0=mid-eye, positive=Nth_fastest_tap)");
+
 static bool ddr_cmd_taps;
 module_param(ddr_cmd_taps, bool, 0644);
 MODULE_PARM_DESC(ddr_cmd_taps, "reduce cmd_out_taps in DDR modes, as before");
@@ -308,11 +312,11 @@ static void do_switch(struct cvm_mmc_host *host, u64 emm_switch)
 	 * Modes setting only taken from slot 0. Work around that hardware
 	 * issue by first switching to slot 0.
 	 */
-	bus_id = get_bus_id(emm_switch);
-	clear_bus_id(&emm_switch);
-	writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
-
-	set_bus_id(&emm_switch, bus_id);
+	if (bus_id) {
+		clear_bus_id(&emm_switch);
+		writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
+		set_bus_id(&emm_switch, bus_id);
+	}
 	writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
 
 	/* wait for the switch to finish */
@@ -325,8 +329,9 @@ static void do_switch(struct cvm_mmc_host *host, u64 emm_switch)
 
 	check_switch_errors(host);
 
-	if (slot && (emm_switch & MIO_EMM_SWITCH_CLK)) {
-		slot->cmd6_pending = false;
+	if (slot) {
+		if (emm_switch & MIO_EMM_SWITCH_CLK)
+			slot->cmd6_pending = false;
 		slot->cached_switch = emm_switch;
 	}
 }
@@ -421,10 +426,11 @@ static void cvm_mmc_switch_to(struct cvm_mmc_slot *slot)
 	host->last_slot = slot->bus_id;
 }
 
-static void do_read(struct cvm_mmc_host *host, struct mmc_request *req,
+static void do_read(struct cvm_mmc_slot *slot, struct mmc_request *req,
 		    u64 dbuf)
 {
-	struct sg_mapping_iter *smi = &host->smi;
+	struct cvm_mmc_host *host = slot->host;
+	struct sg_mapping_iter *smi = &slot->smi;
 	int data_len = req->data->blocks * req->data->blksz;
 	int bytes_xfered, shift = -1;
 	u64 dat = 0;
@@ -491,7 +497,7 @@ static void set_cmd_response(struct cvm_mmc_host *host, struct mmc_request *req,
 	}
 }
 
-static int get_dma_dir(struct mmc_data *data)
+static inline int get_dma_dir(struct mmc_data *data)
 {
 	return (data->flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE : DMA_FROM_DEVICE;
 }
@@ -501,8 +507,8 @@ static int finish_dma_single(struct cvm_mmc_host *host, struct mmc_data *data)
 	data->bytes_xfered = data->blocks * data->blksz;
 	data->error = 0;
 
-	/* Clear and disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 1;
 }
@@ -511,6 +517,7 @@ static int finish_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 {
 	u64 fifo_cfg;
 	int count;
+	void __iomem *dma_intp = host->dma_base + MIO_EMM_DMA_INT(host);
 
 	/* Check if there are any pending requests left */
 	fifo_cfg = readq(host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
@@ -521,8 +528,16 @@ static int finish_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 	data->bytes_xfered = data->blocks * data->blksz;
 	data->error = 0;
 
-	/* Clear and disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+
+	/* on read, wait for internal buffer to flush out to mem */
+	if (get_dma_dir(data) == DMA_FROM_DEVICE) {
+		while (!(readq(dma_intp) & MIO_EMM_DMA_INT_DMA))
+			udelay(10);
+		writeq(MIO_EMM_DMA_INT_DMA, dma_intp);
+	}
+
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 1;
 }
@@ -565,8 +580,8 @@ static void cleanup_dma(struct cvm_mmc_host *host, u64 rsp_sts)
 irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 {
 	struct cvm_mmc_host *host = dev_id;
-	struct mmc_request *req;
-	struct cvm_mmc_slot *slot;
+	struct mmc_request *req = NULL;
+	struct cvm_mmc_slot *slot = NULL;
 	unsigned long flags = 0;
 	u64 emm_int, rsp_sts;
 	bool host_done;
@@ -583,6 +598,12 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	if (slot)
 		req = slot->current_req;
 
+	rsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));
+	bus_id = get_bus_id(rsp_sts);
+	slot = host->slot[bus_id];
+	if (slot)
+		req = slot->current_req;
+
 	/* Clear interrupt bits (write 1 clears ). */
 	emm_int = readq(host->base + MIO_EMM_INT(host));
 	writeq(emm_int, host->base + MIO_EMM_INT(host));
@@ -590,7 +611,6 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	if (emm_int & MIO_EMM_INT_SWITCH_ERR)
 		check_switch_errors(host);
 
-	req = host->current_req;
 	if (!req)
 		goto out;
 
@@ -598,7 +618,7 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	 * dma_pend means DMA has stalled with CRC errs.
 	 * start teardown, get irq on completion, mmc stack retries.
 	 */
-	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_PEND) && host->dma_active) {
+	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_PEND) && slot->dma_active) {
 		cleanup_dma(host, rsp_sts);
 		goto out;
 	}
@@ -608,15 +628,15 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	 * the request and wait for the interrupt indicating that
 	 * the DMA is finished.
 	 */
-	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_VAL) && host->dma_active)
+	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_VAL) && slot->dma_active)
 		goto out;
 
-	if (!host->dma_active && req->data &&
+	if (!slot->dma_active && req->data &&
 	    (emm_int & MIO_EMM_INT_BUF_DONE)) {
 		unsigned int type = (rsp_sts >> 7) & 3;
 
 		if (type == 1)
-			do_read(host, req, rsp_sts & MIO_EMM_RSP_STS_DBUF);
+			do_read(slot, req, rsp_sts & MIO_EMM_RSP_STS_DBUF);
 		else if (type == 2)
 			do_write(req);
 	}
@@ -635,7 +655,7 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 
 	req->cmd->error = check_status(rsp_sts);
 
-	if (host->dma_active && req->data)
+	if (slot->dma_active && req->data)
 		if (!finish_dma(host, req->data))
 			goto no_req_done;
 
@@ -655,7 +675,7 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 		}
 	}
 
-	host->current_req = NULL;
+	slot->current_req = NULL;
 	req->done(req);
 
 no_req_done:
@@ -770,8 +790,8 @@ static u64 prepare_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 
 error:
 	WARN_ON_ONCE(1);
-	/* Disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 0;
 }
@@ -856,9 +876,9 @@ static void cvm_mmc_dma_request(struct mmc_host *mmc,
 	}
 
 	mrq->host = mmc;
-	host->dma_active = true;
-	WARN_ON(host->current_req);
-	host->current_req = mrq;
+	WARN_ON(slot->current_req);
+	slot->current_req = mrq;
+	slot->dma_active = true;
 
 	int_enable_mask = MIO_EMM_INT_CMD_ERR | MIO_EMM_INT_DMA_DONE |
 			MIO_EMM_INT_DMA_ERR;
@@ -890,16 +910,17 @@ static void cvm_mmc_dma_request(struct mmc_host *mmc,
 	host->release_bus(host);
 }
 
-static void do_read_request(struct cvm_mmc_host *host, struct mmc_request *mrq)
+static void do_read_request(struct cvm_mmc_slot *slot, struct mmc_request *mrq)
 {
-	sg_miter_start(&host->smi, mrq->data->sg, mrq->data->sg_len,
+	sg_miter_start(&slot->smi, mrq->data->sg, mrq->data->sg_len,
 		       SG_MITER_ATOMIC | SG_MITER_TO_SG);
 }
 
-static void do_write_request(struct cvm_mmc_host *host, struct mmc_request *mrq)
+static void do_write_request(struct cvm_mmc_slot *slot, struct mmc_request *mrq)
 {
+	struct cvm_mmc_host *host = slot->host;
 	unsigned int data_len = mrq->data->blocks * mrq->data->blksz;
-	struct sg_mapping_iter *smi = &host->smi;
+	struct sg_mapping_iter *smi = &slot->smi;
 	unsigned int bytes_xfered;
 	int shift = 56;
 	u64 dat = 0;
@@ -1006,22 +1027,22 @@ static void cvm_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 	mods = cvm_mmc_get_cr_mods(cmd);
 
-	WARN_ON(host->current_req);
+	WARN_ON(slot->current_req);
 	mrq->host = mmc;
-	host->current_req = mrq;
+	slot->current_req = mrq;
 
 	if (cmd->data) {
 		if (cmd->data->flags & MMC_DATA_READ)
-			do_read_request(host, mrq);
+			do_read_request(slot, mrq);
 		else
-			do_write_request(host, mrq);
+			do_write_request(slot, mrq);
 
 		if (cmd->data->timeout_ns)
 			set_wdog(slot, cmd->data->timeout_ns);
 	} else
 		set_wdog(slot, 0);
 
-	host->dma_active = false;
+	slot->dma_active = false;
 	host->int_enable(host, MIO_EMM_INT_CMD_DONE | MIO_EMM_INT_CMD_ERR);
 
 	if (cmd->opcode == MMC_SWITCH)
@@ -1191,6 +1212,7 @@ struct adj {
 static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 {
 	int err, start_run = -1, best_run = 0, best_start = -1;
+	int last_good = -1;
 	bool prev_ok = false;
 	u64 timing, tap;
 	struct cvm_mmc_slot *slot = mmc_priv(mmc);
@@ -1208,6 +1230,8 @@ static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 			err = adj->test(mmc, NULL, opcode);
 
 			how[tap] = "-+"[!err];
+			if (!err)
+				last_good = tap;
 		} else {
 			/*
 			 * putting the end+1 case in loop simplifies
@@ -1236,13 +1260,17 @@ static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 	}
 
 	if (best_start < 0) {
-		dev_warn(host->dev, "%s tuning %s failed\n",
-			mmc_hostname(mmc), adj->name);
+		dev_warn(host->dev, "%s %lldMHz tuning %s failed\n",
+			mmc_hostname(mmc), slot->clock / 1000000, adj->name);
 		return -EINVAL;
 	}
 
 	tap = best_start + best_run / 2;
 	how[tap] = '@';
+	if (tapdance) {
+		tap = last_good - tapdance;
+		how[tap] = 'X';
+	}
 	dev_dbg(host->dev, "%s/%s %d/%lld/%d %s\n",
 		mmc_hostname(mmc), adj->name,
 		best_start, tap, best_start + best_run,
@@ -1360,17 +1388,17 @@ static void cvm_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		break;
 	case MMC_TIMING_MMC_HS:
 	case MMC_TIMING_SD_HS:
-		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS_TIMING, 1);
-		break;
 	case MMC_TIMING_UHS_SDR12:
 	case MMC_TIMING_UHS_SDR25:
 	case MMC_TIMING_UHS_SDR50:
 	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_UHS_DDR50:
+	case MMC_TIMING_MMC_DDR52:
+		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS_TIMING, 1);
+		break;
 	case MMC_TIMING_MMC_HS200:
 		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS200_TIMING, 1);
 		break;
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
 	case MMC_TIMING_MMC_HS400:
 		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS400_TIMING, 1);
 		break;
@@ -1477,6 +1505,13 @@ static int cvm_execute_tuning(struct mmc_host *mmc, u32 opcode)
 	return ret;
 }
 
+static int cvm_prepare_hs400_tuning(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct cvm_mmc_slot *slot = mmc_priv(mmc);
+
+	return cvm_mmc_configure_delay(slot);
+}
+
 static void cvm_mmc_reset(struct mmc_host *mmc)
 {
 	struct cvm_mmc_slot *slot = mmc_priv(mmc);
@@ -1502,6 +1537,7 @@ static const struct mmc_host_ops cvm_mmc_ops = {
 	.get_cd		= mmc_gpio_get_cd,
 	.hw_reset	= cvm_mmc_reset,
 	.execute_tuning = cvm_execute_tuning,
+	.prepare_hs400_tuning = cvm_prepare_hs400_tuning,
 };
 
 static void cvm_mmc_set_clock(struct cvm_mmc_slot *slot, unsigned int clock)
diff --git a/drivers/mmc/host/cavium.h b/drivers/mmc/host/cavium.h
index bfad450432c6..c88e3de97baa 100644
--- a/drivers/mmc/host/cavium.h
+++ b/drivers/mmc/host/cavium.h
@@ -107,9 +107,6 @@ struct cvm_mmc_host {
 	struct clk *clk;
 	int sys_freq;
 
-	struct mmc_request *current_req;
-	struct sg_mapping_iter smi;
-	bool dma_active;
 	bool use_sg;
 
 	bool has_ciu3;
@@ -143,10 +140,14 @@ struct cvm_mmc_slot {
 	struct mmc_request *current_req;
 
 	u64 clock;
+	u32 ecount, gcount;
 
 	u64 cached_switch;
 	u64 cached_rca;
 
+	struct sg_mapping_iter smi;
+	bool dma_active;
+
 	u64 taps;			/* otx2: MIO_EMM_TIMING */
 	unsigned int cmd_cnt;		/* otx: sample cmd in delay */
 	unsigned int data_cnt;		/* otx: sample data in delay */
@@ -237,6 +238,9 @@ struct cvm_mmc_cr_mods {
 #define MIO_EMM_INT_CMD_DONE		BIT_ULL(1)
 #define MIO_EMM_INT_BUF_DONE		BIT_ULL(0)
 
+#define MIO_EMM_DMA_INT_FIFO		BIT_ULL(1)
+#define MIO_EMM_DMA_INT_DMA		BIT_ULL(0)
+
 #define MIO_EMM_RSP_STS_BUS_ID		GENMASK_ULL(61, 60)
 #define MIO_EMM_RSP_STS_CMD_VAL		BIT_ULL(59)
 #define MIO_EMM_RSP_STS_SWITCH_VAL	BIT_ULL(58)
-- 
2.31.1

