From 892d60178eb81ca3651b8cfb1a79f4f72ec00630 Mon Sep 17 00:00:00 2001
From: Geetha sowjanya <gakula@marvell.com>
Date: Thu, 1 Aug 2019 18:18:40 +0530
Subject: [PATCH 293/767] octeontx2-pf: Fix RQ CQ RED and DROP levels for 96xx
 B0

commit 92a411648c892e5b7d152b451d402c4f90a19285 from
git@git.assembla.com:cavium/WindRiver.linux.git

CQ overflow related HW issues got fixed on 96xx B0 silicon.
Hence, setting CQ RED and DROP level to minimal.

Change-Id: I9516a3d641ff18df649251af89a9a66465855457
Signed-off-by: Geetha sowjanya <gakula@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/13438
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Reviewed-on: https://sj1git1.cavium.com/13479
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../marvell/octeontx2/nic/otx2_common.c       | 26 +++++--------------
 .../marvell/octeontx2/nic/otx2_common.h       | 11 ++++++--
 .../ethernet/marvell/octeontx2/nic/otx2_pf.c  |  2 +-
 3 files changed, 16 insertions(+), 23 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
index 754e3e9c95c7..612683f9662e 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c
@@ -543,7 +543,7 @@ int otx2_txschq_stop(struct otx2_nic *pfvf)
 /* RED and drop levels of CQ on packet reception.
  * For CQ level is measure of emptiness ( 0x0 = full, 255 = empty).
  */
-#define RQ_PASS_LVL_CQ(skid, qsize)	((((skid) + 48) * 256) / (qsize))
+#define RQ_PASS_LVL_CQ(skid, qsize)	((((skid) + 16) * 256) / (qsize))
 #define RQ_DROP_LVL_CQ(skid, qsize)	(((skid) * 256) / (qsize))
 
 /* RED and drop levels of AURA for packet reception.
@@ -558,14 +558,10 @@ int otx2_txschq_stop(struct otx2_nic *pfvf)
 /* Send skid of 2000 packets required for CQ size of 4K CQEs. */
 #define SEND_CQ_SKID	2000
 
-/* Receive skid of 600 packets required for CQ size of 1K CQEs. */
-#define RX_CQ_SKID	600
-
 static int otx2_rq_init(struct otx2_nic *pfvf, u16 qidx, u16 lpb_aura)
 {
 	struct otx2_qset *qset = &pfvf->qset;
 	struct nix_aq_enq_req *aq;
-	int skid = 0;
 
 	/* Get memory to put this msg */
 	aq = otx2_mbox_alloc_msg_nix_aq_enq(&pfvf->mbox);
@@ -582,16 +578,8 @@ static int otx2_rq_init(struct otx2_nic *pfvf, u16 qidx, u16 lpb_aura)
 	aq->rq.qint_idx = 0;
 	aq->rq.lpb_drop_ena = 1; /* Enable RED dropping for AURA */
 	aq->rq.xqe_drop_ena = 1; /* Enable RED dropping for CQ/SSO */
-	/* Due to HW errata #34873 minimum 600 unused CQE need to maintaine to
-	 * avoid CQ overflow. Eg: For CQ size 1K, for pass/drop levels 162/150.
-	 * HW accepts accepts the pkts if unused CQE >= 648.
-	 * RED accepts pkts if unused CQE > 600 & <= 648.
-	 * Drops pkts if unused CQE <= 600.
-	 */
-	if (is_96xx_A0(pfvf->pdev) || is_95xx_A0(pfvf->pdev))
-		skid = RX_CQ_SKID;
-	aq->rq.xqe_pass = RQ_PASS_LVL_CQ(skid, qset->rqe_cnt);
-	aq->rq.xqe_drop = RQ_DROP_LVL_CQ(skid, qset->rqe_cnt);
+	aq->rq.xqe_pass = RQ_PASS_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
+	aq->rq.xqe_drop = RQ_DROP_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
 	aq->rq.lpb_aura_pass = RQ_PASS_LVL_AURA;
 	aq->rq.lpb_aura_drop = RQ_DROP_LVL_AURA;
 
@@ -683,9 +671,9 @@ static int otx2_sq_init(struct otx2_nic *pfvf, u16 qidx, u16 sqb_aura)
 static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 {
 	struct otx2_qset *qset = &pfvf->qset;
-	int err, pool_id, skid = 0;
 	struct nix_aq_enq_req *aq;
 	struct otx2_cq_queue *cq;
+	int err, pool_id;
 
 	cq = &qset->cq[qidx];
 	cq->cqe_cnt = (qidx < pfvf->hw.rx_queues) ? qset->rqe_cnt
@@ -726,9 +714,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 	aq->cq.avg_level = 255;
 
 	if (qidx < pfvf->hw.rx_queues) {
-		if (is_96xx_A0(pfvf->pdev) || is_95xx_A0(pfvf->pdev))
-			skid = RX_CQ_SKID;
-		aq->cq.drop = RQ_DROP_LVL_CQ(skid, cq->cqe_cnt);
+		aq->cq.drop = RQ_DROP_LVL_CQ(pfvf->rq_skid, cq->cqe_cnt);
 		aq->cq.drop_ena = 1;
 
 		/* Enable receive CQ backpressure */
@@ -736,7 +722,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 		aq->cq.bpid = pfvf->bpid[0];
 
 		/* Set backpressure level is same as cq pass level */
-		aq->cq.bp = RQ_PASS_LVL_CQ(skid, qset->rqe_cnt);
+		aq->cq.bp = RQ_PASS_LVL_CQ(pfvf->rq_skid, qset->rqe_cnt);
 	}
 
 	/* Fill AQ info */
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
index b99555d4dac5..f4a188d34f08 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
@@ -233,7 +233,8 @@ struct otx2_nic {
 	u16			tx_chan_base;
 	u8			cq_time_wait;
 	u16			cq_qcount_wait;
-	u32			cq_ecount_wait;
+	u16			cq_ecount_wait;
+	u16			rq_skid;
 	u32			msg_enable;
 	struct work_struct	reset_task;
 	u64			reset_count;
@@ -283,8 +284,14 @@ static inline void otx2_setup_dev_hw_settings(struct otx2_nic *pfvf)
 
 	hw->hw_tso = true;
 
-	if (is_96xx_A0(pfvf->pdev) || is_95xx_A0(pfvf->pdev))
+	if (is_96xx_A0(pfvf->pdev) || is_95xx_A0(pfvf->pdev)) {
 		hw->hw_tso = false;
+	/* Due to HW issue previous silicons required minimum 600
+	 * unused CQE to avoid CQ overflow.
+	 */
+		pfvf->rq_skid = 600;
+		pfvf->qset.rqe_cnt = Q_COUNT(Q_SIZE_1K);
+	}
 	if (is_96xx_A0(pfvf->pdev))
 		pfvf->cq_qcount_wait = 0x0;
 }
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
index ac0f2e77d806..7f354f8716a9 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
@@ -1471,7 +1471,7 @@ int otx2_open(struct net_device *netdev)
 		return -ENOMEM;
 
 	/* CQ size of RQ */
-	qset->rqe_cnt = qset->rqe_cnt ? qset->rqe_cnt : Q_COUNT(Q_SIZE_1K);
+	qset->rqe_cnt = qset->rqe_cnt ? qset->rqe_cnt : Q_COUNT(Q_SIZE_256);
 	/* CQ size of SQ */
 	qset->sqe_cnt = qset->sqe_cnt ? qset->sqe_cnt : Q_COUNT(Q_SIZE_4K);
 
-- 
2.31.1

