From 49e1cd1d18a01c0b67e5f17bfa464fb353e8531a Mon Sep 17 00:00:00 2001
From: Sunil Goutham <sgoutham@marvell.com>
Date: Thu, 24 Oct 2019 11:06:40 +0530
Subject: [PATCH 0312/1921] octeontx2-pf: Fix CQE cleanup done while teardown

Current cleanup is done using napi structs which when used
in non-napi context leads to issues. This patch fixes this
issue.

Change-Id: I3b13e5c4ec54e4a6a4f902e28170367f88a9ef67
Signed-off-by: Sunil Goutham <sgoutham@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/17955
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
Tested-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
[WK: The original patch got from Marvell sdk11.21.09]
Signed-off-by: Wenlin Kang <wenlin.kang@windriver.com>
---
 .../marvell/octeontx2/nic/otx2_common.h       |  7 +-
 .../ethernet/marvell/octeontx2/nic/otx2_pf.c  | 15 +---
 .../marvell/octeontx2/nic/otx2_txrx.c         | 88 +++++++++++++++++--
 3 files changed, 89 insertions(+), 21 deletions(-)

diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
index d0d75bebae18..821039428c7f 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h
@@ -619,11 +619,8 @@ dma_addr_t otx2_alloc_rbuf(struct otx2_nic *pfvf, struct otx2_pool *pool,
 int otx2_rxtx_enable(struct otx2_nic *pfvf, bool enable);
 void otx2_ctx_disable(struct mbox *mbox, int type, bool npa);
 int otx2_nix_config_bp(struct otx2_nic *pfvf, bool enable);
-
-int otx2_rx_napi_handler(struct otx2_nic *pfvf, struct napi_struct *napi,
-			 struct otx2_cq_queue *cq, int budget);
-int otx2_tx_napi_handler(struct otx2_nic *pfvf,
-			 struct otx2_cq_queue *cq, int budget);
+void otx2_cleanup_rx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq);
+void otx2_cleanup_tx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq);
 
 /* RSS configuration APIs*/
 int otx2_rss_init(struct otx2_nic *pfvf);
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
index 0177ba1aac61..2cf58dd54cd0 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c
@@ -1412,11 +1412,9 @@ static void otx2_free_hw_resources(struct otx2_nic *pf)
 	struct otx2_qset *qset = &pf->qset;
 	struct nix_lf_free_req *free_req;
 	struct mbox *mbox = &pf->mbox;
-	struct napi_struct *napi;
 	struct otx2_cq_queue *cq;
 	struct msg_req *req;
 	int qidx, err;
-	u64 cqe_count;
 
 	/* Stop transmission */
 	err = otx2_txschq_stop(pf);
@@ -1437,15 +1435,10 @@ static void otx2_free_hw_resources(struct otx2_nic *pf)
 	/*Dequeue all CQEs */
 	for (qidx = 0; qidx < qset->cq_cnt; qidx++) {
 		cq = &qset->cq[qidx];
-		cqe_count = otx2_read64(pf, NIX_LF_CINTX_CNT(cq->cint_idx));
-		cqe_count &= 0xFFFFFFFF;
-		napi = &qset->napi[cq->cint_idx].napi;
-		if (cqe_count) {
-			if (cq->cq_type == CQ_RX)
-				otx2_rx_napi_handler(pf, napi, cq, cqe_count);
-			else
-				otx2_tx_napi_handler(pf, cq, cqe_count);
-		}
+		if (cq->cq_type == CQ_RX)
+			otx2_cleanup_rx_cqes(pf, cq);
+		else
+			otx2_cleanup_tx_cqes(pf, cq);
 	}
 
 	/* Free RQ buffer pointers*/
diff --git a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
index 3a5a879df5de..6cd96052e7c0 100644
--- a/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
+++ b/drivers/net/ethernet/marvell/octeontx2/nic/otx2_txrx.c
@@ -382,9 +382,9 @@ static void otx2_rcv_pkt_handler(struct otx2_nic *pfvf,
 	napi_gro_receive(napi, skb);
 }
 
-int otx2_rx_napi_handler(struct otx2_nic *pfvf,
-			 struct napi_struct *napi,
-			 struct otx2_cq_queue *cq, int budget)
+static inline int otx2_rx_napi_handler(struct otx2_nic *pfvf,
+				       struct napi_struct *napi,
+				       struct otx2_cq_queue *cq, int budget)
 {
 	struct otx2_pool *rbpool = cq->rbpool;
 	struct nix_cqe_hdr_s *cqe_hdr;
@@ -438,8 +438,8 @@ int otx2_rx_napi_handler(struct otx2_nic *pfvf,
 	return processed_cqe;
 }
 
-int otx2_tx_napi_handler(struct otx2_nic *pfvf,
-			 struct otx2_cq_queue *cq, int budget)
+static inline int otx2_tx_napi_handler(struct otx2_nic *pfvf,
+				       struct otx2_cq_queue *cq, int budget)
 {
 	struct nix_cqe_hdr_s *cqe_hdr;
 	int tx_pkts = 0, tx_bytes = 0;
@@ -981,6 +981,84 @@ bool otx2_sq_append_skb(struct net_device *netdev, struct otx2_snd_queue *sq,
 }
 EXPORT_SYMBOL(otx2_sq_append_skb);
 
+void otx2_cleanup_rx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq)
+{
+	struct nix_cqe_hdr_s *cqe_hdr;
+	struct nix_rx_parse_s *parse;
+	struct nix_rx_sg_s *sg;
+	int processed_cqe = 0;
+	void *start, *end;
+	u64 *iova, pa;
+	int seg;
+
+	/* Make sure HW writes to CQ are done */
+	dma_rmb();
+	while ((cqe_hdr = otx2_get_next_cqe(cq))) {
+		parse = (struct nix_rx_parse_s *)
+				((void *)cqe_hdr + sizeof(*cqe_hdr));
+		start = (void *)parse + sizeof(*parse);
+		end = start + ((parse->desc_sizem1 + 1) * 16);
+		while ((start + sizeof(*sg)) < end) {
+			sg = (struct nix_rx_sg_s *)start;
+			iova = (void *)sg + sizeof(*sg);
+			for (seg = 0; seg < sg->segs; seg++) {
+				/* Free IOVA */
+				*iova -= OTX2_HEAD_ROOM;
+				pa = otx2_iova_to_phys(pfvf->iommu_domain,
+						       *iova);
+				dma_unmap_page_attrs(pfvf->dev, *iova,
+						     RCV_FRAG_LEN,
+						     DMA_FROM_DEVICE,
+						     DMA_ATTR_SKIP_CPU_SYNC);
+				put_page(virt_to_page(phys_to_virt(pa)));
+				iova++;
+			}
+			start += sizeof(*sg);
+			start += (sg->segs == 1) ?
+				  sizeof(u64) : 3 * sizeof(u64);
+		}
+		cqe_hdr->cqe_type = NIX_XQE_TYPE_INVALID;
+		processed_cqe++;
+	}
+
+	/* Free CQEs to HW */
+	otx2_write64(pfvf, NIX_LF_CQ_OP_DOOR,
+		     ((u64)cq->cq_idx << 32) | processed_cqe);
+}
+
+void otx2_cleanup_tx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq)
+{
+	struct nix_send_comp_s *snd_comp;
+	struct nix_cqe_hdr_s *cqe_hdr;
+	struct sk_buff *skb = NULL;
+	struct otx2_snd_queue *sq;
+	int processed_cqe = 0;
+	struct sg_list *sg;
+
+	sq = &pfvf->qset.sq[cq->cint_idx];
+
+	/* Make sure HW writes to CQ are done */
+	dma_rmb();
+	while ((cqe_hdr = otx2_get_next_cqe(cq))) {
+		snd_comp = (struct nix_send_comp_s *)
+				((void *)cqe_hdr + sizeof(*cqe_hdr));
+		sg = &sq->sg[snd_comp->sqe_id];
+		skb = (struct sk_buff *)sg->skb;
+		if (skb) {
+			otx2_dma_unmap_skb_frags(pfvf, sg);
+			dev_kfree_skb_any(skb);
+			sg->skb = (u64)NULL;
+		}
+
+		cqe_hdr->cqe_type = NIX_XQE_TYPE_INVALID;
+		processed_cqe++;
+	}
+
+	/* Free CQEs to HW */
+	otx2_write64(pfvf, NIX_LF_CQ_OP_DOOR,
+		     ((u64)cq->cq_idx << 32) | processed_cqe);
+}
+
 int otx2_rxtx_enable(struct otx2_nic *pfvf, bool enable)
 {
 	struct msg_req *msg;
-- 
2.31.1

