From 0ffe1e50ff8d2294d056dea027b48f1906f2b1c3 Mon Sep 17 00:00:00 2001
From: Ernest Villion <ernestv@marvell.com>
Date: Mon, 28 Mar 2016 19:17:28 +0300
Subject: [PATCH 0223/1345] pp3: cloning pp3 driver and porting to linux 4.4.8

commit  82ce6f43c7dde13b5134bf1999301d442c7060da from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

        - pp3 driver place: "drivers/net/ethernet/marvell"
	- update Makefile and Kconfig under drivers/net/ethernet/marvell
	- clone commit: ff0ea7a00b7d7b82c8f0ac65fa60205b62b98cf9

Change-Id: I8f4ea0c127c28e8a732a26995d01264be2f41a51
Signed-off-by: Ernest Villion <ernestv@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/29601
Reviewed-by: Lior Amsalem <alior@marvell.com>
Tested-by: Lior Amsalem <alior@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/net/ethernet/marvell/Kconfig               |    2 +
 drivers/net/ethernet/marvell/Makefile              |    2 +
 drivers/net/ethernet/marvell/pp3/Kconfig           |  232 +
 drivers/net/ethernet/marvell/pp3/Makefile          |   62 +
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c        | 1424 ++++++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h        |  293 ++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_mem.h    |  137 +
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h   |  267 ++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c  |  183 +
 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.c    | 4248 +++++++++++++++++
 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.h    |   47 +
 .../net/ethernet/marvell/pp3/cmac/mv_cmac_regs.h   |  114 +
 .../net/ethernet/marvell/pp3/cmac/mv_cmac_sysfs.c  |  135 +
 .../net/ethernet/marvell/pp3/cmac/mv_eip197_regs.h | 4960 ++++++++++++++++++++
 .../net/ethernet/marvell/pp3/common/mv_common.c    |  332 ++
 drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h |  117 +
 drivers/net/ethernet/marvell/pp3/common/mv_stack.c |   80 +
 drivers/net/ethernet/marvell/pp3/common/mv_stack.h |  128 +
 drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h |  453 ++
 drivers/net/ethernet/marvell/pp3/emac/mv_emac.c    |  479 ++
 drivers/net/ethernet/marvell/pp3/emac/mv_emac.h    |  109 +
 .../net/ethernet/marvell/pp3/emac/mv_emac_regs.h   |  244 +
 .../net/ethernet/marvell/pp3/emac/mv_emac_sysfs.c  |  169 +
 drivers/net/ethernet/marvell/pp3/fw/mv_fw.c        |  793 ++++
 drivers/net/ethernet/marvell/pp3/fw/mv_fw.h        |  112 +
 drivers/net/ethernet/marvell/pp3/fw/mv_fw_regs.h   |   71 +
 drivers/net/ethernet/marvell/pp3/fw/mv_fw_shared.h |  153 +
 drivers/net/ethernet/marvell/pp3/fw/mv_fw_sysfs.c  |  406 ++
 .../net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.c    |  850 ++++
 .../net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.h    |   71 +
 .../marvell/pp3/fw/mv_pp3_fw_msg_structs.h         |  299 ++
 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.c    |  800 ++++
 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.h    |  148 +
 .../net/ethernet/marvell/pp3/gmac/mv_gmac_regs.h   |  296 ++
 .../net/ethernet/marvell/pp3/gmac/mv_gmac_sysfs.c  |  138 +
 .../net/ethernet/marvell/pp3/gnss/mv_pp3_gnss.h    |   52 +
 .../ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.c    |  842 ++++
 .../ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.h    |   96 +
 .../marvell/pp3/gnss/mv_pp3_gnss_stats_api.c       |  712 +++
 drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.c  |  149 +
 drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.h  |   22 +
 .../net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.c  |  707 +++
 .../net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.h  |   72 +
 .../ethernet/marvell/pp3/gop/mac/mv_gmac_regs.h    |  780 +++
 .../ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.c   |  432 ++
 .../ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.h   |   69 +
 .../ethernet/marvell/pp3/gop/mac/mv_xlg_mac_regs.h |  580 +++
 drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.c   |  703 +++
 drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.h   |  106 +
 .../net/ethernet/marvell/pp3/gop/mv_gop_sysfs.c    |  402 ++
 .../net/ethernet/marvell/pp3/gop/mv_mib_cntrs.c    |  213 +
 drivers/net/ethernet/marvell/pp3/gop/mv_mib_regs.h |   71 +
 drivers/net/ethernet/marvell/pp3/gop/mv_nss_regs.h |  549 +++
 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.c   |  362 ++
 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.h   |   58 +
 .../net/ethernet/marvell/pp3/gop/mv_ptp_if_serv.c  |  417 ++
 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_regs.h |  330 ++
 drivers/net/ethernet/marvell/pp3/gop/mv_smi.c      |   56 +
 drivers/net/ethernet/marvell/pp3/gop/mv_smi.h      |   36 +
 drivers/net/ethernet/marvell/pp3/gop/mv_smi_regs.h |  154 +
 .../net/ethernet/marvell/pp3/gop/mv_tai_clock.c    |  558 +++
 drivers/net/ethernet/marvell/pp3/gop/mv_tai_regs.h |  593 +++
 .../net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.c  |   98 +
 .../net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.h  |   38 +
 .../net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.c  |  118 +
 .../net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.h  |   44 +
 .../ethernet/marvell/pp3/gop/pcs/mv_xpcs_regs.h    |  368 ++
 .../ethernet/marvell/pp3/gop/serdes/mv_serdes_if.c |   90 +
 .../ethernet/marvell/pp3/gop/serdes/mv_serdes_if.h |   43 +
 .../marvell/pp3/gop/serdes/mv_serdes_regs.h        |   69 +
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c    |  919 ++++
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h    |  529 +++
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h |  151 +
 .../net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h   |  313 ++
 .../net/ethernet/marvell/pp3/hmac/mv_hmac_sysfs.c  |  219 +
 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg.h  |   96 +
 .../net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.c |  698 +++
 .../net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.h |  116 +
 .../net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.c  |  262 ++
 .../net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.h  |   88 +
 .../ethernet/marvell/pp3/msg/mv_pp3_msg_sysfs.c    |  141 +
 .../marvell/pp3/net_dev/mv_dev_bpi_sysfs.c         |  160 +
 .../net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.c  | 1504 ++++++
 .../net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.h  |   65 +
 .../marvell/pp3/net_dev/mv_dev_debug_sysfs.c       |  257 +
 .../marvell/pp3/net_dev/mv_dev_init_sysfs.c        |  171 +
 .../ethernet/marvell/pp3/net_dev/mv_dev_sysfs.c    |  254 +
 .../ethernet/marvell/pp3/net_dev/mv_dev_sysfs.h    |   56 +
 .../net/ethernet/marvell/pp3/net_dev/mv_dev_vq.c   |  963 ++++
 .../net/ethernet/marvell/pp3/net_dev/mv_dev_vq.h   |   86 +
 .../ethernet/marvell/pp3/net_dev/mv_dev_vq_sysfs.c |  250 +
 .../net/ethernet/marvell/pp3/net_dev/mv_ethtool.c  |  355 ++
 .../net/ethernet/marvell/pp3/net_dev/mv_ethtool.h  |   35 +
 .../ethernet/marvell/pp3/net_dev/mv_gnss_wrap.h    |   87 +
 .../net/ethernet/marvell/pp3/net_dev/mv_netdev.c   | 3322 +++++++++++++
 .../net/ethernet/marvell/pp3/net_dev/mv_netdev.h   |  260 +
 .../marvell/pp3/net_dev/mv_netdev_structs.h        |  126 +
 .../net/ethernet/marvell/pp3/net_dev/mv_ptp_hook.c |  599 +++
 .../ethernet/marvell/pp3/net_dev/mv_ptp_hook_dbg.h |  339 ++
 .../ethernet/marvell/pp3/net_dev/mv_ptp_service.h  |   36 +
 .../net/ethernet/marvell/pp3/net_dev/mv_ptp_uio.c  |  195 +
 .../marvell/pp3/platform/a390_gic_odmi_if.h        |   55 +
 drivers/net/ethernet/marvell/pp3/platform/mv_a2m.h |   63 +
 drivers/net/ethernet/marvell/pp3/platform/mv_pp3.c | 1036 ++++
 drivers/net/ethernet/marvell/pp3/platform/mv_pp3.h |  218 +
 .../net/ethernet/marvell/pp3/platform/mv_pp3_cfh.h |  329 ++
 .../ethernet/marvell/pp3/platform/mv_pp3_config.c  |  870 ++++
 .../ethernet/marvell/pp3/platform/mv_pp3_config.h  |  233 +
 .../marvell/pp3/platform/mv_pp3_debug_sysfs.c      |  270 ++
 .../ethernet/marvell/pp3/platform/mv_pp3_defs.h    |  119 +
 .../marvell/pp3/platform/mv_pp3_fw_opcodes.h       |   64 +
 .../marvell/pp3/platform/mv_pp3_init_sysfs.c       |  126 +
 .../ethernet/marvell/pp3/platform/mv_pp3_version.c |   37 +
 drivers/net/ethernet/marvell/pp3/qm/mv_qm.c        | 1622 +++++++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm.h        |  363 ++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c   |  412 ++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h   |  958 ++++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm_sysfs.c  |  208 +
 .../pp3/tm/core/resource_management/rm_alloc.c     |  804 ++++
 .../pp3/tm/core/resource_management/rm_alloc.h     |  288 ++
 .../pp3/tm/core/resource_management/rm_chunk.c     |  175 +
 .../pp3/tm/core/resource_management/rm_chunk.h     |  100 +
 .../pp3/tm/core/resource_management/rm_ctl.c       |  423 ++
 .../pp3/tm/core/resource_management/rm_ctl.h       |   68 +
 .../pp3/tm/core/resource_management/rm_free.c      |  753 +++
 .../pp3/tm/core/resource_management/rm_free.h      |  304 ++
 .../pp3/tm/core/resource_management/rm_interface.h |   70 +
 .../core/resource_management/rm_internal_types.h   |  184 +
 .../pp3/tm/core/resource_management/rm_list.c      |  179 +
 .../pp3/tm/core/resource_management/rm_list.h      |  139 +
 .../pp3/tm/core/resource_management/rm_reorder.c   |  335 ++
 .../pp3/tm/core/resource_management/rm_reorder.h   |   85 +
 .../pp3/tm/core/resource_management/rm_status.c    |  316 ++
 .../pp3/tm/core/resource_management/rm_status.h    |  258 +
 .../marvell/pp3/tm/core/set_hw_registers.c         | 4905 +++++++++++++++++++
 .../marvell/pp3/tm/core/set_hw_registers.h         |  267 ++
 .../ethernet/marvell/pp3/tm/core/tm_core_types.h   |  532 +++
 drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.c  |  605 +++
 drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.h  |   94 +
 drivers/net/ethernet/marvell/pp3/tm/core/tm_defs.h |  461 ++
 drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.c | 2901 ++++++++++++
 drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.h |  398 ++
 .../marvell/pp3/tm/core/tm_elig_prio_func.c        |  569 +++
 .../marvell/pp3/tm/core/tm_elig_prio_func.h        |  163 +
 .../net/ethernet/marvell/pp3/tm/core/tm_errcodes.h |  166 +
 .../net/ethernet/marvell/pp3/tm/core/tm_errors.c   |   61 +
 .../net/ethernet/marvell/pp3/tm/core/tm_errors.h   |   62 +
 .../pp3/tm/core/tm_get_gen_param_interface.h       |   41 +
 .../pp3/tm/core/tm_hw_configuration_interface.h    |   65 +
 .../marvell/pp3/tm/core/tm_locking_interface.h     |   77 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_create.c | 2255 +++++++++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_create.h |  625 +++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_ctl.c    |  466 ++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_ctl.h    |  108 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_read.c   |  535 +++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_read.h   |  228 +
 .../marvell/pp3/tm/core/tm_nodes_reorder.c         |  661 +++
 .../marvell/pp3/tm/core/tm_nodes_reorder.h         |   82 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_status.c |  296 ++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_status.h |  148 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_tree.c   |  104 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_tree.h   |   69 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_update.c | 1002 ++++
 .../ethernet/marvell/pp3/tm/core/tm_nodes_update.h |  251 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_utils.c  |   88 +
 .../ethernet/marvell/pp3/tm/core/tm_nodes_utils.h  |   57 +
 .../ethernet/marvell/pp3/tm/core/tm_os_interface.h |   44 +
 .../marvell/pp3/tm/core/tm_registers_processing.c  |   54 +
 .../marvell/pp3/tm/core/tm_registers_processing.h  |  144 +
 .../pp3/tm/core/tm_rw_registers_interface.h        |   46 +
 .../net/ethernet/marvell/pp3/tm/core/tm_sched.c    |  218 +
 .../net/ethernet/marvell/pp3/tm/core/tm_sched.h    |  121 +
 .../marvell/pp3/tm/core/tm_set_local_db_defaults.c | 2113 +++++++++
 .../marvell/pp3/tm/core/tm_set_local_db_defaults.h |   67 +
 .../net/ethernet/marvell/pp3/tm/core/tm_shaping.c  |  366 ++
 .../net/ethernet/marvell/pp3/tm/core/tm_shaping.h  |  168 +
 drivers/net/ethernet/marvell/pp3/tm/mv_tm.c        | 1407 ++++++
 drivers/net/ethernet/marvell/pp3/tm/mv_tm.h        |  170 +
 drivers/net/ethernet/marvell/pp3/tm/platform/TM.h  |   35 +
 .../ethernet/marvell/pp3/tm/platform/tm_alias.c    |  707 +++
 .../ethernet/marvell/pp3/tm/platform/tm_alias.h    |  294 ++
 .../tm/platform/tm_get_gen_param_implementation.c  |   51 +
 .../ethernet/marvell/pp3/tm/platform/tm_hw_conf.c  |  152 +
 .../marvell/pp3/tm/platform/tm_locking_imp.c       |   91 +
 .../ethernet/marvell/pp3/tm/platform/tm_os_if.c    |   68 +
 .../ethernet/marvell/pp3/tm/platform/tm_payloads.h | 2667 +++++++++++
 .../tm_platform_implementation_definitions.h       |   91 +
 .../tm/platform/tm_rw_registers_implementation.c   |  722 +++
 .../ethernet/marvell/pp3/tm/platform/tm_sysfs.c    | 1146 +++++
 .../marvell/pp3/tm/platform/tm_sysfs_debug.c       |  471 ++
 .../marvell/pp3/tm/platform/tm_sysfs_debug.h       |   54 +
 .../marvell/pp3/tm/platform/tm_sysfs_drop.c        |  564 +++
 .../marvell/pp3/tm/platform/tm_sysfs_drop.h        |   55 +
 .../marvell/pp3/tm/platform/tm_sysfs_shaping.c     |   98 +
 .../marvell/pp3/tm/platform/tm_sysfs_shaping.h     |   37 +
 .../marvell/pp3/tm/platform/tm_to_qmtm_enums.c     |  169 +
 .../marvell/pp3/tm/platform/tm_to_qmtm_enums.h     |   39 +
 .../ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.c  |  621 +++
 .../ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.h  |   95 +
 .../ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.c |  243 +
 .../ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.h |   62 +
 .../marvell/pp3/tm/wrappers/mv_tm_scheme.c         |  443 ++
 .../marvell/pp3/tm/wrappers/mv_tm_scheme.h         |   93 +
 .../marvell/pp3/tm/wrappers/mv_tm_shaping.c        |  152 +
 .../marvell/pp3/tm/wrappers/mv_tm_shaping.h        |   82 +
 .../net/ethernet/marvell/pp3/vport/mv_pp3_cpu.c    |  280 ++
 .../net/ethernet/marvell/pp3/vport/mv_pp3_cpu.h    |   90 +
 .../net/ethernet/marvell/pp3/vport/mv_pp3_pool.c   |  527 +++
 .../net/ethernet/marvell/pp3/vport/mv_pp3_pool.h   |  111 +
 .../net/ethernet/marvell/pp3/vport/mv_pp3_swq.c    |  335 ++
 .../net/ethernet/marvell/pp3/vport/mv_pp3_swq.h    |   91 +
 .../net/ethernet/marvell/pp3/vport/mv_pp3_vport.c  |  797 ++++
 .../net/ethernet/marvell/pp3/vport/mv_pp3_vport.h  |  171 +
 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.c |  865 ++++
 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.h |  123 +
 .../ethernet/marvell/pp3/vport/mv_vport_sysfs.c    |  154 +
 216 files changed, 88565 insertions(+)
 create mode 100644 drivers/net/ethernet/marvell/pp3/Kconfig
 create mode 100644 drivers/net/ethernet/marvell/pp3/Makefile
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_mem.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/cmac/mv_eip197_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/common/mv_common.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/common/mv_stack.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/common/mv_stack.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/emac/mv_emac.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/emac/mv_emac.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/emac/mv_emac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/emac/mv_emac_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_fw.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_fw.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_fw_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_fw_shared.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_fw_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg_structs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_stats_api.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_gop_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_mib_cntrs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_mib_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_nss_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if_serv.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_ptp_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_smi.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_smi.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_smi_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_tai_clock.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/mv_tai_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_bpi_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_debug_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_init_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_gnss_wrap.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev_structs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook_dbg.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_service.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_uio.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/a390_gic_odmi_if.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_a2m.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_cfh.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_debug_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_defs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_fw_opcodes.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_init_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/platform/mv_pp3_version.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_internal_types.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_core_types.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_defs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_errcodes.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_get_gen_param_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_hw_configuration_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_locking_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_os_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_rw_registers_interface.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/mv_tm.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/mv_tm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/TM.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_get_gen_param_implementation.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_hw_conf.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_locking_imp.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_os_if.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_payloads.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_platform_implementation_definitions.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_rw_registers_implementation.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/vport/mv_vport_sysfs.c

diff --git a/drivers/net/ethernet/marvell/Kconfig b/drivers/net/ethernet/marvell/Kconfig
index aaafe2b..09beb4e 100644
--- a/drivers/net/ethernet/marvell/Kconfig
+++ b/drivers/net/ethernet/marvell/Kconfig
@@ -196,4 +196,6 @@ config MVNET_COMPLEX
 	Use Marvell propriotary netcomplex driver for A390.
 	The driver located uner directory mvebu_net/a390_nc.
 
+source "drivers/net/ethernet/marvell/pp3/Kconfig"
+
 endif # NET_VENDOR_MARVELL
diff --git a/drivers/net/ethernet/marvell/Makefile b/drivers/net/ethernet/marvell/Makefile
index a55a46d..51b2632 100644
--- a/drivers/net/ethernet/marvell/Makefile
+++ b/drivers/net/ethernet/marvell/Makefile
@@ -13,3 +13,5 @@ obj-$(CONFIG_SKGE) += skge.o
 obj-$(CONFIG_SKY2) += sky2.o
 obj-$(CONFIG_MVPP2X) += mvpp2x/
 obj-$(CONFIG_MVNET_COMPLEX) += net_complex/mv_net_complex_a39x.o
+obj-$(CONFIG_MVPP3) += pp3/
+
diff --git a/drivers/net/ethernet/marvell/pp3/Kconfig b/drivers/net/ethernet/marvell/pp3/Kconfig
new file mode 100644
index 0000000..a9d96b7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/Kconfig
@@ -0,0 +1,232 @@
+config MVPP3
+	tristate "Marvell Armada 390 network interface support"
+	depends on MACH_ARMADA_38X
+	select MVMDIO
+	select MV_GNSS_SUPPORT
+	select MVEBU_ODMI
+	---help---
+		Add support for PP3 driver.
+		This driver supports the network
+		interface units in the Marvell
+		ARMADA 39x SoC.
+
+config MV_GNSS_SUPPORT
+	bool "Generic NSS network interfaces support"
+	depends on MVPP3
+	default n
+	---help---
+	When defined add support for generic
+	NSS capabilities.
+	When not defined only standard network
+	inferfaces are supported.
+
+config MV_PP3_TM_SUPPORT
+	bool "Traffic Management (TM) configuration support"
+	depends on MVPP3
+	default y
+	---help---
+	When defined add support for run-time configuration of Traffic Management
+	hardware capabilities.
+	When not defined hardware default values will be used.
+	If unsure, say N.
+
+menu "BM configuration"
+	depends on MVPP3
+
+config MV_PP3_BM_LINUX_POOL_CAPACITY
+	int "capacity of Linux (TxDone) BM pool"
+	default 16384
+	---help---
+	Number of buffers can be returned to pool after transmit.
+	BM Linux pools are created for each CPU for all interfaces.
+	All BM Linux pools are empty after initialization.
+	Hardware will push buffers to these pools when transmit is completed.
+	Software will pop buffers from these pools and return these buffers to Linux.
+
+config MV_PP3_BM_RX_POOL_CAPACITY
+	int "capacity of Receive BM pools"
+	default 32768
+	---help---
+	Maximal number of buffers can pushed to BM long or short pool.
+	Buffers are allocated for BM pools during initialization.
+	Capacity of BM pools must be bigger then number of buffers that allocated for long or short pools.
+
+config MV_PP3_BM_SHORT_BUF_SIZE
+	int "buffers size for BM short pool"
+	default 0
+	---help---
+	Default size of buffers allocated for short pools.
+	Buffers size should be long enough to contain the predefined headroom
+	and linux shared info.
+	This value is relevant for all ports.
+
+endmenu
+
+menu "Rx/Tx Queue configuration"
+	depends on MVPP3
+
+config  MV_PP3_RXQ_NUM
+	int "Number of RX VQs for NIC devices"
+        default 2
+        ---help---
+	Number of virtual RXQs for each NIC network interface
+
+config  MV_PP3_GNSS_RXQ_NUM
+	int "Number of RX VQs for NSS devices"
+        default 2
+        ---help---
+	Number of virtual RXQs for each NSS network interface
+
+config MV_PP3_RXQ_SIZE
+	int "Number of CFHs [128 bytes] allocated for each RXQ"
+	default 1024
+        ---help---
+	Default number of CFHs [128 bytes] in each RXQ.
+	This value is relevant for all RXQs.
+
+config  MV_PP3_TXQ_NUM
+	int "Number of TX VQs for NIC devices"
+        default 2
+        ---help---
+	Number of virtual TXQs for each NIC network interface
+
+config  MV_PP3_GNSS_TXQ_NUM
+	int "Number of TX VQs for NSS devices"
+        default 2
+        ---help---
+	Number of virtual TXQs for each NSS network interface
+
+config MV_PP3_TXQ_SIZE
+	int "Number of CFHs [128 bytes] allocated for each TXQ"
+	default 2048
+        ---help---
+	Default number of CFHs [128 bytes] in each TXQ.
+	This value is relevant for all TXQs.
+
+endmenu
+
+menu "Control and Statistics"
+	depends on MVPP3
+
+config  MV_PP3_DEBUG_CODE
+	bool "Add run-time debug code"
+	default y
+	---help---
+	When defined special debug code is compiled in kernel image.
+	Some debug messages can be enabled/disabled using special sysfs command.
+	Used for Debug mode and can cause performance decrease.
+	Minory increase kernal image size.
+
+config  MV_PP3_STAT_ERR
+	bool "Collect error statistics"
+	default y
+	---help---
+	Marvell network interface driver collect minimal number of statistics.
+	Provide information only about error events. Doesn't effect performance.
+	Can be displayed using sysfs commands.
+
+config  MV_PP3_STAT_INF
+	bool "Collect event statistics"
+	default y
+	---help---
+	Marvell network interface driver collect event statistics.
+	Provide more information about driver functionality and almost doesn't
+	effect performance. Can be displayed using sysfs command.
+
+config  MV_PP3_STAT_DBG
+	bool "Collect debug statistics"
+	default y
+	---help---
+	Marvell network interface driver collect a lot of statistics.
+	Provide information about each event occurs in the driver.
+	Used for Debug mode and can cause performance decrease.
+	Can be displayed using sysfs command.
+
+endmenu
+
+menu "Advanced Features"
+	depends on MVPP3
+
+config MV_PP3_SKB_RECYCLE
+	depends on NET_SKB_RECYCLE
+	bool "PP3 SKB recycle only for forwarding cases"
+	default y
+	---help---
+	Work-in-progress and experimental.
+
+	This option enables skb's to be recycled after packet transmitted,
+	which makes a fastpath for routine and bridge skb consuming network
+	applications. It only applies to nic interfaces.
+
+config MV_PP3_SKB_RECYCLE_DEF
+	depends on MV_PP3_SKB_RECYCLE
+	int "Default value for SKB recycle:  0 - disable, 1 - enable"
+	default 0
+	---help---
+	SKB recycle can be enabled or disabled in run-time by sysfs command:
+	"echo [0|1] > dev/nic_skb" - set SKB recycle in NIC mode, 0 - disable, 1 - enable
+
+config  MV_PP3_RX_COAL_PKTS
+        int "Threshold [number of packets] for RX interrupt"
+        default 32
+        ---help---
+        Number of packets will be received before RX interrupt will be generated by HW.
+
+config  MV_PP3_RX_COAL_USEC
+        int "Threshold [usec] for RX interrupt"
+        default 100
+        ---help---
+        Time delay in usec before RX interrupt will be generated by HW if number of
+	received packets larger than 0 but smaller than MV_PP3_RX_COAL_PKTS
+
+config  MV_PP3_TXDONE_COAL_PKTS
+        int "Threshold for TX_DONE event trigger"
+        default 16
+        ---help---
+	Number of packets will be sent before TX_DONE event will be triggered.
+
+config MV_PP3_TXDONE_IN_HRTIMER
+        depends on HIGH_RES_TIMERS
+        bool "Use high resolution timer to process TX_DONE event"
+        ---help---
+        When chosen TX_DONE event will be process by high resolution timer in polling mode.
+        High resolution timer can support higher precision in ns level.
+        If high resolution timer is enabled, TX processing
+	 can free SKB memory much faster.
+
+config  MV_PP3_GRO
+        bool "GRO Support for Marvell network interface"
+	default y
+        ---help---
+	Marvell network driver compiled with GRO (Generic Receive Offload) support.
+
+config  MV_PP3_SG
+        bool "Scatter-Gather Support for Marvell network interface"
+        default n
+        ---help---
+        Marvell network driver compiled with SG (Scatter-Gather Offload) support.
+
+config  MV_PP3_TSO
+	depends on MV_PP3_SG
+        bool "TSO Support for Marvell network interface"
+	default n
+        ---help---
+	Marvell PP3 network driver compiled with TSO support
+	(TSO -- TCP Segmentation Offloading)
+	L4 checksum offload must be enabled
+
+config  MV_PP3_PPC_NUM
+        int "Number of active packet processors clusters"
+        default 2
+        ---help---
+	Number of active packet processors clusters in the system.
+
+config  MV_PP3_PTP_SERVICE
+	bool "PTP service"
+	default y
+	select UIO
+	---help---
+	PTP uio mapping and packet-timestamp in Marvell network driver
+
+endmenu
+
diff --git a/drivers/net/ethernet/marvell/pp3/Makefile b/drivers/net/ethernet/marvell/pp3/Makefile
new file mode 100644
index 0000000..ac92f59
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/Makefile
@@ -0,0 +1,62 @@
+#
+# Makefile for the marvell PPv3 network driver.
+#
+
+obj-$(CONFIG_MVPP3) += mv_pp3.o
+
+PLAT_DIR := drivers/net/ethernet/marvell
+
+INCLUDE_DIRS       := -I$(PLAT_DIR)
+INCLUDE_DIRS       += -I$(PLAT_DIR)/common
+INCLUDE_DIRS       += -I$(srctree)/arch/arm/mach-mvebu
+INCLUDE_DIRS       += -I$(PLAT_DIR)/pp3
+INCLUDE_DIRS       += -I$(PLAT_DIR)/net_complex
+
+export INCLUDE_DIRS
+ccflags-y	+= $(INCLUDE_DIRS)
+ccflags-y += -I$(PLAT_DIR)/pp3/tm/platform
+ccflags-y += -I$(PLAT_DIR)/pp3/tm/core
+ccflags-y += -I$(PLAT_DIR)/pp3/tm/core/resource_management
+ccflags-y += -I$(PLAT_DIR)/pp3/tm/wrappers
+
+mv_pp3-objs := common/mv_stack.o common/mv_common.o
+mv_pp3-objs += platform/mv_pp3.o platform/mv_pp3_config.o platform/mv_pp3_debug_sysfs.o platform/mv_pp3_init_sysfs.o
+mv_pp3-objs += vport/mv_pp3_vq.o vport/mv_pp3_swq.o vport/mv_pp3_pool.o vport/mv_pp3_vport.o vport/mv_pp3_cpu.o
+mv_pp3-objs += vport/mv_vport_sysfs.o
+mv_pp3-objs += platform/mv_pp3_version.o
+mv_pp3-objs += hmac/mv_hmac.o hmac/mv_hmac_sysfs.o
+mv_pp3-objs += emac/mv_emac.o emac/mv_emac_sysfs.o
+mv_pp3-objs += fw/mv_pp3_fw_msg.o fw/mv_fw.o fw/mv_fw_sysfs.o
+mv_pp3-objs += msg/mv_pp3_msg_chan.o msg/mv_pp3_msg_drv.o msg/mv_pp3_msg_sysfs.o
+mv_pp3-objs += bm/mv_bm.o bm/mv_bm_sysfs.o
+mv_pp3-objs += qm/mv_qm.o qm/mv_qm_regs.o qm/mv_qm_sysfs.o
+mv_pp3-objs += cmac/mv_cmac.o cmac/mv_cmac_sysfs.o
+mv_pp3-objs += net_dev/mv_netdev.o net_dev/mv_dev_dbg.o net_dev/mv_dev_sysfs.o net_dev/mv_dev_debug_sysfs.o
+mv_pp3-objs += net_dev/mv_dev_vq.o net_dev/mv_dev_vq_sysfs.o net_dev/mv_ethtool.o net_dev/mv_dev_init_sysfs.o
+mv_pp3-objs += gnss/mv_pp3_gnss_api.o gnss/mv_pp3_gnss_stats_api.o
+#mv_pp3-objs += net_dev/mv_dev_bpi_sysfs.o
+
+ifeq ($(CONFIG_MV_PP3_TM_SUPPORT),y)
+mv_pp3-objs += tm/platform/tm_sysfs.o tm/platform/tm_get_gen_param_implementation.o
+mv_pp3-objs += tm/platform/tm_locking_imp.o tm/platform/tm_os_if.o tm/platform/tm_rw_registers_implementation.o
+mv_pp3-objs += tm/platform/tm_alias.o tm/platform/tm_to_qmtm_enums.o tm/platform/tm_hw_conf.o tm/core/tm_ctl.o
+mv_pp3-objs += tm/platform/tm_sysfs_debug.o tm/platform/tm_sysfs_drop.o tm/platform/tm_sysfs_shaping.o
+mv_pp3-objs += tm/core/set_hw_registers.o tm/core/tm_drop.o tm/core/tm_elig_prio_func.o tm/core/tm_errors.o
+mv_pp3-objs += tm/core/tm_nodes_create.o tm/core/tm_nodes_ctl.o tm/core/tm_nodes_read.o tm/core/tm_nodes_reorder.o
+mv_pp3-objs += tm/core/tm_nodes_status.o tm/core/tm_nodes_tree.o tm/core/tm_nodes_update.o tm/core/tm_nodes_utils.o
+mv_pp3-objs += tm/core/tm_registers_processing.o tm/core/tm_sched.o tm/core/tm_set_local_db_defaults.o tm/core/tm_shaping.o
+mv_pp3-objs += tm/core/resource_management/rm_chunk.o tm/core/resource_management/rm_ctl.o
+mv_pp3-objs += tm/core/resource_management/rm_free.o tm/core/resource_management/rm_list.o
+mv_pp3-objs += tm/core/resource_management/rm_reorder.o tm/core/resource_management/rm_status.o
+mv_pp3-objs += tm/core/resource_management/rm_alloc.o
+mv_pp3-objs += tm/wrappers/mv_tm_drop.o tm/wrappers/mv_tm_sched.o tm/wrappers/mv_tm_shaping.o tm/wrappers/mv_tm_scheme.o
+mv_pp3-objs += tm/mv_tm.o
+endif
+
+mv_pp3-objs += gop/a390_mg_if.o gop/mv_gop_if.o gop/mv_mib_cntrs.o gop/mv_gop_sysfs.o
+mv_pp3-objs += gop/mac/mv_xlg_mac_if.o gop/mac/mv_gmac_if.o
+mv_pp3-objs += gop/pcs/mv_xpcs_if.o gop/pcs/mv_gpcs_if.o
+mv_pp3-objs += gop/serdes/mv_serdes_if.o gop/mv_smi.o
+mv_pp3-objs += gop/mv_ptp_if.o gop/mv_ptp_if_serv.o gop/mv_tai_clock.o
+mv_pp3-objs += net_dev/mv_ptp_uio.o
+
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
new file mode 100644
index 0000000..f910ea0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
@@ -0,0 +1,1424 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+/* includes */
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "qm/mv_qm.h"
+#include "mv_bm.h"
+#include "mv_bm_mem.h"
+#include "mv_bm_regs.h"
+
+static int bm_base_offset;
+static void __iomem *mv_hw_silicon;
+
+static int bm_regs_debug_flags;
+
+
+/*------------------------------------------------------------------------------*/
+/*			BM internal functions					*/
+/*------------------------------------------------------------------------------*/
+
+
+int bm_gp_pid_validation(int pid)
+{
+	if ((pid < BM_GP_POOL_MIN) || (pid > BM_GP_POOL_MAX)) {
+		pr_err("%s Error - Invalid pool id %d\n", __func__, pid);
+		return -1;
+	}
+	return 0;
+}
+
+static int bm_qm_pid_validation(int pid)
+{
+	if ((pid < BM_QM_GPM_POOL_0) || (pid > BM_QM_DRAM_POOL_1)) {
+		pr_err("%s Error - Invalid pool id %d\n", __func__, pid);
+		return -1;
+	}
+	return 0;
+}
+
+static int bm_pid_validation(int pid)
+{
+	int ret_val = 0;
+
+	if ((pid < BM_QM_GPM_POOL_0) || (pid > BM_GP_POOL_MAX))
+		ret_val = -1;
+
+	/* pools 4-7 not exist */
+	if ((pid > BM_QM_DRAM_POOL_1) && (pid < BM_GP_POOL_MIN))
+		ret_val = -1;
+
+	if (ret_val)
+		pr_err("%s Error - Invalid pool id %d\n", __func__, pid);
+
+	return ret_val;
+}
+
+static int bm_pid_to_bid(int pid)
+{
+	/* return pid index in cache bank */
+
+	if (pid <= BM_QM_DRAM_POOL_1)
+		return 0;
+	else
+		return (pid % 4) + 1;
+}
+
+static int bm_pid_to_local(int pid)
+{
+	/* return pid index in cache bank */
+
+	if (pid <= BM_QM_DRAM_POOL_1)
+		return pid;
+	else
+		return (pid - 8) >> 2;
+}
+
+static int bm_local_to_pid(int local_pid, int bid)
+{
+	/* return pid index in cache bank */
+	if (bid == 0)
+		return local_pid;
+	else
+		return bid - 1 + 8 + (local_pid << 2);
+}
+
+
+static int bm_pid_to_global(int pid)
+{
+	/* return sequential pool id
+	   skip pool id 4-7*/
+
+	if (pid >= BM_GP_POOL_MIN)
+		return pid - 4;
+	else
+		return pid;
+}
+
+/*------------------------------------------------------------------------------*/
+/*		BM registers & memories access APIs				*/
+/*------------------------------------------------------------------------------*/
+
+void bm_dbg_flags(u32 flag, u32 en)
+{
+	u32 bit_flag;
+
+	bit_flag = (fls(flag) - 1);
+
+	if (en)
+		bm_regs_debug_flags |= (1 << bit_flag);
+	else
+		bm_regs_debug_flags &= ~(1 << bit_flag);
+
+	return;
+}
+
+void mv_pp3_bm_init(void __iomem *base)
+{
+	bm_base_offset = BM_UNIT_OFFS;
+	mv_hw_silicon = base;
+}
+
+static void bm_gl_reg_write(unsigned int reg, unsigned int data)
+{
+	mv_pp3_hw_reg_write(reg + bm_base_offset + mv_hw_silicon, data);
+
+	if (bm_regs_debug_flags & BM_F_DBG_WR)
+		pr_info("BM WRITE: %p = 0x%08x\n", reg + bm_base_offset + mv_hw_silicon, data);
+}
+
+static unsigned int bm_gl_reg_read(unsigned int reg)
+{
+	unsigned int reg_data;
+
+	mv_pp3_hw_read(reg + bm_base_offset + mv_hw_silicon, 1, &reg_data);
+
+	if (bm_regs_debug_flags & BM_F_DBG_RD)
+		pr_info("BM READ : %p = 0x%08x\n", reg + bm_base_offset + mv_hw_silicon, reg_data);
+
+	return reg_data;
+}
+static void bm_gl_reg_print(char *reg_name, unsigned int reg)
+{
+	pr_info(" %-32s: %p = 0x%08x\n",
+		reg_name, reg + bm_base_offset + mv_hw_silicon, bm_gl_reg_read(reg));
+
+}
+
+static void bm_gl_reg_none_zr_print(char *reg_name, unsigned int reg)
+{
+	pr_info(" %-32s: %p = 0x%08x\n",
+		reg_name, reg + bm_base_offset + mv_hw_silicon, bm_gl_reg_read(reg));
+}
+
+static void bm_entry_read(int offs, int words,  unsigned int *entry)
+{
+	mv_pp3_hw_read(mv_hw_silicon + offs, words, entry);
+
+	if (bm_regs_debug_flags & BM_F_DBG_RD) {
+		int i;
+
+		for (i = 0; i < words; i++)
+			pr_info("BM READ : %p = 0x%08x\n", mv_hw_silicon + offs + (4 * i), entry[i]);
+	}
+}
+
+static void bm_entry_write(int offs, int words,  unsigned int *entry)
+{
+	mv_pp3_hw_write(mv_hw_silicon + offs, words, entry);
+
+	if (bm_regs_debug_flags & BM_F_DBG_WR) {
+		int i;
+
+		for (i = 0; i < words; i++)
+			pr_info("BM WRITE: %p = 0x%08x\n", mv_hw_silicon + offs + (4 * i), entry[i]);
+	}
+}
+
+static int bm_entry_print(char *name, int offs, int words)
+{
+	char reg_name[100];
+	unsigned int *entry;
+	int i;
+
+	entry = kzalloc(words * sizeof(unsigned int), GFP_KERNEL);
+
+	if (!entry) {
+		pr_info("%s: Error - out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	bm_entry_read(offs, words, entry);
+
+	for (i = 0; i < words; i++) {
+		sprintf(reg_name, "%s[%d]", name, i);
+		pr_info(" %-32s: %p = 0x%08x\n", reg_name,
+				mv_hw_silicon + offs + (4*i), entry[i]);
+	}
+
+	kfree(entry);
+	return 0;
+}
+
+/*------------------------------------------------------------------------------*/
+/*		BM User Application Interface					*/
+/*------------------------------------------------------------------------------*/
+
+
+/* Set default BM attributes for read/write in DRAM */
+void bm_attr_all_pools_def_set(void)
+{
+	unsigned int reg_val;
+
+	reg_val =  (BM_ADOMAIN << BM_DRAM_DOMAIN_CFG_WR_B0_OFFS) |
+			(BM_ADOMAIN << BM_DRAM_DOMAIN_CFG_WR_BGP_OFFS) |
+			(BM_ADOMAIN << BM_DRAM_DOMAIN_CFG_RD_B0_OFFS) |
+			(BM_ADOMAIN << BM_DRAM_DOMAIN_CFG_RD_BGP_OFFS);
+	bm_gl_reg_write(BM_DRAM_DOMAIN_CFG_REG, reg_val);
+
+	reg_val =  (BM_AWCACHE << BM_DRAM_CACHE_CFG_WR_B0_OFFS) |
+			(BM_AWCACHE << BM_DRAM_CACHE_CFG_WR_BGP_OFFS) |
+			(BM_ARCACHE << BM_DRAM_CACHE_CFG_RD_B0_OFFS) |
+			(BM_ARCACHE << BM_DRAM_CACHE_CFG_RD_BGP_OFFS);
+	bm_gl_reg_write(BM_DRAM_CACHE_CFG_REG, reg_val);
+
+	reg_val =  (BM_AWQOS << BM_DRAM_QOS_CFG_WR_B0_OFFS) |
+			(BM_AWQOS << BM_DRAM_QOS_CFG_WR_BGP_OFFS) |
+			(BM_ARQOS << BM_DRAM_QOS_CFG_RD_B0_OFFS) |
+			(BM_ARQOS << BM_DRAM_QOS_CFG_RD_BGP_OFFS);
+	bm_gl_reg_write(BM_DRAM_QOS_CFG_REG, reg_val);
+}
+
+/* BM module status */
+static bool bm_enable_status(void)
+{
+	unsigned int reg_val;
+	bool enable;
+
+	reg_val = bm_gl_reg_read(BM_COMMON_GENERAL_CFG_REG);
+	enable = reg_val & BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_MASK ? true : false;
+	return enable;
+}
+
+static void bm_pool_enabled_get(int pool, bool *enabled, bool *quick_init)
+{
+	unsigned int reg_val, enabled_flag, quick_flag;
+	int bid, pid_local;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+
+	if  (bid == 0) { /* QM pools */
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		enabled_flag = reg_val & BM_B0_POOL_CFG_ENABLE_MASK;
+		quick_flag = reg_val & BM_B0_POOL_CFG_QUICK_INIT_MASK;
+	} else {
+		/* GP pools */
+		reg_val = bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		enabled_flag = reg_val & reg_val & BM_BGP_POOL_CFG_ENABLE_MASK;
+		quick_flag = reg_val & BM_BGP_POOL_CFG_QUICK_INIT_MASK;
+	}
+
+	if (enabled)
+		*enabled = enabled_flag ? true : false;
+	if (quick_init)
+		*quick_init = quick_flag ? true : false;
+}
+/*
+ * enable BM module
+ */
+void bm_enable(void)
+{
+	unsigned int reg_val;
+
+	reg_val = bm_gl_reg_read(BM_COMMON_GENERAL_CFG_REG);
+
+	/* set swap in to 0 */
+	reg_val &= ~BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_MASK;
+	/* set request rcv to 1 */
+	reg_val |= BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_MASK;
+
+	bm_gl_reg_write(BM_COMMON_GENERAL_CFG_REG, reg_val);
+}
+
+void bm_disable(void)
+{
+	unsigned int reg_val;
+
+	reg_val = bm_gl_reg_read(BM_COMMON_GENERAL_CFG_REG);
+
+	/* set swap in to 0 */
+	reg_val &= ~BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_MASK;
+	/* set request rcv to 0 */
+	reg_val &= ~BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_MASK;
+
+	bm_gl_reg_write(BM_COMMON_GENERAL_CFG_REG, reg_val);
+}
+
+
+void bm_vmid_set(unsigned int bm_vmid)
+{
+	unsigned int reg_val;
+
+	reg_val = bm_gl_reg_read(BM_COMMON_GENERAL_CFG_REG);
+
+	/* set swap in to 0 */
+	reg_val &= ~BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_MASK;
+
+	/* set vmid */
+	reg_val &= ~BM_COMMON_GENERAL_CFG_DM_VMID_MASK;
+	reg_val |= bm_vmid << BM_COMMON_GENERAL_CFG_DM_VMID_OFFS;
+
+	bm_gl_reg_write(BM_COMMON_GENERAL_CFG_REG, reg_val);
+}
+
+/**
+ *  Fill memory of pool with PE index
+ *	PE index is incrementing value of 1 to num_of_buffers
+ *  Mark PE with its location (GPM or DRAM)
+ *  Return values:
+ *		0 - success
+ */
+/*BM Internal functions*/
+static int bm_memory_fill(int buf_num, struct mv_a40 *base_address)
+{
+	unsigned int i, *base;
+
+	/*
+	 * fill all PE's with incrementing value (starting with 1)
+	 * Write in Dram in BM pool section an incrementing index
+	 */
+
+	base = (unsigned int *)(base_address->virt_lsb);
+
+	for (i = 1; i <= buf_num; i++) {
+		*base = i;
+		base++;
+	}
+
+	return 0;
+}
+
+/**
+ *  Configure BM with Fill level of pool in DRAM
+ *  Note: Must be called before pool is enabled
+ *  Return values:
+ *		0 - success
+ */
+static int bm_pool_dram_set(int pool, int buf_num, int pe_bits, struct mv_a40 *base_address,
+						unsigned int ae_thr, unsigned int af_thr)
+{
+	unsigned int entry_ptr[BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS];
+	unsigned int entry_offset;
+	int global_pid, pe_bytes;
+
+	if (bm_pid_validation(pool))
+		return -1;
+
+	global_pid = bm_pid_to_global(pool);
+	entry_offset = BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY(global_pid);
+
+	bm_entry_read(entry_offset, BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS, entry_ptr);
+
+	mv_field_set(BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_OFFS,
+			BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_BITS, entry_ptr,  base_address->dma_msb);
+	mv_field_set(BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_OFFS,
+			BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_BITS, entry_ptr,  base_address->dma_lsb);
+
+	/* for pools 1-3 pe_bits must be 32 bits */
+	/* pe size in dram align to 4 bytes */
+	pe_bytes = MV_ALIGN_UP(pe_bits, MV_WORD_BITS) / MV_BYTE_BITS;
+
+	/* fields are in unit of 64 bytes */
+	mv_field_set(BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_OFFS,
+			BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_BITS, entry_ptr, (ae_thr*pe_bytes) / BM_DRAM_LINE_BYTES);
+	mv_field_set(BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_OFFS,
+			BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_BITS, entry_ptr, (af_thr*pe_bytes) / BM_DRAM_LINE_BYTES);
+	mv_field_set(BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_OFFS,
+			BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_BITS, entry_ptr, (buf_num*pe_bytes) / BM_DRAM_LINE_BYTES);
+
+	bm_entry_write(entry_offset, BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS, entry_ptr);
+	return 0;
+}
+/*
+ *  Configure BM with Fill level of pool in DRAM
+ *	Supports all pools (QM and general purpose)
+ *  Note: Must be called before pool is enabled
+ *	  for pools in quick init mode, buff_num sould set to 0
+ */
+static void bm_pool_fill_level_set(int pool, int buf_num, int pe_bits)
+{
+	unsigned int entry_ptr[BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS];
+	unsigned int entry_offset, dram_fill;
+	int global_pid, pe_bytes;
+
+	global_pid = bm_pid_to_global(pool);
+	entry_offset = BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY(global_pid);
+	bm_entry_read(entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS, entry_ptr);
+
+	/* pe size in dram align to 4 bytes */
+	pe_bytes = MV_ALIGN_UP(pe_bits, MV_WORD_BITS) / MV_BYTE_BITS;
+	dram_fill = pe_bytes * buf_num;
+
+	/* dram fill level in unit of 8 bytes */
+	mv_field_set(BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_OFFS,
+		BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_BITS, entry_ptr, dram_fill / 8);
+
+	bm_entry_write(entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS, entry_ptr);
+}
+
+static int bm_pool_quick_disable(int pool)
+{
+	unsigned int reg_val;
+	int bid, pid_local;
+
+	if (bm_pid_validation(pool))
+		return -1;
+
+	/* set dram fill level to 0 */
+	bm_pool_fill_level_set(pool, 0, MV_32_BITS);
+
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+
+	if  (bid == 0) {
+		/* QM pools */
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		reg_val &= ~BM_B0_POOL_CFG_QUICK_INIT_MASK;
+		bm_gl_reg_write(BM_B0_POOL_CFG_REG(pid_local), reg_val);
+	} else {
+		/* QP pools */
+		reg_val =  bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		reg_val &= ~BM_BGP_POOL_CFG_QUICK_INIT_MASK;
+		bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+	}
+	return 0;
+}
+
+static int bm_qm_pool_quick_enable(int pool, int buf_num, struct mv_a40 *base_address)
+{
+	int pid_local;
+	unsigned int reg_val;
+
+	if (bm_qm_pid_validation(pool))
+		return -1;
+
+	if (!base_address)
+		return -1;
+
+	pid_local = bm_pid_to_local(pool);
+
+	/* set dram fill level */
+	bm_pool_fill_level_set(pool, buf_num, MV_32_BITS);
+
+	bm_memory_fill(buf_num, base_address);
+
+	/* set quick int bit */
+	reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+	reg_val |= BM_B0_POOL_CFG_QUICK_INIT_MASK;
+	bm_gl_reg_write(BM_B0_POOL_CFG_REG(pid_local), reg_val);
+
+	return 0;
+}
+
+
+int bm_qm_pool_total_thresholds(int pool, unsigned int a_empty, unsigned int aa_empty)
+{
+	int pid_local;
+	unsigned int reg_val;
+
+	if (bm_qm_pid_validation(pool))
+		return -1;
+
+	pid_local = bm_pid_to_local(pool);
+
+	/* QM pools */
+	reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+	reg_val &= ~BM_B0_POOL_CFG_AE_THR_MASK;
+	reg_val &= ~BM_B0_POOL_CFG_AAE_THR_MASK;
+	reg_val |= (a_empty << BM_B0_POOL_CFG_AE_THR_OFFS);
+	reg_val |= (aa_empty << BM_B0_POOL_CFG_AAE_THR_OFFS);
+	bm_gl_reg_write(BM_B0_POOL_CFG_REG(pid_local), reg_val);
+
+	return 0;
+}
+
+int bm_gp_pool_total_threshold(int pool, unsigned int a_empty)
+{
+	int pid_local, bid;
+	unsigned int reg_val;
+
+	if (bm_gp_pid_validation(pool))
+		return -1;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+
+	/* QM pools */
+	reg_val = bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+	reg_val &= ~BM_BGP_POOL_CFG_AE_THR_MASK;
+	reg_val |= (a_empty << BM_BGP_POOL_CFG_AE_THR_OFFS);
+	bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+
+	return 0;
+}
+
+int bm_pool_enable(int pool)
+{
+	unsigned int reg_val;
+	int bid, pid_local;
+
+	if (bm_pid_validation(pool))
+		return -1;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+
+	if  (bid == 0) {
+		/* QM pools */
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		reg_val |= BM_B0_POOL_CFG_ENABLE_MASK;
+		bm_gl_reg_write(BM_B0_POOL_CFG_REG(pid_local), reg_val);
+	} else {
+		/* QP pools */
+		reg_val =  bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		reg_val |= BM_BGP_POOL_CFG_ENABLE_MASK;
+		bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+	}
+	return 0;
+}
+
+int bm_pool_disable(int pool)
+{
+	unsigned int reg_val;
+	int bid, pid_local;
+
+	if (bm_pid_validation(pool))
+		return -1;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+
+	if  (bid == 0) {
+		/* QM pools */
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		reg_val &= ~BM_B0_POOL_CFG_ENABLE_MASK;
+		bm_gl_reg_write(BM_B0_POOL_CFG_REG(pid_local), reg_val);
+	} else {
+		/* QP pools */
+		reg_val =  bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		reg_val &= ~BM_BGP_POOL_CFG_ENABLE_MASK;
+		bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+	}
+
+	return 0;
+}
+/**
+ *  Set PE pointer size in general purpose pool
+ *
+ *  Return values:
+ *		0 - success
+ */
+static int bm_gp_pool_pe_size_set(int pool, int pe_bits)
+{
+	unsigned int reg_val, bid, pid_local;
+
+	if (bm_gp_pid_validation(pool))
+		return -1;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+	reg_val =  bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+
+	if (pe_bits == MV_32_BITS)
+		reg_val |= BM_BGP_POOL_CFG_PE_SIZE_MASK;
+	else if (pe_bits == MV_40_BITS)
+		reg_val &= ~BM_BGP_POOL_CFG_PE_SIZE_MASK;
+	else
+		return -1;
+
+	bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+
+	return 0;
+}
+
+/**
+ *  Configure if global pool (8-35) is defined to work in pairs
+ *
+ *  Return values:
+ *		0 - success
+ */
+static int bm_gp_pool_pair_set(int pool, bool pool_pair)
+{
+	unsigned int reg_val;
+	int bid, pid_local;
+
+	if (bm_gp_pid_validation(pool))
+		return -1;
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+	reg_val =  bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+
+	if (pool_pair)
+		reg_val |= BM_BGP_POOL_CFG_IN_PAIRS_MASK;
+	else
+		reg_val &= ~BM_BGP_POOL_CFG_IN_PAIRS_MASK;
+
+	bm_gl_reg_write(BM_BGP_POOL_CFG_REG(bid, pid_local), reg_val);
+
+	return 0;
+}
+/**
+ *  Configure pool cache parameters
+ *
+ *  Note: Must be called before pool is enabled
+ *  Return values:
+ *		0 - success
+ */
+static int bm_pool_cache_set(int pool, unsigned int vmid, unsigned int attr,
+				unsigned int so_thr, unsigned int si_thr, unsigned int cache_buf_num)
+{
+
+	unsigned int entry_ptr[BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS];
+	unsigned int entry_offset;
+	int pid, bid, curr_pid_local, pid_local, bank_pools_num;
+	int pe_cache_units, end_max, cache_end, cache_start;
+	bool pool_enable;
+
+	/* fields calculated in cache lines with granularity of 64B
+		for B0 it is 16 PE's
+		for B1..B4 it is 8 PE's */
+
+	pe_cache_units = 64 / BM_CACHE_PE_BYTES(pool);
+
+	if (cache_buf_num % pe_cache_units)
+		return -1;
+
+	if (so_thr < si_thr + 16) {
+		pr_err("cache swap out threshold should be larger than cache swap in plus 16\n");
+		return -1;
+	}
+
+	bid = bm_pid_to_bid(pool);
+	/* B0 - 4 pools shares same cache which is 512 lines, each with 4 PE's = 2048 PE's
+	   B1..B4 each bank has 7 pools that shares 1024 lines, each with 1 PE = 1024 PE's */
+
+	bank_pools_num = BM_BANK_POOLS_NUM(bid);
+
+	end_max = -1;
+	/* run on all pools in bank and check what is the end of the occupied part */
+	for (curr_pid_local = 0; curr_pid_local < bank_pools_num; curr_pid_local++) {
+		pid = bm_local_to_pid(curr_pid_local, bid);
+		bm_pool_enabled_get(pid, &pool_enable, NULL);
+
+		/* if pool is not enabled that we don't take its cache configuration into account */
+		if (pool_enable == false)
+			continue;
+
+		entry_offset = BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, curr_pid_local);
+		bm_entry_read(entry_offset, BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS, entry_ptr);
+		cache_end = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_END_OFFS,
+						BM_DPR_C_MNG_BANK_STAT_CACHE_END_BITS, entry_ptr);
+		end_max = MV_MAX(end_max, cache_end);
+	}
+
+	cache_start = end_max + 1;
+
+	cache_end = cache_start + (cache_buf_num / pe_cache_units) - 1;
+
+	/* Swap-out threshold Unit is 1 PE.
+	   Swap-in threshold Unit is 1 PE.
+	   start and end are in line units (GP - 1PE, QM - 4 PE's)
+	   and in 64B granularity */
+
+	/* set all fields in entry */
+	pid_local = bm_pid_to_local(pool);
+	entry_offset = BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, pid_local);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_START_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_START_BITS, entry_ptr, cache_start);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_END_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_END_BITS, entry_ptr, cache_end);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_BITS, entry_ptr, si_thr);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_BITS, entry_ptr, so_thr);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_BITS, entry_ptr, attr);
+	mv_field_set(BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_BITS, entry_ptr, vmid);
+	bm_entry_write(entry_offset, BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS, entry_ptr);
+	return 0;
+}
+
+/*
+ * Init of GP pools
+ */
+int bm_gp_pool_def_basic_init(int pool, int buf_num, struct mv_a40 *base_address)
+{
+	unsigned int ret_val = 0;
+
+	if (bm_gp_pid_validation(pool))
+		return -1;
+
+	ret_val |= bm_pool_dram_set(pool, buf_num, MV_32_BITS, base_address,
+					BM_DRAM_AE(buf_num), BM_DRAM_AF(buf_num));
+	ret_val |= bm_pool_cache_set(pool, BM_VMID, BM_CACHE_ATTR,
+					BM_GP_CACHE_SO, BM_GP_CACHE_SI, BM_GP_CACHE_BUF_NUM);
+	ret_val |= bm_gp_pool_pe_size_set(pool, MV_32_BITS);
+	ret_val |= bm_gp_pool_pair_set(pool, true);
+	ret_val |= bm_pool_quick_disable(pool);
+	ret_val |= bm_gp_pool_total_threshold(pool, BM_TOT_AE);
+	ret_val |= bm_pool_enable(pool);
+	return ret_val;
+}
+
+static int bm_pool_quick_init_complete(int pool)
+{
+	int bid, pid_local, count = 0;
+	bool enabled, quick_init, complete = true;
+	u32 reg_val, reg_address;
+
+	bm_pool_enabled_get(pool, &enabled, &quick_init);
+
+	if (!enabled) {
+		pr_err("%s: Error - pool %d is disabled\n", __func__, pool);
+		return -1;
+	}
+	if (!quick_init) {
+		pr_err("%s: Error - pool %d not in quick init mode\n", __func__, pool);
+		return -1;
+	}
+
+	pid_local = bm_pid_to_local(pool);
+
+	bid = bm_pid_to_bid(pool);
+
+	if (bid)
+
+		reg_address = BM_BGP_POOL_STATUS_REG(bid, pid_local);
+	else
+		reg_address = BM_B0_POOL_STATUS_REG(pid_local);
+
+	do {
+		if (count++ >= 100) {
+			pr_err("pool #%d quick initialization time out\n", pool);
+			return -1;
+		}
+
+		mdelay(1);
+
+		reg_val = bm_gl_reg_read(reg_address);
+
+		complete = reg_val & BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_MASK ? true : false;
+
+	} while (!complete);
+
+	return 0;
+}
+
+/* Quick init of QM pools */
+int bm_qm_gpm_pools_def_quick_init(int buf_num, struct mv_a40 *qece_base, struct mv_a40 *pl_base)
+{
+	struct mv_a40 *base_address;
+	bool bm_enable;
+	unsigned int pool, ret_val = 0;
+
+	if (buf_num > BM_QM_GPM_POOL_CAPACITY) {
+		pr_err("Invalid GPM pools num of buffers %d\n", buf_num);
+		return -EINVAL;
+	}
+
+	/* HW limitation, pools 0-3 should hold at least 16 empty PEs */
+	buf_num = buf_num - 16;
+
+	bm_enable = bm_enable_status();
+
+	if (bm_enable) {
+		pr_err("%s: Error - pool 0 and 1 should be enabled before BM module is enabled\n", __func__);
+		return -EINVAL;
+	}
+
+	for (pool = BM_QM_GPM_POOL_0; pool <= BM_QM_GPM_POOL_1; pool++) {
+
+		base_address = (pool == BM_QM_GPM_POOL_0) ? pl_base : qece_base;
+
+		ret_val |= bm_pool_dram_set(pool, buf_num, MV_32_BITS, base_address,
+						BM_DRAM_AE(buf_num), BM_DRAM_AF(buf_num));
+		ret_val |= bm_pool_cache_set(pool, BM_VMID, BM_CACHE_ATTR,
+						BM_QM_CACHE_SO, BM_QM_CACHE_SI, BM_QM_CACHE_BUF_NUM);
+		ret_val |= bm_qm_pool_total_thresholds(pool, BM_TOT_AE, BM_TOT_AAE);
+		ret_val |= bm_qm_pool_quick_enable(pool, buf_num, base_address);
+		ret_val |= bm_pool_enable(pool);
+
+		if (ret_val) {
+			pr_err("%s: Error- pool %d default quick initialization failed\n", __func__, pool);
+			return ret_val;
+		}
+
+		if (bm_pool_quick_init_complete(pool) < 0) {
+			pr_err("%s: Error - pool %d default quick initialization not complete\n", __func__, 1);
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+int bm_qm_dram_pools_def_quick_init(struct device *dev, int buf_num, struct mv_a40 *qece_base, struct mv_a40 *pl_base)
+{
+
+	struct mv_a40 *base_address;
+	struct mv_a40 address_allocate[BM_QM_DRAM_POOLS_NUM];
+	unsigned int pool, ret_val = 0;
+	int index;
+
+
+	memset(address_allocate, 0, BM_QM_DRAM_POOLS_NUM * sizeof(struct mv_a40));
+
+	for (pool = BM_QM_DRAM_POOL_0; pool <= BM_QM_DRAM_POOL_1; pool++) {
+
+		base_address = (pool == BM_QM_DRAM_POOL_0) ? pl_base : qece_base;
+		index = pool - BM_QM_DRAM_POOL_0;
+
+		ret_val |= bm_pool_dram_set(pool, buf_num, MV_32_BITS, base_address,
+						BM_DRAM_AE(buf_num), BM_DRAM_AF(buf_num));
+		ret_val |= bm_pool_cache_set(pool, BM_VMID, BM_CACHE_ATTR, BM_QM_CACHE_SO,
+						BM_QM_CACHE_SI, BM_QM_CACHE_BUF_NUM);
+
+		/* for pools 2&3 it allocates the buffer memory before filling the pool	*/
+
+		address_allocate[index].virt_lsb =
+				(unsigned int)dma_alloc_coherent(dev, (buf_num+1)*BM_QM_DRAM_POOL_BUF_SIZE(pool),
+						&address_allocate[index].dma_lsb, GFP_KERNEL);
+
+		if (address_allocate[index].virt_lsb == (unsigned int)NULL)
+			goto oom;
+
+		ret_val |= bm_qm_pool_quick_enable(pool, buf_num, base_address);
+		ret_val |= bm_qm_pool_total_thresholds(pool, BM_TOT_AE, BM_TOT_AAE);
+		ret_val |= bm_pool_enable(pool);
+
+		if (ret_val) {
+			pr_err("%s: Error- pool %d default quick initialization failed\n", __func__, pool);
+			goto err;
+		}
+
+		if (bm_pool_quick_init_complete(pool) < 0) {
+			pr_err("%s: Error - pool %d quick initialization not complete\n", __func__, pool);
+			goto err;
+		}
+	}
+
+	qm_pfe_base_address_pool_set(&address_allocate[1], &address_allocate[0]);
+
+	return MV_OK;
+
+oom:
+	pr_err("%s: out of memory\n", __func__);
+err:
+	for (index = 0; index < BM_QM_DRAM_POOLS_NUM; index++)
+		kfree((void *)address_allocate[index].virt_lsb);
+
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*BM Debug functions*/
+void bm_global_registers_dump(void)
+{
+	int i;
+	char reg_name[50];
+
+	pr_info("\n-------------- BM Global registers dump -----------");
+
+	for (i = 0; i < 4; i++) {
+		sprintf(reg_name, "SYS_NREC_COMMON_D%d_STATUS", i);
+		bm_gl_reg_print(reg_name, BM_SYS_NREC_COMMON_DX_STATUS_REG(i));
+	}
+
+	bm_gl_reg_print("COMMON_GENERAL_CFG_REG" , BM_COMMON_GENERAL_CFG_REG);
+	bm_gl_reg_print("DRAM_DOMAIN_CFG_REG" , BM_DRAM_DOMAIN_CFG_REG);
+	bm_gl_reg_print("DRAM_CACHE_CFG_REG" , BM_DRAM_CACHE_CFG_REG);
+	bm_gl_reg_print("DRAM_QOS_CFG_REG" , BM_DRAM_QOS_CFG_REG);
+	bm_gl_reg_print("DM_AXI_FIFOS_STATUS_REG" , BM_DM_AXI_FIFOS_STATUS_REG);
+	bm_gl_reg_print("DRM_PENDING_FIFO_STATUS_REG", BM_DRM_PENDING_FIFO_STATUS_REG);
+	bm_gl_reg_print("DM_AXI_WRITE_PENDING_FIFO_STATUS_REG", BM_DM_AXI_WRITE_PENDING_FIFO_STATUS_REG);
+	bm_gl_reg_print("IDLE_STATUS_REG", BM_IDLE_STATUS_REG);
+}
+
+void bm_pool_registers_dump(int pool)
+{
+	int bid, pid_local, pid_global;
+	char reg_name[50];
+
+	if (bm_pid_validation(pool)) {
+		pr_err("Invalid pool id %d\n", pool);
+		return;
+	}
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+	pid_global = bm_pid_to_global(pool);
+
+	pr_info("\n-------------- BM pool %d registers dump -----------\n", pool);
+
+	if (bid == 0) {
+		bm_gl_reg_print("B0_POOL_CFG_REG", BM_B0_POOL_CFG_REG(pid_local));
+		bm_gl_reg_print("B0_POOL_STATUS_REG", BM_B0_POOL_STATUS_REG(pid_local));
+	} else {
+		sprintf(reg_name, "B%d_POOL_CFG_REG", bid);
+		bm_gl_reg_print(reg_name, BM_BGP_POOL_CFG_REG(bid, pid_local));
+		sprintf(reg_name, "B%d_POOL_STATUS_REG", bid);
+		bm_gl_reg_print(reg_name, BM_BGP_POOL_STATUS_REG(bid, pid_local));
+	}
+
+	sprintf(reg_name, "DPR_C_MNG_B%d_STAT", bid);
+	bm_entry_print(reg_name,
+			BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, pid_local), BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS);
+
+	sprintf(reg_name, "TPR_C_MNG_B%d_DYN", bid);
+	bm_entry_print(reg_name,
+			BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY(bid, pid_local), BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS);
+
+	bm_entry_print("DPR_D_MNG_BALL_STAT",
+			BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY(pid_global), BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS);
+
+	bm_entry_print("TPR_DRO_MNG_BALL_DYN",
+			BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY(pid_global), BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS);
+
+	bm_entry_print("TPR_DRW_MNG_BALL_DYN",
+			BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY(pid_global), BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS);
+
+	sprintf(reg_name, "TPR_CTRS_B%d", bid);
+	bm_entry_print(reg_name, BM_TPR_CTRS_BANK_TBL_ENTRY(bid, pid_local), BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS);
+}
+
+void bm_bank_registers_dump(int bank)
+{
+	char reg_name[50];
+
+	if ((bank < BM_BANK_MIN) || (bank > BM_BANK_MAX)) {
+		pr_err("Invalid bank id %d\n", bank);
+		return;
+	}
+
+	pr_info("\n-------------- BM BANK %d registers dump -----------\n", bank);
+	sprintf(reg_name, "MV_B%d_SYS_REC_D0_STATUS_REG", bank);
+	bm_gl_reg_print(reg_name, BM_BANK_SYS_REC_D0_STATUS_REG(bank));
+	sprintf(reg_name, "MV_B%d_SYS_REC_D1_STATUS_REG", bank);
+	bm_gl_reg_print(reg_name, BM_BANK_SYS_REC_D1_STATUS_REG(bank));
+	sprintf(reg_name, "MV_B%d_REQUEST_FIFOS_STATUS_REG", bank);
+	bm_gl_reg_print(reg_name, BM_BANK_REQUEST_FIFOS_STATUS_REG(bank));
+
+	if  (bank == 0) {
+		/*QM pools */
+		bm_gl_reg_print("BM_B0_RELEASE_WRAP_PPE_FIFOS_STATUS_REG",
+					BM_B0_RELEASE_WRAP_PPE_FIFOS_STATUS_REG);
+		bm_gl_reg_print("BM_B0_PAST_ALC_FIFOS_STATUS_REG",
+					BM_B0_PAST_ALC_FIFOS_STATUS_REG);
+	} else
+		/* QP pools */
+		bm_gl_reg_print("BM_BGP_PAST_ALC_FIFOS_FILL_STATUS_REG",
+					BM_BGP_PAST_ALC_FIFOS_FILL_STATUS_REG);
+}
+
+
+void bm_pool_status_dump(int pool)
+{
+	int bid, pid_local, pid_global, pes_in_cache_line, pe_bytes, cache_line_bytes;
+
+	unsigned int reg_val, entry_offset, cache_start, cache_end, cache_si, cache_so;
+	unsigned int cache_fill_min, cache_fill_max, cache_rd, cache_wr, cache_vmid, cache_size;
+	unsigned int delay_release, failed_alloce, release, alloce;
+	unsigned int dram_rd, dram_wr, dram_start, dram_size, dram_ae, dram_af, dram_fill;
+	unsigned int dpr_c_mng_entry[BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS];
+	unsigned int tpr_c_mng_entry[BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS];
+	unsigned int tpr_dro_mng_entry[BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS];
+	unsigned int dpr_d_mng_entry[BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS];
+	unsigned int drw_mng_ball_entry[BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS];
+	unsigned int tpr_ctrs_entry[BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS];
+
+	if (bm_pid_validation(pool)) {
+		pr_err("Invalid pool id %d\n", pool);
+		return;
+	}
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+	pid_global = bm_pid_to_global(pool);
+
+	pr_info("\n---------------- BM pool %d (bank %d) -------------------", pool, bid);
+
+	if  (bid == 0) { /* QM pools */
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		pr_info("pool status         : %s\n", (reg_val & BM_B0_POOL_CFG_ENABLE_MASK) ? "enable" : "disable");
+		pr_info("quick init          : %s\n", (reg_val & BM_B0_POOL_CFG_QUICK_INIT_MASK) ? "yes" : "no");
+		pr_info("total ae       [PEs]: %d\n",
+						(reg_val & BM_B0_POOL_CFG_AE_THR_MASK) >> BM_B0_POOL_CFG_AE_THR_OFFS);
+		pr_info("total aae      [PEs]: %d\n",
+						(reg_val & BM_B0_POOL_CFG_AAE_THR_MASK) >> BM_B0_POOL_CFG_AAE_THR_OFFS);
+
+		reg_val = bm_gl_reg_read(BM_B0_POOL_STATUS_REG(pid_local));
+
+	} else { /* GP pools */
+		reg_val = bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		pr_info("pool status         : %s\n", (reg_val & BM_BGP_POOL_CFG_ENABLE_MASK) ? "enable" : "disable");
+		pr_info("quick init          : %s\n", (reg_val & BM_BGP_POOL_CFG_QUICK_INIT_MASK) ? "yes" : "no");
+		pr_info("pairs mode          : %s\n", (reg_val & BM_BGP_POOL_CFG_IN_PAIRS_MASK) ? "enable" : "disable");
+		pr_info("element size  [bits]: %d bits\n",
+					(reg_val & BM_BGP_POOL_CFG_PE_SIZE_MASK) ? MV_32_BITS : MV_40_BITS);
+		pr_info("total ae       [PEs]: %d\n",
+						(reg_val & BM_BGP_POOL_CFG_AE_THR_MASK) >> BM_BGP_POOL_CFG_AE_THR_OFFS);
+
+		reg_val = bm_gl_reg_read(BM_BGP_POOL_STATUS_REG(bid, pid_local));
+	}
+
+	pes_in_cache_line = BM_PES_IN_CACHE_LINE(pool);
+	pe_bytes = BM_CACHE_PE_BYTES(pool);
+	cache_line_bytes = BM_CACHE_LINE_BYTES(pool);
+
+	pr_info("dram almost empty   : %s\n", reg_val & BM_BGP_POOL_STATUS_AE_MASK ? "yes" : "no");
+	pr_info("dram almost full    : %s\n", reg_val & BM_BGP_POOL_STATUS_AF_MASK ? "yes" : "no");
+
+	/*---------------------------------------------------------------------*/
+
+	entry_offset = BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS, dpr_c_mng_entry);
+
+
+	cache_vmid = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_OFFS,
+					BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_BITS, dpr_c_mng_entry);
+	cache_start = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_START_OFFS,
+					BM_DPR_C_MNG_BANK_STAT_CACHE_START_BITS, dpr_c_mng_entry);
+	cache_end = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_END_OFFS,
+					BM_DPR_C_MNG_BANK_STAT_CACHE_END_BITS, dpr_c_mng_entry);
+	cache_si = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_OFFS,
+					BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_BITS, dpr_c_mng_entry);
+	cache_so = mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_OFFS,
+					BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_BITS, dpr_c_mng_entry);
+
+	cache_size = (cache_end - cache_start + 1) * 64 / BM_CACHE_PE_BYTES(pool);
+
+
+	pr_info("cache state         : %s, vmid = 0x%x\n",
+		reg_val & BM_BGP_POOL_STATUS_NEMPTY_MASK ? "not empty" : "empty", cache_vmid);
+
+	pr_info("cache limits  [line]: start = %d, end = %d\n",
+		cache_start * 64 / cache_line_bytes,
+		cache_end * 64 / cache_line_bytes);
+
+	pr_info("cache size     [PEs]: size = %d\n", cache_size);
+
+	pr_info("cache thresh   [PEs]: si = %d, so = %d\n", cache_si, cache_so);
+
+	/*---------------------------------------------------------------------*/
+	entry_offset = BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS, tpr_c_mng_entry);
+
+	cache_fill_min = mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_OFFS,
+					BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_BITS, tpr_c_mng_entry);
+	cache_fill_max = mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_OFFS,
+					BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_BITS, tpr_c_mng_entry);
+	cache_wr = mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_OFFS,
+					BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_BITS, tpr_c_mng_entry);
+	cache_rd = mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_OFFS,
+					BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_BITS, tpr_c_mng_entry);
+
+	pr_info("cache fill     [PEs]: [%d - %d]\n",
+			cache_fill_min * pes_in_cache_line,
+			cache_fill_max * pes_in_cache_line);
+
+	pr_info("cache line    [line]: read = %d, write = %d\n", cache_rd, cache_wr);
+
+	/*---------------------------------------------------------------------*/
+	entry_offset = BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS, tpr_dro_mng_entry);
+
+	dram_rd = mv_field_get(BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_OFFS,
+					BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_BITS, tpr_dro_mng_entry);
+	dram_wr = mv_field_get(BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_OFFS,
+					BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_BITS, tpr_dro_mng_entry);
+
+	pr_info("dram pointer        : read = 0x%x, write = 0x%x\n", dram_rd, dram_wr);
+
+	/*---------------------------------------------------------------------*/
+	entry_offset = BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS, dpr_d_mng_entry);
+	dram_start = mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_OFFS,
+					BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_BITS, dpr_d_mng_entry);
+	dram_size = mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_OFFS,
+					BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_BITS, dpr_d_mng_entry);
+	dram_ae = mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_OFFS,
+					BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_BITS, dpr_d_mng_entry);
+	dram_af = mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_OFFS,
+					BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_BITS, dpr_d_mng_entry);
+
+	/* fields in unit of 64 bytes,  16 = 64 / PE size in dram */
+	pr_info("dram start pointer  : 0x%x\n", dram_start);
+	pr_info("dram size      [PEs]: %d\n", dram_size * 16);
+	pr_info("dram thresh    [PEs]: ae = %d, af = %d\n", dram_ae * 16, dram_af * 16);
+
+	/*---------------------------------------------------------------------*/
+	entry_offset = BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS, drw_mng_ball_entry);
+
+	dram_fill = mv_field_get(BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_OFFS,
+		BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_BITS, drw_mng_ball_entry);
+
+	pr_info("dram fill      [PEs]: %d\n", dram_fill * 8);
+	/*---------------------------------------------------------------------*/
+	entry_offset = BM_TPR_CTRS_BANK_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS, tpr_ctrs_entry);
+
+	delay_release = mv_field_get(BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_OFFS,
+					BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_BITS, tpr_ctrs_entry);
+	release = mv_field_get(BM_TPR_CTRS_BANK_RELEASED_PES_CTR_OFFS,
+					BM_TPR_CTRS_BANK_RELEASED_PES_CTR_BITS, tpr_ctrs_entry);
+	failed_alloce = mv_field_get(BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_OFFS,
+					BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_BITS, tpr_ctrs_entry);
+	alloce = mv_field_get(BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_OFFS,
+					BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_BITS, tpr_ctrs_entry);
+
+	pr_info("delay releases [PEs]: 0x%08X\n", delay_release);
+	pr_info("failed allocs  [PEs]: 0x%08X\n", failed_alloce);
+	pr_info("released       [PEs]: 0x%08X\n", release);
+	pr_info("allocated      [PEs]: 0x%08X\n", alloce);
+	pr_info("\n");
+}
+
+
+void bm_pool_registers_parse(int pool)
+{
+	int bid, pid_local, pid_global;
+	unsigned int reg_val, entry_offset;
+	unsigned int dpr_c_mng_entry[BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS];
+	unsigned int tpr_c_mng_entry[BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS];
+	unsigned int tpr_dro_mng_entry[BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS];
+	unsigned int dpr_d_mng_entry[BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS];
+	unsigned int drw_mng_ball_entry[BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS];
+	unsigned int tpr_ctrs_entry[BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS];
+
+	if (bm_pid_validation(pool)) {
+		pr_err("Invalid pool id %d\n", pool);
+		return;
+	}
+
+	bid = bm_pid_to_bid(pool);
+	pid_local = bm_pid_to_local(pool);
+	pid_global = bm_pid_to_global(pool);
+
+	pr_info("\nbm_pool_registers_dump\n\n");
+	/*---------------------------------------------------------------------*/
+
+	if  (bid == 0) {	/* QM pools */
+		bm_gl_reg_print("BANK_POOL_CFG_REG", BM_B0_POOL_CFG_REG(pid_local));
+		reg_val = bm_gl_reg_read(BM_B0_POOL_CFG_REG(pid_local));
+		pr_info("  %-46s0x%08X\n", "enable",
+				(reg_val & BM_B0_POOL_CFG_ENABLE_MASK) >> BM_B0_POOL_CFG_ENABLE_OFFS);
+		pr_info("  %-46s0x%08X\n", "quick_init",
+				(reg_val & BM_B0_POOL_CFG_QUICK_INIT_MASK) >> BM_B0_POOL_CFG_QUICK_INIT_OFFS);
+		pr_info("  %-46s0x%08X\n", "ae_tot_thresh",
+				(reg_val & BM_B0_POOL_CFG_AE_THR_MASK) >> BM_B0_POOL_CFG_AE_THR_OFFS);
+		pr_info("  %-46s0x%08X\n", "aae_tot_thresh",
+				(reg_val & BM_B0_POOL_CFG_AAE_THR_MASK) >> BM_B0_POOL_CFG_AAE_THR_OFFS);
+		pr_info("\n");
+		bm_gl_reg_print("BANK_POOL_STATUS_REG", BM_B0_POOL_CFG_REG(pid_local));
+		reg_val = bm_gl_reg_read(BM_B0_POOL_STATUS_REG(pid_local));
+	} else {
+		bm_gl_reg_print("BANK_POOL_CFG_REG", BM_BGP_POOL_CFG_REG(bid, pid_local));
+		reg_val = bm_gl_reg_read(BM_BGP_POOL_CFG_REG(bid, pid_local));
+		pr_info("  %-46s0x%08X\n", "enable",
+				(reg_val & BM_BGP_POOL_CFG_ENABLE_MASK) >> BM_BGP_POOL_CFG_ENABLE_OFFS);
+		pr_info("  %-46s0x%08X\n", "quick_init",
+				(reg_val & BM_BGP_POOL_CFG_QUICK_INIT_MASK) >> BM_BGP_POOL_CFG_QUICK_INIT_OFFS);
+		pr_info("  %-46s0x%08X\n", "ae_tot_thresh",
+				(reg_val & BM_BGP_POOL_CFG_AE_THR_MASK) >> BM_BGP_POOL_CFG_AE_THR_OFFS);
+		pr_info("  %-46s0x%08X\n", "pairs",
+				(reg_val & BM_BGP_POOL_CFG_IN_PAIRS_MASK) >> BM_BGP_POOL_CFG_IN_PAIRS_OFFS);
+		pr_info("  %-46s0x%08X\n", "pe_size",
+				(reg_val & BM_BGP_POOL_CFG_PE_SIZE_MASK) >> BM_BGP_POOL_CFG_PE_SIZE_OFFS);
+		pr_info("\n");
+		bm_gl_reg_print("BANK_POOL_STATUS_REG",  BM_BGP_POOL_STATUS_REG(bid, pid_local));
+		reg_val = bm_gl_reg_read(BM_BGP_POOL_STATUS_REG(bid, pid_local));
+	}
+
+	/*---------------------------------------------------------------------*/
+	pr_info("  %-46s0x%08X\n", "nempty",
+			(reg_val & BM_BGP_POOL_STATUS_NEMPTY_MASK) >> BM_BGP_POOL_STATUS_NEMPTY_OFFS);
+	pr_info("  %-46s0x%08X\n", "ae",
+			(reg_val & BM_BGP_POOL_STATUS_AE_MASK) >> BM_BGP_POOL_STATUS_AE_OFFS);
+	pr_info("  %-46s0x%08X\n", "af",
+			(reg_val & BM_BGP_POOL_STATUS_AF_MASK) >> BM_BGP_POOL_STATUS_AF_OFFS);
+	pr_info("  %-46s0x%08X\n", "fill_bgt",
+			(reg_val & BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_MASK) >> BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_OFFS);
+
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS, dpr_c_mng_entry);
+	bm_entry_print("DPR_C_MNG_BANK_STAT", entry_offset, BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS);
+	pr_info("  %-46s0x%08X\n", "cache_start",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_START_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_START_BITS, dpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_end",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_END_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_END_BITS, dpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_si_thr",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_BITS, dpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_so_thr",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_BITS, dpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_vmid",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_BITS, dpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_attr",
+			mv_field_get(BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_OFFS,
+				BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_BITS, dpr_c_mng_entry));
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS, tpr_c_mng_entry);
+	bm_entry_print("TPR_C_MNG_BANK_DYN", entry_offset, BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS);
+
+	pr_info("  %-46s0x%08X\n", "cache_fill_min",
+			mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_OFFS,
+				BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_BITS, tpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_fill_max",
+			mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_OFFS,
+				BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_BITS, tpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_wr_ptr",
+			mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_OFFS,
+				BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_BITS, tpr_c_mng_entry));
+	pr_info("  %-46s0x%08X\n", "cache_rd_ptr",
+			mv_field_get(BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_OFFS,
+				BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_BITS, tpr_c_mng_entry));
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS, dpr_d_mng_entry);
+	bm_entry_print("DPR_D_MNG_BALL_STAT_TBL", entry_offset, BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS);
+
+	pr_info("  %-46s0x%08X\n", "dram_ae_thr",
+			mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_OFFS,
+				BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_BITS, dpr_d_mng_entry));
+	pr_info("  %-46s0x%08X\n", "dram_af_thr",
+			mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_OFFS,
+				BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_BITS, dpr_d_mng_entry));
+	pr_info("  %-46s0x%08X\n", "dram_start_lsb",
+			mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_OFFS,
+				BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_BITS, dpr_d_mng_entry));
+	pr_info("  %-46s0x%08X\n", "dram_start_msb",
+			mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_OFFS,
+				BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_BITS, dpr_d_mng_entry));
+	pr_info("  %-46s0x%08X\n", "dram_size",
+			mv_field_get(BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_OFFS,
+				BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_BITS, dpr_d_mng_entry));
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS, tpr_dro_mng_entry);
+	bm_entry_print("TPR_DRO_MNG_BALL_DYN", entry_offset, BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS);
+	pr_info("  %-46s0x%08X\n", "dram_rd_ptr",
+			mv_field_get(BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_OFFS,
+				BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_BITS, tpr_dro_mng_entry));
+	pr_info("  %-46s0x%08X\n", "dram_wr_ptr",
+			mv_field_get(BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_OFFS,
+				BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_BITS, tpr_dro_mng_entry));
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY(pid_global);
+	bm_entry_read(entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS, drw_mng_ball_entry);
+	bm_entry_print("TPR_DRW_MNG_BALL_DYN", entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS);
+
+	pr_info("  %-46s0x%08X\n", "dram_fill",
+			mv_field_get(BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_OFFS,
+				BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_BITS, drw_mng_ball_entry));
+	/*---------------------------------------------------------------------*/
+	pr_info("\n");
+	entry_offset = BM_TPR_CTRS_BANK_TBL_ENTRY(bid, pid_local);
+	bm_entry_read(entry_offset, BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS, tpr_ctrs_entry);
+	bm_entry_print("TPR_DRW_MNG_BALL_DYN", entry_offset, BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS);
+
+	pr_info("  %-46s0x%08X\n", "delayed_releases_ctr",
+			mv_field_get(BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_OFFS,
+				BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_BITS, tpr_ctrs_entry));
+	pr_info("  %-46s0x%08X\n", "failed_allocs_ctr",
+			mv_field_get(BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_OFFS,
+				BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_BITS, tpr_ctrs_entry));
+	pr_info("  %-46s0x%08X\n", "released_pes_ctr",
+			mv_field_get(BM_TPR_CTRS_BANK_RELEASED_PES_CTR_OFFS,
+				BM_TPR_CTRS_BANK_RELEASED_PES_CTR_BITS, tpr_ctrs_entry));
+	pr_info("  %-46s0x%08X\n", "allocated_pes_ctr",
+			mv_field_get(BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_OFFS,
+				BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_BITS, tpr_ctrs_entry));
+}
+
+
+static void bm_bank0_cache_memory_dump(void)
+{
+	unsigned int sram_cache_entry[BM_SRAM_B0_CACHE_TBL_ENTRY_WORDS];
+	int line, entry_offset;
+
+	pr_info("\n bank 0 cache memory dump:");
+
+	for (line = 0; line < BM_QM_CACHE_LINES; line++) {
+		entry_offset = BM_SRAM_B0_CACHE_TBL_ENTRY(line);
+		bm_entry_read(entry_offset, BM_SRAM_B0_CACHE_TBL_ENTRY_WORDS, sram_cache_entry);
+		pr_info("%4d: 0x%08x    0x%08x    0x%08x    0x%08x\n", line,
+			sram_cache_entry[0], sram_cache_entry[1], sram_cache_entry[2], sram_cache_entry[3]);
+	}
+}
+
+static void bm_bgp_cache_memory_dump(int bank)
+{
+	unsigned int sram_cache_entry[BM_SRAM_BGP_CACHE_TBL_ENTRY_WORDS];
+
+	int line, entry_offset;
+
+	pr_info("\n bank %d cache memory dump:", bank);
+
+	for (line = 0; line < BM_GP_CACHE_LINES; line++) {
+
+		entry_offset = BM_SRAM_BGP_CACHE_TBL_ENTRY(bank, line);
+		bm_entry_read(entry_offset, BM_SRAM_BGP_CACHE_TBL_ENTRY_WORDS, sram_cache_entry);
+
+		pr_info("%4d: 0x%08x    0x%08x\n", line, sram_cache_entry[0], sram_cache_entry[1]);
+	}
+}
+
+
+void bm_bank_cache_dump(int bank)
+{
+	if ((bank < BM_BANK_MIN) || (bank > BM_BANK_MAX)) {
+		pr_err("Invalid bank id %d\n", bank);
+		return;
+	}
+
+	if (bank == 0)
+		bm_bank0_cache_memory_dump();
+	else
+		bm_bgp_cache_memory_dump(bank);
+}
+
+void bm_idle_status_dump(void)
+{
+	char reg_name[50];
+	int bid;
+
+	bm_gl_reg_print("B0_PAST_ALC_FIFOS_STATUS", BM_B0_PAST_ALC_FIFOS_STATUS_REG);
+	bm_gl_reg_print("B0_RELEASE_WRAP_PPE_FIFOS_STATUS", BM_B0_RELEASE_WRAP_PPE_FIFOS_STATUS_REG);
+
+	for (bid = 0; bid < BM_BANK_NUM; bid++) {
+		sprintf(reg_name, "B%d_REQUEST_FIFOS_STATUS", bid);
+		bm_gl_reg_print(reg_name, BM_BANK_REQUEST_FIFOS_STATUS_REG(bid));
+	}
+
+	pr_info("\n for all banks:\n");
+	bm_gl_reg_print("BGP_PAST_ALC_FIFOS_STATUS", BM_BGP_PAST_ALC_FIFOS_FILL_STATUS_REG);
+	bm_gl_reg_print("BM_DM_AXI_FIFOS_STATUS", BM_DM_AXI_FIFOS_STATUS_REG);
+	bm_gl_reg_print("BM_DRM_PENDING_FIFO_STATUS", BM_DRM_PENDING_FIFO_STATUS_REG);
+	bm_gl_reg_print("BM_DM_AXI_WRITE_PENDING_FIFO_STATUS", BM_DM_AXI_WRITE_PENDING_FIFO_STATUS_REG);
+}
+
+void bm_error_dump(void)
+{
+	int bid;
+	char reg_name[50];
+
+
+	for (bid = 0; bid < BM_BANK_NUM; bid++) {
+		pr_info("bank %d innterrupt regs:\n", bid);
+		sprintf(reg_name, "B%d_SYS_REC_INTERRUPT_CAUSE", bid);
+		bm_gl_reg_none_zr_print(reg_name, BM_BANK_SYS_REC_INTERRUPT_CAUSE_REG(bid));
+
+		if (bid == 0) {
+			bm_gl_reg_none_zr_print("B0_POOL_NEMPTY_INTERRUPT_CAUSE",
+						BM_B0_POOL_NEMPTY_INTERRUPT_CAUSE_REG);
+			bm_gl_reg_none_zr_print("B0_AE_INTERRUPT_CAUSE", BM_B0_AE_INTERRUPT_CAUSE_REG);
+			bm_gl_reg_none_zr_print("B0_AF_INTERRUPT_CAUSE", BM_B0_AF_INTERRUPT_CAUSE_REG);
+
+		} else {
+			sprintf(reg_name, "B%d_POOL_NEMPTY_INTERRUPT_CAUSE", bid);
+			bm_gl_reg_none_zr_print(reg_name, BM_BGP_POOL_NEMPTY_INTERRUPT_CAUSE_REG(bid));
+			sprintf(reg_name, "B%d_AE_INTERRUPT_CAUSE", bid);
+			bm_gl_reg_none_zr_print(reg_name, BM_BGP_AE_INTERRUPT_CAUSE_REG(bid));
+			sprintf(reg_name, "B%d_AF_INTERRUPT_CAUSE", bid);
+			bm_gl_reg_none_zr_print(reg_name, BM_BGP_AF_INTERRUPT_CAUSE_REG(bid));
+		}
+	}
+
+	pr_info("global innterrupt regs:\n");
+
+	bm_gl_reg_none_zr_print("SW_DBG_REC_INT_CAUSE", BM_SW_DBG_REC_INT_CAUSE_REG);
+	bm_gl_reg_none_zr_print("ERR_INTERRUPT_CAUSE_REG", BM_ERR_INTERRUPT_CAUSE_REG);
+	bm_gl_reg_none_zr_print("FUNC_INTERRUPT_CAUSE_REG", BM_FUNC_INTERRUPT_CAUSE_REG);
+	bm_gl_reg_none_zr_print("ECC_ERR_INTERRUPT_CAUSE_REG", BM_ECC_ERR_INTERRUPT_CAUSE_REG);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
new file mode 100644
index 0000000..ac47520
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
@@ -0,0 +1,293 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef	__mv_bm_h__
+#define	__mv_bm_h__
+
+#include "common/mv_sw_if.h"
+
+/* QM debug flags */
+#define BM_F_DBG_RD_BIT			0
+#define BM_F_DBG_WR_BIT			1
+
+#define BM_F_DBG_RD			(1 << BM_F_DBG_RD_BIT)
+#define BM_F_DBG_WR			(1 << BM_F_DBG_WR_BIT)
+
+/*----------------------- cache bank memory HW definitions -----------------------*/
+
+#define BM_QM_CACHE_LINES			512
+#define BM_GP_CACHE_LINES			1024 /* 1024 in each bank */
+#define BM_GP_CACHE_LINE_BYTES			8
+#define BM_QM_CACHE_LINE_BYTES			16
+#define BM_CACHE_LINE_BYTES(pool)		((pool >= BM_GP_POOL_MIN) ? \
+						BM_GP_CACHE_LINE_BYTES : BM_QM_CACHE_LINE_BYTES)
+/*
+ * size of PE is always 32 bits for QM pools (0 to 3)
+ * but can be either 32bits or 40 bits for GP pools (8 to 35)
+ */
+
+#define BM_QM_CACHE_PE_BYTES			4
+#define BM_GP_CACHE_PE_BYTES			8
+#define BM_CACHE_PE_BYTES(pool)			((pool >= BM_GP_POOL_MIN) ? \
+							BM_GP_CACHE_PE_BYTES : BM_QM_CACHE_PE_BYTES)
+#define BM_PES_IN_CACHE_LINE(pool)		(BM_CACHE_LINE_BYTES(pool) / BM_CACHE_PE_BYTES(pool))
+
+#define BM_BANK_MIN				0
+#define BM_BANK_MAX				4
+#define BM_QM_BANK_NUM				1
+#define BM_GP_BANK_NUM				4
+#define BM_BANK_NUM				(BM_QM_BANK_NUM + BM_GP_BANK_NUM)
+
+
+#define BM_QM_BANK_POOLS_NUM			(BM_QM_GPM_POOLS_NUM + BM_QM_DRAM_POOLS_NUM)
+#define BM_GP_BANK_POOLS_NUM			7
+#define BM_BANK_POOLS_NUM(bank)			((bank == 0) ? BM_QM_BANK_POOLS_NUM : BM_GP_BANK_POOLS_NUM)
+
+#ifdef CONFIG_MV_PP3_FPGA
+/* FPGA */
+#define BM_QM_GPM_POOL_CAPACITY			512
+#define BM_QM_CACHE_BUF_NUM			(512 - 16)
+#define BM_QM_CACHE_SI				80
+#define BM_QM_CACHE_SO				112
+#else /* CONFIG_MV_PP3_FPGA */
+
+#define BM_QM_GPM_POOL_CAPACITY			6400
+#define BM_QM_CACHE_BUF_NUM			512
+#define BM_QM_CACHE_SI				448
+#define BM_QM_CACHE_SO				480
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+#define BM_QM_DRAM_POOL_CAPACITY		512
+
+/*------------------------ cache memory thresholds ------------------------*/
+
+/* small partition*/
+#define BM_GP_CACHE_BUF_NUM			144
+#define BM_GP_CACHE_SI				(BM_GP_CACHE_BUF_NUM - 32)
+#define BM_GP_CACHE_SO				(BM_GP_CACHE_BUF_NUM - 16)
+
+/*--------------------------- dram definitions ---------------------------*/
+
+#define BM_DRAM_LINE_BYTES			64
+
+#ifdef CONFIG_MV_PP3_FPGA
+#define BM_DRAM_AE(_buf_num_)			80
+#define BM_DRAM_AF(_buf_num_)			112
+#else /* CONFIG_MV_PP3_FPGA */
+#define BM_DRAM_AE(_buf_num_)			(((_buf_num_ * 1/8) > 16) ? MV_ALIGN_DOWN(_buf_num_/8, 16) : 16)
+#define BM_DRAM_AF(_buf_num_)			MV_ALIGN_DOWN((_buf_num_ * 3/4), 16)
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+
+/*--------------------------- pools definitions --------------------------*/
+#define BM_TOT_AE				300 /* total almost empty threshold */
+#define BM_TOT_AAE				400 /* total almost almost empty threshold */
+
+#define BM_QM_GPM_POOL_0			0
+#define BM_QM_GPM_POOL_1			1
+#define BM_QM_GPM_POOLS_NUM			(1 + BM_QM_GPM_POOL_1 - BM_QM_GPM_POOL_0)
+
+#define BM_QM_DRAM_POOL_0			2
+#define BM_QM_DRAM_POOL_1			3
+#define BM_QM_DRAM_POOLS_NUM			(1 + BM_QM_DRAM_POOL_1 - BM_QM_DRAM_POOL_0)
+
+#define BM_GP_POOL_MIN				8
+#define BM_GP_POOL_MAX				35
+#define BM_GP_POOLS_NUM				(BM_GP_BANK_POOLS_NUM * BM_GP_BANK_NUM)
+
+#define BM_POOLS_NUM				(BM_GP_POOL_MAX + 1)
+
+#define BM_IS_QM_GPM_POOL(pool)			(pool < BM_QM_GPM_POOL_0 || pool > BM_QM_GPM_POOL_1)
+
+/* pool 2 buffer size is 1024, pool 3 buffer size is 16 */
+#define BM_QM_DRAM_POOL_BUF_SIZE(pool)		((pool == 2) ? 1024 : 16)
+
+
+
+/*--------------------------- global definitions --------------------------*/
+
+/*
+ * domain read/write for any pool in the range 0 to 3 (2 bits)
+ * Cache read/write for any pool in the range 0 to 15 (4 bits)
+ * QOS read/write for any pool in the range 0 to 3 (2 bits)
+*/
+
+#define BM_AWCACHE				0x7
+#define BM_ARCACHE				0xB
+#define BM_ADOMAIN				0x2
+#define BM_ARQOS				0x1
+#define BM_AWQOS				0x0
+#define BM_VMID					0x0
+#define BM_CACHE_ATTR				0x1
+
+/*--------------------------------- APIs -----------------------------------*/
+
+/* init bm base addres */
+void mv_pp3_bm_init(void __iomem *base);
+
+/* Enable/Disable BM registers read and write dumps */
+void bm_dbg_flags(u32 flag, u32 en);
+
+int bm_gp_pid_validation(int pool);
+
+/**
+ *  Global functions, configures BM attributes for read/write in DRAM
+ *  configures all 12 attributes with default values
+ *  Return values:
+ *		0 - success
+ */
+void bm_attr_all_pools_def_set(void);
+
+/**
+ *  Initiates of GPM pools with default values
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_gpm_pools_def_quick_init(int buf_num, struct mv_a40 *qece_base, struct mv_a40 *pl_base);
+
+/**
+ *  Initiates of DRAM pools with default values
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_dram_pools_def_quick_init(struct device *dev, int buf_num, struct mv_a40 *qece_base, struct mv_a40 *pl_base);
+
+/**
+ *  Basic initialization of general purpose pools with default values
+ *  enable pair mode, disable quick init
+ *  parameters:
+ *   pool - general purpose pools 8 to 35
+ *   buf_num - number of buffers
+ *   base_address - DRAM base address
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_def_basic_init(int pool, int buf_num, struct mv_a40 *base_address);
+
+/**
+ *  Global enable for BM
+ *
+ */
+void bm_enable(void);
+
+/**
+ *  Global disable for BM
+ */
+void bm_disable(void);
+
+
+/**
+ *  Print all global registers
+ *  Return values:
+ *		0 - success
+ */
+void bm_global_registers_dump(void);
+
+/**
+ *  Print values of all BM pool registers
+ *  Return values:
+ *		0 - success
+ */
+void bm_pool_registers_dump(int pool);
+
+/**
+ *  Print parsed values of all BM pool registers
+ */
+void bm_pool_registers_parse(int pool);
+
+
+/**
+ *  Print values of all BM bank registers
+ */
+void bm_bank_registers_dump(int bank);
+
+/**
+ *  Print all 512 lines of cache per input bank sram_b0...b4_cache_mem
+ *  Return values:
+ *		0 - success
+ */
+void bm_bank_cache_dump(int bank);
+
+/**
+ *  Print several registers status that gives indication why BM is busy
+ *  This funciton is useful to call if BM is not reaching idle after a long time.
+ *
+ *  Return values:
+ *		0 - success
+ */
+void bm_idle_status_dump(void);
+
+/**
+ *  Check error bits If set to 1, and print the error that occurred.
+ *  Bit 0 is always an OR of all the other errors.
+ *  So bit 0 with value 0 indicates there are no errors.
+ *
+ *  Return values:
+ *		0 - success
+ */
+void bm_error_dump(void);
+
+/**
+ *  Enables BM pool
+ *
+ *  Note: Must be called after all other pool related configuration is complete
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_enable(int pool);
+/**
+ *  Set Pool to disable - TBD
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_disable(int pool);
+
+
+/**
+ *  Print pool status
+ *
+ *  Return values:
+ *		0 - success
+ */
+
+void bm_pool_status_dump(int pool);
+
+
+/*
+ BM sysFS function
+*/
+
+int mv_pp3_bm_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_bm_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_bm_debug_sysfs_init(struct kobject *pp3_bm_kobj);
+int mv_pp3_bm_debug_sysfs_exit(struct kobject *pp3_bm_kobj);
+
+#endif /* __mv_bm_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_mem.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_mem.h
new file mode 100644
index 0000000..0a0cbd0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_mem.h
@@ -0,0 +1,137 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_bm_mem_h__
+#define __mv_bm_mem_h__
+
+/* SRAM_B0_CACHE Table */
+#define BM_SRAM_B0_CACHE_TBL_ENTRY(i)				(0x4E0000 + i*16)
+#define BM_SRAM_B0_CACHE_TBL_ENTRY_SIZE				(128)
+#define BM_SRAM_B0_CACHE_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_SRAM_B0_CACHE_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_SRAM_B0_CACHE_DATA_3_OFFS				96
+#define BM_SRAM_B0_CACHE_DATA_3_BITS				22
+#define BM_SRAM_B0_CACHE_DATA_2_OFFS				64
+#define BM_SRAM_B0_CACHE_DATA_2_BITS				22
+#define BM_SRAM_B0_CACHE_DATA_1_OFFS				32
+#define BM_SRAM_B0_CACHE_DATA_1_BITS				22
+#define BM_SRAM_B0_CACHE_DATA_0_OFFS				0
+#define BM_SRAM_B0_CACHE_DATA_0_BITS				22
+
+/* SRAM_bank 1-4 CACHE Table */
+#define BM_SRAM_BGP_CACHE_TBL_ENTRY(bid, i)			(0x4E0000 + (bid*0x4000) + i*8)
+#define BM_SRAM_BGP_CACHE_TBL_ENTRY_SIZE			(40)
+#define BM_SRAM_BGP_CACHE_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_SRAM_BGP_CACHE_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_SRAM_BGP_CACHE_DATA_OFFS				0
+#define BM_SRAM_BGP_CACHE_DATA_BITS				40
+
+
+/* dpr c mng bank [0-4] stat table */
+#define BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY(bid, i)		(0x4D0000 + (bid*0x400) + i*16)
+#define BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_SIZE			(96)
+#define BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_DPR_C_MNG_BANK_STAT_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_START_OFFS			0
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_START_BITS			7
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_OFFS		32
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_SI_THR_BITS		11
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_END_OFFS			16
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_END_BITS			7
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_OFFS		48
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_SO_THR_BITS		11
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_OFFS			64
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_ATTR_BITS			8
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_OFFS			80
+#define BM_DPR_C_MNG_BANK_STAT_CACHE_VMID_BITS			8
+
+/* tpr c mng bank [0-4] dyn table */
+#define BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY(bid, i)			(0x4D1400 + (0x200*bid) + i*8)
+#define BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_SIZE			(64)
+#define BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_TPR_C_MNG_BANK_DYN_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_OFFS		0
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MIN_BITS		10
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_OFFS			32
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_RD_PTR_BITS			10
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_OFFS		16
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_FILL_MAX_BITS		10
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_OFFS			48
+#define BM_TPR_C_MNG_BANK_DYN_CACHE_WR_PTR_BITS			10
+
+/* DPR_D_MNG_BALL_STAT Table */
+#define BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY(i)			(0x4D2000 + i*32)
+#define BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_SIZE			(160)
+#define BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_WORDS		        \
+		(MV_ALIGN_UP(BM_DPR_D_MNG_BALL_STAT_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_OFFS			0
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_AE_THR_BITS			18
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_OFFS			32
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_AF_THR_BITS			18
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_OFFS		64
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_START_LSB_BITS		32
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_OFFS		96
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_START_MSB_BITS		8
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_OFFS                  128
+#define BM_DPR_D_MNG_BALL_STAT_DRAM_SIZE_BITS                  18
+
+
+
+/* TPR_DRO_MNG_BALL_DYN Table */
+#define BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY(i)			(0x4D4000 + i*8)
+#define BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_SIZE			(64)
+#define BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_TPR_DRO_MNG_BALL_DYN_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_OFFS		0
+#define BM_TPR_DRO_MNG_BALL_DYN_DRAM_RD_PTR_BITS		21
+#define BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_OFFS		32
+#define BM_TPR_DRO_MNG_BALL_DYN_DRAM_WR_PTR_BITS		21
+
+/* TPR_DRW_MNG_BALL_DYN Table */
+#define BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY(i)			(0x4D4800 + i*4)
+#define BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_SIZE			(32)
+#define BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_TPR_DRW_MNG_BALL_DYN_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_OFFS			0
+#define BM_TPR_DRW_MNG_BALL_DYN_DRAM_FILL_BITS			21
+
+/* tpr cntrs bnak [0-4] table */
+#define BM_TPR_CTRS_BANK_TBL_ENTRY(bid, pid)			(0x4D5000 + (0x400*bid) + (pid*16))
+#define BM_TPR_CTRS_BANK_TBL_ENTRY_SIZE				(128)
+#define BM_TPR_CTRS_BANK_TBL_ENTRY_WORDS			\
+		(MV_ALIGN_UP(BM_TPR_CTRS_BANK_TBL_ENTRY_SIZE, 32) / 32)
+#define BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_OFFS		0
+#define BM_TPR_CTRS_BANK_DELAYED_RELEASES_CTR_BITS		32
+#define BM_TPR_CTRS_BANK_RELEASED_PES_CTR_OFFS			64
+#define BM_TPR_CTRS_BANK_RELEASED_PES_CTR_BITS			32
+#define BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_OFFS			32
+#define BM_TPR_CTRS_BANK_FAILED_ALLOCS_CTR_BITS			32
+#define BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_OFFS			96
+#define BM_TPR_CTRS_BANK_ALLOCATED_PES_CTR_BITS			32
+
+#endif /* __mv_bm_mem_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
new file mode 100644
index 0000000..1abdfba
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
@@ -0,0 +1,267 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_bm_reg_h__
+#define __mv_bm_reg_h__
+
+#define BM_UNIT_OFFS								(0x4D0000)
+
+/* Bank 0 Pool Configuration */
+#define BM_B0_POOL_CFG_REG(_pid_)						(0x8000 + 0x8 * (_pid_))
+#define BM_B0_POOL_CFG_ENABLE_OFFS						0
+#define BM_B0_POOL_CFG_ENABLE_MASK    \
+		(0x00000001 << BM_B0_POOL_CFG_ENABLE_OFFS)
+
+#define BM_B0_POOL_CFG_QUICK_INIT_OFFS						1
+#define BM_B0_POOL_CFG_QUICK_INIT_MASK    \
+		(0x00000001 << BM_B0_POOL_CFG_QUICK_INIT_OFFS)
+
+/* AE and AEE */
+#define BM_B0_POOL_CFG_AE_THR_OFFS						2
+#define BM_B0_POOL_CFG_AE_THR_MASK    \
+		(0x00001fff << BM_B0_POOL_CFG_AE_THR_OFFS)
+
+#define BM_B0_POOL_CFG_AAE_THR_OFFS						15
+#define BM_B0_POOL_CFG_AAE_THR_MASK    \
+		(0x00001fff << BM_B0_POOL_CFG_AAE_THR_OFFS)
+
+
+/* Bank 0 Pool status */
+#define BM_B0_POOL_STATUS_REG(_pid_)						(0x8004 + 0x8 * (_pid_))
+
+/* Bank X [1-4] Pool status */
+#define BM_BGP_POOL_STATUS_REG(_bid_, _pid_)	\
+							(0x8044 + 0x200*((_bid_) - 1) + 0x8 * (_pid_))
+
+/* fields are relevant for Banks 0-4 */
+#define BM_BGP_POOL_STATUS_NEMPTY_OFFS						0
+#define BM_BGP_POOL_STATUS_NEMPTY_MASK    \
+		(0x00000001 << BM_BGP_POOL_STATUS_NEMPTY_OFFS)
+
+#define BM_BGP_POOL_STATUS_AE_OFFS						1
+#define BM_BGP_POOL_STATUS_AE_MASK    \
+		(0x00000001 << BM_BGP_POOL_STATUS_AE_OFFS)
+
+#define BM_BGP_POOL_STATUS_AF_OFFS						2
+#define BM_BGP_POOL_STATUS_AF_MASK    \
+		(0x00000001 << BM_BGP_POOL_STATUS_AF_OFFS)
+
+#define BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_OFFS					3
+#define BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_MASK    \
+		(0x00000001 << BM_BGP_POOL_STATUS_FILL_BGT_SI_THR_OFFS)
+
+
+/* Bank X [1-4] Pool Configuration */
+#define BM_BGP_POOL_CFG_REG(_bid_, _pid_)	\
+							(0x8040 + 0x200*((_bid_) - 1) + 0x8 * (_pid_))
+#define BM_BGP_POOL_CFG_ENABLE_OFFS						0
+#define BM_BGP_POOL_CFG_ENABLE_MASK    \
+		(0x00000001 << BM_BGP_POOL_CFG_ENABLE_OFFS)
+
+#define BM_BGP_POOL_CFG_IN_PAIRS_OFFS						1
+#define BM_BGP_POOL_CFG_IN_PAIRS_MASK    \
+		(0x00000001 << BM_BGP_POOL_CFG_IN_PAIRS_OFFS)
+
+#define BM_BGP_POOL_CFG_PE_SIZE_OFFS						2
+#define BM_BGP_POOL_CFG_PE_SIZE_MASK    \
+		(0x00000001 << BM_BGP_POOL_CFG_PE_SIZE_OFFS)
+
+#define BM_BGP_POOL_CFG_QUICK_INIT_OFFS						3
+#define BM_BGP_POOL_CFG_QUICK_INIT_MASK    \
+		(0x00000001 << BM_BGP_POOL_CFG_QUICK_INIT_OFFS)
+
+#define BM_BGP_POOL_CFG_AE_THR_OFFS						4
+#define BM_BGP_POOL_CFG_AE_THR_MASK    \
+		(0x00001fff << BM_BGP_POOL_CFG_AE_THR_OFFS)
+
+
+/* Bank X [0-4] System Recoverable interrupt mask reg */
+#define BM_BANK_SYS_REC_INTERRUPT_MASK_REG(_bid_)				(0x90a4 + 0x30 * (_bid_))
+/* Bank X [0-4] System Recoverable interrupt cause reg */
+#define BM_BANK_SYS_REC_INTERRUPT_CAUSE_REG(_bid_)				(0x90d0 + 0x30 * (_bid_))
+
+/* B0 Internal Debug Nonrecoverable Bank Status */
+#define BM_B0_INT_DBG_NREC_STATUS_REGG						(0x9080)
+/* Bank X [1-4] Internal Debug Nonrecoverable Bank Status */
+#define BM_BGP_INT_DBG_NREC_STATUS_REG(_bid_)					(0x90c0 + 0x30 * ((_bid_) - 1))
+
+/* B0 Internal Debug Nonrecoverable Pool Status */
+#define BM_B0_INT_DBG_NREC_POOL_STATUS_RE					(0x9090)
+
+/* Bank X [0-4] System Recoverable Bank D0 Status */
+#define BM_BANK_SYS_REC_D0_STATUS_REG(_bid_)					(0x90b0 + 0x30 * (_bid_))
+
+/* Bank X [0-4] System Recoverable Bank D1 Status */
+#define BM_BANK_SYS_REC_D1_STATUS_REG(_bid_)					(0x90b4 + 0x30 * (_bid_))
+
+/* interrupts registers */
+#define BM_SW_DBG_REC_INT_CAUSE_REG						(0x9190)
+#define BM_ERR_INTERRUPT_CAUSE_REG						(0xA000)
+#define BM_FUNC_INTERRUPT_CAUSE_REG						(0xA010)
+#define BM_ECC_ERR_INTERRUPT_CAUSE_REG						(0xA020)
+#define BM_B0_POOL_NEMPTY_INTERRUPT_CAUSE_REG					(0xA040)
+#define BM_BGP_POOL_NEMPTY_INTERRUPT_CAUSE_REG(_bid_)				(0xA060 + (((_bid_) - 1) * 0x10))
+#define BM_B0_AE_INTERRUPT_CAUSE_REG						(0xA048)
+#define BM_B0_AF_INTERRUPT_CAUSE_REG						(0xA050)
+#define BM_BGP_AE_INTERRUPT_CAUSE_REG(_bid_)					(0xA0A0 + (((_bid_) - 1) * 0x10))
+#define BM_BGP_AF_INTERRUPT_CAUSE_REG(_bid_)					(0xA0E0 + (((_bid_) - 1) * 0x10))
+
+/* System Nonrecoverable Common Debug [0-3] Status register*/
+#define BM_SYS_NREC_COMMON_DX_STATUS_REG(i)					(0x91b0 + (i)*4)
+
+/* Common General Configuration */
+#define BM_COMMON_GENERAL_CFG_REG						(0x9300)
+#define BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_OFFS			0
+#define BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_MASK    \
+		(0x000000ff << BM_COMMON_GENERAL_CFG_DRM_SI_DECIDE_EXTRA_FILL_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_DM_VMID_OFFS					8
+#define BM_COMMON_GENERAL_CFG_DM_VMID_MASK    \
+		(0x000000ff << BM_COMMON_GENERAL_CFG_DM_VMID_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_OFFS				16
+#define BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_REQ_RCV_EN_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_DMA_AS_IS_OFFS			17
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_DMA_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_DMA_AS_IS_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_DMA_AS_IS_OFFS			18
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_DMA_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_DMA_AS_IS_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_PPE_AS_IS_OFFS			19
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_PPE_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_PPE_AS_IS_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_PPE_AS_IS_OFFS			20
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_PPE_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_PPE_AS_IS_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_MAC_AS_IS_OFFS			21
+#define BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_MAC_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_ARBURST_FROM_MAC_AS_IS_OFFS)
+
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_MAC_AS_IS_OFFS			22
+#define BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_MAC_AS_IS_MASK    \
+		(0x00000001 << BM_COMMON_GENERAL_CFG_BM_AWBURST_FROM_MAC_AS_IS_OFFS)
+
+
+/* Dram Domain Configuration */
+#define BM_DRAM_DOMAIN_CFG_REG							(0x9304)
+#define BM_DRAM_DOMAIN_CFG_WR_B0_OFFS						0
+#define BM_DRAM_DOMAIN_CFG_WR_B0_MASK    \
+		(0x00000003 << BM_DRAM_DOMAIN_CFG_WR_B0_OFFS)
+
+#define BM_DRAM_DOMAIN_CFG_WR_BGP_OFFS						2
+#define BM_DRAM_DOMAIN_CFG_WR_BGP_MASK    \
+		(0x00000003 << BM_DRAM_DOMAIN_CFG_WR_BGP_OFFS)
+
+#define BM_DRAM_DOMAIN_CFG_RD_B0_OFFS						4
+#define BM_DRAM_DOMAIN_CFG_RD_B0_MASK    \
+		(0x00000003 << BM_DRAM_DOMAIN_CFG_RD_B0_OFFS)
+
+#define BM_DRAM_DOMAIN_CFG_RD_BGP_OFFS						6
+#define BM_DRAM_DOMAIN_CFG_RD_BGP_MASK    \
+		(0x00000003 << BM_DRAM_DOMAIN_CFG_RD_BGP_OFFS)
+
+
+/* Dram Cache Configuration */
+/* TODO - remove fildes offstes if not in use*/
+#define BM_DRAM_CACHE_CFG_REG							(0x9308)
+#define BM_DRAM_CACHE_CFG_WR_B0_OFFS						0
+#define BM_DRAM_CACHE_CFG_WR_B0_MASK    \
+		(0x0000000f << BM_DRAM_CACHE_CFG_WR_B0_OFFS)
+
+#define BM_DRAM_CACHE_CFG_WR_BGP_OFFS						4
+#define BM_DRAM_CACHE_CFG_WR_BGP_MASK    \
+		(0x0000000f << BM_DRAM_CACHE_CFG_WR_BGP_OFFS)
+
+#define BM_DRAM_CACHE_CFG_RD_B0_OFFS						8
+#define BM_DRAM_CACHE_CFG_RD_B0_MASK    \
+		(0x0000000f << BM_DRAM_CACHE_CFG_RD_B0_OFFS)
+
+#define BM_DRAM_CACHE_CFG_RD_BGP_OFFS						12
+#define BM_DRAM_CACHE_CFG_RD_BGP_MASK    \
+		(0x0000000f << BM_DRAM_CACHE_CFG_RD_BGP_OFFS)
+
+
+/* Dram Qos Configuration */
+#define BM_DRAM_QOS_CFG_REG							(0x930c)
+#define BM_DRAM_QOS_CFG_WR_B0_OFFS						0
+#define BM_DRAM_QOS_CFG_WR_B0_MASK    \
+		(0x00000003 << BM_DRAM_QOS_CFG_WR_B0_OFFS)
+
+#define BM_DRAM_QOS_CFG_WR_BGP_OFFS						2
+#define BM_DRAM_QOS_CFG_WR_BGP_MASK    \
+		(0x00000003 << BM_DRAM_QOS_CFG_WR_BGP_OFFS)
+
+#define BM_DRAM_QOS_CFG_RD_B0_OFFS						4
+#define BM_DRAM_QOS_CFG_RD_B0_MASK    \
+		(0x00000003 << BM_DRAM_QOS_CFG_RD_B0_OFFS)
+
+#define BM_DRAM_QOS_CFG_RD_BGP_OFFS						6
+#define BM_DRAM_QOS_CFG_RD_BGP_MASK    \
+		(0x00000003 << BM_DRAM_QOS_CFG_RD_BGP_OFFS)
+
+
+/* Bank X [0-4] Bank Request Fifos Status */
+#define BM_BANK_REQUEST_FIFOS_STATUS_REG(_bid_)					(0xa200 + 4 * (_bid_))
+
+/* B0 Past Alc Fifos Status */
+#define BM_B0_PAST_ALC_FIFOS_STATUS_REG						(0xa220)
+
+/* BANKS 1-4 Past Alc Fifos Status */
+#define BM_BGP_PAST_ALC_FIFOS_FILL_STATUS_REG					(0xa224)
+
+/* B0 Release-wrap-ppe Fifos Status */
+#define BM_B0_RELEASE_WRAP_PPE_FIFOS_STATUS_REG					(0xa230)
+
+/* Dm Axi Fifos Status */
+#define BM_DM_AXI_FIFOS_STATUS_REG						(0xa240)
+
+
+/* Drm Pending Fifo Status */
+#define BM_DRM_PENDING_FIFO_STATUS_REG						(0xa244)
+#define BM_DRM_PENDING_FIFO_STATUS_FILL_OFFS					0
+#define BM_DRM_PENDING_FIFO_STATUS_FILL_MASK    \
+		(0x000000ff << BM_DRM_PENDING_FIFO_STATUS_FILL_OFFS)
+
+
+/* Dm Axi Write Pending Fifo Status */
+#define BM_DM_AXI_WRITE_PENDING_FIFO_STATUS_REG					(0xa248)
+
+
+/* Bm Idle Status */
+#define BM_IDLE_STATUS_REG							(0xa250)
+#define BM_IDLE_STATUS_IDLE_OFFS						0
+#define BM_IDLE_STATUS_IDLE_MASK    \
+		(0x00000001 << BM_IDLE_STATUS_IDLE_OFFS)
+
+#endif /* __mv_bm_reg_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
new file mode 100644
index 0000000..69ed1f3
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
@@ -0,0 +1,183 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "mv_bm.h"
+
+static ssize_t pp3_dev_bm_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                   > regs         - show BM registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                   > err_regs     - show BM erorr registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                   > idle_regs    - show BM idle mode registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [pool] [0|1]     > pool_regs    - show BM pool registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [pool] [0|1]     > pool_enable  - enable/disable BM pool\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [bank]           > bank_regs    - show BM bank registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [bank]           > bank_dump    - show BM bank cache memory\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [mask]           > debug        - Registers read and write debug outputs\n");
+
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [pool]  - pool number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [bank]  - bank number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mask]  - b0:read, b1:write\n");
+
+	return o;
+}
+
+static ssize_t pp3_dev_bm_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char	*name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "regs"))
+		bm_global_registers_dump();
+	else if (!strcmp(name, "err_regs"))
+		bm_error_dump();
+	else if (!strcmp(name, "idle_regs"))
+		bm_idle_status_dump();
+	else
+		off = pp3_dev_bm_help(buf);
+
+	return off;
+}
+
+
+
+static ssize_t pp3_dev_bm_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    a, b, c;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = a = b = c = 0;
+	sscanf(buf, "%d %d %d", &a, &b, &c);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "pool_enable")) {
+		(b == 0) ? bm_pool_disable(a) : bm_pool_enable(a);
+	} else if (!strcmp(name, "pool_regs")) {
+		(b == 0) ? bm_pool_registers_dump(a) :  bm_pool_registers_parse(a);
+	} else if (!strcmp(name, "bank_regs")) {
+		bm_bank_registers_dump(a);
+	} else if (!strcmp(name, "bank_dump")) {
+		bm_bank_cache_dump(a);
+	} else if (!strcmp(name, "debug")) {
+		bm_dbg_flags(BM_F_DBG_RD, a & 0x1);
+		bm_dbg_flags(BM_F_DBG_WR, a & 0x2);
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(pool_regs,		S_IWUSR, NULL, pp3_dev_bm_store);
+static DEVICE_ATTR(pool_enable,		S_IWUSR, NULL, pp3_dev_bm_store);
+static DEVICE_ATTR(bank_regs,		S_IWUSR, NULL, pp3_dev_bm_store);
+static DEVICE_ATTR(bank_dump,		S_IWUSR, NULL, pp3_dev_bm_store);
+static DEVICE_ATTR(debug,		S_IWUSR, NULL, pp3_dev_bm_store);
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_bm_show, NULL);
+static DEVICE_ATTR(err_regs,		S_IRUSR, pp3_dev_bm_show, NULL);
+static DEVICE_ATTR(idle_regs,		S_IRUSR, pp3_dev_bm_show, NULL);
+static DEVICE_ATTR(regs,		S_IRUSR, pp3_dev_bm_show, NULL);
+
+static struct attribute *pp3_dev_bm_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_err_regs.attr,
+	&dev_attr_idle_regs.attr,
+	&dev_attr_bank_regs.attr,
+	&dev_attr_bank_dump.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_pool_regs.attr,
+	&dev_attr_pool_enable.attr,
+	&dev_attr_debug.attr,
+	NULL
+};
+
+static struct attribute_group pp3_dev_bm_group = {
+	.attrs = pp3_dev_bm_attrs,
+};
+
+static struct kobject *bm_kobj;
+
+int mv_pp3_bm_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	bm_kobj = kobject_create_and_add("bm", pp3_kobj);
+	if (!bm_kobj) {
+		printk(KERN_ERR"%s: cannot create bm kobject\n", __func__);
+		return -ENOMEM;
+	}
+	err = sysfs_create_group(bm_kobj, &pp3_dev_bm_group);
+
+	if (err) {
+		pr_err("sysfs group failed %d\n", err);
+		return err;
+	}
+/*
+	TODO .... fix
+	mv_pp3_bm_debug_sysfs_init(bm_kobj);
+*/
+	return err;
+}
+
+int mv_pp3_bm_sysfs_exit(struct kobject *dev_kobj)
+{
+	sysfs_remove_group(bm_kobj, &pp3_dev_bm_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.c b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.c
new file mode 100644
index 0000000..aa36ed8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.c
@@ -0,0 +1,4248 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "common/mv_hw_if.h"
+#include "cmac/mv_cmac_regs.h"
+#include "cmac/mv_eip197_regs.h"
+
+#ifdef PP3_DEBUG
+#define PP3_CMAC_DEBUG pr_info("\n%s::", __func__)
+#else
+#define PP3_CMAC_DEBUG
+#endif
+
+/* debug print flags definition */
+#define MV_PP3_CMAC_READ_DEBUG_BIT	0
+#define MV_PP3_CMAC_WRITE_DEBUG_BIT	1
+
+#define MV_PP3_CMAC_READ_DEBUG		(1 << MV_PP3_CMAC_READ_DEBUG_BIT)
+#define MV_PP3_CMAC_WRITE_DEBUG		(1 << MV_PP3_CMAC_WRITE_DEBUG_BIT)
+
+/* globals */
+static int mv_pp3_cmac_debug_flags;
+static void __iomem *mv_silicon_base;
+
+/*****************************************
+ *     Reigister acccess functions       *
+ *****************************************/
+static u32 mv_pp3_cmac_reg_read(u32 reg)
+{
+	u32 reg_data;
+
+	mv_pp3_hw_read(reg + mv_silicon_base, 1, &reg_data);
+
+	/* debug print */
+	if (mv_pp3_cmac_debug_flags & MV_PP3_CMAC_READ_DEBUG)
+		pr_info("read     : 0x%04x = 0x%08x\n", reg, reg_data);
+
+	return reg_data;
+}
+
+static void mv_pp3_cmac_reg_write(u32 reg, u32 data)
+{
+	mv_pp3_hw_reg_write(reg + mv_silicon_base, data);
+	/* debug print */
+	if (mv_pp3_cmac_debug_flags & MV_PP3_CMAC_WRITE_DEBUG)
+		pr_info("write    : 0x%04x = 0x%08x\n", reg, data);
+}
+
+void mv_cmac_reg_print(char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg, mv_pp3_cmac_reg_read(reg));
+}
+
+/* print value of unit registers */
+void mv_cmac_top_regs_dump(void)
+{
+	int n;
+	char reg_name[32];
+
+	mv_cmac_reg_print("CMAC_STATUS", MV_CMAC_CMAC_STATUS_REG);
+	mv_cmac_reg_print("CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE", MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_REG);
+	mv_cmac_reg_print("CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE", MV_CMAC_CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE_REG);
+	mv_cmac_reg_print("CMAC_IL_ENQ_CHECKSUM_OFFSET", MV_CMAC_CMAC_IL_ENQ_CHECKSUM_OFFSET_REG);
+	mv_cmac_reg_print("CMAC_IL_AXI_CONFIG", MV_CMAC_CMAC_IL_AXI_CONFIG_REG);
+	mv_cmac_reg_print("CMAC_LA_AXI_CONFIG", MV_CMAC_CMAC_LA_AXI_CONFIG_REG);
+	mv_cmac_reg_print("CMAC_DEBUG_IL_FIFO_FILL_LEVEL", MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_REG);
+	mv_cmac_reg_print("CMAC_DEBUG_LA_FIFO_FILL_LEVEL", MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_REG);
+	mv_cmac_reg_print("CMAC_DEBUG_IL_EIP_PCKT_CNT", MV_CMAC_CMAC_DEBUG_IL_EIP_PCKT_CNT_REG);
+	mv_cmac_reg_print("CMAC_DEBUG_LA_EIP_PCKT_CNT", MV_CMAC_CMAC_DEBUG_LA_EIP_PCKT_CNT_REG);
+	for (n = 0; n < 8; n++) {
+		sprintf(reg_name, "CMAC_SPARE%d", n);
+		mv_cmac_reg_print(reg_name, MV_CMAC_CMAC_SPARE_REG(n));
+	}
+}
+
+/* print value of unit registers */
+void mv_cmac_eip197_regs_dump(void)
+{
+	mv_cmac_reg_print("HIA_CDR_0_RING_BASE_ADDR_LO", MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_CDR_0_RING_BASE_ADDR_HI", MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_CDR_0_DATA_BASE_ADDR_LO", MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_CDR_0_DATA_BASE_ADDR_HI", MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_CDR_0_ATOK_BASE_ADDR_LO", MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_CDR_0_ATOK_BASE_ADDR_HI", MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_CDR_0_RING_SIZE", MV_EIP197_HIA_CDR_0_RING_SIZE_REG);
+	mv_cmac_reg_print("HIA_CDR_0_DESC_SIZE", MV_EIP197_HIA_CDR_0_DESC_SIZE_REG);
+	mv_cmac_reg_print("HIA_CDR_0_CFG", MV_EIP197_HIA_CDR_0_CFG_REG);
+	mv_cmac_reg_print("HIA_CDR_0_DMA_CFG", MV_EIP197_HIA_CDR_0_DMA_CFG_REG);
+	mv_cmac_reg_print("HIA_CDR_0_THRESH", MV_EIP197_HIA_CDR_0_THRESH_REG);
+	mv_cmac_reg_print("HIA_CDR_0_COUNT", MV_EIP197_HIA_CDR_0_COUNT_REG);
+	mv_cmac_reg_print("HIA_CDR_0_PROC_COUNT", MV_EIP197_HIA_CDR_0_PROC_COUNT_REG);
+	mv_cmac_reg_print("HIA_CDR_0_PREP_PNTR", MV_EIP197_HIA_CDR_0_PREP_PNTR_REG);
+	mv_cmac_reg_print("HIA_CDR_0_PROC_PNTR", MV_EIP197_HIA_CDR_0_PROC_PNTR_REG);
+	mv_cmac_reg_print("HIA_CDR_0_STAT", MV_EIP197_HIA_CDR_0_STAT_REG);
+	mv_cmac_reg_print("HIA_CDR_0_OPTIONS", MV_EIP197_HIA_CDR_0_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_CDR_0_VERSION", MV_EIP197_HIA_CDR_0_VERSION_REG);
+	mv_cmac_reg_print("HIA_RDR_0_RING_BASE_ADDR_LO", MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_RDR_0_RING_BASE_ADDR_HI", MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_RDR_0_DATA_BASE_ADDR_LO", MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_RDR_0_DATA_BASE_ADDR_HI", MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_RDR_0_RING_SIZE", MV_EIP197_HIA_RDR_0_RING_SIZE_REG);
+	mv_cmac_reg_print("HIA_RDR_0_DESC_SIZE", MV_EIP197_HIA_RDR_0_DESC_SIZE_REG);
+	mv_cmac_reg_print("HIA_RDR_0_CFG", MV_EIP197_HIA_RDR_0_CFG_REG);
+	mv_cmac_reg_print("HIA_RDR_0_DMA_CFG", MV_EIP197_HIA_RDR_0_DMA_CFG_REG);
+	mv_cmac_reg_print("HIA_RDR_0_THRESH", MV_EIP197_HIA_RDR_0_THRESH_REG);
+	mv_cmac_reg_print("HIA_RDR_0_PREP_COUNT", MV_EIP197_HIA_RDR_0_PREP_COUNT_REG);
+	mv_cmac_reg_print("HIA_RDR_0_PROC_COUNT", MV_EIP197_HIA_RDR_0_PROC_COUNT_REG);
+	mv_cmac_reg_print("HIA_RDR_0_PREP_PNTR", MV_EIP197_HIA_RDR_0_PREP_PNTR_REG);
+	mv_cmac_reg_print("HIA_RDR_0_PROC_PNTR", MV_EIP197_HIA_RDR_0_PROC_PNTR_REG);
+	mv_cmac_reg_print("HIA_RDR_0_STAT", MV_EIP197_HIA_RDR_0_STAT_REG);
+	mv_cmac_reg_print("HIA_RDR_0_OPTIONS", MV_EIP197_HIA_RDR_0_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_RDR_0_VERSION", MV_EIP197_HIA_RDR_0_VERSION_REG);
+	mv_cmac_reg_print("HIA_DFE_0_CFG", MV_EIP197_HIA_DFE_0_CFG_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_CTRL", MV_EIP197_HIA_DFE_0_THR_CTRL_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_STAT", MV_EIP197_HIA_DFE_0_THR_STAT_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_DESC_CTRL", MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_DESC_DPTR_LO", MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_LO_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_DESC_DPTR_HI", MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_HI_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_DESC_ACDPTR_LO", MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_LO_REG);
+	mv_cmac_reg_print("HIA_DFE_0_THR_DESC_ACDPTR_HI", MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_HI_REG);
+	mv_cmac_reg_print("HIA_DFE_0_OPTIONS", MV_EIP197_HIA_DFE_0_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_DFE_0_VERSION", MV_EIP197_HIA_DFE_0_VERSION_REG);
+	mv_cmac_reg_print("HIA_DSE_0_CFG", MV_EIP197_HIA_DSE_0_CFG_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_ERROR_STAT", MV_EIP197_HIA_DSE_0_THR_ERROR_STAT_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_CTRL", MV_EIP197_HIA_DSE_0_THR_CTRL_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_STAT", MV_EIP197_HIA_DSE_0_THR_STAT_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_DESC_CTRL", MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_S_DESC_CTRL", MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_DESC_DPTR_LO", MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_LO_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_DESC_DPTR_HI", MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_HI_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_S_DESC_DPTR_LO", MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_LO_REG);
+	mv_cmac_reg_print("HIA_DSE_0_THR_S_DESC_DPTR_HI", MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_HI_REG);
+	mv_cmac_reg_print("HIA_DSE_0_OPTIONS", MV_EIP197_HIA_DSE_0_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_DSE_0_VERSION", MV_EIP197_HIA_DSE_0_VERSION_REG);
+	mv_cmac_reg_print("HIA_RA_PRIO0", MV_EIP197_HIA_RA_PRIO0_REG);
+	mv_cmac_reg_print("HIA_RA_PE_0_CTRL", MV_EIP197_HIA_RA_PE_0_CTRL_REG);
+	mv_cmac_reg_print("HIA_RA_PE_0_STAT", MV_EIP197_HIA_RA_PE_0_STAT_REG);
+	mv_cmac_reg_print("HIA_AIC_G_POL_CTRL", MV_EIP197_HIA_AIC_G_POL_CTRL_REG);
+	mv_cmac_reg_print("HIA_AIC_G_TYPE_CTRL", MV_EIP197_HIA_AIC_G_TYPE_CTRL_REG);
+	mv_cmac_reg_print("HIA_AIC_G_ENABLE_CTRL", MV_EIP197_HIA_AIC_G_ENABLE_CTRL_REG);
+	mv_cmac_reg_print("HIA_AIC_G_RAW_STAT", MV_EIP197_HIA_AIC_G_RAW_STAT_REG);
+	mv_cmac_reg_print("HIA_AIC_G_ENABLED_STAT", MV_EIP197_HIA_AIC_G_ENABLED_STAT_REG);
+	mv_cmac_reg_print("HIA_AIC_G_ENABLE_CLR", MV_EIP197_HIA_AIC_G_ENABLE_CLR_REG);
+	mv_cmac_reg_print("HIA_AIC_G_OPTIONS", MV_EIP197_HIA_AIC_G_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_AIC_G_VERSION", MV_EIP197_HIA_AIC_G_VERSION_REG);
+	mv_cmac_reg_print("HIA_CLUST_CTRL_0", MV_EIP197_HIA_CLUST_CTRL_0_REG);
+	mv_cmac_reg_print("HIA_CLUST_CTRL_1", MV_EIP197_HIA_CLUST_CTRL_1_REG);
+	mv_cmac_reg_print("HIA_CLUST_CTRL_2", MV_EIP197_HIA_CLUST_CTRL_2_REG);
+	mv_cmac_reg_print("HIA_CLUST_CTRL_3", MV_EIP197_HIA_CLUST_CTRL_3_REG);
+	mv_cmac_reg_print("HIA_LASIDE_BASE_ADDR_LO", MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_REG);
+	mv_cmac_reg_print("HIA_LASIDE_BASE_ADDR_HI", MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_REG);
+	mv_cmac_reg_print("HIA_LASIDE_SLAVE_CTRL_1", MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_REG);
+	mv_cmac_reg_print("HIA_LASIDE_MASTER_CTRL_1", MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_REG);
+	mv_cmac_reg_print("HIA_INLINE_CTRL_0", MV_EIP197_HIA_INLINE_CTRL_0_REG);
+	mv_cmac_reg_print("HIA_MST_TIMEOUT_ERR_0", MV_EIP197_HIA_MST_TIMEOUT_ERR_0_REG);
+	mv_cmac_reg_print("HIA_OPTIONS2", MV_EIP197_HIA_OPTIONS2_REG);
+	mv_cmac_reg_print("HIA_MST_CTRL", MV_EIP197_HIA_MST_CTRL_REG);
+	mv_cmac_reg_print("HIA_OPTIONS", MV_EIP197_HIA_OPTIONS_REG);
+	mv_cmac_reg_print("HIA_VERSION", MV_EIP197_HIA_VERSION_REG);
+	mv_cmac_reg_print("PE_0_IN_DBUF_THRESH", MV_EIP197_PE_0_IN_DBUF_THRESH_REG);
+	mv_cmac_reg_print("PE_0_IN_TBUF_THRESH", MV_EIP197_PE_0_IN_TBUF_THRESH_REG);
+	mv_cmac_reg_print("PE_0_ICE_ADAPT_CTRL", MV_EIP197_PE_0_ICE_ADAPT_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_PUE_CTRL", MV_EIP197_PE_0_ICE_PUE_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_PUE_DEBUG", MV_EIP197_PE_0_ICE_PUE_DEBUG_REG);
+	mv_cmac_reg_print("PE_0_ICE_PUTF_CTRL", MV_EIP197_PE_0_ICE_PUTF_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_SCRATCH_CTRL", MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_TIMER_LO", MV_EIP197_PE_0_ICE_TIMER_LO_REG);
+	mv_cmac_reg_print("PE_0_ICE_TIMER_HI", MV_EIP197_PE_0_ICE_TIMER_HI_REG);
+	mv_cmac_reg_print("PE_0_ICE_UENG_STAT", MV_EIP197_PE_0_ICE_UENG_STAT_REG);
+	mv_cmac_reg_print("PE_0_ICE_FPP_CTRL", MV_EIP197_PE_0_ICE_FPP_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_FPP_DEBUG", MV_EIP197_PE_0_ICE_FPP_DEBUG_REG);
+	mv_cmac_reg_print("PE_0_ICE_PPTF_CTRL", MV_EIP197_PE_0_ICE_PPTF_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_RAM_CTRL", MV_EIP197_PE_0_ICE_RAM_CTRL_REG);
+	mv_cmac_reg_print("PE_0_ICE_OPTIONS", MV_EIP197_PE_0_ICE_OPTIONS_REG);
+	mv_cmac_reg_print("PE_0_ICE_VERSION", MV_EIP197_PE_0_ICE_VERSION_REG);
+	mv_cmac_reg_print("PE_0_EIP96_TOKEN_CTRL_STAT", MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_FUNCTION_EN", MV_EIP197_PE_0_EIP96_FUNCTION_EN_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CONTEXT_CTRL", MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CONTEXT_STAT", MV_EIP197_PE_0_EIP96_CONTEXT_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_OUT_TRANS_CTRL_STAT", MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_OUT_BUF_CTRL", MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_STAT", MV_EIP197_PE_0_EIP96_PRNG_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_CTRL", MV_EIP197_PE_0_EIP96_PRNG_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_SEED_L", MV_EIP197_PE_0_EIP96_PRNG_SEED_L_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_SEED_H", MV_EIP197_PE_0_EIP96_PRNG_SEED_H_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_KEY_0_L", MV_EIP197_PE_0_EIP96_PRNG_KEY_0_L_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_KEY_0_H", MV_EIP197_PE_0_EIP96_PRNG_KEY_0_H_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_KEY_1_L", MV_EIP197_PE_0_EIP96_PRNG_KEY_1_L_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_KEY_1_H", MV_EIP197_PE_0_EIP96_PRNG_KEY_1_H_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_RES_0", MV_EIP197_PE_0_EIP96_PRNG_RES_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_RES_1", MV_EIP197_PE_0_EIP96_PRNG_RES_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_RES_2", MV_EIP197_PE_0_EIP96_PRNG_RES_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_RES_3", MV_EIP197_PE_0_EIP96_PRNG_RES_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_LFSR_L", MV_EIP197_PE_0_EIP96_PRNG_LFSR_L_REG);
+	mv_cmac_reg_print("PE_0_EIP96_PRNG_LFSR_H", MV_EIP197_PE_0_EIP96_PRNG_LFSR_H_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W0", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W1", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W2", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W3", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W4", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W5", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W6", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W7", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W8", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W9", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W10", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W10_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W11", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W11_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W12", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W12_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W13", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W13_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W14", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W14_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W15", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W15_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W16", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W16_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W17", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W17_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W18", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W18_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W19", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W19_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W20", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W20_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W21", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W21_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W22", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W22_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W23", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W23_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W24", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W24_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W25", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W25_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W26", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W26_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W27", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W27_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W28", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W28_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W29", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W29_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W30", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W30_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_TOKEN_W31", MV_EIP197_PE_0_EIP96_CUR_TOKEN_W31_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W0", MV_EIP197_PE_0_EIP96_RES_TOKEN_W0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W1", MV_EIP197_PE_0_EIP96_RES_TOKEN_W1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W2", MV_EIP197_PE_0_EIP96_RES_TOKEN_W2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W3", MV_EIP197_PE_0_EIP96_RES_TOKEN_W3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W4", MV_EIP197_PE_0_EIP96_RES_TOKEN_W4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W5", MV_EIP197_PE_0_EIP96_RES_TOKEN_W5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W6", MV_EIP197_PE_0_EIP96_RES_TOKEN_W6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_TOKEN_W7", MV_EIP197_PE_0_EIP96_RES_TOKEN_W7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_CONTEXT_CMD_0", MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_CONTEXT_CMD_1", MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_GENERAL_PUR_0", MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_GENERAL_PUR_1", MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IV_0", MV_EIP197_PE_0_EIP96_NXT_IV_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IV_1", MV_EIP197_PE_0_EIP96_NXT_IV_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IV_2", MV_EIP197_PE_0_EIP96_NXT_IV_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IV_3", MV_EIP197_PE_0_EIP96_NXT_IV_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_0", MV_EIP197_PE_0_EIP96_NXT_KEY_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_1", MV_EIP197_PE_0_EIP96_NXT_KEY_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_2", MV_EIP197_PE_0_EIP96_NXT_KEY_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_3", MV_EIP197_PE_0_EIP96_NXT_KEY_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_4", MV_EIP197_PE_0_EIP96_NXT_KEY_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_5", MV_EIP197_PE_0_EIP96_NXT_KEY_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_6", MV_EIP197_PE_0_EIP96_NXT_KEY_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_KEY_7", MV_EIP197_PE_0_EIP96_NXT_KEY_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_0", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_1", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_2", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_3", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_4", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_5", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_6", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_7", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_0", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_1", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_2", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_3", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_4", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_5", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_6", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_7", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_DIGEST_CNT", MV_EIP197_PE_0_EIP96_NXT_DIGEST_CNT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SPI_SSRC", MV_EIP197_PE_0_EIP96_NXT_SPI_SSRC_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SEQNUM", MV_EIP197_PE_0_EIP96_NXT_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_EXT_SEQNUM", MV_EIP197_PE_0_EIP96_NXT_EXT_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SEQNUM_MASK_0", MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SEQNUM_MASK_1", MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SEQNUM_MASK_2", MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_SEQNUM_MASK_3", MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_CHECKSUM", MV_EIP197_PE_0_EIP96_NXT_CHECKSUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ARC4_IJ_PNTR", MV_EIP197_PE_0_EIP96_NXT_ARC4_IJ_PNTR_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ARC4_PNTR", MV_EIP197_PE_0_EIP96_NXT_ARC4_PNTR_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_CONTEXT_CMD_0", MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_CONTEXT_CMD_1", MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_GENERAL_PUR_0", MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_GENERAL_PUR_1", MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IV_0", MV_EIP197_PE_0_EIP96_CUR_IV_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IV_1", MV_EIP197_PE_0_EIP96_CUR_IV_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IV_2", MV_EIP197_PE_0_EIP96_CUR_IV_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IV_3", MV_EIP197_PE_0_EIP96_CUR_IV_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_0", MV_EIP197_PE_0_EIP96_CUR_KEY_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_1", MV_EIP197_PE_0_EIP96_CUR_KEY_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_2", MV_EIP197_PE_0_EIP96_CUR_KEY_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_3", MV_EIP197_PE_0_EIP96_CUR_KEY_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_4", MV_EIP197_PE_0_EIP96_CUR_KEY_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_5", MV_EIP197_PE_0_EIP96_CUR_KEY_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_6", MV_EIP197_PE_0_EIP96_CUR_KEY_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_KEY_7", MV_EIP197_PE_0_EIP96_CUR_KEY_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_0", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_1", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_2", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_3", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_4", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_5", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_6", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_7", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_0", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_1", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_2", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_3", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_4", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_5", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_6", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_7", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_DIGEST_CNT", MV_EIP197_PE_0_EIP96_CUR_DIGEST_CNT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SPI_SSRC", MV_EIP197_PE_0_EIP96_CUR_SPI_SSRC_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SEQNUM", MV_EIP197_PE_0_EIP96_CUR_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_EXT_SEQNUM", MV_EIP197_PE_0_EIP96_CUR_EXT_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SEQNUM_MASK_0", MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SEQNUM_MASK_1", MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SEQNUM_MASK_2", MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_SEQNUM_MASK_3", MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_CHECKSUM", MV_EIP197_PE_0_EIP96_CUR_CHECKSUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ARC4_IJ_PNTR", MV_EIP197_PE_0_EIP96_CUR_ARC4_IJ_PNTR_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ARC4_PNTR", MV_EIP197_PE_0_EIP96_CUR_ARC4_PNTR_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_0", MV_EIP197_PE_0_EIP96_RES_HASH_0_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_1", MV_EIP197_PE_0_EIP96_RES_HASH_1_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_2", MV_EIP197_PE_0_EIP96_RES_HASH_2_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_3", MV_EIP197_PE_0_EIP96_RES_HASH_3_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_4", MV_EIP197_PE_0_EIP96_RES_HASH_4_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_5", MV_EIP197_PE_0_EIP96_RES_HASH_5_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_6", MV_EIP197_PE_0_EIP96_RES_HASH_6_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_7", MV_EIP197_PE_0_EIP96_RES_HASH_7_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_DIGEST_CNT", MV_EIP197_PE_0_EIP96_RES_DIGEST_CNT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_SPI_SSRC", MV_EIP197_PE_0_EIP96_RES_SPI_SSRC_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_SEQNUM", MV_EIP197_PE_0_EIP96_RES_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_EXT_SEQNUM", MV_EIP197_PE_0_EIP96_RES_EXT_SEQNUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_CHECKSUM", MV_EIP197_PE_0_EIP96_RES_CHECKSUM_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_8", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_9", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_A", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_A_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_B", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_B_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_C", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_C_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_D", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_D_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_E", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_E_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_IDIGEST_F", MV_EIP197_PE_0_EIP96_NXT_IDIGEST_F_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_8", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_9", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_A", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_A_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_B", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_B_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_C", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_C_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_D", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_D_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_E", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_E_REG);
+	mv_cmac_reg_print("PE_0_EIP96_NXT_ODIGEST_F", MV_EIP197_PE_0_EIP96_NXT_ODIGEST_F_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_8", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_9", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_A", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_A_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_B", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_B_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_C", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_C_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_D", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_D_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_E", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_E_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_IDIGEST_F", MV_EIP197_PE_0_EIP96_CUR_IDIGEST_F_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_8", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_9", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_A", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_A_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_B", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_B_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_C", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_C_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_D", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_D_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_E", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_E_REG);
+	mv_cmac_reg_print("PE_0_EIP96_CUR_ODIGEST_F", MV_EIP197_PE_0_EIP96_CUR_ODIGEST_F_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_8", MV_EIP197_PE_0_EIP96_RES_HASH_8_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_9", MV_EIP197_PE_0_EIP96_RES_HASH_9_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_A", MV_EIP197_PE_0_EIP96_RES_HASH_A_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_B", MV_EIP197_PE_0_EIP96_RES_HASH_B_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_C", MV_EIP197_PE_0_EIP96_RES_HASH_C_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_D", MV_EIP197_PE_0_EIP96_RES_HASH_D_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_E", MV_EIP197_PE_0_EIP96_RES_HASH_E_REG);
+	mv_cmac_reg_print("PE_0_EIP96_RES_HASH_F", MV_EIP197_PE_0_EIP96_RES_HASH_F_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_POL_CTRL", MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_TYPE_CTRL", MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_ENABLE_CTRL", MV_EIP197_PE_0_EIP96_AIC_ENABLE_CTRL_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_RAW_STAT", MV_EIP197_PE_0_EIP96_AIC_RAW_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_ENABLED_STAT", MV_EIP197_PE_0_EIP96_AIC_ENABLED_STAT_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_ENABLE_CLR", MV_EIP197_PE_0_EIP96_AIC_ENABLE_CLR_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_OPTIONS", MV_EIP197_PE_0_EIP96_AIC_OPTIONS_REG);
+	mv_cmac_reg_print("PE_0_EIP96_AIC_VERSION", MV_EIP197_PE_0_EIP96_AIC_VERSION_REG);
+	mv_cmac_reg_print("PE_0_EIP96_OPTIONS", MV_EIP197_PE_0_EIP96_OPTIONS_REG);
+	mv_cmac_reg_print("PE_0_EIP96_VERSION", MV_EIP197_PE_0_EIP96_VERSION_REG);
+	mv_cmac_reg_print("PE_0_OUT_DBUF_THRESH", MV_EIP197_PE_0_OUT_DBUF_THRESH_REG);
+	mv_cmac_reg_print("PE_0_OUT_TBUF_THRESH", MV_EIP197_PE_0_OUT_TBUF_THRESH_REG);
+	mv_cmac_reg_print("PE_0_AIC_POL_CTRL", MV_EIP197_PE_0_AIC_POL_CTRL_REG);
+	mv_cmac_reg_print("PE_0_AIC_TYPE_CTRL", MV_EIP197_PE_0_AIC_TYPE_CTRL_REG);
+	mv_cmac_reg_print("PE_0_AIC_ENABLE_CTRL", MV_EIP197_PE_0_AIC_ENABLE_CTRL_REG);
+	mv_cmac_reg_print("PE_0_AIC_RAW_STAT", MV_EIP197_PE_0_AIC_RAW_STAT_REG);
+	mv_cmac_reg_print("PE_0_AIC_ENABLED_STAT", MV_EIP197_PE_0_AIC_ENABLED_STAT_REG);
+	mv_cmac_reg_print("PE_0_AIC_ENABLE_CLR", MV_EIP197_PE_0_AIC_ENABLE_CLR_REG);
+	mv_cmac_reg_print("PE_0_AIC_OPTIONS", MV_EIP197_PE_0_AIC_OPTIONS_REG);
+	mv_cmac_reg_print("PE_0_AIC_VERSION", MV_EIP197_PE_0_AIC_VERSION_REG);
+	mv_cmac_reg_print("PE_0_PE_ARC4_SIZE", MV_EIP197_PE_0_PE_ARC4_SIZE_REG);
+	mv_cmac_reg_print("PE_0_PE_IN_FLIGHT", MV_EIP197_PE_0_PE_IN_FLIGHT_REG);
+	mv_cmac_reg_print("PE_0_PE_DEBUG", MV_EIP197_PE_0_PE_DEBUG_REG);
+	mv_cmac_reg_print("PE_0_PE_OPTIONS", MV_EIP197_PE_0_PE_OPTIONS_REG);
+	mv_cmac_reg_print("PE_0_PE_VERSION", MV_EIP197_PE_0_PE_VERSION_REG);
+	mv_cmac_reg_print("FRC_0_CTRL", MV_EIP197_FRC_0_CTRL_REG);
+	mv_cmac_reg_print("FRC_0_LASTRES", MV_EIP197_FRC_0_LASTRES_REG);
+	mv_cmac_reg_print("FRC_0_REGINDEX", MV_EIP197_FRC_0_REGINDEX_REG);
+	mv_cmac_reg_print("FRC_0_PARAMS", MV_EIP197_FRC_0_PARAMS_REG);
+	mv_cmac_reg_print("FRC_0_FREECHAIN", MV_EIP197_FRC_0_FREECHAIN_REG);
+	mv_cmac_reg_print("FRC_0_PARAMS2", MV_EIP197_FRC_0_PARAMS2_REG);
+	mv_cmac_reg_print("TRC_0_CTRL", MV_EIP197_TRC_0_CTRL_REG);
+	mv_cmac_reg_print("TRC_0_LASTRES", MV_EIP197_TRC_0_LASTRES_REG);
+	mv_cmac_reg_print("TRC_0_REGINDEX", MV_EIP197_TRC_0_REGINDEX_REG);
+	mv_cmac_reg_print("TRC_0_PARAMS", MV_EIP197_TRC_0_PARAMS_REG);
+	mv_cmac_reg_print("TRC_0_FREECHAIN", MV_EIP197_TRC_0_FREECHAIN_REG);
+	mv_cmac_reg_print("TRC_0_PARAMS2", MV_EIP197_TRC_0_PARAMS2_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_0_LO", MV_EIP197_FLUE_CACHEBASE_0_LO_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_0_HI", MV_EIP197_FLUE_CACHEBASE_0_HI_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_0_LO", MV_EIP197_FLUE_HASHBASE_0_LO_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_0_HI", MV_EIP197_FLUE_HASHBASE_0_HI_REG);
+	mv_cmac_reg_print("FLUE_CONFIG_0", MV_EIP197_FLUE_CONFIG_0_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_1_LO", MV_EIP197_FLUE_CACHEBASE_1_LO_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_1_HI", MV_EIP197_FLUE_CACHEBASE_1_HI_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_1_LO", MV_EIP197_FLUE_HASHBASE_1_LO_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_1_HI", MV_EIP197_FLUE_HASHBASE_1_HI_REG);
+	mv_cmac_reg_print("FLUE_CONFIG_1", MV_EIP197_FLUE_CONFIG_1_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_2_LO", MV_EIP197_FLUE_CACHEBASE_2_LO_REG);
+	mv_cmac_reg_print("FLUE_CACHEBASE_2_HI", MV_EIP197_FLUE_CACHEBASE_2_HI_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_2_LO", MV_EIP197_FLUE_HASHBASE_2_LO_REG);
+	mv_cmac_reg_print("FLUE_HASHBASE_2_HI", MV_EIP197_FLUE_HASHBASE_2_HI_REG);
+	mv_cmac_reg_print("FLUE_CONFIG_2", MV_EIP197_FLUE_CONFIG_2_REG);
+	mv_cmac_reg_print("FLUE_OFFSETS", MV_EIP197_FLUE_OFFSETS_REG);
+	mv_cmac_reg_print("FLUE_ARC4_OFFSET", MV_EIP197_FLUE_ARC4_OFFSET_REG);
+	mv_cmac_reg_print("FLUE_IFC_LUT_0", MV_EIP197_FLUE_IFC_LUT_0_REG);
+	mv_cmac_reg_print("FLUE_ENABLED_LO", MV_EIP197_FLUE_ENABLED_LO_REG);
+	mv_cmac_reg_print("FLUE_ERROR_LO", MV_EIP197_FLUE_ERROR_LO_REG);
+	mv_cmac_reg_print("FHASH_IV_0", MV_EIP197_FHASH_IV_0_REG);
+	mv_cmac_reg_print("FHASH_IV_1", MV_EIP197_FHASH_IV_1_REG);
+	mv_cmac_reg_print("FHASH_IV_2", MV_EIP197_FHASH_IV_2_REG);
+	mv_cmac_reg_print("FHASH_IV_3", MV_EIP197_FHASH_IV_3_REG);
+	mv_cmac_reg_print("CS_AIC_POL_CTRL", MV_EIP197_CS_AIC_POL_CTRL_REG);
+	mv_cmac_reg_print("CS_AIC_TYPE_CTRL", MV_EIP197_CS_AIC_TYPE_CTRL_REG);
+	mv_cmac_reg_print("CS_AIC_ENABLE_CTRL", MV_EIP197_CS_AIC_ENABLE_CTRL_REG);
+	mv_cmac_reg_print("CS_AIC_RAW_STAT", MV_EIP197_CS_AIC_RAW_STAT_REG);
+	mv_cmac_reg_print("CS_AIC_ENABLED_STAT", MV_EIP197_CS_AIC_ENABLED_STAT_REG);
+	mv_cmac_reg_print("CS_AIC_ENABLE_CLR", MV_EIP197_CS_AIC_ENABLE_CLR_REG);
+	mv_cmac_reg_print("CS_AIC_OPTIONS", MV_EIP197_CS_AIC_OPTIONS_REG);
+	mv_cmac_reg_print("CS_AIC_VERSION", MV_EIP197_CS_AIC_VERSION_REG);
+	mv_cmac_reg_print("CS_RAM_CTRL", MV_EIP197_CS_RAM_CTRL_REG);
+	mv_cmac_reg_print("CS_OPTIONS", MV_EIP197_CS_OPTIONS_REG);
+	mv_cmac_reg_print("CS_VERSION", MV_EIP197_CS_VERSION_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_COUNT_0", MV_EIP197_EIP197_DBG_PIPE_COUNT_0_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_STATE_0", MV_EIP197_EIP197_DBG_PIPE_STATE_0_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_DCOUNT_LO_0", MV_EIP197_EIP197_DBG_PIPE_DCOUNT_LO_0_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_DCOUNT_HI_0", MV_EIP197_EIP197_DBG_PIPE_DCOUNT_HI_0_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_PEND_SEQ_0", MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_REG);
+	mv_cmac_reg_print("EIP197_DBG_PIPE_PEND_LEN_0", MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_SELECT_0", MV_EIP197_EIP197_DEBUG_SELECT_0_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_SELECT_1", MV_EIP197_EIP197_DEBUG_SELECT_1_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_SELECT_2", MV_EIP197_EIP197_DEBUG_SELECT_2_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_SELECT_3", MV_EIP197_EIP197_DEBUG_SELECT_3_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_PROBE_0", MV_EIP197_EIP197_DEBUG_PROBE_0_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_PROBE_1", MV_EIP197_EIP197_DEBUG_PROBE_1_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_PROBE_2", MV_EIP197_EIP197_DEBUG_PROBE_2_REG);
+	mv_cmac_reg_print("EIP197_DEBUG_PROBE_3", MV_EIP197_EIP197_DEBUG_PROBE_3_REG);
+	mv_cmac_reg_print("EIP197_CLOCK_STATE", MV_EIP197_EIP197_CLOCK_STATE_REG);
+	mv_cmac_reg_print("EIP197_FORCE_CLOCK_ON", MV_EIP197_EIP197_FORCE_CLOCK_ON_REG);
+	mv_cmac_reg_print("EIP197_FORCE_CLOCK_OFF", MV_EIP197_EIP197_FORCE_CLOCK_OFF_REG);
+	mv_cmac_reg_print("EIP197_MST_CTRL", MV_EIP197_EIP197_MST_CTRL_REG);
+	mv_cmac_reg_print("EIP197_OPTIONS", MV_EIP197_EIP197_OPTIONS_REG);
+	mv_cmac_reg_print("EIP197_VERSION", MV_EIP197_EIP197_VERSION_REG);
+}
+
+/* debug functions */
+void mv_pp3_cmac_debug_cfg(int flags)
+{
+	mv_pp3_cmac_debug_flags = flags;
+}
+
+void mv_pp3_cmac_init(void __iomem *base)
+{
+	mv_silicon_base = base;
+}
+
+/* CMAC EIP 197 unit configuration */
+void mv_pp3_cmac_config(void)
+{
+	u32 reg_data;
+	u32 times;
+	int i;
+
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_MST_CTRL_REG, 0xfe000033);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG, 0x1f000000);
+	for (i = 14; i < 22; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_RAM + i*4, 0x00000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DFE_0_CFG_REG, 0xa7050905);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_CFG_REG, 0x80008807);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_IN_TBUF_THRESH_REG, 0x00007500);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_IN_DBUF_THRESH_REG, 0x00009500);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_OUT_DBUF_THRESH_REG, 0x00000087);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_REG, 0x00410000);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_REG, 0x00000235);
+
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG, 0x80000000);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG, 0xc0000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_INLINE_CTRL_0_REG, 0x00387000);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_SEED_L_REG, 0xd82c07cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_SEED_H_REG, 0xc2094cbc);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_KEY_0_L_REG, 0x6baa9441);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_KEY_0_H_REG, 0x42485e3e);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_KEY_1_L_REG, 0x82e2e66f);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_KEY_1_H_REG, 0x67a9c37d);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_LFSR_L_REG, 0xc8a7063a);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_LFSR_H_REG, 0x4da5e71e);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_EIP96_PRNG_CTRL_REG, 0x00000003);
+	mv_pp3_cmac_reg_write(MV_EIP197_FLUE_IFC_LUT_0_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_FLUE_CONFIG_0_REG, 0xc0000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_FLUE_CONFIG_1_REG, 0xc0000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_FLUE_CONFIG_2_REG, 0xc0000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG, 0x11000000);
+
+	for (i = 0; i < 256; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_RAM + i*4, 0x00000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_FPP_CTRL_REG, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_RAM_CTRL_REG, 0x00000002);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 0, 0x21008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1, 0x22808004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2, 0x27808010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3, 0x23208060);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 4, 0x001df00e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 5, 0x60830056);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 6, 0x24808008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 7, 0x2580800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 8, 0x1079e4c4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 9, 0x60030061);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 10, 0x10499002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 11, 0x6083003a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 12, 0x205577fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 13, 0x26d40000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 14, 0x0e29f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 15, 0x0e300c00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 16, 0x2500802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 17, 0x23008020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 18, 0x10499001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 19, 0x600b0036);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 20, 0x21df80bc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 21, 0x0335ca80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 22, 0x25508098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 23, 0x75700398);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 24, 0x807689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 25, 0x89a68076);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 26, 0x00898061);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 27, 0x09a6808d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 28, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 29, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 30, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 31, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 32, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 33, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 34, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 35, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 36, 0x00948094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 37, 0x00948094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 38, 0x00948094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 39, 0x00948094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 40, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 41, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 42, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 43, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 44, 0x007b807b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 45, 0x007b807b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 46, 0x007b807b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 47, 0x007b807b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 48, 0x89778983);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 49, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 50, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 51, 0x09a689a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 52, 0x00858085);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 53, 0x202071dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 54, 0x21df80f4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 55, 0x0335ca80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 56, 0x255080d0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 57, 0x60800017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 58, 0x10499001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 59, 0x6003004a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 60, 0x20c577fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 61, 0x26440000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 62, 0x24c08014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 63, 0x25408018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 64, 0xb1128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 65, 0x0006e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 66, 0x60010974);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 67, 0x20847008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 68, 0x06499003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 69, 0x1069e002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 70, 0x6009800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 71, 0x2085700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 72, 0x60008017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 73, 0xaf000040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 74, 0x004de00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 75, 0x60830006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 76, 0x104d9000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 77, 0x608b0051);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 78, 0x71400022);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 79, 0x897a0051);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 80, 0x0980097d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 81, 0x0e29f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 82, 0x0e300c00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 83, 0x0f100000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 84, 0x60008017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 85, 0xbff08040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 86, 0x08090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 87, 0x218087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 88, 0x111a93ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 89, 0x111ae200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 90, 0x6081005e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 91, 0x6083005f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 92, 0x5b880000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 93, 0x60800059);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 94, 0x011ac200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 95, 0x5b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 96, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 97, 0x00499003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 98, 0x60830999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 99, 0x0b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 100, 0x43804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 101, 0x080a0018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 102, 0x218087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 103, 0x111a93ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 104, 0x011ae018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 105, 0x111ae200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 106, 0x6081006e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 107, 0x6083006f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 108, 0x5b880000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 109, 0x60800069);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 110, 0x011ac200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 111, 0x5b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 112, 0x22008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 113, 0xd22f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 114, 0x2320e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 115, 0x2420f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 116, 0x60808932);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 117, 0x17090001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 118, 0xa0f19000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 119, 0x600b0999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 120, 0xa0f09040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 121, 0x60030094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 122, 0x6000093e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 123, 0x278080b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 124, 0x00799081);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 125, 0x6003007f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 126, 0xaff28400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 127, 0xa0f19000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 128, 0x608b8999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 129, 0x20a771dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 130, 0xa0f09040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 131, 0x60030094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 132, 0x6000093e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 133, 0xa0f19000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 134, 0x60030094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 135, 0x60800999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 136, 0x60000094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 137, 0x20c577fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 138, 0x20c42000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 139, 0x600088cb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 140, 0x204aa7fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 141, 0x205577fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 142, 0x20542000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 143, 0x600088cb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 144, 0x20daa7fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 145, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 146, 0x608009a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 147, 0x608009a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 148, 0x133db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 149, 0x10499001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 150, 0x608b809a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 151, 0x20a37188);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 152, 0x6080809b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 153, 0x1d0a0098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 154, 0x1d0a00d0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 155, 0x20b27004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 156, 0x20b47008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 157, 0x375087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 158, 0x2400800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 159, 0x3250802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 160, 0x0006e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 161, 0x60018970);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 162, 0x1b0a0010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 163, 0x36508028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 164, 0x111c8a80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 165, 0x0000600e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 166, 0x11300800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 167, 0x20317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 168, 0xe75295c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 169, 0x202271d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 170, 0x232081dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 171, 0x00ece8c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 172, 0x0000010f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 173, 0x600b80b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 174, 0x2034700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 175, 0xb3388000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 176, 0x117dc40f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 177, 0x1a11d400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 178, 0x77600230);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 179, 0x00ff80c6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 180, 0x01c0818d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 181, 0x80d88217);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 182, 0x823b81a9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 183, 0x016b8229);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 184, 0x81208205);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 185, 0x83b181d2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 186, 0x840283d9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 187, 0x03b1842a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 188, 0x840283d9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 189, 0x8482842a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 190, 0x848282e9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 191, 0x82588362);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 192, 0x03888312);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 193, 0x04828375);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 194, 0x028e8482);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 195, 0x0453832c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 196, 0x0482845f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 197, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 198, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 199, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 200, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 201, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 202, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 203, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 204, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 205, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 206, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 207, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 208, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 209, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 210, 0xa1000906);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 211, 0x1257c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 212, 0x1259dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 213, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 214, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 215, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 216, 0x21008044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 217, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 218, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 219, 0x17100480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 220, 0x1724ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 221, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 222, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 223, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 224, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 225, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 226, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 227, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 228, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 229, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 230, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 231, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 232, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 233, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 234, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 235, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 236, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 237, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 238, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 239, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 240, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 241, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 242, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 243, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 244, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 245, 0xa1060132);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 246, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 247, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 248, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 249, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 250, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 251, 0x0229e00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 252, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 253, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 254, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 255, 0x21008044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 256, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 257, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 258, 0x17100480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 259, 0x1724ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 260, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 261, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 262, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 263, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 264, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 265, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 266, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 267, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 268, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 269, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 270, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 271, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 272, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 273, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 274, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 275, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 276, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 277, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 278, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 279, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 280, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 281, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 282, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 283, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 284, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 285, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 286, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 287, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 288, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 289, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 290, 0x2289802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 291, 0x07100400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 292, 0x14100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 293, 0x0792ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 294, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 295, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 296, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 297, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 298, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 299, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 300, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 301, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 302, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 303, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 304, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 305, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 306, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 307, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 308, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 309, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 310, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 311, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 312, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 313, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 314, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 315, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 316, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 317, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 318, 0xe51f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 319, 0x23008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 320, 0x033df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 321, 0xf072e489);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 322, 0x6001815c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 323, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 324, 0xa1080100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 325, 0x025db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 326, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 327, 0x024ae028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 328, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 329, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 330, 0x2500802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 331, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 332, 0x0239e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 333, 0x0225e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 334, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 335, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 336, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 337, 0x31d80001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 338, 0x00000032);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 339, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 340, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 341, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 342, 0x1229e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 343, 0x0223e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 344, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 345, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 346, 0x60808169);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 347, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 348, 0xb1080132);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 349, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 350, 0x0227c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 351, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 352, 0x0224c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 353, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 354, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 355, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 356, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 357, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 358, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 359, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 360, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 361, 0x252081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 362, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 363, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 364, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 365, 0x2289802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 366, 0x07100400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 367, 0x14100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 368, 0x0792ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 369, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 370, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 371, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 372, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 373, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 374, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 375, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 376, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 377, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 378, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 379, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 380, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 381, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 382, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 383, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 384, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 385, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 386, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 387, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 388, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 389, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 390, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 391, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 392, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 393, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 394, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 395, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 396, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 397, 0x170c0e00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 398, 0x00041400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 399, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 400, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 401, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 402, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 403, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 404, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 405, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 406, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 407, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 408, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 409, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 410, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 411, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 412, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 413, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 414, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 415, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 416, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 417, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 418, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 419, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 420, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 421, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 422, 0x21000014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 423, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 424, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 425, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 426, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 427, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 428, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 429, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 430, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 431, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 432, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 433, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 434, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 435, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 436, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 437, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 438, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 439, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 440, 0x61000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 441, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 442, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 443, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 444, 0x0229e00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 445, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 446, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 447, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 448, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 449, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 450, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 451, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 452, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 453, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 454, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 455, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 456, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 457, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 458, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 459, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 460, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 461, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 462, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 463, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 464, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 465, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 466, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 467, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 468, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 469, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 470, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 471, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 472, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 473, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 474, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 475, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 476, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 477, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 478, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 479, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 480, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 481, 0xf41f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 482, 0x25008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 483, 0x055df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 484, 0x004ae032);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 485, 0x600b01ef);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 486, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 487, 0x81000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 488, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 489, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 490, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 491, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 492, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 493, 0x60808203);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 494, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 495, 0xa1080100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 496, 0x124db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 497, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 498, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 499, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 500, 0x0259e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 501, 0x0223e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 502, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 503, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 504, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 505, 0x31d80001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 506, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 507, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 508, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 509, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 510, 0x1229e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 511, 0x0225e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 512, 0x1223c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 513, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 514, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 515, 0x252081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 516, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 517, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 518, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 519, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 520, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 521, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 522, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 523, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 524, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 525, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 526, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 527, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 528, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 529, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 530, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 531, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 532, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 533, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 534, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 535, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 536, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 537, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 538, 0x17090700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 539, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 540, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 541, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 542, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 543, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 544, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 545, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 546, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 547, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 548, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 549, 0xb10400d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 550, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 551, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 552, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 553, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 554, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 555, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 556, 0x17090700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 557, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 558, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 559, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 560, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 561, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 562, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 563, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 564, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 565, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 566, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 567, 0xb10400d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 568, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 569, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 570, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 571, 0x23008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 572, 0x170c0e00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 573, 0x00292800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 574, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 575, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 576, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 577, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 578, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 579, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 580, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 581, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 582, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 583, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 584, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 585, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 586, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 587, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 588, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 589, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 590, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 591, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 592, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 593, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 594, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 595, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 596, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 597, 0x21000028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 598, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 599, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 600, 0x21008044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 601, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 602, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 603, 0x17100480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 604, 0x0224e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 605, 0x17200600);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 606, 0x1729c708);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 607, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 608, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 609, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 610, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 611, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 612, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 613, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 614, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 615, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 616, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 617, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 618, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 619, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 620, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 621, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 622, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 623, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 624, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 625, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 626, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 627, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 628, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 629, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 630, 0xb1060111);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 631, 0x0249c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 632, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 633, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 634, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 635, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 636, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 637, 0x0229e00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 638, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 639, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 640, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 641, 0x21d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 642, 0x3350800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 643, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 644, 0x01090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 645, 0x0117c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 646, 0x0101e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 647, 0x0119c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 648, 0x0114c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 649, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 650, 0x12100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 651, 0x12100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 652, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 653, 0x38327000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 654, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 655, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 656, 0x2189802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 657, 0x17900400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 658, 0x04900440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 659, 0x0221e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 660, 0x17200600);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 661, 0x0779c788);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 662, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 663, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 664, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 665, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 666, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 667, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 668, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 669, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 670, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 671, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 672, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 673, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 674, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 675, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 676, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 677, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 678, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 679, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 680, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 681, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 682, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 683, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 684, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 685, 0xe51f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 686, 0x23008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 687, 0x033df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 688, 0xf072e489);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 689, 0x608182cb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 690, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 691, 0xa1080100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 692, 0x025db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 693, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 694, 0x124ae020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 695, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 696, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 697, 0x2500802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 698, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 699, 0x0239e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 700, 0x0225e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 701, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 702, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 703, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 704, 0x31d80001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 705, 0x00000011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 706, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 707, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 708, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 709, 0x1229e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 710, 0x0223e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 711, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 712, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 713, 0x600082d9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 714, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 715, 0xa1080111);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 716, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 717, 0x0227c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 718, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 719, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 720, 0x0224c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 721, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 722, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 723, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 724, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 725, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 726, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 727, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 728, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 729, 0x252081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 730, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 731, 0x21d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 732, 0x34d0800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 733, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 734, 0x23a081cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 735, 0x01090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 736, 0x0117c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 737, 0x0101e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 738, 0x0119c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 739, 0x1113c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 740, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 741, 0x12100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 742, 0x12100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 743, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 744, 0x38327000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 745, 0x23008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 746, 0x07080e00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 747, 0x00041c00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 748, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 749, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 750, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 751, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 752, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 753, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 754, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 755, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 756, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 757, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 758, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 759, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 760, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 761, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 762, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 763, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 764, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 765, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 766, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 767, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 768, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 769, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 770, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 771, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 772, 0x21000014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 773, 0x21d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 774, 0x3350800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 775, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 776, 0x01090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 777, 0x0117c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 778, 0x0101e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 779, 0x0119c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 780, 0x0114c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 781, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 782, 0x12100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 783, 0x12100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 784, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 785, 0x38327000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 786, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 787, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 788, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 789, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 790, 0x1779ca88);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 791, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 792, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 793, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 794, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 795, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 796, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 797, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 798, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 799, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 800, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 801, 0x61000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 802, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 803, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 804, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 805, 0x022ae014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 806, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 807, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 808, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 809, 0x40d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 810, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 811, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 812, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 813, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 814, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 815, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 816, 0x1779ca88);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 817, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 818, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 819, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 820, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 821, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 822, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 823, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 824, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 825, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 826, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 827, 0x21808038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 828, 0xf41f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 829, 0x25008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 830, 0x055df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 831, 0x104ae011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 832, 0x608b034a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 833, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 834, 0x81000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 835, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 836, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 837, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 838, 0x122ae010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 839, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 840, 0x6080835e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 841, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 842, 0xa1080100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 843, 0x124db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 844, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 845, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 846, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 847, 0x0259e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 848, 0x0223e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 849, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 850, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 851, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 852, 0x31d80001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 853, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 854, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 855, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 856, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 857, 0x0229e009);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 858, 0x0225e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 859, 0x1223c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 860, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 861, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 862, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 863, 0x40d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 864, 0x252081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 865, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 866, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 867, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 868, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 869, 0x17090700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 870, 0x1779ca88);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 871, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 872, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 873, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 874, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 875, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 876, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 877, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 878, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 879, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 880, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 881, 0xb10400d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 882, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 883, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 884, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 885, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 886, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 887, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 888, 0x17090700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 889, 0x1779ca88);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 890, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 891, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 892, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 893, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 894, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 895, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 896, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 897, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 898, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 899, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 900, 0xb10400d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 901, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 902, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 903, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 904, 0x23008034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 905, 0x170c0e00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 906, 0x00293000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 907, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 908, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 909, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 910, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 911, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 912, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 913, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 914, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 915, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 916, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 917, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 918, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 919, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 920, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 921, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 922, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 923, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 924, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 925, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 926, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 927, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 928, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 929, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 930, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 931, 0x21000028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 932, 0x21d80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 933, 0x3350800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 934, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 935, 0x01090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 936, 0x0117c420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 937, 0x0101e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 938, 0x0119c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 939, 0x0114c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 940, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 941, 0x12100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 942, 0x12100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 943, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 944, 0x38327000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 945, 0x21808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 946, 0x2280802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 947, 0x1779f145);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 948, 0x1707e510);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 949, 0x07799545);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 950, 0x0112e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 951, 0x1719c708);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 952, 0x1777c6d0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 953, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 954, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 955, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 956, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 957, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 958, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 959, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 960, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 961, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 962, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 963, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 964, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 965, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 966, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 967, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 968, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 969, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 970, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 971, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 972, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 973, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 974, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 975, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 976, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 977, 0x01178430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 978, 0xf061e481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 979, 0x6001848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 980, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 981, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 982, 0x21d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 983, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 984, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 985, 0x21808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 986, 0x2280802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 987, 0x240080b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 988, 0x1779f145);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 989, 0x1707e510);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 990, 0x07799545);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 991, 0x0112e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 992, 0x07100700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 993, 0x0774c6c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 994, 0x0776c680);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 995, 0x1776c690);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 996, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 997, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 998, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 999, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1000, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1001, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1002, 0x1069e4cf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1003, 0x600b83f7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1004, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1005, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1006, 0xa0220000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1007, 0x24d8001c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1008, 0x4b807100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1009, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1010, 0x25d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1011, 0x2100811c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1012, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1013, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1014, 0x08000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1015, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1016, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1017, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1018, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1019, 0x01178430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1020, 0xf061e481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1021, 0x6001848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1022, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1023, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1024, 0x40d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1025, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1026, 0x21808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1027, 0x2280802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1028, 0x1779f145);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1029, 0x1707e510);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1030, 0x07799545);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1031, 0x0112e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1032, 0x1719c708);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1033, 0x1777c6d0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1034, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1035, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1036, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1037, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1038, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1039, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1040, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1041, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1042, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1043, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1044, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1045, 0xf17f908f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1046, 0x0249c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1047, 0x12a29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1048, 0x02a2e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1049, 0x1c29c002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1050, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1051, 0x12090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1052, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1053, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1054, 0x0441c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1055, 0x0442c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1056, 0x202471cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1057, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1058, 0x01178430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1059, 0xf061e481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1060, 0x6001848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1061, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1062, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1063, 0x21d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1064, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1065, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1066, 0x21808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1067, 0x2280802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1068, 0x240080b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1069, 0x1779f145);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1070, 0x1707e510);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1071, 0x07799545);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1072, 0x0112e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1073, 0x07100700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1074, 0x0774c6c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1075, 0x0776c680);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1076, 0x1776c690);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1077, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1078, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1079, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1080, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1081, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1082, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1083, 0x1069e4cf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1084, 0x600b8448);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1085, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1086, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1087, 0xa0220000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1088, 0x24d8001c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1089, 0x4b807100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1090, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1091, 0x25d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1092, 0x2100811c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1093, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1094, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1095, 0x08000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1096, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1097, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1098, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1099, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1100, 0x01178430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1101, 0xf061e481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1102, 0x6001848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1103, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1104, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1105, 0x40d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1106, 0x6000048d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1107, 0x0709060c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1108, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1109, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1110, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1111, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1112, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1113, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1114, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1115, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1116, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1117, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1118, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1119, 0x0709060c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1120, 0x315087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1121, 0x24808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1122, 0x02000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1123, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1124, 0x0442ea80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1125, 0x12600400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1126, 0x0442ea80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1127, 0x22808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1128, 0xe441ea88);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1129, 0x60030998);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1130, 0x60810998);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1131, 0x0021ec00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1132, 0x608b0998);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1133, 0x0002e430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1134, 0x60810471);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1135, 0x60008476);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1136, 0x044df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1137, 0xf023e4c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1138, 0x60090998);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1139, 0x0042e4b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1140, 0x60810998);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1141, 0x142df008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1142, 0x20a471dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1143, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1144, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1145, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1146, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1147, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1148, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1149, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1150, 0x01090011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1151, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1152, 0x6080848d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1153, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1154, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1155, 0x2180802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1156, 0x1721ea00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1157, 0x17700780);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1158, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1159, 0x02000500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1160, 0x12700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1161, 0x151df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1162, 0x0552e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1163, 0x60008999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1164, 0x202571c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1165, 0x77e00158);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1166, 0x049a081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1167, 0x04cd04bb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1168, 0x853104eb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1169, 0x05770554);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1170, 0x85a80598);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1171, 0x060d05c6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1172, 0x8651062f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1173, 0x06cd068b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1174, 0x872906fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1175, 0x07970777);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1176, 0x099907ee);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1177, 0x6080081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1178, 0xb1020390);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1179, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1180, 0x12600400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1181, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1182, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1183, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1184, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1185, 0x01090017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1186, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1187, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1188, 0x608b84ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1189, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1190, 0xb1020f22);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1191, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1192, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1193, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1194, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1195, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1196, 0x608084b7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1197, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1198, 0xa1020f20);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1199, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1200, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1201, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1202, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1203, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1204, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1205, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1206, 0x224a0004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1207, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1208, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1209, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1210, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1211, 0xa1020190);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1212, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1213, 0x12600400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1214, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1215, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1216, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1217, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1218, 0x11090015);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1219, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1220, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1221, 0xb1020d26);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1222, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1223, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1224, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1225, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1226, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1227, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1228, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1229, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1230, 0x23900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1231, 0x23a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1232, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1233, 0x01090017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1234, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1235, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1236, 0x600b84de);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1237, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1238, 0xb1020f22);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1239, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1240, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1241, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1242, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1243, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1244, 0x608084e7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1245, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1246, 0xa1020f20);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1247, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1248, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1249, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1250, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1251, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1252, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1253, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1254, 0x224a0004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1255, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1256, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1257, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1258, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1259, 0x335087f8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1260, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1261, 0x14000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1262, 0x02c2c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1263, 0x04200640);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1264, 0x04200700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1265, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1266, 0x22d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1267, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1268, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1269, 0x22a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1270, 0x22d80006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1271, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1272, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1273, 0x608b8500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1274, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1275, 0x43903000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1276, 0x00000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1277, 0x23900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1278, 0x22000006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1279, 0x60800506);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1280, 0x43905000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1281, 0x00000c00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1282, 0x23900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1283, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1284, 0x23980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1285, 0x22000002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1286, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1287, 0x21a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1288, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1289, 0x123ac010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1290, 0x1227c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1291, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1292, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1293, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1294, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1295, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1296, 0x24a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1297, 0x14c4c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1298, 0x0404e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1299, 0x1449900f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1300, 0x20a471c4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1301, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1302, 0x01090017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1303, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1304, 0x1049e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1305, 0x600b8523);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1306, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1307, 0xb1020f22);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1308, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1309, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1310, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1311, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1312, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1313, 0x6000852d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1314, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1315, 0xa1020f20);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1316, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1317, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1318, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1319, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1320, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1321, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1322, 0xb1020202);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1323, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1324, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1325, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1326, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1327, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1328, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1329, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1330, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1331, 0x600b8538);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1332, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1333, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1334, 0x2b900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1335, 0x6080053c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1336, 0x43903000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1337, 0x23900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1338, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1339, 0x2b980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1340, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1341, 0x21a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1342, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1343, 0x024ac010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1344, 0x1227c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1345, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1346, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1347, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1348, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1349, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1350, 0x01090017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1351, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1352, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1353, 0xb1020f22);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1354, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1355, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1356, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1357, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1358, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1359, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1360, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1361, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1362, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1363, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1364, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1365, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1366, 0x600b855b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1367, 0x13c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1368, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1369, 0x23900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1370, 0x6080055f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1371, 0x43903000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1372, 0x23900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1373, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1374, 0x23980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1375, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1376, 0x23a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1377, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1378, 0x024ac010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1379, 0x1227c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1380, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1381, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1382, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1383, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1384, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1385, 0x11090013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1386, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1387, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1388, 0xa1020b22);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1389, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1390, 0x02700400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1391, 0x022db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1392, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1393, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1394, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1395, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1396, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1397, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1398, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1399, 0xa1040290);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1400, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1401, 0x12600400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1402, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1403, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1404, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1405, 0x600b8589);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1406, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1407, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1408, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1409, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1410, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1411, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1412, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1413, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1414, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1415, 0x60808594);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1416, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1417, 0x1109001f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1418, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1419, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1420, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1421, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1422, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1423, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1424, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1425, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1426, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1427, 0x224a0004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1428, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1429, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1430, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1431, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1432, 0xa1040290);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1433, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1434, 0x12600400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1435, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1436, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1437, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1438, 0xb1000d06);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1439, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1440, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1441, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1442, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1443, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1444, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1445, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1446, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1447, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1448, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1449, 0x42900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1450, 0x42a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1451, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1452, 0x600b05b7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1453, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1454, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1455, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1456, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1457, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1458, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1459, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1460, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1461, 0x608085c2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1462, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1463, 0x1109001f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1464, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1465, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1466, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1467, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1468, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1469, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1470, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1471, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1472, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1473, 0x224a0004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1474, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1475, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1476, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1477, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1478, 0x335087f8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1479, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1480, 0x14000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1481, 0x02c2c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1482, 0xe16f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1483, 0x0221e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1484, 0xf221e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1485, 0x04200640);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1486, 0x04200700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1487, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1488, 0x40900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1489, 0x22d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1490, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1491, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1492, 0x42a80008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1493, 0x22d80006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1494, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1495, 0x232081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1496, 0xe16f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1497, 0x1331e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1498, 0x0303e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1499, 0x1339900f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1500, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1501, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1502, 0x600b05e4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1503, 0x43903000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1504, 0x00000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1505, 0x22900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1506, 0x22000006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1507, 0x600005ea);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1508, 0x43905000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1509, 0x00000c00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1510, 0x22900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1511, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1512, 0x22980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1513, 0x22000002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1514, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1515, 0x1247c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1516, 0x0249dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1517, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1518, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1519, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1520, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1521, 0x0039e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1522, 0x608b05fd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1523, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1524, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1525, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1526, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1527, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1528, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1529, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1530, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1531, 0x60008609);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1532, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1533, 0x1109001f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1534, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1535, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1536, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1537, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1538, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1539, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1540, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1541, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1542, 0xb1020202);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1543, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1544, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1545, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1546, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1547, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1548, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1549, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1550, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1551, 0x608b0613);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1552, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1553, 0x4a900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1554, 0x60800618);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1555, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1556, 0x42900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1557, 0x40980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1558, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1559, 0x2a980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1560, 0xa10400a8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1561, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1562, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1563, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1564, 0x0237c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1565, 0x1239dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1566, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1567, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1568, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1569, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1570, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1571, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1572, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1573, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1574, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1575, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1576, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1577, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1578, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1579, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1580, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1581, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1582, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1583, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1584, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1585, 0x600b0635);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1586, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1587, 0x42900008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1588, 0x6080063a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1589, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1590, 0x42900004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1591, 0x40980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1592, 0x22480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1593, 0x22980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1594, 0xb10402a8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1595, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1596, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1597, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1598, 0x0237c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1599, 0x1239dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1600, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1601, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1602, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1603, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1604, 0xa1000b02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1605, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1606, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1607, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1608, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1609, 0x1229e008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1610, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1611, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1612, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1613, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1614, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1615, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1616, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1617, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1618, 0x60830655);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1619, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1620, 0x40d80005);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1621, 0x210080b4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1622, 0x03100000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1623, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1624, 0x22580004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1625, 0x22500004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1626, 0x010c0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1627, 0x23100001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1628, 0x123db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1629, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1630, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1631, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1632, 0xf42f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1633, 0x14200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1634, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1635, 0x11a9c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1636, 0x1226c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1637, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1638, 0x1321c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1639, 0x0101e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1640, 0x11319000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1641, 0x1212e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1642, 0x0c200000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1643, 0x0116c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1644, 0x0119dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1645, 0x03100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1646, 0x03100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1647, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1648, 0x23900002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1649, 0x21580004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1650, 0x21500004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1651, 0x22d80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1652, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1653, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1654, 0x21d80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1655, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1656, 0x04c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1657, 0xa10201a0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1658, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1659, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1660, 0x60038682);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1661, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1662, 0xa1000702);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1663, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1664, 0x60008684);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1665, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1666, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1667, 0x27020000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1668, 0xb10205e2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1669, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1670, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1671, 0xa1020d2e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1672, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1673, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1674, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1675, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1676, 0x6003068f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1677, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1678, 0x40d80005);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1679, 0x210080b4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1680, 0x03100000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1681, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1682, 0x22580004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1683, 0x22500004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1684, 0x010c0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1685, 0x23100001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1686, 0x123db007);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1687, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1688, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1689, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1690, 0xf42f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1691, 0x14200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1692, 0x21a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1693, 0x0116c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1694, 0x0119dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1695, 0x1116c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1696, 0x0119dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1697, 0x03100440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1698, 0x03100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1699, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1700, 0x23900002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1701, 0x21580004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1702, 0x21500004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1703, 0x2ad80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1704, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1705, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1706, 0x21d80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1707, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1708, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1709, 0xb10201a8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1710, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1711, 0xf061e481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1712, 0x600186b9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1713, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1714, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1715, 0x024ac019);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1716, 0x1227c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1717, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1718, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1719, 0x608086bf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1720, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1721, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1722, 0x024ac015);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1723, 0x1227c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1724, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1725, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1726, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1727, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1728, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1729, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1730, 0x600306c7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1731, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1732, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1733, 0x600086c9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1734, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1735, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1736, 0x2f020000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1737, 0xb10201e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1738, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1739, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1740, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1741, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1742, 0x600306d9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1743, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1744, 0x41900003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1745, 0x42480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1746, 0x42400004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1747, 0x22c00003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1748, 0xb1020378);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1749, 0x0259e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1750, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1751, 0x600086e2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1752, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1753, 0x43104000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1754, 0x40900003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1755, 0x42480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1756, 0x42400004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1757, 0x22c00003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1758, 0xa1020278);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1759, 0x0259e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1760, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1761, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1762, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1763, 0x40d80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1764, 0xb10400a0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1765, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1766, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1767, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1768, 0xb10a0002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1769, 0x0237c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1770, 0x1239dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1771, 0x0227c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1772, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1773, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1774, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1775, 0x02600440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1776, 0x1229b00d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1777, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1778, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1779, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1780, 0x077a0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1781, 0xb1000d7e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1782, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1783, 0x02600440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1784, 0x0229c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1785, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1786, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1787, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1788, 0x1079e440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1789, 0x60030709);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1790, 0x43905000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1791, 0x41900003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1792, 0x42480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1793, 0x42400004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1794, 0x22c00003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1795, 0x2bd80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1796, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1797, 0xe32f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1798, 0x03200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1799, 0x60008713);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1800, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1801, 0x43905000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1802, 0x40900003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1803, 0x42480004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1804, 0x42400004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1805, 0x22c00003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1806, 0x2ad80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1807, 0x22a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1808, 0xe32f904f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1809, 0x03200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1810, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1811, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1812, 0x40d80002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1813, 0xa10400a8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1814, 0x11168400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1815, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1816, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1817, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1818, 0x1247c430);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1819, 0x0249dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1820, 0x0227c410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1821, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1822, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1823, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1824, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1825, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1826, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1827, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1828, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1829, 0xa10400e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1830, 0x01168410);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1831, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1832, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1833, 0x33d087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1834, 0x21a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1835, 0x021ae030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1836, 0x032197c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1837, 0x34d087f8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1838, 0x11090013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1839, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1840, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1841, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1842, 0x23d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1843, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1844, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1845, 0x1049e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1846, 0x608b074d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1847, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1848, 0x608b073c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1849, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1850, 0x9b996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1851, 0x60800740);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1852, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1853, 0x93996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1854, 0x9bd94008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1855, 0x610008bf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1856, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1857, 0x023ac014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1858, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1859, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1860, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1861, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1862, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1863, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1864, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1865, 0x0254e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1866, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1867, 0x60808774);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1868, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1869, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1870, 0x93996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1871, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1872, 0x60830754);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1873, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1874, 0x93d94008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1875, 0x610008bf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1876, 0x1045e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1877, 0x60010764);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1878, 0x0109001b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1879, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1880, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1881, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1882, 0x023ac014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1883, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1884, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1885, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1886, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1887, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1888, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1889, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1890, 0x2f020000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1891, 0x60000774);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1892, 0x0109001b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1893, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1894, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1895, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1896, 0x023ac014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1897, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1898, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1899, 0x0224c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1900, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1901, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1902, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1903, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1904, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1905, 0x0254e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1906, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1907, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1908, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1909, 0x21e60010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1910, 0x6080081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1911, 0x33d087fc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1912, 0x21a081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1913, 0x021ae030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1914, 0x032197c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1915, 0x11090013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1916, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1917, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1918, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1919, 0x23d80004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1920, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1921, 0x2480802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1922, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1923, 0x93996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1924, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1925, 0x60830789);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1926, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1927, 0x93d94008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1928, 0x610008bf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1929, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1930, 0x124ac014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1931, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1932, 0x0229dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1933, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1934, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1935, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1936, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1937, 0xa1000b02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1938, 0x01158000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1939, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1940, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1941, 0x21e60010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1942, 0x6080081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1943, 0x335087f8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1944, 0x24a081dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1945, 0x11090013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1946, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1947, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1948, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1949, 0x02000004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1950, 0x0039e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1951, 0x600b07b5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1952, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1953, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1954, 0x608b07a6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1955, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1956, 0x4a980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1957, 0x600007a9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1958, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1959, 0x42980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1960, 0x4aa00008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1961, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1962, 0x90996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1963, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1964, 0x0239c00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1965, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1966, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1967, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1968, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1969, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1970, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1971, 0x600087da);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1972, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1973, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1974, 0x42980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1975, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1976, 0x600307bb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1977, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1978, 0x42a00008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1979, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1980, 0x90996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1981, 0x1034e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1982, 0x608107ca);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1983, 0x2500802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1984, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1985, 0x0259c00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1986, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1987, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1988, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1989, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1990, 0xa1000b02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1991, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1992, 0x600087d9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1993, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1994, 0x0109001b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1995, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1996, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1997, 0x2500802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1998, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1999, 0x0259c00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2000, 0x1223c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2001, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2002, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2003, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2004, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2005, 0xb1000f02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2006, 0x0243e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2007, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2008, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2009, 0x252081c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2010, 0x114ac018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2011, 0x0116c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2012, 0x0119dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2013, 0x1015e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2014, 0x600907eb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2015, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2016, 0x40e20010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2017, 0xb10400de);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2018, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2019, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2020, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2021, 0x022ae018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2022, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2023, 0x1224e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2024, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2025, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2026, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2027, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2028, 0x40e60010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2029, 0x6080081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2030, 0x2300802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2031, 0x24a081dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2032, 0x11090013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2033, 0x11178420);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2034, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2035, 0x43102000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2036, 0x02000004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2037, 0x42980004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2038, 0x1069e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2039, 0x600307fa);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2040, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2041, 0x42a00008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2042, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2043, 0x90996004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2044, 0xb10a0080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2045, 0x0239c00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2046, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2047, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2048, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2049, 0x25000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2050, 0xa1000b02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2051, 0x11148000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2052, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2053, 0x114ac018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2054, 0x0116c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2055, 0x0119dd40);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2056, 0x1015e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2057, 0x60890816);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2058, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2059, 0x40e20010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2060, 0xb10400de);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2061, 0x02090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2062, 0x0226c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2063, 0x0202e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2064, 0x022ae018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2065, 0x1225c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2066, 0x1224e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2067, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2068, 0x6000881a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2069, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2070, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2071, 0x40e60010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2072, 0x6080081a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2073, 0x60800999);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2074, 0x77e00210);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2075, 0x88a1082c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2076, 0x08a10878);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2077, 0x08a10878);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2078, 0x888d0839);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2079, 0x8869088d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2080, 0x8869085a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2081, 0x88a10849);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2082, 0x88a108a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2083, 0x88a108a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2084, 0x88a108a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2085, 0x88a108a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2086, 0x08a10878);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2087, 0x08a10878);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2088, 0x888d0839);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2089, 0x08a1088d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2090, 0x086908a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2091, 0x88a10849);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2092, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2093, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2094, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2095, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2096, 0x14ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2097, 0x1049e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2098, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2099, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2100, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2101, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2102, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2103, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2104, 0x608008ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2105, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2106, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2107, 0xae3d0002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2108, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2109, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2110, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2111, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2112, 0x14ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2113, 0x1049e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2114, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2115, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2116, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2117, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2118, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2119, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2120, 0x608008ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2121, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2122, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2123, 0x24808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2124, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2125, 0xad470004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2126, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2127, 0x044df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2128, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2129, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2130, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2131, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2132, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2133, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2134, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2135, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2136, 0x600088ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2137, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2138, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2139, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2140, 0x24808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2141, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2142, 0x044df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2143, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2144, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2145, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2146, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2147, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2148, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2149, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2150, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2151, 0x600088ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2152, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2153, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2154, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2155, 0x24808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2156, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2157, 0x044df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2158, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2159, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2160, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2161, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2162, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2163, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2164, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2165, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2166, 0x600088ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2167, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2168, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2169, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2170, 0x24008048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2171, 0x1149b00e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2172, 0x144db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2173, 0x14100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2174, 0x044a91ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2175, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2176, 0x044db00b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2177, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2178, 0x1243c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2179, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2180, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2181, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2182, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2183, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2184, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2185, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2186, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2187, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2188, 0x608008ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2189, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2190, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2191, 0x24008048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2192, 0x144db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2193, 0x144a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2194, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2195, 0x044db00b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2196, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2197, 0x1243c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2198, 0x11128000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2199, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2200, 0x0059e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2201, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2202, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2203, 0x24808034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2204, 0x044df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2205, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2206, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2207, 0x600088ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2208, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2209, 0x23808014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2210, 0x610088c5);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2211, 0xe33f924f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2212, 0xa10f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2213, 0x01138000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2214, 0x14ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2215, 0x1049e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2216, 0x608b88ae);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2217, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2218, 0x43002008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2219, 0x43a011d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2220, 0x43101000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2221, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2222, 0x14edf008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2223, 0x1049e00f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2224, 0x600b08e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2225, 0x05ea90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2226, 0x1059e001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2227, 0x600b08e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2228, 0x22a081dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2229, 0x71200030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2230, 0x08e608bd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2231, 0x08ba08b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2232, 0x432041e0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2233, 0x608008e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2234, 0x1a0a01e0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2235, 0x420040c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2236, 0x608008e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2237, 0x438040c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2238, 0x608008e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2239, 0x00dae098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2240, 0x600308c3);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2241, 0x43502100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2242, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2243, 0x435020c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2244, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2245, 0x00dae098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2246, 0x600308c9);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2247, 0x43d020d4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2248, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2249, 0x43d0209c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2250, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2251, 0x08090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2252, 0x39008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2253, 0x3a008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2254, 0x3b808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2255, 0x3c008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2256, 0x3d808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2257, 0x3e808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2258, 0x43107000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2259, 0x42220000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2260, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2261, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2262, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2263, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2264, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2265, 0x00060000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2266, 0x38387000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2267, 0xf0000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2268, 0x10e9e401);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2269, 0x600308e2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2270, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2271, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2272, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2273, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2274, 0x20b15000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2275, 0x20b27004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2276, 0x20b15018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2277, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2278, 0x21508000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2279, 0x2320e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2280, 0x2420f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2281, 0x22808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2282, 0x2780802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2283, 0x25008008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2284, 0x022df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2285, 0x1227c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2286, 0xa0f29000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2287, 0x608b88f4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2288, 0x170d000f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2289, 0x10199001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2290, 0x608b0902);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2291, 0x60000929);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2292, 0x10f99014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2293, 0x600b0917);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2294, 0x21c08024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2295, 0x2320e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2296, 0x2420f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2297, 0x20237030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2298, 0x01199002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2299, 0x60038924);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2300, 0x20247034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2301, 0x20c2e838);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2302, 0x2040e03c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2303, 0x20c7c040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2304, 0x20437030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2305, 0x20447034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2306, 0xa1000030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2307, 0xa6000020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2308, 0x3052e818);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2309, 0x30d0e01c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2310, 0x30d7c020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2311, 0x30d37010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2312, 0x30d47014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2313, 0x30d1b024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2314, 0x30d6a024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2315, 0x21a08050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2316, 0x25a08040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2317, 0x0119c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2318, 0x20a17050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2319, 0x0552c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2320, 0x60018913);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2321, 0x20a57040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2322, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2323, 0x25208044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2324, 0x0559d000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2325, 0x20257044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2326, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2327, 0xa1000030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2328, 0xa6000020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2329, 0x3052e818);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2330, 0x30d0e01c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2331, 0x30d37010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2332, 0x30d47014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2333, 0x30d1b024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2334, 0x30d6a024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2335, 0x25a08040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2336, 0x0552c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2337, 0x60018913);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2338, 0x20a57040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2339, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2340, 0x20c2e838);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2341, 0x2040e03c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2342, 0x20c7c040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2343, 0x20437030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2344, 0x20447034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2345, 0xa1000030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2346, 0xa6000020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2347, 0x3052e818);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2348, 0x30d0e01c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2349, 0x30d7c020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2350, 0x30d37010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2351, 0x30d47014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2352, 0x30d1b024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2353, 0x30d6a024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2354, 0x21208054);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2355, 0x25208048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2356, 0x0119c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2357, 0x20217054);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2358, 0x0552c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2359, 0x6081893a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2360, 0x20257048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2361, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2362, 0x25a0804c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2363, 0x0559d000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2364, 0x20a5704c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2365, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2366, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2367, 0x0449f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2368, 0x0449901c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2369, 0xa44f8000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2370, 0x21808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2371, 0x011df000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2372, 0x22008014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2373, 0x0229f008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2374, 0x122a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2375, 0x1112c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2376, 0x22808004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2377, 0x13100800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2378, 0xb3308106);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2379, 0xa1168226);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2380, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2381, 0x38327000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2382, 0x38bf7000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2383, 0x38bf7000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2384, 0x21008014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2385, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2386, 0x00ece8c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2387, 0x0000010f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2388, 0x600b8964);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2389, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2390, 0x22a081dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2391, 0xa5080000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2392, 0x38b57000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2393, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2394, 0x1449c401);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2395, 0x04100640);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2396, 0x71200030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2397, 0x896f8962);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2398, 0x89628960);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2399, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2400, 0x432041e0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2401, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2402, 0x438040c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2403, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2404, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2405, 0x38b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2406, 0x1449c401);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2407, 0x04100640);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2408, 0x10e9e401);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2409, 0x6003896f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2410, 0x38347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2411, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2412, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2413, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2414, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2415, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2416, 0x0b000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2417, 0x016db00f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2418, 0x6000898b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2419, 0x1119c003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2420, 0x016db00f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2421, 0x6000898b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2422, 0x1119c005);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2423, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2424, 0x60008993);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2425, 0x11090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2426, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2427, 0x60008993);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2428, 0x01090009);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2429, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2430, 0x60008993);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2431, 0x0109000a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2432, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2433, 0x60008993);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2434, 0x1109000b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2435, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2436, 0x6000898b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2437, 0x0109000c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2438, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2439, 0x6000898b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2440, 0x1109000d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2441, 0x1109000d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2442, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2443, 0x23a08038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2444, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2445, 0x0339c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2446, 0x60098993);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2447, 0x20a37038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2448, 0x2320803c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2449, 0x0339d000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2450, 0x2023703c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2451, 0x0449f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2452, 0x0449901c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2453, 0xa44f8000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2454, 0x60008942);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2455, 0x14418000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2456, 0x0b000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2457, 0x23a08038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2458, 0x24008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2459, 0x0339c001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2460, 0x608989a1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2461, 0x20a37038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2462, 0x2320803c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2463, 0x0339d000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2464, 0x2023703c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2465, 0x0449f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2466, 0x0449901c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2467, 0x044c8000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2468, 0xf0000002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2469, 0x60800942);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2470, 0x24808020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2471, 0x21008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2472, 0x144db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2473, 0x04100a80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2474, 0x0449f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2475, 0x0449901c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2476, 0x044c8000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2477, 0xf0000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2478, 0x60800942);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2479, 0xe0d9e808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2480, 0x600b09b4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2481, 0x435010c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2482, 0x43d010d8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2483, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2484, 0x43501100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2485, 0x43d01110);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2486, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2487, 0xe0d9e808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2488, 0x600b09bb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2489, 0x435080c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2490, 0x68900000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2491, 0x43508100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2492, 0x68900000);
+	for (i = 2493; i < 3056; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + i*4, 0x10000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3056, 0x0a090008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3057, 0x42901000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3058, 0x00000230);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3059, 0x0a0a0010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3060, 0x42901000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3061, 0x00ec0044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3062, 0x1a0a0018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3063, 0x42901000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3064, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3065, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3066, 0x10000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3067, 0x10000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_RAM_CTRL_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_PUE_CTRL_REG, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_RAM_CTRL_REG, 0x00000001);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 0, 0x16000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1, 0x180a0200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2, 0x0b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3, 0x39008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 4, 0x38317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 5, 0x25208060);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 6, 0x161007c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 7, 0xf66c97c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 8, 0x2380f7ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 9, 0x3f008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 10, 0xb33f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 11, 0xb2739f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 12, 0xd77f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 13, 0x07738000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 14, 0x7110001e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 15, 0x801a8011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 16, 0x38377000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 17, 0x2180f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 18, 0xc11893ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 19, 0x60830011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 20, 0x111a93ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 21, 0x6003004a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 22, 0x5b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 23, 0xc1189000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 24, 0x60830011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 25, 0x6000004a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 26, 0x0005e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 27, 0x60830035);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 28, 0x077df00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 29, 0x1079e00f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 30, 0x600b0035);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 31, 0x14100000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 32, 0x04000600);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 33, 0x20347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 34, 0x20b27010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 35, 0xb41090ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 36, 0x1449b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 37, 0x20347014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 38, 0x5b802000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 39, 0xeb0c0800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 40, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 41, 0x7220007b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 42, 0x0343802f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 43, 0x00a18343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 44, 0x808d8343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 45, 0x00b08343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 46, 0xeb010808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 47, 0xa32f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 48, 0x72b00078);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 49, 0x807a0343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 50, 0x034300bd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 51, 0x80cf0042);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 52, 0x034300cf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 53, 0x2200e210);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 54, 0x2480e214);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 55, 0x7220007b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 56, 0x0343003c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 57, 0x80a10343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 58, 0x008b0343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 59, 0x00af0343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 60, 0xa32f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 61, 0x72b00078);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 62, 0x80790343);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 63, 0x034300bd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 64, 0x80cf0042);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 65, 0x034300cf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 66, 0x2180f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 67, 0xc11893ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 68, 0x60830042);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 69, 0x111a93ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 70, 0x6003004a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 71, 0x5b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 72, 0xc1189000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 73, 0x60830042);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 74, 0x21b08008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 75, 0x2230800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 76, 0x71900020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 77, 0x004f0072);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 78, 0x80600056);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 79, 0x20600000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 80, 0x20614000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 81, 0x20e25000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 82, 0x12080000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 83, 0x00080800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 84, 0x60008072);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 85, 0x20621000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 86, 0x24308000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 87, 0x20600000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 88, 0x20614000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 89, 0x20e25000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 90, 0x130c0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 91, 0x00082800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 92, 0x00499021);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 93, 0x60038072);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 94, 0x20e31000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 95, 0x60800069);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 96, 0x24308000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 97, 0x20600000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 98, 0x20614000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 99, 0x20e25000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 100, 0x03080000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 101, 0x00083800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 102, 0x00499021);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 103, 0x60038072);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 104, 0x20e31000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 105, 0x25a08064);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 106, 0x1449a021);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 107, 0x20347000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 108, 0x011d900c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 109, 0x1115c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 110, 0x0229d000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 111, 0x20614000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 112, 0x20e25000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 113, 0x20e31000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 114, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 115, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 116, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 117, 0x11400000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 118, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 119, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 120, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 121, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 122, 0xd71f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 123, 0xa54090ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 124, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 125, 0x20357038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 126, 0x0549b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 127, 0x155a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 128, 0x2035702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 129, 0x08500000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 130, 0x1575e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 131, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 132, 0x20357020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 133, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 134, 0xa0389000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 135, 0x600b80dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 136, 0x20600000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 137, 0x608080dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 138, 0x16698008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 139, 0x203070b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 140, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 141, 0xb7139000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 142, 0x077df00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 143, 0x077a8014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 144, 0x203770b4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 145, 0xc51f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 146, 0xb74090ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 147, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 148, 0x20b77038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 149, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 150, 0x20377044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 151, 0xd74f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 152, 0x1779b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 153, 0x177a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 154, 0x20b7702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 155, 0x18700000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 156, 0x0557e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 157, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 158, 0x20357020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 159, 0x608080dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 160, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 161, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 162, 0xc51f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 163, 0xb74090ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 164, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 165, 0x20b77038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 166, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 167, 0x20377044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 168, 0xd74f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 169, 0x1779b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 170, 0x20b77034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 171, 0x07500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 172, 0x20b77020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 173, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 174, 0x2030702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 175, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 176, 0xc51f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 177, 0xd74f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 178, 0x1779b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 179, 0x177a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 180, 0x20b7702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 181, 0x18700000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 182, 0x3180800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 183, 0x0757e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 184, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 185, 0x20b77020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 186, 0x177db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 187, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 188, 0x20b17034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 189, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 190, 0xd71f9fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 191, 0xa54090ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 192, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 193, 0x20357038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 194, 0x0549b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 195, 0x155a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 196, 0x2035702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 197, 0x08500000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 198, 0x1575e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 199, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 200, 0x20357020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 201, 0x155db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 202, 0xa0389000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 203, 0x600b80dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 204, 0x20600000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 205, 0x608080dc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 206, 0x16698008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 207, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 208, 0x21308000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 209, 0x01090804);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 210, 0x20317000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 211, 0x22b08008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 212, 0x122d940c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 213, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 214, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 215, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 216, 0x20b27008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 217, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 218, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 219, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 220, 0x3400c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 221, 0x024df00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 222, 0x0029e004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 223, 0x600300e3);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 224, 0x1029e006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 225, 0x60030117);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 226, 0x6000031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 227, 0x12800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 228, 0x07798000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 229, 0x20377024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 230, 0x3c80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 231, 0x03090001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 232, 0x2033704c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 233, 0x20337064);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 234, 0x3b00c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 235, 0x3980c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 236, 0x28b07054);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 237, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 238, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 239, 0x2830706c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 240, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 241, 0x38b07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 242, 0xf74f9a8f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 243, 0xf7349830);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 244, 0x20377048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 245, 0x074df006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 246, 0x177a903c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 247, 0x024df00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 248, 0x0029e004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 249, 0x608b031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 250, 0xf071e804);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 251, 0x6081031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 252, 0x1047e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 253, 0x6081031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 254, 0x3c008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 255, 0xd0339fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 256, 0x600b010d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 257, 0x3b808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 258, 0x1119b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 259, 0xd11f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 260, 0x20347050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 261, 0x20337068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 262, 0x127db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 263, 0xf371e804);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 264, 0x608b8115);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 265, 0x20327028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 266, 0x17800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 267, 0x6000813d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 268, 0x20b77034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 269, 0x04500000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 270, 0x20b47040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 271, 0x06698018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 272, 0x033c9800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 273, 0x00001fff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 274, 0x133db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 275, 0x60808349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 276, 0x20b3703c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 277, 0x6080810a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 278, 0x0883c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 279, 0x02800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 280, 0x3c80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 281, 0x07798011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 282, 0x20377024);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 283, 0x3b00c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 284, 0x11090002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 285, 0x2831704c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 286, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 287, 0x28317064);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 288, 0x5b804000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 289, 0x166a8020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 290, 0xb1409ff0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 291, 0x0119f004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 292, 0x074df00c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 293, 0x1079e006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 294, 0x600b831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 295, 0x20317048);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 296, 0xf732c888);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 297, 0x20307094);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 298, 0x20307098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 299, 0x20b0709c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 300, 0x0039e880);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 301, 0x608b8131);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 302, 0x20b070a0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 303, 0x1039e4c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 304, 0x60030349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 305, 0x0057e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 306, 0x6082031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 307, 0x15700800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 308, 0x11300540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 309, 0xd11f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 310, 0x0219f008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 311, 0x122a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 312, 0x12200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 313, 0x20b27038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 314, 0x02800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 315, 0xf222ea02);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 316, 0x20b27034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 317, 0x17800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 318, 0x177ae200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 319, 0x600a031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 320, 0x779003c8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 321, 0x01600291);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 322, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 323, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 324, 0x03490186);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 325, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 326, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 327, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 328, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 329, 0x01bc0349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 330, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 331, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 332, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 333, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 334, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 335, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 336, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 337, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 338, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 339, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 340, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 341, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 342, 0x02ce0349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 343, 0x034902f1);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 344, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 345, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 346, 0x8349027b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 347, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 348, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 349, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 350, 0x83490172);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 351, 0x02f602a8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 352, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 353, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 354, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 355, 0x600b831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 356, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 357, 0x011db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 358, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 359, 0x1119b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 360, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 361, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 362, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 363, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 364, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 365, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 366, 0x46b04050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 367, 0x12000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 368, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 369, 0x20327028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 370, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 371, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 372, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 373, 0x6083831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 374, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 375, 0x011db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 376, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 377, 0x1119b008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 378, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 379, 0x011987c2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 380, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 381, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 382, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 383, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 384, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 385, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 386, 0x46b04050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 387, 0x12000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 388, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 389, 0x20327028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 390, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 391, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 392, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 393, 0x3c80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 394, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 395, 0x6083818e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 396, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 397, 0x011987c2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 398, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 399, 0x011db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 400, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 401, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 402, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 403, 0x144db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 404, 0x20647000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 405, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 406, 0x46b04050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 407, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 408, 0x600b819c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 409, 0x20b4707c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 410, 0x6000819d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 411, 0x005ae028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 412, 0x005ae03c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 413, 0x6082031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 414, 0x00048800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 415, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 416, 0x10048820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 417, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 418, 0x0044e820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 419, 0x600b01b6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 420, 0x21308050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 421, 0x22b08068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 422, 0x0012e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 423, 0x600b01b6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 424, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 425, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 426, 0x21b08054);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 427, 0x2230806c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 428, 0x0012e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 429, 0x600b01b6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 430, 0x21b08058);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 431, 0x22b08070);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 432, 0x0012e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 433, 0x600b01b6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 434, 0x2130805c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 435, 0x22308074);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 436, 0x0012e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 437, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 438, 0x0889c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 439, 0x3980c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 440, 0xe1129a89);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 441, 0xf012e889);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 442, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 443, 0x60000354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 444, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 445, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 446, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 447, 0x3c80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 448, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 449, 0x600381c4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 450, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 451, 0x011987c2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 452, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 453, 0x3380c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 454, 0x011db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 455, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 456, 0x600b81cc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 457, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 458, 0x600081cd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 459, 0x105ae01c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 460, 0x005ae030);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 461, 0x6082031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 462, 0x144db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 463, 0x10048820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 464, 0x6083831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 465, 0x20b4707c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 466, 0x00048800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 467, 0x6083831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 468, 0x20337080);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 469, 0x23b08000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 470, 0x104ce880);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 471, 0x00001194);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 472, 0x600301ed);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 473, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 474, 0xe018e488);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 475, 0x600301e7);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 476, 0x0029e888);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 477, 0x6081031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 478, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 479, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 480, 0x20647000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 481, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 482, 0x46b04050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 483, 0x02399018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 484, 0x600b01fd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 485, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 486, 0x203070b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 487, 0x0029e888);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 488, 0x600101ea);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 489, 0x600001de);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 490, 0x0029e881);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 491, 0x608101de);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 492, 0x6000031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 493, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 494, 0x1029e88c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 495, 0x60810349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 496, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 497, 0x1020e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 498, 0x600b01f4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 499, 0x60000349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 500, 0x20627000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 501, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 502, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 503, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 504, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 505, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 506, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 507, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 508, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 509, 0x20bc70b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 510, 0x0000000d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 511, 0x02399014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 512, 0x60030206);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 513, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 514, 0x203870b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 515, 0x00000011);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 516, 0x022db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 517, 0x78a0031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 518, 0x22b0802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 519, 0x155ae020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 520, 0x0552c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 521, 0x22b08034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 522, 0x0229c008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 523, 0x20b27034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 524, 0x14800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 525, 0x1234e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 526, 0x0229e80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 527, 0x6001830d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 528, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 529, 0x025ce800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 530, 0x00000fe0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 531, 0x600a030d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 532, 0x3700c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 533, 0x3280900b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 534, 0x077c9040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 535, 0x00fcfffd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 536, 0x0078e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 537, 0x0014fefd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 538, 0x608b030d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 539, 0x1442c540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 540, 0x1449da80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 541, 0x3200900c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 542, 0x1442c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 543, 0x1449d540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 544, 0x144ae013);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 545, 0x1054e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 546, 0x6081030d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 547, 0x608b0230);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 548, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 549, 0x20840000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 550, 0x184a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 551, 0x0b090831);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 552, 0x5b808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 553, 0x203070b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 554, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 555, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 556, 0x11400000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 557, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 558, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 559, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 560, 0x20840000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 561, 0x184a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 562, 0x0b090831);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 563, 0x5b808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 564, 0x12090023);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 565, 0x1221aa80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 566, 0x20b270b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 567, 0x0a0a0200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 568, 0x0b090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 569, 0x5ab06000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 570, 0x23a08200);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 571, 0xa33f9800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 572, 0x13348000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 573, 0xe332c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 574, 0x20b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 575, 0x27b0802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 576, 0xf2309017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 577, 0x1227e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 578, 0x122db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 579, 0x20b27020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 580, 0x20b01000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 581, 0x1254e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 582, 0x0229e80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 583, 0x60818311);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 584, 0x20307034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 585, 0x3700c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 586, 0x3280900b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 587, 0x077c9040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 588, 0x00fcfffd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 589, 0x0078e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 590, 0x0014fefd);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 591, 0x600b0311);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 592, 0x16400800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 593, 0x1442c540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 594, 0x03200500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 595, 0x1449da80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 596, 0x3200900c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 597, 0x1442c400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 598, 0x1449d540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 599, 0x0449c00d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 600, 0x1054e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 601, 0x6081830f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 602, 0x13200400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 603, 0x600b025d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 604, 0x11090001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 605, 0x02090021);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 606, 0x1221aa80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 607, 0x0719b00f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 608, 0x12278aa0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 609, 0x20b270b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 610, 0x20840000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 611, 0x184a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 612, 0x0b090831);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 613, 0x5b808000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 614, 0x1339c80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 615, 0x20b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 616, 0xf2309017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 617, 0x122db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 618, 0x20b27020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 619, 0x20307034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 620, 0x20bc70b8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 621, 0x0000000d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 622, 0x2030702c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 623, 0x1a0a0204);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 624, 0x1b090004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 625, 0x5ba05000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 626, 0x78900244);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 627, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 628, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 629, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 630, 0x11400000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 631, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 632, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 633, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 634, 0x60000349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 635, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 636, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 637, 0x3b00c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 638, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 639, 0x60838282);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 640, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 641, 0x011987c2);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 642, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 643, 0x011db008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 644, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 645, 0x20627000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 646, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 647, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 648, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 649, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 650, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 651, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 652, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 653, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 654, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 655, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 656, 0x20327084);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 657, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 658, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 659, 0x11800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 660, 0x27b0802c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 661, 0x0117e400);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 662, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 663, 0x1717c700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 664, 0xf012e408);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 665, 0x608b031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 666, 0x21b08038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 667, 0x012004c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 668, 0x20b17038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 669, 0x0129c481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 670, 0x011db00d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 671, 0xc11f9ff8);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 672, 0x17100900);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 673, 0x117006c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 674, 0x0111c820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 675, 0x20b17034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 676, 0x08100800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 677, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 678, 0x60008140);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 679, 0x112005c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 680, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 681, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 682, 0x21b08098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 683, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 684, 0x23308038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 685, 0x10108440);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 686, 0x608382b4);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 687, 0x07200680);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 688, 0x1119c541);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 689, 0x07100540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 690, 0x600082bf);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 691, 0x20b17098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 692, 0x07090500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 693, 0x132004c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 694, 0x20337038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 695, 0x03800a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 696, 0x0339ea84);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 697, 0x03200480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 698, 0x1339c801);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 699, 0x133db80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 700, 0x033d9808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 701, 0x1333c820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 702, 0x20337034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 703, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 704, 0x11700480);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 705, 0x1119c801);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 706, 0x111db80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 707, 0x011d9808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 708, 0x11800a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 709, 0x0119ea84);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 710, 0x0111c820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 711, 0x08100800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 712, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 713, 0x0079e441);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 714, 0x608b8140);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 715, 0x112005c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 716, 0x60008140);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 717, 0x20b77098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 718, 0x2730809c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 719, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 720, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 721, 0x1007e000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 722, 0x600b831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 723, 0x11800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 724, 0x07000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 725, 0x17100a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 726, 0x3a80c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 727, 0x21b08038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 728, 0x012004c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 729, 0x20b17038);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 730, 0x0129c481);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 731, 0x111db80d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 732, 0x011d9808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 733, 0x17100500);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 734, 0x01700a80);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 735, 0x0111c820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 736, 0x12208540);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 737, 0x608b82e6);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 738, 0x20b17034);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 739, 0x0029e482);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 740, 0x6082031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 741, 0x60000349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 742, 0x203c7098);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 743, 0x00000100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 744, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 745, 0x11700880);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 746, 0x01700640);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 747, 0x0111c820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 748, 0x08100800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 749, 0x112005c0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 750, 0xd11f9f00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 751, 0x60008140);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 752, 0x2037709c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 753, 0x006a9020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 754, 0x6003031f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 755, 0x60808349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 756, 0x06698018);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 757, 0x60000349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 758, 0xe018e448);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 759, 0x608301bc);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 760, 0x779fd028);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 761, 0x82fb02fb);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 762, 0x83490349);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 763, 0x04800800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 764, 0x04500a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 765, 0x20b47020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 766, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 767, 0x20617000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 768, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 769, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 770, 0x20e07000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 771, 0x46304068);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 772, 0x46b04050);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 773, 0xf141e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 774, 0x08100800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 775, 0x3100c000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 776, 0x11000700);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 777, 0x11000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 778, 0x20317044);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 779, 0x60808354);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 780, 0xe841c800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 781, 0x6080831f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 782, 0x203070b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 783, 0x60008312);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 784, 0x1356e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 785, 0x0354e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 786, 0x203c70b0);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 787, 0x00020000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 788, 0x20b37000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 789, 0xf2309017);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 790, 0x23a08214);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 791, 0x0339f008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 792, 0x133a90ff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 793, 0x1223e800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 794, 0x122db000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 795, 0x20b27020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 796, 0x1a0a0204);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 797, 0x1b090004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 798, 0x5ba05000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 799, 0xb6618000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 800, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 801, 0x20307008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 802, 0x20b0700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 803, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 804, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 805, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 806, 0x11400000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 807, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 808, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 809, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 810, 0x11090004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 811, 0x01108a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 812, 0x6083832a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 813, 0x11000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 814, 0x20b17020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 815, 0xb66c8040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 816, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 817, 0x20307008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 818, 0x20b0700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 819, 0xb2030100);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 820, 0x20b27010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 821, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 822, 0x11090004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 823, 0x01108a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 824, 0x60038336);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 825, 0x11000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 826, 0x20b17020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 827, 0xb66c8040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 828, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 829, 0x20307008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 830, 0x20b0700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 831, 0xa2030000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 832, 0x20b27010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 833, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 834, 0x11090004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 835, 0x01108a00);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 836, 0x60038342);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 837, 0x11000800);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 838, 0x20b17020);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 839, 0x20b27010);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 840, 0x20347014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 841, 0xb6608040);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 842, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 843, 0x20307008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 844, 0x20b0700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 845, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 846, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 847, 0x608b832b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 848, 0x11400000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 849, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 850, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 851, 0x90800000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 852, 0x21b08008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 853, 0x2230800c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 854, 0x00199003);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 855, 0x6083035c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 856, 0x6080804a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 857, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 858, 0x6080804a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 859, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 860, 0x20bd7008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 861, 0x20bf700c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 862, 0x16698004);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 863, 0x20b67000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 864, 0x06699008);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 865, 0x600b0365);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 866, 0x20681000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 867, 0x00088000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 868, 0x60000367);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 869, 0x20ec1000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 870, 0x0008a000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 871, 0x21008000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 872, 0x2300f000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 873, 0xc0349000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 874, 0x600b032b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 875, 0xc0329000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 876, 0x608b0337);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 877, 0x90800000);
+	for (i = 878; i < 1008; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + i*4, 0x10000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1008, 0x1a090000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1009, 0x42901000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1010, 0x00000230);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1011, 0x1a0a0014);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1012, 0x42901000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1013, 0x00000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1014, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1015, 0x10000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1016, 0x10000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_RAM_CTRL_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG, 0x03000000);
+
+	for (i = 0; i < 32; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_RAM + i*4, 0x00000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_FPP_CTRL_REG, 0x0bf00008);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_PUE_CTRL_REG, 0x03f00008);
+
+	times = 0;
+	do {
+		reg_data = mv_pp3_cmac_reg_read(MV_EIP197_PE_0_ICE_SCRATCH_RAM + i * 6);
+	} while ((((reg_data) & (0x00000001)) != 0x00000001) && (times++ < 1000));
+	times = 0;
+	do {
+		reg_data = mv_pp3_cmac_reg_read(MV_EIP197_PE_0_ICE_SCRATCH_RAM + i * 5);
+	} while ((((reg_data) & (0x00000001)) != 0x00000001) && (times++ < 1000));
+
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_RAM + 4 * 25, 0x00000100);
+	mv_pp3_cmac_reg_write(MV_EIP197_PE_0_ICE_SCRATCH_RAM + 4 * 24, 0x00000001);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DFE_0_THR_CTRL_REG, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_THR_CTRL_REG, 0x80000000);
+
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_RA_PE_0_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RA_PE_0_CTRL_REG, 0x40000000);
+
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_DFE_0_THR_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DFE_0_THR_CTRL_REG, 0x40000000);
+
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_DSE_0_THR_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_THR_CTRL_REG, 0x40000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_DMA_CFG_REG, 0x01c00000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_LO_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_LO_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_RING_SIZE_REG, 0x00004000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_DESC_SIZE_REG, 0x8010000c);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_CFG_REG, 0x80800200);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_PREP_COUNT_REG, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_PROC_COUNT_REG, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_PREP_PNTR_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_PROC_PNTR_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_THRESH_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RDR_0_STAT_REG, 0x000000ff);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_DSE_0_THR_CTRL_REG);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_THR_CTRL_REG, 0x40000001);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_LO_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_LO_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_CFG_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_COUNT_REG, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_PROC_COUNT_REG, 0x80000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_PREP_PNTR_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_PROC_PNTR_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_RING_SIZE_REG, 0x00004000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_LO_REG, 0x00004000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_REG, 0x00004000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_DMA_CFG_REG, 0x01000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_DESC_SIZE_REG, 0xc010000c);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_CFG_REG, 0x807800a0);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_THRESH_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_CDR_0_STAT_REG, 0x0000003f);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_RA_PE_0_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RA_PE_0_CTRL_REG, 0x40000001);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_DSE_0_THR_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_THR_CTRL_REG, 0x40000002);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_RA_PE_0_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RA_PE_0_CTRL_REG, 0x40000003);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_DSE_0_THR_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_DSE_0_THR_CTRL_REG, 0x40000004);
+	reg_data = mv_pp3_cmac_reg_read(MV_EIP197_HIA_RA_PE_0_CTRL_REG);
+	mv_pp3_cmac_reg_write(MV_EIP197_HIA_RA_PE_0_CTRL_REG, 0x40000007);
+	mv_pp3_cmac_reg_write(MV_EIP197_CS_RAM_CTRL_REG, 0x00000010);
+	mv_pp3_cmac_reg_write(MV_EIP197_TRC_0_PARAMS_REG, 0x00000001);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 0, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 1, 0x000ffc01);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 2, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 3, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 4, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 5, 0x00000002);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 6, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 7, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 8, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 9, 0x00000403);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 10, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 11, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 12, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 13, 0x00000804);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 14, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 15, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 16, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 17, 0x00000c05);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 18, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 19, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 20, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 21, 0x00001006);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 22, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 23, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 24, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 25, 0x00001407);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 26, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 27, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 28, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 29, 0x00001808);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 30, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 31, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 32, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 33, 0x00001c09);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 34, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 35, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 36, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 37, 0x0000200a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 38, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 39, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 40, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 41, 0x0000240b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 42, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 43, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 44, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 45, 0x0000280c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 46, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 47, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 48, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 49, 0x00002c0d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 50, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 51, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 52, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 53, 0x0000300e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 54, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 55, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 56, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 57, 0x0000340f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 58, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 59, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 60, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 61, 0x00003810);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 62, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 63, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 64, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 65, 0x00003c11);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 66, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 67, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 68, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 69, 0x00004012);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 70, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 71, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 72, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 73, 0x00004413);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 74, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 75, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 76, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 77, 0x00004814);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 78, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 79, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 80, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 81, 0x00004c15);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 82, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 83, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 84, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 85, 0x00005016);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 86, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 87, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 88, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 89, 0x00005417);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 90, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 91, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 92, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 93, 0x00005818);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 94, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 95, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 96, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 97, 0x00005c19);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 98, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 99, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 100, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 101, 0x0000601a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 102, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 103, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 104, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 105, 0x0000641b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 106, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 107, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 108, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 109, 0x0000681c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 110, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 111, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 112, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 113, 0x00006c1d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 114, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 115, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 116, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 117, 0x0000701e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 118, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 119, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 120, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 121, 0x0000741f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 122, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 123, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 124, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 125, 0x00007820);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 126, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 127, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 128, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 129, 0x00007c21);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 130, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 131, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 132, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 133, 0x00008022);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 134, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 135, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 136, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 137, 0x00008423);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 138, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 139, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 140, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 141, 0x00008824);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 142, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 143, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 144, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 145, 0x00008c25);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 146, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 147, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 148, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 149, 0x00009026);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 150, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 151, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 152, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 153, 0x00009427);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 154, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 155, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 156, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 157, 0x00009828);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 158, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 159, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 160, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 161, 0x00009c29);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 162, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 163, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 164, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 165, 0x0000a02a);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 166, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 167, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 168, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 169, 0x0000a42b);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 170, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 171, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 172, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 173, 0x0000a82c);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 174, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 175, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 176, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 177, 0x0000ac2d);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 178, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 179, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 180, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 181, 0x0000b02e);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 182, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 183, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 184, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 185, 0x0000b42f);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 186, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 187, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 188, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 189, 0x0000bbff);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 190, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + 4 * 191, 0x00000000);
+	for (i = 192; i < 320; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + i*4, 0xffffffff);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_TRC_0_PARAMS_REG, 0x00000005);
+	for (i = 0; i < 3840; i++)
+		mv_pp3_cmac_reg_write(MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE + i*4, 0x00000000);
+
+	mv_pp3_cmac_reg_write(MV_EIP197_CS_RAM_CTRL_REG, 0x00000000);
+	mv_pp3_cmac_reg_write(MV_EIP197_TRC_0_FREECHAIN_REG, 0x002f0000);
+	mv_pp3_cmac_reg_write(MV_EIP197_TRC_0_PARAMS2_REG, 0x01001c30);
+	mv_pp3_cmac_reg_write(MV_EIP197_TRC_0_PARAMS_REG, 0x01400430);
+	mv_pp3_cmac_reg_write(MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_REG, 1);
+}
+
+
+/* check CMAC idle state */
+bool mv_cmac_idle_state_check(void)
+{
+	return mv_pp3_cmac_reg_read(MV_CMAC_CMAC_STATUS_REG) & MV_CMAC_CMAC_STATUS_CMAC_IDLE_MASK;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.h b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.h
new file mode 100644
index 0000000..2f273ca
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac.h
@@ -0,0 +1,47 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_cmac_h__
+#define __mv_cmac_h__
+
+/* print value of unit registers */
+void mv_cmac_top_regs_dump(void);
+void mv_cmac_eip197_regs_dump(void);
+
+/* check CMAC idle state */
+bool mv_cmac_idle_state_check(void);
+
+void mv_pp3_cmac_init(void __iomem *base);
+/* CMAC EIP 197 unit configuration */
+void mv_pp3_cmac_config(void);
+/* debug functions */
+void mv_pp3_cmac_debug_cfg(int flags);
+
+int mv_pp3_cmac_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_cmac_sysfs_exit(struct kobject *cmac_kobj);
+
+#endif /* __mv_cmac_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_regs.h b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_regs.h
new file mode 100644
index 0000000..062eac7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_regs.h
@@ -0,0 +1,114 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef	__mv_cmac_regs_h__
+#define	__mv_cmac_regs_h__
+
+
+/* Cmac Status */
+#define MV_CMAC_CMAC_STATUS_REG								(0x002fc000)
+#define MV_CMAC_CMAC_STATUS_CMAC_IDLE_OFFS		0
+#define MV_CMAC_CMAC_STATUS_CMAC_IDLE_MASK    \
+		(0x00000001 << MV_CMAC_CMAC_STATUS_CMAC_IDLE_OFFS)
+
+
+/* Cmac Il Next Hop C1 Field Change */
+#define MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_REG					(0x002fc040)
+#define MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_IND_FIFO_COPY_NEXT_HOP_C1_FIELD_OFFS		0
+#define MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_IND_FIFO_COPY_NEXT_HOP_C1_FIELD_MASK    \
+		(0x00000001 << MV_CMAC_CMAC_IL_NEXT_HOP_C1_FIELD_CHANGE_IND_FIFO_COPY_NEXT_HOP_C1_FIELD_OFFS)
+
+
+/* Cmac La Next Hop C1 Field Change */
+#define MV_CMAC_CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE_REG					(0x002fc044)
+#define MV_CMAC_CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE_LAD_FIFO_COPY_NEXT_HOP_C1_FIELD_OFFS		0
+#define MV_CMAC_CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE_LAD_FIFO_COPY_NEXT_HOP_C1_FIELD_MASK    \
+		(0x00000001 << MV_CMAC_CMAC_LA_NEXT_HOP_C1_FIELD_CHANGE_LAD_FIFO_COPY_NEXT_HOP_C1_FIELD_OFFS)
+
+
+/* Cmac Il Enq Checksum Offset */
+#define MV_CMAC_CMAC_IL_ENQ_CHECKSUM_OFFSET_REG					(0x002fc048)
+#define MV_CMAC_CMAC_IL_ENQ_CHECKSUM_OFFSET_CHECKSUM_OFFSET_OFFS		0
+#define MV_CMAC_CMAC_IL_ENQ_CHECKSUM_OFFSET_CHECKSUM_OFFSET_MASK    \
+		(0x0000007f << MV_CMAC_CMAC_IL_ENQ_CHECKSUM_OFFSET_CHECKSUM_OFFSET_OFFS)
+
+
+/* Cmac Il Axi Config */
+#define MV_CMAC_CMAC_IL_AXI_CONFIG_REG					(0x002fc080)
+#define MV_CMAC_CMAC_IL_AXI_CONFIG_AXI4_IL_DEQ_PORT_NUMBER_OFFS		0
+#define MV_CMAC_CMAC_IL_AXI_CONFIG_AXI4_IL_DEQ_PORT_NUMBER_MASK    \
+		(0x00000fff << MV_CMAC_CMAC_IL_AXI_CONFIG_AXI4_IL_DEQ_PORT_NUMBER_OFFS)
+
+
+/* Cmac La Axi Config */
+#define MV_CMAC_CMAC_LA_AXI_CONFIG_REG					(0x002fc084)
+#define MV_CMAC_CMAC_LA_AXI_CONFIG_AXI4_LA_DEQ_PORT_NUMBER_OFFS		0
+#define MV_CMAC_CMAC_LA_AXI_CONFIG_AXI4_LA_DEQ_PORT_NUMBER_MASK    \
+		(0x00000fff << MV_CMAC_CMAC_LA_AXI_CONFIG_AXI4_LA_DEQ_PORT_NUMBER_OFFS)
+
+
+/* Cmac Debug Il Fifo Fill Level */
+#define MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_REG					(0x002fc0c0)
+#define MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_IND_FIFO_OFFS		0
+#define MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_IND_FIFO_MASK    \
+		(0x000000ff << MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_IND_FIFO_OFFS)
+
+#define MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_INE_FIFO_OFFS		8
+#define MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_INE_FIFO_MASK    \
+		(0x000000ff << MV_CMAC_CMAC_DEBUG_IL_FIFO_FILL_LEVEL_INE_FIFO_OFFS)
+
+
+/* Cmac Debug La Fifo Fill Level */
+#define MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_REG				(0x002fc0c4)
+#define MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAD_FIFO_OFFS		0
+#define MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAD_FIFO_MASK    \
+		(0x000000ff << MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAD_FIFO_OFFS)
+
+#define MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAE_FIFO_OFFS		8
+#define MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAE_FIFO_MASK    \
+		(0x000000ff << MV_CMAC_CMAC_DEBUG_LA_FIFO_FILL_LEVEL_LAE_FIFO_OFFS)
+
+
+/* Cmac Debug Il Eip Packet Count */
+#define MV_CMAC_CMAC_DEBUG_IL_EIP_PCKT_CNT_REG					(0x002fc0c8)
+#define MV_CMAC_CMAC_DEBUG_IL_EIP_PCKT_CNT_EIP_IL_PACKET_COUNT_OFFS		0
+#define MV_CMAC_CMAC_DEBUG_IL_EIP_PCKT_CNT_EIP_IL_PACKET_COUNT_MASK    \
+		(0x0000ffff << MV_CMAC_CMAC_DEBUG_IL_EIP_PCKT_CNT_EIP_IL_PACKET_COUNT_OFFS)
+
+
+/* Cmac Debug La Eip Packet Count */
+#define MV_CMAC_CMAC_DEBUG_LA_EIP_PCKT_CNT_REG					(0x002fc0cc)
+#define MV_CMAC_CMAC_DEBUG_LA_EIP_PCKT_CNT_EIP_LA_PACKET_COUNT_OFFS		0
+#define MV_CMAC_CMAC_DEBUG_LA_EIP_PCKT_CNT_EIP_LA_PACKET_COUNT_MASK    \
+		(0x0000ffff << MV_CMAC_CMAC_DEBUG_LA_EIP_PCKT_CNT_EIP_LA_PACKET_COUNT_OFFS)
+
+
+/* Cmac Spare  */
+#define MV_CMAC_CMAC_SPARE_REG(n)						(0x002fc0e0 + n*4)
+#define MV_CMAC_CMAC_SPARE_CMAC_SPR_OFFS		0
+
+#endif /* __mv_cmac_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_sysfs.c b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_sysfs.c
new file mode 100644
index 0000000..b1412e4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/cmac/mv_cmac_sysfs.c
@@ -0,0 +1,135 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "cmac/mv_cmac.h"
+
+static ssize_t mv_cmac_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat            regs           - Dump CMAC unit registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat            eip197_regs    - Dump EIP197 units registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat            cmac_cfg       - Run default CMAC configuration\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [v]       > debug        - 0 disable, bit0 enable read, bit1 enable write debug outputs\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_cmac_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int err = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		return mv_cmac_help(buf);
+	else if (!strcmp(name, "regs"))
+		mv_cmac_top_regs_dump();
+	else if (!strcmp(name, "eip197_regs"))
+		mv_cmac_eip197_regs_dump();
+	else if (!strcmp(name, "cmac_cfg"))
+		mv_pp3_cmac_config();
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	return err;
+}
+
+static ssize_t mv_cmac_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	unsigned int    p, err;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read parameters */
+	p = err = 0;
+	sscanf(buf, "%d", &p);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "debug"))
+		mv_pp3_cmac_debug_cfg(p);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,	S_IRUSR, mv_cmac_show, NULL);
+static DEVICE_ATTR(regs,	S_IRUSR, mv_cmac_show, NULL);
+static DEVICE_ATTR(eip197_regs, S_IRUSR, mv_cmac_show, NULL);
+static DEVICE_ATTR(cmac_cfg,	S_IRUSR, mv_cmac_show, NULL);
+static DEVICE_ATTR(debug,	S_IWUSR, NULL, mv_cmac_store);
+
+static struct attribute *mv_cmac_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_eip197_regs.attr,
+	&dev_attr_cmac_cfg.attr,
+	&dev_attr_debug.attr,
+	NULL
+};
+
+static struct attribute_group mv_cmac_group = {
+	.name = "cmac",
+	.attrs = mv_cmac_attrs,
+};
+
+int mv_pp3_cmac_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &mv_cmac_group);
+	if (err) {
+		pr_err("sysfs group failed %d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_cmac_sysfs_exit(struct kobject *cmac_kobj)
+{
+	sysfs_remove_group(cmac_kobj, &mv_cmac_group);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/cmac/mv_eip197_regs.h b/drivers/net/ethernet/marvell/pp3/cmac/mv_eip197_regs.h
new file mode 100644
index 0000000..cb4c3fd
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/cmac/mv_eip197_regs.h
@@ -0,0 +1,4960 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef	__mv_eip197_h__
+#define	__mv_eip197_h__
+
+/* HIA_CDR_0_RING_BASE_ADDR_LO */
+#define MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_LO_REG					(0x00280000)
+#define MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_LO_CDR_BASE_ADDR_OFFS		0
+
+/* HIA_CDR_0_RING_BASE_ADDR_HI */
+#define MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_REG					(0x00280004)
+#define MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_CDR_BASE_ADDR_OFFS		0
+#define MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_CDR_BASE_ADDR_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_CDR_0_RING_BASE_ADDR_HI_CDR_BASE_ADDR_OFFS)
+
+
+/* HIA_CDR_0_DATA_BASE_ADDR_LO */
+#define MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_LO_REG					(0x00280008)
+#define MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_LO_CDR_DBASE_ADDR_OFFS		0
+
+/* HIA_CDR_0_DATA_BASE_ADDR_HI */
+#define MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_REG					(0x0028000c)
+#define MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_CDR_DBASE_ADDR_OFFS		0
+#define MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_CDR_DBASE_ADDR_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_CDR_0_DATA_BASE_ADDR_HI_CDR_DBASE_ADDR_OFFS)
+
+
+/* HIA_CDR_0_ATOK_BASE_ADDR_LO */
+#define MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_LO_REG					(0x00280010)
+#define MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_LO_CDR_ACDBASE_ADDR_OFFS		0
+
+/* HIA_CDR_0_ATOK_BASE_ADDR_HI */
+#define MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_REG					(0x00280014)
+#define MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_CDR_ACDBASE_ADDR_OFFS		0
+#define MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_CDR_ACDBASE_ADDR_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_CDR_0_ATOK_BASE_ADDR_HI_CDR_ACDBASE_ADDR_OFFS)
+
+
+/* HIA_CDR_0_RING_SIZE */
+#define MV_EIP197_HIA_CDR_0_RING_SIZE_REG					(0x00280018)
+#define MV_EIP197_HIA_CDR_0_RING_SIZE_CDR_SIZE_OFFS		2
+#define MV_EIP197_HIA_CDR_0_RING_SIZE_CDR_SIZE_MASK    \
+		(0x003fffff << MV_EIP197_HIA_CDR_0_RING_SIZE_CDR_SIZE_OFFS)
+
+
+/* HIA_CDR_0_DESC_SIZE */
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_REG					(0x0028001c)
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_SIZE_OFFS		0
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_SIZE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_OFFSET_OFFS		16
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_OFFSET_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CDR_0_DESC_SIZE_CD_OFFSET_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_ACDP_PRESENT_OFFS		30
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_ACDP_PRESENT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_DESC_SIZE_ACDP_PRESENT_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_MODE_64_BIT_OFFS		31
+#define MV_EIP197_HIA_CDR_0_DESC_SIZE_MODE_64_BIT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_DESC_SIZE_MODE_64_BIT_OFFS)
+
+
+/* HIA_CDR_0_CFG */
+#define MV_EIP197_HIA_CDR_0_CFG_REG					(0x00280020)
+#define MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_SIZE_OFFS		0
+#define MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_SIZE_MASK    \
+		(0x00001fff << MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_SIZE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_THRESH_OFFS		18
+#define MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_THRESH_MASK    \
+		(0x0000001f << MV_EIP197_HIA_CDR_0_CFG_CD_FETCH_THRESH_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_CFG_SSM_ENABLE_OFFS		28
+#define MV_EIP197_HIA_CDR_0_CFG_SSM_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_CFG_SSM_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_CFG_ETM_DUAL_EDGE_OFFS		30
+#define MV_EIP197_HIA_CDR_0_CFG_ETM_DUAL_EDGE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_CFG_ETM_DUAL_EDGE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_CFG_ETM_ENABLE_OFFS		31
+#define MV_EIP197_HIA_CDR_0_CFG_ETM_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_CFG_ETM_ENABLE_OFFS)
+
+
+/* HIA_CDR_0_DMA_CFG */
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_REG					(0x00280024)
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_CD_SWAP_OFFS		0
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_CD_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_CD_SWAP_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_CD_PROT_OFFS		4
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_CD_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_CD_PROT_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_SWAP_OFFS		8
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_PROT_OFFS		12
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_DATA_PROT_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_SWAP_OFFS		16
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_SWAP_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_PROT_OFFS		20
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_ACD_PROT_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_WR_OWN_BUF_OFFS		24
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_WR_OWN_BUF_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_DMA_CFG_WR_OWN_BUF_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_WR_CACHE_OFFS		25
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_WR_CACHE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_WR_CACHE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_RD_CACHE_OFFS		29
+#define MV_EIP197_HIA_CDR_0_DMA_CFG_RD_CACHE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_DMA_CFG_RD_CACHE_OFFS)
+
+
+/* HIA_CDR_0_THRESH */
+#define MV_EIP197_HIA_CDR_0_THRESH_REG					(0x00280028)
+#define MV_EIP197_HIA_CDR_0_THRESH_PREP_CD_THRESH_OFFS		0
+#define MV_EIP197_HIA_CDR_0_THRESH_PREP_CD_THRESH_MASK    \
+		(0x003fffff << MV_EIP197_HIA_CDR_0_THRESH_PREP_CD_THRESH_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_THRESH_PROC_MODE_OFFS		22
+#define MV_EIP197_HIA_CDR_0_THRESH_PROC_MODE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_THRESH_PROC_MODE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_THRESH_PKT_MODE_OFFS		23
+#define MV_EIP197_HIA_CDR_0_THRESH_PKT_MODE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_THRESH_PKT_MODE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_THRESH_CD_TIMEOUT_OFFS		24
+#define MV_EIP197_HIA_CDR_0_THRESH_CD_TIMEOUT_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CDR_0_THRESH_CD_TIMEOUT_OFFS)
+
+
+/* HIA_CDR_0_COUNT */
+#define MV_EIP197_HIA_CDR_0_COUNT_REG					(0x0028002c)
+#define MV_EIP197_HIA_CDR_0_COUNT_PREP_CD_COUNT_INCR_OFFS		2
+#define MV_EIP197_HIA_CDR_0_COUNT_PREP_CD_COUNT_INCR_MASK    \
+		(0x00003fff << MV_EIP197_HIA_CDR_0_COUNT_PREP_CD_COUNT_INCR_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_COUNT_UPDATE_PROC_OFFS		29
+#define MV_EIP197_HIA_CDR_0_COUNT_UPDATE_PROC_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_COUNT_UPDATE_PROC_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_COUNT_CONTINUE_OFFS		30
+#define MV_EIP197_HIA_CDR_0_COUNT_CONTINUE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_COUNT_CONTINUE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_COUNT_CLEAR_COUNT_OFFS		31
+#define MV_EIP197_HIA_CDR_0_COUNT_CLEAR_COUNT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_COUNT_CLEAR_COUNT_OFFS)
+
+
+/* HIA_CDR_0_PROC_COUNT */
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_REG					(0x00280030)
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_CD_COUNT_DECR_OFFS		2
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_CD_COUNT_DECR_MASK    \
+		(0x00003fff << MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_CD_COUNT_DECR_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_OFFS		24
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_MASK    \
+		(0x0000007f << MV_EIP197_HIA_CDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_CLEAR_COUNT_OFFS		31
+#define MV_EIP197_HIA_CDR_0_PROC_COUNT_CLEAR_COUNT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_PROC_COUNT_CLEAR_COUNT_OFFS)
+
+
+/* HIA_CDR_0_PREP_PNTR */
+#define MV_EIP197_HIA_CDR_0_PREP_PNTR_REG					(0x00280034)
+#define MV_EIP197_HIA_CDR_0_PREP_PNTR_PREP_CDR_PNTR_OFFS		2
+#define MV_EIP197_HIA_CDR_0_PREP_PNTR_PREP_CDR_PNTR_MASK    \
+		(0x003fffff << MV_EIP197_HIA_CDR_0_PREP_PNTR_PREP_CDR_PNTR_OFFS)
+
+
+/* HIA_CDR_0_PROC_PNTR */
+#define MV_EIP197_HIA_CDR_0_PROC_PNTR_REG					(0x00280038)
+#define MV_EIP197_HIA_CDR_0_PROC_PNTR_PROC_CDR_PNTR_OFFS		2
+#define MV_EIP197_HIA_CDR_0_PROC_PNTR_PROC_CDR_PNTR_MASK    \
+		(0x003fffff << MV_EIP197_HIA_CDR_0_PROC_PNTR_PROC_CDR_PNTR_OFFS)
+
+
+/* HIA_CDR_0_STAT */
+#define MV_EIP197_HIA_CDR_0_STAT_REG					(0x0028003c)
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_DMA_ERR_IRQ_OFFS		0
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_DMA_ERR_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_CDR_DMA_ERR_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_PREP_CD_THRESH_IRQ_OFFS		1
+#define MV_EIP197_HIA_CDR_0_STAT_PREP_CD_THRESH_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_PREP_CD_THRESH_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_ERR_IRQ_OFFS		2
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_ERR_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_CDR_ERR_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_OFLO_UFLO_IRQ_OFFS		3
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_OFLO_UFLO_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_CDR_OFLO_UFLO_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_PROC_CD_THRESH_IRQ_OFFS		4
+#define MV_EIP197_HIA_CDR_0_STAT_PROC_CD_THRESH_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_PROC_CD_THRESH_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_TIMEOUT_IRQ_OFFS		5
+#define MV_EIP197_HIA_CDR_0_STAT_CDR_TIMEOUT_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_CDR_TIMEOUT_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_THRESH_REQ_PEND_OFFS		8
+#define MV_EIP197_HIA_CDR_0_STAT_THRESH_REQ_PEND_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_THRESH_REQ_PEND_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_CD_FIFO_FREE_COUNT_OFFS		16
+#define MV_EIP197_HIA_CDR_0_STAT_CD_FIFO_FREE_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_HIA_CDR_0_STAT_CD_FIFO_FREE_COUNT_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_FORCE_IRQ_OFFS		30
+#define MV_EIP197_HIA_CDR_0_STAT_FORCE_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_FORCE_IRQ_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_STAT_PAUSED_SUSPEND_OFFS		31
+#define MV_EIP197_HIA_CDR_0_STAT_PAUSED_SUSPEND_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_STAT_PAUSED_SUSPEND_OFFS)
+
+
+/* HIA_CDR_0_OPTIONS */
+#define MV_EIP197_HIA_CDR_0_OPTIONS_REG					(0x002807f8)
+#define MV_EIP197_HIA_CDR_0_OPTIONS_N_RINGS_OFFS		0
+#define MV_EIP197_HIA_CDR_0_OPTIONS_N_RINGS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CDR_0_OPTIONS_N_RINGS_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_N_PES_OFFS		4
+#define MV_EIP197_HIA_CDR_0_OPTIONS_N_PES_MASK    \
+		(0x0000001f << MV_EIP197_HIA_CDR_0_OPTIONS_N_PES_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_CF_SIZE_OFFS		9
+#define MV_EIP197_HIA_CDR_0_OPTIONS_CF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_OPTIONS_CF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_RF_SIZE_OFFS		12
+#define MV_EIP197_HIA_CDR_0_OPTIONS_RF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_OPTIONS_RF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_EXT_PLW_OFFS		15
+#define MV_EIP197_HIA_CDR_0_OPTIONS_EXT_PLW_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_OPTIONS_EXT_PLW_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_HOST_IFC_OFFS		16
+#define MV_EIP197_HIA_CDR_0_OPTIONS_HOST_IFC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CDR_0_OPTIONS_HOST_IFC_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_DMA_LEN_OFFS		20
+#define MV_EIP197_HIA_CDR_0_OPTIONS_DMA_LEN_MASK    \
+		(0x0000001f << MV_EIP197_HIA_CDR_0_OPTIONS_DMA_LEN_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_HDW_OFFS		25
+#define MV_EIP197_HIA_CDR_0_OPTIONS_HDW_MASK    \
+		(0x00000007 << MV_EIP197_HIA_CDR_0_OPTIONS_HDW_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_PE_ARBITER_OFFS		29
+#define MV_EIP197_HIA_CDR_0_OPTIONS_PE_ARBITER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_OPTIONS_PE_ARBITER_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_TGT_ALIGN_OFFS		30
+#define MV_EIP197_HIA_CDR_0_OPTIONS_TGT_ALIGN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_OPTIONS_TGT_ALIGN_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_OPTIONS_ADDR_64_OFFS		31
+#define MV_EIP197_HIA_CDR_0_OPTIONS_ADDR_64_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CDR_0_OPTIONS_ADDR_64_OFFS)
+
+
+/* HIA_CDR_0_VERSION */
+#define MV_EIP197_HIA_CDR_0_VERSION_REG					(0x002807fc)
+#define MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CDR_0_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_CDR_0_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CDR_0_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_CDR_0_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CDR_0_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_CDR_0_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_CDR_0_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CDR_0_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* HIA_RDR_0_RING_BASE_ADDR_LO */
+#define MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_LO_REG					(0x00280800)
+#define MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_LO_RDR_BASE_ADDR_OFFS		0
+
+/* HIA_RDR_0_RING_BASE_ADDR_HI */
+#define MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_REG					(0x00280804)
+#define MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_RDR_BASE_ADDR_OFFS		0
+#define MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_RDR_BASE_ADDR_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_RDR_0_RING_BASE_ADDR_HI_RDR_BASE_ADDR_OFFS)
+
+
+/* HIA_RDR_0_DATA_BASE_ADDR_LO */
+#define MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_LO_REG					(0x00280808)
+#define MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_LO_RDR_DBASE_ADDR_OFFS		0
+
+/* HIA_RDR_0_DATA_BASE_ADDR_HI */
+#define MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_REG					(0x0028080c)
+#define MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_RDR_DBASE_ADDR_OFFS		0
+#define MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_RDR_DBASE_ADDR_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_RDR_0_DATA_BASE_ADDR_HI_RDR_DBASE_ADDR_OFFS)
+
+
+/* HIA_RDR_0_RING_SIZE */
+#define MV_EIP197_HIA_RDR_0_RING_SIZE_REG					(0x00280818)
+#define MV_EIP197_HIA_RDR_0_RING_SIZE_RDR_SIZE_OFFS		2
+#define MV_EIP197_HIA_RDR_0_RING_SIZE_RDR_SIZE_MASK    \
+		(0x003fffff << MV_EIP197_HIA_RDR_0_RING_SIZE_RDR_SIZE_OFFS)
+
+
+/* HIA_RDR_0_DESC_SIZE */
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_REG					(0x0028081c)
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_SIZE_OFFS		0
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_SIZE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_OFFSET_OFFS		16
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_OFFSET_MASK    \
+		(0x000000ff << MV_EIP197_HIA_RDR_0_DESC_SIZE_RD_OFFSET_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_MODE_64_BIT_OFFS		31
+#define MV_EIP197_HIA_RDR_0_DESC_SIZE_MODE_64_BIT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_DESC_SIZE_MODE_64_BIT_OFFS)
+
+
+/* HIA_RDR_0_CFG */
+#define MV_EIP197_HIA_RDR_0_CFG_REG					(0x00280820)
+#define MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_SIZE_OFFS		0
+#define MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_SIZE_MASK    \
+		(0x00001fff << MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_SIZE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_THRESH_OFFS		18
+#define MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_THRESH_MASK    \
+		(0x0000001f << MV_EIP197_HIA_RDR_0_CFG_RD_FETCH_THRESH_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_OFLO_IRQ_EN_OFFS		25
+#define MV_EIP197_HIA_RDR_0_CFG_OFLO_IRQ_EN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_CFG_OFLO_IRQ_EN_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_TCM_RDACK_EN_OFFS		26
+#define MV_EIP197_HIA_RDR_0_CFG_TCM_RDACK_EN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_CFG_TCM_RDACK_EN_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_SSM_ENABLE_OFFS		28
+#define MV_EIP197_HIA_RDR_0_CFG_SSM_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_CFG_SSM_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_ETM_DUAL_EDGE_OFFS		30
+#define MV_EIP197_HIA_RDR_0_CFG_ETM_DUAL_EDGE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_CFG_ETM_DUAL_EDGE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_CFG_ETM_ENABLE_OFFS		31
+#define MV_EIP197_HIA_RDR_0_CFG_ETM_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_CFG_ETM_ENABLE_OFFS)
+
+
+/* HIA_RDR_0_DMA_CFG */
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_REG					(0x00280824)
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_SWAP_OFFS		0
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_RD_SWAP_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_PROT_OFFS		4
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_RD_PROT_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_SWAP_OFFS		8
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_PROT_OFFS		12
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_DATA_PROT_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_RES_BUF_OFFS		22
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_RES_BUF_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_DMA_CFG_WR_RES_BUF_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CTRL_BUF_OFFS		23
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CTRL_BUF_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CTRL_BUF_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_OWN_BUF_OFFS		24
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_OWN_BUF_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_DMA_CFG_WR_OWN_BUF_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CACHE_OFFS		25
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CACHE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_WR_CACHE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_CACHE_OFFS		29
+#define MV_EIP197_HIA_RDR_0_DMA_CFG_RD_CACHE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_DMA_CFG_RD_CACHE_OFFS)
+
+
+/* HIA_RDR_0_THRESH */
+#define MV_EIP197_HIA_RDR_0_THRESH_REG					(0x00280828)
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_THRESH_OFFS		0
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_THRESH_MASK    \
+		(0x003fffff << MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_THRESH_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_PKT_MODE_OFFS		23
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_PKT_MODE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_THRESH_PROC_PKT_MODE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_TIMEOUT_OFFS		24
+#define MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_TIMEOUT_MASK    \
+		(0x000000ff << MV_EIP197_HIA_RDR_0_THRESH_PROC_RD_TIMEOUT_OFFS)
+
+
+/* HIA_RDR_0_PREP_COUNT */
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_REG					(0x0028082c)
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_PREP_RD_COUNT_INCR_OFFS		2
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_PREP_RD_COUNT_INCR_MASK    \
+		(0x00003fff << MV_EIP197_HIA_RDR_0_PREP_COUNT_PREP_RD_COUNT_INCR_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_CONTINUE_OFFS		30
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_CONTINUE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_PREP_COUNT_CONTINUE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_CLEAR_COUNT_OFFS		31
+#define MV_EIP197_HIA_RDR_0_PREP_COUNT_CLEAR_COUNT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_PREP_COUNT_CLEAR_COUNT_OFFS)
+
+
+/* HIA_RDR_0_PROC_COUNT */
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_REG					(0x00280830)
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_RD_COUNT_DECR_OFFS		2
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_RD_COUNT_DECR_MASK    \
+		(0x00003fff << MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_RD_COUNT_DECR_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_OFFS		24
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_MASK    \
+		(0x0000007f << MV_EIP197_HIA_RDR_0_PROC_COUNT_PROC_PKT_COUNT_DECR_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_CLEAR_COUNT_OFFS		31
+#define MV_EIP197_HIA_RDR_0_PROC_COUNT_CLEAR_COUNT_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_PROC_COUNT_CLEAR_COUNT_OFFS)
+
+
+/* HIA_RDR_0_PREP_PNTR */
+#define MV_EIP197_HIA_RDR_0_PREP_PNTR_REG					(0x00280834)
+#define MV_EIP197_HIA_RDR_0_PREP_PNTR_PREP_RDR_PNTR_OFFS		2
+#define MV_EIP197_HIA_RDR_0_PREP_PNTR_PREP_RDR_PNTR_MASK    \
+		(0x003fffff << MV_EIP197_HIA_RDR_0_PREP_PNTR_PREP_RDR_PNTR_OFFS)
+
+
+/* HIA_RDR_0_PROC_PNTR */
+#define MV_EIP197_HIA_RDR_0_PROC_PNTR_REG					(0x00280838)
+#define MV_EIP197_HIA_RDR_0_PROC_PNTR_PROC_RDR_PNTR_OFFS		2
+#define MV_EIP197_HIA_RDR_0_PROC_PNTR_PROC_RDR_PNTR_MASK    \
+		(0x003fffff << MV_EIP197_HIA_RDR_0_PROC_PNTR_PROC_RDR_PNTR_OFFS)
+
+
+/* HIA_RDR_0_STAT */
+#define MV_EIP197_HIA_RDR_0_STAT_REG					(0x0028083c)
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_DMA_ERR_IRQ_OFFS		0
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_DMA_ERR_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_RDR_DMA_ERR_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_PREP_RD_THRESH_IRQ_OFFS		1
+#define MV_EIP197_HIA_RDR_0_STAT_PREP_RD_THRESH_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_PREP_RD_THRESH_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_ERR_IRQ_OFFS		2
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_ERR_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_RDR_ERR_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_OFLO_UFLO_IRQ_OFFS		3
+#define MV_EIP197_HIA_RDR_0_STAT_RDR_OFLO_UFLO_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_RDR_OFLO_UFLO_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_THRESH_IRQ_OFFS		4
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_THRESH_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_PROC_RD_THRESH_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_TIMEOUT_IRQ_OFFS		5
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_TIMEOUT_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_PROC_RD_TIMEOUT_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RD_BUF_OFLO_IRQ_OFFS		6
+#define MV_EIP197_HIA_RDR_0_STAT_RD_BUF_OFLO_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_RD_BUF_OFLO_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_OFLO_IRQ_OFFS		7
+#define MV_EIP197_HIA_RDR_0_STAT_PROC_RD_OFLO_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_PROC_RD_OFLO_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RD_SKIP_COUNT_OFFS		8
+#define MV_EIP197_HIA_RDR_0_STAT_RD_SKIP_COUNT_MASK    \
+		(0x0000001f << MV_EIP197_HIA_RDR_0_STAT_RD_SKIP_COUNT_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_SOURCE_ENGINE_OFFS		13
+#define MV_EIP197_HIA_RDR_0_STAT_SOURCE_ENGINE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_STAT_SOURCE_ENGINE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RD_FIFO_FREE_COUNT_OFFS		16
+#define MV_EIP197_HIA_RDR_0_STAT_RD_FIFO_FREE_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_HIA_RDR_0_STAT_RD_FIFO_FREE_COUNT_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_RD_PROCESSED_OFFS		29
+#define MV_EIP197_HIA_RDR_0_STAT_RD_PROCESSED_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_RD_PROCESSED_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_FORCE_IRQ_OFFS		30
+#define MV_EIP197_HIA_RDR_0_STAT_FORCE_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_FORCE_IRQ_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_STAT_PAUSED_SUSPEND_OFFS		31
+#define MV_EIP197_HIA_RDR_0_STAT_PAUSED_SUSPEND_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_STAT_PAUSED_SUSPEND_OFFS)
+
+
+/* HIA_RDR_0_OPTIONS */
+#define MV_EIP197_HIA_RDR_0_OPTIONS_REG					(0x00280ff8)
+#define MV_EIP197_HIA_RDR_0_OPTIONS_N_RINGS_OFFS		0
+#define MV_EIP197_HIA_RDR_0_OPTIONS_N_RINGS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RDR_0_OPTIONS_N_RINGS_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_N_PES_OFFS		4
+#define MV_EIP197_HIA_RDR_0_OPTIONS_N_PES_MASK    \
+		(0x0000001f << MV_EIP197_HIA_RDR_0_OPTIONS_N_PES_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_CF_SIZE_OFFS		9
+#define MV_EIP197_HIA_RDR_0_OPTIONS_CF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_OPTIONS_CF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_RF_SIZE_OFFS		12
+#define MV_EIP197_HIA_RDR_0_OPTIONS_RF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_OPTIONS_RF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_EXT_PLW_OFFS		15
+#define MV_EIP197_HIA_RDR_0_OPTIONS_EXT_PLW_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_OPTIONS_EXT_PLW_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_HOST_IFC_OFFS		16
+#define MV_EIP197_HIA_RDR_0_OPTIONS_HOST_IFC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RDR_0_OPTIONS_HOST_IFC_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_DMA_LEN_OFFS		20
+#define MV_EIP197_HIA_RDR_0_OPTIONS_DMA_LEN_MASK    \
+		(0x0000001f << MV_EIP197_HIA_RDR_0_OPTIONS_DMA_LEN_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_HDW_OFFS		25
+#define MV_EIP197_HIA_RDR_0_OPTIONS_HDW_MASK    \
+		(0x00000007 << MV_EIP197_HIA_RDR_0_OPTIONS_HDW_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_PE_ARBITER_OFFS		29
+#define MV_EIP197_HIA_RDR_0_OPTIONS_PE_ARBITER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_OPTIONS_PE_ARBITER_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_TGT_ALIGN_OFFS		30
+#define MV_EIP197_HIA_RDR_0_OPTIONS_TGT_ALIGN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_OPTIONS_TGT_ALIGN_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_OPTIONS_ADDR_64_OFFS		31
+#define MV_EIP197_HIA_RDR_0_OPTIONS_ADDR_64_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RDR_0_OPTIONS_ADDR_64_OFFS)
+
+
+/* HIA_RDR_0_VERSION */
+#define MV_EIP197_HIA_RDR_0_VERSION_REG					(0x00280ffc)
+#define MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_RDR_0_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_RDR_0_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RDR_0_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_RDR_0_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RDR_0_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_RDR_0_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_RDR_0_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RDR_0_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* HIA_DFE_0_CFG */
+#define MV_EIP197_HIA_DFE_0_CFG_REG					(0x0028c000)
+#define MV_EIP197_HIA_DFE_0_CFG_MIN_DATA_SIZE_OFFS		0
+#define MV_EIP197_HIA_DFE_0_CFG_MIN_DATA_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_CFG_MIN_DATA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_DATA_CACHE_CTRL_OFFS		4
+#define MV_EIP197_HIA_DFE_0_CFG_DATA_CACHE_CTRL_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DFE_0_CFG_DATA_CACHE_CTRL_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_DATA_SRC_LOCK_OFFS		7
+#define MV_EIP197_HIA_DFE_0_CFG_DATA_SRC_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_CFG_DATA_SRC_LOCK_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_MAX_DATA_SIZE_OFFS		8
+#define MV_EIP197_HIA_DFE_0_CFG_MAX_DATA_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_CFG_MAX_DATA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_MIN_CTRL_SIZE_OFFS		16
+#define MV_EIP197_HIA_DFE_0_CFG_MIN_CTRL_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_CFG_MIN_CTRL_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_CTRL_CACHE_CTRL_OFFS		20
+#define MV_EIP197_HIA_DFE_0_CFG_CTRL_CACHE_CTRL_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DFE_0_CFG_CTRL_CACHE_CTRL_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_CTRL_SRC_LOCK_OFFS		23
+#define MV_EIP197_HIA_DFE_0_CFG_CTRL_SRC_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_CFG_CTRL_SRC_LOCK_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_MAX_CTRL_SIZE_OFFS		24
+#define MV_EIP197_HIA_DFE_0_CFG_MAX_CTRL_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_CFG_MAX_CTRL_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_SKIP_ON_DMA_ERR_OFFS		30
+#define MV_EIP197_HIA_DFE_0_CFG_SKIP_ON_DMA_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_CFG_SKIP_ON_DMA_ERR_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_CFG_AGGRESSIVE_OFFS		31
+#define MV_EIP197_HIA_DFE_0_CFG_AGGRESSIVE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_CFG_AGGRESSIVE_OFFS)
+
+
+/* HIA_DFE_0_THR_CTRL */
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_REG					(0x0028c040)
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_FORCE_IRQ_OFFS		28
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_FORCE_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_CTRL_FORCE_IRQ_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_STOP_OFFS		29
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_STOP_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_CTRL_STOP_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_RESET_OFFS		31
+#define MV_EIP197_HIA_DFE_0_THR_CTRL_RESET_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_CTRL_RESET_OFFS)
+
+
+/* HIA_DFE_0_THR_STAT */
+#define MV_EIP197_HIA_DFE_0_THR_STAT_REG					(0x0028c044)
+#define MV_EIP197_HIA_DFE_0_THR_STAT_CD_FIFO_COUNT_OFFS		0
+#define MV_EIP197_HIA_DFE_0_THR_STAT_CD_FIFO_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_HIA_DFE_0_THR_STAT_CD_FIFO_COUNT_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DMA_SIZE_OFFS		16
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DMA_SIZE_MASK    \
+		(0x00000fff << MV_EIP197_HIA_DFE_0_THR_STAT_DMA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_STAT_AT_DMA_BUSY_OFFS		28
+#define MV_EIP197_HIA_DFE_0_THR_STAT_AT_DMA_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_STAT_AT_DMA_BUSY_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DATA_DMA_BUSY_OFFS		29
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DATA_DMA_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_STAT_DATA_DMA_BUSY_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DMA_ERROR_OFFS		31
+#define MV_EIP197_HIA_DFE_0_THR_STAT_DMA_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_STAT_DMA_ERROR_OFFS)
+
+
+/* HIA_DFE_0_THR_DESC_CTRL */
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_REG					(0x0028c048)
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_16_0_OFFS		0
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_16_0_MASK    \
+		(0x0001ffff << MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_16_0_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_22_OFFS		22
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_22_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_22_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_23_OFFS		23
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_23_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_23_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_31_24_OFFS		24
+#define MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_31_24_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DFE_0_THR_DESC_CTRL_CD_CTRL_WORD_31_24_OFFS)
+
+
+/* HIA_DFE_0_THR_DESC_DPTR_LO */
+#define MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_LO_REG					(0x0028c050)
+#define MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_LO_DATA_POINTER_OFFS		0
+
+/* HIA_DFE_0_THR_DESC_DPTR_HI */
+#define MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_HI_REG					(0x0028c054)
+#define MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_HI_DATA_POINTER_OFFS		0
+#define MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_HI_DATA_POINTER_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_DFE_0_THR_DESC_DPTR_HI_DATA_POINTER_OFFS)
+
+
+/* HIA_DFE_0_THR_DESC_ACDPTR_LO */
+#define MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_LO_REG					(0x0028c058)
+#define MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_LO_ADD_CDATA_POINTER_OFFS		0
+
+/* HIA_DFE_0_THR_DESC_ACDPTR_HI */
+#define MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_HI_REG					(0x0028c05c)
+#define MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_HI_ADD_CDATA_POINTER_OFFS		0
+#define MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_HI_ADD_CDATA_POINTER_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_DFE_0_THR_DESC_ACDPTR_HI_ADD_CDATA_POINTER_OFFS)
+
+
+/* HIA_DFE_0_OPTIONS */
+#define MV_EIP197_HIA_DFE_0_OPTIONS_REG					(0x0028c078)
+#define MV_EIP197_HIA_DFE_0_OPTIONS_N_RINGS_OFFS		0
+#define MV_EIP197_HIA_DFE_0_OPTIONS_N_RINGS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_OPTIONS_N_RINGS_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_N_PES_OFFS		4
+#define MV_EIP197_HIA_DFE_0_OPTIONS_N_PES_MASK    \
+		(0x0000001f << MV_EIP197_HIA_DFE_0_OPTIONS_N_PES_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_CF_SIZE_OFFS		9
+#define MV_EIP197_HIA_DFE_0_OPTIONS_CF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DFE_0_OPTIONS_CF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_RF_SIZE_OFFS		12
+#define MV_EIP197_HIA_DFE_0_OPTIONS_RF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DFE_0_OPTIONS_RF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_EXT_PLW_OFFS		15
+#define MV_EIP197_HIA_DFE_0_OPTIONS_EXT_PLW_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_OPTIONS_EXT_PLW_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_HOST_IFC_OFFS		16
+#define MV_EIP197_HIA_DFE_0_OPTIONS_HOST_IFC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_OPTIONS_HOST_IFC_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_DMA_LEN_OFFS		20
+#define MV_EIP197_HIA_DFE_0_OPTIONS_DMA_LEN_MASK    \
+		(0x0000001f << MV_EIP197_HIA_DFE_0_OPTIONS_DMA_LEN_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_HDW_OFFS		25
+#define MV_EIP197_HIA_DFE_0_OPTIONS_HDW_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DFE_0_OPTIONS_HDW_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_PE_ARBITER_OFFS		29
+#define MV_EIP197_HIA_DFE_0_OPTIONS_PE_ARBITER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_OPTIONS_PE_ARBITER_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_TGT_ALIGN_OFFS		30
+#define MV_EIP197_HIA_DFE_0_OPTIONS_TGT_ALIGN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_OPTIONS_TGT_ALIGN_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_OPTIONS_ADDR_64_OFFS		31
+#define MV_EIP197_HIA_DFE_0_OPTIONS_ADDR_64_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DFE_0_OPTIONS_ADDR_64_OFFS)
+
+
+/* HIA_DFE_0_VERSION */
+#define MV_EIP197_HIA_DFE_0_VERSION_REG					(0x0028c07c)
+#define MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DFE_0_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_DFE_0_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_DFE_0_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_DFE_0_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_DFE_0_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DFE_0_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* HIA_DSE_0_CFG */
+#define MV_EIP197_HIA_DSE_0_CFG_REG					(0x0028d000)
+#define MV_EIP197_HIA_DSE_0_CFG_MIN_DATA_SIZE_OFFS		0
+#define MV_EIP197_HIA_DSE_0_CFG_MIN_DATA_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_CFG_MIN_DATA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_DATA_CACHE_CTRL_OFFS		4
+#define MV_EIP197_HIA_DSE_0_CFG_DATA_CACHE_CTRL_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DSE_0_CFG_DATA_CACHE_CTRL_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_DATA_SRC_LOCK_OFFS		7
+#define MV_EIP197_HIA_DSE_0_CFG_DATA_SRC_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_CFG_DATA_SRC_LOCK_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_MAX_DATA_SIZE_OFFS		8
+#define MV_EIP197_HIA_DSE_0_CFG_MAX_DATA_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_CFG_MAX_DATA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_BUFFER_CTRL_OFFS		14
+#define MV_EIP197_HIA_DSE_0_CFG_BUFFER_CTRL_MASK    \
+		(0x00000003 << MV_EIP197_HIA_DSE_0_CFG_BUFFER_CTRL_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_SKIP_ON_DMA_ERR_OFFS		30
+#define MV_EIP197_HIA_DSE_0_CFG_SKIP_ON_DMA_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_CFG_SKIP_ON_DMA_ERR_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_CFG_AGGRESSIVE_OFFS		31
+#define MV_EIP197_HIA_DSE_0_CFG_AGGRESSIVE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_CFG_AGGRESSIVE_OFFS)
+
+
+/* HIA_DSE_0_THR_ERROR_STAT */
+#define MV_EIP197_HIA_DSE_0_THR_ERROR_STAT_REG					(0x0028d008)
+#define MV_EIP197_HIA_DSE_0_THR_ERROR_STAT_PKT_FLUSH_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_ERROR_STAT_PKT_FLUSH_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_ERROR_STAT_PKT_FLUSH_OFFS)
+
+
+/* HIA_DSE_0_THR_CTRL */
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_REG					(0x0028d040)
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_FORCE_IRQ_OFFS		28
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_FORCE_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_CTRL_FORCE_IRQ_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_STOP_OFFS		29
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_STOP_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_CTRL_STOP_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_ENABLE_OFFS		30
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_CTRL_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_RESET_OFFS		31
+#define MV_EIP197_HIA_DSE_0_THR_CTRL_RESET_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_CTRL_RESET_OFFS)
+
+
+/* HIA_DSE_0_THR_STAT */
+#define MV_EIP197_HIA_DSE_0_THR_STAT_REG					(0x0028d044)
+#define MV_EIP197_HIA_DSE_0_THR_STAT_RD_FIFO_COUNT_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_STAT_RD_FIFO_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_HIA_DSE_0_THR_STAT_RD_FIFO_COUNT_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DMA_SIZE_OFFS		16
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DMA_SIZE_MASK    \
+		(0x00000fff << MV_EIP197_HIA_DSE_0_THR_STAT_DMA_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DATA_FLUSH_BUSY_OFFS		28
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DATA_FLUSH_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_STAT_DATA_FLUSH_BUSY_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DATA_DMA_BUSY_OFFS		29
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DATA_DMA_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_STAT_DATA_DMA_BUSY_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DMA_ERROR_OFFS		31
+#define MV_EIP197_HIA_DSE_0_THR_STAT_DMA_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_STAT_DMA_ERROR_OFFS)
+
+
+/* HIA_DSE_0_THR_DESC_CTRL */
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_REG					(0x0028d048)
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_16_0_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_16_0_MASK    \
+		(0x0001ffff << MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_16_0_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_22_OFFS		22
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_22_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_22_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_23_OFFS		23
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_23_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_23_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_31_24_OFFS		24
+#define MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_31_24_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DSE_0_THR_DESC_CTRL_RD_CTRL_WORD_31_24_OFFS)
+
+
+/* HIA_DSE_0_THR_S_DESC_CTRL */
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_REG					(0x0028d04c)
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_16_0_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_16_0_MASK    \
+		(0x0001ffff << MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_16_0_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_22_OFFS		22
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_22_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_22_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_23_OFFS		23
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_23_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_23_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_31_24_OFFS		24
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_31_24_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DSE_0_THR_S_DESC_CTRL_SHADOW_RD_CTRL_WORD_31_24_OFFS)
+
+
+/* HIA_DSE_0_THR_DESC_DPTR_LO */
+#define MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_LO_REG					(0x0028d050)
+#define MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_LO_DATA_POINTER_OFFS		0
+
+/* HIA_DSE_0_THR_DESC_DPTR_HI */
+#define MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_HI_REG					(0x0028d054)
+#define MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_HI_DATA_POINTER_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_HI_DATA_POINTER_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_DSE_0_THR_DESC_DPTR_HI_DATA_POINTER_OFFS)
+
+
+/* HIA_DSE_0_THR_S_DESC_DPTR_LO */
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_LO_REG					(0x0028d058)
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_LO_SHADOW_DATA_POINTER_OFFS		0
+
+/* HIA_DSE_0_THR_S_DESC_DPTR_HI */
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_HI_REG					(0x0028d05c)
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_HI_SHADOW_DATA_POINTER_OFFS		0
+#define MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_HI_SHADOW_DATA_POINTER_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_DSE_0_THR_S_DESC_DPTR_HI_SHADOW_DATA_POINTER_OFFS)
+
+
+/* HIA_DSE_0_OPTIONS */
+#define MV_EIP197_HIA_DSE_0_OPTIONS_REG					(0x0028d078)
+#define MV_EIP197_HIA_DSE_0_OPTIONS_N_RINGS_OFFS		0
+#define MV_EIP197_HIA_DSE_0_OPTIONS_N_RINGS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_OPTIONS_N_RINGS_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_N_PES_OFFS		4
+#define MV_EIP197_HIA_DSE_0_OPTIONS_N_PES_MASK    \
+		(0x0000001f << MV_EIP197_HIA_DSE_0_OPTIONS_N_PES_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_CF_SIZE_OFFS		9
+#define MV_EIP197_HIA_DSE_0_OPTIONS_CF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DSE_0_OPTIONS_CF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_RF_SIZE_OFFS		12
+#define MV_EIP197_HIA_DSE_0_OPTIONS_RF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DSE_0_OPTIONS_RF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_EXT_PLW_OFFS		15
+#define MV_EIP197_HIA_DSE_0_OPTIONS_EXT_PLW_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_OPTIONS_EXT_PLW_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_HOST_IFC_OFFS		16
+#define MV_EIP197_HIA_DSE_0_OPTIONS_HOST_IFC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_OPTIONS_HOST_IFC_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_DMA_LEN_OFFS		20
+#define MV_EIP197_HIA_DSE_0_OPTIONS_DMA_LEN_MASK    \
+		(0x0000001f << MV_EIP197_HIA_DSE_0_OPTIONS_DMA_LEN_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_HDW_OFFS		25
+#define MV_EIP197_HIA_DSE_0_OPTIONS_HDW_MASK    \
+		(0x00000007 << MV_EIP197_HIA_DSE_0_OPTIONS_HDW_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_PE_ARBITER_OFFS		29
+#define MV_EIP197_HIA_DSE_0_OPTIONS_PE_ARBITER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_OPTIONS_PE_ARBITER_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_TGT_ALIGN_OFFS		30
+#define MV_EIP197_HIA_DSE_0_OPTIONS_TGT_ALIGN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_OPTIONS_TGT_ALIGN_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_OPTIONS_ADDR_64_OFFS		31
+#define MV_EIP197_HIA_DSE_0_OPTIONS_ADDR_64_MASK    \
+		(0x00000001 << MV_EIP197_HIA_DSE_0_OPTIONS_ADDR_64_OFFS)
+
+
+/* HIA_DSE_0_VERSION */
+#define MV_EIP197_HIA_DSE_0_VERSION_REG					(0x0028d07c)
+#define MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_DSE_0_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_DSE_0_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_DSE_0_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_DSE_0_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_DSE_0_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_DSE_0_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* HIA_RA_PRIO0 */
+#define MV_EIP197_HIA_RA_PRIO0_REG					(0x00290000)
+#define MV_EIP197_HIA_RA_PRIO0_CDR_0_SLOTS_OFFS		0
+#define MV_EIP197_HIA_RA_PRIO0_CDR_0_SLOTS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RA_PRIO0_CDR_0_SLOTS_OFFS)
+
+#define MV_EIP197_HIA_RA_PRIO0_CDR_0_PRIO_OFFS		7
+#define MV_EIP197_HIA_RA_PRIO0_CDR_0_PRIO_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PRIO0_CDR_0_PRIO_OFFS)
+
+#define MV_EIP197_HIA_RA_PRIO0_CDR_1_SLOTS_OFFS		8
+#define MV_EIP197_HIA_RA_PRIO0_CDR_1_SLOTS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RA_PRIO0_CDR_1_SLOTS_OFFS)
+
+#define MV_EIP197_HIA_RA_PRIO0_CDR_1_PRIO_OFFS		15
+#define MV_EIP197_HIA_RA_PRIO0_CDR_1_PRIO_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PRIO0_CDR_1_PRIO_OFFS)
+
+#define MV_EIP197_HIA_RA_PRIO0_CDR_2_SLOTS_OFFS		16
+#define MV_EIP197_HIA_RA_PRIO0_CDR_2_SLOTS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RA_PRIO0_CDR_2_SLOTS_OFFS)
+
+#define MV_EIP197_HIA_RA_PRIO0_CDR_2_PRIO_OFFS		23
+#define MV_EIP197_HIA_RA_PRIO0_CDR_2_PRIO_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PRIO0_CDR_2_PRIO_OFFS)
+
+
+/* HIA_RA_PE_0_CTRL */
+#define MV_EIP197_HIA_RA_PE_0_CTRL_REG					(0x00290010)
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_0_ENABLE_OFFS		0
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_0_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PE_0_CTRL_RING_0_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_1_ENABLE_OFFS		1
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_1_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PE_0_CTRL_RING_1_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_2_ENABLE_OFFS		2
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RING_2_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PE_0_CTRL_RING_2_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_RA_PE_0_CTRL_ENABLE_OFFS		30
+#define MV_EIP197_HIA_RA_PE_0_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PE_0_CTRL_ENABLE_OFFS)
+
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RESET_OFFS		31
+#define MV_EIP197_HIA_RA_PE_0_CTRL_RESET_MASK    \
+		(0x00000001 << MV_EIP197_HIA_RA_PE_0_CTRL_RESET_OFFS)
+
+
+/* HIA_RA_PE_0_STAT */
+#define MV_EIP197_HIA_RA_PE_0_STAT_REG					(0x00290014)
+#define MV_EIP197_HIA_RA_PE_0_STAT_ASSIGNED_RING_ID_OFFS		0
+#define MV_EIP197_HIA_RA_PE_0_STAT_ASSIGNED_RING_ID_MASK    \
+		(0x0000000f << MV_EIP197_HIA_RA_PE_0_STAT_ASSIGNED_RING_ID_OFFS)
+
+
+/* HIA_AIC_G_POL_CTRL */
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_REG					(0x0029f800)
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_0_OFFS		0
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_0_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_1_OFFS		1
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_1_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_2_OFFS		2
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_2_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_3_OFFS		3
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_3_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_4_OFFS		4
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_4_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_4_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_5_OFFS		5
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_5_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_5_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_6_OFFS		6
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_6_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_6_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_7_OFFS		7
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_7_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_7_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_8_OFFS		8
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_8_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_8_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_9_OFFS		9
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_9_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_9_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_10_OFFS		10
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_10_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_10_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_11_OFFS		11
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_11_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_11_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_12_OFFS		12
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_12_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_12_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_13_OFFS		13
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_13_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_13_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_14_OFFS		14
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_14_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_14_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_15_OFFS		15
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_15_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_15_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_16_OFFS		16
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_16_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_16_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_17_OFFS		17
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_17_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_17_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_18_OFFS		18
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_18_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_18_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_19_OFFS		19
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_19_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_19_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_20_OFFS		20
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_20_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_20_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_21_OFFS		21
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_21_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_21_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_22_OFFS		22
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_22_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_22_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_23_OFFS		23
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_23_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_23_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_24_OFFS		24
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_24_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_24_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_25_OFFS		25
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_25_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_25_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_26_OFFS		26
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_26_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_26_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_27_OFFS		27
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_27_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_27_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_28_OFFS		28
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_28_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_28_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_29_OFFS		29
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_29_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_29_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_30_OFFS		30
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_30_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_30_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_31_OFFS		31
+#define MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_31_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_POL_CTRL_POLARITY_CTRL_31_OFFS)
+
+
+/* HIA_AIC_G_TYPE_CTRL */
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_REG					(0x0029f804)
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_0_OFFS		0
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_0_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_1_OFFS		1
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_1_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_2_OFFS		2
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_2_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_3_OFFS		3
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_3_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_4_OFFS		4
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_4_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_4_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_5_OFFS		5
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_5_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_5_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_6_OFFS		6
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_6_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_6_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_7_OFFS		7
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_7_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_7_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_8_OFFS		8
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_8_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_8_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_9_OFFS		9
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_9_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_9_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_10_OFFS		10
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_10_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_10_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_11_OFFS		11
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_11_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_11_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_12_OFFS		12
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_12_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_12_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_13_OFFS		13
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_13_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_13_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_14_OFFS		14
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_14_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_14_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_15_OFFS		15
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_15_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_15_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_16_OFFS		16
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_16_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_16_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_17_OFFS		17
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_17_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_17_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_18_OFFS		18
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_18_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_18_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_19_OFFS		19
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_19_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_19_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_20_OFFS		20
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_20_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_20_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_21_OFFS		21
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_21_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_21_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_22_OFFS		22
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_22_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_22_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_23_OFFS		23
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_23_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_23_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_24_OFFS		24
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_24_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_24_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_25_OFFS		25
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_25_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_25_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_26_OFFS		26
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_26_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_26_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_27_OFFS		27
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_27_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_27_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_28_OFFS		28
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_28_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_28_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_29_OFFS		29
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_29_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_29_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_30_OFFS		30
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_30_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_30_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_31_OFFS		31
+#define MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_31_MASK    \
+		(0x00000001 << MV_EIP197_HIA_AIC_G_TYPE_CTRL_TYPE_CTRL_31_OFFS)
+
+
+/* HIA_AIC_G_ENABLE_CTRL */
+#define MV_EIP197_HIA_AIC_G_ENABLE_CTRL_REG					(0x0029f808)
+#define MV_EIP197_HIA_AIC_G_ENABLE_CTRL_ENABLE_CTRL_OFFS		0
+
+/* HIA_AIC_G_RAW_STAT */
+#define MV_EIP197_HIA_AIC_G_RAW_STAT_REG					(0x0029f80c)
+#define MV_EIP197_HIA_AIC_G_RAW_STAT_RAW_STATUS_OFFS		0
+
+/* HIA_AIC_G_ENABLED_STAT */
+#define MV_EIP197_HIA_AIC_G_ENABLED_STAT_REG					(0x0029f810)
+#define MV_EIP197_HIA_AIC_G_ENABLED_STAT_ENABLED_STATUS_OFFS		0
+
+/* HIA_AIC_G_ENABLE_CLR */
+#define MV_EIP197_HIA_AIC_G_ENABLE_CLR_REG					(0x0029f814)
+#define MV_EIP197_HIA_AIC_G_ENABLE_CLR_ENABLE_CLR_OFFS		0
+
+/* HIA_AIC_G_OPTIONS */
+#define MV_EIP197_HIA_AIC_G_OPTIONS_REG					(0x0029f818)
+#define MV_EIP197_HIA_AIC_G_OPTIONS_NR_OF_INPUTS_OFFS		0
+#define MV_EIP197_HIA_AIC_G_OPTIONS_NR_OF_INPUTS_MASK    \
+		(0x0000003f << MV_EIP197_HIA_AIC_G_OPTIONS_NR_OF_INPUTS_OFFS)
+
+
+/* HIA_AIC_G_VERSION */
+#define MV_EIP197_HIA_AIC_G_VERSION_REG					(0x0029f81c)
+#define MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_AIC_G_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_AIC_G_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_AIC_G_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_AIC_G_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_AIC_G_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_AIC_G_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_AIC_G_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_AIC_G_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* HIA_CLUST_CTRL_0 */
+#define MV_EIP197_HIA_CLUST_CTRL_0_REG					(0x0029fe00)
+#define MV_EIP197_HIA_CLUST_CTRL_0_MAX_CMD_QUEUE_OFFS		0
+#define MV_EIP197_HIA_CLUST_CTRL_0_MAX_CMD_QUEUE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CLUST_CTRL_0_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_0_MAX_BURST_OFFS		8
+#define MV_EIP197_HIA_CLUST_CTRL_0_MAX_BURST_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CLUST_CTRL_0_MAX_BURST_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_0_CTRL_ENABLE_OFFS		31
+#define MV_EIP197_HIA_CLUST_CTRL_0_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CLUST_CTRL_0_CTRL_ENABLE_OFFS)
+
+
+/* HIA_CLUST_CTRL_1 */
+#define MV_EIP197_HIA_CLUST_CTRL_1_REG					(0x0029fe04)
+#define MV_EIP197_HIA_CLUST_CTRL_1_MAX_CMD_QUEUE_OFFS		0
+#define MV_EIP197_HIA_CLUST_CTRL_1_MAX_CMD_QUEUE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CLUST_CTRL_1_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_1_MAX_BURST_OFFS		8
+#define MV_EIP197_HIA_CLUST_CTRL_1_MAX_BURST_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CLUST_CTRL_1_MAX_BURST_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_1_CTRL_ENABLE_OFFS		31
+#define MV_EIP197_HIA_CLUST_CTRL_1_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CLUST_CTRL_1_CTRL_ENABLE_OFFS)
+
+
+/* HIA_CLUST_CTRL_2 */
+#define MV_EIP197_HIA_CLUST_CTRL_2_REG					(0x0029fe08)
+#define MV_EIP197_HIA_CLUST_CTRL_2_MAX_CMD_QUEUE_OFFS		0
+#define MV_EIP197_HIA_CLUST_CTRL_2_MAX_CMD_QUEUE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CLUST_CTRL_2_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_2_MAX_BURST_OFFS		8
+#define MV_EIP197_HIA_CLUST_CTRL_2_MAX_BURST_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CLUST_CTRL_2_MAX_BURST_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_2_CTRL_ENABLE_OFFS		31
+#define MV_EIP197_HIA_CLUST_CTRL_2_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CLUST_CTRL_2_CTRL_ENABLE_OFFS)
+
+
+/* HIA_CLUST_CTRL_3 */
+#define MV_EIP197_HIA_CLUST_CTRL_3_REG					(0x0029fe0c)
+#define MV_EIP197_HIA_CLUST_CTRL_3_MAX_CMD_QUEUE_OFFS		0
+#define MV_EIP197_HIA_CLUST_CTRL_3_MAX_CMD_QUEUE_MASK    \
+		(0x000000ff << MV_EIP197_HIA_CLUST_CTRL_3_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_3_MAX_BURST_OFFS		8
+#define MV_EIP197_HIA_CLUST_CTRL_3_MAX_BURST_MASK    \
+		(0x0000000f << MV_EIP197_HIA_CLUST_CTRL_3_MAX_BURST_OFFS)
+
+#define MV_EIP197_HIA_CLUST_CTRL_3_CTRL_ENABLE_OFFS		31
+#define MV_EIP197_HIA_CLUST_CTRL_3_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_HIA_CLUST_CTRL_3_CTRL_ENABLE_OFFS)
+
+
+/* HIA_LASIDE_BASE_ADDR_LO */
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_REG					(0x0029ff00)
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_LA_SWAP_OFFS		0
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_LA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_LA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_BASE_ADDR_LO_OFFS		4
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_BASE_ADDR_LO_MASK    \
+		(0x0fffffff << MV_EIP197_HIA_LASIDE_BASE_ADDR_LO_BASE_ADDR_LO_OFFS)
+
+
+/* HIA_LASIDE_BASE_ADDR_HI */
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_REG					(0x0029ff04)
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_BASE_ADDR_HI_OFFS		0
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_BASE_ADDR_HI_MASK    \
+		(0x00ffffff << MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_BASE_ADDR_HI_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_INPLACE_MAXGROW_OFFS		24
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_INPLACE_MAXGROW_MASK    \
+		(0x0000007f << MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_INPLACE_MAXGROW_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_CDS_PROT_ERR_OFFS		31
+#define MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_CDS_PROT_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_LASIDE_BASE_ADDR_HI_CDS_PROT_ERR_OFFS)
+
+
+/* HIA_LASIDE_SLAVE_CTRL_1 */
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_REG					(0x0029ff08)
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_SWAP_OFFS		0
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_PROT_OFFS		4
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_IDATA_PROT_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_SWAP_OFFS		8
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_SWAP_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_PROT_OFFS		12
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_ACD_PROT_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_FIFO_DATA_AVAIL_OFFS		16
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_FIFO_DATA_AVAIL_MASK    \
+		(0x00007fff << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_FIFO_DATA_AVAIL_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_CMD_DESC_ERR_OFFS		31
+#define MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_CMD_DESC_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_LASIDE_SLAVE_CTRL_1_CMD_DESC_ERR_OFFS)
+
+
+/* HIA_LASIDE_MASTER_CTRL_1 */
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_REG					(0x0029ff0c)
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_SWAP_OFFS		0
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_PROT_OFFS		4
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_PROT_MASK    \
+		(0x00000007 << MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_ODATA_PROT_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_FIFO_DATA_AVAIL_OFFS		16
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_FIFO_DATA_AVAIL_MASK    \
+		(0x00007fff << MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_FIFO_DATA_AVAIL_OFFS)
+
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_RES_DESC_ERR_OFFS		31
+#define MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_RES_DESC_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_LASIDE_MASTER_CTRL_1_RES_DESC_ERR_OFFS)
+
+
+/* HIA_INLINE_CTRL_0 */
+#define MV_EIP197_HIA_INLINE_CTRL_0_REG					(0x0029ff80)
+#define MV_EIP197_HIA_INLINE_CTRL_0_IDATA_SWAP_OFFS		0
+#define MV_EIP197_HIA_INLINE_CTRL_0_IDATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_INLINE_CTRL_0_IDATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_IPROT_ERROR_OFFS		7
+#define MV_EIP197_HIA_INLINE_CTRL_0_IPROT_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_INLINE_CTRL_0_IPROT_ERROR_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_SWAP_OFFS		8
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_HIA_INLINE_CTRL_0_ODATA_SWAP_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_LOW_OFFS		12
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_LOW_MASK    \
+		(0x0000000f << MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_LOW_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_HIGH_OFFS		16
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_HIGH_MASK    \
+		(0x0000000f << MV_EIP197_HIA_INLINE_CTRL_0_ODATA_THRESH_HIGH_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_BURST_OFFS		20
+#define MV_EIP197_HIA_INLINE_CTRL_0_ODATA_BURST_MASK    \
+		(0x0000000f << MV_EIP197_HIA_INLINE_CTRL_0_ODATA_BURST_OFFS)
+
+#define MV_EIP197_HIA_INLINE_CTRL_0_FORCE_INORDER_OFFS		31
+#define MV_EIP197_HIA_INLINE_CTRL_0_FORCE_INORDER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_INLINE_CTRL_0_FORCE_INORDER_OFFS)
+
+
+/* HIA_MST_TIMEOUT_ERR_0 */
+#define MV_EIP197_HIA_MST_TIMEOUT_ERR_0_REG					(0x0029ffd0)
+#define MV_EIP197_HIA_MST_TIMEOUT_ERR_0_TIMEOUT_ERR_OFFS		0
+#define MV_EIP197_HIA_MST_TIMEOUT_ERR_0_TIMEOUT_ERR_MASK    \
+		(0x0000000f << MV_EIP197_HIA_MST_TIMEOUT_ERR_0_TIMEOUT_ERR_OFFS)
+
+
+/* HIA_OPTIONS2 */
+#define MV_EIP197_HIA_OPTIONS2_REG					(0x0029fff0)
+#define MV_EIP197_HIA_OPTIONS2_N_LA_IF_OFFS		0
+#define MV_EIP197_HIA_OPTIONS2_N_LA_IF_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS2_N_LA_IF_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS2_N_INLINE_IF_OFFS		4
+#define MV_EIP197_HIA_OPTIONS2_N_INLINE_IF_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS2_N_INLINE_IF_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS2_AXI_WR_CHAN_OFFS		16
+#define MV_EIP197_HIA_OPTIONS2_AXI_WR_CHAN_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS2_AXI_WR_CHAN_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS2_AXI_RD_CLUSTERS_OFFS		20
+#define MV_EIP197_HIA_OPTIONS2_AXI_RD_CLUSTERS_MASK    \
+		(0x000000ff << MV_EIP197_HIA_OPTIONS2_AXI_RD_CLUSTERS_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS2_AXI_CPC_OFFS		28
+#define MV_EIP197_HIA_OPTIONS2_AXI_CPC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS2_AXI_CPC_OFFS)
+
+
+/* HIA_MST_CTRL */
+#define MV_EIP197_HIA_MST_CTRL_REG					(0x0029fff4)
+#define MV_EIP197_HIA_MST_CTRL_RX_BURST_SIZE_OFFS		0
+#define MV_EIP197_HIA_MST_CTRL_RX_BURST_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_MST_CTRL_RX_BURST_SIZE_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_AXI_BURST_SIZE_OFFS		4
+#define MV_EIP197_HIA_MST_CTRL_AXI_BURST_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_MST_CTRL_AXI_BURST_SIZE_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_AXI_WR_ERR_OFFS		13
+#define MV_EIP197_HIA_MST_CTRL_AXI_WR_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_MST_CTRL_AXI_WR_ERR_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_AXI_RD_ERR_OFFS		14
+#define MV_EIP197_HIA_MST_CTRL_AXI_RD_ERR_MASK    \
+		(0x00000001 << MV_EIP197_HIA_MST_CTRL_AXI_RD_ERR_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_RX_MAX_CMD_QUEUE_OFFS		16
+#define MV_EIP197_HIA_MST_CTRL_RX_MAX_CMD_QUEUE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_MST_CTRL_RX_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_TX_MAX_CMD_QUEUE_OFFS		20
+#define MV_EIP197_HIA_MST_CTRL_TX_MAX_CMD_QUEUE_MASK    \
+		(0x0000000f << MV_EIP197_HIA_MST_CTRL_TX_MAX_CMD_QUEUE_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_SLAVE_SWAP_EN_OFFS		24
+#define MV_EIP197_HIA_MST_CTRL_SLAVE_SWAP_EN_MASK    \
+		(0x00000003 << MV_EIP197_HIA_MST_CTRL_SLAVE_SWAP_EN_OFFS)
+
+#define MV_EIP197_HIA_MST_CTRL_TIMEOUT_VAL_OFFS		26
+#define MV_EIP197_HIA_MST_CTRL_TIMEOUT_VAL_MASK    \
+		(0x0000003f << MV_EIP197_HIA_MST_CTRL_TIMEOUT_VAL_OFFS)
+
+
+/* HIA_OPTIONS */
+#define MV_EIP197_HIA_OPTIONS_REG					(0x0029fff8)
+#define MV_EIP197_HIA_OPTIONS_N_RINGS_OFFS		0
+#define MV_EIP197_HIA_OPTIONS_N_RINGS_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS_N_RINGS_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_N_PES_OFFS		4
+#define MV_EIP197_HIA_OPTIONS_N_PES_MASK    \
+		(0x0000001f << MV_EIP197_HIA_OPTIONS_N_PES_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_CF_SIZE_OFFS		9
+#define MV_EIP197_HIA_OPTIONS_CF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_OPTIONS_CF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_RF_SIZE_OFFS		12
+#define MV_EIP197_HIA_OPTIONS_RF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_HIA_OPTIONS_RF_SIZE_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_EXT_PLW_OFFS		15
+#define MV_EIP197_HIA_OPTIONS_EXT_PLW_MASK    \
+		(0x00000001 << MV_EIP197_HIA_OPTIONS_EXT_PLW_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_HOST_IFC_OFFS		16
+#define MV_EIP197_HIA_OPTIONS_HOST_IFC_MASK    \
+		(0x0000000f << MV_EIP197_HIA_OPTIONS_HOST_IFC_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_DMA_LEN_OFFS		20
+#define MV_EIP197_HIA_OPTIONS_DMA_LEN_MASK    \
+		(0x0000001f << MV_EIP197_HIA_OPTIONS_DMA_LEN_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_HDW_OFFS		25
+#define MV_EIP197_HIA_OPTIONS_HDW_MASK    \
+		(0x00000007 << MV_EIP197_HIA_OPTIONS_HDW_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_PE_ARBITER_OFFS		29
+#define MV_EIP197_HIA_OPTIONS_PE_ARBITER_MASK    \
+		(0x00000001 << MV_EIP197_HIA_OPTIONS_PE_ARBITER_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_TGT_ALIGN_OFFS		30
+#define MV_EIP197_HIA_OPTIONS_TGT_ALIGN_MASK    \
+		(0x00000001 << MV_EIP197_HIA_OPTIONS_TGT_ALIGN_OFFS)
+
+#define MV_EIP197_HIA_OPTIONS_ADDR_64_OFFS		31
+#define MV_EIP197_HIA_OPTIONS_ADDR_64_MASK    \
+		(0x00000001 << MV_EIP197_HIA_OPTIONS_ADDR_64_OFFS)
+
+
+/* HIA_VERSION */
+#define MV_EIP197_HIA_VERSION_REG					(0x0029fffc)
+#define MV_EIP197_HIA_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_HIA_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_HIA_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_HIA_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_HIA_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_HIA_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_HIA_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_HIA_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_HIA_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_HIA_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_HIA_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_HIA_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_HIA_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_HIA_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* PE_0_IN_DBUF_THRESH */
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_REG					(0x002a0000)
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_MIN_THRESH_OFFS		8
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_MIN_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_IN_DBUF_THRESH_MIN_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_MAX_THRESH_OFFS		12
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_MAX_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_IN_DBUF_THRESH_MAX_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_COUNT_OFFS		16
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_COUNT_MASK    \
+		(0x00001fff << MV_EIP197_PE_0_IN_DBUF_THRESH_COUNT_OFFS)
+
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_UFLOW_IRQ_OFFS		30
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_UFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_IN_DBUF_THRESH_UFLOW_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_OFLOW_IRQ_OFFS		31
+#define MV_EIP197_PE_0_IN_DBUF_THRESH_OFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_IN_DBUF_THRESH_OFLOW_IRQ_OFFS)
+
+
+/* PE_0_IN_TBUF_THRESH */
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_REG					(0x002a0100)
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_MIN_THRESH_OFFS		8
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_MIN_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_IN_TBUF_THRESH_MIN_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_MAX_THRESH_OFFS		12
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_MAX_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_IN_TBUF_THRESH_MAX_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_OFLOW_IRQ_OFFS		31
+#define MV_EIP197_PE_0_IN_TBUF_THRESH_OFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_IN_TBUF_THRESH_OFLOW_IRQ_OFFS)
+
+
+/* PE_0_ICE_ADAPT_CTRL */
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_REG					(0x002a0c00)
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_WORDS_OFFS		0
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_WORDS_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_WORDS_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_DATA_WORDS_OFFS		8
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_DATA_WORDS_MASK    \
+		(0x0000003f << MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_DATA_WORDS_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_SOURCE_OFFS		18
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_SOURCE_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_ADAPT_CTRL_PACKET_SOURCE_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_COUNTER_OFFS		22
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_COUNTER_MASK    \
+		(0x00000007 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_TOKEN_COUNTER_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_PACKET_OFFS		25
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_PACKET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_PACKET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_TOKEN_OFFS		26
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_TOKEN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_WAITING_TOKEN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_CLOCK_CTRL_OFFS		27
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_CLOCK_CTRL_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_CLOCK_CTRL_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PREFETCHING_OFFS		28
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PREFETCHING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PREFETCHING_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PIPELINING_OFFS		29
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PIPELINING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_PIPELINING_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_BUFFERING_OFFS		30
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_BUFFERING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_NO_BUFFERING_OFFS)
+
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_SW_RESET_OFFS		31
+#define MV_EIP197_PE_0_ICE_ADAPT_CTRL_SW_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_ADAPT_CTRL_SW_RESET_OFFS)
+
+
+/* PE_0_ICE_PUE_CTRL */
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_REG					(0x002a0c80)
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_SW_RESET_OFFS		0
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_SW_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_SW_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_HOLD_OFFS		1
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_HOLD_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_HOLD_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_STEP_OFFS		2
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_STEP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_STEP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DEBUG_RESET_OFFS		3
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DEBUG_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_DEBUG_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_RUNS_OFFS		4
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_RUNS_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_RUNS_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_INSTR_ERROR_OFFS		5
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_INSTR_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_INSTR_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_ERROR_OFFS		6
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_DMA_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_PARITY_ERROR_OFFS		7
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_PARITY_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_PARITY_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_WAITING_OFFS		8
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_WAITING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_WAITING_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_CARRY_OFFS		9
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_CARRY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_CARRY_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_SIGN_OFFS		10
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_SIGN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_SIGN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_ZERO_OFFS		11
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_ZERO_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_CTRL_ZERO_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_CURRENT_PC_OFFS		16
+#define MV_EIP197_PE_0_ICE_PUE_CTRL_CURRENT_PC_MASK    \
+		(0x00007fff << MV_EIP197_PE_0_ICE_PUE_CTRL_CURRENT_PC_OFFS)
+
+
+/* PE_0_ICE_PUE_DEBUG */
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_REG					(0x002a0c84)
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP0_OFFS		0
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP0_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP1_OFFS		1
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_BP1_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_START_OFFS		8
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_START_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_STOPPED_AT_START_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOP_ON_START_OFFS		9
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_STOP_ON_START_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_STOP_ON_START_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_EN_STOP_IRQ_OFFS		10
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_EN_STOP_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_EN_STOP_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_WRITE_BP_OFFS		11
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_WRITE_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_WRITE_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_SELECT_BP_OFFS		12
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_SELECT_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_SELECT_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_ENABLE_BP_OFFS		15
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_ENABLE_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUE_DEBUG_ENABLE_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_BREAKPOINT_ADDRESS_OFFS		16
+#define MV_EIP197_PE_0_ICE_PUE_DEBUG_BREAKPOINT_ADDRESS_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_ICE_PUE_DEBUG_BREAKPOINT_ADDRESS_OFFS)
+
+
+/* PE_0_ICE_PUTF_CTRL */
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_REG					(0x002a0d00)
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_FIFO_RESET_OFFS		15
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_FIFO_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUTF_CTRL_FIFO_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_PUE_BLOCK_OFFS		16
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_PUE_BLOCK_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PUTF_CTRL_PUE_BLOCK_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_TOKEN_SIZE_OFFS		24
+#define MV_EIP197_PE_0_ICE_PUTF_CTRL_TOKEN_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_ICE_PUTF_CTRL_TOKEN_SIZE_OFFS)
+
+
+/* PE_0_ICE_SCRATCH_CTRL */
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_REG					(0x002a0d04)
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_IRQ_OFFS		0
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_TIMER_OFFS		2
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_TIMER_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_TIMER_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_EN_OFFS		3
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_EN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_EN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_PRESALER_OFFS		4
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_PRESALER_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_PRESALER_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_BIT_OFFS		16
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_BIT_MASK    \
+		(0x0000001f << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_TIMER_OFLO_BIT_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_ACCESS_OFFS		24
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_ACCESS_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_CHANGE_ACCESS_OFFS)
+
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_SCRATCH_ACCESS_OFFS		25
+#define MV_EIP197_PE_0_ICE_SCRATCH_CTRL_SCRATCH_ACCESS_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_SCRATCH_CTRL_SCRATCH_ACCESS_OFFS)
+
+
+/* PE_0_ICE_TIMER_LO */
+#define MV_EIP197_PE_0_ICE_TIMER_LO_REG					(0x002a0d08)
+#define MV_EIP197_PE_0_ICE_TIMER_LO_TIMER_OFFS		0
+
+/* PE_0_ICE_TIMER_HI */
+#define MV_EIP197_PE_0_ICE_TIMER_HI_REG					(0x002a0d0c)
+#define MV_EIP197_PE_0_ICE_TIMER_HI_TIMER_OFFS		0
+
+/* PE_0_ICE_UENG_STAT */
+#define MV_EIP197_PE_0_ICE_UENG_STAT_REG					(0x002a0d10)
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_STAT_OFFS		0
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_STAT_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_STAT_OFFS)
+
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_IRQ_OFFS		4
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_UENG_STAT_PULLUP_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_STAT_OFFS		8
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_STAT_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_STAT_OFFS)
+
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_IRQ_OFFS		12
+#define MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_UENG_STAT_PPROC_IRQ_OFFS)
+
+
+/* PE_0_ICE_FPP_CTRL */
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_REG					(0x002a0d80)
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_SW_RESET_OFFS		0
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_SW_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_SW_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_HOLD_OFFS		1
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_HOLD_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_HOLD_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_STEP_OFFS		2
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_STEP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_STEP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DEBUG_RESET_OFFS		3
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DEBUG_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_DEBUG_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_RUNS_OFFS		4
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_RUNS_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_RUNS_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_INSTR_ERROR_OFFS		5
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_INSTR_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_INSTR_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_ERROR_OFFS		6
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_DMA_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_PARITY_ERROR_OFFS		7
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_PARITY_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_PARITY_ERROR_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_WAITING_OFFS		8
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_WAITING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_WAITING_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_CARRY_OFFS		9
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_CARRY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_CARRY_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_SIGN_OFFS		10
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_SIGN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_SIGN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_ZERO_OFFS		11
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_ZERO_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_CTRL_ZERO_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_CURRENT_PC_OFFS		16
+#define MV_EIP197_PE_0_ICE_FPP_CTRL_CURRENT_PC_MASK    \
+		(0x00007fff << MV_EIP197_PE_0_ICE_FPP_CTRL_CURRENT_PC_OFFS)
+
+
+/* PE_0_ICE_FPP_DEBUG */
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_REG					(0x002a0d84)
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP0_OFFS		0
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP0_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP1_OFFS		1
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_BP1_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_START_OFFS		8
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_START_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_STOPPED_AT_START_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOP_ON_START_OFFS		9
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_STOP_ON_START_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_STOP_ON_START_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_EN_STOP_IRQ_OFFS		10
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_EN_STOP_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_EN_STOP_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_WRITE_BP_OFFS		11
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_WRITE_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_WRITE_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_SELECT_BP_OFFS		12
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_SELECT_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_SELECT_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_ENABLE_BP_OFFS		15
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_ENABLE_BP_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_FPP_DEBUG_ENABLE_BP_OFFS)
+
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_BREAKPOINT_ADDRESS_OFFS		16
+#define MV_EIP197_PE_0_ICE_FPP_DEBUG_BREAKPOINT_ADDRESS_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_ICE_FPP_DEBUG_BREAKPOINT_ADDRESS_OFFS)
+
+
+/* PE_0_ICE_PPTF_CTRL */
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_REG					(0x002a0e00)
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_FIFO_RESET_OFFS		15
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_FIFO_RESET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PPTF_CTRL_FIFO_RESET_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_FPP_BLOCK_OFFS		16
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_FPP_BLOCK_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_PPTF_CTRL_FPP_BLOCK_OFFS)
+
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_TOKEN_SIZE_OFFS		24
+#define MV_EIP197_PE_0_ICE_PPTF_CTRL_TOKEN_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_ICE_PPTF_CTRL_TOKEN_SIZE_OFFS)
+
+
+/* PE_0_ICE_RAM_CTRL */
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_REG					(0x002a0ff0)
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_PUE_PROG_EN_OFFS		0
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_PUE_PROG_EN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_RAM_CTRL_PUE_PROG_EN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_FPP_PROG_EN_OFFS		1
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_FPP_PROG_EN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_RAM_CTRL_FPP_PROG_EN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_DEBUG_EN_OFFS		16
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_DEBUG_EN_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_RAM_CTRL_DEBUG_EN_OFFS)
+
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_UNLOCK_OFFS		24
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_UNLOCK_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_ICE_RAM_CTRL_UNLOCK_OFFS)
+
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_SOFT_LOCK_OFFS		30
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_SOFT_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_RAM_CTRL_SOFT_LOCK_OFFS)
+
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_HARD_LOCK_OFFS		31
+#define MV_EIP197_PE_0_ICE_RAM_CTRL_HARD_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_RAM_CTRL_HARD_LOCK_OFFS)
+
+
+/* PE_0_ICE_OPTIONS */
+#define MV_EIP197_PE_0_ICE_OPTIONS_REG					(0x002a0ff8)
+#define MV_EIP197_PE_0_ICE_OPTIONS_SUPPORT_CONFIG_OFFS		0
+#define MV_EIP197_PE_0_ICE_OPTIONS_SUPPORT_CONFIG_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_ICE_OPTIONS_SUPPORT_CONFIG_OFFS)
+
+#define MV_EIP197_PE_0_ICE_OPTIONS_UE_BREAKPOINTS_OFFS		2
+#define MV_EIP197_PE_0_ICE_OPTIONS_UE_BREAKPOINTS_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_ICE_OPTIONS_UE_BREAKPOINTS_OFFS)
+
+
+/* PE_0_ICE_VERSION */
+#define MV_EIP197_PE_0_ICE_VERSION_REG					(0x002a0ffc)
+#define MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_ICE_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_PE_0_ICE_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_PE_0_ICE_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_PE_0_ICE_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_PE_0_ICE_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_PE_0_ICE_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_PE_0_ICE_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_ICE_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* PE_0_EIP96_TOKEN_CTRL_STAT */
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_REG					(0x002a1000)
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ACTIVE_TOKENS_OFFS		0
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ACTIVE_TOKENS_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ACTIVE_TOKENS_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_LOCATION_AVAILABLE_OFFS		2
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_LOCATION_AVAILABLE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_LOCATION_AVAILABLE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_TOKEN_AVAILABLE_OFFS		3
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_TOKEN_AVAILABLE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_TOKEN_AVAILABLE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_READ_ACTIVE_OFFS		4
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_READ_ACTIVE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TOKEN_READ_ACTIVE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_CACHE_ACTIVE_OFFS		5
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_CACHE_ACTIVE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_CACHE_ACTIVE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_FETCH_OFFS		6
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_FETCH_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_CONTEXT_FETCH_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_CONTEXT_OFFS		7
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_CONTEXT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_RESULT_CONTEXT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PACKETS_TO_BE_PROCESSED_OFFS		8
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PACKETS_TO_BE_PROCESSED_MASK    \
+		(0x0000003f << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PACKETS_TO_BE_PROCESSED_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSING_HELD_OFFS		14
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSING_HELD_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSING_HELD_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_BUSY_OFFS		15
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_BUSY_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_OPTIMAL_CONTEXT_UPDATES_OFFS		16
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_OPTIMAL_CONTEXT_UPDATES_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_OPTIMAL_CONTEXT_UPDATES_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ABSOLUTE_ARC4_POINTER_OFFS		18
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ABSOLUTE_ARC4_POINTER_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ABSOLUTE_ARC4_POINTER_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_REUSE_CACHED_CTX_OFFS		19
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_REUSE_CACHED_CTX_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_REUSE_CACHED_CTX_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_POSTPONED_CTX_REUSE_OFFS		20
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_POSTPONED_CTX_REUSE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ALLOW_POSTPONED_CTX_REUSE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ZERO_LENGTH_RESULT_PACKET_OFFS		21
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ZERO_LENGTH_RESULT_PACKET_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_ZERO_LENGTH_RESULT_PACKET_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TIMEOUT_COUNTER_ENABLE_OFFS		22
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TIMEOUT_COUNTER_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_TIMEOUT_COUNTER_ENABLE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_DEBUG_MODE_OFFS		23
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_DEBUG_MODE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_DEBUG_MODE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSPACKETS_OFFS		24
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSPACKETS_MASK    \
+		(0x0000003f << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_PROCESSPACKETS_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_HOLD_PROCESSING_OFFS		31
+#define MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_HOLD_PROCESSING_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_TOKEN_CTRL_STAT_HOLD_PROCESSING_OFFS)
+
+
+/* PE_0_EIP96_FUNCTION_EN */
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_REG					(0x002a1004)
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ONLY_NULL_OFFS		0
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ONLY_NULL_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ONLY_NULL_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_ONLY_OFFS		1
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_ONLY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_ONLY_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ENCRYPT_OFFS		2
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ENCRYPT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_ENCRYPT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_DECRYPT_OFFS		3
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_DECRYPT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HASH_DECRYPT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_HASH_OFFS		4
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_HASH_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_ENCRYPT_HASH_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DECRYPT_HASH_OFFS		5
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DECRYPT_HASH_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_DECRYPT_HASH_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_6_OFFS		6
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_6_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_6_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ARC4_OFFS		7
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_ARC4_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_ARC4_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_ECB_OFFS		8
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_ECB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_ECB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CBC_OFFS		9
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CBC_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CBC_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CTR_ICM_OFFS		10
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CTR_ICM_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CTR_ICM_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_OFB_OFFS		11
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_OFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_OFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CFB_OFFS		12
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_CFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_ECB_OFFS		13
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_ECB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_ECB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CBC_OFFS		14
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CBC_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CBC_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_15_OFFS		15
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_15_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_15_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_OFB_OFFS		16
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_OFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_OFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CFB_OFFS		17
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_DES_CFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_ECB_OFFS		18
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_ECB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_ECB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CBC_OFFS		19
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CBC_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CBC_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_20_OFFS		20
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_20_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_20_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_OFB_OFFS		21
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_OFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_OFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CFB_OFFS		22
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CFB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_TDES_CFB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_23_OFFS		23
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_23_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_RESERVED_23_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_MD5_OFFS		24
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_MD5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_MD5_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_MD5_OFFS		25
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_MD5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_MD5_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA1_OFFS		26
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA1_OFFS		27
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA2_OFFS		28
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_BASIC_SHA2_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA2_OFFS		29
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_HMAC_SHA2_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_XCBC_MAC_OFFS		30
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_XCBC_MAC_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_AES_XCBC_MAC_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_GCM_HASH_OFFS		31
+#define MV_EIP197_PE_0_EIP96_FUNCTION_EN_GCM_HASH_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_FUNCTION_EN_GCM_HASH_OFFS)
+
+
+/* PE_0_EIP96_CONTEXT_CTRL */
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_REG					(0x002a1008)
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CONTEXT_SIZE_OFFS		0
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CONTEXT_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CONTEXT_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_ADDRESS_MODE_OFFS		8
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_ADDRESS_MODE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_ADDRESS_MODE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CTRL_MODE_OFFS		9
+#define MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CTRL_MODE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_CTRL_CTRL_MODE_OFFS)
+
+
+/* PE_0_EIP96_CONTEXT_STAT */
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_REG					(0x002a100c)
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E0_OFFS		0
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E0_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E1_OFFS		1
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E2_OFFS		2
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E2_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E3_OFFS		3
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E3_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E3_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E4_OFFS		4
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E4_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E4_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E5_OFFS		5
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E5_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E6_OFFS		6
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E6_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E6_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E7_OFFS		7
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E7_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E7_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E8_OFFS		8
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E8_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E8_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E9_OFFS		9
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E9_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E9_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E10_OFFS		10
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E10_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E10_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E11_OFFS		11
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E11_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E11_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E12_OFFS		12
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E12_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E12_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E13_OFFS		13
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E13_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E13_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E14_OFFS		14
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E14_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_E14_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_AVAILABLE_TOKENS_OFFS		16
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_AVAILABLE_TOKENS_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_AVAILABLE_TOKENS_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_CONTEXT_OFFS		18
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_CONTEXT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_CONTEXT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_CONTEXT_OFFS		19
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_CONTEXT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_CONTEXT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_RESULT_CONTEXT_OFFS		20
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_RESULT_CONTEXT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_RESULT_CONTEXT_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ERROR_RECOVERY_OFFS		21
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ERROR_RECOVERY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ERROR_RECOVERY_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_PACKET_STATE_OFFS		24
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_PACKET_STATE_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_ACTIVE_PACKET_STATE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_PACKET_STATE_OFFS		28
+#define MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_PACKET_STATE_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_CONTEXT_STAT_NEXT_PACKET_STATE_OFFS)
+
+
+/* PE_0_EIP96_OUT_TRANS_CTRL_STAT */
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_REG					(0x002a1018)
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_AVAILABLE_DWORDS_OFFS		0
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_AVAILABLE_DWORDS_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_AVAILABLE_DWORDS_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MIN_TRANSFER_SIZE_OFFS		8
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MIN_TRANSFER_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MIN_TRANSFER_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MAX_TRANSFER_SIZE_OFFS		16
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MAX_TRANSFER_SIZE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_MAX_TRANSFER_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_TRANSFER_SIZE_MASK_OFFS		24
+#define MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_TRANSFER_SIZE_MASK_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_OUT_TRANS_CTRL_STAT_TRANSFER_SIZE_MASK_OFFS)
+
+
+/* PE_0_EIP96_OUT_BUF_CTRL */
+#define MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_REG					(0x002a101c)
+#define MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_HOLD_OUTPUT_DATA_OFFS		3
+#define MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_HOLD_OUTPUT_DATA_MASK    \
+		(0x0000001f << MV_EIP197_PE_0_EIP96_OUT_BUF_CTRL_HOLD_OUTPUT_DATA_OFFS)
+
+
+/* PE_0_EIP96_PRNG_STAT */
+#define MV_EIP197_PE_0_EIP96_PRNG_STAT_REG					(0x002a1040)
+#define MV_EIP197_PE_0_EIP96_PRNG_STAT_BUSY_OFFS		0
+#define MV_EIP197_PE_0_EIP96_PRNG_STAT_BUSY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_PRNG_STAT_BUSY_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_PRNG_STAT_RESULT_READY_OFFS		1
+#define MV_EIP197_PE_0_EIP96_PRNG_STAT_RESULT_READY_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_PRNG_STAT_RESULT_READY_OFFS)
+
+
+/* PE_0_EIP96_PRNG_CTRL */
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_REG					(0x002a1044)
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_ENABLE_OFFS		0
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_PRNG_CTRL_ENABLE_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_AUTO_OFFS		1
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_AUTO_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_PRNG_CTRL_AUTO_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_RESULT_128_OFFS		2
+#define MV_EIP197_PE_0_EIP96_PRNG_CTRL_RESULT_128_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_PRNG_CTRL_RESULT_128_OFFS)
+
+
+/* PE_0_EIP96_PRNG_SEED_L */
+#define MV_EIP197_PE_0_EIP96_PRNG_SEED_L_REG					(0x002a1048)
+#define MV_EIP197_PE_0_EIP96_PRNG_SEED_L_PRNG_SEED_LOW_OFFS		0
+
+/* PE_0_EIP96_PRNG_SEED_H */
+#define MV_EIP197_PE_0_EIP96_PRNG_SEED_H_REG					(0x002a104c)
+#define MV_EIP197_PE_0_EIP96_PRNG_SEED_H_PRNG_SEED_HIGH_OFFS		0
+
+/* PE_0_EIP96_PRNG_KEY_0_L */
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_0_L_REG					(0x002a1050)
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_0_L_PRNG_DES_KEY0_LOW_OFFS		0
+
+/* PE_0_EIP96_PRNG_KEY_0_H */
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_0_H_REG					(0x002a1054)
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_0_H_PRNG_DES_KEY0_HIGH_OFFS		0
+
+/* PE_0_EIP96_PRNG_KEY_1_L */
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_1_L_REG					(0x002a1058)
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_1_L_PRNG_DES_KEY1_LOW_OFFS		0
+
+/* PE_0_EIP96_PRNG_KEY_1_H */
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_1_H_REG					(0x002a105c)
+#define MV_EIP197_PE_0_EIP96_PRNG_KEY_1_H_PRNG_DES_KEY1_HIGH_OFFS		0
+
+/* PE_0_EIP96_PRNG_RES_0 */
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_0_REG					(0x002a1060)
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_0_PRNG_OUTPUT_OFFS		0
+
+/* PE_0_EIP96_PRNG_RES_1 */
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_1_REG					(0x002a1064)
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_1_PRNG_OUTPUT_OFFS		0
+
+/* PE_0_EIP96_PRNG_RES_2 */
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_2_REG					(0x002a1068)
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_2_PRNG_OUTPUT_OFFS		0
+
+/* PE_0_EIP96_PRNG_RES_3 */
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_3_REG					(0x002a106c)
+#define MV_EIP197_PE_0_EIP96_PRNG_RES_3_PRNG_OUTPUT_OFFS		0
+
+/* PE_0_EIP96_PRNG_LFSR_L */
+#define MV_EIP197_PE_0_EIP96_PRNG_LFSR_L_REG					(0x002a1070)
+#define MV_EIP197_PE_0_EIP96_PRNG_LFSR_L_PRNG_LFSR_LOW_OFFS		0
+
+/* PE_0_EIP96_PRNG_LFSR_H */
+#define MV_EIP197_PE_0_EIP96_PRNG_LFSR_H_REG					(0x002a1074)
+#define MV_EIP197_PE_0_EIP96_PRNG_LFSR_H_PRNG_LFSR_HIGH_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W0 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W0_REG					(0x002a1080)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W0_CUR_TOKEN_W0_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W1 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W1_REG					(0x002a1084)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W1_CUR_TOKEN_W1_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W2 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W2_REG					(0x002a1088)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W2_CUR_TOKEN_W2_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W3 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W3_REG					(0x002a108c)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W3_CUR_TOKEN_W3_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W4 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W4_REG					(0x002a1090)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W4_CUR_TOKEN_W4_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W5 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W5_REG					(0x002a1094)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W5_CUR_TOKEN_W5_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W6 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W6_REG					(0x002a1098)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W6_CUR_TOKEN_W6_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W7 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W7_REG					(0x002a109c)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W7_CUR_TOKEN_W7_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W8 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W8_REG					(0x002a10a0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W8_CUR_TOKEN_W8_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W9 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W9_REG					(0x002a10a4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W9_CUR_TOKEN_W9_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W10 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W10_REG					(0x002a10a8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W10_CUR_TOKEN_W10_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W11 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W11_REG					(0x002a10ac)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W11_CUR_TOKEN_W11_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W12 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W12_REG					(0x002a10b0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W12_CUR_TOKEN_W12_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W13 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W13_REG					(0x002a10b4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W13_CUR_TOKEN_W13_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W14 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W14_REG					(0x002a10b8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W14_CUR_TOKEN_W14_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W15 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W15_REG					(0x002a10bc)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W15_CUR_TOKEN_W15_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W16 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W16_REG					(0x002a10c0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W16_CUR_TOKEN_W16_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W17 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W17_REG					(0x002a10c4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W17_CUR_TOKEN_W17_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W18 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W18_REG					(0x002a10c8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W18_CUR_TOKEN_W18_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W19 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W19_REG					(0x002a10cc)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W19_CUR_TOKEN_W19_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W20 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W20_REG					(0x002a10d0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W20_CUR_TOKEN_W20_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W21 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W21_REG					(0x002a10d4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W21_CUR_TOKEN_W21_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W22 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W22_REG					(0x002a10d8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W22_CUR_TOKEN_W22_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W23 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W23_REG					(0x002a10dc)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W23_CUR_TOKEN_W23_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W24 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W24_REG					(0x002a10e0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W24_CUR_TOKEN_W24_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W25 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W25_REG					(0x002a10e4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W25_CUR_TOKEN_W25_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W26 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W26_REG					(0x002a10e8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W26_CUR_TOKEN_W26_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W27 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W27_REG					(0x002a10ec)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W27_CUR_TOKEN_W27_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W28 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W28_REG					(0x002a10f0)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W28_CUR_TOKEN_W28_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W29 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W29_REG					(0x002a10f4)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W29_CUR_TOKEN_W29_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W30 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W30_REG					(0x002a10f8)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W30_CUR_TOKEN_W30_OFFS		0
+
+/* PE_0_EIP96_CUR_TOKEN_W31 */
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W31_REG					(0x002a10fc)
+#define MV_EIP197_PE_0_EIP96_CUR_TOKEN_W31_CUR_TOKEN_W31_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W0 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W0_REG					(0x002a1100)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W0_RES_TOKEN_W0_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W1 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W1_REG					(0x002a1104)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W1_RES_TOKEN_W1_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W2 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W2_REG					(0x002a1108)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W2_RES_TOKEN_W2_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W3 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W3_REG					(0x002a110c)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W3_RES_TOKEN_W3_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W4 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W4_REG					(0x002a1110)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W4_RES_TOKEN_W4_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W5 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W5_REG					(0x002a1114)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W5_RES_TOKEN_W5_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W6 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W6_REG					(0x002a1118)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W6_RES_TOKEN_W6_OFFS		0
+
+/* PE_0_EIP96_RES_TOKEN_W7 */
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W7_REG					(0x002a111c)
+#define MV_EIP197_PE_0_EIP96_RES_TOKEN_W7_RES_TOKEN_W7_OFFS		0
+
+/* PE_0_EIP96_NXT_CONTEXT_CMD_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_0_REG					(0x002a1140)
+#define MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_0_NXT_CONTEXT_CMD_0_OFFS		0
+
+/* PE_0_EIP96_NXT_CONTEXT_CMD_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_1_REG					(0x002a1144)
+#define MV_EIP197_PE_0_EIP96_NXT_CONTEXT_CMD_1_NXT_CONTEXT_CMD_1_OFFS		0
+
+/* PE_0_EIP96_NXT_GENERAL_PUR_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_0_REG					(0x002a1148)
+#define MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_0_NXT_GEN_PURPOSE_0_OFFS		0
+
+/* PE_0_EIP96_NXT_GENERAL_PUR_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_1_REG					(0x002a114c)
+#define MV_EIP197_PE_0_EIP96_NXT_GENERAL_PUR_1_NXT_GEN_PURPOSE_1_OFFS		0
+
+/* PE_0_EIP96_NXT_IV_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_IV_0_REG					(0x002a1150)
+#define MV_EIP197_PE_0_EIP96_NXT_IV_0_NXT_IV_0_OFFS		0
+
+/* PE_0_EIP96_NXT_IV_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_IV_1_REG					(0x002a1154)
+#define MV_EIP197_PE_0_EIP96_NXT_IV_1_NXT_IV_1_OFFS		0
+
+/* PE_0_EIP96_NXT_IV_2 */
+#define MV_EIP197_PE_0_EIP96_NXT_IV_2_REG					(0x002a1158)
+#define MV_EIP197_PE_0_EIP96_NXT_IV_2_NXT_IV_2_OFFS		0
+
+/* PE_0_EIP96_NXT_IV_3 */
+#define MV_EIP197_PE_0_EIP96_NXT_IV_3_REG					(0x002a115c)
+#define MV_EIP197_PE_0_EIP96_NXT_IV_3_NXT_IV_3_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_0_REG					(0x002a1160)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_0_NXT_KEY_0_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_1_REG					(0x002a1164)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_1_NXT_KEY_1_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_2 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_2_REG					(0x002a1168)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_2_NXT_KEY_2_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_3 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_3_REG					(0x002a116c)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_3_NXT_KEY_3_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_4 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_4_REG					(0x002a1170)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_4_NXT_KEY_4_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_5 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_5_REG					(0x002a1174)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_5_NXT_KEY_5_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_6 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_6_REG					(0x002a1178)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_6_NXT_KEY_6_OFFS		0
+
+/* PE_0_EIP96_NXT_KEY_7 */
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_7_REG					(0x002a117c)
+#define MV_EIP197_PE_0_EIP96_NXT_KEY_7_NXT_KEY_7_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_0_REG					(0x002a1180)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_0_NXT_IDIGEST_0_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_1_REG					(0x002a1184)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_1_NXT_IDIGEST_1_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_2 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_2_REG					(0x002a1188)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_2_NXT_IDIGEST_2_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_3 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_3_REG					(0x002a118c)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_3_NXT_IDIGEST_3_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_4 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_4_REG					(0x002a1190)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_4_NXT_IDIGEST_4_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_5 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_5_REG					(0x002a1194)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_5_NXT_IDIGEST_5_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_6 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_6_REG					(0x002a1198)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_6_NXT_IDIGEST_6_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_7 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_7_REG					(0x002a119c)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_7_NXT_IDIGEST_7_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_0_REG					(0x002a11a0)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_0_NXT_ODIGEST_0_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_1_REG					(0x002a11a4)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_1_NXT_ODIGEST_1_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_2 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_2_REG					(0x002a11a8)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_2_NXT_ODIGEST_2_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_3 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_3_REG					(0x002a11ac)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_3_NXT_ODIGEST_3_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_4 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_4_REG					(0x002a11b0)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_4_NXT_ODIGEST_4_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_5 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_5_REG					(0x002a11b4)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_5_NXT_ODIGEST_5_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_6 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_6_REG					(0x002a11b8)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_6_NXT_ODIGEST_6_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_7 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_7_REG					(0x002a11bc)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_7_NXT_ODIGEST_7_OFFS		0
+
+/* PE_0_EIP96_NXT_DIGEST_CNT */
+#define MV_EIP197_PE_0_EIP96_NXT_DIGEST_CNT_REG					(0x002a11c0)
+#define MV_EIP197_PE_0_EIP96_NXT_DIGEST_CNT_NXT_DIGEST_CNT_OFFS		0
+
+/* PE_0_EIP96_NXT_SPI_SSRC */
+#define MV_EIP197_PE_0_EIP96_NXT_SPI_SSRC_REG					(0x002a11c4)
+#define MV_EIP197_PE_0_EIP96_NXT_SPI_SSRC_NXT_SPI_SSRC_OFFS		0
+
+/* PE_0_EIP96_NXT_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_REG					(0x002a11c8)
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_NXT_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_NXT_EXT_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_NXT_EXT_SEQNUM_REG					(0x002a11cc)
+#define MV_EIP197_PE_0_EIP96_NXT_EXT_SEQNUM_NXT_EXT_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_NXT_SEQNUM_MASK_0 */
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_0_REG					(0x002a11d0)
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_0_NXT_SEQNUM_MASK_0_OFFS		0
+
+/* PE_0_EIP96_NXT_SEQNUM_MASK_1 */
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_1_REG					(0x002a11d4)
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_1_NXT_SEQNUM_MASK_1_OFFS		0
+
+/* PE_0_EIP96_NXT_SEQNUM_MASK_2 */
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_2_REG					(0x002a11d8)
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_2_NXT_SEQNUM_MASK_2_OFFS		0
+
+/* PE_0_EIP96_NXT_SEQNUM_MASK_3 */
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_3_REG					(0x002a11dc)
+#define MV_EIP197_PE_0_EIP96_NXT_SEQNUM_MASK_3_NXT_SEQNUM_MASK_3_OFFS		0
+
+/* PE_0_EIP96_NXT_CHECKSUM */
+#define MV_EIP197_PE_0_EIP96_NXT_CHECKSUM_REG					(0x002a11e4)
+#define MV_EIP197_PE_0_EIP96_NXT_CHECKSUM_NXT_CHECKSUM_OFFS		0
+#define MV_EIP197_PE_0_EIP96_NXT_CHECKSUM_NXT_CHECKSUM_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_EIP96_NXT_CHECKSUM_NXT_CHECKSUM_OFFS)
+
+
+/* PE_0_EIP96_NXT_ARC4_IJ_PNTR */
+#define MV_EIP197_PE_0_EIP96_NXT_ARC4_IJ_PNTR_REG					(0x002a11e8)
+#define MV_EIP197_PE_0_EIP96_NXT_ARC4_IJ_PNTR_NXT_ARC4_IJ_PNTR_OFFS		0
+#define MV_EIP197_PE_0_EIP96_NXT_ARC4_IJ_PNTR_NXT_ARC4_IJ_PNTR_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_EIP96_NXT_ARC4_IJ_PNTR_NXT_ARC4_IJ_PNTR_OFFS)
+
+
+/* PE_0_EIP96_NXT_ARC4_PNTR */
+#define MV_EIP197_PE_0_EIP96_NXT_ARC4_PNTR_REG					(0x002a11ec)
+#define MV_EIP197_PE_0_EIP96_NXT_ARC4_PNTR_NXT_ARC4_PNTR_OFFS		0
+
+/* PE_0_EIP96_CUR_CONTEXT_CMD_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_0_REG					(0x002a1200)
+#define MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_0_CUR_CONTEXT_CMD_0_OFFS		0
+
+/* PE_0_EIP96_CUR_CONTEXT_CMD_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_1_REG					(0x002a1204)
+#define MV_EIP197_PE_0_EIP96_CUR_CONTEXT_CMD_1_CUR_CONTEXT_CMD_1_OFFS		0
+
+/* PE_0_EIP96_CUR_GENERAL_PUR_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_0_REG					(0x002a1208)
+#define MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_0_CUR_GEN_PURPOSE_0_OFFS		0
+
+/* PE_0_EIP96_CUR_GENERAL_PUR_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_1_REG					(0x002a120c)
+#define MV_EIP197_PE_0_EIP96_CUR_GENERAL_PUR_1_CUR_GEN_PURPOSE_1_OFFS		0
+
+/* PE_0_EIP96_CUR_IV_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_IV_0_REG					(0x002a1210)
+#define MV_EIP197_PE_0_EIP96_CUR_IV_0_CUR_IV_0_OFFS		0
+
+/* PE_0_EIP96_CUR_IV_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_IV_1_REG					(0x002a1214)
+#define MV_EIP197_PE_0_EIP96_CUR_IV_1_CUR_IV_1_OFFS		0
+
+/* PE_0_EIP96_CUR_IV_2 */
+#define MV_EIP197_PE_0_EIP96_CUR_IV_2_REG					(0x002a1218)
+#define MV_EIP197_PE_0_EIP96_CUR_IV_2_CUR_IV_2_OFFS		0
+
+/* PE_0_EIP96_CUR_IV_3 */
+#define MV_EIP197_PE_0_EIP96_CUR_IV_3_REG					(0x002a121c)
+#define MV_EIP197_PE_0_EIP96_CUR_IV_3_CUR_IV_3_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_0_REG					(0x002a1220)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_0_CUR_KEY_0_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_1_REG					(0x002a1224)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_1_CUR_KEY_1_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_2 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_2_REG					(0x002a1228)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_2_CUR_KEY_2_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_3 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_3_REG					(0x002a122c)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_3_CUR_KEY_3_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_4 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_4_REG					(0x002a1230)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_4_CUR_KEY_4_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_5 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_5_REG					(0x002a1234)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_5_CUR_KEY_5_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_6 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_6_REG					(0x002a1238)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_6_CUR_KEY_6_OFFS		0
+
+/* PE_0_EIP96_CUR_KEY_7 */
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_7_REG					(0x002a123c)
+#define MV_EIP197_PE_0_EIP96_CUR_KEY_7_CUR_KEY_7_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_0_REG					(0x002a1240)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_0_CUR_IDIGEST_0_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_1_REG					(0x002a1244)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_1_CUR_IDIGEST_1_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_2 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_2_REG					(0x002a1248)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_2_CUR_IDIGEST_2_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_3 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_3_REG					(0x002a124c)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_3_CUR_IDIGEST_3_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_4 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_4_REG					(0x002a1250)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_4_CUR_IDIGEST_4_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_5 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_5_REG					(0x002a1254)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_5_CUR_IDIGEST_5_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_6 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_6_REG					(0x002a1258)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_6_CUR_IDIGEST_6_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_7 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_7_REG					(0x002a125c)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_7_CUR_IDIGEST_7_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_0_REG					(0x002a1260)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_0_CUR_ODIGEST_0_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_1_REG					(0x002a1264)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_1_CUR_ODIGEST_1_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_2 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_2_REG					(0x002a1268)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_2_CUR_ODIGEST_2_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_3 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_3_REG					(0x002a126c)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_3_CUR_ODIGEST_3_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_4 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_4_REG					(0x002a1270)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_4_CUR_ODIGEST_4_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_5 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_5_REG					(0x002a1274)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_5_CUR_ODIGEST_5_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_6 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_6_REG					(0x002a1278)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_6_CUR_ODIGEST_6_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_7 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_7_REG					(0x002a127c)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_7_CUR_ODIGEST_7_OFFS		0
+
+/* PE_0_EIP96_CUR_DIGEST_CNT */
+#define MV_EIP197_PE_0_EIP96_CUR_DIGEST_CNT_REG					(0x002a1280)
+#define MV_EIP197_PE_0_EIP96_CUR_DIGEST_CNT_CUR_DIGEST_CNT_OFFS		0
+
+/* PE_0_EIP96_CUR_SPI_SSRC */
+#define MV_EIP197_PE_0_EIP96_CUR_SPI_SSRC_REG					(0x002a1284)
+#define MV_EIP197_PE_0_EIP96_CUR_SPI_SSRC_CUR_SPI_SSRC_OFFS		0
+
+/* PE_0_EIP96_CUR_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_REG					(0x002a1288)
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_CUR_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_CUR_EXT_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_CUR_EXT_SEQNUM_REG					(0x002a128c)
+#define MV_EIP197_PE_0_EIP96_CUR_EXT_SEQNUM_CUR_EXT_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_CUR_SEQNUM_MASK_0 */
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_0_REG					(0x002a1290)
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_0_CUR_SEQNUM_MASK_0_OFFS		0
+
+/* PE_0_EIP96_CUR_SEQNUM_MASK_1 */
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_1_REG					(0x002a1294)
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_1_CUR_SEQNUM_MASK_1_OFFS		0
+
+/* PE_0_EIP96_CUR_SEQNUM_MASK_2 */
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_2_REG					(0x002a1298)
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_2_CUR_SEQNUM_MASK_2_OFFS		0
+
+/* PE_0_EIP96_CUR_SEQNUM_MASK_3 */
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_3_REG					(0x002a129c)
+#define MV_EIP197_PE_0_EIP96_CUR_SEQNUM_MASK_3_CUR_SEQNUM_MASK_3_OFFS		0
+
+/* PE_0_EIP96_CUR_CHECKSUM */
+#define MV_EIP197_PE_0_EIP96_CUR_CHECKSUM_REG					(0x002a12a4)
+#define MV_EIP197_PE_0_EIP96_CUR_CHECKSUM_CUR_CHECKSUM_OFFS		0
+#define MV_EIP197_PE_0_EIP96_CUR_CHECKSUM_CUR_CHECKSUM_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_EIP96_CUR_CHECKSUM_CUR_CHECKSUM_OFFS)
+
+
+/* PE_0_EIP96_CUR_ARC4_IJ_PNTR */
+#define MV_EIP197_PE_0_EIP96_CUR_ARC4_IJ_PNTR_REG					(0x002a12a8)
+#define MV_EIP197_PE_0_EIP96_CUR_ARC4_IJ_PNTR_CUR_ARC4_IJ_PNTR_OFFS		0
+#define MV_EIP197_PE_0_EIP96_CUR_ARC4_IJ_PNTR_CUR_ARC4_IJ_PNTR_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_EIP96_CUR_ARC4_IJ_PNTR_CUR_ARC4_IJ_PNTR_OFFS)
+
+
+/* PE_0_EIP96_CUR_ARC4_PNTR */
+#define MV_EIP197_PE_0_EIP96_CUR_ARC4_PNTR_REG					(0x002a12ac)
+#define MV_EIP197_PE_0_EIP96_CUR_ARC4_PNTR_CUR_ARC4_PNTR_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_0 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_0_REG					(0x002a12c0)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_0_RES_HASH_0_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_1 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_1_REG					(0x002a12c4)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_1_RES_HASH_1_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_2 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_2_REG					(0x002a12c8)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_2_RES_HASH_2_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_3 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_3_REG					(0x002a12cc)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_3_RES_HASH_3_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_4 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_4_REG					(0x002a12d0)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_4_RES_HASH_4_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_5 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_5_REG					(0x002a12d4)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_5_RES_HASH_5_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_6 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_6_REG					(0x002a12d8)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_6_RES_HASH_6_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_7 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_7_REG					(0x002a12dc)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_7_RES_HASH_7_OFFS		0
+
+/* PE_0_EIP96_RES_DIGEST_CNT */
+#define MV_EIP197_PE_0_EIP96_RES_DIGEST_CNT_REG					(0x002a12e0)
+#define MV_EIP197_PE_0_EIP96_RES_DIGEST_CNT_RES_DIGEST_CNT_OFFS		0
+
+/* PE_0_EIP96_RES_SPI_SSRC */
+#define MV_EIP197_PE_0_EIP96_RES_SPI_SSRC_REG					(0x002a12e4)
+#define MV_EIP197_PE_0_EIP96_RES_SPI_SSRC_RES_SPI_SSRC_OFFS		0
+
+/* PE_0_EIP96_RES_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_RES_SEQNUM_REG					(0x002a12e8)
+#define MV_EIP197_PE_0_EIP96_RES_SEQNUM_RES_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_RES_EXT_SEQNUM */
+#define MV_EIP197_PE_0_EIP96_RES_EXT_SEQNUM_REG					(0x002a12ec)
+#define MV_EIP197_PE_0_EIP96_RES_EXT_SEQNUM_RES_EXT_SEQNUM_OFFS		0
+
+/* PE_0_EIP96_RES_CHECKSUM */
+#define MV_EIP197_PE_0_EIP96_RES_CHECKSUM_REG					(0x002a12f0)
+#define MV_EIP197_PE_0_EIP96_RES_CHECKSUM_RES_CHECKSUM_OFFS		0
+#define MV_EIP197_PE_0_EIP96_RES_CHECKSUM_RES_CHECKSUM_MASK    \
+		(0x0000ffff << MV_EIP197_PE_0_EIP96_RES_CHECKSUM_RES_CHECKSUM_OFFS)
+
+
+/* PE_0_EIP96_NXT_IDIGEST_8 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_8_REG					(0x002a1300)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_8_NXT_IDIGEST_8_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_9 */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_9_REG					(0x002a1304)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_9_NXT_IDIGEST_9_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_A */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_A_REG					(0x002a1308)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_A_NXT_IDIGEST_A_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_B */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_B_REG					(0x002a130c)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_B_NXT_IDIGEST_B_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_C */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_C_REG					(0x002a1310)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_C_NXT_IDIGEST_C_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_D */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_D_REG					(0x002a1314)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_D_NXT_IDIGEST_D_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_E */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_E_REG					(0x002a1318)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_E_NXT_IDIGEST_E_OFFS		0
+
+/* PE_0_EIP96_NXT_IDIGEST_F */
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_F_REG					(0x002a131c)
+#define MV_EIP197_PE_0_EIP96_NXT_IDIGEST_F_NXT_IDIGEST_F_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_8 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_8_REG					(0x002a1320)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_8_NXT_ODIGEST_8_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_9 */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_9_REG					(0x002a1324)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_9_NXT_ODIGEST_9_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_A */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_A_REG					(0x002a1328)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_A_NXT_ODIGEST_A_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_B */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_B_REG					(0x002a132c)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_B_NXT_ODIGEST_B_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_C */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_C_REG					(0x002a1330)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_C_NXT_ODIGEST_C_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_D */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_D_REG					(0x002a1334)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_D_NXT_ODIGEST_D_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_E */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_E_REG					(0x002a1338)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_E_NXT_ODIGEST_E_OFFS		0
+
+/* PE_0_EIP96_NXT_ODIGEST_F */
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_F_REG					(0x002a133c)
+#define MV_EIP197_PE_0_EIP96_NXT_ODIGEST_F_NXT_ODIGEST_F_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_8 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_8_REG					(0x002a1340)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_8_CUR_IDIGEST_8_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_9 */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_9_REG					(0x002a1344)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_9_CUR_IDIGEST_9_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_A */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_A_REG					(0x002a1348)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_A_CUR_IDIGEST_A_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_B */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_B_REG					(0x002a134c)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_B_CUR_IDIGEST_B_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_C */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_C_REG					(0x002a1350)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_C_CUR_IDIGEST_C_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_D */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_D_REG					(0x002a1354)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_D_CUR_IDIGEST_D_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_E */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_E_REG					(0x002a1358)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_E_CUR_IDIGEST_E_OFFS		0
+
+/* PE_0_EIP96_CUR_IDIGEST_F */
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_F_REG					(0x002a135c)
+#define MV_EIP197_PE_0_EIP96_CUR_IDIGEST_F_CUR_IDIGEST_F_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_8 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_8_REG					(0x002a1360)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_8_CUR_ODIGEST_8_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_9 */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_9_REG					(0x002a1364)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_9_CUR_ODIGEST_9_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_A */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_A_REG					(0x002a1368)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_A_CUR_ODIGEST_A_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_B */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_B_REG					(0x002a136c)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_B_CUR_ODIGEST_B_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_C */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_C_REG					(0x002a1370)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_C_CUR_ODIGEST_C_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_D */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_D_REG					(0x002a1374)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_D_CUR_ODIGEST_D_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_E */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_E_REG					(0x002a1378)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_E_CUR_ODIGEST_E_OFFS		0
+
+/* PE_0_EIP96_CUR_ODIGEST_F */
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_F_REG					(0x002a137c)
+#define MV_EIP197_PE_0_EIP96_CUR_ODIGEST_F_CUR_ODIGEST_F_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_8 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_8_REG					(0x002a1380)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_8_RES_HASH_8_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_9 */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_9_REG					(0x002a1384)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_9_RES_HASH_9_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_A */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_A_REG					(0x002a1388)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_A_RES_HASH_A_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_B */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_B_REG					(0x002a138c)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_B_RES_HASH_B_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_C */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_C_REG					(0x002a1390)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_C_RES_HASH_C_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_D */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_D_REG					(0x002a1394)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_D_RES_HASH_D_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_E */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_E_REG					(0x002a1398)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_E_RES_HASH_E_OFFS		0
+
+/* PE_0_EIP96_RES_HASH_F */
+#define MV_EIP197_PE_0_EIP96_RES_HASH_F_REG					(0x002a139c)
+#define MV_EIP197_PE_0_EIP96_RES_HASH_F_RES_HASH_F_OFFS		0
+
+/* PE_0_EIP96_AIC_POL_CTRL */
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_REG					(0x002a13c0)
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS		1
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS		2
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS		3
+#define MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS)
+
+
+/* PE_0_EIP96_AIC_TYPE_CTRL */
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_REG					(0x002a13c4)
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS		1
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS		2
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS		3
+#define MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS)
+
+
+/* PE_0_EIP96_AIC_ENABLE_CTRL */
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CTRL_REG					(0x002a13c8)
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CTRL_ENABLE_CTRL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS)
+
+
+/* PE_0_EIP96_AIC_RAW_STAT */
+#define MV_EIP197_PE_0_EIP96_AIC_RAW_STAT_REG					(0x002a13cc)
+#define MV_EIP197_PE_0_EIP96_AIC_RAW_STAT_RAW_STATUS_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_RAW_STAT_RAW_STATUS_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_RAW_STAT_RAW_STATUS_OFFS)
+
+
+/* PE_0_EIP96_AIC_ENABLED_STAT */
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLED_STAT_REG					(0x002a13d0)
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLED_STAT_ENABLED_STATUS_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS)
+
+
+/* PE_0_EIP96_AIC_ENABLE_CLR */
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CLR_REG					(0x002a13d4)
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CLR_ENABLE_CLR_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_ENABLE_CLR_ENABLE_CLR_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_ENABLE_CLR_ENABLE_CLR_OFFS)
+
+
+/* PE_0_EIP96_AIC_OPTIONS */
+#define MV_EIP197_PE_0_EIP96_AIC_OPTIONS_REG					(0x002a13d8)
+#define MV_EIP197_PE_0_EIP96_AIC_OPTIONS_NR_OF_INPUTS_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_OPTIONS_NR_OF_INPUTS_MASK    \
+		(0x0000003f << MV_EIP197_PE_0_EIP96_AIC_OPTIONS_NR_OF_INPUTS_OFFS)
+
+
+/* PE_0_EIP96_AIC_VERSION */
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_REG					(0x002a13dc)
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_AIC_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_PE_0_EIP96_AIC_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_AIC_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* PE_0_EIP96_OPTIONS */
+#define MV_EIP197_PE_0_EIP96_OPTIONS_REG					(0x002a13f8)
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_OFFS		12
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_AES_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_FB_OFFS		13
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_FB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_AES_FB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_SPEED_OFFS		14
+#define MV_EIP197_PE_0_EIP96_OPTIONS_AES_SPEED_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_AES_SPEED_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_OFFS		15
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_DES_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_FB_OFFS		16
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_FB_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_DES_FB_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_SPEED_OFFS		17
+#define MV_EIP197_PE_0_EIP96_OPTIONS_DES_SPEED_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_DES_SPEED_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_ARC4_OFFS		18
+#define MV_EIP197_PE_0_EIP96_OPTIONS_ARC4_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_EIP96_OPTIONS_ARC4_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_OFFS		20
+#define MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_MD5_OFFS		22
+#define MV_EIP197_PE_0_EIP96_OPTIONS_MD5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_MD5_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_OFFS		23
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_SPEED_OFFS		24
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_SPEED_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_SHA1_SPEED_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA224_256_OFFS		25
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA224_256_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_SHA224_256_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA384_512_OFFS		26
+#define MV_EIP197_PE_0_EIP96_OPTIONS_SHA384_512_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_SHA384_512_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_XCBC_MAC_OFFS		27
+#define MV_EIP197_PE_0_EIP96_OPTIONS_XCBC_MAC_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_XCBC_MAC_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_SPEED_OFFS		28
+#define MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_SPEED_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_SPEED_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_KEYLENS_OFFS		29
+#define MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_KEYLENS_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_CBC_MAC_KEYLENS_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_GHASH_OFFS		30
+#define MV_EIP197_PE_0_EIP96_OPTIONS_GHASH_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_GHASH_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_F9_OFFS		31
+#define MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_F9_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_EIP96_OPTIONS_KASUMI_F9_OFFS)
+
+
+/* PE_0_EIP96_VERSION */
+#define MV_EIP197_PE_0_EIP96_VERSION_REG					(0x002a13fc)
+#define MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_EIP96_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_PE_0_EIP96_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_PE_0_EIP96_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_PE_0_EIP96_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_PE_0_EIP96_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_EIP96_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* PE_0_OUT_DBUF_THRESH */
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_REG					(0x002a1c00)
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_MIN_THRESH_OFFS		0
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_MIN_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_OUT_DBUF_THRESH_MIN_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_MAX_THRESH_OFFS		4
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_MAX_THRESH_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_OUT_DBUF_THRESH_MAX_THRESH_OFFS)
+
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_COUNT_OFFS		16
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_OUT_DBUF_THRESH_COUNT_OFFS)
+
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_UFLOW_IRQ_OFFS		30
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_UFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_OUT_DBUF_THRESH_UFLOW_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_OFLOW_IRQ_OFFS		31
+#define MV_EIP197_PE_0_OUT_DBUF_THRESH_OFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_OUT_DBUF_THRESH_OFLOW_IRQ_OFFS)
+
+
+/* PE_0_OUT_TBUF_THRESH */
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_REG					(0x002a1d00)
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_COUNT_OFFS		16
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_COUNT_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_OUT_TBUF_THRESH_COUNT_OFFS)
+
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_UFLOW_IRQ_OFFS		30
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_UFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_OUT_TBUF_THRESH_UFLOW_IRQ_OFFS)
+
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_OFLOW_IRQ_OFFS		31
+#define MV_EIP197_PE_0_OUT_TBUF_THRESH_OFLOW_IRQ_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_OUT_TBUF_THRESH_OFLOW_IRQ_OFFS)
+
+
+/* PE_0_AIC_POL_CTRL */
+#define MV_EIP197_PE_0_AIC_POL_CTRL_REG					(0x002a1f00)
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS		0
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS		1
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS		2
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS		3
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_4_OFFS		4
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_4_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_4_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_5_OFFS		5
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_5_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_6_OFFS		6
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_6_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_6_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_7_OFFS		7
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_7_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_7_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_8_OFFS		8
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_8_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_8_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_9_OFFS		9
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_9_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_9_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_10_OFFS		10
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_10_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_10_OFFS)
+
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_11_OFFS		11
+#define MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_11_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_POL_CTRL_POLARITY_CTRL_11_OFFS)
+
+
+/* PE_0_AIC_TYPE_CTRL */
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_REG					(0x002a1f04)
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS		0
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS		1
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS		2
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS		3
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_4_OFFS		4
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_4_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_4_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_5_OFFS		5
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_5_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_5_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_6_OFFS		6
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_6_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_6_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_7_OFFS		7
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_7_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_7_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_8_OFFS		8
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_8_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_8_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_9_OFFS		9
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_9_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_9_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_10_OFFS		10
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_10_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_10_OFFS)
+
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_11_OFFS		11
+#define MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_11_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_AIC_TYPE_CTRL_TYPE_CTRL_11_OFFS)
+
+
+/* PE_0_AIC_ENABLE_CTRL */
+#define MV_EIP197_PE_0_AIC_ENABLE_CTRL_REG					(0x002a1f08)
+#define MV_EIP197_PE_0_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS		0
+#define MV_EIP197_PE_0_AIC_ENABLE_CTRL_ENABLE_CTRL_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS)
+
+
+/* PE_0_AIC_RAW_STAT */
+#define MV_EIP197_PE_0_AIC_RAW_STAT_REG					(0x002a1f0c)
+#define MV_EIP197_PE_0_AIC_RAW_STAT_RAW_STATUS_OFFS		0
+#define MV_EIP197_PE_0_AIC_RAW_STAT_RAW_STATUS_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_AIC_RAW_STAT_RAW_STATUS_OFFS)
+
+
+/* PE_0_AIC_ENABLED_STAT */
+#define MV_EIP197_PE_0_AIC_ENABLED_STAT_REG					(0x002a1f10)
+#define MV_EIP197_PE_0_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS		0
+#define MV_EIP197_PE_0_AIC_ENABLED_STAT_ENABLED_STATUS_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS)
+
+
+/* PE_0_AIC_ENABLE_CLR */
+#define MV_EIP197_PE_0_AIC_ENABLE_CLR_REG					(0x002a1f14)
+#define MV_EIP197_PE_0_AIC_ENABLE_CLR_ENABLE_CLR_OFFS		0
+#define MV_EIP197_PE_0_AIC_ENABLE_CLR_ENABLE_CLR_MASK    \
+		(0x00000fff << MV_EIP197_PE_0_AIC_ENABLE_CLR_ENABLE_CLR_OFFS)
+
+
+/* PE_0_AIC_OPTIONS */
+#define MV_EIP197_PE_0_AIC_OPTIONS_REG					(0x002a1f18)
+#define MV_EIP197_PE_0_AIC_OPTIONS_NR_OF_INPUTS_OFFS		0
+#define MV_EIP197_PE_0_AIC_OPTIONS_NR_OF_INPUTS_MASK    \
+		(0x0000003f << MV_EIP197_PE_0_AIC_OPTIONS_NR_OF_INPUTS_OFFS)
+
+
+/* PE_0_AIC_VERSION */
+#define MV_EIP197_PE_0_AIC_VERSION_REG					(0x002a1f1c)
+#define MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_AIC_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_PE_0_AIC_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_PE_0_AIC_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_AIC_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_PE_0_AIC_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_PE_0_AIC_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_AIC_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_PE_0_AIC_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_PE_0_AIC_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_AIC_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* PE_0_PE_ARC4_SIZE */
+#define MV_EIP197_PE_0_PE_ARC4_SIZE_REG					(0x002a1fec)
+#define MV_EIP197_PE_0_PE_ARC4_SIZE_ARC4_SIZE_OFFS		0
+#define MV_EIP197_PE_0_PE_ARC4_SIZE_ARC4_SIZE_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_PE_ARC4_SIZE_ARC4_SIZE_OFFS)
+
+
+/* PE_0_PE_IN_FLIGHT */
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_REG					(0x002a1ff0)
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_UNSAFE_OFFS		0
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_UNSAFE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_IN_FLIGHT_UNSAFE_OFFS)
+
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_IN_FLIGHT_OFFS		16
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_IN_FLIGHT_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_IN_FLIGHT_IN_FLIGHT_OFFS)
+
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_WR_IN_FLIGHT_OFFS		29
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_WR_IN_FLIGHT_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_PE_IN_FLIGHT_WR_IN_FLIGHT_OFFS)
+
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_UNDERFLOW_OFFS		30
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_UNDERFLOW_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_PE_IN_FLIGHT_UNDERFLOW_OFFS)
+
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_OVERFLOW_OFFS		31
+#define MV_EIP197_PE_0_PE_IN_FLIGHT_OVERFLOW_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_PE_IN_FLIGHT_OVERFLOW_OFFS)
+
+
+/* PE_0_PE_DEBUG */
+#define MV_EIP197_PE_0_PE_DEBUG_REG					(0x002a1ff4)
+#define MV_EIP197_PE_0_PE_DEBUG_IC2OUT_BYPASS_OFFS		0
+#define MV_EIP197_PE_0_PE_DEBUG_IC2OUT_BYPASS_MASK    \
+		(0x00000001 << MV_EIP197_PE_0_PE_DEBUG_IC2OUT_BYPASS_OFFS)
+
+#define MV_EIP197_PE_0_PE_DEBUG_IN_FLIGHT_MAX_OFFS		16
+#define MV_EIP197_PE_0_PE_DEBUG_IN_FLIGHT_MAX_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_DEBUG_IN_FLIGHT_MAX_OFFS)
+
+
+/* PE_0_PE_OPTIONS */
+#define MV_EIP197_PE_0_PE_OPTIONS_REG					(0x002a1ff8)
+#define MV_EIP197_PE_0_PE_OPTIONS_PE_TYPE_OFFS		0
+#define MV_EIP197_PE_0_PE_OPTIONS_PE_TYPE_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_OPTIONS_PE_TYPE_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_CLASSIFIER_OFFS		8
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_CLASSIFIER_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_PE_OPTIONS_IN_CLASSIFIER_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_CLASSIFIER_OFFS		10
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_CLASSIFIER_MASK    \
+		(0x00000003 << MV_EIP197_PE_0_PE_OPTIONS_OUT_CLASSIFIER_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_TBUF_SIZE_OFFS		18
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_TBUF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_PE_0_PE_OPTIONS_IN_TBUF_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_DBUF_SIZE_OFFS		21
+#define MV_EIP197_PE_0_PE_OPTIONS_IN_DBUF_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_PE_OPTIONS_IN_DBUF_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_TBUF_SIZE_OFFS		25
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_TBUF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_PE_0_PE_OPTIONS_OUT_TBUF_SIZE_OFFS)
+
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_DBUF_SIZE_OFFS		28
+#define MV_EIP197_PE_0_PE_OPTIONS_OUT_DBUF_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_PE_OPTIONS_OUT_DBUF_SIZE_OFFS)
+
+
+/* PE_0_PE_VERSION */
+#define MV_EIP197_PE_0_PE_VERSION_REG					(0x002a1ffc)
+#define MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_COMPLEMENT_OFFS		8
+#define MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_COMPLEMENT_MASK    \
+		(0x000000ff << MV_EIP197_PE_0_PE_VERSION_EIP_NUMBER_COMPLEMENT_OFFS)
+
+#define MV_EIP197_PE_0_PE_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_PE_0_PE_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_PE_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_PE_0_PE_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_PE_0_PE_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_PE_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_PE_0_PE_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_PE_0_PE_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_PE_0_PE_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* FRC_0_CTRL */
+#define MV_EIP197_FRC_0_CTRL_REG					(0x002f0000)
+#define MV_EIP197_FRC_0_CTRL_COMMAND_OFFS		0
+#define MV_EIP197_FRC_0_CTRL_COMMAND_MASK    \
+		(0x0000000f << MV_EIP197_FRC_0_CTRL_COMMAND_OFFS)
+
+#define MV_EIP197_FRC_0_CTRL_LOCK_OFFS		8
+#define MV_EIP197_FRC_0_CTRL_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_CTRL_LOCK_OFFS)
+
+#define MV_EIP197_FRC_0_CTRL_LOCK_PRESET_OFFS		16
+#define MV_EIP197_FRC_0_CTRL_LOCK_PRESET_MASK    \
+		(0x0000000f << MV_EIP197_FRC_0_CTRL_LOCK_PRESET_OFFS)
+
+#define MV_EIP197_FRC_0_CTRL_LOCK_TIMER_OFFS		24
+#define MV_EIP197_FRC_0_CTRL_LOCK_TIMER_MASK    \
+		(0x0000001f << MV_EIP197_FRC_0_CTRL_LOCK_TIMER_OFFS)
+
+#define MV_EIP197_FRC_0_CTRL_UPDATING_OFFS		31
+#define MV_EIP197_FRC_0_CTRL_UPDATING_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_CTRL_UPDATING_OFFS)
+
+
+/* FRC_0_LASTRES */
+#define MV_EIP197_FRC_0_LASTRES_REG					(0x002f0004)
+#define MV_EIP197_FRC_0_LASTRES_LAST_READ_RESULT_OFFS		0
+
+/* FRC_0_REGINDEX */
+#define MV_EIP197_FRC_0_REGINDEX_REG					(0x002f0008)
+#define MV_EIP197_FRC_0_REGINDEX_REGINDEX_OFFS		0
+#define MV_EIP197_FRC_0_REGINDEX_REGINDEX_MASK    \
+		(0x0000003f << MV_EIP197_FRC_0_REGINDEX_REGINDEX_OFFS)
+
+#define MV_EIP197_FRC_0_REGINDEX_GENERATION_OFFS		6
+#define MV_EIP197_FRC_0_REGINDEX_GENERATION_MASK    \
+		(0x00000007 << MV_EIP197_FRC_0_REGINDEX_GENERATION_OFFS)
+
+#define MV_EIP197_FRC_0_REGINDEX_USE_GEN_OFFS		31
+#define MV_EIP197_FRC_0_REGINDEX_USE_GEN_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_REGINDEX_USE_GEN_OFFS)
+
+
+/* FRC_0_PARAMS */
+#define MV_EIP197_FRC_0_PARAMS_REG					(0x002f0020)
+#define MV_EIP197_FRC_0_PARAMS_SW_RESET_OFFS		0
+#define MV_EIP197_FRC_0_PARAMS_SW_RESET_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_SW_RESET_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_NO_BLOCK_OFFS		1
+#define MV_EIP197_FRC_0_PARAMS_NO_BLOCK_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_NO_BLOCK_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_DATA_ACCESS_OFFS		2
+#define MV_EIP197_FRC_0_PARAMS_DATA_ACCESS_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_DATA_ACCESS_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_HASH__SIZE_OFFS		4
+#define MV_EIP197_FRC_0_PARAMS_HASH__SIZE_MASK    \
+		(0x00000007 << MV_EIP197_FRC_0_PARAMS_HASH__SIZE_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_BLOCK_TIMEBASE_OFFS		10
+#define MV_EIP197_FRC_0_PARAMS_BLOCK_TIMEBASE_MASK    \
+		(0x00000007 << MV_EIP197_FRC_0_PARAMS_BLOCK_TIMEBASE_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_RECORD_SIZE_OFFS		21
+#define MV_EIP197_FRC_0_PARAMS_RECORD_SIZE_MASK    \
+		(0x0000003f << MV_EIP197_FRC_0_PARAMS_RECORD_SIZE_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_CTRL_ERROR_OFFS		28
+#define MV_EIP197_FRC_0_PARAMS_CTRL_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_CTRL_ERROR_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_DMA_ERR_ACC_OFFS		29
+#define MV_EIP197_FRC_0_PARAMS_DMA_ERR_ACC_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_DMA_ERR_ACC_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_DMA_RD_ERR_OFFS		30
+#define MV_EIP197_FRC_0_PARAMS_DMA_RD_ERR_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_DMA_RD_ERR_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS_DMA_WR_ERR_OFFS		31
+#define MV_EIP197_FRC_0_PARAMS_DMA_WR_ERR_MASK    \
+		(0x00000001 << MV_EIP197_FRC_0_PARAMS_DMA_WR_ERR_OFFS)
+
+
+/* FRC_0_FREECHAIN */
+#define MV_EIP197_FRC_0_FREECHAIN_REG					(0x002f0024)
+#define MV_EIP197_FRC_0_FREECHAIN_HEAD_POINTER_OFFS		0
+#define MV_EIP197_FRC_0_FREECHAIN_HEAD_POINTER_MASK    \
+		(0x000003ff << MV_EIP197_FRC_0_FREECHAIN_HEAD_POINTER_OFFS)
+
+#define MV_EIP197_FRC_0_FREECHAIN_TAIL_POINTER_OFFS		16
+#define MV_EIP197_FRC_0_FREECHAIN_TAIL_POINTER_MASK    \
+		(0x000003ff << MV_EIP197_FRC_0_FREECHAIN_TAIL_POINTER_OFFS)
+
+
+/* FRC_0_PARAMS2 */
+#define MV_EIP197_FRC_0_PARAMS2_REG					(0x002f0028)
+#define MV_EIP197_FRC_0_PARAMS2_HASH__START_OFFS		0
+#define MV_EIP197_FRC_0_PARAMS2_HASH__START_MASK    \
+		(0x000003ff << MV_EIP197_FRC_0_PARAMS2_HASH__START_OFFS)
+
+#define MV_EIP197_FRC_0_PARAMS2_DMA_WR_COMB_DLY_OFFS		10
+#define MV_EIP197_FRC_0_PARAMS2_DMA_WR_COMB_DLY_MASK    \
+		(0x000000ff << MV_EIP197_FRC_0_PARAMS2_DMA_WR_COMB_DLY_OFFS)
+
+
+/* TRC_0_CTRL */
+#define MV_EIP197_TRC_0_CTRL_REG					(0x002f0800)
+#define MV_EIP197_TRC_0_CTRL_COMMAND_OFFS		0
+#define MV_EIP197_TRC_0_CTRL_COMMAND_MASK    \
+		(0x0000000f << MV_EIP197_TRC_0_CTRL_COMMAND_OFFS)
+
+#define MV_EIP197_TRC_0_CTRL_LOCK_OFFS		8
+#define MV_EIP197_TRC_0_CTRL_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_CTRL_LOCK_OFFS)
+
+#define MV_EIP197_TRC_0_CTRL_LOCK_PRESET_OFFS		16
+#define MV_EIP197_TRC_0_CTRL_LOCK_PRESET_MASK    \
+		(0x0000001f << MV_EIP197_TRC_0_CTRL_LOCK_PRESET_OFFS)
+
+#define MV_EIP197_TRC_0_CTRL_LOCK_TIMER_OFFS		24
+#define MV_EIP197_TRC_0_CTRL_LOCK_TIMER_MASK    \
+		(0x0000001f << MV_EIP197_TRC_0_CTRL_LOCK_TIMER_OFFS)
+
+#define MV_EIP197_TRC_0_CTRL_UPDATING_OFFS		31
+#define MV_EIP197_TRC_0_CTRL_UPDATING_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_CTRL_UPDATING_OFFS)
+
+
+/* TRC_0_LASTRES */
+#define MV_EIP197_TRC_0_LASTRES_REG					(0x002f0804)
+#define MV_EIP197_TRC_0_LASTRES_LAST_READ_RESULT_OFFS		0
+
+/* TRC_0_REGINDEX */
+#define MV_EIP197_TRC_0_REGINDEX_REG					(0x002f0808)
+#define MV_EIP197_TRC_0_REGINDEX_REGINDEX_OFFS		0
+#define MV_EIP197_TRC_0_REGINDEX_REGINDEX_MASK    \
+		(0x0000003f << MV_EIP197_TRC_0_REGINDEX_REGINDEX_OFFS)
+
+#define MV_EIP197_TRC_0_REGINDEX_GENERATION_OFFS		6
+#define MV_EIP197_TRC_0_REGINDEX_GENERATION_MASK    \
+		(0x00000007 << MV_EIP197_TRC_0_REGINDEX_GENERATION_OFFS)
+
+#define MV_EIP197_TRC_0_REGINDEX_USE_GEN_OFFS		31
+#define MV_EIP197_TRC_0_REGINDEX_USE_GEN_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_REGINDEX_USE_GEN_OFFS)
+
+
+/* TRC_0_PARAMS */
+#define MV_EIP197_TRC_0_PARAMS_REG					(0x002f0820)
+#define MV_EIP197_TRC_0_PARAMS_SW_RESET_OFFS		0
+#define MV_EIP197_TRC_0_PARAMS_SW_RESET_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_SW_RESET_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_NO_BLOCK_OFFS		1
+#define MV_EIP197_TRC_0_PARAMS_NO_BLOCK_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_NO_BLOCK_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_DATA_ACCESS_OFFS		2
+#define MV_EIP197_TRC_0_PARAMS_DATA_ACCESS_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_DATA_ACCESS_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_HASH__SIZE_OFFS		4
+#define MV_EIP197_TRC_0_PARAMS_HASH__SIZE_MASK    \
+		(0x00000007 << MV_EIP197_TRC_0_PARAMS_HASH__SIZE_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_BLOCK_TIMEBASE_OFFS		10
+#define MV_EIP197_TRC_0_PARAMS_BLOCK_TIMEBASE_MASK    \
+		(0x00000007 << MV_EIP197_TRC_0_PARAMS_BLOCK_TIMEBASE_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_RECORD_SIZE_OFFS		21
+#define MV_EIP197_TRC_0_PARAMS_RECORD_SIZE_MASK    \
+		(0x0000003f << MV_EIP197_TRC_0_PARAMS_RECORD_SIZE_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_CTRL_ERROR_OFFS		28
+#define MV_EIP197_TRC_0_PARAMS_CTRL_ERROR_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_CTRL_ERROR_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_DMA_ERR_ACC_OFFS		29
+#define MV_EIP197_TRC_0_PARAMS_DMA_ERR_ACC_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_DMA_ERR_ACC_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_DMA_RD_ERR_OFFS		30
+#define MV_EIP197_TRC_0_PARAMS_DMA_RD_ERR_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_DMA_RD_ERR_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS_DMA_WR_ERR_OFFS		31
+#define MV_EIP197_TRC_0_PARAMS_DMA_WR_ERR_MASK    \
+		(0x00000001 << MV_EIP197_TRC_0_PARAMS_DMA_WR_ERR_OFFS)
+
+
+/* TRC_0_FREECHAIN */
+#define MV_EIP197_TRC_0_FREECHAIN_REG					(0x002f0824)
+#define MV_EIP197_TRC_0_FREECHAIN_HEAD_POINTER_OFFS		0
+#define MV_EIP197_TRC_0_FREECHAIN_HEAD_POINTER_MASK    \
+		(0x000003ff << MV_EIP197_TRC_0_FREECHAIN_HEAD_POINTER_OFFS)
+
+#define MV_EIP197_TRC_0_FREECHAIN_TAIL_POINTER_OFFS		16
+#define MV_EIP197_TRC_0_FREECHAIN_TAIL_POINTER_MASK    \
+		(0x000003ff << MV_EIP197_TRC_0_FREECHAIN_TAIL_POINTER_OFFS)
+
+
+/* TRC_0_PARAMS2 */
+#define MV_EIP197_TRC_0_PARAMS2_REG					(0x002f0828)
+#define MV_EIP197_TRC_0_PARAMS2_HASH__START_OFFS		0
+#define MV_EIP197_TRC_0_PARAMS2_HASH__START_MASK    \
+		(0x000003ff << MV_EIP197_TRC_0_PARAMS2_HASH__START_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS2_DMA_WR_COMB_DLY_OFFS		10
+#define MV_EIP197_TRC_0_PARAMS2_DMA_WR_COMB_DLY_MASK    \
+		(0x000000ff << MV_EIP197_TRC_0_PARAMS2_DMA_WR_COMB_DLY_OFFS)
+
+#define MV_EIP197_TRC_0_PARAMS2_RECORD_SIZE2_OFFS		21
+#define MV_EIP197_TRC_0_PARAMS2_RECORD_SIZE2_MASK    \
+		(0x0000003f << MV_EIP197_TRC_0_PARAMS2_RECORD_SIZE2_OFFS)
+
+
+/* FLUE_CACHEBASE_0_LO */
+#define MV_EIP197_FLUE_CACHEBASE_0_LO_REG					(0x002f6000)
+#define MV_EIP197_FLUE_CACHEBASE_0_LO_CACHE_BASE_OFFS		2
+#define MV_EIP197_FLUE_CACHEBASE_0_LO_CACHE_BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_CACHEBASE_0_LO_CACHE_BASE_OFFS)
+
+
+/* FLUE_CACHEBASE_0_HI */
+#define MV_EIP197_FLUE_CACHEBASE_0_HI_REG					(0x002f6004)
+#define MV_EIP197_FLUE_CACHEBASE_0_HI_CACHE_BASE_OFFS		0
+#define MV_EIP197_FLUE_CACHEBASE_0_HI_CACHE_BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_CACHEBASE_0_HI_CACHE_BASE_OFFS)
+
+
+/* FLUE_HASHBASE_0_LO */
+#define MV_EIP197_FLUE_HASHBASE_0_LO_REG					(0x002f6008)
+#define MV_EIP197_FLUE_HASHBASE_0_LO__BASE_OFFS		2
+#define MV_EIP197_FLUE_HASHBASE_0_LO__BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_HASHBASE_0_LO__BASE_OFFS)
+
+
+/* FLUE_HASHBASE_0_HI */
+#define MV_EIP197_FLUE_HASHBASE_0_HI_REG					(0x002f600c)
+#define MV_EIP197_FLUE_HASHBASE_0_HI__BASE_OFFS		0
+#define MV_EIP197_FLUE_HASHBASE_0_HI__BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_HASHBASE_0_HI__BASE_OFFS)
+
+
+/* FLUE_CONFIG_0 */
+#define MV_EIP197_FLUE_CONFIG_0_REG					(0x002f6010)
+#define MV_EIP197_FLUE_CONFIG_0_PREFETCH_DIS_OFFS		1
+#define MV_EIP197_FLUE_CONFIG_0_PREFETCH_DIS_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_0_PREFETCH_DIS_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0_PREFETCH_TRC_OFFS		2
+#define MV_EIP197_FLUE_CONFIG_0_PREFETCH_TRC_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_0_PREFETCH_TRC_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0__SIZE_OFFS		4
+#define MV_EIP197_FLUE_CONFIG_0__SIZE_MASK    \
+		(0x0000000f << MV_EIP197_FLUE_CONFIG_0__SIZE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0_FUNCTION_OFFS		16
+#define MV_EIP197_FLUE_CONFIG_0_FUNCTION_MASK    \
+		(0x000000ff << MV_EIP197_FLUE_CONFIG_0_FUNCTION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0_GENERATION_OFFS		24
+#define MV_EIP197_FLUE_CONFIG_0_GENERATION_MASK    \
+		(0x00000007 << MV_EIP197_FLUE_CONFIG_0_GENERATION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0__ENABLE_OFFS		30
+#define MV_EIP197_FLUE_CONFIG_0__ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_0__ENABLE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_0_ACCESS_ENABLE_OFFS		31
+#define MV_EIP197_FLUE_CONFIG_0_ACCESS_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_0_ACCESS_ENABLE_OFFS)
+
+
+/* FLUE_CACHEBASE_1_LO */
+#define MV_EIP197_FLUE_CACHEBASE_1_LO_REG					(0x002f6020)
+#define MV_EIP197_FLUE_CACHEBASE_1_LO_CACHE_BASE_OFFS		2
+#define MV_EIP197_FLUE_CACHEBASE_1_LO_CACHE_BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_CACHEBASE_1_LO_CACHE_BASE_OFFS)
+
+
+/* FLUE_CACHEBASE_1_HI */
+#define MV_EIP197_FLUE_CACHEBASE_1_HI_REG					(0x002f6024)
+#define MV_EIP197_FLUE_CACHEBASE_1_HI_CACHE_BASE_OFFS		0
+#define MV_EIP197_FLUE_CACHEBASE_1_HI_CACHE_BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_CACHEBASE_1_HI_CACHE_BASE_OFFS)
+
+
+/* FLUE_HASHBASE_1_LO */
+#define MV_EIP197_FLUE_HASHBASE_1_LO_REG					(0x002f6028)
+#define MV_EIP197_FLUE_HASHBASE_1_LO__BASE_OFFS		2
+#define MV_EIP197_FLUE_HASHBASE_1_LO__BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_HASHBASE_1_LO__BASE_OFFS)
+
+
+/* FLUE_HASHBASE_1_HI */
+#define MV_EIP197_FLUE_HASHBASE_1_HI_REG					(0x002f602c)
+#define MV_EIP197_FLUE_HASHBASE_1_HI__BASE_OFFS		0
+#define MV_EIP197_FLUE_HASHBASE_1_HI__BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_HASHBASE_1_HI__BASE_OFFS)
+
+
+/* FLUE_CONFIG_1 */
+#define MV_EIP197_FLUE_CONFIG_1_REG					(0x002f6030)
+#define MV_EIP197_FLUE_CONFIG_1_PREFETCH_DIS_OFFS		1
+#define MV_EIP197_FLUE_CONFIG_1_PREFETCH_DIS_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_1_PREFETCH_DIS_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1_PREFETCH_TRC_OFFS		2
+#define MV_EIP197_FLUE_CONFIG_1_PREFETCH_TRC_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_1_PREFETCH_TRC_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1__SIZE_OFFS		4
+#define MV_EIP197_FLUE_CONFIG_1__SIZE_MASK    \
+		(0x0000000f << MV_EIP197_FLUE_CONFIG_1__SIZE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1_FUNCTION_OFFS		16
+#define MV_EIP197_FLUE_CONFIG_1_FUNCTION_MASK    \
+		(0x000000ff << MV_EIP197_FLUE_CONFIG_1_FUNCTION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1_GENERATION_OFFS		24
+#define MV_EIP197_FLUE_CONFIG_1_GENERATION_MASK    \
+		(0x00000007 << MV_EIP197_FLUE_CONFIG_1_GENERATION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1__ENABLE_OFFS		30
+#define MV_EIP197_FLUE_CONFIG_1__ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_1__ENABLE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_1_ACCESS_ENABLE_OFFS		31
+#define MV_EIP197_FLUE_CONFIG_1_ACCESS_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_1_ACCESS_ENABLE_OFFS)
+
+
+/* FLUE_CACHEBASE_2_LO */
+#define MV_EIP197_FLUE_CACHEBASE_2_LO_REG					(0x002f6040)
+#define MV_EIP197_FLUE_CACHEBASE_2_LO_CACHE_BASE_OFFS		2
+#define MV_EIP197_FLUE_CACHEBASE_2_LO_CACHE_BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_CACHEBASE_2_LO_CACHE_BASE_OFFS)
+
+
+/* FLUE_CACHEBASE_2_HI */
+#define MV_EIP197_FLUE_CACHEBASE_2_HI_REG					(0x002f6044)
+#define MV_EIP197_FLUE_CACHEBASE_2_HI_CACHE_BASE_OFFS		0
+#define MV_EIP197_FLUE_CACHEBASE_2_HI_CACHE_BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_CACHEBASE_2_HI_CACHE_BASE_OFFS)
+
+
+/* FLUE_HASHBASE_2_LO */
+#define MV_EIP197_FLUE_HASHBASE_2_LO_REG					(0x002f6048)
+#define MV_EIP197_FLUE_HASHBASE_2_LO__BASE_OFFS		2
+#define MV_EIP197_FLUE_HASHBASE_2_LO__BASE_MASK    \
+		(0x3fffffff << MV_EIP197_FLUE_HASHBASE_2_LO__BASE_OFFS)
+
+
+/* FLUE_HASHBASE_2_HI */
+#define MV_EIP197_FLUE_HASHBASE_2_HI_REG					(0x002f604c)
+#define MV_EIP197_FLUE_HASHBASE_2_HI__BASE_OFFS		0
+#define MV_EIP197_FLUE_HASHBASE_2_HI__BASE_MASK    \
+		(0x00ffffff << MV_EIP197_FLUE_HASHBASE_2_HI__BASE_OFFS)
+
+
+/* FLUE_CONFIG_2 */
+#define MV_EIP197_FLUE_CONFIG_2_REG					(0x002f6050)
+#define MV_EIP197_FLUE_CONFIG_2_PREFETCH_DIS_OFFS		1
+#define MV_EIP197_FLUE_CONFIG_2_PREFETCH_DIS_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_2_PREFETCH_DIS_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2_PREFETCH_TRC_OFFS		2
+#define MV_EIP197_FLUE_CONFIG_2_PREFETCH_TRC_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_2_PREFETCH_TRC_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2__SIZE_OFFS		4
+#define MV_EIP197_FLUE_CONFIG_2__SIZE_MASK    \
+		(0x0000000f << MV_EIP197_FLUE_CONFIG_2__SIZE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2_FUNCTION_OFFS		16
+#define MV_EIP197_FLUE_CONFIG_2_FUNCTION_MASK    \
+		(0x000000ff << MV_EIP197_FLUE_CONFIG_2_FUNCTION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2_GENERATION_OFFS		24
+#define MV_EIP197_FLUE_CONFIG_2_GENERATION_MASK    \
+		(0x00000007 << MV_EIP197_FLUE_CONFIG_2_GENERATION_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2__ENABLE_OFFS		30
+#define MV_EIP197_FLUE_CONFIG_2__ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_2__ENABLE_OFFS)
+
+#define MV_EIP197_FLUE_CONFIG_2_ACCESS_ENABLE_OFFS		31
+#define MV_EIP197_FLUE_CONFIG_2_ACCESS_ENABLE_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_CONFIG_2_ACCESS_ENABLE_OFFS)
+
+
+/* FLUE_OFFSETS */
+#define MV_EIP197_FLUE_OFFSETS_REG					(0x002f6808)
+#define MV_EIP197_FLUE_OFFSETS_FORCE_HASH_ID_OFFS		1
+#define MV_EIP197_FLUE_OFFSETS_FORCE_HASH_ID_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_OFFSETS_FORCE_HASH_ID_OFFS)
+
+#define MV_EIP197_FLUE_OFFSETS_FORCE_PREFETCH_OFFS		2
+#define MV_EIP197_FLUE_OFFSETS_FORCE_PREFETCH_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_OFFSETS_FORCE_PREFETCH_OFFS)
+
+#define MV_EIP197_FLUE_OFFSETS_XFORM_REC_OFFSET_OFFS		24
+#define MV_EIP197_FLUE_OFFSETS_XFORM_REC_OFFSET_MASK    \
+		(0x000000ff << MV_EIP197_FLUE_OFFSETS_XFORM_REC_OFFSET_OFFS)
+
+
+/* FLUE_ARC4_OFFSET */
+#define MV_EIP197_FLUE_ARC4_OFFSET_REG					(0x002f680c)
+#define MV_EIP197_FLUE_ARC4_OFFSET_PREFETCH_DIS_OFFS		0
+#define MV_EIP197_FLUE_ARC4_OFFSET_PREFETCH_DIS_MASK    \
+		(0x00000001 << MV_EIP197_FLUE_ARC4_OFFSET_PREFETCH_DIS_OFFS)
+
+
+/* FLUE_IFC_LUT_0 */
+#define MV_EIP197_FLUE_IFC_LUT_0_REG					(0x002f6820)
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC0__ID_OFFS		0
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC0__ID_MASK    \
+		(0x00000003 << MV_EIP197_FLUE_IFC_LUT_0_IFC0__ID_OFFS)
+
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC1__ID_OFFS		8
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC1__ID_MASK    \
+		(0x00000003 << MV_EIP197_FLUE_IFC_LUT_0_IFC1__ID_OFFS)
+
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC2__ID_OFFS		16
+#define MV_EIP197_FLUE_IFC_LUT_0_IFC2__ID_MASK    \
+		(0x00000003 << MV_EIP197_FLUE_IFC_LUT_0_IFC2__ID_OFFS)
+
+
+/* FLUE_ENABLED_LO */
+#define MV_EIP197_FLUE_ENABLED_LO_REG					(0x002f6840)
+#define MV_EIP197_FLUE_ENABLED_LO__ENABLED_BITMAP_OFFS		0
+#define MV_EIP197_FLUE_ENABLED_LO__ENABLED_BITMAP_MASK    \
+		(0x00000007 << MV_EIP197_FLUE_ENABLED_LO__ENABLED_BITMAP_OFFS)
+
+
+/* FLUE_ERROR_LO */
+#define MV_EIP197_FLUE_ERROR_LO_REG					(0x002f6848)
+#define MV_EIP197_FLUE_ERROR_LO_ACCESS_ERROR_BITMAP_OFFS		0
+#define MV_EIP197_FLUE_ERROR_LO_ACCESS_ERROR_BITMAP_MASK    \
+		(0x00000007 << MV_EIP197_FLUE_ERROR_LO_ACCESS_ERROR_BITMAP_OFFS)
+
+
+/* FHASH_IV_0 */
+#define MV_EIP197_FHASH_IV_0_REG					(0x002f68c0)
+#define MV_EIP197_FHASH_IV_0_FLOW_HASH_IV_OFFS		0
+
+/* FHASH_IV_1 */
+#define MV_EIP197_FHASH_IV_1_REG					(0x002f68c4)
+#define MV_EIP197_FHASH_IV_1_FLOW_HASH_IV_OFFS		0
+
+/* FHASH_IV_2 */
+#define MV_EIP197_FHASH_IV_2_REG					(0x002f68c8)
+#define MV_EIP197_FHASH_IV_2_FLOW_HASH_IV_OFFS		0
+
+/* FHASH_IV_3 */
+#define MV_EIP197_FHASH_IV_3_REG					(0x002f68cc)
+#define MV_EIP197_FHASH_IV_3_FLOW_HASH_IV_OFFS		0
+
+/* CS_AIC_POL_CTRL */
+#define MV_EIP197_CS_AIC_POL_CTRL_REG					(0x002f7800)
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS		0
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_0_OFFS)
+
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS		1
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_1_OFFS)
+
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS		2
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_2_OFFS)
+
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS		3
+#define MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_POL_CTRL_POLARITY_CTRL_3_OFFS)
+
+
+/* CS_AIC_TYPE_CTRL */
+#define MV_EIP197_CS_AIC_TYPE_CTRL_REG					(0x002f7804)
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS		0
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_0_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_0_OFFS)
+
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS		1
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_1_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_1_OFFS)
+
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS		2
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_2_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_2_OFFS)
+
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS		3
+#define MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_3_MASK    \
+		(0x00000001 << MV_EIP197_CS_AIC_TYPE_CTRL_TYPE_CTRL_3_OFFS)
+
+
+/* CS_AIC_ENABLE_CTRL */
+#define MV_EIP197_CS_AIC_ENABLE_CTRL_REG					(0x002f7808)
+#define MV_EIP197_CS_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS		0
+#define MV_EIP197_CS_AIC_ENABLE_CTRL_ENABLE_CTRL_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_ENABLE_CTRL_ENABLE_CTRL_OFFS)
+
+
+/* CS_AIC_RAW_STAT */
+#define MV_EIP197_CS_AIC_RAW_STAT_REG					(0x002f780c)
+#define MV_EIP197_CS_AIC_RAW_STAT_RAW_STATUS_OFFS		0
+#define MV_EIP197_CS_AIC_RAW_STAT_RAW_STATUS_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_RAW_STAT_RAW_STATUS_OFFS)
+
+
+/* CS_AIC_ENABLED_STAT */
+#define MV_EIP197_CS_AIC_ENABLED_STAT_REG					(0x002f7810)
+#define MV_EIP197_CS_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS		0
+#define MV_EIP197_CS_AIC_ENABLED_STAT_ENABLED_STATUS_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_ENABLED_STAT_ENABLED_STATUS_OFFS)
+
+
+/* CS_AIC_ENABLE_CLR */
+#define MV_EIP197_CS_AIC_ENABLE_CLR_REG					(0x002f7814)
+#define MV_EIP197_CS_AIC_ENABLE_CLR_ENABLE_CLR_OFFS		0
+#define MV_EIP197_CS_AIC_ENABLE_CLR_ENABLE_CLR_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_ENABLE_CLR_ENABLE_CLR_OFFS)
+
+
+/* CS_AIC_OPTIONS */
+#define MV_EIP197_CS_AIC_OPTIONS_REG					(0x002f7818)
+#define MV_EIP197_CS_AIC_OPTIONS_NR_OF_INPUTS_OFFS		0
+#define MV_EIP197_CS_AIC_OPTIONS_NR_OF_INPUTS_MASK    \
+		(0x0000003f << MV_EIP197_CS_AIC_OPTIONS_NR_OF_INPUTS_OFFS)
+
+
+/* CS_AIC_VERSION */
+#define MV_EIP197_CS_AIC_VERSION_REG					(0x002f781c)
+#define MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_CS_AIC_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_CS_AIC_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_CS_AIC_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_CS_AIC_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_CS_AIC_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_CS_AIC_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_CS_AIC_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_CS_AIC_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* CS_RAM_CTRL */
+#define MV_EIP197_CS_RAM_CTRL_REG					(0x002f7ff0)
+#define MV_EIP197_CS_RAM_CTRL_FRC_EN_0_OFFS		0
+#define MV_EIP197_CS_RAM_CTRL_FRC_EN_0_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_FRC_EN_0_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_TRC_EN_0_OFFS		4
+#define MV_EIP197_CS_RAM_CTRL_TRC_EN_0_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_TRC_EN_0_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_OFFS		16
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_MASK    \
+		(0x00000003 << MV_EIP197_CS_RAM_CTRL_DEBUG_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_EN_OFFS		22
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_EN_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_DEBUG_EN_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_DIS_OFFS		23
+#define MV_EIP197_CS_RAM_CTRL_DEBUG_DIS_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_DEBUG_DIS_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_UNLOCK_OFFS		24
+#define MV_EIP197_CS_RAM_CTRL_UNLOCK_MASK    \
+		(0x00000003 << MV_EIP197_CS_RAM_CTRL_UNLOCK_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_SOFT_LOCK_OFFS		30
+#define MV_EIP197_CS_RAM_CTRL_SOFT_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_SOFT_LOCK_OFFS)
+
+#define MV_EIP197_CS_RAM_CTRL_HARD_LOCK_OFFS		31
+#define MV_EIP197_CS_RAM_CTRL_HARD_LOCK_MASK    \
+		(0x00000001 << MV_EIP197_CS_RAM_CTRL_HARD_LOCK_OFFS)
+
+
+/* CS_OPTIONS */
+#define MV_EIP197_CS_OPTIONS_REG					(0x002f7ff8)
+#define MV_EIP197_CS_OPTIONS_SUPPORT_CONFIG_OFFS		0
+#define MV_EIP197_CS_OPTIONS_SUPPORT_CONFIG_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_SUPPORT_CONFIG_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_CACHE_SETS_OFFS		1
+#define MV_EIP197_CS_OPTIONS_CACHE_SETS_MASK    \
+		(0x00000003 << MV_EIP197_CS_OPTIONS_CACHE_SETS_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_FRC_CLIENTS_OFFS		3
+#define MV_EIP197_CS_OPTIONS_FRC_CLIENTS_MASK    \
+		(0x0000001f << MV_EIP197_CS_OPTIONS_FRC_CLIENTS_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_TRC_CLIENTS_OFFS		8
+#define MV_EIP197_CS_OPTIONS_TRC_CLIENTS_MASK    \
+		(0x0000001f << MV_EIP197_CS_OPTIONS_TRC_CLIENTS_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_TRC_FRC_COMBO_OFFS		13
+#define MV_EIP197_CS_OPTIONS_TRC_FRC_COMBO_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_TRC_FRC_COMBO_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_ARC4_CLIENTS_OFFS		14
+#define MV_EIP197_CS_OPTIONS_ARC4_CLIENTS_MASK    \
+		(0x0000001f << MV_EIP197_CS_OPTIONS_ARC4_CLIENTS_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_ARC4_PRESENT_OFFS		19
+#define MV_EIP197_CS_OPTIONS_ARC4_PRESENT_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_ARC4_PRESENT_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_ARC4_FRC_COMBO_OFFS		20
+#define MV_EIP197_CS_OPTIONS_ARC4_FRC_COMBO_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_ARC4_FRC_COMBO_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_ARC4_TRC_COMBO_OFFS		21
+#define MV_EIP197_CS_OPTIONS_ARC4_TRC_COMBO_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_ARC4_TRC_COMBO_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_LOOKUP_CLIENTS_OFFS		22
+#define MV_EIP197_CS_OPTIONS_LOOKUP_CLIENTS_MASK    \
+		(0x0000001f << MV_EIP197_CS_OPTIONS_LOOKUP_CLIENTS_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_LOOKUP_CACHED_OFFS		27
+#define MV_EIP197_CS_OPTIONS_LOOKUP_CACHED_MASK    \
+		(0x00000001 << MV_EIP197_CS_OPTIONS_LOOKUP_CACHED_OFFS)
+
+#define MV_EIP197_CS_OPTIONS_LOOKUP_S_OFFS		28
+#define MV_EIP197_CS_OPTIONS_LOOKUP_S_MASK    \
+		(0x00000007 << MV_EIP197_CS_OPTIONS_LOOKUP_S_OFFS)
+
+
+/* CS_VERSION */
+#define MV_EIP197_CS_VERSION_REG					(0x002f7ffc)
+#define MV_EIP197_CS_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_CS_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_CS_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_CS_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_CS_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_CS_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_CS_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_CS_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_CS_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_CS_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_CS_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_CS_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_CS_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_CS_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_CS_VERSION_MAJOR_VERSION_OFFS)
+
+
+/* EIP197_DBG_PIPE_COUNT_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_COUNT_0_REG					(0x002ffc00)
+#define MV_EIP197_EIP197_DBG_PIPE_COUNT_0_TOTAL_PKTS_LO_OFFS		0
+
+/* EIP197_DBG_PIPE_STATE_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_REG					(0x002ffc04)
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_TOTAL_PKTS_HI_OFFS		0
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_TOTAL_PKTS_HI_MASK    \
+		(0x0000ffff << MV_EIP197_EIP197_DBG_PIPE_STATE_0_TOTAL_PKTS_HI_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_CUR_PKTS_OFFS		16
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_CUR_PKTS_MASK    \
+		(0x000000ff << MV_EIP197_EIP197_DBG_PIPE_STATE_0_CUR_PKTS_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_MAX_PKTS_OFFS		24
+#define MV_EIP197_EIP197_DBG_PIPE_STATE_0_MAX_PKTS_MASK    \
+		(0x000000ff << MV_EIP197_EIP197_DBG_PIPE_STATE_0_MAX_PKTS_OFFS)
+
+
+/* EIP197_DBG_PIPE_DCOUNT_LO_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_DCOUNT_LO_0_REG					(0x002ffc08)
+#define MV_EIP197_EIP197_DBG_PIPE_DCOUNT_LO_0_TOTAL_DWORDS_LO_OFFS		0
+
+/* EIP197_DBG_PIPE_DCOUNT_HI_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_DCOUNT_HI_0_REG					(0x002ffc0c)
+#define MV_EIP197_EIP197_DBG_PIPE_DCOUNT_HI_0_TOTAL_DWORDS_HI_OFFS		0
+
+/* EIP197_DBG_PIPE_PEND_SEQ_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_REG					(0x002ffe00)
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_SEQ_OFFS		0
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_SEQ_MASK    \
+		(0x00000fff << MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_SEQ_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_RING_OFFS		12
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_RING_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_PKT_DEST_RING_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_SEQ_OFFS		16
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_SEQ_MASK    \
+		(0x00000fff << MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_SEQ_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_RING_OFFS		28
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_RING_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DBG_PIPE_PEND_SEQ_0_TOK_DEST_RING_OFFS)
+
+
+/* EIP197_DBG_PIPE_PEND_LEN_0 */
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_REG					(0x002ffe04)
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_OFFS		0
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_MASK    \
+		(0x0000ffff << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_LENGTH_OFFS		16
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_LENGTH_MASK    \
+		(0x000000ff << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_LENGTH_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_AVAIL_OFFS		28
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_AVAIL_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_TOK_AVAIL_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MIN_OFFS		29
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MIN_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MIN_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MAX_OFFS		30
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MAX_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_AVAIL_MAX_OFFS)
+
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_AV_OFFS		31
+#define MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_AV_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_DBG_PIPE_PEND_LEN_0_PKT_LENGTH_AV_OFFS)
+
+
+/* EIP197_DEBUG_SELECT_0 */
+#define MV_EIP197_EIP197_DEBUG_SELECT_0_REG					(0x002fff80)
+#define MV_EIP197_EIP197_DEBUG_SELECT_0_INPUT_SEL_OFFS		0
+#define MV_EIP197_EIP197_DEBUG_SELECT_0_INPUT_SEL_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DEBUG_SELECT_0_INPUT_SEL_OFFS)
+
+
+/* EIP197_DEBUG_SELECT_1 */
+#define MV_EIP197_EIP197_DEBUG_SELECT_1_REG					(0x002fff84)
+#define MV_EIP197_EIP197_DEBUG_SELECT_1_INPUT_SEL_OFFS		0
+#define MV_EIP197_EIP197_DEBUG_SELECT_1_INPUT_SEL_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DEBUG_SELECT_1_INPUT_SEL_OFFS)
+
+
+/* EIP197_DEBUG_SELECT_2 */
+#define MV_EIP197_EIP197_DEBUG_SELECT_2_REG					(0x002fff88)
+#define MV_EIP197_EIP197_DEBUG_SELECT_2_INPUT_SEL_OFFS		0
+#define MV_EIP197_EIP197_DEBUG_SELECT_2_INPUT_SEL_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DEBUG_SELECT_2_INPUT_SEL_OFFS)
+
+
+/* EIP197_DEBUG_SELECT_3 */
+#define MV_EIP197_EIP197_DEBUG_SELECT_3_REG					(0x002fff8c)
+#define MV_EIP197_EIP197_DEBUG_SELECT_3_INPUT_SEL_OFFS		0
+#define MV_EIP197_EIP197_DEBUG_SELECT_3_INPUT_SEL_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_DEBUG_SELECT_3_INPUT_SEL_OFFS)
+
+
+/* EIP197_DEBUG_PROBE_0 */
+#define MV_EIP197_EIP197_DEBUG_PROBE_0_REG					(0x002fffa0)
+#define MV_EIP197_EIP197_DEBUG_PROBE_0_PROBE_OUT_OFFS		0
+
+/* EIP197_DEBUG_PROBE_1 */
+#define MV_EIP197_EIP197_DEBUG_PROBE_1_REG					(0x002fffa4)
+#define MV_EIP197_EIP197_DEBUG_PROBE_1_PROBE_OUT_OFFS		0
+
+/* EIP197_DEBUG_PROBE_2 */
+#define MV_EIP197_EIP197_DEBUG_PROBE_2_REG					(0x002fffa8)
+#define MV_EIP197_EIP197_DEBUG_PROBE_2_PROBE_OUT_OFFS		0
+
+/* EIP197_DEBUG_PROBE_3 */
+#define MV_EIP197_EIP197_DEBUG_PROBE_3_REG					(0x002fffac)
+#define MV_EIP197_EIP197_DEBUG_PROBE_3_PROBE_OUT_OFFS		0
+
+/* EIP197_CLOCK_STATE */
+#define MV_EIP197_EIP197_CLOCK_STATE_REG					(0x002fffe4)
+#define MV_EIP197_EIP197_CLOCK_STATE_DMA_RD_CLK_OFFS		0
+#define MV_EIP197_EIP197_CLOCK_STATE_DMA_RD_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DMA_RD_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_DFE_CLK_OFFS		1
+#define MV_EIP197_EIP197_CLOCK_STATE_DFE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DFE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_DSE_CLK_OFFS		2
+#define MV_EIP197_EIP197_CLOCK_STATE_DSE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DSE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_CDR_CLK_OFFS		3
+#define MV_EIP197_EIP197_CLOCK_STATE_CDR_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_CDR_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_RDR_CLK_OFFS		4
+#define MV_EIP197_EIP197_CLOCK_STATE_RDR_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_RDR_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_SUPP_CLK_OFFS		5
+#define MV_EIP197_EIP197_CLOCK_STATE_SUPP_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_SUPP_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_DMA_WR_CLK_OFFS		6
+#define MV_EIP197_EIP197_CLOCK_STATE_DMA_WR_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DMA_WR_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_PE_CLK_OFFS		8
+#define MV_EIP197_EIP197_CLOCK_STATE_PE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_PE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_CORE_CLK_OFFS		9
+#define MV_EIP197_EIP197_CLOCK_STATE_CORE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_CORE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_IPUE_CLK_OFFS		10
+#define MV_EIP197_EIP197_CLOCK_STATE_IPUE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_IPUE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_IFPP_CLK_OFFS		11
+#define MV_EIP197_EIP197_CLOCK_STATE_IFPP_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_IFPP_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_FLUE_CLK_OFFS		15
+#define MV_EIP197_EIP197_CLOCK_STATE_FLUE_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_FLUE_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_AES_CLK_OFFS		16
+#define MV_EIP197_EIP197_CLOCK_STATE_AES_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_AES_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_DES_CLK_OFFS		17
+#define MV_EIP197_EIP197_CLOCK_STATE_DES_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DES_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_ARC4_CLK_OFFS		18
+#define MV_EIP197_EIP197_CLOCK_STATE_ARC4_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_ARC4_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_HASH_CLK_OFFS		19
+#define MV_EIP197_EIP197_CLOCK_STATE_HASH_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_HASH_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_SHA1_CLK_OFFS		20
+#define MV_EIP197_EIP197_CLOCK_STATE_SHA1_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_SHA1_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_GHASH_CLK_OFFS		21
+#define MV_EIP197_EIP197_CLOCK_STATE_GHASH_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_GHASH_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_AESXCBC_CLK_OFFS		22
+#define MV_EIP197_EIP197_CLOCK_STATE_AESXCBC_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_AESXCBC_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_DBG_CLK_OFFS		27
+#define MV_EIP197_EIP197_CLOCK_STATE_DBG_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_DBG_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_FRC_CLK_OFFS		28
+#define MV_EIP197_EIP197_CLOCK_STATE_FRC_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_FRC_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_TRC_CLK_OFFS		29
+#define MV_EIP197_EIP197_CLOCK_STATE_TRC_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_TRC_CLK_OFFS)
+
+#define MV_EIP197_EIP197_CLOCK_STATE_CRC_CLK_OFFS		31
+#define MV_EIP197_EIP197_CLOCK_STATE_CRC_CLK_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_CLOCK_STATE_CRC_CLK_OFFS)
+
+
+/* EIP197_FORCE_CLOCK_ON */
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_REG					(0x002fffe8)
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_RD_CLK_ON_OFFS		0
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_RD_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_RD_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DFE_CLK_ON_OFFS		1
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DFE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DFE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DSE_CLK_ON_OFFS		2
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DSE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DSE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CDR_CLK_ON_OFFS		3
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CDR_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_CDR_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RDR_CLK_ON_OFFS		4
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RDR_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RDR_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_SUPP_CLK_ON_OFFS		5
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_SUPP_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_SUPP_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_WR_CLK_ON_OFFS		6
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_WR_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DMA_WR_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_7_OFFS		7
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_7_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_7_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_PE_CLK_ON_OFFS		8
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_PE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_PE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CORE_CLK_ON_OFFS		9
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CORE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_CORE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_IPUE_CLK_ON_OFFS		10
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_IPUE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_IPUE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_IFPP_CLK_ON_OFFS		11
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_IFPP_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_IFPP_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_14_12_OFFS		12
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_14_12_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_14_12_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_FLUE_CLK_ON_OFFS		15
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_FLUE_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_FLUE_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_AES_CLK_ON_OFFS		16
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_AES_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_AES_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DES_CLK_ON_OFFS		17
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DES_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DES_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_ARC4_CLK_ON_OFFS		18
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_ARC4_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_ARC4_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_HASH_CLK_ON_OFFS		19
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_HASH_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_HASH_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_SHA1_CLK_ON_OFFS		20
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_SHA1_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_SHA1_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_GHASH_CLK_ON_OFFS		21
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_GHASH_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_GHASH_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_AESXCBC_CLK_ON_OFFS		22
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_AESXCBC_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_AESXCBC_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_24_23_OFFS		23
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_24_23_MASK    \
+		(0x00000003 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_24_23_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_25_OFFS		25
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_25_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_25_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_26_OFFS		26
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_26_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_26_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DBG_CLK_ON_OFFS		27
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_DBG_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_DBG_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_FRC_CLK_ON_OFFS		28
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_FRC_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_FRC_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_TRC_CLK_ON_OFFS		29
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_TRC_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_TRC_CLK_ON_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_30_OFFS		30
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_30_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_RESERVED_30_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CRC_CLK_ON_OFFS		31
+#define MV_EIP197_EIP197_FORCE_CLOCK_ON_CRC_CLK_ON_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_ON_CRC_CLK_ON_OFFS)
+
+
+/* EIP197_FORCE_CLOCK_OFF */
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_REG					(0x002fffec)
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_RD_CLK_OFF_OFFS		0
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_RD_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_RD_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DFE_CLK_OFF_OFFS		1
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DFE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DFE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DSE_CLK_OFF_OFFS		2
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DSE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DSE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CDR_CLK_OFF_OFFS		3
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CDR_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_CDR_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RDR_CLK_OFF_OFFS		4
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RDR_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RDR_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_SUPP_CLK_OFF_OFFS		5
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_SUPP_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_SUPP_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_WR_CLK_OFF_OFFS		6
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_WR_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DMA_WR_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_7_OFFS		7
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_7_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_7_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_PE_CLK_OFF_OFFS		8
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_PE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_PE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CORE_CLK_OFF_OFFS		9
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CORE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_CORE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_IPUE_CLK_OFF_OFFS		10
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_IPUE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_IPUE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_IFPP_CLK_OFF_OFFS		11
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_IFPP_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_IFPP_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_14_12_OFFS		12
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_14_12_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_14_12_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_FLUE_CLK_OFF_OFFS		15
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_FLUE_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_FLUE_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_AES_CLK_OFF_OFFS		16
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_AES_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_AES_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DES_CLK_OFF_OFFS		17
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DES_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DES_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_ARC4_CLK_OFF_OFFS		18
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_ARC4_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_ARC4_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_HASH_CLK_OFF_OFFS		19
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_HASH_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_HASH_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_SHA1_CLK_OFF_OFFS		20
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_SHA1_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_SHA1_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_GHASH_CLK_OFF_OFFS		21
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_GHASH_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_GHASH_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_AESXCBC_CLK_OFF_OFFS		22
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_AESXCBC_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_AESXCBC_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_24_23_OFFS		23
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_24_23_MASK    \
+		(0x00000003 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_24_23_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_25_OFFS		25
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_25_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_25_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_26_OFFS		26
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_26_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_26_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DBG_CLK_OFF_OFFS		27
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_DBG_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_DBG_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_FRC_CLK_OFF_OFFS		28
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_FRC_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_FRC_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_TRC_CLK_OFF_OFFS		29
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_TRC_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_TRC_CLK_OFF_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_30_OFFS		30
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_30_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_RESERVED_30_OFFS)
+
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CRC_CLK_OFF_OFFS		31
+#define MV_EIP197_EIP197_FORCE_CLOCK_OFF_CRC_CLK_OFF_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_FORCE_CLOCK_OFF_CRC_CLK_OFF_OFFS)
+
+
+/* EIP197_MST_CTRL */
+#define MV_EIP197_EIP197_MST_CTRL_REG					(0x002ffff4)
+#define MV_EIP197_EIP197_MST_CTRL_RD_CACHE_OFFS		0
+#define MV_EIP197_EIP197_MST_CTRL_RD_CACHE_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_MST_CTRL_RD_CACHE_OFFS)
+
+#define MV_EIP197_EIP197_MST_CTRL_WR_CACHE_OFFS		4
+#define MV_EIP197_EIP197_MST_CTRL_WR_CACHE_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_MST_CTRL_WR_CACHE_OFFS)
+
+#define MV_EIP197_EIP197_MST_CTRL_SUPPORT_SWAP_OFFS		8
+#define MV_EIP197_EIP197_MST_CTRL_SUPPORT_SWAP_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_MST_CTRL_SUPPORT_SWAP_OFFS)
+
+#define MV_EIP197_EIP197_MST_CTRL_SUPPORT_PROTECTION_OFFS		12
+#define MV_EIP197_EIP197_MST_CTRL_SUPPORT_PROTECTION_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_MST_CTRL_SUPPORT_PROTECTION_OFFS)
+
+
+/* EIP197_OPTIONS */
+#define MV_EIP197_EIP197_OPTIONS_REG					(0x002ffff8)
+#define MV_EIP197_EIP197_OPTIONS_NR_OF_PES_OFFS		0
+#define MV_EIP197_EIP197_OPTIONS_NR_OF_PES_MASK    \
+		(0x0000001f << MV_EIP197_EIP197_OPTIONS_NR_OF_PES_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_IN_TBUF_SIZE_OFFS		6
+#define MV_EIP197_EIP197_OPTIONS_IN_TBUF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_OPTIONS_IN_TBUF_SIZE_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_IN_DBUF_SIZE_OFFS		9
+#define MV_EIP197_EIP197_OPTIONS_IN_DBUF_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_OPTIONS_IN_DBUF_SIZE_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_OUT_TBUF_SIZE_OFFS		13
+#define MV_EIP197_EIP197_OPTIONS_OUT_TBUF_SIZE_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_OPTIONS_OUT_TBUF_SIZE_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_OUT_DBUF_SIZE_OFFS		16
+#define MV_EIP197_EIP197_OPTIONS_OUT_DBUF_SIZE_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_OPTIONS_OUT_DBUF_SIZE_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_MAC_CHANNELS_OFFS		20
+#define MV_EIP197_EIP197_OPTIONS_MAC_CHANNELS_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_OPTIONS_MAC_CHANNELS_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_MAC_DEMUX_CONFIG_OFFS		24
+#define MV_EIP197_EIP197_OPTIONS_MAC_DEMUX_CONFIG_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_OPTIONS_MAC_DEMUX_CONFIG_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_MAC_ARBITER_CONFIG_OFFS		27
+#define MV_EIP197_EIP197_OPTIONS_MAC_ARBITER_CONFIG_MASK    \
+		(0x00000007 << MV_EIP197_EIP197_OPTIONS_MAC_ARBITER_CONFIG_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_TG_OFFS		30
+#define MV_EIP197_EIP197_OPTIONS_TG_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_OPTIONS_TG_OFFS)
+
+#define MV_EIP197_EIP197_OPTIONS_TRC_OFFS		31
+#define MV_EIP197_EIP197_OPTIONS_TRC_MASK    \
+		(0x00000001 << MV_EIP197_EIP197_OPTIONS_TRC_OFFS)
+
+
+/* EIP197_VERSION */
+#define MV_EIP197_EIP197_VERSION_REG					(0x002ffffc)
+#define MV_EIP197_EIP197_VERSION_EIP_NUMBER_OFFS		0
+#define MV_EIP197_EIP197_VERSION_EIP_NUMBER_MASK    \
+		(0x000000ff << MV_EIP197_EIP197_VERSION_EIP_NUMBER_OFFS)
+
+#define MV_EIP197_EIP197_VERSION_EIP_NUMBER_COMPL_OFFS		8
+#define MV_EIP197_EIP197_VERSION_EIP_NUMBER_COMPL_MASK    \
+		(0x000000ff << MV_EIP197_EIP197_VERSION_EIP_NUMBER_COMPL_OFFS)
+
+#define MV_EIP197_EIP197_VERSION_PATCH_LEVEL_OFFS		16
+#define MV_EIP197_EIP197_VERSION_PATCH_LEVEL_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_VERSION_PATCH_LEVEL_OFFS)
+
+#define MV_EIP197_EIP197_VERSION_MINOR_VERSION_OFFS		20
+#define MV_EIP197_EIP197_VERSION_MINOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_VERSION_MINOR_VERSION_OFFS)
+
+#define MV_EIP197_EIP197_VERSION_MAJOR_VERSION_OFFS		24
+#define MV_EIP197_EIP197_VERSION_MAJOR_VERSION_MASK    \
+		(0x0000000f << MV_EIP197_EIP197_VERSION_MAJOR_VERSION_OFFS)
+
+/* RAMs */
+#define MV_EIP197_PE_0_ICE_SCRATCH_RAM					(0x002A0800)
+#define MV_EIP197_IES_AXI_MRVL_CLASSIF_RAM_ACCESS_SPACE			(0x002E0000)
+
+#endif /* __mv_eip197_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_common.c b/drivers/net/ethernet/marvell/pp3/common/mv_common.c
new file mode 100644
index 0000000..322f9f2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_common.c
@@ -0,0 +1,332 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "mv_sw_if.h"
+
+int mv_pp3_max_check(int value, int limit, char *name)
+{
+	if ((value < 0) || (value >= limit)) {
+		pr_err("%s %d is out of range [0..%d]\n",
+			name ? name : "value", value, (limit - 1));
+		return 1;
+	}
+	return 0;
+}
+
+const char *mv_pp3_pkt_mode_str(enum mv_pp3_pkt_mode mode)
+{
+	const char *pkt_mode_str;
+
+	switch (mode) {
+	case MV_PP3_PKT_DRAM:
+		pkt_mode_str = "DRAM     ";
+		break;
+
+	case MV_PP3_PKT_CFH:
+		pkt_mode_str = "CFH      ";
+		break;
+	default:
+		pkt_mode_str = "Unknown  ";
+	}
+	return pkt_mode_str;
+}
+
+const char *mv_hash_type_str(enum mv_hash_type hash)
+{
+	const char *hash_str;
+
+	switch (hash) {
+	case MV_HASH_NONE:
+		hash_str = "None     ";
+		break;
+	case MV_HASH_SA:      /* MAC SA */
+		hash_str = "MAC_SA   ";
+		break;
+	case MV_HASH_2_TUPLE: /* SIP + DIP */
+		hash_str = "2-tuples ";
+		break;
+	case MV_HASH_4_TUPLE: /* SIP + DIP + SPort + DPort */
+		hash_str = "4-tuples ";
+		break;
+	default:
+		hash_str = "Unknown  ";
+	}
+	return hash_str;
+}
+
+const char *mv_port_mode_str(enum mv_port_mode mode)
+{
+	const char *mode_str;
+
+	switch (mode) {
+	case MV_PORT_RXAUI:
+		mode_str = "RXAUI    ";
+		break;
+	case MV_PORT_XAUI:
+		mode_str = "XAUI     ";
+		break;
+	case MV_PORT_SGMII:
+		mode_str = "SGMII    ";
+		break;
+	case MV_PORT_SGMII2_5:
+		mode_str = "SGMII_2.5";
+		break;
+	case MV_PORT_QSGMII:
+		mode_str = "QSGMII   ";
+		break;
+	case MV_PORT_RGMII:
+		mode_str = "RGMII    ";
+		break;
+	default:
+		mode_str = "Unknown  ";
+	}
+	return mode_str;
+}
+
+void mv_link_to_str(struct mv_port_link_status status, char *str)
+{
+	char *speed_str;
+	char *duplex_str;
+
+	if (!status.linkup) {
+		sprintf(str, "Link is Down");
+		return;
+	}
+
+	/* update speed string */
+	switch (status.speed) {
+	case MV_PORT_SPEED_10:
+		speed_str = "10";
+		break;
+	case MV_PORT_SPEED_100:
+		speed_str = "100";
+		break;
+	case MV_PORT_SPEED_1000:
+		speed_str = "1000";
+		break;
+	case MV_PORT_SPEED_2000:
+		speed_str = "2500";
+		break;
+	case MV_PORT_SPEED_10000:
+		speed_str = "10000";
+		break;
+	default:
+		speed_str = "unknown speed";
+	}
+	/* update duplex string */
+	switch (status.duplex) {
+	case MV_PORT_DUPLEX_HALF:
+		duplex_str = "Half";
+		break;
+	case MV_PORT_DUPLEX_FULL:
+		duplex_str = "Full";
+		break;
+	default:
+		duplex_str = "unknown";
+	}
+
+	sprintf(str, "Link is Up %s Mbps %s Duplex\n", speed_str, duplex_str);
+}
+/*
+Description:
+	Dump memory in specific format:
+	address: X1X1X1X1 X2X2X2X2 ... X8X8X8X8
+Inputs :
+	addr - buffer address
+	size - num of bytes to dump
+	access - width of read access
+*/
+
+void mv_debug_mem_dump(void *addr, int size, int access)
+{
+	int i, j;
+	u32 mem_addr = (u32) addr;
+
+	if (access == 0)
+		access = 1;
+
+	if ((access != 4) && (access != 2) && (access != 1)) {
+		pr_info("%d wrong access size. Access must be 1 or 2 or 4\n", access);
+		return;
+	}
+
+	mem_addr = MV_ALIGN_DOWN((unsigned int)addr, 4);
+	size = MV_ALIGN_UP(size, 4);
+	addr = (void *)MV_ALIGN_DOWN((unsigned int)addr, access);
+	while (size > 0) {
+		pr_info("%08x: ", mem_addr);
+		i = 0;
+		/* 32 bytes in the line */
+		while (i < 32) {
+			if (mem_addr >= (u32) addr) {
+				switch (access) {
+				case 1:
+					pr_cont("%02x ", ((*((unsigned char *)(mem_addr)))));
+					break;
+
+				case 2:
+					pr_cont("%04x ", ((*((unsigned short *)(mem_addr)))));
+					break;
+
+				case 4:
+					pr_cont("%08x ", ((*((unsigned int *)(mem_addr)))));
+					break;
+				}
+			} else {
+				for (j = 0; j < (access * 2 + 1); j++)
+					pr_cont(" ");
+			}
+			i += access;
+			mem_addr += access;
+			size -= access;
+			if (size <= 0)
+				break;
+		}
+	}
+	pr_cont("\n");
+}
+
+
+/*
+Description:
+	Allocate number of memory buffers of request size.
+Inputs:
+	size - buffer size in bytes
+	buf_num - number of buffers to allocate
+	buff - pointer to array of buffers pointers
+Return:
+	true on success
+	false on fail
+*/
+static bool mv_bufs_alloc(int buf_num, int size, unsigned int *buff)
+{
+	int i, j;
+
+	for (i = 0; i < buf_num; i++) {
+		buff[i] = (unsigned int) kzalloc(size, GFP_KERNEL);
+		if (buff[i] == 0)
+			break;
+	}
+	if (i < buf_num) {
+		/* error through allocation */
+		for (j = 0 ; j < i; j++)
+			kfree((unsigned int *)buff[j]);
+		return false;
+	}
+	return true;
+}
+
+/*
+Description:
+	Allocate memory buffer of request size.
+	If there is no one buffer of requested size, try to allocate smaller buffers.
+	Start from 2 buffers and continue with power of 2 buffers number.
+	Stop if buffers size goes less than linux PAGE_SIZE.
+Inputs:
+	req_size - buffer size in kbytes
+	max_bufs_num - max number of buffers to allocate
+	buff - pointer to array of buffers pointers
+Return:
+	number of allocated buffers or
+	0 for fail
+*/
+int mv_memory_buffer_alloc(unsigned int req_size, int max_bufs_num, unsigned int *buff)
+{
+	unsigned int cur_size, buf_num;
+
+	/* cur_size in bytes */
+	cur_size = req_size * 1024;
+	buf_num = 1;
+
+	while (buf_num <= max_bufs_num) {
+
+		/* cur_size aligned to PAGE_SIZE */
+		cur_size = MV_ALIGN_UP(cur_size, PAGE_SIZE);
+		if (mv_bufs_alloc(buf_num, cur_size, buff))
+			return buf_num;
+
+		cur_size = cur_size / 2;
+		if (cur_size < PAGE_SIZE)
+			/* min buffer size is linux page size  (4KB) */
+			return 0;
+
+		buf_num = buf_num * 2;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_memory_buffer_alloc);
+
+/*
+Description:
+ read field from entry
+ requested filed cannot cross words in the entry
+Inputs:
+	offs  - field start offset in bits
+	bits  - field size in bits
+	entry - entry memory
+return:
+	field value
+*/
+
+unsigned int mv_field_get(int offs, int bits,  unsigned int *entry)
+{
+	int word, offs_in_word;
+	unsigned int maks = (1 << bits) - 1;
+
+	word = offs / 32;
+	offs_in_word = (offs % 32);
+
+	return (entry[word] >> offs_in_word) & maks;
+}
+/*
+Description:
+ write field to entry
+ filed cannot cross words in the entry
+Inputs:
+	offs  - field start offset in bits
+	bits  - field size in bits
+	entry - entry memory
+	val - field value
+return:
+	void
+*/
+
+void mv_field_set(int offs, int bits, unsigned int *entry,  unsigned int val)
+{
+	int word, offs_in_word;
+	unsigned int maks = (1 << bits) - 1;
+
+	word = offs / 32;
+	offs_in_word = (offs % 32);
+
+	/* clear field */
+	entry[word] &= ~(maks << offs_in_word);
+	/* set new field */
+	entry[word] |= (val << offs_in_word);
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h b/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
new file mode 100644
index 0000000..f965fde
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
@@ -0,0 +1,117 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_hw_if_h__
+#define __mv_hw_if_h__
+
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include "coherency.h"
+
+/*
+	access_addr - absolute address: Silicon base + unit base + table base + entry offset
+	words_num   - number of words (word = 32 bits) to read
+	data_ptr    - pointer to an array containing the read data
+*/
+static inline void mv_pp3_hw_read(void __iomem *access_addr, int words_num, u32 *data_ptr)
+{
+	int i;
+
+	for (i = 0; i < words_num; i++)
+		data_ptr[i] = readl(access_addr + (4 * i));
+}
+
+/*
+	access_addr - absolute address: Silicon base + unit base + table base + entry offset
+	words_num   - number of words (word = 32 bits) to write
+	data_ptr    - pointer to an array containing the write data
+*/
+static inline void mv_pp3_hw_write(void __iomem *access_addr, int words_num, u32 *data_ptr)
+{
+	int i;
+
+	for (i = 0; i < words_num; i++)
+		writel(data_ptr[i], access_addr + (4 * i));
+
+	/* WA for MBUS issue occurs when read interrupts multiple write transactions */
+	/* Occurs for write tables with line width more than 32 bits */
+	if (words_num > 1)
+		readl(access_addr + 4 * (words_num - 1));
+}
+
+/*
+	access_addr - absolute address: Silicon base + unit base + register offset
+	return register value
+*/
+static inline u32 mv_pp3_hw_reg_read(void __iomem *access_addr)
+{
+	return readl(access_addr);
+}
+
+/*
+	access_addr - absolute address: Silicon base + unit base + register offset
+	write data to register
+*/
+static inline void mv_pp3_hw_reg_write(void __iomem *access_addr, u32 data)
+{
+#ifdef PP3_DEBUG
+	pr_info("\nwrite reg %p, data 0x%x", access_addr, data);
+#endif
+	writel(data, access_addr);
+}
+
+/* Cache coherency functions */
+static inline void mv_pp3_os_cache_io_sync(void *handle)
+{
+	if (likely(coherency_available()))
+		dma_sync_single_for_cpu(handle, (dma_addr_t) NULL,
+			(size_t) NULL, DMA_FROM_DEVICE);
+}
+
+static inline dma_addr_t mv_pp3_os_dma_map_single(struct device *dev, void *addr, size_t size, int direction)
+{
+	if (unlikely(!coherency_available()))
+		return dma_map_single(dev, addr, size, direction);
+
+	return virt_to_phys(addr);
+}
+
+static inline dma_addr_t mv_pp3_os_dma_map_page(struct device *dev, struct page *page, int offset,
+						size_t size, int direction)
+{
+	if (unlikely(!coherency_available()))
+		return dma_map_page(dev, page, offset, size, direction);
+
+	return pfn_to_dma(dev, page_to_pfn(page)) + offset;
+}
+
+#endif /* __mv_hw_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_stack.c b/drivers/net/ethernet/marvell/pp3/common/mv_stack.c
new file mode 100644
index 0000000..2d9c1ef
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_stack.c
@@ -0,0 +1,80 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+/* includes */
+#include <linux/io.h>
+#include <linux/slab.h>
+#include "mv_stack.h"
+
+/* defines  */
+
+/* Public functions */
+
+/* Purpose: Create new stack
+ * Inputs:
+ *	- u32	num_of_elements	- maximum number of elements in the stack.
+ *                              Each element 4 bytes size
+ * Return: void* - pointer to created stack.
+ */
+void *mv_stack_create(int num_of_elements)
+{
+	struct  mv_stack *p_stack;
+	u32 *p_stack_elements;
+
+	p_stack = kmalloc(sizeof(struct mv_stack), GFP_KERNEL);
+	p_stack_elements = kmalloc(num_of_elements * sizeof(u32), GFP_KERNEL);
+	if ((p_stack == NULL) || (p_stack_elements == NULL)) {
+		pr_err("mvStack: Can't create new stack\n");
+		kfree(p_stack);
+		kfree(p_stack_elements);
+		return NULL;
+	}
+	memset(p_stack_elements, 0, num_of_elements * sizeof(u32));
+	p_stack->num_of_elements = num_of_elements;
+	p_stack->stack_idx = 0;
+	p_stack->stack_elements = p_stack_elements;
+
+	return p_stack;
+}
+
+/* Purpose: Delete existing stack
+ * Inputs:
+ *	- void*		stack_hndl	- Stack handle as returned by "mvStackCreate()" function
+ *
+ * Return: none.
+ */
+void mv_stack_delete(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	if ((p_stack == NULL) || (p_stack->stack_elements == NULL))
+		return;
+
+	kfree(p_stack->stack_elements);
+	kfree(p_stack);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_stack.h b/drivers/net/ethernet/marvell/pp3/common/mv_stack.h
new file mode 100644
index 0000000..e827db3
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_stack.h
@@ -0,0 +1,128 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_stack_h__
+#define __mv_stack_h__
+
+/* includes */
+#include <linux/kernel.h>
+
+
+/* LIFO Stack implementation */
+/* Data structure describes general purpose Stack */
+struct mv_stack {
+	int stack_idx;
+	int num_of_elements;
+	u32 *stack_elements;
+};
+
+static inline bool mv_stack_is_full(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	if (p_stack->stack_idx == p_stack->num_of_elements)
+		return true;
+
+	return false;
+}
+
+static inline bool mv_stack_is_empty(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	if (p_stack->stack_idx == 0)
+		return true;
+
+	return false;
+}
+
+/* Purpose: Push new element to stack
+ * Inputs:
+ *	- void*		stack_hndl	- Stack handle as returned by "mv_stack_create()" function.
+ *	- u32		value		- New element.
+ *
+ */
+static inline int mv_stack_push(void *stack_hndl, u32 value)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	if (p_stack->stack_idx == p_stack->num_of_elements) {
+		pr_info("%s: Stack is FULL\n", __func__);
+		return 0;
+	}
+
+	p_stack->stack_elements[p_stack->stack_idx] = value;
+	p_stack->stack_idx++;
+	return 1;
+}
+
+/* Purpose: Pop element from the top of stack and copy it to "p_value"
+ * Inputs:
+ *	- void*		stack_hndl	- Stack handle as returned by "mv_stack_create()" function.
+ *	- u32		value		- Element in the top of stack.
+ *
+ * Return: int		-1 - Failure. Stack is empty.
+ *					value - Success. Element is removed from the stack and
+ *							copied to pValue argument
+ */
+static inline int mv_stack_pop(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	if (p_stack->stack_idx == 0) {
+		pr_info("%s: Stack is EMPTY\n", __func__);
+		return -1;
+	}
+
+	p_stack->stack_idx--;
+	return p_stack->stack_elements[p_stack->stack_idx];
+}
+
+static inline int mv_stack_index(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	return p_stack->stack_idx;
+}
+
+static inline int mv_stack_free_elements(void *stack_hndl)
+{
+	struct mv_stack *p_stack = (struct mv_stack *) stack_hndl;
+
+	return p_stack->num_of_elements - p_stack->stack_idx;
+}
+
+/* mv_stack.h API list */
+
+/* Create new Stack */
+void *mv_stack_create(int num_of_elements);
+
+/* Delete existing stack */
+void mv_stack_delete(void *stack_hndl);
+
+#endif /* __mv_stack_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h b/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
new file mode 100644
index 0000000..ea63b3c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
@@ -0,0 +1,453 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_sw_if_h__
+#define __mv_sw_if_h__
+
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/errno.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/interrupt.h>
+#include <linux/if_vlan.h>
+#include <linux/platform_device.h>
+
+
+#define __ATTRIBUTE_PACKED__	__packed
+#define MV_MALLOC	kmalloc
+
+#define	MV_MAC_ADDR_SIZE	(6)
+#define MV_MAC_STR_SIZE		(20)
+#define MV_MH_SIZE		(2)
+#define MV_CRC_SIZE		(4)
+#define MV_DSCP_NUM		(64)
+
+#define MV_MTU_MIN		(68)
+/* Layer2 packet info EtherType + Double VLAN + MAC_SA + MAC_DA + Marvell header */
+#define MV_L2_HLEN		(MV_MH_SIZE + 2 * VLAN_HLEN + ETH_HLEN)
+
+/* MTU = MRU - MV_L2_SIZE */
+#define MV_MTU_MAX		((10 * 1024) - MV_L2_HLEN)
+#define MV_EXT_PORT_MTU		(7904)
+
+#define MV_MAC_IS_EQUAL(_mac1, _mac2)			\
+	(!memcmp((_mac1), (_mac2), MV_MAC_ADDR_SIZE))
+
+
+/* MTU + EtherType + Double VLAN + MAC_SA + MAC_DA + Marvell header */
+#define MV_MAX_PKT_SIZE(mtu)	((mtu) + MV_L2_HLEN)
+
+#define MV_RX_PKT_SIZE(mtu)	SKB_DATA_ALIGN(MV_MAX_PKT_SIZE(mtu) + ETH_FCS_LEN)
+
+
+#ifdef CONFIG_MV_PP3_STAT_ERR
+#define STAT_ERR(c) c
+#else
+#define STAT_ERR(c)
+#endif
+
+#ifdef CONFIG_MV_PP3_STAT_INF
+#define STAT_INFO(c) c
+#else
+#define STAT_INFO(c)
+#endif
+
+#ifdef CONFIG_MV_PP3_STAT_DBG
+#define STAT_DBG(c) c
+#else
+#define STAT_DBG(c)
+#endif
+
+/******************************************************
+ * interrupt control --                               *
+ ******************************************************/
+#define MV_TRYLOCK(lock, flags)                               \
+	(in_interrupt() ? spin_trylock((lock)) :              \
+		spin_trylock_irqsave((lock), (flags)))
+
+#define MV_LOCK(lock, flags)					\
+do {								\
+	if (in_interrupt())					\
+		spin_lock((lock));				\
+	else							\
+		spin_lock_irqsave((lock), (flags));		\
+} while (0)
+
+#define MV_UNLOCK(lock, flags)					\
+do {								\
+	if (in_interrupt())					\
+		spin_unlock((lock));				\
+	else							\
+		spin_unlock_irqrestore((lock), (flags));	\
+} while (0)
+
+#define MV_LIGHT_LOCK(flags)					\
+do {								\
+	if (!in_interrupt())					\
+		local_irq_save(flags);				\
+} while (0)
+
+#define MV_LIGHT_UNLOCK(flags)					\
+do {								\
+	if (!in_interrupt())					\
+		local_irq_restore(flags);			\
+} while (0)
+
+/* resource lock depend on usage - used by any cpu or dedicate to specific one */
+#define MV_RES_LOCK(share_res, lock, flags)	\
+do {						\
+	if (share_res)				\
+		MV_LOCK(lock, flags);		\
+	else					\
+		MV_LIGHT_LOCK(flags);		\
+} while (0)
+
+#define MV_RES_UNLOCK(share_res, lock, flags)	\
+do {						\
+	if (share_res)				\
+		MV_UNLOCK(lock, flags);		\
+	else					\
+		MV_LIGHT_UNLOCK(flags);		\
+} while (0)
+
+/******************************************************
+ * align memory allocateion                           *
+ ******************************************************/
+/* Macro for testing aligment. Positive if number is NOT aligned   */
+#define MV_IS_NOT_ALIGN(number, align)      ((number) & ((align) - 1))
+
+/* Macro for alignment up. For example, MV_ALIGN_UP(0x0330, 0x20) = 0x0340   */
+#define MV_ALIGN_UP(number, align)                             \
+(((number) & ((align) - 1)) ? (((number) + (align)) & ~((align)-1)) : (number))
+
+/* Macro for alignment down. For example, MV_ALIGN_UP(0x0330, 0x20) = 0x0320 */
+#define MV_ALIGN_DOWN(number, align) ((number) & ~((align)-1))
+
+/* Return mask of all ones for any number of bits less than 32 */
+#define MV_ALL_ONES_MASK(bits)	((1 << (bits)) - 1)
+
+/* Check that num is power of 2 */
+#define MV_IS_POWER_OF_2(num) ((num != 0) && ((num & (num - 1)) == 0))
+
+/* Sets the field located at the specified in data.     */
+#define MV_U32_SET_FIELD(data, mask, val)		((data) = (((data) & ~(mask)) | (val)))
+
+/* Returns value with bitNum Set or Clear */
+#define MV_SET_BIT(word, bitNum, bitVal) (((word) & ~(1 << (bitNum))) | (bitVal << bitNum))
+#define MV_GET_BIT(word, bitNum)        (((word) & (1 << (bitNum))) >> (bitNum))
+
+/* QM/BM related */
+#define MV_MIN(a , b) (((a) < (b)) ? (a) : (b))
+#define MV_MAX(a , b) (((a) > (b)) ? (a) : (b))
+
+#define MV_UNIT_OF__8_BYTES	8
+#define MV_UNIT_OF_64_BYTES	64
+
+#define MV_32_BITS		32
+#define MV_40_BITS		40
+#define MV_WORD_BITS		32
+#define MV_BYTE_BITS		8
+
+/* Error definitions*/
+/* Error Codes */
+
+#define MV_OK			0
+#define MV_ON			1
+#define MV_OFF			0
+
+
+/******************************************************
+ * validation macros                                  *
+ ******************************************************/
+#define MV_PP3_NULL_PTR(_ptr_, _label_)	\
+do {					\
+	if (!(_ptr_)) {			\
+		pr_err("%s: Error - unexpected NULL pointer\n", __func__);\
+		goto _label_;		\
+	}				\
+} while (0)
+
+/* port related */
+enum mv_reset {RESET, UNRESET};
+
+enum mv_port_mode {
+	MV_PORT_RXAUI,
+	MV_PORT_XAUI,
+	MV_PORT_SGMII,
+	MV_PORT_SGMII2_5,
+	MV_PORT_QSGMII,
+	MV_PORT_RGMII
+};
+
+enum mv_port_speed {
+	MV_PORT_SPEED_AN,
+	MV_PORT_SPEED_10,
+	MV_PORT_SPEED_100,
+	MV_PORT_SPEED_1000,
+	MV_PORT_SPEED_2000,
+	MV_PORT_SPEED_10000
+};
+
+enum mv_port_duplex {
+	MV_PORT_DUPLEX_AN,
+	MV_PORT_DUPLEX_HALF,
+	MV_PORT_DUPLEX_FULL
+};
+
+enum mv_port_fc {
+	MV_PORT_FC_AN_NO,
+	MV_PORT_FC_AN_SYM,
+	MV_PORT_FC_AN_ASYM,
+	MV_PORT_FC_DISABLE,
+	MV_PORT_FC_ENABLE,
+	MV_PORT_FC_ACTIVE
+};
+
+struct mv_port_link_status {
+	int			linkup; /*flag*/
+	enum mv_port_speed	speed;
+	enum mv_port_duplex	duplex;
+	enum mv_port_fc		rx_fc;
+	enum mv_port_fc		tx_fc;
+};
+
+/* different loopback types can be configure on different levels: MAC, PCS, SERDES */
+enum mv_lb_type {
+	MV_DISABLE_LB,
+	MV_RX_2_TX_LB,
+	MV_TX_2_RX_LB,         /* on SERDES level - analog loopback */
+	MV_TX_2_RX_DIGITAL_LB  /* on SERDES level - digital loopback */
+};
+
+enum mv_sched_type {
+	MV_SCHED_STRICT,
+	MV_SCHED_WRR,
+	MV_SCHED_INV
+};
+
+enum mv_priority_type {
+	MV_PRIO_INV = 0,
+	MV_PRIO_LOW,
+	MV_PRIO_HIGH,
+	MV_PRIO_SPEC
+};
+
+/* QoS profile configuration modes */
+enum mv_qos_mode {
+	MV_QOS_MODE_DISABLED = 0,
+	MV_QOS_DSCP_VPRIO,
+	MV_QOS_VPRIO_DSCP,
+	MV_QOS_MODE_LAST
+};
+
+/* HASH types */
+enum mv_hash_type {
+	MV_HASH_NONE = 0,
+	MV_HASH_SA,	 /* MAC SA */
+	MV_HASH_2_TUPLE, /* SIP + DIP */
+	MV_HASH_4_TUPLE, /* SIP + DIP + SPort + DPort */
+	MV_HASH_LAST
+};
+
+/* PP3 packet modes */
+enum mv_pp3_pkt_mode {
+	MV_PP3_PKT_DRAM,    /* All packet data store in DRAM buffer, no data in CFH */
+	MV_PP3_PKT_CFH,     /* Packet Data split between CFH to DRAM, first 64 bytes store in CFH */
+	MV_PP3_PKT_LAST
+};
+
+enum mv_state {
+	MV_STATE_DISABLE = 0,
+	MV_STATE_ENABLE,
+	MV_STATE_LAST,
+};
+
+/* store here all MC MACs sent to FW */
+struct mac_mc_info {
+	struct list_head head;
+	u8	mac[MV_MAC_ADDR_SIZE];
+};
+
+struct mv_io_addr {
+	phys_addr_t	paddr;
+	void __iomem	*vaddr;
+	size_t		size;
+};
+struct mv_a40 {
+	u32 virt_lsb;                   /* byte[ 0-11] ,bit[ 0-31] */
+	u32 dma_lsb;                    /* byte[ 0-11] ,bit[32-63] */
+	u8  virt_msb;                   /* byte[ 0-11] ,bit[64-71] */
+	u8  dma_msb;                    /* byte[ 0-11] ,bit[72-79] */
+	u8 _reserved[2];                /* byte[ 0-11] ,bit[80-95] */
+};
+
+struct mv_unit_info {
+	void __iomem	*base_addr; /* unit base address = silicon addr + unit offset */
+	u32		ins_offs;  /* unit instance offset - for multiple units */
+};
+
+struct mv_mac_data {
+	/* Whether a PHY is present, and if yes, at which address. */
+	int			phy_addr;
+	enum mv_port_mode	port_mode;
+	int			link_irq;
+	bool			force_link;
+};
+
+enum mv_nss_port_type {
+	MV_PP3_NSS_PORT_ETH, /* EMAC virtual port	   */
+	MV_PP3_NSS_PORT_CPU, /* CPU virtual port	   */
+	MV_PP3_NSS_PORT_EXT, /* NSS virtual port	   */
+	MV_PP3_NSS_PORT_LAST
+};
+
+/* Invalid virtual port definition */
+#define MV_PP3_NSS_PORT_INV	MV_PP3_NSS_PORT_LAST
+
+
+/* CFH common fields definitions */
+/* CFH word 0 */
+#define MV_HOST_MSG_PACKET_LENGTH(l)	((l) & 0xFFFF)
+#define MV_HOST_MSG_DESCR_MODE		(2 << 30)
+/* CFH word 1 */
+#define MV_HOST_MSG_CFH_LENGTH(l)	(((l) & 0xFF) << 16)
+/* CFH word 2 */
+#define MV_HOST_MSG_CHAN_ID(l)		(((l) & 0xFF) << 16)
+/* CFH word 5 */
+#define MV_HOST_MSG_BPID(l)		(((l) & 0xFF) << 24)
+
+
+/* convert one char symbol to 8 bit interger hex format */
+static inline unsigned char char_to_hex(char msg)
+{
+	unsigned char tmp = 0;
+
+	if ((msg >= '0') && (msg <= '9'))
+		tmp = msg - '0';
+	else if ((msg >= 'a') && (msg <= 'f'))
+		tmp = msg - 'a' + 10;
+	else if ((msg >= 'A') && (msg <= 'F'))
+		tmp = msg - 'A' + 10;
+
+	return tmp;
+}
+
+static inline void mv_mac_addr_print(char *prefix, unsigned char *mac_addr, char *suffix)
+{
+	pr_info("%s %02x:%02x:%02x:%02x:%02x:%02x %s\n", prefix ? prefix : "",
+		mac_addr[0], mac_addr[1], mac_addr[2],
+		mac_addr[3], mac_addr[4], mac_addr[5], suffix ? suffix : "");
+}
+
+/* convert asci string of known size to 8 bit interger hex format array */
+static inline void str_to_hex(char *msg, int size, unsigned char *imsg, int new_size)
+{
+	int i, j;
+	unsigned char tmp;
+
+	for (i = 0, j = 0; j < new_size; i = i + 2, j++) {
+		/* build high byte nible */
+		tmp = (char_to_hex(msg[i]) << 4);
+		/* build low byte nible */
+		tmp += char_to_hex(msg[i+1]);
+		imsg[j] = tmp;
+	}
+}
+
+/* convert u32 value from BE to cpu native */
+static inline void mv_be32_convert(u32 *ptr, int size)
+{
+	int i;
+	for (i = 0; i < size; i++, ptr++)
+		*ptr = be32_to_cpu(*ptr);
+}
+
+/* convert mac address in format xx:xx:xx:xx:xx:xx to array of unsigned char [6] */
+static inline void mv_mac_str2hex(const char *mac_str, u8 *mac_hex)
+{
+	int i;
+	char tmp[3];
+	u8 tmp1;
+
+	for (i = 0; i < 6; i++) {
+		tmp[0] = mac_str[(i * 3) + 0];
+		tmp[1] = mac_str[(i * 3) + 1];
+		tmp[2] = '\0';
+		str_to_hex(tmp, 3, &tmp1, 1);
+		mac_hex[i] = tmp1;
+	}
+	return;
+}
+static inline void mv_u32_memcpy(u32 *dst, u32 *src, int bytes)
+{
+	int i, words;
+
+	/* copy whole number of words */
+	words = bytes >> 2;
+	for (i = 0; i < words; i++)
+		*dst++ = *src++;
+
+	/* copy rest bytes if needed */
+	bytes = bytes - (words << 2);
+	if (bytes) {
+		u8 *src_u8 = (u8 *)src;
+		u8 *dst_u8 = (u8 *)dst;
+		switch (bytes) {
+		case 1:
+			dst_u8[0] = src_u8[0];
+			break;
+		case 2:
+			dst_u8[0] = src_u8[0];
+			dst_u8[1] = src_u8[1];
+			break;
+
+		case 3:
+			dst_u8[0] = src_u8[0];
+			dst_u8[1] = src_u8[1];
+			dst_u8[2] = src_u8[2];
+			break;
+		}
+	}
+}
+/******************************************************
+ * common functions				      *
+ ******************************************************/
+void mv_debug_mem_dump(void *addr, int size, int access);
+unsigned int mv_field_get(int offs, int bits,  unsigned int *entry);
+void mv_field_set(int offs, int bits, unsigned int *entry,  unsigned int val);
+const char *mv_port_mode_str(enum mv_port_mode mode);
+const char *mv_hash_type_str(enum mv_hash_type hash);
+int mv_memory_buffer_alloc(unsigned int req_size, int max_bufs_num, unsigned int *buff);
+const char *mv_pp3_pkt_mode_str(enum mv_pp3_pkt_mode mode);
+int mv_pp3_max_check(int value, int limit, char *name);
+void mv_link_to_str(struct mv_port_link_status status, char *str);
+
+
+#endif /* __mv_sw_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/emac/mv_emac.c b/drivers/net/ethernet/marvell/pp3/emac/mv_emac.c
new file mode 100644
index 0000000..1e8aa13
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/emac/mv_emac.c
@@ -0,0 +1,479 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "emac/mv_emac.h"
+#include "mv_emac_regs.h"
+
+static struct mv_pp3_emac_ctrl *pp3_emac;
+
+/*--------------------------------------------------------------*/
+/*--------------------- EMAC globals ---------------------------*/
+/*--------------------------------------------------------------*/
+
+
+u32 mv_pp3_emac_reg_read(int port, u32 reg)
+{
+	u32 reg_data;
+
+	reg_data = mv_pp3_hw_reg_read(reg + pp3_emac[port].base);
+
+	if (pp3_emac[port].flags & MV_PP3_EMAC_F_DEBUG)
+		pr_info("read     : 0x%04x = 0x%08x\n", reg, reg_data);
+
+	return reg_data;
+}
+
+void mv_pp3_emac_reg_write(int port, u32 reg, u32 data)
+{
+	mv_pp3_hw_reg_write(reg + pp3_emac[port].base, data);
+
+	if (pp3_emac[port].flags & MV_PP3_EMAC_F_DEBUG) {
+		u32 reg_data;
+		pr_info("write    : 0x%04x = 0x%08x\n", reg, data);
+		reg_data = mv_pp3_hw_reg_read(reg + pp3_emac[port].base);
+		pr_info("read back: 0x%04x = 0x%08x\n", reg, reg_data);
+	}
+}
+
+static void mv_pp3_emac_reg_print(int port, char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%04x = 0x%08x\n", reg_name, reg, mv_pp3_emac_reg_read(port, reg));
+}
+
+int mv_pp3_emac_global_init(int emacs_num)
+{
+	if (pp3_emac != NULL) {
+		pr_warn("EMAC component is already initialized\n");
+		return -1;
+	}
+	pp3_emac = kzalloc(sizeof(struct mv_pp3_emac_ctrl) * emacs_num, GFP_KERNEL);
+	if (pp3_emac == NULL) {
+		pr_err("%s: Memory allocation of %d bytes failed\n", __func__,
+				sizeof(struct mv_pp3_emac_ctrl) * emacs_num);
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+void mv_pp3_emac_unit_base(int port, void __iomem *base)
+{
+	pp3_emac[port].base = base;
+	pp3_emac[port].flags |= MV_PP3_EMAC_F_ATTACH;
+}
+
+void mv_pp3_emac_init(int port, int qmp, int qmq)
+{
+	mv_pp3_emac_qm_mapping(port, qmp, qmq);
+	mv_pp3_emac_fw_data(port);
+	mv_pp3_emac_deq_undrn_threshold(port, MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_DEF);
+
+	/* use hw defaults */
+	/*mv_pp3_emac_rx_cfh_reorder_mode(int port, int lock_id);*/
+	/*mv_pp3_emac_rx_cfh_deq_mode(port, mode)*/
+	/*mv_pp3_emac_mh_en(port, 1);*/
+	/*mv_pp3_emac_rx_desc_rsvd(port, 2);*/
+	/* mv_pp3_emac_tx_min_pkt_len(int port, 60)*/
+	/*mv_pp3_emac_rx_enable(port,1);*/
+	/*mv_pp3_emac_loopback(port, 0)*/
+}
+
+/* enable debug flag */
+void mv_pp3_emac_debug(int port, int en)
+{
+	if (en)
+		pp3_emac[port].flags |= MV_PP3_EMAC_F_DEBUG;
+	else
+		pp3_emac[port].flags &= ~MV_PP3_EMAC_F_DEBUG;
+
+
+}
+
+/* set logical port and CFH mode, used by FW */
+void mv_pp3_emac_fw_data(int port)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W1_REG);
+
+	data &= ~(MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_MASK | MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_MASK);
+
+	data |= (port << MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_OFFS) |
+		(1 << MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_DESC_W1_REG, data);
+}
+
+/* set QM Enq queu and Deq port */
+void mv_pp3_emac_qm_mapping(int port, int qmp, int qmq)
+{
+	u32 data;
+
+	data = (qmq << MV_EMAC_AXI_CFG_AXI4_ENQ_QUEUE_NUM_OFFS) |
+		(qmp << MV_EMAC_AXI_CFG_AXI4_DEQ_PORT_NUM_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_AXI_CFG_REG, data);
+}
+
+/* add mh in rx and strip in tx - enable/disable */
+void mv_pp3_emac_mh_en(int port, int en)
+{
+	u32 data_rx, data_tx;
+
+	data_rx = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CR_REG);
+	data_tx = mv_pp3_emac_reg_read(port, MV_EMAC_DEQ_CR_REG);
+
+	if (en) {
+		data_rx |= MV_EMAC_ENQ_CR_ADD_MH_MASK;
+		data_tx |= MV_EMAC_DEQ_CR_STRIP_MH_MASK;
+	} else {
+		data_rx &= ~MV_EMAC_ENQ_CR_ADD_MH_MASK;
+		data_tx &= ~MV_EMAC_DEQ_CR_STRIP_MH_MASK;
+	}
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_CR_REG, data_rx);
+	mv_pp3_emac_reg_write(port, MV_EMAC_DEQ_CR_REG, data_tx);
+}
+
+/* Set dequeue packet FIFO under run protection threshold in units of 16 bytes*/
+void mv_pp3_emac_deq_undrn_threshold(int port, int thr)
+{
+	u32 reg_val;
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_DEQ_CR_REG);
+
+	reg_val &= ~MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_MASK;
+	reg_val |= (thr << MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_DEQ_CR_REG, reg_val);
+}
+/*
+set source of timestamp
+	from = 0: from RTC
+	from = 1: from descriptor
+*/
+void mv_pp3_emac_ts(int port, int from)
+{
+	u32 data_rx, data_tx;
+
+	data_rx = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CR_REG);
+	data_tx = mv_pp3_emac_reg_read(port, MV_EMAC_DEQ_CR_REG);
+
+	if (from) {
+		data_rx |= MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_MASK;
+		data_tx |= MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_MASK;
+	} else {
+		data_rx &= ~MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_MASK;
+		data_tx &= ~MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_MASK;
+	}
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_CR_REG, data_rx);
+	mv_pp3_emac_reg_write(port, MV_EMAC_DEQ_CR_REG, data_tx);
+}
+
+/* dump emac registers */
+void mv_pp3_emac_regs(int port)
+{
+	mv_pp3_emac_reg_print(port, "CR", MV_EMAC_CR_REG);
+	mv_pp3_emac_reg_print(port, "INT_MASK", MV_EMAC_INT_MASK_REG);
+	mv_pp3_emac_reg_print(port, "STATUS", MV_EMAC_STATUS_REG);
+	mv_pp3_emac_reg_print(port, "ENQ", MV_EMAC_ENQ_CR_REG);
+	mv_pp3_emac_reg_print(port, "ENQ_CFH_MH", MV_EMAC_ENQ_CFH_MH_REG);
+	mv_pp3_emac_reg_print(port, "ENQ_DESC_W0", MV_EMAC_ENQ_DESC_W0_REG);
+	mv_pp3_emac_reg_print(port, "ENQ_DESC_W1", MV_EMAC_ENQ_DESC_W1_REG);
+	mv_pp3_emac_reg_print(port, "AXI_CFG", MV_EMAC_AXI_CFG_REG);
+	mv_pp3_emac_reg_print(port, "DEQ_CR", MV_EMAC_DEQ_CR_REG);
+	mv_pp3_emac_reg_print(port, "MIN_PKT_LEN", MV_EMAC_MIN_PKT_LEN_REG);
+	mv_pp3_emac_reg_print(port, "DEQ_RTC_STRM_VAL", MV_EMAC_DEQ_RTC_STRM_VAL_REG);
+	mv_pp3_emac_reg_print(port, "DEQ_RTC_PORT_VAL", MV_EMAC_DEQ_RTC_PORT_VAL_REG);
+
+	pr_info("------------------------ debug regs ---------------------\n");
+
+	mv_pp3_emac_reg_print(port, "DBG_SM_STATUS", MV_EMAC_DBG_SM_STATUS_REG);
+	mv_pp3_emac_reg_print(port, "DBG_FIFO_FILL_LVL1", MV_EMAC_DBG_FIFO_FILL_LVL1_REG);
+	mv_pp3_emac_reg_print(port, "DBG_FIFO_FILL_LVL2", MV_EMAC_DBG_FIFO_FILL_LVL2_REG);
+}
+
+
+/* dump emac status */
+void mv_pp3_emac_status(int port)
+{
+	u32 reg_val;
+
+	pr_info("settings for emac%d:\n", port);
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_CR_REG);
+	pr_info("HW loopback: %s\n", (reg_val & MV_EMAC_CR_LOOPBACK_EN_MASK) ? "on" : "off");
+	pr_info("RX enq: %s\n", (reg_val & MV_EMAC_CR_ENQ_EN_MASK) ? "on" : "off");
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CR_REG);
+	pr_info("RX add MH: %s\n", (reg_val & MV_EMAC_ENQ_CR_ADD_MH_MASK) ? "on" : "off");
+	pr_info("RX timestamp source: %s\n",
+			(reg_val & MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_MASK) ? "descriptor" : "RTC");
+	pr_info("RX CFH wr offs: %d\n",
+			((MV_EMAC_ENQ_CR_CFH_OFFSET_MASK & reg_val) >>
+			MV_EMAC_ENQ_CR_CFH_OFFSET_OFFS) * 8);
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W1_REG);
+	pr_info("RX CFH wr mode: %d (0-HMAC, 1-EMAC, 2-CMAC, 3-RADIO)\n",
+			(MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_MASK & reg_val) >> MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_OFFS);
+	pr_info("RX CFH wr port: %d\n",
+			(MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_MASK & reg_val) >> MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_OFFS);
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CFH_MH_REG);
+	pr_info("RX MH val: %d\n", reg_val &
+			(MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_MASK & reg_val) >> MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_OFFS);
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W0_REG);
+	pr_info("RX lock id: %d\n", reg_val &
+			(MV_EMAC_ENQ_DESC_W0_LOCKID_MASK & reg_val) >> MV_EMAC_ENQ_DESC_W0_LOCKID_OFFS);
+	pr_info("RX reorder mode: %d\n", reg_val &
+			(MV_EMAC_ENQ_DESC_W0_REORDER_MODE_MASK & reg_val) >> MV_EMAC_ENQ_DESC_W0_REORDER_MODE_OFFS);
+	pr_info("TX deq mode: %d\n", reg_val &
+			(MV_EMAC_ENQ_DESC_W0_DEQ_MODE_MASK & reg_val) >> MV_EMAC_ENQ_DESC_W0_DEQ_MODE_OFFS);
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_DEQ_CR_REG);
+	pr_info("TX strm CFH size: %d\n",
+			((MV_EMAC_DEQ_CR_STRM_DESC_SIZE_MASK & reg_val) >>
+			MV_EMAC_DEQ_CR_STRM_DESC_SIZE_OFFS) * 16);
+	pr_info("TX srip MH: %s\n",
+			(reg_val & MV_EMAC_DEQ_CR_STRIP_MH_MASK) ? "on" : "off");
+	pr_info("TX timestamp source: %s\n",
+			(reg_val & MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_MASK) ?
+			"descriptor" : "RTC");
+
+	/*-------------------------------------------------------------------*/
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_MIN_PKT_LEN_REG);
+	pr_info("TX min packet length: %d\n",
+			(MV_EMAC_MIN_PKT_LEN_DEQ_MASK & reg_val) >>
+			MV_EMAC_MIN_PKT_LEN_DEQ_OFFS);
+}
+
+/* enable/disable loopback forom TX to RX */
+void mv_pp3_emac_loopback(int port, int lb)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_CR_REG);
+
+	if (lb)
+		data |= MV_EMAC_CR_LOOPBACK_EN_MASK;
+	else
+		data &= ~MV_EMAC_CR_LOOPBACK_EN_MASK;
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_CR_REG, data);
+}
+
+/* enable/disable emac rx */
+void mv_pp3_emac_rx_enable(int port, int en)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_CR_REG);
+
+	if (en)
+		data |= MV_EMAC_CR_ENQ_EN_MASK;
+	else
+		data &= ~MV_EMAC_CR_ENQ_EN_MASK;
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_CR_REG, data);
+
+	/*pr_info("\nEMAC #%d - %s\n", port, en ? "enabled" : "disabled");*/
+
+	/*TODO do we need to wait to interrupt bit*/
+}
+
+/*
+set offset to CFH after 16B descriptor
+	bytes: 0-64 in multiples of 8 (0, 8, 16, etc.)
+*/
+int mv_pp3_emac_rx_desc_rsvd(int port, int bytes)
+{
+	u32 data;
+
+	/* TODO: do we need bytes validation here ? */
+	if (bytes % 8)
+		return 1;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CR_REG);
+
+	data &= ~MV_EMAC_ENQ_CR_CFH_OFFSET_MASK;
+	data |= ((bytes/8) << MV_EMAC_ENQ_CR_CFH_OFFSET_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_CR_REG, data);
+
+	return 0;
+}
+
+/* set mh value, relevant only if mh is enable */
+void mv_pp3_emac_rx_mh(int port, short mh)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_CFH_MH_REG);
+
+	data &= ~MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_MASK;
+	data |= (mh << MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_CFH_MH_REG, data);
+}
+
+/*
+set the minimum packet length that will sent to GOP
+	bytes: length in bytes, valid range [16, 64]
+*/
+void mv_pp3_emac_tx_min_pkt_len(int port, int bytes)
+{
+	u32 data;
+
+	/* TODO: do we need bytes validation here ? */
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_MIN_PKT_LEN_REG);
+
+	data &= ~MV_EMAC_MIN_PKT_LEN_DEQ_MASK;
+	data |= (bytes << MV_EMAC_MIN_PKT_LEN_DEQ_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_MIN_PKT_LEN_REG, data);
+}
+/*
+set CFH lockId
+*/
+void mv_pp3_emac_rx_cfh_lock_id(int port, int lock_id)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W0_REG);
+	data &= ~MV_EMAC_ENQ_DESC_W0_LOCKID_MASK;
+	data |= (lock_id << MV_EMAC_ENQ_DESC_W0_LOCKID_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_DESC_W0_REG, data);
+}
+
+/*
+set CFH reorder mode
+*/
+void mv_pp3_emac_rx_cfh_reorder_mode(int port, int mode)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W0_REG);
+	data &= ~MV_EMAC_ENQ_DESC_W0_REORDER_MODE_MASK;
+	data |= (mode << MV_EMAC_ENQ_DESC_W0_REORDER_MODE_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_DESC_W0_REG, data);
+}
+
+/*
+set CFH deq mode
+*/
+void mv_pp3_emac_rx_cfh_deq_mode(int port, int mode)
+{
+	u32 data;
+
+	data = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DESC_W0_REG);
+	data &= ~MV_EMAC_ENQ_DESC_W0_DEQ_MODE_MASK;
+	data |= (mode << MV_EMAC_ENQ_DESC_W0_DEQ_MODE_OFFS);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_ENQ_DESC_W0_REG, data);
+}
+
+u32 mv_pp3_emac_drop_packets_cntr_get(int port)
+{
+	u32 reg_val;
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DRP_PKT_CNT_REG);
+	if (pp3_emac[port].flags & MV_PP3_EMAC_F_ROC_CNT_EN)
+		return reg_val;
+
+	pp3_emac[port].enq_drop_cnt += reg_val;
+	return pp3_emac[port].enq_drop_cnt;
+}
+
+void mv_pp3_emac_counters_clear(int port)
+{
+	u32 reg_val;
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DRP_PKT_CNT_REG);
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_XOFF_CNT_REG);
+
+	pp3_emac[port].enq_drop_cnt = 0;
+	pp3_emac[port].enq_xoff_cnt = 0;
+}
+
+void mv_pp3_emac_counters_show(int port)
+{
+	u32 drop, xoff;
+
+	pr_info("\n-------------- EMAC %d counters -----------", port);
+
+	drop = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_DRP_PKT_CNT_REG);
+	xoff = mv_pp3_emac_reg_read(port, MV_EMAC_ENQ_XOFF_CNT_REG);
+	if (!(pp3_emac[port].flags & MV_PP3_EMAC_F_ROC_CNT_EN)) {
+		pp3_emac[port].enq_drop_cnt += drop;
+		pp3_emac[port].enq_xoff_cnt += xoff;
+		drop = pp3_emac[port].enq_drop_cnt;
+		xoff = pp3_emac[port].enq_xoff_cnt;
+	}
+	pr_info("  %-32s: %-8u\n", "ENQ_DRP_PKT_CNT", drop);
+	pr_info("  %-32s: %-8u\n", "ENQ_XOFF_CNT", xoff);
+}
+
+
+void mv_pp3_emac_pfc_regs(int port)
+{
+	/* TODO: print PFC registers */
+	return;
+}
+
+void mv_pp3_emac_sleep_state(int port, bool en)
+{
+	u32 reg_val;
+
+	reg_val = mv_pp3_emac_reg_read(port, MV_EMAC_CR_REG);
+	if (en)
+		reg_val |= MV_EMAC_CR_SLEEP_MASK;
+	else
+		reg_val &= (~MV_EMAC_CR_SLEEP_MASK);
+
+	mv_pp3_emac_reg_write(port, MV_EMAC_CR_REG, reg_val);
+
+	return;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/emac/mv_emac.h b/drivers/net/ethernet/marvell/pp3/emac/mv_emac.h
new file mode 100644
index 0000000..44cdebb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/emac/mv_emac.h
@@ -0,0 +1,109 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_emac_h__
+#define __mv_emac_h__
+
+#include "common/mv_sw_if.h"
+
+/*--------------------------------------------------------------*/
+/*--------------------- EMAC globals ---------------------------*/
+/*--------------------------------------------------------------*/
+
+struct mv_pp3_emac_ctrl {
+	void __iomem *base;
+	u32 flags;
+	/* shadow of HW ROC counters */
+	u32 enq_drop_cnt;
+	u32 enq_xoff_cnt;
+};
+
+/* mv_pp3_emac_ctrl flags */
+
+
+#define MV_PP3_EMAC_F_DEBUG_BIT		0
+#define MV_PP3_EMAC_F_ATTACH_BIT	1
+#define MV_PP3_EMAC_F_ROC_CNT_EN_BIT	2
+
+#define MV_PP3_EMAC_F_DEBUG		(1 << MV_PP3_EMAC_F_DEBUG_BIT)
+#define MV_PP3_EMAC_F_ATTACH		(1 << MV_PP3_EMAC_F_ATTACH_BIT)
+#define MV_PP3_EMAC_F_ROC_CNT_EN	(1 << MV_PP3_EMAC_F_ROC_CNT_EN_BIT)
+
+
+void mv_pp3_emac_unit_base(int index, void __iomem *base);
+int mv_pp3_emac_global_init(int emacs_num);
+u32  mv_pp3_emac_reg_read(int port, u32 reg);
+void mv_pp3_emac_reg_write(int port, u32 reg, u32 data);
+void mv_pp3_emac_init(int port, int qmp, int qmq);
+void mv_pp3_emac_qm_mapping(int port, int qmp, int qmq);
+void mv_pp3_emac_mh_en(int port, int en);
+void mv_pp3_emac_ts(int port, int from);
+void mv_pp3_emac_loopback(int port, int lb);
+void mv_pp3_emac_regs(int port);
+u32 mv_pp3_emac_drop_packets_cntr_get(int port);
+void mv_pp3_emac_counters_show(int port);
+void mv_pp3_emac_counters_clear(int port);
+void mv_pp3_emac_status(int port);
+void mv_pp3_emac_debug(int port, int en);
+void mv_pp3_emac_rx_enable(int port, int en);
+void mv_pp3_emac_rx_cfh_lock_id(int port, int lock_id);
+void mv_pp3_emac_rx_cfh_deq_mode(int port, int mode);
+void mv_pp3_emac_rx_cfh_reorder_mode(int port, int mode);
+int mv_pp3_emac_rx_desc_rsvd(int port, int bytes);
+void mv_pp3_emac_rx_mh(int port, short mh);
+void mv_pp3_emac_tx_min_pkt_len(int port, int bytes);
+void mv_pp3_emac_fw_data(int port);
+void mv_pp3_emac_sleep_state(int port, bool en);
+void mv_pp3_emac_deq_undrn_threshold(int port, int thr);
+
+/*--------------------------------------------------------------*/
+/*------------------------- PFC --------------------------------*/
+/*--------------------------------------------------------------*/
+
+#define MV_EMAC_PFC_PRIO_MAX	8
+
+void mv_pp3_emac_pfc_tbl_addr(int port, int prio, u32 val);
+void mv_pp3_emac_pfc_tbl_pause(int port, int prio, u32 val);
+void mv_pp3_emac_pfc_tbl_resume(int port, int prio, u32 val);
+void mv_pp3_emac_pfc_regs(int port);
+
+/*--------------------------------------------------------------*/
+/*-------------------------- WOL -------------------------------*/
+/*--------------------------------------------------------------*/
+
+void mv_pp3_emac_wol_regs(int port);
+/* TODO */
+
+/*--------------------------------------------------------------*/
+/*------------------------- SYSFS ------------------------------*/
+/*--------------------------------------------------------------*/
+
+int mv_pp3_emac_sysfs_exit(struct kobject *pp3_kobj);
+int mv_pp3_emac_sysfs_init(struct kobject *pp3_kobj);
+
+#endif /* __mv_emac_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/emac/mv_emac_regs.h b/drivers/net/ethernet/marvell/pp3/emac/mv_emac_regs.h
new file mode 100644
index 0000000..66da395
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/emac/mv_emac_regs.h
@@ -0,0 +1,244 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_emac_reg_h__
+#define __mv_emac_reg_h__
+
+
+/* Emac Control (emac_cr) */
+#define MV_EMAC_CR_REG								(0x0000)
+#define MV_EMAC_CR_ENQ_EN_OFFS							0
+#define MV_EMAC_CR_ENQ_EN_MASK    \
+		(0x00000001 << MV_EMAC_CR_ENQ_EN_OFFS)
+
+#define MV_EMAC_CR_SLEEP_OFFS							1
+#define MV_EMAC_CR_SLEEP_MASK    \
+		(0x00000001 << MV_EMAC_CR_SLEEP_OFFS)
+
+#define MV_EMAC_CR_LOOPBACK_EN_OFFS						2
+#define MV_EMAC_CR_LOOPBACK_EN_MASK    \
+		(0x00000001 << MV_EMAC_CR_LOOPBACK_EN_OFFS)
+
+#define MV_EMAC_INT_MASK_REG							(0x0008)
+
+/* Emac Status */
+#define MV_EMAC_STATUS_REG							(0x000c)
+#define MV_EMAC_STATUS_EMAC_IDLE_OFFS						0
+#define MV_EMAC_STATUS_EMAC_IDLE_MASK    \
+		(0x00000001 << MV_EMAC_STATUS_EMAC_IDLE_OFFS)
+
+#define MV_EMAC_STATUS_ENQ_IDLE_OFFS						1
+#define MV_EMAC_STATUS_ENQ_IDLE_MASK    \
+		(0x00000001 << MV_EMAC_STATUS_ENQ_IDLE_OFFS)
+
+#define MV_EMAC_STATUS_DEQ_IDLE_OFFS						2
+#define MV_EMAC_STATUS_DEQ_IDLE_MASK    \
+		(0x00000001 << MV_EMAC_STATUS_DEQ_IDLE_OFFS)
+
+#define MV_EMAC_STATUS_XOFF_REASON_OFFS						3
+#define MV_EMAC_STATUS_XOFF_REASON_MASK    \
+		(0x00000007 << MV_EMAC_STATUS_XOFF_REASON_OFFS)
+
+/* Emac Enq Control (EMAC_ENQ_CR) */
+#define MV_EMAC_ENQ_CR_REG							(0x0010)
+#define MV_EMAC_ENQ_CR_CFH_OFFSET_OFFS					0
+#define MV_EMAC_ENQ_CR_CFH_OFFSET_MASK    \
+		(0x0000000f << MV_EMAC_ENQ_CR_CFH_OFFSET_OFFS)
+
+#define MV_EMAC_ENQ_CR_ADD_MH_OFFS					4
+#define MV_EMAC_ENQ_CR_ADD_MH_MASK    \
+		(0x00000001 << MV_EMAC_ENQ_CR_ADD_MH_OFFS)
+
+#define MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_OFFS			5
+#define MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_MASK    \
+		(0x00000001 << MV_EMAC_ENQ_CR_TIMESTAMP_FROM_DESCRIPTOR_OFFS)
+
+
+/* Emac Enq Cfh Mh (EMAC_ENQ_CFH_MH) */
+#define MV_EMAC_ENQ_CFH_MH_REG							(0x0014)
+#define MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_OFFS					0
+#define MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_MASK    \
+		(0x0000ffff << MV_EMAC_ENQ_CFH_MH_EMAC_ENQ_CFH_MH_OFFS)
+
+
+/* Emac Enq Descriptor Word 0 (EMAC_ENQ_DESC_W0) */
+#define MV_EMAC_ENQ_DESC_W0_REG							(0x0018)
+#define MV_EMAC_ENQ_DESC_W0_EMAC_ENQ_DESC_W0_31_16_OFFS				0
+#define MV_EMAC_ENQ_DESC_W0_EMAC_ENQ_DESC_W0_31_16_MASK    \
+		(0x0000ffff << MV_EMAC_ENQ_DESC_W0_EMAC_ENQ_DESC_W0_31_16_OFFS)
+
+#define MV_EMAC_ENQ_DESC_W0_LOCKID_OFFS						16
+#define MV_EMAC_ENQ_DESC_W0_LOCKID_MASK			\
+		(0x00000fff << MV_EMAC_ENQ_DESC_W0_LOCKID_OFFS)
+
+#define MV_EMAC_ENQ_DESC_W0_REORDER_MODE_OFFS					28
+#define MV_EMAC_ENQ_DESC_W0_REORDER_MODE_MASK			\
+		(0x00000003 << MV_EMAC_ENQ_DESC_W0_REORDER_MODE_OFFS)
+
+#define MV_EMAC_ENQ_DESC_W0_DEQ_MODE_OFFS					30
+#define MV_EMAC_ENQ_DESC_W0_DEQ_MODE_MASK			\
+		(0x00000003 << MV_EMAC_ENQ_DESC_W0_DEQ_MODE_OFFS)
+
+
+/* Emac Enq Descriptor Word 1 (EMAC_ENQ_DESC_W1) */
+#define MV_EMAC_ENQ_DESC_W1_REG							(0x001c)
+#define MV_EMAC_ENQ_DESC_W1_EMAC_ENQ_DESC_W1_OFFS				0
+#define MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_OFFS					24
+#define MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_MASK			\
+		(0x00000003 << MV_EMAC_ENQ_DESC_W1_FW_CFH_MODE_OFFS)
+#define MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_OFFS					28
+#define MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_MASK			\
+		(0x0000000F << MV_EMAC_ENQ_DESC_W1_FW_LOGIC_PORT_OFFS)
+
+
+
+/* Emac Axi Configuration (EMAC_AXI_CFG) */
+#define MV_EMAC_AXI_CFG_REG							(0x0030)
+#define MV_EMAC_AXI_CFG_AXI4_ENQ_QUEUE_NUM_OFFS					0
+#define MV_EMAC_AXI_CFG_AXI4_ENQ_QUEUE_NUM_MASK    \
+		(0x00000fff << MV_EMAC_AXI_CFG_AXI4_ENQ_QUEUE_NUM_OFFS)
+
+#define MV_EMAC_AXI_CFG_AXI4_DEQ_PORT_NUM_OFFS					12
+#define MV_EMAC_AXI_CFG_AXI4_DEQ_PORT_NUM_MASK    \
+		(0x00000fff << MV_EMAC_AXI_CFG_AXI4_DEQ_PORT_NUM_OFFS)
+
+/* Emac Enq Dropped Packets Counter (EMAC_ENQ_DRP_PKT_CNT) */
+#define MV_EMAC_ENQ_DRP_PKT_CNT_REG						(0x00c0)
+#define MV_EMAC_ENQ_DRP_PKT_CNT_ENQ_DRP_PKT_CNT_OFFS				0
+
+/* Emac Enq Xoff Counter (EMAC_ENQ_XOFF_CNT) */
+#define MV_EMAC_ENQ_XOFF_CNT_REG						(0x00c4)
+#define MV_EMAC_ENQ_XOFF_CNT_ENQ_XOFF_CNT_OFFS					0
+
+/* Emac Deq Control (EMAC_DEQ_CR) */
+#define MV_EMAC_DEQ_CR_REG							(0x00d0)
+#define MV_EMAC_DEQ_CR_STRM_DESC_SIZE_OFFS					0
+#define MV_EMAC_DEQ_CR_STRM_DESC_SIZE_MASK    \
+		(0x00000003 << MV_EMAC_DEQ_CR_STRM_DESC_SIZE_OFFS)
+
+#define MV_EMAC_DEQ_CR_STRIP_MH_OFFS						2
+#define MV_EMAC_DEQ_CR_STRIP_MH_MASK    \
+		(0x00000001 << MV_EMAC_DEQ_CR_STRIP_MH_OFFS)
+
+#define MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_OFFS					3
+#define MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_MASK    \
+		(0x000000ff << MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_OFFS)
+
+#define MV_EMAC_DEQ_CR_FIFO_UNDRN_PROT_TH_DEF					0x80
+
+#define MV_EMAC_DEQ_CR_TX_SOP_DESC_PTP_ACTION_OFFS				12
+#define MV_EMAC_DEQ_CR_TX_SOP_DESC_PTP_ACTION_MASK    \
+		(0x0000000f << MV_EMAC_DEQ_CR_TX_SOP_DESC_PTP_ACTION_OFFS)
+
+#define MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_OFFS		16
+#define MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_MASK    \
+		(0x00000001 << MV_EMAC_DEQ_CR_TX_SOP_DESC_INGRS_TIME_STMP_FROM_CFH_OFFS)
+
+
+/* Emac Deq Minimum Packet Length (EMAC_MIN_PKT_LEN) */
+#define MV_EMAC_MIN_PKT_LEN_REG							(0x00d4)
+#define MV_EMAC_MIN_PKT_LEN_DEQ_OFFS						0
+#define MV_EMAC_MIN_PKT_LEN_DEQ_MASK    \
+		(0x0000007f << MV_EMAC_MIN_PKT_LEN_DEQ_OFFS)
+
+
+/* Emac Deq Rtc Value From Descriptor (EMAC_DEQ_RTC_STRM_VAL) */
+#define MV_EMAC_DEQ_RTC_STRM_VAL_REG						(0x00d8)
+#define MV_EMAC_DEQ_RTC_STRM_VAL_DEQ_RTC_STRM_VAL_OFFS				0
+
+/* Emac Deq Rtc Value From Port (EMAC_DEQ_RTC_PORT_VAL) */
+#define MV_EMAC_DEQ_RTC_PORT_VAL_REG						(0x00dc)
+#define MV_EMAC_DEQ_RTC_PORT_VAL_DEQ_RTC_PORT_VAL_OFFS				0
+
+/* Emac Deq Egress Pipe Delay */
+#define MV_EMAC_DEQ_EG_PIPE_DELAY_REG						(0x00e0)
+#define MV_EMAC_DEQ_EG_PIPE_DELAY_EGRESS_PIPE_DELAY_OFFS			0
+#define MV_EMAC_DEQ_EG_PIPE_DELAY_EGRESS_PIPE_DELAY_MASK    \
+		(0x3fffffff << MV_EMAC_DEQ_EG_PIPE_DELAY_EGRESS_PIPE_DELAY_OFFS)
+
+/* Debug State Machines Status (EMAC_DBG_SM_STATUS) */
+#define MV_EMAC_DBG_SM_STATUS_REG						(0x0100)
+#define MV_EMAC_DBG_SM_STATUS_ENQ_FC_STATE_OFFS					0
+#define MV_EMAC_DBG_SM_STATUS_ENQ_FC_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_ENQ_FC_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_ENQ_STATE_OFFS					4
+#define MV_EMAC_DBG_SM_STATUS_ENQ_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_ENQ_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_AXI4_W_STATE_OFFS					8
+#define MV_EMAC_DBG_SM_STATUS_AXI4_W_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_AXI4_W_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_AXI4_AW_STATE_OFFS				12
+#define MV_EMAC_DBG_SM_STATUS_AXI4_AW_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_AXI4_AW_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_DEQ_STATE_OFFS					16
+#define MV_EMAC_DBG_SM_STATUS_DEQ_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_DEQ_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_APB_ARB_STATE_OFFS				20
+#define MV_EMAC_DBG_SM_STATUS_APB_ARB_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_APB_ARB_STATE_OFFS)
+
+#define MV_EMAC_DBG_SM_STATUS_APB2MG_STATE_OFFS					24
+#define MV_EMAC_DBG_SM_STATUS_APB2MG_STATE_MASK    \
+		(0x0000000f << MV_EMAC_DBG_SM_STATUS_APB2MG_STATE_OFFS)
+
+
+/* Debug Fill Level Status 1 (EMAC_DBG_FIFO_FILL_LVL1) */
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_REG						(0x0104)
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_PFC_FIFO_OFFS		0
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_PFC_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_PFC_FIFO_OFFS)
+
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_OFFS		8
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_OFFS)
+
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_LEN_FIFO_OFFS		16
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_LEN_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_LEN_FIFO_OFFS)
+
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_EOP_FIFO_OFFS		24
+#define MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_EOP_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL1_DBG_FIFO_FILL_LVL_ENQ_EOP_FIFO_OFFS)
+
+
+/* Debug Fill Level Status 2 (EMAC_DBG_FIFO_FILL_LVL2) */
+#define MV_EMAC_DBG_FIFO_FILL_LVL2_REG						(0x0108)
+#define MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_OFFS		0
+#define MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_ENQ_CFH_FIFO_OFFS)
+
+#define MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_DEQ_CFH_FIFO_OFFS		16
+#define MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_DEQ_CFH_FIFO_MASK    \
+		(0x000000ff << MV_EMAC_DBG_FIFO_FILL_LVL2_DBG_FIFO_FILL_LVL_DEQ_PKT_FIFO_OFFS)
+
+#endif /* __mv_emac_reg_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/emac/mv_emac_sysfs.c b/drivers/net/ethernet/marvell/pp3/emac/mv_emac_sysfs.c
new file mode 100644
index 0000000..631e498
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/emac/mv_emac_sysfs.c
@@ -0,0 +1,169 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "emac/mv_emac.h"
+
+static ssize_t mv_emac_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > regs        - show EMAC port registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > pfc_regs    - show EMAC port PFC registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > config      - show EMAC port configuration\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > cntrs       - show EMAC port counters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > clear_cntrs - clear EMAC port counters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [0|1]   > rx_en       - enable/disable RX on EMAC port [p]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [0|1]   > debug       - enable/disable debug outputs registers read/write\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [u] [v] > qm_map_set  - set QM mapping, [u] QM port, [v] QM queue\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [u] [v] > reg_write   - write register: emac [p], offset [u], value [v]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [u]     > reg_read    - read register: emac [p], offset [u]\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [p]  - emac number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_emac_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	/* const char      *name = attr->attr.name; */
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_emac_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_emac_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, u, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = u = v = 0;
+	sscanf(buf, "%x %x %x", &p, &u, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "regs"))
+		mv_pp3_emac_regs(p);
+	else if (!strcmp(name, "pfc_regs"))
+		mv_pp3_emac_pfc_regs(p);
+	else if (!strcmp(name, "config"))
+		mv_pp3_emac_status(p);
+	else if (!strcmp(name, "cntrs"))
+		mv_pp3_emac_counters_show(p);
+	else if (!strcmp(name, "clear_cntrs"))
+		mv_pp3_emac_counters_clear(p);
+	else if (!strcmp(name, "reg_write"))
+		mv_pp3_emac_reg_write(p, u, v);
+	else if (!strcmp(name, "reg_read"))
+		mv_pp3_emac_reg_read(p, u);
+	else if (!strcmp(name, "debug"))
+		mv_pp3_emac_debug(p, u);
+	else if (!strcmp(name, "qm_map_set"))
+		mv_pp3_emac_qm_mapping(p, u, v);
+	else if (!strcmp(name, "rx_en"))
+		mv_pp3_emac_rx_enable(p, u);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help, S_IRUSR, mv_emac_show, NULL);
+static DEVICE_ATTR(regs, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(pfc_regs, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(config, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(cntrs, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(clear_cntrs, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(reg_write, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(reg_read, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(debug, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(qm_map_set, S_IWUSR, NULL, mv_emac_3_hex_store);
+static DEVICE_ATTR(rx_en, S_IWUSR, NULL, mv_emac_3_hex_store);
+
+
+static struct attribute *mv_emac_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_pfc_regs.attr,
+	&dev_attr_config.attr,
+	&dev_attr_cntrs.attr,
+	&dev_attr_clear_cntrs.attr,
+	&dev_attr_reg_write.attr,
+	&dev_attr_reg_read.attr,
+	&dev_attr_debug.attr,
+	&dev_attr_qm_map_set.attr,
+	&dev_attr_rx_en.attr,
+	NULL
+};
+
+static struct attribute_group mv_emac_group = {
+	.name = "emac",
+	.attrs = mv_emac_attrs,
+};
+
+
+int mv_pp3_emac_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &mv_emac_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", mv_emac_group.name, err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_emac_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &mv_emac_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_fw.c b/drivers/net/ethernet/marvell/pp3/fw/mv_fw.c
new file mode 100644
index 0000000..ecae2c0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_fw.c
@@ -0,0 +1,793 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/syscalls.h>
+#include <linux/fcntl.h>
+#include <linux/uaccess.h>
+#include <linux/platform_device.h>
+#include <linux/firmware.h>
+#include <linux/io.h>
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "mv_fw.h"
+#include "mv_fw_regs.h"
+#include "mv_fw_shared.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "fw/mv_pp3_fw_msg_structs.h"
+
+static struct mv_pp3 *pp3_fw_priv;
+static u32 mv_pp3_fw_buffers[MV_PP3_PPN_MEM_BUFS];
+
+static unsigned int active_ppc_num;
+static void __iomem *apb_base_addr;
+static unsigned char *mv_pp3_fw_path;
+
+/* active PPNs mask per cluster */
+static u32 ppc_ppn_mask[MV_PP3_PPC_MAX_NUM];
+
+/* array to store virtual DRAM buffers addresses allocated by host for FW */
+static unsigned int host_to_nss_dram_addr[MV_PP3_PPC_MAX_NUM][LAST_DRAM_BUFFER];
+/* array to store physical DRAM buffers addresses allocated by host for FW */
+static unsigned int fw_nss_dram_addr[MV_PP3_PPC_MAX_NUM][LAST_DRAM_BUFFER];
+
+static bool fw_ec_eng2apb_response_status_check(void);
+
+/* Send request for memory buffer size needed by FW */
+int mv_pp3_fw_memory_alloc(struct mv_pp3 *priv)
+{
+	int i, fw_mem, buf_num;
+	u32 fw_buffs[MV_PP3_PPN_MEM_BUFS];
+
+	/* Send request for memory buffer size needed by FW */
+	fw_mem = pp3_fw_mem_bufs_alloc_size_get();
+
+	buf_num = mv_memory_buffer_alloc(fw_mem, MV_PP3_PPN_MEM_BUFS, mv_pp3_fw_buffers);
+	if (!buf_num) {
+		pr_err("%s: failed to allocate %d kbytes requested by FW.\n", __func__, fw_mem);
+		return -1;
+	}
+	for (i = 0; i < buf_num; i++) {
+		dma_addr_t phys_addr = dma_map_single(mv_pp3_dev_get(priv),
+				(void *)(mv_pp3_fw_buffers[i]), fw_mem/buf_num, DMA_TO_DEVICE);
+
+		fw_buffs[i] = cpu_to_be32((u32)phys_addr);
+	}
+	if (pp3_fw_mem_bufs_alloc_set(fw_mem, buf_num, fw_buffs) < 0) {
+		pr_err("%s: pp3 cannot allocate buffers for FW", __func__);
+		return -1;
+	}
+	pr_info("Allocate %d kbytes by FW request\n", fw_mem);
+
+	return 0;
+}
+
+void mv_pp3_fw_memory_free(struct mv_pp3 *priv)
+{
+	int j;
+
+	for (j = 0; j < MV_PP3_PPN_MEM_BUFS; j++)
+		kfree((void *)mv_pp3_fw_buffers[j]);
+
+}
+
+
+int mv_pp3_fw_ppc_num_set(int ppc_num)
+{
+	if (ppc_num > MV_PP3_PPC_MAX_NUM) {
+		pr_err("Invalid value %d, system suport up to %d PPCs\n",
+				ppc_num, MV_PP3_PPC_MAX_NUM);
+		return -EINVAL;
+	}
+	active_ppc_num = ppc_num;
+	return 0;
+}
+
+
+int mv_pp3_fw_ppc_num_get(void)
+{
+	return active_ppc_num;
+}
+
+
+int mv_pp3_fw_parse_img_file(const char *image, int image_size, struct mem_image *img)
+{
+	int i, size;
+	char ch;
+	char buf[MV_FW_MAX_LINE_SIZE] = "\0";
+
+	size = 0;
+	for (i = 0; i < image_size; i++) {
+		ch = image[i];
+		if ((size >= MV_FW_MAX_LINE_SIZE) || (ch == '\n')) {
+			sscanf(buf, "%X:%X", &img->rows[img->size].address,
+					&img->rows[img->size].data);
+			img->size++;
+			size = 0;
+			if (img->size >= img->allocated) {
+				pr_warn("FW image is too large: %d bytes, %d lines\n",
+					image_size, img->size);
+				break;
+			}
+			continue;
+		}
+		buf[size++] = ch;
+	}
+	if (size > 0)
+		sscanf(buf, "%X:%X", &(img->rows[img->size].address), &(img->rows[img->size].data));
+
+	return img->size;
+}
+
+int mv_pp3_fw_request_file(char *path, struct mem_image *img)
+{
+	int lines;
+	const struct firmware *fw = NULL;
+
+	if (request_firmware(&fw, path, mv_pp3_dev_get(pp3_fw_priv))) {
+		pr_err("Failed to load firmware file: %s\n", path);
+		return -ENOENT;
+	}
+	lines = mv_pp3_fw_parse_img_file(fw->data, fw->size, img);
+	pr_info("Load firmware file %s: %d bytes, %d lines\n", path, fw->size, lines);
+	release_firmware(fw);
+	return lines;
+}
+
+/* imem and profile table FW load to ppc unit*/
+static int mv_pp3_ppc_fw_image_load(struct mem_image *ptr_to_image, int ppc)
+{
+	unsigned int data, size, curr_val, mask;
+	void __iomem *curr_apb_address, *addr = NULL;
+	enum ppc_mem_type type;
+
+	size = ptr_to_image->size;
+	type = ptr_to_image->type;
+
+	if ((type != PPC_MEM_IMEM) && (type != PPC_MEM_PROF)) {
+		pr_err("%s: wronge image type\n", __func__);
+		return -1;
+	}
+
+	curr_apb_address = apb_base_addr + ptr_to_image->offset +  MV_DP_PPC_BASE(ppc);
+
+	mask = ptr_to_image->mask;
+
+	for (curr_val = 0; curr_val < size; curr_val++)	{
+		data = ptr_to_image->rows[curr_val].data;
+		addr =  curr_apb_address + (ptr_to_image->rows[curr_val].address & mask);
+		mv_pp3_hw_reg_write(addr, data);
+	}
+
+	/* WA - must add read after sequence of memory writes */
+	if (addr)
+		mv_pp3_hw_reg_read(addr);
+
+	return 0;
+}
+
+
+/* search engine FW load */
+static int mv_pp3_se_cfg_fw_load(struct mem_image *ptr_to_image)
+{
+	unsigned int data, size, curr_val, mask;
+	void __iomem *addr, *curr_apb_address;
+
+	size = ptr_to_image->size;
+
+	curr_apb_address = apb_base_addr + ptr_to_image->offset;
+
+	mask = ptr_to_image->mask;
+
+	for (curr_val = 0; curr_val < size; curr_val++)	{
+
+		data = ptr_to_image->rows[curr_val].data;
+		addr =  curr_apb_address + (ptr_to_image->rows[curr_val].address & mask);
+		mv_pp3_hw_reg_write(addr, data);
+
+		if (addr == (MV_EC_APB2ENG_REQ_ADDR_CNTRL_REG + apb_base_addr))
+			/* - read status and wait for done to be set */
+			if (!fw_ec_eng2apb_response_status_check())
+				return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_get_path(char *path, int len, char *dir, char *file_name)
+{
+    /* in case the dir initialized load FW from file system */
+	if (dir) {
+		/* check that len does not exceed max len */
+		if (strlen(dir) >= len) {
+			pr_err("Failed to initialize file %s path <%s>\n", file_name, __func__);
+			return -ENOMEM;
+		}
+		strcpy(path, dir);
+	} else
+		/* in case no path initialize point to kernel dir of the FW */
+		strcpy(path, "pp3_gnss/");
+
+	/* check path len */
+	if (strlen(path) + strlen(file_name) >= len) {
+			pr_err("Failed to initialize file %s path <%s>\n", file_name, __func__);
+			return -ENOMEM;
+	}
+	strcat(path, file_name);
+	return 0;
+}
+
+
+int mv_pp3_se_fw_image_download(char *dir)
+{
+	char path[MV_MAX_FW_FILE_PATH] = "\0";
+	struct mem_image mem;
+	int rc;
+
+	memset(&mem, 0, sizeof(mem));
+
+	rc = mv_pp3_get_path(path, MV_MAX_FW_FILE_PATH, dir, "se_image.txt");
+	if (rc != 0)
+		return -1;
+
+	mem.offset = MV_NSS_SE_OFFS;
+	mem.mask = MV_NSS_SE_MASK;
+
+	pr_info("Firmware file to load: %s\n", path);
+	mem.rows = kzalloc(MV_PP3_FW_MAX_ROWS * sizeof(struct mem_rec), GFP_KERNEL);
+	mem.allocated = MV_PP3_FW_MAX_ROWS;
+
+	if (!mem.rows) {
+		pr_err("FW Image Allocation Failed in <%s>\n", __func__);
+		return -ENOMEM;
+	}
+	/* request firmware from the FS or internal files */
+	rc = mv_pp3_fw_request_file(path, &mem);
+	/* check read size is legal */
+	if ((rc < 0) || (mem.size == 0)) {
+		kfree(mem.rows);
+		return -ENOENT;
+	}
+
+	if (mv_pp3_se_cfg_fw_load(&mem) < 0) {
+		pr_err("search engine fw load Failed\n");
+		kfree(mem.rows);
+		return -1;
+	}
+
+	kfree(mem.rows);
+
+	return 0;
+}
+
+
+int mv_pp3_ppc_fw_image_download(int ppc, char *dir, unsigned int mem_type)
+{
+	char path[MV_MAX_FW_FILE_PATH] = "\0";
+	char file[MV_MAX_FW_FILE_PATH] = "\0";
+	struct mem_image mem;
+	int rc;
+
+	memset(&mem, 0, sizeof(mem));
+
+	switch (mem_type) {
+	case PPC_MEM_IMEM:
+		strcat(file, "imem_addr_data.txt");
+		mem.offset = MV_PPC_IMEM_OFFS;
+		mem.mask = MV_PPC_IMEM_MASK;
+	break;
+	case PPC_MEM_PROF:
+		strcat(file, "pt_addr_data.txt");
+		mem.offset = MV_PPC_PROF_MEM_OFFS;
+		mem.mask = MV_PPC_PROF_MEM_MASK;
+	break;
+
+	default:
+		pr_err("Unexpected firmware file type%d\n", mem_type);
+		return -ENOENT;
+	}
+
+	rc = mv_pp3_get_path(path, MV_MAX_FW_FILE_PATH, dir, file);
+	if (rc != 0)
+		return -ENOENT;
+
+	pr_info("Firmware file to load: %s\n", path);
+	mem.type = mem_type;
+	mem.rows = kzalloc(MV_PP3_FW_MAX_ROWS * sizeof(struct mem_rec), GFP_KERNEL);
+	mem.allocated = MV_PP3_FW_MAX_ROWS;
+
+	if (!mem.rows) {
+		pr_err("FW Image Allocation Failed in <%s>\n", __func__);
+		return -ENOMEM;
+	}
+	/* request firmware from the FS or internal files */
+	rc = mv_pp3_fw_request_file(path, &mem);
+	/* check read size is legal */
+	if ((rc < 0) || (mem.size == 0)) {
+		kfree(mem.rows);
+		return -ENOENT;
+	}
+
+	if (mv_pp3_ppc_fw_image_load(&mem, ppc) < 0) {
+		pr_err("PPC %d fw load Failed\n", ppc);
+		kfree(mem.rows);
+		return -1;
+	}
+
+	kfree(mem.rows);
+
+	return 0;
+}
+
+/* size - number of words to print */
+static void mv_fw_dump_print(u32 dram_offset, u32 size)
+{
+	u32 num0, num1, num2, num3;
+	u32 numb_of_strings, i;
+	u32 *ptr_to_sp;
+
+	numb_of_strings = size/4; /* 4 words in output line */
+	if (size % 4)
+		numb_of_strings++;
+	ptr_to_sp = (u32 *)dram_offset;
+	for (i = 0; i < numb_of_strings*4; i = i+4) {
+		num0 = cpu_to_be32(*(ptr_to_sp + i));
+		num1 = cpu_to_be32(*(ptr_to_sp + i + 1));
+		num2 = cpu_to_be32(*(ptr_to_sp + i + 2));
+		num3 = cpu_to_be32(*(ptr_to_sp + i + 3));
+		pr_info("0x%8p:  0x%08x  0x%08x  0x%08x  0x%08x\n", (ptr_to_sp + i),  num0, num1, num2, num3);
+	}
+}
+
+/* size - number of words to print */
+int mv_fw_pkts_rec_dump(int ppc, u32 offset, int size)
+{
+	u32 dram_offset;
+
+	if (offset > PACKET_RECORDING_DRAM_BUFFER_SIZE) {
+		pr_err("Wrong  entry offset %d\n", offset);
+		return -1;
+	}
+	if (offset + size * 4 > PACKET_RECORDING_DRAM_BUFFER_SIZE) {
+		pr_err("Wrong size %d\n", size);
+		return -1;
+	}
+	pr_info("PPC%d:: FW messages/packets buffer log start_entry: %d numb of words: %d\n",
+		ppc, offset, size);
+	/*calculate adr of logger start entry */
+	dram_offset = host_to_nss_dram_addr[ppc][PACKET_RECORDING_BUFFER] + offset;
+	mv_fw_dump_print(dram_offset, size);
+
+	return 0;
+}
+
+/* size - nuber of words to print */
+int mv_fw_sp_dump(int ppc, u32 ppn_numb, u32 buf_index, u32 start_sp_adr, u32 size)
+{
+	u32 dram_offset;
+
+	if (ppn_numb > 15) {
+		pr_err("Wrong PPN numb %d\n", ppn_numb);
+		return -1;
+	}
+	if (buf_index > MAX_SP_MIRROR_BUF_NUMB) {
+		pr_err("Wrong  SP address %x\n", start_sp_adr);
+		return -1;
+	}
+	if (start_sp_adr > SP_SIZE) {
+		pr_err("Wrong  SP address %x\n", start_sp_adr);
+		return -1;
+	}
+	if (start_sp_adr + size * 4 > SP_SIZE) {
+		pr_err("Wrong size %d\n", size);
+		return -1;
+	}
+
+	pr_info("PPC%d:: PPN #%d SP start_address: %x size: %d\n", ppc, ppn_numb, start_sp_adr, size);
+	/*calculate adr of SP image in DRAM */
+	dram_offset = host_to_nss_dram_addr[ppc][SP_MIRRORING_BUFFER] +
+		ppn_numb * SP_MIRRORING_PER_PPN_DRAM_BUFFER_SIZE + buf_index * SP_SIZE + start_sp_adr;
+	mv_fw_dump_print(dram_offset, size);
+
+	return 0;
+
+}
+
+/* size - number of entries to print */
+int mv_fw_inf_logger_dump(int ppc, u32 ppn_numb, u32 start_lg_entry, int size)
+{
+	u32 dram_offset;
+
+	if (ppn_numb > 15) {
+		pr_err("Wrong PPN numb %d\n", ppn_numb);
+		return -1;
+	}
+	if (start_lg_entry > MAX_INF_LOG_ENTRY_NUMB) {
+		pr_err("Wrong  entry numb %d\n", start_lg_entry);
+		return -1;
+	}
+	if (start_lg_entry + size > MAX_INF_LOG_ENTRY_NUMB) {
+		pr_err("Wrong size %d\n", size);
+		return -1;
+	}
+
+	pr_info("PPC%d:: PPN #%d info logger start_entry: %d numb of logs: %d\n",
+		ppc, ppn_numb, start_lg_entry, size);
+	/*calculate adr of logger start entry */
+	dram_offset = host_to_nss_dram_addr[ppc][LOGGER_BUFFER] +
+		ppn_numb * INFORMATION_LOGGER_PER_PPN_DRAM_BUFFER_SIZE + start_lg_entry * LOGGER_ENTRY_SIZE;
+	mv_fw_dump_print(dram_offset, (size*LOGGER_ENTRY_SIZE) / 4);
+
+	return 0;
+}
+
+int mv_fw_critical_logger_dump(int ppc, u32 ppn_numb, u32 start_lg_entry, int size)
+{
+	u32 dram_offset;
+
+	if (ppn_numb > 15) {
+		pr_err("Wrong PPN numb %d\n", ppn_numb);
+		return -1;
+	}
+	if (start_lg_entry > MAX_CRITICAL_LOG_ENTRY_NUMB) {
+		pr_err("Wrong  entry numb %d\n", start_lg_entry);
+		return -1;
+	}
+	if (start_lg_entry + size > MAX_CRITICAL_LOG_ENTRY_NUMB) {
+		pr_err("Wrong size %d\n", size);
+		return -1;
+	}
+
+	pr_info("PPC%d:: PPN #%d critical logger start_entry: %d numb of entries: %d\n",
+		ppc, ppn_numb, start_lg_entry, size);
+	/*calculate adr of logger start entry */
+	dram_offset = host_to_nss_dram_addr[ppc][LOGGER_BUFFER] +  LOGGER_CRITICAL_DRAM_OFFSET +
+		ppn_numb * CRITICAL_LOGGER_PER_PPN_DRAM_BUFFER_SIZE + start_lg_entry * LOGGER_ENTRY_SIZE;
+	mv_fw_dump_print(dram_offset, (size*LOGGER_ENTRY_SIZE) / 4);
+
+	return 0;
+}
+
+void mv_fw_keep_alive_dump(int ppc)
+{
+	int i;
+	u32 dram_offset, num;
+	u32 *ptr_to_keep_alive_array;
+
+	pr_info("PPC%d Keep Alive array contents:\n", ppc);
+	/*calculate start adr of keep alive array */
+	dram_offset = host_to_nss_dram_addr[ppc][KEEP_ALIVE_BUFFER];
+
+	ptr_to_keep_alive_array = (u32 *)dram_offset;
+	for (i = 0; i < NUMBER_OF_PPNs; i++) {
+		num = cpu_to_be32(*(ptr_to_keep_alive_array + i));
+		pr_info("PPN #%2d:   0x%08x\n", i, num);
+	}
+}
+
+static bool fw_ec_eng2apb_response_status_check(void)
+{
+	int count_down = 100;
+	u32 rq_status;
+
+	/* - read status and wait for done to be set */
+	do {
+		rq_status = mv_pp3_hw_reg_read(apb_base_addr + MV_EC_ENG2APB_RESPONSE_STATUS_REG);
+	} while (((rq_status & 0x4) != 4) && (count_down--));
+
+	if ((count_down == 0) && ((rq_status & 0x4) != 4)) {
+		pr_err("%s: no response from EC engine", __func__);
+		return false;
+	}
+	return true;
+}
+
+
+static int mv_pp3_ppc_dram_allocation(int ppc)
+{
+	dma_addr_t nss_dram_addr;
+	u32 host_addr;
+
+	/* allocate SP_MIRRORING_DRAM_BUFFER */
+
+	host_addr = (u32)dma_alloc_coherent(mv_pp3_dev_get(pp3_fw_priv),
+				SP_MIRRORING_DRAM_BUFFER_SIZE, &nss_dram_addr, GFP_KERNEL);
+	if (!host_addr) {
+		pr_err("Can't allocate %d bytes of coherent memory for SP_MIRRORING_BUFFER on PPC #%d\n",
+			SP_MIRRORING_DRAM_BUFFER_SIZE, ppc);
+		return -ENOMEM;
+	}
+	pr_info("0x%x bytes of coherent memory allocated for PPC%d::SP_MIRRORING_BUFFER     : vaddr=0x%x, paddr=0x%x\n",
+		SP_MIRRORING_DRAM_BUFFER_SIZE, ppc, host_addr, (unsigned int)nss_dram_addr);
+	host_to_nss_dram_addr[ppc][SP_MIRRORING_BUFFER] = host_addr;
+	fw_nss_dram_addr[ppc][SP_MIRRORING_BUFFER] = cpu_to_be32(nss_dram_addr);
+
+	/* allocate PACKET_RECORDING_BUFFER */
+	host_addr = (u32)dma_alloc_coherent(mv_pp3_dev_get(pp3_fw_priv), PACKET_RECORDING_DRAM_BUFFER_SIZE,
+						&nss_dram_addr, GFP_KERNEL);
+	if (!host_addr) {
+		pr_err("Can't allocate %d bytes of coherent memory for PACKET_RECORDING_BUFFER on PPC #%d\n",
+			PACKET_RECORDING_DRAM_BUFFER_SIZE, ppc);
+		return -ENOMEM;
+	}
+	pr_info("0x%x bytes of coherent memory allocated for PPC%d::PACKET_RECORDING_BUFFER : vaddr=0x%x, paddr=0x%x\n",
+		PACKET_RECORDING_DRAM_BUFFER_SIZE, ppc, host_addr, (unsigned int)nss_dram_addr);
+	host_to_nss_dram_addr[ppc][PACKET_RECORDING_BUFFER] = host_addr;
+	fw_nss_dram_addr[ppc][PACKET_RECORDING_BUFFER] = cpu_to_be32(nss_dram_addr);
+
+	/* allocate LOGGER_BUFFER */
+	host_addr = (u32)dma_alloc_coherent(mv_pp3_dev_get(pp3_fw_priv), LOGGER_BUFFER_SIZE,
+						&nss_dram_addr, GFP_KERNEL);
+	if (!host_addr) {
+		pr_err("Can't allocate %d bytes of coherent memory for LOGGER_BUFFER on PPC #%d\n",
+			LOGGER_BUFFER_SIZE, ppc);
+		return -ENOMEM;
+	}
+	pr_info("0x%x bytes of coherent memory allocated for PPC%d::LOGGER_BUFFER           : vaddr=0x%x, paddr=0x%x\n",
+		LOGGER_BUFFER_SIZE, ppc, host_addr, (unsigned int)nss_dram_addr);
+	host_to_nss_dram_addr[ppc][LOGGER_BUFFER] = host_addr;
+	fw_nss_dram_addr[ppc][LOGGER_BUFFER] = cpu_to_be32(nss_dram_addr);
+	pr_info("  LOGGER_INFORMATION_DRAM_OFFSET  0x%x\n", host_addr);
+	pr_info("  LOGGER_CRITICAL_DRAM_OFFSET     0x%x\n", host_addr + LOGGER_CRITICAL_DRAM_OFFSET);
+
+	/* allocate KEEP_ALIVE_BUFFER */
+	host_addr = (u32)dma_alloc_coherent(mv_pp3_dev_get(pp3_fw_priv), KEEP_ALIVE_BUFFER_SIZE,
+						&nss_dram_addr, GFP_KERNEL);
+	if (!host_addr) {
+		pr_err("Can't allocate %d bytes of coherent memory for KEEP_ALIVE_BUFFER on PPC #%d\n",
+			KEEP_ALIVE_BUFFER_SIZE, ppc);
+		return -ENOMEM;
+	}
+	pr_info("0x%x bytes of coherent memory allocated for PPC%d::KEEP_ALIVE_BUFFER       : vaddr=0x%x, paddr=0x%x\n",
+		KEEP_ALIVE_BUFFER_SIZE, ppc, host_addr, (unsigned int)nss_dram_addr);
+	host_to_nss_dram_addr[ppc][KEEP_ALIVE_BUFFER] = host_addr;
+	fw_nss_dram_addr[ppc][KEEP_ALIVE_BUFFER] = cpu_to_be32(nss_dram_addr);
+
+	return 0;
+}
+
+static void mv_pp3_ppc_dram_buffers_set(int ppc)
+{
+	void __iomem *apb_shared_sram_adr;
+
+	/* write physical address to Shared SRAM */
+	apb_shared_sram_adr = mv_pp3_nss_regs_vaddr_get() + MV_DP_PPC_BASE(ppc) +
+				MV_PPC_SHARED_MEM_OFFS + DRAM_FOR_FW_SHARED_SRAM_OFFSET;
+	pr_info(" shared_sram_adr %p\n", apb_shared_sram_adr);
+
+	mv_pp3_hw_write(apb_shared_sram_adr, LAST_DRAM_BUFFER, fw_nss_dram_addr[ppc]);
+}
+
+/* search engine FW init */
+int mv_pp3_se_fw_init(void)
+{
+	int err = -ENOENT;
+	if (mv_pp3_fw_path)
+		err = mv_pp3_se_fw_image_download(mv_pp3_fw_path);
+	if (err) {
+		err = mv_pp3_se_fw_image_download(NULL);
+		if (err)
+			return err;
+	}
+
+	/* WA for SE bug */
+	err = mv_pp3_fw_half_range_addr_cfg();
+
+	return err;
+
+}
+
+/* ppc FW load - imem and profile table */
+int mv_pp3_ppc_fw_load(int ppc)
+{
+	int err = -ENOENT;
+
+	if (mv_pp3_fw_path)
+		err = mv_pp3_ppc_fw_image_download(ppc, mv_pp3_fw_path, PPC_MEM_IMEM);
+	if (err) {
+		err = mv_pp3_ppc_fw_image_download(ppc, NULL, PPC_MEM_IMEM);
+		if (err)
+			return err;
+	}
+	err = -ENOENT;
+	if (mv_pp3_fw_path)
+		err = mv_pp3_ppc_fw_image_download(ppc, mv_pp3_fw_path, PPC_MEM_PROF);
+	if (err) {
+		err = mv_pp3_ppc_fw_image_download(ppc, NULL, PPC_MEM_PROF);
+		if (err)
+			return err;
+	}
+
+	mv_pp3_ppc_dram_buffers_set(ppc);
+
+	return 0;
+}
+
+int mv_pp3_fw_load(void)
+{
+	int  err, ppc = 0;
+
+	/* init base address */
+	apb_base_addr = mv_pp3_nss_regs_vaddr_get();
+
+	/*load FW to all PPCs */
+	for (ppc = 0; ppc < active_ppc_num; ppc++) {
+		err = mv_pp3_ppc_fw_load(ppc);
+		if (err) {
+			pr_err("%s: FW load to ppc %d failed\n", __func__, ppc);
+			return -1;
+		}
+	}
+
+	/* load FW to search engine */
+	err = mv_pp3_se_fw_init();
+	if (err) {
+		pr_err("%s: FW load to search engine failed\n", __func__);
+		return -1;
+	}
+	return 0;
+}
+
+/* set path for FW files download */
+/* allocate buffer with additional place for file name concatination */
+
+void mv_pp3_fw_path_set(u8 *path)
+{
+	int s_size = strlen(path) + sizeof("imem_addr_data.txt");
+
+	if (!mv_pp3_fw_path)
+		kfree(mv_pp3_fw_path);
+
+	mv_pp3_fw_path = kmalloc(s_size, GFP_KERNEL);
+	if (!mv_pp3_fw_path)
+		return;
+
+	strcpy(mv_pp3_fw_path, path);
+}
+
+int mv_pp3_fw_half_range_addr_cfg(void)
+{
+	unsigned int resp_data[MV_EC_ENG2APB_DATA_REGS_NUM];
+	void __iomem *curr_apb_address;
+	int i;
+
+	/* clear the status register */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_ENG2APB_RESPONSE_STATUS_REG, 7);
+	/* request opcode */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_APB2ENG_REQ_OPCODE_REG, 1);
+	/* address 0x50, trigger, SE_dual */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_APB2ENG_REQ_ADDR_CNTRL_REG, 0x01500050);
+	/* read status and wait for done to be set */
+	if (!fw_ec_eng2apb_response_status_check())
+		return -1;
+
+	/* read response data */
+	/* resp_data[0] = word 3 with address 0xd7080, resp_data[3] = word 0 with address 0xd708c */
+	for (i = 0; i < MV_EC_ENG2APB_DATA_REGS_NUM; i++)
+		resp_data[i] = mv_pp3_hw_reg_read(apb_base_addr + MV_EC_ENG2APB_RESPONSE_DATA3_REG + (i * 4));
+
+	/* clear the status register */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_ENG2APB_RESPONSE_STATUS_REG, 7);
+	/* request opcode */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_APB2ENG_REQ_OPCODE_REG, 2);
+
+	/* resp_data[0] = word 3 with address 0xd7080 */
+	/* clear bit 5 in byte 13 */
+	resp_data[0] = resp_data[0] & ~(1 << 13);
+	/* write new configuration */
+	for (i = 0; i < MV_EC_ENG2APB_DATA_REGS_NUM; i++) {
+		curr_apb_address = apb_base_addr + MV_EC_APB2ENG_REQUEST_DATA3_REG + (i * 4);
+		mv_pp3_hw_reg_write(curr_apb_address, resp_data[i]);
+	}
+	/* address 0x50, trigger, SE_dual */
+	mv_pp3_hw_reg_write(apb_base_addr + MV_EC_APB2ENG_REQ_ADDR_CNTRL_REG, 0x01500050);
+	/* read status and wait for done to be set */
+	if (!fw_ec_eng2apb_response_status_check())
+		return -1;
+
+	return 0;
+}
+
+static void mv_pp3_ppc_run(int ppc)
+{
+	void __iomem *base_addr;
+
+	base_addr = apb_base_addr + MV_DP_PPC_BASE(ppc);
+	mv_pp3_hw_reg_write(base_addr + MV_PPC_IMEM_HOLD_OFF_REG, 0);
+
+}
+
+
+void mv_pp3_ppc_run_all(void)
+{
+	int  ppc;
+
+	/* calculate EAP start address */
+	for (ppc = 0; ppc < active_ppc_num; ppc++)
+		mv_pp3_ppc_run(ppc);
+
+	mdelay(1);
+	for (ppc = 0; ppc < active_ppc_num; ppc++) {
+		ppc_ppn_mask[ppc] = mv_pp3_hw_reg_read(apb_base_addr + MV_DP_PPC_BASE(ppc) + MV_PPC_WAIT_FOR_DEQ_REG);
+		pr_info("Start PPC #%d with 0x%x active PPNs mask\n", ppc, ppc_ppn_mask[ppc]);
+	}
+}
+int mv_pp3_fw_init(struct mv_pp3 *priv)
+{
+	int ppc, err;
+
+	pp3_fw_priv = priv;
+
+	/* alloc DRAM for each active PPC */
+	for (ppc = 0; ppc < active_ppc_num; ppc++) {
+		err = mv_pp3_ppc_dram_allocation(ppc);
+		if (err)
+			return err;
+	}
+	return 0;
+
+}
+
+static int mv_pp3_ppc_idle_wait(int ppc)
+{
+	void __iomem *base_addr;
+	u32 busy, dq;
+	u32 count;
+
+	base_addr = apb_base_addr + MV_DP_PPC_BASE(ppc);
+
+	count = 0;
+	do {
+		busy = mv_pp3_hw_reg_read(base_addr + MV_PPC_BUSY_REG);
+		if (busy)
+			udelay(1);
+		else {
+			dq = mv_pp3_hw_reg_read(base_addr + MV_PPC_WAIT_FOR_DEQ_REG);
+			if (dq == ppc_ppn_mask[ppc])
+				return 0;
+			else
+				udelay(1);
+		}
+	} while (count < 100);
+	pr_err("%s: Cannot stop PPC #%d (busy = 0x%x, dq = 0x%x)\n", __func__, ppc, busy, dq);
+
+	return 1;
+}
+
+int mv_pp3_ppc_idle_wait_all(void)
+{
+	int ppc;
+	int err = 0;
+
+	for (ppc = 0; ppc < active_ppc_num; ppc++)
+		err += mv_pp3_ppc_idle_wait(ppc);
+
+	return err;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_fw.h b/drivers/net/ethernet/marvell/pp3/fw/mv_fw.h
new file mode 100644
index 0000000..79ea228
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_fw.h
@@ -0,0 +1,112 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_fw_h__
+#define __mv_fw_h__
+
+#include "platform/mv_pp3.h"
+
+/* IMEM size 196KB */
+#define MV_PP3_FW_MAX_SIZE (196 * 1024)
+#define MV_PP3_FW_MAX_ROWS (MV_PP3_FW_MAX_SIZE / 4)
+#define MV_FW_MAX_LINE_SIZE (128)
+
+#define MV_MAX_FW_FILE_PATH	(128)
+
+/* datapath ppc */
+#define MV_DP_PPC_BASE(ppc)		MV_PPC_BASE(ppc+1)
+
+enum ppc_mem_type {
+	PPC_MEM_IMEM,
+	PPC_MEM_CFG,
+	PPC_MEM_PROF,
+	PPC_MEM_SE_CFG,
+	PPC_MEM_SRAM,
+	PPC_MEM_SPAD,
+	PPC_MEM_INVALID
+};
+
+
+struct mem_rec {
+	u32 address;
+	u32 data;
+};
+
+struct mem_image {
+	struct mem_rec *rows;
+	u32 size;
+	u32 allocated;
+	enum ppc_mem_type type;
+	u32 offset;
+	u32 mask;
+};
+
+int mv_pp3_fw_memory_alloc(struct mv_pp3 *priv);
+void mv_pp3_fw_memory_free(struct mv_pp3 *priv);
+
+void mv_pp3_fw_path_set(u8 *path);
+void mv_pp3_ppc_run_all(void);
+int mv_pp3_ppc_idle_wait_all(void);
+
+int mv_pp3_se_fw_image_download(char *dir);
+int mv_pp3_ppc_fw_image_download(int ppc, char *dir, unsigned int mem_type);
+int mv_pp3_cfg_download(char *path);
+int mv_pp3_fw_image_load(struct mem_image *ptr_to_image);
+int mv_pp3_fw_dram_allocation(void);
+int mv_pp3_fw_init(struct mv_pp3 *priv);
+int mv_pp3_fw_load(void);
+int mv_pp3_imem_dump(char *path);
+int mv_pp3_fw_half_range_addr_cfg(void);
+
+int mv_pp3_profile_dump(char *path);
+
+int mv_pp3_cfg_dump(char *path);
+
+int mv_pp3_fw_read_file(char *path, char *buf, int size);
+int mv_pp3_fw_write_file(char *path, char *buf, int size);
+int mv_pp3_fw_read_img_file(char *path, struct mem_image *img);
+
+int mv_fw_mem_write(char *data, int size, unsigned int target_mem);
+int mv_fw_mem_read(char *data, int size, unsigned int source_mem);
+
+int mv_fw_mem_img_write(struct mem_image *img, unsigned int mem_type);
+
+
+int mv_fw_pkts_rec_dump(int ppc, u32 start_entry, int size);
+int mv_fw_sp_dump(int ppc, u32 ppn_numb, u32 buf_index, u32 start_sp_adr, u32 size);
+int mv_fw_inf_logger_dump(int ppc, u32 ppn_numb, u32 start_lg_entry, int size);
+int mv_fw_critical_logger_dump(int ppc, u32 ppn_numb, u32 start_lg_entry, int size);
+void mv_fw_keep_alive_dump(int ppc);
+
+int mv_pp3_fw_ppc_num_set(int ppc_num);
+int mv_pp3_fw_ppc_num_get(void);
+/* SYSFS*/
+int mv_pp3_fw_sysfs_init(struct kobject *fw_kobj);
+int mv_pp3_fw_sysfs_exit(struct kobject *fw_kobj);
+
+#endif /* __mv_fw_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_fw_regs.h b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_regs.h
new file mode 100644
index 0000000..cbbdb22
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_regs.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_fw_regs_h__
+#define __mv_fw_regs_h__
+
+/*
+	0 - maintenance PPC
+	1 - datapath PPC0
+	2 - datapath PPC1
+*/
+
+#define MV_PPC_BASE(ppc)		(0x800000 + ((ppc)*0x80000))
+
+/* PPC memories */
+#define MV_PPC_IMEM_OFFS		0x000000
+#define MV_PPC_IMEM_MASK		0x1FFFFF
+
+#define MV_PPC_SHARED_MEM_OFFS		0x50000
+
+#define MV_PPC_PROF_MEM_OFFS		0x78000
+#define MV_PPC_PROF_MEM_MASK		0x0FFFF
+
+/* PPC registers */
+#define MV_PPC_IMEM_HOLD_OFF_REG	0x7F034
+#define MV_PPC_WAIT_FOR_DEQ_REG		0x7F038
+#define MV_PPC_BUSY_REG			0x7F03C
+
+#define MV_NSS_SE_OFFS			0xD7000
+#define MV_NSS_SE_MASK			0x00FFF
+
+/* Search engine registers */
+#define MV_EC_ENG2APB_DATA_REGS_NUM         4
+#define MV_EC_APB2ENG_REQ_OPCODE_REG        0xd7060
+#define MV_EC_APB2ENG_REQ_ADDR_CNTRL_REG    0xd7064
+#define MV_EC_ENG2APB_RESPONSE_STATUS_REG   0xd7068
+#define MV_EC_APB2ENG_REQUEST_DATA3_REG     0xd7070
+#define MV_EC_APB2ENG_REQUEST_DATA2_REG     0xd7074
+#define MV_EC_APB2ENG_REQUEST_DATA1_REG     0xd7078
+#define MV_EC_APB2ENG_REQUEST_DATA0_REG     0xd707C
+#define MV_EC_ENG2APB_RESPONSE_DATA3_REG    0xd7080
+#define MV_EC_ENG2APB_RESPONSE_DATA2_REG    0xd7084
+#define MV_EC_ENG2APB_RESPONSE_DATA1_REG    0xd7088
+#define MV_EC_ENG2APB_RESPONSE_DATA0_REG    0xd708C
+
+#endif /* __mv_fw_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_fw_shared.h b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_shared.h
new file mode 100644
index 0000000..253aa6a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_shared.h
@@ -0,0 +1,153 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_fw_shared_h__
+#define __mv_fw_shared_h__
+
+/* SW- FW shared parameters definitions */
+
+/* FW utilities 4 (do not change) DRAM memory separate blocks :
+_________________________________|_______start address___________|___size____|
+SP_MIRRORING_DRAM_BUFFER         |     A                         | 0x80000   |
+PACKET_RECORDING_DRAM_BUFFER     |     B                         | 0x80000   |
+LOGGER_DRAM_BUFFER:              |     C                         | 0x24000   |
+-     Information buffer         |     C                         | 0x20000   |
+-     Critical buffer            |     C + 0x20000               |  0x4000   |
+KEEP_ALIVE_BUFFER                |     D                         |   0x400   |
+
+All 4 memory blocks are allocated per PPC.
+*/
+/* Do not change: DRAM memory blocks list */
+enum mv_fw_dram_blocks {
+	SP_MIRRORING_BUFFER = 0,
+	PACKET_RECORDING_BUFFER,
+	LOGGER_BUFFER,
+	KEEP_ALIVE_BUFFER,
+	LAST_DRAM_BUFFER = 4
+};
+
+#define NUMBER_OF_PPNs    16
+
+#define DRAM_FOR_FW_SHARED_SRAM_OFFSET   0x10
+
+#define SP_SIZE                            2560		/* 2.5K Scratch Pad size */
+#define LOGGER_ENTRY_SIZE                  16
+#define KEEP_ALIVE_ENTRY_SIZE              4
+
+#define MAX_SP_MIRROR_BUF_NUMB             16
+#define MAX_INF_LOG_ENTRY_NUMB            512
+#define MAX_CRITICAL_LOG_ENTRY_NUMB        64
+
+#define SP_MIRRORING_PER_PPN_DRAM_BUFFER_SIZE        (SP_SIZE * MAX_SP_MIRROR_BUF_NUMB)
+#define SP_MIRRORING_DRAM_BUFFER_SIZE                (SP_MIRRORING_PER_PPN_DRAM_BUFFER_SIZE * NUMBER_OF_PPNs)
+
+#define PACKET_RECORDING_DRAM_BUFFER_SIZE            (MAX_INF_LOG_ENTRY_NUMB * 1024)
+#define KEEP_ALIVE_BUFFER_SIZE                       (NUMBER_OF_PPNs * KEEP_ALIVE_ENTRY_SIZE)
+
+#define INFORMATION_LOGGER_PER_PPN_DRAM_BUFFER_SIZE  (LOGGER_ENTRY_SIZE * MAX_INF_LOG_ENTRY_NUMB)
+#define INFORMATION_LOGGER_DRAM_BUFFER_SIZE          (INFORMATION_LOGGER_PER_PPN_DRAM_BUFFER_SIZE * NUMBER_OF_PPNs)
+
+#define CRITICAL_LOGGER_PER_PPN_DRAM_BUFFER_SIZE     (LOGGER_ENTRY_SIZE * MAX_CRITICAL_LOG_ENTRY_NUMB)
+#define CRITICAL_LOGGER_DRAM_BUFFER_SIZE             (CRITICAL_LOGGER_PER_PPN_DRAM_BUFFER_SIZE * NUMBER_OF_PPNs)
+
+#define LOGGER_BUFFER_SIZE                        \
+			(INFORMATION_LOGGER_DRAM_BUFFER_SIZE + CRITICAL_LOGGER_DRAM_BUFFER_SIZE)
+
+#define LOGGER_CRITICAL_DRAM_OFFSET           (INFORMATION_LOGGER_DRAM_BUFFER_SIZE)
+
+
+/* CFH related */
+#define MV_CFH_MSG_OFFS		(32)	/* bytes */
+
+#define MV_CFH_FW_MSG_HEADER_SIZE	(2)	/* words */
+#define MV_CFH_FW_MSG_HEADER_BYTES	(MV_CFH_FW_MSG_HEADER_SIZE * 4)	/* bytes */
+
+/* Host to FW message types */
+enum mv_pp3_h2f_msg_type {
+	H2F_NO_ACK_REQ = 0,
+	H2F_ACK_REPLY_REQ
+};
+
+/* FW to Host message type */
+enum mv_pp3_f2h_msg_type {
+	F2H_PPN_EVENT = 0,
+	F2H_ACK_REPLY
+};
+
+/* Clients list */
+enum mv_pp3_fw_clients {
+	MV_DRIVER_CL_ID = 0,
+	MV_DPAPI_CL_ID,
+
+	MV_LAST_CL_ID
+};
+
+/* CFH message header data structure */
+struct mv_pp3_fw_msg_header {
+	unsigned int word0;		/* msg size[31:16], number of instanse to/from FW */
+	unsigned int word1;		/*  */
+};
+
+/* FW message header fields macros. All fields offsets are start bit in current word */
+/* word 0 */
+#define MV_HOST_MSG_INST_NUM_OFFS	(0)
+#define MV_HOST_MSG_INST_NUM_MASK	(0xFFFF)
+#define MV_HOST_MSG_INST_NUM_SET(v)	(((v) & MV_HOST_MSG_INST_NUM_MASK) << MV_HOST_MSG_INST_NUM_OFFS)
+#define MV_HOST_MSG_INST_NUM_GET(v)	(((v) >> MV_HOST_MSG_INST_NUM_OFFS) & MV_HOST_MSG_INST_NUM_MASK)
+
+#define MV_HOST_MSG_SIZE_OFFS		(16)
+#define MV_HOST_MSG_SIZE_MASK		(0xFFFF)
+#define MV_HOST_MSG_SIZE_SET(v)		(((v) & MV_HOST_MSG_SIZE_MASK) << MV_HOST_MSG_SIZE_OFFS)
+#define MV_HOST_MSG_SIZE_GET(v)		(((v) >> MV_HOST_MSG_SIZE_OFFS) & MV_HOST_MSG_SIZE_MASK)
+
+/* word 1 */
+#define MV_HOST_MSG_SEQ_NUM_OFFS	(0)
+#define MV_HOST_MSG_SEQ_NUM_MASK	(0xFFF)
+#define MV_HOST_MSG_SEQ_NUM_SET(v)	(((v) & MV_HOST_MSG_SEQ_NUM_MASK) << MV_HOST_MSG_SEQ_NUM_OFFS)
+#define MV_HOST_MSG_SEQ_NUM_GET(v)	(((v) >> MV_HOST_MSG_SEQ_NUM_OFFS) & MV_HOST_MSG_SEQ_NUM_MASK)
+
+#define MV_HOST_MSG_RC_OFFS		(12)
+#define MV_HOST_MSG_RC_MASK		(0xF)
+#define MV_HOST_MSG_RC_GET(v)		(((v) >> MV_HOST_MSG_RC_OFFS) & MV_HOST_MSG_RC_MASK)
+
+#define MV_HOST_MSG_OPCODE_OFFS		(16)
+#define MV_HOST_MSG_OPCODE_MASK		(0xFFF)
+#define MV_HOST_MSG_OPCODE_SET(v)	(((v) & MV_HOST_MSG_OPCODE_MASK) << MV_HOST_MSG_OPCODE_OFFS)
+#define MV_HOST_MSG_OPCODE_GET(v)	(((v) >> MV_HOST_MSG_OPCODE_OFFS) & MV_HOST_MSG_OPCODE_MASK)
+
+#define MV_HOST_MSG_EXT_HDR_OFFS	(28)
+#define MV_HOST_MSG_EXT_HDR_MASK	(0x3)
+#define MV_HOST_MSG_EXT_HDR_SET(v)	(((v) & MV_HOST_MSG_EXT_HDR_MASK) << MV_HOST_MSG_EXT_HDR_OFFS)
+#define MV_HOST_MSG_EXT_HDR_GET(v)	(((v) >> MV_HOST_MSG_EXT_HDR_OFFS) & MV_HOST_MSG_EXT_HDR_MASK)
+
+#define MV_HOST_MSG_ACK_OFFS		(30)
+#define MV_HOST_MSG_ACK_MASK		(1)
+#define MV_HOST_MSG_ACK_SET(v)		(((v) & MV_HOST_MSG_ACK_MASK) << MV_HOST_MSG_ACK_OFFS)
+#define MV_HOST_MSG_ACK_GET(v)		(((v) >> MV_HOST_MSG_ACK_OFFS) & MV_HOST_MSG_ACK_MASK)
+
+#endif /* __mv_fw_shared_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_fw_sysfs.c b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_sysfs.c
new file mode 100644
index 0000000..f430e14
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_fw_sysfs.c
@@ -0,0 +1,406 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/platform_device.h>
+#include "mv_fw.h"
+#include "mv_pp3_fw_msg.h"
+
+static ssize_t mv_fw_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                               version         - show FW version\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [path]                     > fw_path         - define FW images folder\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [num]                      > ppc_active      - number of active PPCs\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ppc] [ppn] [entry] [numb] > inf_lg_dump     - informational logger dump\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ppc] [ppn] [entry] [numb] > cr_lg_dump      - critical logger dump\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ppc]                      > keep_alive_dump - show Keep Alive array\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [port]                     > emac_vp_show    - show EMAC virtual port status\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [port]                     > vp_stats        - show virtual port FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [queue]                    > hwq_stats       - show HW queue FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [queue]                    > swq_stats       - show SW queue FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [pool]                     > bmpool_stats    - show BM pool FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [channel]                  > chan_stats      - show message channel FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [st] [ind]                 > clear_stats     - clear FW statistics by type, 0 - all\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ppc]     - PPC number (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ppn]     - PPN number in current PPC (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [entry]   - start entry number (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [numb]    - number of entries to print (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [port]    - virtual port number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [queue]   - queue number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [pool]    - pool number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [channel] - message channel number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [st]      - statistics type: 0-all, 1-vport, 2-hwq, 3-swq, 4-bm pool, 5-channel\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ind]     - index according to statistics type\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [num]     - number of active PPCs (decimal)\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_fw_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             rc, off = 0;
+	struct mv_pp3_version fw_ver;
+	char version_name[MV_PP3_VERSION_NAME_SIZE + 1];
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "version")) {
+		rc = pp3_fw_version_get(&fw_ver);
+		if (rc) {
+			pr_err("FW version is unknown. rc = %d\n", rc);
+			return 0;
+		}
+		memcpy(version_name, fw_ver.name, MV_PP3_VERSION_NAME_SIZE);
+		version_name[MV_PP3_VERSION_NAME_SIZE] = '\0';
+		pr_info("FW version:     %s:%d.%d.%d.%d\n",
+				version_name, fw_ver.major_x, fw_ver.minor_y, fw_ver.local_z, fw_ver.debug_d);
+	} else
+		off = mv_fw_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_fw_store(struct device *dev,
+			   struct device_attribute *attr, const char *buf,
+			   size_t len)
+{
+	const char *name = attr->attr.name;
+	unsigned int    a, b, c, d;
+	int err;
+	int fields;
+	char str[128] = "/0";
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = a = b = c = 0;
+
+	if (!strcmp(name, "fw_path")) {
+		sscanf(buf, "%s", str);
+		mv_pp3_fw_path_set(str);
+	} else if (!strcmp(name, "inf_lg_dump")) {
+		fields = sscanf(buf, "%d %d %d %d", &a, &b, &c, &d);
+		if (fields == 4)
+			mv_fw_inf_logger_dump(a, b, c, d);
+		else
+			err = 1;
+	} else if (!strcmp(name, "ppc_active")) {
+		fields = sscanf(buf, "%d", &a);
+		if (fields == 1)
+			err = mv_pp3_fw_ppc_num_set(a);
+		else
+			err = 1;
+	} else if (!strcmp(name, "cr_lg_dump")) {
+		fields = sscanf(buf, "%d %d %d %d", &a, &b, &c, &d);
+		if (fields == 4)
+			mv_fw_critical_logger_dump(a, b, c, d);
+		else
+			err = 1;
+	} else if (!strcmp(name, "keep_alive_dump")) {
+		fields = sscanf(buf, "%d", &a);
+		if (fields == 1)
+			mv_fw_keep_alive_dump(a);
+		else
+			err = 1;
+	} else if (!strcmp(name, "emac_vp_show")) {
+		int i;
+		unsigned char valid_macs;
+		unsigned char macs_list[MV_PP3_MAC_ADDR_NUM][MV_MAC_ADDR_SIZE];
+		char prefix[16];
+
+		fields = sscanf(buf, "%d", &a);
+		if (fields == 1) {
+			if (a > MV_NSS_ETH_PORT_MAX) {
+				pr_info("Not supported for vp=%d. Only for EMAC virtual ports [%d..%d]\n",
+					a, MV_NSS_ETH_PORT_MIN, MV_NSS_ETH_PORT_MAX);
+				goto out;
+			}
+			pp3_fw_emac_vport_msg_show(a);
+
+			err = pp3_fw_vport_mac_list_get(a, MV_PP3_MAC_ADDR_NUM, &macs_list[0][0],
+						&valid_macs);
+			if (!err) {
+				pr_info("%d valid MAC addresses\n", valid_macs);
+				for (i = 0; i < valid_macs; i++) {
+					sprintf(prefix, "%2d: ", i);
+					mv_mac_addr_print(prefix, &macs_list[i][0], NULL);
+				}
+			}
+		} else
+			err = 1;
+	} else if (!strcmp(name, "vp_stats")) {
+		fields = sscanf(buf, "%d", &a);
+		if (fields == 1)
+			mv_pp3_vport_fw_stats_dump(a);
+		else
+			err = 1;
+	} else if (!strcmp(name, "hwq_stats")) {
+		struct mv_pp3_fw_hwq_stat hwq_stats;
+
+		sscanf(buf, "%d", &a);
+		if (pp3_fw_hwq_stat_get((unsigned short)a, false, &hwq_stats) == 0)
+			pp3_fw_hwq_stat_print(&hwq_stats);
+
+	} else if (!strcmp(name, "swq_stats")) {
+		struct mv_pp3_fw_swq_stat swq_stats;
+
+		sscanf(buf, "%d", &a);
+		if (pp3_fw_swq_stat_get(a, &swq_stats) == 0)
+			/* print statistic */
+			pp3_fw_swq_stat_print(&swq_stats);
+
+	} else if (!strcmp(name, "bmpool_stats")) {
+		struct mv_pp3_fw_bm_pool_stat pool_stat;
+		unsigned char param;
+
+		sscanf(buf, "%d", &a);
+		param = (unsigned char)a;
+		if (pp3_fw_bm_pool_stat_get(param, &pool_stat) == 0)
+			pp3_fw_bmpool_stat_print(&pool_stat);
+	} else if (!strcmp(name, "chan_stats")) {
+		struct mv_pp3_fw_msg_chan_stat msg_stat;
+		unsigned char param;
+
+		sscanf(buf, "%d", &a);
+		param = (unsigned char)a;
+		if (pp3_fw_channel_stat_get(param, &msg_stat) == 0)
+			/* print statistic */
+			pp3_fw_msg_stat_print(&msg_stat);
+	} else if (!strcmp(name, "clear_stats")) {
+
+		sscanf(buf, "%d %d", &a, &b);
+		if (pp3_fw_clear_stat_set((unsigned char) a, b) != 0)
+			pr_info("Command failed");
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__,
+		       attr->attr.name);
+	}
+out:
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, mv_fw_show, NULL);
+static DEVICE_ATTR(version,		S_IRUSR, mv_fw_show, NULL);
+static DEVICE_ATTR(fw_path,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(inf_lg_dump,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(ppc_active,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(cr_lg_dump,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(keep_alive_dump,	S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(emac_vp_show,	S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(vp_stats,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(hwq_stats,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(swq_stats,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(bmpool_stats,	S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(chan_stats,		S_IWUSR, NULL, mv_fw_store);
+static DEVICE_ATTR(clear_stats,		S_IWUSR, NULL, mv_fw_store);
+
+
+static struct attribute *mv_fw_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_version.attr,
+	&dev_attr_fw_path.attr,
+	&dev_attr_inf_lg_dump.attr,
+	&dev_attr_ppc_active.attr,
+	&dev_attr_cr_lg_dump.attr,
+	&dev_attr_keep_alive_dump.attr,
+	&dev_attr_emac_vp_show.attr,
+	&dev_attr_vp_stats.attr,
+	&dev_attr_hwq_stats.attr,
+	&dev_attr_swq_stats.attr,
+	&dev_attr_bmpool_stats.attr,
+	&dev_attr_chan_stats.attr,
+	&dev_attr_clear_stats.attr,
+
+	NULL
+};
+
+static struct attribute_group mv_fw_group = {
+	.attrs = mv_fw_attrs,
+};
+
+
+static ssize_t mv_fw_debug_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b + o, PAGE_SIZE - o,
+		       "echo [ppc] [path]                > imem_dnld     - Download PPC IMEM from file\n");
+	o += scnprintf(b + o, PAGE_SIZE - o,
+		       "echo [ppc] [path]                > profile_dnld  - Download PPC profile table from file\n");
+	o += scnprintf(b + o, PAGE_SIZE - o,
+		       "echo [path]                      > se_dnld       - Download SE from file\n");
+	o += scnprintf(b + o, PAGE_SIZE - o,
+		       "echo                             > ppn_run       - Run PPN\n");
+	o += sprintf(b + o,
+		       "echo [ppc][ppn][ind][adr][words] > sp_dump       - Print SP contents\n");
+	o += sprintf(b + o,
+		       "echo [ppc][adr][words]           > rec_dump      - Print messages/packets buffer contents\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\nparameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ppc]   - PPC number (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ppn]   - PPN number in current PPC (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ind]   - index of SP_image array (decimal)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [adr]   - offset to print (hex)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [words] - words number to print (decimal)\n");
+
+
+	return o;
+}
+
+static ssize_t mv_fw_debug_show(struct device *dev,
+			  struct device_attribute *attr, char *buf)
+{
+	/* TODO: const char      *name = attr->attr.name; */
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_fw_debug_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_fw_debug_store(struct device *dev,
+			   struct device_attribute *attr, const char *buf,
+			   size_t len)
+{
+	const char *name = attr->attr.name;
+	unsigned int    a, b, c, d, e;
+	int err;
+	int fields;
+	char str[128] = "/0";
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = a = b = c = d = 0;
+
+	if (!strcmp(name, "imem_dnld")) {
+		fields = sscanf(buf, "%d %s", &a, str);
+		err = (fields != 2) ? 1 : 0;
+		mv_pp3_ppc_fw_image_download(a, str, PPC_MEM_IMEM);
+	} else if (!strcmp(name, "profile_dnld")) {
+		fields = sscanf(buf, "%d %s", &a, str);
+		err = (fields != 2) ? 1 : 0;
+		mv_pp3_ppc_fw_image_download(a, str, PPC_MEM_PROF);
+	} else if (!strcmp(name, "se_dnld")) {
+		fields = sscanf(buf, "%s", str);
+		err = (fields != 1) ? 1 : 0;
+		mv_pp3_se_fw_image_download(str);
+	} else if (!strcmp(name, "ppn_run")) {
+		mv_pp3_ppc_run_all();
+	} else if (!strcmp(name, "rec_dump")) {
+		fields = sscanf(buf, "%d %x %d", &a, &b, &c);
+		err = (fields != 3) ? 1 : 0;
+		mv_fw_pkts_rec_dump(a, b, c);
+	} else if (!strcmp(name, "sp_dump")) {
+		fields = sscanf(buf, "%d %d %d %x %d", &a, &b, &c, &d, &e);
+		err = (fields != 5) ? 1 : 0;
+		mv_fw_sp_dump(a, b, c, d, e);
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__,
+		       attr->attr.name);
+	}
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help_debug,		S_IRUSR, mv_fw_debug_show, NULL);
+static DEVICE_ATTR(imem_dnld,		S_IWUSR, NULL, mv_fw_debug_store);
+static DEVICE_ATTR(se_dnld,		    S_IWUSR, NULL, mv_fw_debug_store);
+static DEVICE_ATTR(profile_dnld,	S_IWUSR, NULL, mv_fw_debug_store);
+static DEVICE_ATTR(ppn_run,		    S_IWUSR, NULL, mv_fw_debug_store);
+static DEVICE_ATTR(sp_dump,		S_IWUSR, NULL, mv_fw_debug_store);
+static DEVICE_ATTR(rec_dump,		S_IWUSR, NULL, mv_fw_debug_store);
+
+static struct attribute *mv_fw_debug_attrs[] = {
+	&dev_attr_help_debug.attr,
+	&dev_attr_imem_dnld.attr,
+	&dev_attr_se_dnld.attr,
+	&dev_attr_profile_dnld.attr,
+	&dev_attr_ppn_run.attr,
+	&dev_attr_sp_dump.attr,
+	&dev_attr_rec_dump.attr,
+
+	NULL
+};
+static struct attribute_group mv_fw_debug_group = {
+	.name = "debug",
+	.attrs = mv_fw_debug_attrs,
+};
+
+
+int mv_pp3_fw_sysfs_init(struct kobject *neta_kobj)
+{
+	int err;
+	struct kobject *fw_kobj;
+
+
+	fw_kobj = kobject_create_and_add("fw", neta_kobj);
+	if (!fw_kobj) {
+		printk(KERN_ERR"%s: cannot create fw kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(fw_kobj, &mv_fw_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for fw %d\n", err);
+		return err;
+	}
+
+	err = sysfs_create_group(fw_kobj, &mv_fw_debug_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for bm debug%d\n", err);
+		return err;
+	}
+
+
+	return err;
+}
+
+int mv_pp3_fw_sysfs_exit(struct kobject *neta_kobj)
+{
+	sysfs_remove_group(neta_kobj, &mv_fw_debug_group);
+	sysfs_remove_group(neta_kobj, &mv_fw_group);
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.c b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.c
new file mode 100644
index 0000000..4674921
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.c
@@ -0,0 +1,850 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <linux/completion.h>
+#include <linux/bug.h>
+#include <linux/list.h>
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "vport/mv_pp3_vport.h"
+#include "vport/mv_pp3_pool.h"
+#include "vport/mv_pp3_cpu.h"
+#include "msg/mv_pp3_msg_drv.h"
+#include "fw/mv_pp3_fw_msg_structs.h"
+
+#ifdef CONFIG_MV_PP3_FPGA
+#include "gmac/mv_gmac.h"
+#else /* CONFIG_MV_PP3_FPGA */
+#include "gop/mv_gop_if.h"
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+
+static void pp3_fw_struct_size_checker(void)
+{
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_msg_chan_cfg) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_version) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_emac_vport) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_cpu_vport) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_internal_cpu_port) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_cpu_vport_map) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_mac_list) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_mtu) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_def_dest) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_rx_pkt_mode) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vq_map) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_cos_to_vq) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_bm_pool) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_mac) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_l2_option) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_vport_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_hwq_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_swq_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_bm_pool_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_msg_chan_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_mem_get) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_mem_set) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_reset_stat) % 4);
+	BUILD_BUG_ON(sizeof(struct mv_pp3_fw_link_change_note) % 4);
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Callback function used for wait to responce from FW and check return
+	info
+---------------------------------------------------------------------------*/
+static void drv_msg_cb_with_complete(struct drv_msg_cb_params *p)
+{
+	/*pr_info("Get response from FW for request N%d, return code 0x%x\n", p->req_num, p->ret_code);*/
+	complete(&(p->complete));
+
+	return;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send any request to FW, wait for acknowledge and check
+	return status.
+inputs:
+	opcode - request opcode
+	in_p   - request structure
+	in_size - size of request structure in bytes
+outputs:
+	stat - requested data converted to LE
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+static inline int pp3_fw_set_wait_req(int opcode, void *in_p, int in_size, void *out_p, int out_size)
+{
+	struct drv_msg_cb_params req_params;
+	struct request_info req_info;
+	int req_num;
+
+	init_completion(&req_params.complete);
+
+	/* send message */
+	req_info.msg_opcode = opcode;
+	req_info.in_param = in_p;
+	req_info.size_of_input = in_size;
+	req_info.out_buff = out_p;
+	req_info.size_of_output = out_size;
+	req_info.req_cb = (void (*)(void *))drv_msg_cb_with_complete;
+	req_info.cb_params = &req_params;
+	req_info.num_of_ints = 1;
+
+	req_num = mv_pp3_drv_request_send(&req_info);
+	/* The return value is 0 if timed out, and positive (at least 1, or number of
+	 jiffies left till timeout) if completed. */
+	if (wait_for_completion_interruptible_timeout(&req_params.complete, 1000) == 0) {
+		pr_err("No response from FW for request N%d with opcode %d\n", req_num, opcode);
+		/* delete request from list head */
+		mv_pp3_drv_request_delete(req_num);
+		return -1;
+	}
+	/* convert reply to OK/FAIL status */
+	if (req_params.ret_code != 0) {
+		pr_err("Get bad response from FW for request N%d return code 0x%x\n",
+			req_params.req_num, req_params.ret_code);
+			return -1;
+	}
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send simple "set request" request to FW, no wait for acknowledge and check
+	return status.
+inputs:
+	opcode - request opcode
+	in_p   - request structure
+	in_size - size of request structure in bytes
+outputs:
+	none
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+static inline int pp3_fw_set_simple_req(enum mv_pp3_fw_msg_opcode opcode, void *in_p, int in_size)
+{
+	struct request_info req_info;
+	int ret_val;
+
+	/* send message */
+	req_info.msg_opcode = opcode;
+	req_info.in_param = in_p;
+	req_info.size_of_input = in_size;
+	req_info.out_buff = NULL;
+	req_info.size_of_output = 0;
+	req_info.req_cb = NULL;
+	req_info.cb_params = NULL;
+	req_info.num_of_ints = 1;
+
+	ret_val = mv_pp3_drv_request_send(&req_info);
+	return ret_val;
+}
+
+/* get FW version info */
+int pp3_fw_version_get(struct mv_pp3_version *fw_ver)
+{
+	return pp3_fw_set_wait_req(MV_FW_VERSION_GET, NULL, 0, fw_ver, sizeof(struct mv_pp3_version));
+}
+
+
+/* Set RX packet mode for Vport */
+int pp3_fw_vport_rx_pkt_mode_set(int vport, enum mv_pp3_pkt_mode mode)
+{
+	struct mv_pp3_fw_vport_rx_pkt_mode msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_rx_pkt_mode));
+	msg.int_cpu_port = cpu_to_be16((unsigned short)vport);
+	msg.rx_pkt_mode = (unsigned char)mode;
+
+	return pp3_fw_set_simple_req(MV_FW_INTERNAL_CPU_PORT_RX_PKT_MODE_SET,
+					&msg, sizeof(struct mv_pp3_fw_vport_rx_pkt_mode));
+}
+
+/*---------------------------------------------------------------------------
+ description:
+	Link change event message. When lik up send speed and duplex configuration
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+
+---------------------------------------------------------------------------*/
+int pp3_fw_link_changed(int emac_num, bool link_is_up)
+{
+	struct mv_pp3_fw_link_change_note msg;
+	struct mv_port_link_status port_cfg;
+
+	msg.emac_num = (unsigned char)emac_num;
+	msg.link_status = (link_is_up) ? 1 : 0;
+	if (link_is_up) {
+#ifdef CONFIG_MV_PP3_FPGA
+		pp3_gmac_link_status(emac_num, &port_cfg);
+#else /* CONFIG_MV_PP3_FPGA */
+		mv_pp3_gop_port_link_status(emac_num, &port_cfg);
+#endif /* !CONFIG_MV_PP3_FPGA */
+		msg.speed = (unsigned char)port_cfg.speed;
+		msg.duplex = (unsigned char)port_cfg.duplex;
+	} else {
+		msg.speed = 0;
+		msg.duplex = 0;
+	}
+
+	return pp3_fw_set_simple_req(MV_FW_LINK_CHANGE_NOTE, &msg, sizeof(struct mv_pp3_fw_link_change_note));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Enable / disable virtual port
+	Send MV_FW_EMAC_VPORT_SET or MV_FW_CPU_VPORT_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+
+int pp3_fw_vport_state_set(int vport, bool port_enable)
+{
+	struct mv_pp3_fw_vport_state msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_state));
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.state = (port_enable) ? 1 : 0;
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_STATE_SET, &msg, sizeof(struct mv_pp3_fw_vport_state));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Set MTU for virtual port
+	Send MV_FW_VPORT_MTU_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+
+int pp3_fw_vport_mtu_set(int vport, int mtu)
+{
+	struct mv_pp3_fw_vport_mtu msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_state));
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.mtu = cpu_to_be16((unsigned short)mtu);
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_MTU_SET, &msg, sizeof(struct mv_pp3_fw_vport_mtu));
+}
+/*---------------------------------------------------------------------------
+description:
+	Set defauld destination for virtual port
+	Send MV_FW_VPORT_DEF_DEST_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+
+int pp3_fw_vport_def_dest_set(int vport, int dest_vport)
+{
+	struct mv_pp3_fw_vport_def_dest msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_def_dest));
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.def_dst_vport = cpu_to_be16((unsigned short)dest_vport);
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_DEF_DEST_SET, &msg, sizeof(struct mv_pp3_fw_vport_def_dest));
+}
+/*---------------------------------------------------------------------------
+description:
+	Create EMAC virtual port
+	By default EMAC virtual port is disabled.
+	Send MV_FW_EMAC_VPORT_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_emac_vport_set(struct pp3_vport *vp_cfg, unsigned char *mac)
+{
+	struct mv_pp3_fw_emac_vport msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_emac_vport));
+	msg.vport = cpu_to_be16((unsigned short)vp_cfg->vport);
+	msg.mtu = cpu_to_be16(vp_cfg->port.emac.mtu);
+	msg.vport_dst = cpu_to_be16((unsigned short)vp_cfg->dest_vp);
+	msg.state = (unsigned char)vp_cfg->state;
+	msg.cos = (unsigned char)vp_cfg->cos;
+	msg.l2_options = vp_cfg->port.emac.l2_options;
+
+	memcpy(msg.mac_addr, mac, MV_MAC_ADDR_SIZE);
+/*
+	pr_info("%s: vport:%d, mtu:%d, cos:%d, vp_dst:%d l2_opt:%02X mac:%02x:%02x:%02x:%02x:%02x:%02x\n",
+		__func__, be16_to_cpu(msg.vport), be16_to_cpu(msg.mtu),
+		msg.cos, be16_to_cpu(msg.vport_dst), msg.l2_options,
+		msg.mac_addr[0], msg.mac_addr[1], msg.mac_addr[2],
+		msg.mac_addr[3], msg.mac_addr[4], msg.mac_addr[5]);
+*/
+	return pp3_fw_set_simple_req(MV_FW_EMAC_VPORT_SET, &msg, sizeof(struct mv_pp3_fw_emac_vport));
+}
+/*---------------------------------------------------------------------------*/
+
+int pp3_fw_emac_vport_msg_get(int vport, struct mv_pp3_fw_emac_vport *out_msg)
+{
+	int err;
+	struct mv_pp3_fw_emac_vport in_msg;
+
+	memset(&in_msg, 0, sizeof(in_msg));
+	memset(out_msg, 0, sizeof(*out_msg));
+
+	in_msg.vport = cpu_to_be16((unsigned short)vport);
+
+	err = pp3_fw_set_wait_req(MV_FW_EMAC_VPORT_GET, &in_msg, sizeof(in_msg),
+						out_msg, sizeof(*out_msg));
+	return err;
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_fw_emac_vport_msg_show(int vport)
+{
+	int err;
+	struct mv_pp3_fw_emac_vport out_msg;
+
+	pr_info("---- EMAC virtual port #%d information from Firmware ----\n", vport);
+	err = pp3_fw_emac_vport_msg_get(vport, &out_msg);
+	if (!err) {
+		pr_info("state       : %s\n", out_msg.state ? "Enable" : "Disable");
+		pr_info("mtu         : %u\n", out_msg.mtu);
+		pr_info("def_dst_vp  : %u\n", out_msg.vport_dst);
+		pr_info("cos         : %u\n", out_msg.cos);
+		pr_info("L2 options  : 0x%02x\n", out_msg.l2_options);
+		mv_mac_addr_print("ucast MAC   :", &out_msg.mac_addr[0], NULL);
+	} else
+		pr_err("vport #%d FW information is unavailable. err = %d\n", vport, err);
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------
+description:
+	Create and enable CPU virtual port
+	Send MV_FW_INTERNAL_CPU_VPORT_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+
+int pp3_fw_internal_cpu_vport_set(struct pp3_vport *vp_cfg)
+{
+	struct mv_pp3_fw_internal_cpu_port msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_internal_cpu_port));
+
+	msg.int_cpu_port = cpu_to_be16((unsigned short)vp_cfg->vport);
+	msg.rx_pkt_mode = (unsigned char)vp_cfg->port.cpu.cpu_shared->rx_pkt_mode;
+
+	if (vp_cfg->port.cpu.cpu_shared->long_pool)
+		msg.bm_long_pool = (unsigned char)vp_cfg->port.cpu.cpu_shared->long_pool->pool;
+	else {
+		pr_err("%s: long pool must be initialized\n", __func__);
+		return -1;
+	}
+
+	msg.bm_short_pool = (vp_cfg->port.cpu.cpu_shared->short_pool) ?
+					(unsigned char)vp_cfg->port.cpu.cpu_shared->short_pool->pool : -1;
+
+	msg.bm_lro_pool = (vp_cfg->port.cpu.cpu_shared->lro_pool) ?
+					(unsigned char)vp_cfg->port.cpu.cpu_shared->lro_pool->pool : -1;
+
+	return pp3_fw_set_simple_req(MV_FW_INTERNAL_CPU_PORT_SET, &msg, sizeof(struct mv_pp3_fw_internal_cpu_port));
+}
+/*---------------------------------------------------------------------------
+description:
+	Set CPU virtual port
+	Send MV_FW_CPU_VPORT_SET message
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_cpu_vport_set(int vport)
+{
+	struct mv_pp3_fw_cpu_vport msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_cpu_vport));
+
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.vport_dst = cpu_to_be16((unsigned short)MV_NSS_PORT_DROP);
+	msg.state = 1;
+	msg.cos = 0;
+
+	return pp3_fw_set_simple_req(MV_FW_CPU_VPORT_SET, &msg, sizeof(struct mv_pp3_fw_cpu_vport));
+}
+/*---------------------------------------------------------------------------
+description:
+	Set internal virtual port to be used between
+	EMAC/WLAN virtual port and CPU virtual port
+	Send MV_FW_CPU_VPORT_MAP message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+
+int pp3_fw_cpu_vport_map(int vport, int cpu_vp, int int_cpu_vp)
+{
+	struct mv_pp3_fw_cpu_vport_map msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_cpu_vport_map));
+
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.cpu_vport = cpu_to_be16((unsigned short)cpu_vp);
+	msg.int_cpu_port = cpu_to_be16((unsigned short)int_cpu_vp);
+/*
+	pr_info("%s: vport:%d, cpu_vp:%d int_cpu_vp:%d\n",
+			__func__, be16_to_cpu(msg.vport), be16_to_cpu(msg.cpu_vport), be16_to_cpu(msg.int_cpu_port));
+*/
+	return pp3_fw_set_simple_req(MV_FW_CPU_VPORT_MAP, &msg, sizeof(struct mv_pp3_fw_cpu_vport_map));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	set list of mac addresses for EMAC virtual port
+	By default EMAC virtual port is disabled.
+	Send MV_FW_VPORT_MAC_LIST_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_vport_mac_list_set(int vport, unsigned char macs_list_size, unsigned char *macs_list)
+{
+	struct mv_pp3_fw_vport_mac_list msg;
+	int i;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_mac_list));
+
+	msg.vport = cpu_to_be16((unsigned short)vport);
+
+	for (i = 0; i < macs_list_size && i < MV_PP3_MAC_ADDR_NUM; i++)
+		memcpy(msg.mac_addr_list[i], &macs_list[i * MV_MAC_ADDR_SIZE], MV_MAC_ADDR_SIZE);
+
+	msg.mac_addr_list_size = i;
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_MAC_LIST_SET, &msg, sizeof(msg));
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get list of MAC addresses for EMAC virtual port */
+int pp3_fw_vport_mac_list_get(int vport,  unsigned char macs_list_size, unsigned char *macs_list,
+					unsigned char *macs_valid)
+{
+	int i;
+	struct mv_pp3_fw_vport_mac_list in_msg, out_msg;
+
+	in_msg.vport = cpu_to_be16((unsigned short)vport);
+	in_msg.mac_addr_list_size = macs_list_size;
+
+	if (pp3_fw_set_wait_req(MV_FW_VPORT_MAC_LIST_GET, &in_msg, sizeof(in_msg),
+							&out_msg, sizeof(out_msg)) == 0) {
+
+		if (out_msg.mac_addr_list_size > macs_list_size)
+			out_msg.mac_addr_list_size = macs_list_size;
+
+		*macs_valid = out_msg.mac_addr_list_size;
+		for (i = 0; i < out_msg.mac_addr_list_size; i++)
+			memcpy(&macs_list[i * MV_MAC_ADDR_SIZE], out_msg.mac_addr_list[i], MV_MAC_ADDR_SIZE);
+
+		return 0;
+	}
+	return -1;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	BM pool configurationn
+	Send MV_FW_BM_POOL_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_bm_pool_set(struct pp3_pool *pool)
+{
+	struct mv_pp3_fw_bm_pool msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_bm_pool));
+	msg.bm_pool_num = pool->pool;
+	msg.buf_headroom = (pool->headroom / MV_PP3_BM_POOL_HROOM_RES);
+	msg.buf_size = cpu_to_be16(pool->pkt_max_size + pool->headroom);
+	/* pair mode */
+	msg.pe_size = 1;
+
+	return pp3_fw_set_simple_req(MV_FW_BM_POOL_SET, &msg, sizeof(struct mv_pp3_fw_bm_pool));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Ingress / egress VQ to SWQ/HWQ map configuration
+	Send MV_FW_VQ_MAP_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_vq_map_set(int vport, int vq, enum mv_pp3_queue_type q_type, int swq, int hwq)
+{
+	struct mv_pp3_fw_vq_map msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vq_map));
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.type = (unsigned char)q_type;
+	msg.vq = (unsigned char)vq;
+	msg.hwq = cpu_to_be16((unsigned short)hwq);
+	msg.swq = (unsigned char)swq;
+/*
+	pr_info("%s: sent: vport:%d, type:%d, vq:%d, swq:%d, hwq:%d\n", __func__,
+		cpu_to_be16(msg.vport), msg.type, msg.vq, msg.swq, be16_to_cpu(msg.hwq));
+*/
+	return pp3_fw_set_simple_req(MV_FW_VQ_MAP_SET, &msg, sizeof(struct mv_pp3_fw_vq_map));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Map ingress/egress CoS value to VQ per port
+	Send MV_FW_COS_TO_VQ_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_cos_to_vq_set(int vport, int vq, enum mv_pp3_queue_type q_type, int cos)
+{
+	struct mv_pp3_fw_cos_to_vq msg;
+
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	msg.type = (unsigned char) q_type;
+	msg.vq = (unsigned char) vq;
+	msg.cos = (unsigned char) cos;
+/*
+	pr_info("%s: sent: vport:%d, type:%d, vq:%d, cos:%d\n", __func__, q_type,
+		cpu_to_be16(msg.vport), msg.vq, msg.cos);
+*/
+	return pp3_fw_set_simple_req(MV_FW_COS_TO_VQ_SET, &msg, sizeof(struct mv_pp3_fw_cos_to_vq));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Set virtual port MAC addres
+	Send MV_FW_VPORT_MAC_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+
+---------------------------------------------------------------------------*/
+int pp3_fw_port_mac_addr(int vport, unsigned char *addr)
+{
+	struct mv_pp3_fw_vport_mac msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_vport_mac));
+	msg.vport = cpu_to_be16((unsigned short)vport);
+	memcpy(msg.mac, addr, MV_MAC_ADDR_SIZE);
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_MAC_SET, &msg, sizeof(struct mv_pp3_fw_vport_mac));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Set L2 filter mode for virtual port
+	Send MV_FW_L2_FILTER_SET message
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_port_l2_filter_mode(int vport, enum mv_nss_l2_option opt, bool state)
+{
+	struct mv_pp3_fw_l2_option msg;
+
+	memset(&msg, 0, sizeof(struct mv_pp3_fw_l2_option));
+	msg.vport = cpu_to_be16((unsigned char) vport);
+	msg.option = (unsigned char) opt;
+	msg.state = (state) ? 1 : 0;
+
+	return pp3_fw_set_simple_req(MV_FW_VPORT_L2_OPTION_SET, &msg, sizeof(struct mv_pp3_fw_l2_option));
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for memory buffer size needed by FW
+
+Return:
+	>= 0- memory buffer size
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_mem_bufs_alloc_size_get(void)
+{
+	struct mv_pp3_fw_mem_get msg;
+	struct mv_pp3_fw_mem_get req_size;		/* buffer size in kbytes */
+
+	msg.size = 0;
+
+	if (pp3_fw_set_wait_req(MV_FW_MEM_REQ_GET, &msg, sizeof(msg), &req_size, sizeof(req_size)) < 0)
+		return -1;
+
+	return be32_to_cpu(req_size.size);
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send message to FW with allocated buffers addresses
+
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure
+---------------------------------------------------------------------------*/
+int pp3_fw_mem_bufs_alloc_set(unsigned int size, unsigned int buf_num, unsigned int *bufs)
+{
+	struct mv_pp3_fw_mem_set res;
+	struct request_info req_info;
+	int i, ret_val = 0;
+
+	memset(&res, 0, sizeof(res));
+	res.buf_num = cpu_to_be16(buf_num);
+	res.size = cpu_to_be16(size/buf_num);
+
+	for (i = 0; i < buf_num; i++)
+		res.buffer[i] = bufs[i];
+
+	/* fill request structure */
+	req_info.msg_opcode = MV_FW_MEM_REQ_SET;
+	req_info.in_param = &res;
+	req_info.size_of_input = sizeof(res);
+	req_info.out_buff = NULL;
+	req_info.size_of_output = 0;
+	req_info.req_cb = NULL;
+	req_info.cb_params = NULL;
+	req_info.num_of_ints = 1;
+
+	ret_val = mv_pp3_drv_request_send(&req_info);
+
+	return ret_val;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send syncronization msg and wait for completion
+
+return values:
+		success: msg return code
+		fail: -1
+---------------------------------------------------------------------------*/
+int pp3_fw_sync(void)
+{
+	struct request_info req_info;
+	struct drv_msg_cb_params req_params;
+	int msg_num;
+
+	pp3_fw_struct_size_checker();
+
+	/* send sync message and wait to complete */
+	init_completion(&req_params.complete);
+
+	/* fill request structure */
+	req_info.msg_opcode = MV_IDLE_MSG;
+	req_info.in_param = NULL;
+	req_info.size_of_input = 0;
+	req_info.out_buff = NULL;
+	req_info.size_of_output = 0;
+	req_info.req_cb = (void (*)(void *))drv_msg_cb_with_complete;
+	req_info.cb_params = &req_params;
+	req_info.num_of_ints = 1;
+
+	msg_num = mv_pp3_drv_request_send(&req_info);
+	/* The return value is 0 if timed out, and positive (at least 1, or number of
+	 jiffies left till timeout) if completed. */
+	if (wait_for_completion_interruptible_timeout(&req_params.complete, 1000) == 0) {
+		pr_err("No response from FW. System doesn't configured properly\n");
+		mv_pp3_drv_request_delete(msg_num);
+		return -1;
+	}
+
+	if (req_params.ret_code != 0)
+		pr_err("Get bad response from FW, ret_val = %d\nSystem doesn't ready\n", req_params.ret_code);
+
+	return req_params.ret_code;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for vport statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_vport_stat_get(int vport, struct mv_pp3_fw_vport_stat *vport_stat)
+{
+	unsigned short param;
+
+	param = cpu_to_be16((unsigned short)vport);
+	if (pp3_fw_set_wait_req(MV_FW_VPORT_STATS_GET, &param, sizeof(param), vport_stat,
+		sizeof(struct mv_pp3_fw_vport_stat)) == 0)
+		mv_be32_convert((u32 *)vport_stat, sizeof(struct mv_pp3_fw_vport_stat)/sizeof(u32));
+	else
+		return -1;
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for HW queue statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_hwq_stat_get(unsigned short q, bool clean, struct mv_pp3_fw_hwq_stat *hw_stat)
+{
+
+	struct mv_pp3_fw_hwq_stats_get msg_stat;
+
+	msg_stat.hwq = cpu_to_be16(q);
+	msg_stat.clear = clean;
+	msg_stat.reserved = 0;
+
+	if (pp3_fw_set_wait_req(MV_FW_HWQ_STATS_GET, &msg_stat, sizeof(struct mv_pp3_fw_hwq_stats_get), hw_stat,
+		sizeof(struct mv_pp3_fw_hwq_stat)) == 0)
+		mv_be32_convert((u32 *)hw_stat, sizeof(struct mv_pp3_fw_hwq_stat)/sizeof(u32));
+	else
+		return -1;
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for SW queue statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_swq_stat_get(unsigned char q, struct mv_pp3_fw_swq_stat *sw_stat)
+{
+	if (pp3_fw_set_wait_req(MV_FW_SWQ_STATS_GET, &q, sizeof(unsigned char), sw_stat,
+		sizeof(struct mv_pp3_fw_swq_stat)) == 0)
+		mv_be32_convert((u32 *)sw_stat, sizeof(struct mv_pp3_fw_swq_stat)/sizeof(u32));
+	else
+		return -1;
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for BM pool statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_bm_pool_stat_get(unsigned char q, struct mv_pp3_fw_bm_pool_stat *stat)
+{
+	if (pp3_fw_set_wait_req(MV_FW_BM_POOL_STATS_GET, &q, sizeof(unsigned char), stat,
+		sizeof(struct mv_pp3_fw_bm_pool_stat)) == 0)
+		mv_be32_convert((u32 *)stat, sizeof(struct mv_pp3_fw_bm_pool_stat)/sizeof(u32));
+	else
+		return -1;
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for messenger channel statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_channel_stat_get(unsigned char q, struct mv_pp3_fw_msg_chan_stat *stat)
+{
+	if (pp3_fw_set_wait_req(MV_FW_MSG_CHAN_STATS_GET, &q, sizeof(unsigned char), stat,
+		sizeof(struct mv_pp3_fw_msg_chan_stat)) == 0)
+		mv_be32_convert((u32 *)stat, sizeof(struct mv_pp3_fw_msg_chan_stat)/sizeof(u32));
+	else
+		return -1;
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Send request for messenger channel statistics
+
+Return:
+	= 0 - Success.
+	< 0 - Failure.
+---------------------------------------------------------------------------*/
+int pp3_fw_clear_stat_set(unsigned char stat_type, unsigned short num)
+{
+	struct mv_pp3_fw_reset_stat msg_stat;
+
+	msg_stat.type = stat_type;
+	msg_stat.reserved = 0;
+	msg_stat.index = cpu_to_be16(num);
+
+	if (pp3_fw_set_wait_req(MV_FW_RESET_STATISTICS, &msg_stat, sizeof(struct mv_pp3_fw_reset_stat), NULL, 0) != 0)
+		return -1;
+
+	return 0;
+}
+
+void pp3_fw_hwq_stat_print(struct mv_pp3_fw_hwq_stat *stat)
+{
+	pr_info("Number of enqueue packets high %10u\n", stat->hwq_pkt_high);
+	pr_info("Number of enqueue packets low  %10u\n", stat->hwq_pkt_low);
+	pr_info("Number of enqueue octets  high %10u\n", stat->hwq_oct_high);
+	pr_info("Number of enqueue octets  low  %10u\n", stat->hwq_oct_low);
+	pr_info("Number of dropped packets high %10u\n", stat->hwq_pkt_drop_high);
+	pr_info("Number of dropped packets low  %10u\n", stat->hwq_pkt_drop_low);
+}
+
+void pp3_fw_swq_stat_print(struct mv_pp3_fw_swq_stat *stat)
+{
+	pr_info("Number of enqueue to specific SWQ failed          %10u\n", stat->swq_enq_err_cntr);
+	pr_info("Number of enqueue to specific SWQ success high    %10u\n", stat->swq_enq_cntr_high);
+	pr_info("Number of enqueue to specific SWQ success low     %10u\n", stat->swq_enq_cntr_low);
+}
+
+void pp3_fw_bmpool_stat_print(struct mv_pp3_fw_bm_pool_stat *stat)
+{
+	pr_info("Number of times FW allocate buffers from specific BM pool    %10u\n", stat->bm_alloc_cntr);
+	pr_info("Number of times FW free buffer to specific BM pool           %10u\n", stat->bm_free_cntr);
+}
+
+void pp3_fw_msg_stat_print(struct mv_pp3_fw_msg_chan_stat *stat)
+{
+	pr_info("Number of requests received by FW              %10u\n", stat->msg_request_cntr);
+	pr_info("Number of requests that FW failed to execute   %10u\n", stat->msg_request_err);
+	pr_info("Number of replies sent by FW                   %10u\n", stat->msg_reply_cntr);
+	pr_info("Number of events sent by FW                    %10u\n", stat->msg_event_cntr);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.h b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.h
new file mode 100644
index 0000000..ef3284b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg.h
@@ -0,0 +1,71 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************/
+#ifndef __mv_pp3_fw_msg_h__
+#define __mv_pp3_fw_msg_h__
+
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "vport/mv_pp3_pool.h"
+#include "vport/mv_pp3_vport.h"
+#include "mv_pp3_fw_msg_structs.h"
+
+/*------------------------------------------------------------------------------*/
+/*				Host FW API					*/
+/*------------------------------------------------------------------------------*/
+
+/* get request */
+int pp3_fw_mem_bufs_alloc_size_get(void);
+int pp3_fw_version_get(struct mv_pp3_version *fw_ver);
+int pp3_fw_mem_bufs_alloc_set(unsigned int size, unsigned int buf_num, unsigned int *bufs);
+int pp3_fw_vport_stat_get(int vport, struct mv_pp3_fw_vport_stat *vport_stat);
+int pp3_fw_hwq_stat_get(unsigned short q, bool clean, struct mv_pp3_fw_hwq_stat *hwq_stat);
+int pp3_fw_swq_stat_get(unsigned char q, struct mv_pp3_fw_swq_stat *sw_stat);
+int pp3_fw_bm_pool_stat_get(unsigned char q, struct mv_pp3_fw_bm_pool_stat *stat);
+int pp3_fw_channel_stat_get(unsigned char q, struct mv_pp3_fw_msg_chan_stat *stat);
+int pp3_fw_clear_stat_set(unsigned char stat_type, unsigned short num);
+int pp3_fw_emac_vport_msg_get(int vport, struct mv_pp3_fw_emac_vport *out_msg);
+int pp3_fw_emac_vport_msg_show(int vport);
+
+/* set request */
+int pp3_fw_vport_rx_pkt_mode_set(int vport, enum mv_pp3_pkt_mode mode);
+int pp3_fw_bm_pool_set(struct pp3_pool *pool);
+int pp3_fw_link_changed(int emac_num, bool link_is_up);
+int pp3_fw_vport_state_set(int vport, bool enable_port);
+int pp3_fw_vport_def_dest_set(int vport, int dest_vport);
+int pp3_fw_vport_mtu_set(int vport, int mtu);
+int pp3_fw_vport_mac_list_set(int vport,  unsigned char macs_list_size, unsigned char *macs_list);
+int pp3_fw_vport_mac_list_get(int vport,  unsigned char macs_list_size, unsigned char *macs_list,
+					unsigned char *macs_valid);
+int pp3_fw_emac_vport_set(struct pp3_vport *vp_cfg, unsigned char *mac);
+int pp3_fw_internal_cpu_vport_set(struct pp3_vport *vp_cfg);
+int pp3_fw_cpu_vport_set(int vport);
+int pp3_fw_cpu_vport_map(int vport, int user_cpu_vp, int int_cpu_vp);
+int pp3_fw_vq_map_set(int vport, int vq, enum mv_pp3_queue_type q_type, int swq, int hwq);
+int pp3_fw_cos_to_vq_set(int vport, int vq, enum mv_pp3_queue_type q_type, int cos);
+int pp3_fw_port_mac_addr(int vport, unsigned char *addr);
+int pp3_fw_port_l2_filter_mode(int vport, enum mv_nss_l2_option opt, bool state);
+int pp3_fw_sync(void);
+
+/* print assist */
+void pp3_fw_hwq_stat_print(struct mv_pp3_fw_hwq_stat *stat);
+void pp3_fw_swq_stat_print(struct mv_pp3_fw_swq_stat *stat);
+void pp3_fw_bmpool_stat_print(struct mv_pp3_fw_bm_pool_stat *stat);
+void pp3_fw_msg_stat_print(struct mv_pp3_fw_msg_chan_stat *stat);
+
+#endif /* __mv_pp3_fw_msg_h__ */
+
diff --git a/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg_structs.h b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg_structs.h
new file mode 100644
index 0000000..5275b57
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/fw/mv_pp3_fw_msg_structs.h
@@ -0,0 +1,299 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************/
+#ifndef __mv_pp3_fw_msg_structs_h__
+#define __mv_pp3_fw_msg_structs_h__
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3_defs.h"
+#include "platform/mv_pp3_fw_opcodes.h"
+
+/* Create communication channel between Host and Firmware - MV_FW_MSG_CHAN_SET - 4 bytes */
+struct mv_pp3_fw_msg_chan_cfg {
+	unsigned char	chan_id;
+	unsigned char	hmac_sw_rxq;
+	unsigned short	hmac_hw_rxq;
+};
+
+#define MV_PP3_VERSION_NAME_SIZE	4
+
+/* Get version message. Version number is represented in x.y.z */
+/* MV_FW_VERSION_GET - 8 bytes */
+struct mv_pp3_version {
+	char            name[MV_PP3_VERSION_NAME_SIZE];
+	unsigned char	major_x;
+	unsigned char	minor_y;
+	unsigned char	local_z;
+	unsigned char	debug_d;
+};
+
+/* Set/Get EMAC virtual port - MV_FW_EMAC_VPORT_SET/MV_FW_EMAC_VPORT_GET - 16 bytes */
+struct mv_pp3_fw_emac_vport {
+	unsigned short	vport;          /* virtual port ID of the EMAC */
+	unsigned short	mtu;		/* MTU for virtual port - used for MSS and MRU */
+	unsigned short  vport_dst;      /* default desctination virtual port */
+	unsigned char   state;          /* 0 - disable, 1 - enable */
+	unsigned char   cos;            /* default CoS value */
+	unsigned char	l2_options;	/* bitmask of options from "enum mv_gnss_l2_option" */
+	unsigned char   reserved;
+	unsigned char	mac_addr[MV_MAC_ADDR_SIZE];    /* MAC addresses for the port */
+};
+
+/* Set/Get CPU virtual port - MV_FW_CPU_VPORT_SET/MV_FW_CPU_VPORT_GET - 8 bytes */
+struct mv_pp3_fw_cpu_vport {
+	unsigned short	vport;          /* CPU virtual port [10..11] */
+	unsigned short  vport_dst;      /* default desctination virtual port */
+	unsigned char   state;          /* 0 - disable, 1 - enable */
+	unsigned char   cos;            /* default CoS value */
+	unsigned char   reserved[2];
+};
+
+/* Set/Get internal CPU port - MV_FW_INTERNAL_CPU_PORT_SET/MV_FW_INTERNAL_CPU_PORT_GET - 8 bytes */
+struct mv_pp3_fw_internal_cpu_port {
+	unsigned short	int_cpu_port;   /* internal CPU port in range [0 .. 31] */
+	unsigned char	rx_pkt_mode;	/* value from "enum mv_pp3_pkt_mode" */
+	signed char	bm_long_pool;   /* long pool must be valid */
+	signed char	bm_short_pool;	/* -1 - short pool is not exist */
+	signed char	bm_lro_pool;	/* -1 - LRO pool is not exist */
+	unsigned char   reserved[2];
+};
+
+/* Set internal virtual port to be used between EMAC/WLAN virtual port and CPU virtual port */
+/* MV_FW_CPU_VPORT_MAP - 8 bytes */
+struct mv_pp3_fw_cpu_vport_map {
+	unsigned short vport;		/* virtual port ID of EMAC/WLAN virtual port */
+	unsigned short cpu_vport;	/* CPU virtual port [10, 11] */
+	unsigned short int_cpu_port;	/* Internal CPU port to be used [0..31] */
+	unsigned short reserved;
+};
+
+/* Message to set rx_pkt_mode for virtual port */
+/* MV_FW_INTERNAL_CPU_PORT_RX_PKT_MODE_SET - 4 bytes */
+struct mv_pp3_fw_vport_rx_pkt_mode {
+	unsigned short	int_cpu_port;   /* Internal CPU port i[0..31] */
+	unsigned char	rx_pkt_mode;	/* one from mv_pp3_pkt_mode enumerations: */
+					/* 0 - minimal CFH, the whole packet is in DRAM buffer */
+					/* 1 - maximal CFH, upto 96 bytes of packet in CFH, rest in DRAM buffer */
+	unsigned char	reserved;
+};
+
+/* Message to map ingress/egress VQ to SWQ/HWQ pair */
+/* MV_FW_VQ_MAP_SET / MV_FW_VQ_MAP_GET - 8 bytes */
+/* For EMAC virtual port valid vq types are 0 - emac_to_ppc, 1 - ppc_to_emac */
+/* For internal CPU port valid vq types are 2 - hmac_to_ppc, 3 - ppc_to_hmac */
+struct mv_pp3_fw_vq_map {
+	unsigned short  vport;          /* EMAC virtual port / internal CPU port */
+	unsigned char   type;           /* for emac virtual port: 0 - emac_to_ppc (not for FW), 1 - ppc_to_emac, */
+					/* for internal cpu port: 2 - hmac_to_ppc (not for FW), 3 - ppc_to_hmac */
+	unsigned char   vq;             /* virtual queue number: [0..15] */
+	unsigned short  hwq;            /* HWQ number */
+	unsigned char   swq;            /* SWQ number */
+	unsigned char   reserved;
+};
+
+/* Map ingress/egress CoS value to VQ per vport */
+/* MV_FW_COS_TO_VQ_SET  - 8 bytes */
+struct mv_pp3_fw_cos_to_vq {
+	unsigned short  vport;          /* EMAC virtual port / internal CPU port */
+	unsigned char   type;           /* for emac virtual port: 0 - emac_to_ppc (not for FW), 1 - ppc_to_emac */
+					/* for internal cpu port: 2 - hmac_to_ppc (not for FW), 3 - ppc_to_hmac */
+	unsigned char   cos;            /* CoS value */
+	unsigned char   vq;             /* virtual queue number: [0..15] */
+	unsigned char   reserved[3];
+};
+
+/* Message to set metering parameters for VQ per vport */
+/* MV_FW_VQ_POLICER_SET / MV_FW_VQ_POLICER_GET - 24 bytes */
+struct mv_pp3_fw_vq_policer {
+	unsigned short  vport;          /* EMAC virtual port / internal CPU port */
+	unsigned char   type;           /* for emac virtual port: 0 - emac_to_ppc, 1 - ppc_to_emac */
+					/* for internal cpu port: 2 - hmac_to_ppc, 3 - ppc_to_hmac */
+	unsigned char   vq;             /* virtual queue number 0 ... 15 */
+	unsigned char   enable;         /* 0 - disable, 1 - enable */
+	unsigned char   reserved[3];
+	unsigned int    cir;            /* committed information rate, Kbps. */
+	unsigned int    eir;            /* excess information rate, Kbps. */
+	unsigned int    cbs;            /* committed burst size, KB. */
+	unsigned int    ebs;            /* excess burst size, KB. */
+};
+
+/* BM pool configuration - MV_FW_BM_POOL_SET - 8 bytes */
+struct mv_pp3_fw_bm_pool {
+	unsigned char   bm_pool_num;
+	unsigned char   buf_headroom; /* 32 bytes resolution */
+	unsigned short  buf_size;
+	unsigned char   pe_size;      /* 0 - one pool element, 1 - two pool elements */
+	char            reserved[3];
+};
+
+/* Set MAC address to EMAC/WLAN vport structure. */
+/* MV_FW_VPORT_MAC_SET - 8 bytes */
+struct mv_pp3_fw_vport_mac {
+	unsigned short vport;
+	unsigned char  mac[MV_MAC_ADDR_SIZE];
+};
+
+#define MV_PP3_MAC_ADDR_NUM	6
+
+/* Set/Get list of MAC addresses for EMAC virtual port. */
+/* MV_FW_VPORT_MAC_LIST_SET / MV_FW_VPORT_MAC_LIST_GET  */
+/* MV_PP3_MAC_ADDR_NUM = 4 -> message size = 28 bytes */
+/* MV_PP3_MAC_ADDR_NUM = 6 -> message size = 40 bytes */
+/* MV_PP3_MAC_ADDR_NUM = 8 -> message size = 52 bytes */
+/* MV_PP3_MAC_ADDR_NUM = 14 -> message size = 88 bytes */
+struct mv_pp3_fw_vport_mac_list {
+	unsigned short vport;
+	unsigned char  mac_addr_list_size;  /* number of valid MAC addresses (MCAST and UCAST) in the mac_addr_list */
+	unsigned char  reserved;
+	unsigned char  mac_addr_list[MV_PP3_MAC_ADDR_NUM][MV_MAC_ADDR_SIZE]; /* array of MAC addresses for the port */
+};
+
+/* Enable / Disable virtual port: MV_FW_VPORT_STATE_SET */
+struct mv_pp3_fw_vport_state {
+	unsigned short vport;
+	unsigned char  state;          /* 0 - disable, 1 - enable */
+	unsigned char  reserved;
+};
+
+/* Toggle (on/off) l2 option. MV_FW_VPORT_L2_OPTION_SET - 4 bytes */
+struct mv_pp3_fw_l2_option {
+	unsigned short vport;
+	unsigned char  option;   /* one from "enum mv_gnss_l2_option" */
+	unsigned char  state;    /* 0 - off, 1 - on */
+};
+
+/* Set MTU for virtual port: MV_FW_VPORT_MTU_SET */
+struct mv_pp3_fw_vport_mtu {
+	unsigned short vport;
+	unsigned short mtu; /* MTU for virtual port - used for MSS and MRU */
+};
+
+/* Set default destination virtual port: MV_FW_VPORT_DEF_DEST_SET */
+struct mv_pp3_fw_vport_def_dest {
+	unsigned short vport;
+	unsigned short def_dst_vport; /* Default destination virtual port for packets recieved on [vport] */
+};
+
+/* Virtual port statistics (6 counters * 8 bytes) */
+struct mv_pp3_fw_vport_stat {
+	unsigned int rx_packets_high;	/* Number of packets received high */
+	unsigned int rx_packets_low;	/* Number of packets received low */
+	unsigned int rx_errors_high;	/* Number of errors received high */
+	unsigned int rx_errors_low;	/* Number of errors received low */
+	unsigned int tx_packets_high;	/* Number of packets transmited high */
+	unsigned int tx_packets_low;	/* Number of packets transmitted */
+	unsigned int tx_errors_high;	/* Number of errors transmitted high */
+	unsigned int tx_errors_low;	/* Number of errors transmitted low */
+	unsigned int rx_bytes_high;	/* Number of bytes received high */
+	unsigned int rx_bytes_low;	/* Number of bytes received low */
+	unsigned int tx_bytes_high;	/* Number of bytes transmitted high */
+	unsigned int tx_bytes_low;	/* Number of bytes transmitted low */
+};
+
+/* get HWQ statistics: MV_FW_HWQ_STATS_GET */
+struct mv_pp3_fw_hwq_stats_get {
+	unsigned short hwq;		/* hwq number */
+	unsigned char  clear;		/* clear after read */
+	unsigned char  reserved;
+};
+
+/* HWQ statistics */
+struct mv_pp3_fw_hwq_stat {
+	unsigned short hwq;		/* HWQ number */
+	unsigned short reserved;
+	unsigned int hwq_pkt_high;	/* Number of packets enqueue to specific HWQ success */
+	unsigned int hwq_pkt_low;	/* Number of packets enqueue to specific HWQ success */
+	unsigned int hwq_oct_high;	/* Number of octets enqueue to specific HWQ success */
+	unsigned int hwq_oct_low;	/* Number of octets enqueue to specific HWQ success */
+	unsigned int hwq_pkt_drop_high;	/* Number of times enqueue to specific HWQ failed (full hwq) */
+	unsigned int hwq_pkt_drop_low;	/* Number of times enqueue to specific HWQ failed (full hwq) */
+};
+
+/* SWQ statistics */
+struct mv_pp3_fw_swq_stat {
+	unsigned int swq_enq_cntr_high;	/* Number of times enqueue to specific SWQ success */
+	unsigned int swq_enq_cntr_low;	/* Number of times enqueue to specific SWQ success */
+	unsigned int swq_enq_err_cntr;	/* Number of times enqueue to specific SWQ failed */
+};
+
+/* BM pool statistics */
+struct mv_pp3_fw_bm_pool_stat {
+	unsigned int bm_alloc_cntr;	/* Number of times Firmware allocate buffer from specific BM pool */
+	unsigned int bm_free_cntr;	/* Number of times Firmware free buffer to specific BM pool */
+};
+
+/* Message channel statistics */
+struct mv_pp3_fw_msg_chan_stat {
+	unsigned int msg_request_cntr;	/* Number of requests received by Firmware on specific channel */
+	unsigned int msg_request_err;	/* Number of requests that Firmware failed to execute */
+	unsigned int msg_reply_cntr;	/* Number of replies sent by Firmware on specific channel */
+	unsigned int msg_event_cntr;	/* Number of events sent by Firmware on specific channel */
+};
+
+
+#define MV_PP3_PPN_MEM_BUFS	(16)
+/* MV_FW_MEM_REQ_GET request message */
+struct mv_pp3_fw_mem_get {
+	unsigned int size;		/* requested memory size in kbytes */
+};
+
+/* MV_FW_MEM_REQ_SET response message */
+struct mv_pp3_fw_mem_set {
+	unsigned short buf_num;		/* number of allocated buffers */
+	unsigned short size;		/* single buffer memory size in kbytes */
+	unsigned int buffer[MV_PP3_PPN_MEM_BUFS];	/* pointers to allocated buffers */
+};
+
+
+/* MV_FW_RESET_STATISTICS */
+enum mv_fw_counter_types {
+
+	MV_PP3_FW_ALL_STAT = 0,
+	MV_PP3_FW_VPORT_STAT,
+	MV_PP3_FW_HWQ_STAT,
+	MV_PP3_FW_SWQ_STAT,
+	MV_PP3_FW_BM_POOL_STAT,
+	MV_PP3_FW_CHANNEL_STAT,
+};
+
+struct mv_pp3_fw_reset_stat {
+	unsigned char type;		/* counter type to reset */
+	unsigned char reserved;
+	unsigned short index;		/* counter index according to type */
+};
+
+/* MV_FW_LINK_CHANGE_NOTE message */
+/* for speed:
+	MV_PORT_SPEED_UNKNOWN	= 0,
+	MV_PORT_SPEED_10	= 1,
+	MV_PORT_SPEED_100	= 2,
+	MV_PORT_SPEED_1000	= 3,
+	MV_PORT_SPEED_2000	= 4,
+	MV_PORT_SPEED_10000	= 5
+
+   for duplex:
+	MV_PORT_DUPLEX_UNKNOWN	= 0,
+	MV_PORT_DUPLEX_HALF	= 1,
+	MV_PORT_DUPLEX_FULL	= 2
+*/
+struct mv_pp3_fw_link_change_note {
+	unsigned char emac_num;
+	unsigned char link_status;	/* 0 - link down, 1 - link up */
+	unsigned char speed;
+	unsigned char duplex;
+};
+
+#endif /* __mv_pp3_fw_msg_structs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.c b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.c
new file mode 100644
index 0000000..4241f73
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.c
@@ -0,0 +1,800 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "net_dev/mv_netdev.h"
+#include "mv_gmac_regs.h"
+#include "mv_gmac.h"
+
+static struct pp3_gmac_ctrl pp3_gmac[PP3_GMAC_MAX];
+static unsigned int gop_base_addr;
+
+/*-------------------------------------------------------------------*/
+/*		Gmac regs API					     */
+/*-------------------------------------------------------------------*/
+void pp3_gmac_base_addr_set(unsigned int addr)
+{
+	int gmac;
+
+	gop_base_addr = addr;
+	for (gmac = 0; gmac < PP3_GMAC_MAX; gmac++)
+		pp3_gmac_unit_base(gmac, gop_base_addr + GMAC_REG_BASE(gmac));
+}
+
+u32 pp3_gmac_base_addr_get(void)
+{
+	return gop_base_addr;
+}
+
+u32 pp3_gmac_reg_read(int port, u32 reg)
+{
+	u32 reg_data;
+
+	reg_data = mv_pp3_hw_reg_read(reg + pp3_gmac[port].base);
+
+	if (pp3_gmac[port].flags & MV_PP3_GMAC_F_DEBUG)
+		pr_info("read     : 0x%x = 0x%08x\n", reg, reg_data);
+
+	return reg_data;
+}
+
+void pp3_gmac_reg_write(int port, u32 reg, u32 data)
+{
+	mv_pp3_hw_reg_write(reg + pp3_gmac[port].base, data);
+
+	if (pp3_gmac[port].flags & MV_PP3_GMAC_F_DEBUG) {
+		u32 reg_data;
+		pr_info("write    : 0x%x = 0x%08x\n", reg, data);
+		reg_data = mv_pp3_hw_reg_read(reg + pp3_gmac[port].base);
+		pr_info("read back: 0x%x = 0x%08x\n", reg, reg_data);
+	}
+}
+
+static void pp3_gmac_reg_print(int port, char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg, pp3_gmac_reg_read(port, reg));
+}
+
+void pp3_gmac_unit_base(int port, u32 base)
+{
+	pr_info("\tgop port %d silicon base address is 0x%x\n", port, base);
+	pp3_gmac[port].base = base;
+	pp3_gmac[port].flags |= MV_PP3_GMAC_F_ATTACH;
+}
+
+/*-------------------------------------------------------------------*/
+void pp3_gmac_port_def_init(int port)
+{
+	/* NSS FPGA def config */
+	pp3_gmac_reg_write(port, 0x00000000 , 0x0000d001);/* mac_ctrl0 */
+	pp3_gmac_reg_write(port, 0x00000014 , 0x000008c4);/* ser_par */
+	pp3_gmac_reg_write(port, 0x00000094 , 0x00000005);/* ser_par_1 */
+	pp3_gmac_reg_write(port, 0x00000090 , 0x0000001a);/* mac_ctrl4 */
+	pp3_gmac_reg_write(port, 0x00000048 , 0x00000300);/* mac_ctrl3 */
+	pp3_gmac_reg_write(port, 0x0000000c , 0x00009222);/* an_ctrl_reg */
+	pp3_gmac_reg_write(port, 0x00000008 , 0x00000100);/* mac_ctrl2 */
+}
+
+/*-------------------------------------------------------------------*/
+void pp3_gmac_port_enable(int port)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_0_REG);
+	rev_val |= GMAC_PORT_EN_MASK;
+	rev_val |= GMAC_GMAC_MIB_CNTR_EN_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_0_REG, rev_val);
+}
+
+void pp3_gmac_port_diable(int port)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_0_REG);
+	rev_val &= ~(GMAC_PORT_EN_MASK);
+	pp3_gmac_reg_write(port, GMAC_CTRL_0_REG, rev_val);
+}
+
+static void pp3_gmac_port_rgmii_set(int port, int enable)
+{
+	u32  rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_2_REG);
+
+	if (enable)
+		rev_val |= GMAC_PORT_RGMII_MASK;
+	else
+		rev_val &= ~GMAC_PORT_RGMII_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_2_REG, rev_val);
+}
+
+static void pp3_gmac_port_sgmii_set(int port, int enable)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_2_REG);
+
+	if (enable)
+		rev_val |= (GMAC_PCS_ENABLE_MASK | GMAC_INBAND_AN_MASK);
+	else
+		rev_val &= ~(GMAC_PCS_ENABLE_MASK | GMAC_INBAND_AN_MASK);
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_2_REG, rev_val);
+}
+
+void pp3_gmac_port_periodic_xon_set(int port, int enable)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_1_REG);
+
+	if (enable)
+		rev_val |= GMAC_PERIODIC_XON_EN_MASK;
+	else
+		rev_val &= ~GMAC_PERIODIC_XON_EN_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_1_REG, rev_val);
+}
+
+void pp3_gmac_port_lb_set(int port, int is_gmii, int is_pcs_en)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_1_REG);
+
+	if (is_gmii)
+		rev_val |= GMAC_GMII_LB_EN_MASK;
+	else
+		rev_val &= ~GMAC_GMII_LB_EN_MASK;
+
+	if (is_pcs_en)
+		rev_val |= GMAC_PCS_LB_EN_MASK;
+	else
+		rev_val &= ~GMAC_PCS_LB_EN_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_1_REG, rev_val);
+}
+
+void pp3_gmac_port_reset_set(int port, bool setReset)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_CTRL_2_REG);
+	rev_val &= ~GMAC_PORT_RESET_MASK;
+
+	if (setReset == 1 /*TRUE*/)
+		rev_val |= GMAC_PORT_RESET_MASK;
+	else
+		rev_val &= ~GMAC_PORT_RESET_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_CTRL_2_REG, rev_val);
+
+	if (setReset == 0 /*FALSE*/) {
+		u32 reset = 1;
+		while (reset)
+			reset = pp3_gmac_reg_read(port, GMAC_CTRL_2_REG) & GMAC_PORT_RESET_MASK;
+	}
+}
+
+void pp3_gmac_port_power_up(int port, bool is_sgmii, bool is_rgmii)
+{
+	pp3_gmac_port_sgmii_set(port, is_sgmii);
+	pp3_gmac_port_rgmii_set(port, is_rgmii);
+	pp3_gmac_port_periodic_xon_set(port, 0 /*FALSE*/);
+	pp3_gmac_port_reset_set(port, 0 /*FALSE*/);
+}
+
+void pp3_gmac_def_set(int port)
+{
+	u32 rev_val;
+
+	/* Update TX FIFO MIN Threshold */
+	rev_val = pp3_gmac_reg_read(port, GMAC_PORT_FIFO_CFG_1_REG);
+	rev_val &= ~GMAC_TX_FIFO_MIN_TH_ALL_MASK;
+	/* Minimal TX threshold must be less than minimal packet length */
+	rev_val |= GMAC_TX_FIFO_MIN_TH_MASK(64 - 4 - 2);
+	pp3_gmac_reg_write(port, GMAC_PORT_FIFO_CFG_1_REG, rev_val);
+}
+
+void pp3_gmac_port_power_down(int port)
+{
+	pp3_gmac_port_diable(port);
+	pp3_gmac_mib_counters_clear(port);
+	pp3_gmac_port_reset_set(port, 1 /*TRUE*/);
+}
+
+bool pp3_gmac_port_is_link_up(int port)
+{
+	return pp3_gmac_reg_read(port, GMAC_STATUS_REG) & GMAC_LINK_UP_MASK;
+}
+
+int pp3_gmac_link_status(int port, struct mv_port_link_status *pstatus)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_STATUS_REG);
+
+	if (rev_val & GMAC_SPEED_1000_MASK)
+		pstatus->speed = MV_PORT_SPEED_1000;
+	else if (rev_val & GMAC_SPEED_100_MASK)
+		pstatus->speed = MV_PORT_SPEED_100;
+	else
+		pstatus->speed = MV_PORT_SPEED_10;
+
+	if (rev_val & GMAC_LINK_UP_MASK)
+		pstatus->linkup = 1 /*TRUE*/;
+	else
+		pstatus->linkup = 0 /*FALSE*/;
+
+	if (rev_val & GMAC_FULL_DUPLEX_MASK)
+		pstatus->duplex = MV_PORT_DUPLEX_FULL;
+	else
+		pstatus->duplex = MV_PORT_DUPLEX_HALF;
+
+	if (rev_val & GMAC_TX_FLOW_CTRL_ACTIVE_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ACTIVE;
+	else if (rev_val & GMAC_TX_FLOW_CTRL_ENABLE_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->tx_fc = MV_PORT_FC_DISABLE;
+
+	if (rev_val & GMAC_RX_FLOW_CTRL_ACTIVE_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ACTIVE;
+	else if (rev_val & GMAC_RX_FLOW_CTRL_ENABLE_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->rx_fc = MV_PORT_FC_DISABLE;
+
+	return 0;
+}
+
+char *pp3_gmac_speed_str_get(enum mv_port_speed speed)
+{
+	char *str;
+
+	switch (speed) {
+	case MV_PORT_SPEED_10:
+		str = "10 Mbps";
+		break;
+	case MV_PORT_SPEED_100:
+		str = "100 Mbps";
+		break;
+	case MV_PORT_SPEED_1000:
+		str = "1 Gbps";
+		break;
+	case MV_PORT_SPEED_2000:
+		str = "2 Gbps";
+		break;
+	case MV_PORT_SPEED_AN:
+		str = "AutoNeg";
+		break;
+	default:
+		str = "Unknown";
+	}
+	return str;
+}
+
+/******************************************************************************/
+/*                          Port Configuration functions                      */
+/******************************************************************************/
+
+/*******************************************************************************
+* mvNetaMaxRxSizeSet -
+*
+* DESCRIPTION:
+*       Change maximum receive size of the port. This configuration will take place
+*       imidiately.
+*
+* INPUT:
+*
+* RETURN:
+*******************************************************************************/
+int pp3_gmac_max_rx_size_set(int port, int max_rx_size)
+{
+	u32		rev_val;
+
+	rev_val =  pp3_gmac_reg_read(port, GMAC_CTRL_0_REG);
+	rev_val &= ~GMAC_MAX_RX_SIZE_MASK;
+	rev_val |= (((max_rx_size - MV_MH_SIZE) / 2) << GMAC_MAX_RX_SIZE_OFFS);
+	pp3_gmac_reg_write(port, GMAC_CTRL_0_REG, rev_val);
+	return 0;
+}
+
+/*******************************************************************************
+* pp3_gmac_force_link_mode_set -
+*
+* DESCRIPTION:
+*       Sets "Force Link Pass" and "Do Not Force Link Fail" bits.
+*	Note: This function should only be called when the port is disabled.
+*
+* INPUT:
+*	int  port		- port number
+*	bool force_link_pass	- Force Link Pass
+*	bool force_link_fail - Force Link Failure
+*		0, 0 - normal state: detect link via PHY and connector
+*		1, 1 - prohibited state.
+*
+* RETURN:
+*******************************************************************************/
+int pp3_gmac_force_link_mode_set(int port, bool force_link_up, bool force_link_down)
+{
+	u32 rev_val;
+
+	/* Can't force link pass and link fail at the same time */
+	if ((force_link_up) && (force_link_down))
+		return -EINVAL;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_AN_CTRL_REG);
+
+	if (force_link_up)
+		rev_val |= GMAC_FORCE_LINK_PASS_MASK;
+	else
+		rev_val &= ~GMAC_FORCE_LINK_PASS_MASK;
+
+	if (force_link_down)
+		rev_val |= GMAC_FORCE_LINK_FAIL_MASK;
+	else
+		rev_val &= ~GMAC_FORCE_LINK_FAIL_MASK;
+
+	pp3_gmac_reg_write(port, GMAC_AN_CTRL_REG, rev_val);
+
+	return 0;
+}
+
+/*******************************************************************************
+* pp3_gmac_speed_duplex_set -
+*
+* DESCRIPTION:
+*       Sets port speed to Auto Negotiation / 1000 / 100 / 10 Mbps.
+*	Sets port duplex to Auto Negotiation / Full / Half Duplex.
+*
+* INPUT:
+*	int port - port number
+*	enum mv_port_speed speed - port speed
+*	enum mv_port_duplex duplex - port duplex mode
+*
+* RETURN:
+*******************************************************************************/
+int pp3_gmac_speed_duplex_set(int port, enum mv_port_speed speed, enum mv_port_duplex duplex)
+{
+	u32 rev_val;
+
+	/* Check validity */
+	if ((speed == MV_PORT_SPEED_1000) && (duplex == MV_PORT_DUPLEX_HALF))
+		return -EINVAL;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_AN_CTRL_REG);
+
+	switch (speed) {
+	case MV_PORT_SPEED_AN:
+		rev_val |= GMAC_ENABLE_SPEED_AUTO_NEG_MASK;
+		/* the other bits don't matter in this case */
+		break;
+	case MV_PORT_SPEED_1000:
+		rev_val &= ~GMAC_ENABLE_SPEED_AUTO_NEG_MASK;
+		rev_val |= GMAC_SET_GMII_SPEED_1000_MASK;
+		/* the 100/10 bit doesn't matter in this case */
+		break;
+	case MV_PORT_SPEED_100:
+		rev_val &= ~GMAC_ENABLE_SPEED_AUTO_NEG_MASK;
+		rev_val &= ~GMAC_SET_GMII_SPEED_1000_MASK;
+		rev_val |= GMAC_SET_MII_SPEED_100_MASK;
+		break;
+	case MV_PORT_SPEED_10:
+		rev_val &= ~GMAC_ENABLE_SPEED_AUTO_NEG_MASK;
+		rev_val &= ~GMAC_SET_GMII_SPEED_1000_MASK;
+		rev_val &= ~GMAC_SET_MII_SPEED_100_MASK;
+		break;
+	default:
+		pr_info("Unexpected Speed value %d\n", speed);
+		return -EINVAL;
+	}
+
+	switch (duplex) {
+	case MV_PORT_DUPLEX_AN:
+		rev_val  |= GMAC_ENABLE_DUPLEX_AUTO_NEG_MASK;
+		/* the other bits don't matter in this case */
+		break;
+	case MV_PORT_DUPLEX_HALF:
+		rev_val &= ~GMAC_ENABLE_DUPLEX_AUTO_NEG_MASK;
+		rev_val &= ~GMAC_SET_FULL_DUPLEX_MASK;
+		break;
+	case MV_PORT_DUPLEX_FULL:
+		rev_val &= ~GMAC_ENABLE_DUPLEX_AUTO_NEG_MASK;
+		rev_val |= GMAC_SET_FULL_DUPLEX_MASK;
+		break;
+	default:
+		pr_err("Unexpected Duplex value %d\n", duplex);
+		return -EINVAL;
+	}
+
+	pp3_gmac_reg_write(port, GMAC_AN_CTRL_REG, rev_val);
+	return 0;
+}
+
+/*******************************************************************************
+* pp3_gmac_speed_duplex_get -
+*
+* DESCRIPTION:
+*       Gets port speed
+*	Gets port duplex
+*
+* INPUT:
+*	int port - port number
+* OUTPUT:
+*	enum mv_port_speed *speed - port speed
+*	enum mv_port_duplex *duplex - port duplex mode
+*
+* RETURN:
+*******************************************************************************/
+int pp3_gmac_speed_duplex_get(int port, enum mv_port_speed *speed, enum mv_port_duplex *duplex)
+{
+	u32 rev_val;
+
+	/* Check validity */
+	if (!speed || !duplex)
+		return -EINVAL;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_AN_CTRL_REG);
+	if (rev_val & GMAC_ENABLE_SPEED_AUTO_NEG_MASK)
+		*speed = MV_PORT_SPEED_AN;
+	else if (rev_val & GMAC_SET_GMII_SPEED_1000_MASK)
+		*speed = MV_PORT_SPEED_1000;
+	else if (rev_val & GMAC_SET_MII_SPEED_100_MASK)
+		*speed = MV_PORT_SPEED_100;
+	else
+		*speed = MV_PORT_SPEED_10;
+
+	if (rev_val & GMAC_ENABLE_DUPLEX_AUTO_NEG_MASK)
+		*duplex = MV_PORT_DUPLEX_AN;
+	else if (rev_val & GMAC_SET_FULL_DUPLEX_MASK)
+		*duplex = MV_PORT_DUPLEX_FULL;
+	else
+		*duplex = MV_PORT_DUPLEX_HALF;
+
+	return 0;
+}
+
+/*******************************************************************************
+* pp3_gmac_fc_set - Set Flow Control of the port.
+*
+* DESCRIPTION:
+*       This function configures the port's Flow Control properties.
+*
+* INPUT:
+*       int				port		- Port number
+*       enum mv_port_fc  fc - Flow control of the port.
+*
+* RETURN:   int
+*       0           - Success
+*       MV_OUT_OF_RANGE - Failed. Port is out of valid range
+*       MV_BAD_VALUE    - Value fc parameters is not valid
+*
+*******************************************************************************/
+int pp3_gmac_fc_set(int port, enum mv_port_fc fc)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_AN_CTRL_REG);
+
+	switch (fc) {
+	case MV_PORT_FC_AN_NO:
+		rev_val |= GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK;
+		rev_val &= ~GMAC_FLOW_CONTROL_ADVERTISE_MASK;
+		rev_val &= ~GMAC_FLOW_CONTROL_ASYMETRIC_MASK;
+		break;
+
+	case MV_PORT_FC_AN_SYM:
+		rev_val |= GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK;
+		rev_val |= GMAC_FLOW_CONTROL_ADVERTISE_MASK;
+		rev_val &= ~GMAC_FLOW_CONTROL_ASYMETRIC_MASK;
+		break;
+
+	case MV_PORT_FC_AN_ASYM:
+		rev_val |= GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK;
+		rev_val |= GMAC_FLOW_CONTROL_ADVERTISE_MASK;
+		rev_val |= GMAC_FLOW_CONTROL_ASYMETRIC_MASK;
+		break;
+
+	case MV_PORT_FC_DISABLE:
+		rev_val &= ~GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK;
+		rev_val &= ~GMAC_SET_FLOW_CONTROL_MASK;
+		break;
+
+	case MV_PORT_FC_ENABLE:
+		rev_val &= ~GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK;
+		rev_val |= GMAC_SET_FLOW_CONTROL_MASK;
+		break;
+
+	default:
+		pr_err("ethDrv: Unexpected FlowControl value %d\n", fc);
+		return -EINVAL;
+	}
+
+	pp3_gmac_reg_write(port, GMAC_AN_CTRL_REG, rev_val);
+
+	return 0;
+}
+
+/*******************************************************************************
+* pp3_gmac_fc_get - Get Flow Control configuration of the port.
+*
+* DESCRIPTION:
+*       This function returns the port's Flow Control properties.
+*
+* INPUT:
+*       int port			- Port number
+*
+* OUTPUT:
+*       enum mv_port_fc  *fc		- Flow control of the port.
+*
+*
+*******************************************************************************/
+void pp3_gmac_fc_get(int port, enum mv_port_fc *fc)
+{
+	u32 rev_val;
+
+	rev_val = pp3_gmac_reg_read(port, GMAC_AN_CTRL_REG);
+
+	if (rev_val & GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK) {
+		/* Auto negotiation is enabled */
+		if (rev_val & GMAC_FLOW_CONTROL_ADVERTISE_MASK) {
+			if (rev_val & GMAC_FLOW_CONTROL_ASYMETRIC_MASK)
+				*fc = MV_PORT_FC_AN_ASYM;
+			else
+				*fc = MV_PORT_FC_AN_SYM;
+		} else
+			*fc = MV_PORT_FC_AN_NO;
+	} else {
+		/* Auto negotiation is disabled */
+		if (rev_val & GMAC_SET_FLOW_CONTROL_MASK)
+			*fc = MV_PORT_FC_ENABLE;
+		else
+			*fc = MV_PORT_FC_DISABLE;
+	}
+}
+
+int pp3_gmac_port_link_speed_fc(int port, enum mv_port_speed speed,
+				     int force_link_up)
+{
+	if (force_link_up) {
+		if (pp3_gmac_speed_duplex_set(port, speed, MV_PORT_DUPLEX_FULL)) {
+			pr_err("pp3_gmac_speed_duplex_set failed\n");
+			return -EPERM;
+		}
+		if (pp3_gmac_fc_set(port, MV_PORT_FC_ENABLE)) {
+			pr_err("pp3_gmac_fc_set failed\n");
+			return -EPERM;
+		}
+		if (pp3_gmac_force_link_mode_set(port, 1, 0)) {
+			pr_err("pp3_gmac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+	} else {
+		if (pp3_gmac_force_link_mode_set(port, 0, 0)) {
+			pr_err("pp3_gmac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+		if (pp3_gmac_speed_duplex_set(port, MV_PORT_SPEED_AN, MV_PORT_DUPLEX_AN)) {
+			pr_err("pp3_gmac_speed_duplex_set failed\n");
+			return -EPERM;
+		}
+		if (pp3_gmac_fc_set(port, MV_PORT_FC_AN_SYM)) {
+			pr_err("pp3_gmac_fc_set failed\n");
+			return -EPERM;
+		}
+	}
+
+	return 0;
+}
+
+/******************************************************************************/
+/*                         PHY Control Functions                              */
+/******************************************************************************/
+void pp3_gmac_phy_addr_set(int port, int phy_addr)
+{
+	unsigned int rev_val;
+
+	rev_val = mv_pp3_hw_reg_read(PHY_ADDR_REG + pp3_gmac_base_addr_get());
+
+	rev_val &= ~PHY_ADDR_MASK(port);
+	rev_val |= ((phy_addr << PHY_ADDR_OFFS(port)) & PHY_ADDR_MASK(port));
+
+	 mv_pp3_hw_reg_write((PHY_ADDR_REG + pp3_gmac_base_addr_get()), rev_val);
+
+	return;
+}
+
+int pp3_gmac_phy_addr_get(int port)
+{
+	unsigned int rev_val;
+
+	rev_val = mv_pp3_hw_reg_read(PHY_ADDR_REG + pp3_gmac_base_addr_get());
+
+	return (rev_val & PHY_ADDR_MASK(port)) >> PHY_ADDR_OFFS(port);
+}
+
+/*
+void pp3_gmac_lms_regs(void)
+{
+	pr_info("\n[GoP LMS registers]\n");
+
+	mvGmacPrintReg(PHY_ADDR_REG, "MV_GOP_LMS_PHY_ADDR_REG");
+	mvGmacPrintReg(GMAC_PHY_AN_CFG0_REG, "MV_GOP_LMS_PHY_AN_CFG0_REG");
+}
+*/
+
+void pp3_gmac_port_regs(int port)
+{
+	/*TODO: port val validation */
+
+	pr_info("\n[gop MAC #%d registers]\n", port);
+
+	pp3_gmac_reg_print(port, "GMAC_CTRL_0_REG", GMAC_CTRL_0_REG);
+	pp3_gmac_reg_print(port, "GMAC_CTRL_1_REG", GMAC_CTRL_1_REG);
+	pp3_gmac_reg_print(port, "GMAC_CTRL_2_REG", GMAC_CTRL_2_REG);
+
+	pp3_gmac_reg_print(port, "GMAC_AN_CTRL_REG", GMAC_AN_CTRL_REG);
+	pp3_gmac_reg_print(port, "GMAC_STATUS_REG", GMAC_STATUS_REG);
+
+	pp3_gmac_reg_print(port, "GMAC_PORT_FIFO_CFG_0_REG", GMAC_PORT_FIFO_CFG_0_REG);
+	pp3_gmac_reg_print(port, "GMAC_PORT_FIFO_CFG_1_REG", GMAC_PORT_FIFO_CFG_1_REG);
+
+	pp3_gmac_reg_print(port, "GMAC_PORT_ISR_CAUSE_REG", GMAC_PORT_ISR_CAUSE_REG);
+	pp3_gmac_reg_print(port, "GMAC_PORT_ISR_MASK_REG", GMAC_PORT_ISR_CAUSE_REG);
+	pp3_gmac_reg_print(port, "GMAC_PORT_ISR_SUM_CAUSE_REG", GMAC_PORT_ISR_SUM_CAUSE_REG);
+	pp3_gmac_reg_print(port, "GMAC_PORT_ISR_SUM_MASK_REG", GMAC_PORT_ISR_SUM_MASK_REG);
+}
+
+/******************************************************************************/
+/*                      MIB Counters functions                                */
+/******************************************************************************/
+
+/*******************************************************************************
+* pp3_gmac_mib_counter_read - Read a MIB counter
+*
+* DESCRIPTION:
+*       This function reads a MIB counter of a specific ethernet port.
+*       NOTE - Read from GMAC_MIB_GOOD_OCTETS_RECEIVED_LOW or
+*              GMAC_MIB_GOOD_OCTETS_SENT_LOW counters will return 64 bits value,
+*              so p_high_32 pointer should not be NULL in this case.
+*
+* INPUT:
+*       port        - Ethernet Port number.
+*       offset   - MIB counter offset.
+*
+* OUTPUT:
+*       u32*       p_high_32 - pointer to place where 32 most significant bits
+*                             of the counter will be stored.
+*
+* RETURN:
+*       32 low sgnificant bits of MIB counter value.
+*
+*******************************************************************************/
+u32 pp3_gmac_mib_counter_read(int port, unsigned int offset, u32 *p_high_32)
+{
+	u32 val_low_32, val_high_32;
+	int abs_offset;
+
+	val_low_32 = mv_pp3_hw_reg_read(pp3_gmac_base_addr_get() + GMAC_MIB_COUNTERS_BASE(port) + offset);
+
+	/* Implement FEr ETH. Erroneous Value when Reading the Upper 32-bits    */
+	/* of a 64-bit MIB Counter.                                             */
+	if ((offset == GMAC_MIB_GOOD_OCTETS_RECEIVED_LOW) || (offset == GMAC_MIB_GOOD_OCTETS_SENT_LOW)) {
+		abs_offset = pp3_gmac_base_addr_get() + GMAC_MIB_COUNTERS_BASE(port) + offset + 4;
+
+		val_high_32 = mv_pp3_hw_reg_read(abs_offset);
+
+		if (p_high_32 != NULL)
+			*p_high_32 = val_high_32;
+	}
+	return val_low_32;
+}
+
+/*******************************************************************************
+* pp3_gmac_mib_counters_clear - Clear all MIB counters
+*
+* DESCRIPTION:
+*       This function clears all MIB counters
+*
+* INPUT:
+*       port      - Ethernet Port number.
+*
+* RETURN:   void
+*
+*******************************************************************************/
+void pp3_gmac_mib_counters_clear(int port)
+{
+	int i, abs_offset;
+
+	/* Perform dummy reads from MIB counters */
+	/* Read of last counter clear all counter were read before */
+	for (i = GMAC_MIB_GOOD_OCTETS_RECEIVED_LOW; i <= GMAC_MIB_LATE_COLLISION; i += 4) {
+		abs_offset = pp3_gmac_base_addr_get() + GMAC_MIB_COUNTERS_BASE(port) + i;
+		mv_pp3_hw_reg_read(abs_offset);
+	}
+}
+
+static void pp3_gmac_mib_print(int port, u32 offset, char *mib_name)
+{
+	u32 reg_low, reg_high = 0;
+
+	reg_low = pp3_gmac_mib_counter_read(port, offset, &reg_high);
+
+	if (!reg_high)
+		pr_info("  %-32s: 0x%02x = %u\n", mib_name, offset, reg_low);
+	else
+		pr_info("  %-32s: 0x%02x = 0x%08x%08x\n", mib_name, offset, reg_high, reg_low);
+
+}
+
+/* Print MIB counters of the Ethernet port */
+void pp3_gmac_mib_counters_show(int port)
+{
+	/* TODO: check port value */
+
+	pr_info("\nMIBs: port=%d, base=0x%x\n", port, GMAC_MIB_COUNTERS_BASE(port));
+
+	pr_info("\n[Rx]\n");
+	pp3_gmac_mib_print(port, GMAC_MIB_GOOD_OCTETS_RECEIVED_LOW, "GOOD_OCTETS_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_BAD_OCTETS_RECEIVED, "BAD_OCTETS_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_UNICAST_FRAMES_RECEIVED, "UNCAST_FRAMES_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_BROADCAST_FRAMES_RECEIVED, "BROADCAST_FRAMES_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_MULTICAST_FRAMES_RECEIVED, "MULTICAST_FRAMES_RECEIVED");
+
+	pr_info("\n[RMON]\n");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_64_OCTETS, "FRAMES_64_OCTETS");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_65_TO_127_OCTETS, "FRAMES_65_TO_127_OCTETS");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_128_TO_255_OCTETS, "FRAMES_128_TO_255_OCTETS");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_256_TO_511_OCTETS, "FRAMES_256_TO_511_OCTETS");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_512_TO_1023_OCTETS, "FRAMES_512_TO_1023_OCTETS");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAMES_1024_TO_MAX_OCTETS, "FRAMES_1024_TO_MAX_OCTETS");
+
+	pr_info("\n[Tx]\n");
+	pp3_gmac_mib_print(port, GMAC_MIB_GOOD_OCTETS_SENT_LOW, "GOOD_OCTETS_SENT");
+	pp3_gmac_mib_print(port, GMAC_MIB_UNICAST_FRAMES_SENT, "UNICAST_FRAMES_SENT");
+	pp3_gmac_mib_print(port, GMAC_MIB_MULTICAST_FRAMES_SENT, "MULTICAST_FRAMES_SENT");
+	pp3_gmac_mib_print(port, GMAC_MIB_BROADCAST_FRAMES_SENT, "BROADCAST_FRAMES_SENT");
+	pp3_gmac_mib_print(port, GMAC_MIB_CRC_ERRORS_SENT, "CRC_ERRORS_SENT");
+
+	pr_info("\n[FC control]\n");
+	pp3_gmac_mib_print(port, GMAC_MIB_FC_RECEIVED, "FC_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_FC_SENT, "FC_SENT");
+
+	pr_info("\n[Errors]\n");
+	pp3_gmac_mib_print(port, GMAC_MIB_RX_FIFO_OVERRUN, "GMAC_MIB_RX_FIFO_OVERRUN");
+	pp3_gmac_mib_print(port, GMAC_MIB_UNDERSIZE_RECEIVED, "UNDERSIZE_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_FRAGMENTS_RECEIVED, "FRAGMENTS_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_OVERSIZE_RECEIVED, "OVERSIZE_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_JABBER_RECEIVED, "JABBER_RECEIVED");
+	pp3_gmac_mib_print(port, GMAC_MIB_MAC_RECEIVE_ERROR, "MAC_RECEIVE_ERROR");
+	pp3_gmac_mib_print(port, GMAC_MIB_BAD_CRC_EVENT, "BAD_CRC_EVENT");
+	pp3_gmac_mib_print(port, GMAC_MIB_COLLISION, "COLLISION");
+	/* This counter must be read last. Read it clear all the counters */
+	pp3_gmac_mib_print(port, GMAC_MIB_LATE_COLLISION, "LATE_COLLISION");
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.h b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.h
new file mode 100644
index 0000000..8f855e5
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac.h
@@ -0,0 +1,148 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gmac_h__
+#define __mv_gmac_h__
+
+#include "common/mv_hw_if.h"
+#include "common/mv_sw_if.h"
+#include "gmac/mv_gmac_regs.h"
+
+struct pp3_gmac_ctrl {
+	u32 base;
+	u32 flags;
+};
+
+/* mv_pp3_gmac_ctrl flags */
+
+
+#define MV_PP3_GMAC_F_DEBUG_BIT		0
+#define MV_PP3_GMAC_F_ATTACH_BIT	1
+
+#define MV_PP3_GMAC_F_DEBUG		(1 << MV_PP3_GMAC_F_DEBUG_BIT)
+#define MV_PP3_GMAC_F_ATTACH		(1 << MV_PP3_GMAC_F_ATTACH_BIT)
+
+
+/***************************************************************************/
+/*                          regs access functions                          */
+/***************************************************************************/
+void pp3_gmac_unit_base(int index, u32 base);
+u32  pp3_gmac_reg_read(int port, u32 reg);
+void pp3_gmac_reg_write(int port, u32 reg, u32 data);
+void pp3_gmac_base_addr_set(unsigned int addr);
+u32  pp3_gmac_base_addr_get(void);
+
+
+/***************************************************************************/
+/*                          inline functions                               */
+/***************************************************************************/
+static inline void pp3_gmac_isr_summary_mask(void)
+{
+	mv_pp3_hw_reg_write(pp3_gmac_base_addr_get() + ISR_SUM_MASK_REG, 0);
+}
+
+static inline void pp3_gmac_isr_summary_unmask(void)
+{
+	mv_pp3_hw_reg_write(pp3_gmac_base_addr_get() + ISR_SUM_MASK_REG,
+			ISR_SUM_PORT0_MASK | ISR_SUM_PORT1_MASK | 0x20 /* magic bit */);
+}
+
+static inline u32 pp3_gmac_isr_summary_cause_get(void)
+{
+	return mv_pp3_hw_reg_read(pp3_gmac_base_addr_get() + ISR_SUM_CAUSE_REG);
+}
+
+static inline u32 pp3_gmac_port_isr_cause_get(int port)
+{
+	return pp3_gmac_reg_read(port, GMAC_PORT_ISR_CAUSE_REG);
+}
+
+static inline void pp3_gmac_port_isr_mask(int port)
+{
+	pp3_gmac_reg_write(port, GMAC_PORT_ISR_MASK_REG, 0);
+}
+
+static inline void pp3_gmac_port_isr_unmask(int port)
+{
+	pp3_gmac_reg_write(port, GMAC_PORT_ISR_MASK_REG, GMAC_PORT_LINK_CHANGE_MASK);
+}
+
+static inline void pp3_gmac_port_sum_isr_mask(int port)
+{
+	pp3_gmac_reg_write(port, GMAC_PORT_ISR_SUM_MASK_REG, 0);
+}
+
+static inline void pp3_gmac_port_sum_isr_unmask(int port)
+{
+	pp3_gmac_reg_write(port, GMAC_PORT_ISR_SUM_MASK_REG, GMAC_PORT_ISR_SUM_INTERN_MASK);
+}
+
+void pp3_gmac_port_def_init(int port);
+void pp3_gmac_def_set(int port);
+void pp3_gmac_port_enable(int port);
+void pp3_gmac_port_diable(int port);
+void pp3_gmac_port_periodic_xon_set(int port, int enable);
+bool pp3_gmac_port_is_link_up(int port);
+int pp3_gmac_link_status(int port, struct mv_port_link_status *pstatus);
+void pp3_gmac_port_lb_set(int port, int is_gmii, int is_pcs_en);
+void pp3_gmac_port_reset_set(int port, bool set_reset);
+void pp3_gmac_port_power_up(int port, bool is_sgmii, bool isRgmii);
+void pp3_gmac_port_power_down(int port);
+char *pp3_gmac_speed_str_get(enum mv_port_speed speed);
+
+/******************************************************************************/
+/*                          Port Configuration functions                      */
+/******************************************************************************/
+int pp3_gmac_max_rx_size_set(int port, int max_rx_size);
+int pp3_gmac_force_link_mode_set(int port_num, bool force_link_up, bool force_link_down);
+int pp3_gmac_speed_duplex_set(int port_num, enum mv_port_speed speed, enum mv_port_duplex duplex);
+int pp3_gmac_speed_duplex_get(int port_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex);
+int pp3_gmac_fc_set(int port, enum mv_port_fc fc);
+void pp3_gmac_fc_get(int port, enum mv_port_fc *fc);
+int pp3_gmac_port_link_speed_fc(int port, enum mv_port_speed speed,
+				     int force_link_up);
+
+/******************************************************************************/
+/*                         PHY Control Functions                              */
+/******************************************************************************/
+void pp3_gmac_phy_addr_set(int port, int phy_addr);
+int pp3_gmac_phy_addr_get(int port);
+
+/****************************************/
+/*	MIB counters			*/
+/****************************************/
+u32 pp3_gmac_mib_counter_read(int port, u32 offset, u32 *p_high_32);
+void pp3_gmac_mib_counters_clear(int port);
+void pp3_gmac_mib_counters_show(int port);
+void pp3_gmac_port_regs(int port);
+/*
+void pp3_gmac_lms_regs(void);
+*/
+int mv_pp3_gmac_sysfs_exit(struct kobject *pp3_kobj);
+int mv_pp3_gmac_sysfs_init(struct kobject *pp3_kobj);
+
+#endif /* __mv_gmac_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_regs.h b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_regs.h
new file mode 100644
index 0000000..184bd09
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_regs.h
@@ -0,0 +1,296 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_gmac_regs_h__
+#define __mv_gmac_regs_h__
+/*
+#ifdef CONFIG_ARCH_MVEBU
+#include "mvNetConfig.h"
+#else
+#include "mvSysEthConfig.h"
+#endif
+*/
+
+#define PP3_GMAC_MAX			2
+#define GMAC_REG_BASE(_port_)		(0x4000 + (0x1000 * (_port_)))
+#define LMS_REG_BASE			(0x0)
+#define GMAC_MIB_COUNTERS_REG_BASE	(0x1000)
+
+#define MNG_EXTENDED_GLOBAL_CTRL_REG	(0x3000 + 0x5c)
+
+/****************************************/
+/*        MAC Unit Registers            */
+/****************************************/
+
+/**** Tri-Speed Ports MAC and CPU Port MAC Configuration Sub-Unit Registers ****/
+#define GMAC_CTRL_0_REG				(0x0000)
+
+#define GMAC_PORT_EN_BIT			0
+#define GMAC_PORT_EN_MASK			(1 << GMAC_PORT_EN_BIT)
+
+#define GMAC_PORT_TYPE_BIT			1
+#define GMAC_PORT_TYPE_MASK			(1 << GMAC_PORT_TYPE_BIT)
+#define GMAC_PORT_TYPE_SGMII			(0 << GMAC_PORT_TYPE_BIT)
+#define GMAC_PORT_TYPE_1000X			(1 << GMAC_PORT_TYPE_BIT)
+
+#define GMAC_MAX_RX_SIZE_OFFS			2
+#define GMAC_MAX_RX_SIZE_MASK			(0x1FFF << GMAC_MAX_RX_SIZE_OFFS)
+
+#define GMAC_GMAC_MIB_CNTR_EN_BIT		15
+#define GMAC_GMAC_MIB_CNTR_EN_MASK		(1 << GMAC_GMAC_MIB_CNTR_EN_BIT)
+/*-------------------------------------------------------------------------------*/
+
+#define GMAC_CTRL_1_REG				(0x0004)
+
+#define GMAC_PERIODIC_XON_EN_BIT		1
+#define GMAC_PERIODIC_XON_EN_MASK		(0x1 << GMAC_PERIODIC_XON_EN_BIT)
+
+#define GMAC_GMII_LB_EN_BIT			5
+#define GMAC_GMII_LB_EN_MASK			(1 << GMAC_GMII_LB_EN_BIT)
+
+#define GMAC_PCS_LB_EN_BIT			6
+#define GMAC_PCS_LB_EN_MASK			(1 << GMAC_PCS_LB_EN_BIT)
+
+#define GMAC_SA_LOW_OFFS			7
+#define GMAC_SA_LOW_MASK			(0xFF << GMAC_SA_LOW_OFFS)
+/*-------------------------------------------------------------------------------*/
+
+#define GMAC_CTRL_2_REG				(0x0008)
+
+#define GMAC_INBAND_AN_BIT			0
+#define GMAC_INBAND_AN_MASK			(1 << GMAC_INBAND_AN_BIT)
+
+#define GMAC_PCS_ENABLE_BIT			3
+#define GMAC_PCS_ENABLE_MASK			(1 << GMAC_PCS_ENABLE_BIT)
+
+#define GMAC_PORT_RGMII_BIT			4
+#define GMAC_PORT_RGMII_MASK			(1 << GMAC_PORT_RGMII_BIT)
+
+#define GMAC_PORT_RESET_BIT			6
+#define GMAC_PORT_RESET_MASK			(1 << GMAC_PORT_RESET_BIT)
+/*-------------------------------------------------------------------------------*/
+
+/**** Port Auto-Negotiation Configuration Sub-Unit Registers ****/
+#define GMAC_AN_CTRL_REG			(0x000C)
+
+#define GMAC_FORCE_LINK_FAIL_BIT		0
+#define GMAC_FORCE_LINK_FAIL_MASK		(1 << GMAC_FORCE_LINK_FAIL_BIT)
+
+#define GMAC_FORCE_LINK_PASS_BIT		1
+#define GMAC_FORCE_LINK_PASS_MASK		(1 << GMAC_FORCE_LINK_PASS_BIT)
+
+#define GMAC_SET_MII_SPEED_100_BIT		5
+#define GMAC_SET_MII_SPEED_100_MASK		(1 << GMAC_SET_MII_SPEED_100_BIT)
+
+#define GMAC_SET_GMII_SPEED_1000_BIT		6
+#define GMAC_SET_GMII_SPEED_1000_MASK		(1 << GMAC_SET_GMII_SPEED_1000_BIT)
+
+#define GMAC_ENABLE_SPEED_AUTO_NEG_BIT		7
+#define GMAC_ENABLE_SPEED_AUTO_NEG_MASK		(1 << GMAC_ENABLE_SPEED_AUTO_NEG_BIT)
+
+#define GMAC_ENABLE_FLOW_CTRL_AUTO_NEG_BIT	11
+#define GMAC_ENABLE_FLOW_CTRL_AUTO_NEG_MASK	(1 << GMAC_ENABLE_FLOW_CTRL_AUTO_NEG_BIT)
+
+/* TODO: I keep this bit even though it's not listed in Cider */
+#define GMAC_SET_FLOW_CONTROL_BIT		8
+#define GMAC_SET_FLOW_CONTROL_MASK		(1 << GMAC_SET_FLOW_CONTROL_BIT)
+
+#define GMAC_FLOW_CONTROL_ADVERTISE_BIT		9
+#define GMAC_FLOW_CONTROL_ADVERTISE_MASK	(1 << GMAC_FLOW_CONTROL_ADVERTISE_BIT)
+
+#define GMAC_FLOW_CONTROL_ASYMETRIC_BIT		10
+#define GMAC_FLOW_CONTROL_ASYMETRIC_MASK	(1 << GMAC_FLOW_CONTROL_ASYMETRIC_BIT)
+
+#define GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_BIT	11
+#define GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_MASK	(1 << GMAC_ENABLE_FLOW_CONTROL_AUTO_NEG_BIT)
+
+#define GMAC_SET_FULL_DUPLEX_BIT		12
+#define GMAC_SET_FULL_DUPLEX_MASK		(1 << GMAC_SET_FULL_DUPLEX_BIT)
+
+#define GMAC_ENABLE_DUPLEX_AUTO_NEG_BIT		13
+#define GMAC_ENABLE_DUPLEX_AUTO_NEG_MASK	(1 << GMAC_ENABLE_DUPLEX_AUTO_NEG_BIT)
+/*-------------------------------------------------------------------------------*/
+
+/**** Port Status Sub-Unit Registers ****/
+#define GMAC_STATUS_REG				(0x0010)
+
+#define GMAC_LINK_UP_BIT			0
+#define GMAC_LINK_UP_MASK			(1 << GMAC_LINK_UP_BIT)
+
+#define GMAC_SPEED_1000_BIT			1
+#define GMAC_SPEED_1000_MASK			(1 << GMAC_SPEED_1000_BIT)
+
+#define GMAC_SPEED_100_BIT			2
+#define GMAC_SPEED_100_MASK			(1 << GMAC_SPEED_100_BIT)
+
+#define GMAC_FULL_DUPLEX_BIT			3
+#define GMAC_FULL_DUPLEX_MASK			(1 << GMAC_FULL_DUPLEX_BIT)
+
+#define GMAC_RX_FLOW_CTRL_ENABLE_BIT		4
+#define GMAC_RX_FLOW_CTRL_ENABLE_MASK		(1 << GMAC_RX_FLOW_CTRL_ENABLE_BIT)
+
+#define GMAC_TX_FLOW_CTRL_ENABLE_BIT		5
+#define GMAC_TX_FLOW_CTRL_ENABLE_MASK		(1 << GMAC_TX_FLOW_CTRL_ENABLE_BIT)
+
+#define GMAC_RX_FLOW_CTRL_ACTIVE_BIT		6
+#define GMAC_RX_FLOW_CTRL_ACTIVE_MASK		(1 << GMAC_RX_FLOW_CTRL_ACTIVE_BIT)
+
+#define GMAC_TX_FLOW_CTRL_ACTIVE_BIT		7
+#define GMAC_TX_FLOW_CTRL_ACTIVE_MASK		(1 << GMAC_TX_FLOW_CTRL_ACTIVE_BIT)
+/*-------------------------------------------------------------------------------*/
+
+/**** Port Internal Sub-Unit Registers ****/
+#define GMAC_PORT_FIFO_CFG_0_REG		(0x0018)
+
+#define GMAC_PORT_FIFO_CFG_1_REG		(0x001C)
+
+#define GMAC_RX_FIFO_MAX_TH_OFFS		0
+
+#define GMAC_TX_FIFO_MIN_TH_OFFS		6
+#define GMAC_TX_FIFO_MIN_TH_ALL_MASK		(0x7F << GMAC_TX_FIFO_MIN_TH_OFFS)
+#define GMAC_TX_FIFO_MIN_TH_MASK(val)		(((val) << GMAC_TX_FIFO_MIN_TH_OFFS) & GMAC_TX_FIFO_MIN_TH_ALL_MASK)
+/*-------------------------------------------------------------------------------*/
+
+/**** Port Interrupt Sub-Unit Registers ****/
+#define GMAC_PORT_ISR_CAUSE_REG			(0x0020)
+
+#define GMAC_PORT_ISR_SUM_BIT			0
+#define GMAC_PORT_ISR_SUM_MASK			(1 << GMAC_PORT_ISR_SUM_BIT)
+
+#define GMAC_PORT_LINK_CHANGE_BIT		1
+#define GMAC_PORT_LINK_CHANGE_MASK		(1 << GMAC_PORT_LINK_CHANGE_BIT)
+
+#define GMAC_PORT_ISR_MASK_REG			(0x0024)
+
+#define GMAC_PORT_ISR_SUM_CAUSE_REG		(0x00A0)
+#define GMAC_PORT_ISR_SUM_MASK_REG		(0x00A4)
+
+#define GMAC_PORT_ISR_SUM_INTERN_BIT		0x1
+#define GMAC_PORT_ISR_SUM_INTERN_MASK		(1 << GMAC_PORT_ISR_SUM_INTERN_BIT)
+
+/*-------------------------------------------------------------------------------*/
+
+/****************************************/
+/*	LMS Unit Registers		*/
+/****************************************/
+
+/*
+ * PHY Address Ports 0 through 5 Register
+ */
+#define PHY_ADDR_REG				(LMS_REG_BASE + 0x30)
+#define PHY_ADDR_OFFS(port)			(port * 5)
+#define PHY_ADDR_MASK(port)			(0x1F << PHY_ADDR_OFFS(port))
+
+/*------------------------------------------------------------------------------
+ * PHY Auto-Negotiation Configuration Register0
+ */
+#define PHY_AN_CFG0_REG				(LMS_REG_BASE + 0x34)
+#define PHY_AN_CFG0_STOP_AN_SMI0_BIT		7
+#define PHY_AN_CFG0_STOP_AN_SMI0_MASK		(1 << PHY_AN_CFG0_STOP_AN_SMI0_BIT)
+#define PHY_AN_EN_OFFS(port)			(port)
+#define PHY_AN_EN_MASK(port)			(1 << PHY_AN_EN_OFFS(port))
+
+/*------------------------------------------------------------------------------
+ * Interrupt Summary Cause Register
+ */
+#define ISR_SUM_CAUSE_REG			(LMS_REG_BASE + 0x10)
+#define ISR_SUM_LMS_BIT				0
+#define ISR_SUM_LMS_MASK			(1 << ISR_SUM_LMS_BIT)
+
+#define ISR_SUM_LMS0_BIT			1
+#define ISR_SUM_LMS0_MASK			(1 << ISR_SUM_LMS0_BIT)
+
+#define ISR_SUM_LMS1_BIT			2
+#define ISR_SUM_LMS1_MASK			(1 << ISR_SUM_LMS1_BIT)
+
+#define ISR_SUM_LMS2_BIT			3
+#define ISR_SUM_LMS2_MASK			(1 << ISR_SUM_LMS2_BIT)
+
+#define ISR_SUM_LMS3_BIT			4
+#define ISR_SUM_LMS3_MASK			(1 << ISR_SUM_LMS3_BIT)
+
+#define ISR_SUM_PORTS_BIT			16
+#define ISR_SUM_PORTS_MASK			(1 << ISR_SUM_PORTS_BIT)
+
+#define ISR_SUM_PORT0_BIT			17
+#define ISR_SUM_PORT0_MASK			(1 << ISR_SUM_PORT0_BIT)
+
+#define ISR_SUM_PORT1_BIT			18
+#define ISR_SUM_PORT1_MASK			(1 << ISR_SUM_PORT1_BIT)
+
+#define ISR_SUM_PORT2_BIT			19
+#define ISR_SUM_PORT2_MASK			(1 << ISR_SUM_PORT2_BIT)
+
+#define ISR_SUM_MASK_REG			(LMS_REG_BASE + 0x220c)
+
+/*------------------------------------------------------------------------------
+ * SMI Management Register
+ */
+#define SMI_REG(port)				(LMS_REG_BASE + 0x54)
+
+/****************************************/
+/*	GMAC_MIB counters		*/
+/****************************************/
+
+#define GMAC_MIB_PORT_OFFSET(port)		((port) * 0x400)
+#define GMAC_MIB_COUNTERS_BASE(port)		(GMAC_MIB_COUNTERS_REG_BASE + GMAC_MIB_PORT_OFFSET(port))
+
+/* GMAC_MIB Counters register definitions */
+#define GMAC_MIB_GOOD_OCTETS_RECEIVED_LOW	0x0
+#define GMAC_MIB_GOOD_OCTETS_RECEIVED_HIGH	0x4
+#define GMAC_MIB_BAD_OCTETS_RECEIVED		0x8
+/* Reserved				0xc */
+#define GMAC_MIB_UNICAST_FRAMES_RECEIVED	0x10
+#define GMAC_MIB_CRC_ERRORS_SENT		0x14
+#define GMAC_MIB_BROADCAST_FRAMES_RECEIVED	0x18
+#define GMAC_MIB_MULTICAST_FRAMES_RECEIVED	0x1c
+#define GMAC_MIB_FRAMES_64_OCTETS		0x20
+#define GMAC_MIB_FRAMES_65_TO_127_OCTETS	0x24
+#define GMAC_MIB_FRAMES_128_TO_255_OCTETS	0x28
+#define GMAC_MIB_FRAMES_256_TO_511_OCTETS	0x2c
+#define GMAC_MIB_FRAMES_512_TO_1023_OCTETS	0x30
+#define GMAC_MIB_FRAMES_1024_TO_MAX_OCTETS	0x34
+#define GMAC_MIB_GOOD_OCTETS_SENT_LOW		0x38
+#define GMAC_MIB_GOOD_OCTETS_SENT_HIGH		0x3c
+#define GMAC_MIB_UNICAST_FRAMES_SENT		0x40
+/* Reserved					0x44 */
+#define GMAC_MIB_MULTICAST_FRAMES_SENT		0x48
+#define GMAC_MIB_BROADCAST_FRAMES_SENT		0x4c
+/* Reserved					0x50 */
+#define GMAC_MIB_FC_SENT			0x54
+#define GMAC_MIB_FC_RECEIVED			0x58
+#define GMAC_MIB_RX_FIFO_OVERRUN		0x5c
+#define GMAC_MIB_UNDERSIZE_RECEIVED		0x60
+#define GMAC_MIB_FRAGMENTS_RECEIVED		0x64
+#define GMAC_MIB_OVERSIZE_RECEIVED		0x68
+#define GMAC_MIB_JABBER_RECEIVED		0x6c
+#define GMAC_MIB_MAC_RECEIVE_ERROR		0x70
+#define GMAC_MIB_BAD_CRC_EVENT			0x74
+#define GMAC_MIB_COLLISION			0x78
+#define GMAC_MIB_LATE_COLLISION			0x7c
+#endif /* mv_gmac_regs */
diff --git a/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_sysfs.c b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_sysfs.c
new file mode 100644
index 0000000..340f102
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gmac/mv_gmac_sysfs.c
@@ -0,0 +1,138 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "gmac/mv_gmac.h"
+
+static ssize_t mv_gmac_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > regs       - show GMAC port registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]         > mib_cntrs  - show GMAC port MIB counters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [u] [v] > reg_write  - write register: gmac [p], address [u], value [v]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [u]     > reg_read   - read register: gmac [p], address [u]\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [p]  - gmac number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_gmac_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_gmac_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_gmac_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, u, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = u = v = 0;
+	sscanf(buf, "%x %x %x", &p, &u, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "regs"))
+		pp3_gmac_port_regs(p);
+	else if (!strcmp(name, "mib_cntrs"))
+		pp3_gmac_mib_counters_show(p);
+	else if (!strcmp(name, "reg_write"))
+		pp3_gmac_reg_write(p, u, v);
+	else if (!strcmp(name, "reg_read"))
+		pp3_gmac_reg_read(p, u);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help, S_IRUSR, mv_gmac_show, NULL);
+static DEVICE_ATTR(regs, S_IWUSR, NULL, mv_gmac_3_hex_store);
+static DEVICE_ATTR(reg_write, S_IWUSR, NULL, mv_gmac_3_hex_store);
+static DEVICE_ATTR(reg_read, S_IWUSR, NULL, mv_gmac_3_hex_store);
+static DEVICE_ATTR(mib_cntrs, S_IWUSR, NULL, mv_gmac_3_hex_store);
+
+
+static struct attribute *mv_gmac_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_reg_write.attr,
+	&dev_attr_reg_read.attr,
+	&dev_attr_mib_cntrs.attr,
+	NULL
+};
+
+static struct attribute_group mv_gmac_group = {
+	.name = "gmac",
+	.attrs = mv_gmac_attrs,
+};
+
+
+int mv_pp3_gmac_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &mv_gmac_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", mv_gmac_group.name, err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_gmac_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &mv_gmac_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss.h b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss.h
new file mode 100644
index 0000000..a2b3094
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss.h
@@ -0,0 +1,52 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "platform/mv_pp3.h"
+
+struct mv_pp3_vq_update_stats {
+	unsigned int	pkts_fill_lvl;       /* Current queue fill level, packets */
+	unsigned int	pkts_fill_lvl_max;   /* Maximum queue fill level, packets */
+	unsigned int	pkts_fill_lvl_sum;   /* Sum of pkts_fill_lvl */
+	unsigned int	bytes_fill_lvl;      /* Current queue fill level, octets */
+	unsigned int	bytes_fill_lvl_max;  /* Maximum queue fill level, octets */
+	unsigned int	bytes_fill_lvl_sum;  /* Sum of bytes_fill_lvl */
+	unsigned int	pkts_sum;
+	unsigned int	bytes_sum;
+};
+struct mv_pp3_vq_collect_stats {
+	struct pp3_swq_stats swq_ext_stats_base;
+	struct pp3_swq_stats swq_ext_stats_curr;
+	struct mv_pp3_fw_hwq_stat fw_ext_stats_curr;
+};
+
+/* Extension statistics DB */
+struct mv_pp3_stats_ext_vp {
+	int vport;
+	struct mv_pp3_vq_update_stats rx_vqs_stats[MV_PP3_VQ_NUM][CONFIG_NR_CPUS];
+	struct mv_pp3_vq_collect_stats rx_vqs_collect_stats[MV_PP3_VQ_NUM][CONFIG_NR_CPUS];
+	struct mv_pp3_timer	stats_timer;  /* Statistics collection timer */
+	struct spinlock		*stats_lock;  /* Spinlock for Statistics collection */
+	int time_elapsed;
+	int iter;
+};
+
+/* Simple statistics DB */
+struct mv_pp3_stats_simple_vp {
+	int vport;
+	struct mv_pp3_fw_hwq_stat hwq_stats_base[MV_PP3_VQ_NUM][CONFIG_NR_CPUS];
+};
diff --git a/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.c b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.c
new file mode 100644
index 0000000..bfbd73e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.c
@@ -0,0 +1,842 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+#include "platform/mv_pp3.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "net_dev/mv_dev_vq.h"
+#include "net_dev/mv_netdev.h"
+
+#include "mv_pp3_gnss_api.h"
+#include <net/gnss/mv_nss_defs.h>
+
+/* For external interfaces RX supported only on CPU0 */
+#define MV_PP3_GNSS_DEV_RX_CPUS_MASK	0x1
+
+static unsigned int mv_pp3_gnss_dev_rx_cpus_mask = MV_PP3_GNSS_DEV_RX_CPUS_MASK;
+static unsigned int mv_pp3_gnss_rxq_num = CONFIG_MV_PP3_GNSS_RXQ_NUM;
+static unsigned int mv_pp3_gnss_txq_num = CONFIG_MV_PP3_GNSS_TXQ_NUM;
+
+int mv_pp3_gnss_sys_init(void)
+{
+	int err;
+
+	if (pp3_device == NULL) {
+		pr_err("PP3 driver is not probed yet\n");
+		return -1;
+	}
+	if (mv_pp3_shared_initialized(pp3_device))
+		return 0;
+
+	rtnl_lock();
+	err = mv_pp3_shared_start(pp3_device);
+	rtnl_unlock();
+
+	return err;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_sys_init);
+
+int mv_pp3_gnss_dev_rx_cpus_set(unsigned int rx_cpus_mask)
+{
+	mv_pp3_gnss_dev_rx_cpus_mask = rx_cpus_mask;
+	return 0;
+}
+
+int mv_pp3_gnss_dev_rxqs_set(unsigned int rxqs)
+{
+	mv_pp3_gnss_rxq_num = rxqs;
+	return 0;
+}
+
+int mv_pp3_gnss_dev_txqs_set(unsigned int txqs)
+{
+	mv_pp3_gnss_txq_num = txqs;
+	return 0;
+}
+
+void mv_pp3_gnss_dev_init_show(void)
+{
+	pr_info("------- nssX network interfaces initialization parameters -------\n");
+	pr_info("Number of RX VQs         : %u\n", mv_pp3_gnss_rxq_num);
+	pr_info("Number of TX VQs         : %u\n", mv_pp3_gnss_txq_num);
+	pr_info("CPUs mask                : 0x%u\n", mv_pp3_gnss_dev_rx_cpus_mask);
+}
+
+/*---------------------------------------------------------------------------
+  mv_pp3_gnss_dev_create:
+	description: Create networke device with name gnss%d where %d is vport
+		     MTU, RXQs number and TXQs number are taken from globals defenititons
+
+	input      : vport - virtual port id
+		     state - network device state after creation
+
+	return     : 0 for success, otherwise return negative integer
+---------------------------------------------------------------------------*/
+int mv_pp3_gnss_dev_create(unsigned short vport, bool state, unsigned char *mac)
+{
+	int rc = 0;
+	char name[10];
+	struct net_device *dev;
+	struct pp3_dev_priv *dev_priv;
+	int msec;
+
+	sprintf(name, "nss%d", vport);
+
+	/* check MAC validation */
+	if (mac && !is_valid_ether_addr(mac))
+		return -EADDRNOTAVAIL;
+
+	dev = mv_pp3_netdev_init(name, mv_pp3_gnss_rxq_num, mv_pp3_gnss_txq_num);
+	if (!dev)
+		goto oom;
+
+	/* copy MAC */
+	if (mac)
+		memcpy(dev->dev_addr, mac, MV_MAC_ADDR_SIZE);
+
+	dev->mtu = MV_EXT_PORT_MTU;
+	dev_priv = MV_PP3_PRIV(dev);
+	dev_priv->id = vport;
+
+	if (mv_pp3_dev_rx_cpus_set(dev, mv_pp3_gnss_dev_rx_cpus_mask))
+		pr_warn("%s: Can't set rx_cpus mask\n", dev->name);
+
+	mv_pp3_netdev_show(dev);
+
+	if (state) {
+		rtnl_lock();
+		/* Disconnect TX from Linux stack */
+		netif_tx_stop_all_queues(dev);
+		/* Open external device and alloc HW recources */
+		rc = dev_open(dev);
+		rtnl_unlock();
+	}
+
+	if (rc < 0)
+		return rc;
+
+	/* Init statistics extension if already set */
+	msec = mv_pp3_gnss_ext_vport_msec_get();
+	if (msec)
+		rc = mv_pp3_gnss_ingress_vport_stats_init(vport, msec);
+
+	return rc;
+oom:
+	pr_err("%s: Out of memory\n", __func__);
+	return -ENOMEM;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_dev_create);
+
+/*---------------------------------------------------------------------------
+  mv_pp3_gnss_dev_delete:
+	description: delete networke device that attached to
+		     virtual port (external or EMAC)
+		     release all relevants HW resources and memories
+
+	input      : vport - virtual port id
+
+	return     : 0 for success, otherwise return negative integer
+---------------------------------------------------------------------------*/
+int mv_pp3_gnss_dev_delete(unsigned short vport)
+{
+	int err;
+	struct pp3_dev_priv *dev_priv;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n",
+				__func__,  vport);
+		return -ENODEV;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	/* stop network decive */
+	rtnl_lock();
+	err = dev_close(dev);
+	rtnl_unlock();
+
+	if (err < 0) {
+		pr_err("%s: failed to close network device %s\n", __func__, dev->name);
+		return err;
+	}
+
+	mv_pp3_netdev_delete(dev);
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_dev_delete);
+
+/*---------------------------------------------------------------------------
+  mv_pp3_gnss_vport_type_get:
+	description: get virtual port type
+		     External APIs can use this function in order to know if
+		     network device (for virtual port) created by driver or not.
+
+	input      : vport - virtual port id
+
+	return     : return virtual port type if netork device is exist,
+		     Otherwise return MV_NSS_PORT_INV.
+---------------------------------------------------------------------------*/
+enum mv_nss_port_type mv_pp3_gnss_vport_type_get(unsigned short vport)
+{
+	struct pp3_dev_priv *dev_priv;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev)
+		return MV_PP3_NSS_PORT_INV;
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	return dev_priv->vport->type;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_type_get);
+
+/*---------------------------------------------------------------------------
+  mv_pp3_gnss_vport_state_get:
+	description: check virtual port state state
+
+	input      : vport - virtual port id
+
+	return     : fail    - return negative integer if virtual
+			       port not created by driver
+		     success - 0 if virtual port is disabled
+			       1 if virtual port is enabled
+---------------------------------------------------------------------------*/
+int mv_pp3_gnss_vport_state_get(unsigned short vport)
+{
+	struct pp3_dev_priv *dev_priv;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	return dev_priv->vport->state;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_state_get);
+
+/*---------------------------------------------------------------------------
+  mv_pp3_gnss_vport_state_set:
+	description: set virtual port state in driver and FW
+		     driver call to standard Linux dev_open/dev_stop function
+		     for the network decive that connected to the virtual port.
+
+	input      : vport - virtual port id
+
+	return     : 0 for success, otherwise return negative integer
+---------------------------------------------------------------------------*/
+int mv_pp3_gnss_vport_state_set(unsigned short vport, bool enable)
+{
+	int ret_val;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+
+	rtnl_lock();
+	ret_val = enable ? dev_open(dev) : dev_close(dev);
+	rtnl_unlock();
+
+	return ret_val;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_state_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_mtu_get(unsigned short vport)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	return dev->mtu;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_mtu_get);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_mtu_set(unsigned short vport, int mtu)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rtnl_lock();
+	rc = dev_set_mtu(dev, mtu);
+	rtnl_unlock();
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_mtu_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_def_dst_get(unsigned short vport)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	return dev_priv->vport->dest_vp;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_def_dst_get);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_def_dst_set(unsigned short vport, unsigned short def_dst)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (pp3_fw_vport_def_dest_set(dev_priv->vport->vport, def_dst) < 0) {
+		pr_warn("%s Error: FW vport %d default destination update failed\n",
+				dev->name, def_dst);
+		return -1;
+	}
+	dev_priv->vport->dest_vp = def_dst;
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_def_dst_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_mcast_list_get(unsigned short vport, unsigned char *mac_list, int max_num, int *num)
+{
+	int count, offset;
+	struct netdev_hw_addr *ha;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: Failed on vport #%d. Applicable only for EMAC virtual ports\n", __func__, vport);
+		return -EINVAL;
+	}
+	count = offset = 0;
+	netdev_for_each_mc_addr(ha, dev) {
+		if (count >= max_num)
+			break;
+
+		memcpy(&mac_list[offset], ha->addr, MV_MAC_ADDR_SIZE);
+		offset += MV_MAC_ADDR_SIZE;
+		count++;
+		/*
+		pr_info("%02x:%02x:%02x:%02x:%02x:%02x\n",
+			macs_list[offset + 0], macs_list[offset + 1], macs_list[offset + 2],
+			macs_list[offset + 3], macs_list[offset + 4], macs_list[offset + 5]);
+		*/
+	}
+	if (num)
+		*num = count;
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_mcast_list_get);
+/*---------------------------------------------------------------------------*/
+
+/* Replace dev->mc list with new one */
+int mv_pp3_gnss_vport_mcast_list_set(unsigned short vport, unsigned char *mac_list, int num)
+{
+	int rc, i, offset;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: Failed on vport #%d. Applicable only for EMAC virtual ports\n", __func__, vport);
+		return -EINVAL;
+	}
+	dev_mc_flush(dev);
+	offset = 0;
+	for (i = 0; i < num; i++) {
+		rc = dev_mc_add(dev, &mac_list[offset]);
+		if (rc)
+			return -EINVAL;
+		offset += MV_MAC_ADDR_SIZE;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_mcast_list_set);
+/*---------------------------------------------------------------------------*/
+
+/* Delete (op=0) / Add (op=1) multicast address from L2 filter */
+int mv_pp3_gnss_vport_mcast_addr_set(unsigned short vport, unsigned char *mac_addr, int op)
+{
+	int rc = -EINVAL;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: Failed on vport #%d. Applicable only for EMAC virtual ports\n", __func__, vport);
+		return -EINVAL;
+	}
+	if (op == 0)
+		rc = dev_mc_del(dev, mac_addr);
+	else if (op == 1)
+		rc = dev_mc_add(dev, mac_addr);
+	else
+		pr_err("%s: unsupported command: op=%d on vp=%d (%s)\n",
+			__func__, op, vport, dev->name);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_mcast_addr_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_l2_options_get(unsigned short vport, unsigned char *l2_options)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: Failed on vport #%d. Applicable only for EMAC virtual ports\n", __func__, vport);
+		return -EINVAL;
+	}
+	*l2_options = dev_priv->vport->port.emac.l2_options;
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_l2_options_get);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_l2_options_set(unsigned short vport, unsigned char l2_options)
+{
+	int bit;
+	unsigned int changes;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: Failed on vport #%d. Applicable only for EMAC virtual ports\n", __func__, vport);
+		return -EINVAL;
+	}
+
+	/* set L2 features known to Linux */
+	if ((dev->flags & IFF_PROMISC) ^ (l2_options & MV_NSS_PROMISC_MODE)) {
+		/* Values are different. Update network device promiscous mode */
+		rtnl_lock();
+		dev_set_promiscuity(dev, (l2_options & MV_NSS_PROMISC_MODE) ? 1 : -1);
+		rtnl_unlock();
+	}
+
+	if ((dev->flags & IFF_ALLMULTI) ^ (l2_options & MV_NSS_ALL_MCAST_MODE)) {
+		/* Values are different. Update network device allmulticast mode */
+		rtnl_lock();
+		dev_set_allmulti(dev, (l2_options & MV_NSS_ALL_MCAST_MODE) ? 1 : -1);
+		rtnl_unlock();
+	}
+	/* For all other bits send only message to firmware */
+	changes = l2_options ^ dev_priv->vport->port.emac.l2_options;
+	for (bit = MV_NSS_L2_UCAST_PROMISC; bit < MV_NSS_L2_OPTION_LAST; bit++) {
+		if (changes & BIT(bit))
+			pp3_fw_port_l2_filter_mode(vport, bit, l2_options & BIT(bit));
+	}
+	/* remember L2 options were set */
+	dev_priv->vport->port.emac.l2_options = l2_options;
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_l2_options_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_cos_get(unsigned short vport, unsigned char *cos)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	*cos  = dev_priv->vport->cos;
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_cos_get);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_vport_cos_set(unsigned short vport, unsigned char cos)
+{
+#if 0 /* wait for FW support */
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	dev_priv = MV_PP3_PRIV(dev);
+	/* Add message */
+	if (pp3_fw_vport_cos_set(dev_priv->vport->vport, cos) < 0) {
+		pr_warn("%s Error: FW vport %d default CoS update failed\n", dev->name, cos);
+		return -1;
+	}
+	dev_priv->vport->cos = cos;
+#endif
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_vport_cos_set);
+/*---------------------------------------------------------------------------*/
+/* Function for VQ configuration */
+/* [vport] argument is EMAC or External virtual port. */
+
+/* Set drop parameters (TD and RED) for ingress [vq] of the [vport] */
+int mv_pp3_gnss_ingress_vq_drop_set(unsigned short vport, int vq, struct mv_nss_drop *drop)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_drop_set(dev, vq, drop);
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_drop_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get drop parameters (TD and RED) for ingress [vq] of the [vport] */
+int mv_pp3_gnss_ingress_vq_drop_get(unsigned short vport, int vq, struct mv_nss_drop *drop)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_drop_get(dev, vq, drop);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_drop_get);
+/*---------------------------------------------------------------------------*/
+
+/* Set scheduling parameters (prio and weight) for ingress [vq] of the [vport] */
+int mv_pp3_gnss_ingress_vq_sched_set(unsigned short vport, int vq, struct mv_nss_sched *sched)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_prio_set(dev, vq, sched->priority);
+	if (!rc)
+		rc = mv_pp3_dev_ingress_vq_weight_set(dev, vq, sched->weight);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_sched_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get scheduling parameters (prio and weight) for ingress [vq] of the [vport] */
+int mv_pp3_gnss_ingress_vq_sched_get(unsigned short vport, int vq, struct mv_nss_sched *sched)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_sched_get(dev, vq, sched);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_sched_get);
+/*---------------------------------------------------------------------------*/
+
+/* Map cos value to vq for ingress vq of the vport */
+int mv_pp3_gnss_ingress_cos_to_vq_set(unsigned short vport, int cos, int vq)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_cos_to_vq_set(dev, cos, vq);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_cos_to_vq_set);
+/*---------------------------------------------------------------------------*/
+
+/* get vq mapped on cos value for ingress vq of the vport */
+int mv_pp3_gnss_ingress_cos_to_vq_get(unsigned short vport, int cos, int *vq)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_cos_to_vq_get(dev, cos, vq);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_cos_to_vq_get);
+/*---------------------------------------------------------------------------*/
+
+/* Set ingress VQ size in packets - SWQ part of VQ */
+/* XOFF/XON threshold - must be less that RXQ capacity */
+int mv_pp3_gnss_ingress_vq_size_set(unsigned short vport, int vq, u16 length)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_size_set(dev, vq, length);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_size_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get ingress VQ size in packets - SWQ part of VQ */
+/* XOFF/XON threshold - must be less that RXQ capacity */
+int mv_pp3_gnss_ingress_vq_size_get(unsigned short vport, int vq, u16 *length)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_ingress_vq_size_get(dev, vq, length);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vq_size_get);
+/*---------------------------------------------------------------------------*/
+
+/* Set drop parameters (TD and RED) for egress [vq] of the [vport] */
+int mv_pp3_gnss_egress_vq_drop_set(unsigned short vport, int vq, struct mv_nss_drop *drop)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_drop_set(dev, vq, drop);
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_drop_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get drop parameters (TD and RED) for egress [vq] of the [vport] */
+int mv_pp3_gnss_egress_vq_drop_get(unsigned short vport, int vq, struct mv_nss_drop *drop)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_drop_get(dev, vq, drop);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_drop_get);
+/*---------------------------------------------------------------------------*/
+
+/* Set scheduling parameters (prio and weight) for ingress [vq] of the [vport] */
+int mv_pp3_gnss_egress_vq_sched_set(unsigned short vport, int vq, struct mv_nss_sched *sched)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_prio_set(dev, vq, sched->priority);
+	if (!rc)
+		rc = mv_pp3_dev_egress_vq_weight_set(dev, vq, sched->weight);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_sched_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get scheduling parameters (prio and weight) for egress [vq] of the [vport] */
+int mv_pp3_gnss_egress_vq_sched_get(unsigned short vport, int vq, struct mv_nss_sched *sched)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_sched_get(dev, vq, sched);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_sched_get);
+/*---------------------------------------------------------------------------*/
+
+/* Map cos value to vq for egress vq of the vport */
+int mv_pp3_gnss_egress_cos_to_vq_set(unsigned short vport, int cos, int vq)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_cos_to_vq_set(dev, cos, vq);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_cos_to_vq_set);
+/*---------------------------------------------------------------------------*/
+
+/* get vq mapped on cos value for egress vq of the vport */
+int mv_pp3_gnss_egress_cos_to_vq_get(unsigned short vport, int cos, int *vq)
+{
+	int rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_cos_to_vq_get(dev, cos, vq);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_cos_to_vq_get);
+/*---------------------------------------------------------------------------*/
+
+/* Set egress VQ size in packets - SWQ part of VQ */
+/* Must be less than egress VQ capacity defined in Kconfig */
+int mv_pp3_gnss_egress_vq_size_set(unsigned short vport, int vq, u16 length)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_size_set(dev, vq, length);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_size_set);
+/*---------------------------------------------------------------------------*/
+
+/* Get egress VQ size in packets - SWQ part of VQ */
+int mv_pp3_gnss_egress_vq_size_get(unsigned short vport, int vq, u16 *length)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_size_get(dev, vq, length);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_size_get);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_egress_vq_rate_limit_set(unsigned short vport, int vq, struct mv_nss_meter *meter)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_rate_limit_set(dev, vq, meter);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_rate_limit_set);
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_egress_vq_rate_limit_get(unsigned short vport, int vq, struct mv_nss_meter *meter)
+{
+	int rc;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+
+	if (!dev) {
+		pr_err("%s: network device for virtual port %d not exist\n", __func__,  vport);
+		return -ENODEV;
+	}
+	rc = mv_pp3_dev_egress_vq_rate_limit_get(dev, vq, meter);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_egress_vq_rate_limit_get);
+
diff --git a/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.h b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.h
new file mode 100644
index 0000000..92190a1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_api.h
@@ -0,0 +1,96 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/* This file provides interface between external application and driver functionality */
+
+#include "platform/mv_pp3_defs.h"
+#include <linux/types.h>
+#include <net/gnss/mv_nss_defs.h>
+
+int mv_pp3_gnss_sys_init(void);
+int mv_pp3_gnss_dev_create(unsigned short vport, bool state, unsigned char *mac);
+int mv_pp3_gnss_dev_delete(unsigned short vport);
+int mv_pp3_gnss_dev_rx_cpus_set(unsigned int rx_cpus_mask);
+int mv_pp3_gnss_dev_rxqs_set(unsigned int rxqs);
+int mv_pp3_gnss_dev_txqs_set(unsigned int txqs);
+void mv_pp3_gnss_dev_init_show(void);
+enum mv_nss_port_type mv_pp3_gnss_vport_type_get(unsigned short vport);
+
+/* Virtual port functions */
+int mv_pp3_gnss_vport_mtu_get(unsigned short vport);
+int mv_pp3_gnss_vport_mtu_set(unsigned short vport, int mtu);
+
+int mv_pp3_gnss_vport_state_get(unsigned short vport);
+int mv_pp3_gnss_vport_state_set(unsigned short vport, bool enable);
+
+int mv_pp3_gnss_vport_def_dst_get(unsigned short vport);
+int mv_pp3_gnss_vport_def_dst_set(unsigned short vport, unsigned short def_dst);
+
+int mv_pp3_gnss_vport_ucast_list_get(unsigned short vport, unsigned char *mac_list, int max_num, int *num);
+int mv_pp3_gnss_vport_ucast_list_set(unsigned short vport, unsigned char *mac_list, int num);
+/* Delete (op=0) / Add (op=1) unicast address from L2 filter */
+int mv_pp3_gnss_vport_ucast_addr_set(unsigned short vport, unsigned char *mac_addr, int op);
+
+int mv_pp3_gnss_vport_mcast_list_get(unsigned short vport, unsigned char *mac_list, int max_num, int *num);
+int mv_pp3_gnss_vport_mcast_list_set(unsigned short vport, unsigned char *mac_list, int num);
+/* Delete (op=0) / Add (op=1) multicast address from L2 filter */
+int mv_pp3_gnss_vport_mcast_addr_set(unsigned short vport, unsigned char *mac_addr, int op);
+
+int mv_pp3_gnss_vport_l2_options_get(unsigned short vport, unsigned char *l2_options);
+int mv_pp3_gnss_vport_l2_options_set(unsigned short vport, unsigned char l2_options);
+
+int mv_pp3_gnss_vport_cos_get(unsigned short vport, unsigned char *cos);
+int mv_pp3_gnss_vport_cos_set(unsigned short vport, unsigned char cos);
+
+/* Function for VQ configuration */
+/* [vport] argument is EMAC or External virtual port. */
+int mv_pp3_gnss_ingress_vq_drop_set(unsigned short vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_gnss_ingress_vq_drop_get(unsigned short vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_gnss_ingress_vq_sched_set(unsigned short vport, int vq, struct mv_nss_sched *sched);
+int mv_pp3_gnss_ingress_vq_sched_get(unsigned short vport, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_gnss_ingress_cos_to_vq_set(unsigned short vport, int cos, int vq);
+int mv_pp3_gnss_ingress_cos_to_vq_get(unsigned short vport, int cos, int *vq);
+
+int mv_pp3_gnss_ingress_vq_size_set(unsigned short vport, int vq, u16 length);
+int mv_pp3_gnss_ingress_vq_size_get(unsigned short vport, int vq, u16 *length);
+
+
+int mv_pp3_gnss_egress_vq_drop_set(unsigned short vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_gnss_egress_vq_drop_get(unsigned short vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_gnss_egress_vq_sched_set(unsigned short vport, int vq, struct mv_nss_sched *sched);
+int mv_pp3_gnss_egress_vq_sched_get(unsigned short vport, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_gnss_egress_cos_to_vq_set(unsigned short vport, int cos, int vq);
+int mv_pp3_gnss_egress_cos_to_vq_get(unsigned short vport, int cos, int *vq);
+
+int mv_pp3_gnss_egress_vq_size_set(unsigned short vport, int vq, u16 length);
+int mv_pp3_gnss_egress_vq_size_get(unsigned short vport, int vq, u16 *length);
+
+int mv_pp3_gnss_egress_vq_rate_limit_set(unsigned short vport, int vq, struct mv_nss_meter *meter);
+int mv_pp3_gnss_egress_vq_rate_limit_get(unsigned short vport, int vq, struct mv_nss_meter *meter);
+
+int mv_pp3_gnss_ingress_vport_stats_init(int vport, unsigned int msec); /* stop to collect statistics if if msec = 0*/
+int mv_pp3_gnss_ingress_msec_all_set(unsigned int msec);
+int mv_pp3_gnss_ingress_vport_stats_get(int vport, bool clean, int size, struct mv_nss_vq_stats res_stats[]);
+int mv_pp3_gnss_ingress_vport_ext_stats_get(int vport, bool clean, int size,
+						struct mv_nss_vq_advance_stats res_stats[]);
+int mv_pp3_gnss_ingress_vport_ext_stats_clean(int vport);
+int mv_pp3_gnss_ingress_vport_stats_clean(int vport);
+int mv_pp3_gnss_ext_vport_msec_get(void);
+
diff --git a/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_stats_api.c b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_stats_api.c
new file mode 100644
index 0000000..e1cae96
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gnss/mv_pp3_gnss_stats_api.c
@@ -0,0 +1,712 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "platform/mv_pp3.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "net_dev/mv_dev_vq.h"
+#include "net_dev/mv_netdev.h"
+#include "net_dev/mv_dev_dbg.h"
+#include "mv_pp3_gnss_api.h"
+#include "mv_pp3_gnss.h"
+#include <net/gnss/mv_nss_defs.h>
+
+#define MV_PP3_GNSS_STATS_COLLECTOR_CPU_ID	1
+#define MV_PP3_GNSS_STATS_USEC_DEF		20000
+/*---------------------------------------------------------------------------*/
+/*				Globals					     */
+/*---------------------------------------------------------------------------*/
+static int ext_vport_msec;
+static struct mv_pp3_stats_ext_vp *mv_ext_vports[MV_NSS_EXT_PORT_MAX + 1];
+static struct mv_pp3_stats_simple_vp mv_simple_vports[MV_NSS_EXT_PORT_MAX + 1];
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_vq_reset_flag_get(int vport, int vq, int cpu)
+{
+	struct net_device *dev;
+	struct pp3_dev_priv *dev_priv;
+	int reset;
+
+	dev = mv_pp3_vport_dev_get(vport);
+	MV_PP3_NULL_PTR(dev, err);
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (mv_pp3_ingress_vq_reset_stats_get(dev_priv->cpu_vp[cpu], vq, &reset) < 0)
+		goto err;
+
+	return reset;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_vq_reset_flag_set(int vport, int vq, int cpu, int reset)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	MV_PP3_NULL_PTR(dev, err);
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (mv_pp3_ingress_vq_reset_stats_set(dev_priv->cpu_vp[cpu], vq, reset) < 0)
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_ingress_hwq_stats(int vport, int vq, int cpu, struct mv_pp3_fw_hwq_stat *hwq_stat)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	unsigned short hwq = dev_priv->cpu_vp[cpu]->rx_vqs[vq]->hwq;
+
+	if (pp3_fw_hwq_stat_get(hwq, false, hwq_stat)) {
+		pr_err("%s:Can't read HWQ #%d statistics from FW\n", __func__, hwq);
+		return -1;
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* return SWQ stats per CPU */
+static struct pp3_swq_stats *mv_pp3_ingress_vq_stats(int vport, int vq, int cpu)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct pp3_dev_priv *dev_priv;
+
+	MV_PP3_NULL_PTR(dev, err);
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	return mv_pp3_ingress_vq_sw_stats(dev_priv->cpu_vp[cpu], vq);
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+static struct mv_pp3_vq_update_stats *mv_pp3_update_stats_get(int vport, int vq, int cpu)
+{
+	if ((vport > MV_NSS_EXT_PORT_MAX) || (vq > MV_PP3_VQ_NUM) || (cpu > CONFIG_NR_CPUS)) {
+		pr_err("%s: function failed\n", __func__);
+		return NULL;
+	}
+
+	return &mv_ext_vports[vport]->rx_vqs_stats[vq][cpu];
+}
+/*---------------------------------------------------------------------------*/
+static struct mv_pp3_vq_collect_stats *mv_pp3_stats_collect_get(int vport, int vq, int cpu)
+{
+	if ((vport > MV_NSS_EXT_PORT_MAX) || (vq > MV_PP3_VQ_NUM) || (cpu > CONFIG_NR_CPUS)) {
+		pr_err("%s: function failed\n", __func__);
+		return NULL;
+	}
+	if (mv_ext_vports[vport])
+		return &mv_ext_vports[vport]->rx_vqs_collect_stats[vq][cpu];
+
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+static struct mv_pp3_fw_hwq_stat *mv_pp3_stats_hwq_base_get(int vport, int vq, int cpu)
+{
+	if ((vport > MV_NSS_EXT_PORT_MAX) || (vq > MV_PP3_VQ_NUM) || (cpu > CONFIG_NR_CPUS)) {
+		pr_err("%s: function failed\n", __func__);
+		return NULL;
+	}
+	return &mv_simple_vports[vport].hwq_stats_base[vq][cpu];
+}
+/*---------------------------------------------------------------------------*/
+/* Update base for simple statistics */
+static int mv_pp3_gnss_ingress_vq_stats_clean(int vport, int vq, int cpu)
+{
+	struct mv_pp3_fw_hwq_stat *hwq_stats_base;
+
+	hwq_stats_base = mv_pp3_stats_hwq_base_get(vport, vq, cpu);
+
+	/* overrite simple stats base */
+	if (mv_pp3_ingress_hwq_stats(vport, vq, cpu, hwq_stats_base) < 0) {
+		pr_err("%s: failed to collect fw vport %d vq %d statistics\n", __func__, vport, vq);
+		return -1;
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_ingress_vq_stats_update_after_dev_reset(int vport, int vq, int cpu)
+{
+	struct mv_pp3_vq_collect_stats *collect_stats = mv_pp3_stats_collect_get(vport, vq, cpu);
+	struct pp3_swq_stats *swq_stats;
+
+	/* update ext stats base */
+	if (collect_stats) {
+		swq_stats = mv_pp3_ingress_vq_stats(vport, vq, cpu);
+		memcpy(&collect_stats->swq_ext_stats_base, swq_stats, sizeof(struct pp3_swq_stats));
+	}
+
+	if (mv_pp3_gnss_ingress_vq_stats_clean(vport, vq, cpu) < 0) {
+		pr_err("%s: function failed\n", __func__);
+		return -1;
+	}
+
+	pr_info("vp#%d vq#%d, cpu#%d: Sync statistics DB after reset\n", vport, vq, cpu);
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+/* update counters base after reset */
+
+
+static int mv_pp3_ingress_vq_stats_collect(int vport, int vq, int cpu)
+{
+	struct mv_pp3_vq_collect_stats *collect_stats = mv_pp3_stats_collect_get(vport, vq, cpu);
+	struct pp3_swq_stats *swq_stats = mv_pp3_ingress_vq_stats(vport, vq, cpu);
+
+	collect_stats->swq_ext_stats_curr.pkts = swq_stats->pkts;
+	collect_stats->swq_ext_stats_curr.bytes = swq_stats->bytes;
+	collect_stats->swq_ext_stats_curr.pkts_drop = swq_stats->pkts_drop;
+	collect_stats->swq_ext_stats_curr.pkts_errors = swq_stats->pkts_errors;
+
+	if (mv_pp3_ingress_hwq_stats(vport, vq, cpu, &collect_stats->fw_ext_stats_curr) < 0) {
+		pr_err("%s: failed to collect fw vport %d vq %d statistics\n", __func__, vport, vq);
+		return -1;
+	}
+	if (mv_pp3_vq_reset_flag_get(vport, vq, cpu)) {
+		if (mv_pp3_ingress_vq_stats_update_after_dev_reset(vport, vq, cpu) < 0) {
+			pr_err("%s: function failed\n", __func__);
+			return -1;
+		}
+		mv_pp3_vq_reset_flag_set(vport, vq, cpu, false);
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_ingress_vq_stats_update(int vport, int vq, int cpu)
+{
+	struct mv_pp3_vq_update_stats *ext_stats = mv_pp3_update_stats_get(vport, vq, cpu);
+	struct mv_pp3_vq_collect_stats *collect_stats = mv_pp3_stats_collect_get(vport, vq, cpu);
+	unsigned long flags = 0;
+	struct spinlock	*stats_lock = mv_ext_vports[vport]->stats_lock;
+	uint64_t temp64;
+
+	MV_LOCK(stats_lock, flags);
+
+	/* pkts calculation */
+	ext_stats->pkts_sum = collect_stats->swq_ext_stats_curr.pkts - collect_stats->swq_ext_stats_base.pkts;
+
+	temp64 = (((uint64_t)collect_stats->fw_ext_stats_curr.hwq_pkt_high << 31)
+			| (uint64_t)collect_stats->fw_ext_stats_curr.hwq_pkt_low);
+
+	ext_stats->pkts_fill_lvl = (unsigned int)(temp64 & 0xFFFFFFFF) - collect_stats->swq_ext_stats_curr.pkts;
+
+	ext_stats->pkts_fill_lvl_sum += ext_stats->pkts_fill_lvl;
+	ext_stats->pkts_fill_lvl_max = MV_MAX(ext_stats->pkts_fill_lvl_max, ext_stats->pkts_fill_lvl);
+
+	ext_stats->bytes_sum = collect_stats->swq_ext_stats_curr.bytes - collect_stats->swq_ext_stats_base.bytes;
+
+	temp64 = (((uint64_t)collect_stats->fw_ext_stats_curr.hwq_oct_high << 31)
+			| (uint64_t)collect_stats->fw_ext_stats_curr.hwq_oct_low);
+
+	ext_stats->bytes_fill_lvl = (unsigned int)(temp64 & 0xFFFFFFFF) - collect_stats->swq_ext_stats_curr.bytes;
+
+	ext_stats->bytes_fill_lvl_sum += ext_stats->bytes_fill_lvl;
+	ext_stats->bytes_fill_lvl_max = MV_MAX(ext_stats->bytes_fill_lvl_max, ext_stats->bytes_fill_lvl);
+	MV_UNLOCK(stats_lock, flags);
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_stats_callback(unsigned long data)
+{
+	struct mv_pp3_stats_ext_vp *vp_priv = (struct mv_pp3_stats_ext_vp *)data;
+	int vport = vp_priv->vport;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct mv_pp3_timer *stats_timer = &vp_priv->stats_timer;
+	int cpu, vq, vq_num;
+
+	vp_priv->time_elapsed += stats_timer->usec;
+	vp_priv->iter++;
+
+	for_each_possible_cpu(cpu) {
+		if (!mv_pp3_dev_cpu_inuse(dev, cpu))
+			continue;
+		vq_num = mv_pp3_dev_rxvq_num_get(dev, cpu);
+
+		for (vq = 0; vq < vq_num; vq++) {
+			mv_pp3_ingress_vq_stats_collect(vport, vq, cpu);
+			mv_pp3_ingress_vq_stats_update(vport, vq, cpu);
+
+		}
+	}
+	mv_pp3_timer_complete(stats_timer);
+
+	if (stats_timer->usec)
+		mv_pp3_timer_add(stats_timer);
+}
+
+/*---------------------------------------------------------------------------*/
+/* Set msec for all external (WLAN) vports statistic timers		     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ingress_msec_all_set(unsigned int msec)
+{
+	int vport;
+
+	if (msec == ext_vport_msec) {
+		pr_info("No change in extended statistics configuration\n");
+		return -1;
+	}
+
+	if ((msec != 0) && (msec < jiffies_to_msecs(1))) {
+		pr_err("Invalid time interval, must be >= %d msec\n", jiffies_to_msecs(1));
+		return -1;
+	}
+
+	pr_info("Reset extended statistics\n");
+
+	for (vport = MV_NSS_EXT_PORT_MIN; vport < MV_NSS_EXT_PORT_MAX + 1; vport++)
+		if (mv_pp3_vport_dev_get(vport))
+			mv_pp3_gnss_ingress_vport_stats_init(vport, msec);
+
+	if (!ext_vport_msec && msec)
+		pr_info("Enable extended staistics, set time interval to %d msec\n", msec);
+
+	else if (ext_vport_msec && msec)
+		pr_info("Set extended staistics time interval to %d msec\n", msec);
+
+	else
+		pr_info("Disable extended statistics\n");
+
+	ext_vport_msec = msec;
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_msec_all_set);
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ext_vport_msec_get(void)
+{
+	return ext_vport_msec;
+}
+/*---------------------------------------------------------------------------*/
+static struct mv_pp3_stats_ext_vp *mv_pp3_gnss_ingress_vport_stats_alloc(int vport)
+{
+	struct mv_pp3_stats_ext_vp *vp_priv;
+	int rc;
+
+	if (vport > MV_NSS_EXT_PORT_MAX) {
+		pr_err("%s: virtual port %d is out of range\n", __func__, vport);
+		return NULL;
+	}
+	vp_priv = kzalloc(sizeof(struct mv_pp3_stats_ext_vp), GFP_KERNEL);
+
+	if (!vp_priv) {
+		pr_err("%s: Out of memory\n", __func__);
+		return NULL;
+	}
+
+	vp_priv->stats_lock = kzalloc(sizeof(struct spinlock), GFP_KERNEL);
+
+	if (!vp_priv->stats_lock) {
+		pr_err("%s: Out of memory\n", __func__);
+		return NULL;
+	}
+
+	spin_lock_init(vp_priv->stats_lock);
+
+	rc = mv_pp3_timer_init(&vp_priv->stats_timer,
+				MV_PP3_GNSS_STATS_COLLECTOR_CPU_ID,
+				MV_PP3_GNSS_STATS_USEC_DEF,
+				MV_PP3_WORKQUEUE, mv_pp3_stats_callback,
+				(unsigned long)vp_priv);
+	if (rc < 0)
+		return NULL;
+
+	vp_priv->vport = vport;
+
+	/*pr_info("Initialized vport #%d statistic extenstion\n", vport);*/
+
+	return vp_priv;
+}
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ingress_vport_stats_init(int vport, unsigned int msec)
+{
+	struct mv_pp3_stats_ext_vp *vp_priv;
+	int rc;
+
+
+	if ((msec != 0) && (msec < jiffies_to_msecs(1))) {
+		pr_err("Invalid time period, must be >= %d msec\n", jiffies_to_msecs(1));
+		return -1;
+	}
+
+	if (vport > MV_NSS_EXT_PORT_MAX) {
+		pr_err("%s: Invalid virtual port %d\n", __func__, vport);
+		return -1;
+	}
+
+	if (!mv_ext_vports[vport]) {
+		mv_ext_vports[vport] = mv_pp3_gnss_ingress_vport_stats_alloc(vport);
+
+		if (!mv_ext_vports[vport])
+			return -1;
+	}
+
+	vp_priv = mv_ext_vports[vport];
+
+	/* if msec = 0 timer will stop */
+	rc = mv_pp3_timer_usec_set(&vp_priv->stats_timer, msec * 1000);
+
+	if (msec) {
+		mv_pp3_gnss_ingress_vport_ext_stats_clean(vport);
+		mv_pp3_timer_add(&vp_priv->stats_timer);
+	}
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vport_stats_init);
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ingress_vport_stats_clean(int vport)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	int cpu, vq, vq_num = 0;
+
+	if (!dev)
+		goto err;
+
+	if (vport > MV_NSS_EXT_PORT_MAX) {
+		pr_err("%s: Invalid virtual port %d\n", __func__, vport);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+
+		if (!mv_pp3_dev_cpu_inuse(dev, cpu))
+			continue;
+
+		vq_num = mv_pp3_dev_rxvq_num_get(dev, cpu);
+
+		for (vq = 0; vq < vq_num; vq++) {
+			/* clean vq advanced statistics */
+			if  (mv_pp3_gnss_ingress_vq_stats_clean(vport, vq, cpu))
+				goto err;
+		}
+	}
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vport_stats_clean);
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ingress_vport_stats_get(int vport, bool clean, int size, struct mv_nss_vq_stats res_stats[])
+{
+	int cpu, vq, vq_num, rc = 0;
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct mv_pp3_fw_hwq_stat hwq_stats, *hwq_stats_base;
+	uint64_t temp64, temp64_base;
+
+	 if (!dev) {
+		pr_err("%s: function failed\n", __func__);
+		return -1;
+	}
+	/* clear input */
+	memset(res_stats, 0, sizeof(struct mv_nss_vq_stats) * size);
+
+	for_each_possible_cpu(cpu) {
+
+		if (!mv_pp3_dev_cpu_inuse(dev, cpu))
+			continue;
+
+		vq_num = mv_pp3_dev_rxvq_num_get(dev, cpu);
+
+		if (size > vq_num) {
+			pr_err("%s: vport %d have only %d rx virtual queues\n",
+						__func__, vport, vq_num);
+			return -1;
+		}
+
+		for (vq = 0; vq < size; vq++) {
+			if (mv_pp3_vq_reset_flag_get(vport, vq, cpu)) {
+					if (mv_pp3_ingress_vq_stats_update_after_dev_reset(vport, vq, cpu) < 0) {
+						pr_err("%s: function failed\n", __func__);
+						return -1;
+					}
+					mv_pp3_vq_reset_flag_set(vport, vq, cpu, false);
+			}
+			if (mv_pp3_ingress_hwq_stats(vport, vq, cpu, &hwq_stats) < 0) {
+				pr_err("%s: failed to read fw vport %d vq %d statistics\n", __func__, vport, vq);
+				return -1;
+			}
+			hwq_stats_base  = mv_pp3_stats_hwq_base_get(vport, vq, cpu);
+			/* calc packets */
+			temp64_base = (((uint64_t)hwq_stats_base->hwq_pkt_high << 31) |
+							(uint64_t)hwq_stats_base->hwq_pkt_low);
+			temp64 = (((uint64_t)hwq_stats.hwq_pkt_high << 31) |
+							(uint64_t)hwq_stats.hwq_pkt_low);
+			res_stats[vq].pkts += (unsigned int)((temp64 - temp64_base) & 0xFFFFFFFF);
+
+			/* octets packets */
+			temp64_base = (((uint64_t)hwq_stats_base->hwq_oct_high << 31) |
+							(uint64_t)hwq_stats_base->hwq_oct_low);
+			temp64 = (((uint64_t)hwq_stats.hwq_oct_high << 31) |
+							(uint64_t)hwq_stats.hwq_oct_low);
+			res_stats[vq].octets += (unsigned int)((temp64 - temp64_base) & 0xFFFFFFFF);
+
+			/* drops packets */
+			temp64_base = (((uint64_t)hwq_stats_base->hwq_pkt_drop_high << 31) |
+							(uint64_t)hwq_stats_base->hwq_pkt_drop_low);
+			temp64 = (((uint64_t)hwq_stats.hwq_pkt_drop_high << 31) |
+								(uint64_t)hwq_stats.hwq_pkt_drop_low);
+			res_stats[vq].drops += (unsigned int)((temp64 - temp64_base) & 0xFFFFFFFF);
+
+			/* errors packets - not supported, FW and SW do not count errors */
+		}
+	}
+	if (clean)
+		rc = mv_pp3_gnss_ingress_vport_stats_clean(vport);
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vport_stats_get);
+
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_gnss_ingress_vq_ext_stats_clean(int vport, int vq, int cpu)
+{
+	struct mv_pp3_vq_update_stats *ext_stats;
+	struct mv_pp3_vq_collect_stats *collect_stats = mv_pp3_stats_collect_get(vport, vq, cpu);
+	struct pp3_swq_stats *swq_stats = mv_pp3_ingress_vq_stats(vport, vq, cpu);
+
+	ext_stats = mv_pp3_update_stats_get(vport, vq, cpu);
+
+	if (!ext_stats)
+		return -1;
+
+	/* clean vq advanced statistics */
+	ext_stats->pkts_fill_lvl = 0;
+	ext_stats->pkts_fill_lvl_max = 0;
+	ext_stats->pkts_fill_lvl_sum = 0;
+	ext_stats->pkts_sum = 0;
+	ext_stats->bytes_fill_lvl = 0;
+	ext_stats->bytes_fill_lvl_max = 0;
+	ext_stats->bytes_fill_lvl_sum = 0;
+	ext_stats->bytes_sum = 0;
+	memcpy(&collect_stats->swq_ext_stats_base, swq_stats, sizeof(struct pp3_swq_stats));
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_gnss_ingress_vport_ext_stats_clean(int vport)
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct mv_pp3_stats_ext_vp *vp_priv;
+	int cpu, vq, vq_num = 0;
+
+	if (!dev)
+		goto err;
+
+
+	if (vport > MV_NSS_EXT_PORT_MAX) {
+		pr_err("%s: Invalid virtual port %d\n", __func__, vport);
+		return -1;
+	}
+
+	vp_priv = mv_ext_vports[vport];
+
+	if (!vp_priv)
+		return -1;
+
+	for_each_possible_cpu(cpu) {
+
+		if (!mv_pp3_dev_cpu_inuse(dev, cpu))
+			continue;
+
+		vq_num = mv_pp3_dev_rxvq_num_get(dev, cpu);
+
+		for (vq = 0; vq < vq_num; vq++) {
+
+			/* clean timer time elapsed counter */
+			vp_priv->time_elapsed = 0;
+
+			/* clean timer iterations counter */
+			vp_priv->iter = 0;
+
+			/* clean vq advanced statistics */
+			if  (mv_pp3_gnss_ingress_vq_ext_stats_clean(vport, vq, cpu))
+				goto err;
+		}
+	}
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vport_ext_stats_clean);
+
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_gnss_ingress_vport_ext_stats_get(int vport, bool clean, int size,
+						struct mv_nss_vq_advance_stats res_stats[])
+{
+	struct net_device *dev = mv_pp3_vport_dev_get(vport);
+	struct mv_pp3_stats_ext_vp *vp_priv;
+	struct mv_pp3_vq_update_stats *ext_stats;
+	int cpu, i, vq_num, rc = 0;
+	unsigned long flags = 0;
+	uint64_t temp64;
+
+	 if (!dev) {
+		pr_err("%s: function failed\n", __func__);
+		return -1;
+	}
+
+	if (vport > MV_NSS_EXT_PORT_MAX) {
+		pr_err("%s: Invalid virtual port %d\n", __func__, vport);
+		return -1;
+	}
+
+	vp_priv = mv_ext_vports[vport];
+
+	if (!vp_priv) {
+		pr_err("%s: statistics extension not initialized\n", __func__);
+		return -1;
+
+	}
+
+	/* clear input */
+	memset(res_stats, 0, sizeof(struct mv_nss_vq_advance_stats) * size);
+
+	MV_LOCK(vp_priv->stats_lock, flags);
+
+	for_each_possible_cpu(cpu) {
+
+		if (!mv_pp3_dev_cpu_inuse(dev, cpu))
+			continue;
+
+		vq_num = mv_pp3_dev_rxvq_num_get(dev, cpu);
+
+		if (size > vq_num) {
+			pr_err("%s: vport %d have only %d rx virtual queues\n",
+						__func__, vport, vq_num);
+			MV_UNLOCK(vp_priv->stats_lock, flags);
+			return -1;
+		}
+		for (i = 0; i < size; i++) {
+			ext_stats = mv_pp3_update_stats_get(vport, i, cpu);
+			/* time elapsed in msec */
+			res_stats[i].time_elapsed = vp_priv->time_elapsed / 1000;
+
+			res_stats[i].pkts_fill_lvl += ext_stats->pkts_fill_lvl;
+			res_stats[i].pkts_fill_lvl_max =
+				MV_MAX(res_stats[i].pkts_fill_lvl_max, ext_stats->pkts_fill_lvl_max);
+
+			res_stats[i].bytes_fill_lvl += ext_stats->bytes_fill_lvl;
+			res_stats[i].bytes_fill_lvl_max =
+				MV_MAX(res_stats[i].bytes_fill_lvl_max, ext_stats->bytes_fill_lvl_max);
+
+
+			res_stats[i].pkts_fill_lvl_avg += ext_stats->pkts_fill_lvl_sum;
+			res_stats[i].bytes_fill_lvl_avg += ext_stats->bytes_fill_lvl_sum;
+
+			res_stats[i].pkts_rate += ext_stats->pkts_sum;
+			res_stats[i].bytes_rate += ext_stats->bytes_sum;
+		}
+	}
+
+	for (i = 0; i < size; i++) {
+		if (vp_priv->iter) {
+			res_stats[i].pkts_fill_lvl_avg = res_stats[i].pkts_fill_lvl_avg / vp_priv->iter;
+			res_stats[i].bytes_fill_lvl_avg = res_stats[i].bytes_fill_lvl_avg / vp_priv->iter;
+		}
+
+		if (vp_priv->time_elapsed) {
+			temp64 = ((uint64_t)res_stats[i].pkts_rate) *  1000000;
+			do_div(temp64, vp_priv->time_elapsed);
+			res_stats[i].pkts_rate = (unsigned int) (temp64 & 0xFFFFFFFF);
+
+			temp64 = ((uint64_t)res_stats[i].bytes_rate) *  1000000;
+			do_div(temp64, vp_priv->time_elapsed);
+			res_stats[i].bytes_rate = (unsigned int) (temp64 & 0xFFFFFFFF);
+		}
+	}
+	if (clean)
+		rc = mv_pp3_gnss_ingress_vport_ext_stats_clean(vport);
+
+	MV_UNLOCK(vp_priv->stats_lock, flags);
+
+
+	return rc;
+}
+EXPORT_SYMBOL(mv_pp3_gnss_ingress_vport_ext_stats_get);
+#if 0
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_gnss_ingress_vport_ext_stats_show(int vport, bool clean)
+{
+	int rc, vq = 0;
+	struct mv_nss_vq_advance_stats res_stats[CONFIG_MV_PP3_RXQ_NUM];
+
+	rc = mv_pp3_gnss_ingress_vport_ext_stats_get(vport, clean, CONFIG_MV_PP3_RXQ_NUM, res_stats);
+
+	if (rc < 0) {
+		pr_info("Failed read vport #%d advanced statistics\n", vport);
+		return;
+	}
+	pr_info("Vport %d Advanced statistics\n", vport);
+
+	for (vq = 0; vq < CONFIG_MV_PP3_RXQ_NUM; vq++) {
+		pr_info("\nvq = %d\n", vq);
+		pr_info("-------------------\n");
+		pr_info("pkts_fill_lvl     = %d\n", res_stats[vq].pkts_fill_lvl);
+		pr_info("pkts_fill_lvl_max = %d\n", res_stats[vq].pkts_fill_lvl_max);
+		pr_info("pkts_fill_lvl_avg = %d\n", res_stats[vq].pkts_fill_lvl_avg);
+		pr_info("pkts_rate = %d pps\n", res_stats[vq].pkts_rate);
+		pr_info("bytes_fill_lvl     = %d\n", res_stats[vq].bytes_fill_lvl);
+		pr_info("bytes_fill_lvl_max = %d\n", res_stats[vq].bytes_fill_lvl_max);
+		pr_info("bytes_fill_lvl_avg = %d\n", res_stats[vq].bytes_fill_lvl_avg);
+		pr_info("bytes_rate = %d bps\n", res_stats[vq].bytes_rate);
+		pr_info("time_elapsed = %d msec\n", res_stats[vq].time_elapsed);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_gnss_ingress_vport_stats_show(int vport, bool clean)
+{
+	int rc, vq;
+	struct mv_nss_vq_stats res_stats[CONFIG_MV_PP3_RXQ_NUM];
+
+	rc = mv_pp3_gnss_ingress_vport_stats_get(vport, clean, CONFIG_MV_PP3_RXQ_NUM, res_stats);
+
+	if (rc < 0) {
+		pr_info("Failed read vport #%d statistics\n", vport);
+		return;
+	}
+	pr_info("Vport %d statistics\n", vport);
+
+	for (vq = 0; vq < CONFIG_MV_PP3_RXQ_NUM; vq++) {
+		pr_info("\nvq = %d\n", vq);
+		pr_info("-------------------\n");
+		pr_info("pkts   = %10llu\n", res_stats[vq].pkts);
+		pr_info("octets = %10llu\n", res_stats[vq].octets);
+		pr_info("errors = %10llu\n", res_stats[vq].errors);
+		pr_info("drops  = %10llu\n",  res_stats[vq].drops);
+	}
+}
+#endif
diff --git a/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.c b/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.c
new file mode 100644
index 0000000..547ee86
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.c
@@ -0,0 +1,149 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "a390_mg_if.h"
+#include "mv_gop_if.h"
+
+/* Enable address completion on 8 regions over register 0x0140 on INIT.
+ * Run-time Completion registers (0x0120, .. 0x013c) are used over array
+ * a390_int.addr_completion_regs[]
+ */
+#define MV_PP3_ADDR_COMP_CNTRL_REG_OFFS	0x0140
+#define MV_PP3_ADDR_COMP_USED_REGIONS	0xff00
+
+ /* bits of address passes as is throw PCI window */
+#define NOT_ADDRESS_COMPLETION_BITS_NUM 19
+/* bits of address extracted from address completion registers */
+#define ADDRESS_COMPLETION_BITS_MASK    (0xFFFFFFFF << NOT_ADDRESS_COMPLETION_BITS_NUM)
+
+struct a390_internals {
+	u32 fixed_addr_filter;
+	u32 dedicated_completion_msbits;
+	u32 addr_completion_regs[8];
+	u32 mg_base;
+};
+
+static struct a390_internals a390_int = {
+	.addr_completion_regs = {0x0120, 0x0124, 0x0128, 0x012c, 0x0130, 0x0134, 0x0138, 0x013c},
+};
+
+
+/* return new calculated access address without silicon base */
+/*        that added in real read/write function             */
+u32 a390_addr_completion_cfg(u32 reg_addr)
+{
+	int cpu = smp_processor_id();
+	int comp_indx;
+	u32 address;
+	u32 addr_region = (reg_addr >> NOT_ADDRESS_COMPLETION_BITS_NUM);
+
+	if (addr_region == 0) {
+		/* address comletion bits are 0, region0 used */
+		return reg_addr;
+	}
+
+	/* choose region for cpu (application or ISR) */
+	/* address completion region assignment: */
+	/* cpu 0 all applications  - REGION 1    */
+	/* cpu 0 all SW interrupts - REGION 2    */
+	/* cpu 0 HW interrupt      - REGION 3    */
+	/* cpu 1 all applications  - REGION 4    */
+	/* cpu 1 all SW interrupts - REGION 5    */
+	/* cpu 1 HW interrupt      - REGION 6    */
+	/* Dedicated with FIX addr - REGION 7    */
+
+	/* On fixed_addr_filter==0 the fixed is not set and to be ignored.
+	 * Use "common" in that case
+	 */
+	if (a390_int.fixed_addr_filter && (addr_region == a390_int.fixed_addr_filter)) {
+		address = a390_int.dedicated_completion_msbits  | (reg_addr & (~ADDRESS_COMPLETION_BITS_MASK));
+		return address;
+	}
+
+	if (cpu == 0) {
+		if (in_irq())
+			comp_indx = 3;
+		else if (in_softirq())
+			comp_indx = 2;
+		else
+			comp_indx = 1;
+	} else {
+		if (in_irq())
+			comp_indx = 6;
+		else if (in_softirq())
+			comp_indx = 5;
+		else
+			comp_indx = 4;
+	}
+
+	/* configure completion addr_region into HW */
+	/* adders base added at the lower level cpuWrite/cpuRead */
+	address = a390_int.mg_base + a390_int.addr_completion_regs[comp_indx];
+	writel(addr_region, (void *)address);
+
+	/* adders base added at the lower level cpuWrite/cpuRead */
+	address = ((comp_indx << NOT_ADDRESS_COMPLETION_BITS_NUM)
+		| (reg_addr & (~ADDRESS_COMPLETION_BITS_MASK)));
+
+	return address;
+}
+
+/* --- Init-Configurations --------------------------- */
+void a390_addr_completion_init(void *mg_base)
+{
+	a390_int.mg_base = (u32)mg_base;
+	/* enable address completion on 7 regions + region 0 */
+	mv_pp3_hw_reg_write(mg_base + MV_PP3_ADDR_COMP_CNTRL_REG_OFFS,
+		MV_PP3_ADDR_COMP_USED_REGIONS);
+}
+
+void a390_addr_completion_fixed_init(u32 dedicated_region_no, u32 reg_base)
+{
+	/* Static(never changed) configuration for dedicated MG_REGION */
+	u32 address;
+	/* If the mg_base, reg_base are null - no dedicated configured.
+	 * Currently only 1 dedicated region supported and so
+	 * the procedure should be called once only
+	 */
+	if (!a390_int.mg_base)
+		return;
+	if (!dedicated_region_no)
+		return;
+	if (!reg_base)
+		return;
+	if (a390_int.dedicated_completion_msbits)
+		return; /* already configured */
+	a390_int.fixed_addr_filter = reg_base >> NOT_ADDRESS_COMPLETION_BITS_NUM;
+	address = a390_int.mg_base + a390_int.addr_completion_regs[dedicated_region_no];
+	a390_int.dedicated_completion_msbits = dedicated_region_no << NOT_ADDRESS_COMPLETION_BITS_NUM;
+	/* Set fixed address completion into MG hw (for MV_PP3_DEDICATED_MG_REGION)
+	 * dedicated for the given "reg_base"
+	 */
+	writel(a390_int.fixed_addr_filter, (void *)address);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.h b/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.h
new file mode 100644
index 0000000..3ca094c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/a390_mg_if.h
@@ -0,0 +1,22 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+*******************************************************************************/
+#ifndef __a390_mg_if_h__
+#define __a390_mg_if_h__
+
+#define MV_PP3_DEDICATED_MG_REGION	7
+
+void a390_addr_completion_init(void *mg_base);
+void a390_addr_completion_fixed_init(u32 dedicated_region_no, u32 reg_base);
+u32 a390_addr_completion_cfg(u32 reg_addr);
+
+#endif /* __a390_mg_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.c b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.c
new file mode 100644
index 0000000..ca93e1c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.c
@@ -0,0 +1,707 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include <gop/mac/mv_gmac_if.h>
+#include <gop/mac/mv_gmac_regs.h>
+
+/* print value of unit registers */
+void mv_gmac_regs_dump(int port)
+{
+	int ind;
+	char reg_name[32];
+
+	mv_gop_reg_print("PORT_MAC_CTRL0", MV_GMAC_PORT_CTRL0_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL1", MV_GMAC_PORT_CTRL1_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL2", MV_GMAC_PORT_CTRL2_REG(port));
+	mv_gop_reg_print("PORT_AUTO_NEG_CFG", MV_GMAC_PORT_AUTO_NEG_CFG_REG(port));
+	mv_gop_reg_print("PORT_STATUS0", MV_GMAC_PORT_STATUS0_REG(port));
+	mv_gop_reg_print("PORT_SERIAL_PARAM_CFG", MV_GMAC_PORT_SERIAL_PARAM_CFG_REG(port));
+	mv_gop_reg_print("PORT_FIFO_CFG_0", MV_GMAC_PORT_FIFO_CFG_0_REG(port));
+	mv_gop_reg_print("PORT_FIFO_CFG_1", MV_GMAC_PORT_FIFO_CFG_1_REG(port));
+	mv_gop_reg_print("PORT_SERDES_CFG0", MV_GMAC_PORT_SERDES_CFG0_REG(port));
+	mv_gop_reg_print("PORT_SERDES_CFG1", MV_GMAC_PORT_SERDES_CFG1_REG(port));
+	mv_gop_reg_print("PORT_SERDES_CFG2", MV_GMAC_PORT_SERDES_CFG2_REG(port));
+	mv_gop_reg_print("PORT_SERDES_CFG3", MV_GMAC_PORT_SERDES_CFG3_REG(port));
+	mv_gop_reg_print("PORT_PRBS_STATUS", MV_GMAC_PORT_PRBS_STATUS_REG(port));
+	mv_gop_reg_print("PORT_PRBS_ERR_CNTR", MV_GMAC_PORT_PRBS_ERR_CNTR_REG(port));
+	mv_gop_reg_print("PORT_STATUS1", MV_GMAC_PORT_STATUS1_REG(port));
+	mv_gop_reg_print("PORT_MIB_CNTRS_CTRL", MV_GMAC_PORT_MIB_CNTRS_CTRL_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL3", MV_GMAC_PORT_CTRL3_REG(port));
+	mv_gop_reg_print("QSGMII", MV_GMAC_QSGMII_REG(port));
+	mv_gop_reg_print("QSGMII_STATUS", MV_GMAC_QSGMII_STATUS_REG(port));
+	mv_gop_reg_print("QSGMII_PRBS_CNTR", MV_GMAC_QSGMII_PRBS_CNTR_REG(port));
+	for (ind = 0; ind < 8; ind++) {
+		sprintf(reg_name, "CCFC_PORT_SPEED_TIMER%d", ind);
+		mv_gop_reg_print(reg_name, MV_GMAC_CCFC_PORT_SPEED_TIMER_REG(port, ind));
+	}
+	for (ind = 0; ind < 4; ind++) {
+		sprintf(reg_name, "FC_DSA_TAG%d", ind);
+		mv_gop_reg_print(reg_name, MV_GMAC_FC_DSA_TAG_REG(port, ind));
+	}
+	mv_gop_reg_print("LINK_LEVEL_FLOW_CTRL_WIN_REG_0", MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_0(port));
+	mv_gop_reg_print("LINK_LEVEL_FLOW_CTRL_WIN_REG_1", MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1(port));
+	mv_gop_reg_print("PORT_MAC_CTRL4", MV_GMAC_PORT_CTRL4_REG(port));
+	mv_gop_reg_print("PORT_SERIAL_PARAM_1_CFG", MV_GMAC_PORT_SERIAL_PARAM_1_CFG_REG(port));
+	mv_gop_reg_print("LPI_CTRL_0", MV_GMAC_LPI_CTRL_0_REG(port));
+	mv_gop_reg_print("LPI_CTRL_1", MV_GMAC_LPI_CTRL_1_REG(port));
+	mv_gop_reg_print("LPI_CTRL_2", MV_GMAC_LPI_CTRL_2_REG(port));
+	mv_gop_reg_print("LPI_STATUS", MV_GMAC_LPI_STATUS_REG(port));
+	mv_gop_reg_print("LPI_CNTR", MV_GMAC_LPI_CNTR_REG(port));
+	mv_gop_reg_print("PULSE_1_MS_LOW", MV_GMAC_PULSE_1_MS_LOW_REG(port));
+	mv_gop_reg_print("PULSE_1_MS_HIGH", MV_GMAC_PULSE_1_MS_HIGH_REG(port));
+	mv_gop_reg_print("PORT_INT_MASK", MV_GMAC_INTERRUPT_MASK_REG(port));
+	mv_gop_reg_print("INT_SUM_MASK", MV_GMAC_INTERRUPT_SUM_MASK_REG(port));
+}
+
+/* Set the MAC to reset or exit from reset */
+int mv_gmac_reset(int mac_num, enum mv_reset reset)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_GMAC_PORT_CTRL2_REG(mac_num);
+
+	/* read - modify - write */
+	val = mv_gop_reg_read(reg_addr);
+	if (reset == RESET)
+		val |= MV_GMAC_PORT_CTRL2_PORTMACRESET_MASK;
+	else
+		val &= ~MV_GMAC_PORT_CTRL2_PORTMACRESET_MASK;
+	mv_gop_reg_write(reg_addr, val);
+
+	return 0;
+}
+
+static void mv_gmac_rgmii_cfg(int mac_num)
+{
+	u32 val, thresh, an;
+
+	/* configure minimal level of the Tx FIFO before the lower part starts to read a packet */
+	thresh = MV_RGMII_TX_FIFO_MIN_TH;
+	val = mv_gop_reg_read(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num));
+	MV_U32_SET_FIELD(val, MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_MASK,
+		(thresh << MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS));
+	mv_gop_reg_write(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num), val);
+
+	/* Disable bypass of sync module */
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL4_SYNC_BYPASS_MASK;
+	/* configure DP clock select according to mode */
+	val &= ~MV_GMAC_PORT_CTRL4_DP_CLK_SEL_MASK;
+	val |= MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_MASK;
+	val |= MV_GMAC_PORT_CTRL4_EXT_PIN_GMII_SEL_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(mac_num));
+	val &= ~MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	/* configure GIG MAC to SGMII mode */
+	val &= ~MV_GMAC_PORT_CTRL0_PORTTYPE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), val);
+
+	/* configure AN 0xb8e8 */
+	an = MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK   |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK      |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK     |
+		MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), an);
+}
+
+static void mv_gmac_qsgmii_cfg(int mac_num)
+{
+	u32 val, thresh, an;
+
+	/* configure minimal level of the Tx FIFO before the lower part starts to read a packet */
+	thresh = MV_SGMII_TX_FIFO_MIN_TH;
+	val = mv_gop_reg_read(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num));
+	MV_U32_SET_FIELD(val, MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_MASK,
+		(thresh << MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS));
+	mv_gop_reg_write(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num), val);
+
+	/* Disable bypass of sync module */
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL4_SYNC_BYPASS_MASK;
+	/* configure DP clock select according to mode */
+	val &= ~MV_GMAC_PORT_CTRL4_DP_CLK_SEL_MASK;
+	val &= ~MV_GMAC_PORT_CTRL4_EXT_PIN_GMII_SEL_MASK;
+	/* configure QSGMII bypass according to mode */
+	val &= ~MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(mac_num));
+	val &= ~MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	/* configure GIG MAC to SGMII mode */
+	val &= ~MV_GMAC_PORT_CTRL0_PORTTYPE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), val);
+
+	/* configure AN 0xB8EC */
+	an = MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK  |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK     |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK    |
+		MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), an);
+}
+
+static void mv_gmac_sgmii_cfg(int mac_num)
+{
+	u32 val, thresh, an;
+
+	/* configure minimal level of the Tx FIFO before the lower part starts to read a packet */
+	thresh = MV_SGMII_TX_FIFO_MIN_TH;
+	val = mv_gop_reg_read(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num));
+	MV_U32_SET_FIELD(val, MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_MASK,
+		(thresh << MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS));
+	mv_gop_reg_write(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num), val);
+
+	/* Disable bypass of sync module */
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL4_SYNC_BYPASS_MASK;
+	/* configure DP clock select according to mode */
+	val &= ~MV_GMAC_PORT_CTRL4_DP_CLK_SEL_MASK;
+	/* configure QSGMII bypass according to mode */
+	val |= MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	/* configure GIG MAC to SGMII mode */
+	val &= ~MV_GMAC_PORT_CTRL0_PORTTYPE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), val);
+
+	/* configure AN */
+	an = MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK  |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK     |
+		MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK    |
+		MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), an);
+}
+
+static void mv_gmac_sgmii2_5_cfg(int mac_num)
+{
+	u32 val, thresh, an;
+
+	/* configure minimal level of the Tx FIFO before the lower part starts to read a packet */
+	thresh = MV_SGMII2_5_TX_FIFO_MIN_TH;
+	val = mv_gop_reg_read(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num));
+	MV_U32_SET_FIELD(val, MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_MASK,
+		(thresh << MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS));
+	mv_gop_reg_write(MV_GMAC_PORT_FIFO_CFG_1_REG(mac_num), val);
+
+	/* Disable bypass of sync module */
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL4_SYNC_BYPASS_MASK;
+	/* configure DP clock select according to mode */
+	val |= MV_GMAC_PORT_CTRL4_DP_CLK_SEL_MASK;
+	/* configure QSGMII bypass according to mode */
+	val |= MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(mac_num));
+	val |= MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(mac_num), val);
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	/* configure GIG MAC to 1000Base-X mode connected to a fiber transceiver */
+	val |= MV_GMAC_PORT_CTRL0_PORTTYPE_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), val);
+
+	/* configure AN 0x9268 */
+	an = MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_MASK |
+		MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_MASK  |
+		MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK     |
+		MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK    |
+		MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_MASK  |
+		MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), an);
+}
+
+/* Set the internal mux's to the required MAC in the GOP */
+int mv_gmac_mode_cfg(int mac_num, int mode)
+{
+	u32 reg_addr;
+	u32 val;
+
+	/* Set TX FIFO thresholds */
+	switch (mode) {
+	case MV_PORT_SGMII2_5:
+		mv_gmac_sgmii2_5_cfg(mac_num);
+	break;
+	case MV_PORT_SGMII:
+		mv_gmac_sgmii_cfg(mac_num);
+	break;
+	case MV_PORT_RGMII:
+		mv_gmac_rgmii_cfg(mac_num);
+	break;
+	case MV_PORT_QSGMII:
+		mv_gmac_qsgmii_cfg(mac_num);
+	break;
+	default:
+		return -1;
+	}
+
+	/* Jumbo frame support - 0x1400*2= 0x2800 bytes */
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	MV_U32_SET_FIELD(val, MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_MASK,
+		(0x1400 << MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_OFFS));
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), val);
+
+	/* PeriodicXonEn disable */
+	reg_addr = MV_GMAC_PORT_CTRL1_REG(mac_num);
+	val = mv_gop_reg_read(reg_addr);
+	val &= ~MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_MASK;
+	mv_gop_reg_write(reg_addr, val);
+
+	/* mask all ports interrupts */
+	mv_gmac_port_link_event_mask(mac_num);
+
+	/* unmask link change interrupt */
+	val = mv_gop_reg_read(MV_GMAC_INTERRUPT_MASK_REG(mac_num));
+	val |= MV_GMAC_INTERRUPT_CAUSE_LINK_CHANGE_MASK;
+	val |= 1; /* unmask summary bit */
+	mv_gop_reg_write(MV_GMAC_INTERRUPT_MASK_REG(mac_num), val);
+
+	return 0;
+}
+
+/* Configure MAC loopback */
+int mv_gmac_loopback_cfg(int mac_num, enum mv_lb_type type)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_GMAC_PORT_CTRL1_REG(mac_num);
+	val = mv_gop_reg_read(reg_addr);
+	switch (type) {
+	case MV_DISABLE_LB:
+		val &= ~MV_GMAC_PORT_CTRL1_GMII_LOOPBACK_MASK;
+		break;
+	case MV_TX_2_RX_LB:
+		val |= MV_GMAC_PORT_CTRL1_GMII_LOOPBACK_MASK;
+		break;
+	case MV_RX_2_TX_LB:
+	default:
+		return -1;
+	}
+	mv_gop_reg_write(reg_addr, val);
+
+	return 0;
+}
+
+/* Get MAC link status */
+bool mv_gmac_link_status_get(int mac_num)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_GMAC_PORT_STATUS0_REG(mac_num);
+
+	val = mv_gop_reg_read(reg_addr);
+	return (val & 1) ? true : false;
+}
+
+/* Enable port and MIB counters */
+void mv_gmac_port_enable(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	reg_val |= MV_GMAC_PORT_CTRL0_PORTEN_MASK;
+	reg_val |= MV_GMAC_PORT_CTRL0_COUNT_EN_MASK;
+
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), reg_val);
+}
+
+/* Disable port */
+void mv_gmac_port_disable(int mac_num)
+{
+	u32 reg_val;
+
+	/* mask all ports interrupts */
+	mv_gmac_port_link_event_mask(mac_num);
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	reg_val &= ~MV_GMAC_PORT_CTRL0_PORTEN_MASK;
+
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), reg_val);
+}
+
+void mv_gmac_port_periodic_xon_set(int mac_num, int enable)
+{
+	u32 reg_val;
+
+	reg_val =  mv_gop_reg_read(MV_GMAC_PORT_CTRL1_REG(mac_num));
+
+	if (enable)
+		reg_val |= MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_MASK;
+	else
+		reg_val &= ~MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_MASK;
+
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL1_REG(mac_num), reg_val);
+}
+
+int mv_gmac_link_status(int mac_num, struct mv_port_link_status *pstatus)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_STATUS0_REG(mac_num));
+
+	if (reg_val & MV_GMAC_PORT_STATUS0_GMIISPEED_MASK)
+		pstatus->speed = MV_PORT_SPEED_1000;
+	else if (reg_val & MV_GMAC_PORT_STATUS0_MIISPEED_MASK)
+		pstatus->speed = MV_PORT_SPEED_100;
+	else
+		pstatus->speed = MV_PORT_SPEED_10;
+
+	if (reg_val & MV_GMAC_PORT_STATUS0_LINKUP_MASK)
+		pstatus->linkup = 1 /*TRUE*/;
+	else
+		pstatus->linkup = 0 /*FALSE*/;
+
+	if (reg_val & MV_GMAC_PORT_STATUS0_FULLDX_MASK)
+		pstatus->duplex = MV_PORT_DUPLEX_FULL;
+	else
+		pstatus->duplex = MV_PORT_DUPLEX_HALF;
+
+	if (reg_val & MV_GMAC_PORT_STATUS0_PORTTXPAUSE_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ACTIVE;
+	else if (reg_val & MV_GMAC_PORT_STATUS0_TXFCEN_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->tx_fc = MV_PORT_FC_DISABLE;
+
+	if (reg_val & MV_GMAC_PORT_STATUS0_PORTRXPAUSE_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ACTIVE;
+	else if (reg_val & MV_GMAC_PORT_STATUS0_RXFCEN_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->rx_fc = MV_PORT_FC_DISABLE;
+
+	return 0;
+}
+
+/* Change maximum receive size of the port */
+int mv_gmac_max_rx_size_set(int mac_num, int max_rx_size)
+{
+	u32	reg_val;
+
+	reg_val =  mv_gop_reg_read(MV_GMAC_PORT_CTRL0_REG(mac_num));
+	reg_val &= ~MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_MASK;
+	reg_val |= (((max_rx_size - MV_MH_SIZE) / 2) << MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_OFFS);
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL0_REG(mac_num), reg_val);
+
+	return 0;
+}
+
+/* Sets "Force Link Pass" and "Do Not Force Link Fail" bits.
+*  This function should only be called when the port is disabled.
+* INPUT:
+*	int  port		- port number
+*	bool force_link_pass	- Force Link Pass
+*	bool force_link_fail - Force Link Failure
+*		0, 0 - normal state: detect link via PHY and connector
+*		1, 1 - prohibited state.
+*/
+int mv_gmac_force_link_mode_set(int mac_num, bool force_link_up, bool force_link_down)
+{
+	u32 reg_val;
+
+	/* Can't force link pass and link fail at the same time */
+	if ((force_link_up) && (force_link_down))
+		return -EINVAL;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+
+	if (force_link_up)
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_UP_MASK;
+	else
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_UP_MASK;
+
+	if (force_link_down)
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_DOWN_MASK;
+	else
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_DOWN_MASK;
+
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), reg_val);
+
+	return 0;
+}
+
+/* Sets port speed to Auto Negotiation / 1000 / 100 / 10 Mbps.
+*  Sets port duplex to Auto Negotiation / Full / Half Duplex.
+*/
+int mv_gmac_speed_duplex_set(int mac_num, enum mv_port_speed speed, enum mv_port_duplex duplex)
+{
+	u32 reg_val;
+
+	/* Check validity */
+	if ((speed == MV_PORT_SPEED_1000) && (duplex == MV_PORT_DUPLEX_HALF))
+		return -EINVAL;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+
+	switch (speed) {
+	case MV_PORT_SPEED_AN:
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK;
+		/* the other bits don't matter in this case */
+		break;
+	case MV_PORT_SPEED_1000:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK;
+		/* the 100/10 bit doesn't matter in this case */
+		break;
+	case MV_PORT_SPEED_100:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_MASK;
+		break;
+	case MV_PORT_SPEED_10:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_MASK;
+		break;
+	default:
+		pr_info("GMAC: Unexpected Speed value %d\n", speed);
+		return -EINVAL;
+	}
+
+	switch (duplex) {
+	case MV_PORT_DUPLEX_AN:
+		reg_val  |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK;
+		/* the other bits don't matter in this case */
+		break;
+	case MV_PORT_DUPLEX_HALF:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_MASK;
+		break;
+	case MV_PORT_DUPLEX_FULL:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_MASK;
+		break;
+	default:
+		pr_err("GMAC: Unexpected Duplex value %d\n", duplex);
+		return -EINVAL;
+	}
+
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), reg_val);
+	return 0;
+}
+
+/* Gets port speed and duplex */
+int mv_gmac_speed_duplex_get(int mac_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex)
+{
+	u32 reg_val;
+
+	/* Check validity */
+	if (!speed || !duplex)
+		return -EINVAL;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+
+	if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK)
+		*speed = MV_PORT_SPEED_AN;
+	else if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK)
+		*speed = MV_PORT_SPEED_1000;
+	else if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_MASK)
+		*speed = MV_PORT_SPEED_100;
+	else
+		*speed = MV_PORT_SPEED_10;
+
+	if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK)
+		*duplex = MV_PORT_DUPLEX_AN;
+	else if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_MASK)
+		*duplex = MV_PORT_DUPLEX_FULL;
+	else
+		*duplex = MV_PORT_DUPLEX_HALF;
+
+	return 0;
+}
+
+/* Configure the port's Flow Control properties */
+int mv_gmac_fc_set(int mac_num, enum mv_port_fc fc)
+{
+	u32 reg_val;
+	u32 fc_en;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+
+	switch (fc) {
+	case MV_PORT_FC_AN_NO:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK;
+		break;
+
+	case MV_PORT_FC_AN_SYM:
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK;
+		break;
+
+	case MV_PORT_FC_AN_ASYM:
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK;
+		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK;
+		break;
+
+	case MV_PORT_FC_DISABLE:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK;
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK;
+		fc_en = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+		fc_en &= ~MV_GMAC_PORT_CTRL4_FC_EN_RX_MASK;
+		fc_en &= ~MV_GMAC_PORT_CTRL4_FC_EN_TX_MASK;
+		mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), fc_en);
+		break;
+
+	case MV_PORT_FC_ENABLE:
+		reg_val &= ~MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK;
+		fc_en = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+		fc_en |= MV_GMAC_PORT_CTRL4_FC_EN_RX_MASK;
+		fc_en |= MV_GMAC_PORT_CTRL4_FC_EN_TX_MASK;
+		mv_gop_reg_write(MV_GMAC_PORT_CTRL4_REG(mac_num), fc_en);
+		break;
+
+	default:
+		pr_err("GMAC: Unexpected FlowControl value %d\n", fc);
+		return -EINVAL;
+	}
+
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), reg_val);
+	return 0;
+}
+
+/* Get Flow Control configuration of the port */
+void mv_gmac_fc_get(int mac_num, enum mv_port_fc *fc)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+
+	if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK) {
+		/* Auto negotiation is enabled */
+		if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK) {
+			if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK)
+				*fc = MV_PORT_FC_AN_ASYM;
+			else
+				*fc = MV_PORT_FC_AN_SYM;
+		} else
+			*fc = MV_PORT_FC_AN_NO;
+	} else {
+		/* Auto negotiation is disabled */
+		reg_val = mv_gop_reg_read(MV_GMAC_PORT_CTRL4_REG(mac_num));
+		if ((reg_val & MV_GMAC_PORT_CTRL4_FC_EN_RX_MASK) &&
+			(reg_val & MV_GMAC_PORT_CTRL4_FC_EN_TX_MASK))
+			*fc = MV_PORT_FC_ENABLE;
+		else
+			*fc = MV_PORT_FC_DISABLE;
+	}
+}
+
+int mv_gmac_port_link_speed_fc(int mac_num, enum mv_port_speed speed, int force_link_up)
+{
+	if (force_link_up) {
+		if (mv_gmac_speed_duplex_set(mac_num, speed, MV_PORT_DUPLEX_FULL)) {
+			pr_err("mv_gmac_speed_duplex_set failed\n");
+			return -EPERM;
+		}
+		if (mv_gmac_fc_set(mac_num, MV_PORT_FC_ENABLE)) {
+			pr_err("mv_gmac_fc_set failed\n");
+			return -EPERM;
+		}
+		if (mv_gmac_force_link_mode_set(mac_num, 1, 0)) {
+			pr_err("mv_gmac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+	} else {
+		if (mv_gmac_force_link_mode_set(mac_num, 0, 0)) {
+			pr_err("mv_gmac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+		if (mv_gmac_speed_duplex_set(mac_num, MV_PORT_SPEED_AN, MV_PORT_DUPLEX_AN)) {
+			pr_err("mv_gmac_speed_duplex_set failed\n");
+			return -EPERM;
+		}
+		if (mv_gmac_fc_set(mac_num, MV_PORT_FC_AN_SYM)) {
+			pr_err("mv_gmac_fc_set failed\n");
+			return -EPERM;
+		}
+	}
+
+	return 0;
+}
+
+void mv_gmac_port_link_event_mask(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_INTERRUPT_SUM_MASK_REG(mac_num));
+	reg_val &= ~MV_GMAC_INTERRUPT_SUM_CAUSE_LINK_CHANGE_MASK;
+	mv_gop_reg_write(MV_GMAC_INTERRUPT_SUM_MASK_REG(mac_num), reg_val);
+}
+
+void mv_gmac_port_link_event_unmask(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_INTERRUPT_SUM_MASK_REG(mac_num));
+	reg_val |= MV_GMAC_INTERRUPT_SUM_CAUSE_LINK_CHANGE_MASK;
+	reg_val |= 1; /* unmask summary bit */
+	mv_gop_reg_write(MV_GMAC_INTERRUPT_SUM_MASK_REG(mac_num), reg_val);
+}
+
+void mv_gmac_port_link_event_clear(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_INTERRUPT_CAUSE_REG(mac_num));
+}
+
+int mv_gmac_port_autoneg_restart(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num));
+	/* enable AN and restart it */
+	reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_MASK;
+	reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_INBAND_RESTARTAN_MASK;
+	mv_gop_reg_write(MV_GMAC_PORT_AUTO_NEG_CFG_REG(mac_num), reg_val);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.h b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.h
new file mode 100644
index 0000000..11ba322
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_if.h
@@ -0,0 +1,72 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gmac_if_h__
+#define __mv_gmac_if_h__
+
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+
+#define MV_RGMII_TX_FIFO_MIN_TH		(0x41)
+#define MV_SGMII_TX_FIFO_MIN_TH		(0x5)
+#define MV_SGMII2_5_TX_FIFO_MIN_TH	(0xB)
+
+/* print value of unit registers */
+void mv_gmac_regs_dump(int port);
+/* Set the MAC to reset or exit from reset */
+int mv_gmac_reset(int mac_num, enum mv_reset reset);
+/* Set the internal mux's to the required MAC in the GOP */
+int mv_gmac_mode_cfg(int mac_num, int mode);
+/* Configure MAC loopback */
+int mv_gmac_loopback_cfg(int mac_num, enum mv_lb_type type);
+/* Get MAC link status */
+bool mv_gmac_link_status_get(int mac_num);
+/* Enable port and MIB counters */
+void mv_gmac_port_enable(int mac_num);
+/* Disable port */
+void mv_gmac_port_disable(int mac_num);
+
+void mv_gmac_port_periodic_xon_set(int mac_num, int enable);
+int mv_gmac_link_status(int mac_num, struct mv_port_link_status *pstatus);
+/* Change maximum receive size of the port */
+int mv_gmac_max_rx_size_set(int mac_num, int max_rx_size);
+int mv_gmac_force_link_mode_set(int mac_num, bool force_link_up, bool force_link_down);
+int mv_gmac_speed_duplex_set(int mac_num, enum mv_port_speed speed, enum mv_port_duplex duplex);
+int mv_gmac_port_autoneg_restart(int mac_num);
+/* Gets port speed and duplex */
+int mv_gmac_speed_duplex_get(int mac_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex);
+/* Configure the port's Flow Control properties */
+int mv_gmac_fc_set(int mac_num, enum mv_port_fc fc);
+/* Get Flow Control configuration of the port */
+void mv_gmac_fc_get(int mac_num, enum mv_port_fc *fc);
+int mv_gmac_port_link_speed_fc(int mac_num, enum mv_port_speed speed, int force_link_up);
+/* Link Interrupt Handle */
+void mv_gmac_port_link_event_unmask(int mac_num);
+void mv_gmac_port_link_event_mask(int mac_num);
+void mv_gmac_port_link_event_clear(int mac_num);
+
+#endif /* __mv_gmac_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_regs.h
new file mode 100644
index 0000000..c9fafaa
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_gmac_regs.h
@@ -0,0 +1,780 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gmac_regs_h__
+#define __mv_gmac_regs_h__
+
+/* includes */
+
+/* unit offset */
+#define MV_GMAC_UNIT_OFFSET		0x03000000
+
+/* Port Mac Control0 */
+#define MV_GMAC_PORT_CTRL0_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0000 + (port) * 0x1000)
+#define MV_GMAC_PORT_CTRL0_PORTEN_OFFS		0
+#define MV_GMAC_PORT_CTRL0_PORTEN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL0_PORTEN_OFFS)
+
+#define MV_GMAC_PORT_CTRL0_PORTTYPE_OFFS		1
+#define MV_GMAC_PORT_CTRL0_PORTTYPE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL0_PORTTYPE_OFFS)
+
+#define MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_OFFS		2
+#define MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_MASK    \
+		(0x00001fff << MV_GMAC_PORT_CTRL0_FRAMESIZELIMIT_OFFS)
+
+#define MV_GMAC_PORT_CTRL0_COUNT_EN_OFFS		15
+#define MV_GMAC_PORT_CTRL0_COUNT_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL0_COUNT_EN_OFFS)
+
+
+/* Port Mac Control1 */
+#define MV_GMAC_PORT_CTRL1_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0004 + (port) * 0x1000)
+#define MV_GMAC_PORT_CTRL1_EN_RX_CRC_CHECK_OFFS	0
+#define MV_GMAC_PORT_CTRL1_EN_RX_CRC_CHECK_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_EN_RX_CRC_CHECK_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_OFFS		1
+#define MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_EN_PERIODIC_FC_XON_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_MGMII_MODE_OFFS		2
+#define MV_GMAC_PORT_CTRL1_MGMII_MODE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_MGMII_MODE_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_PFC_CASCADE_PORT_ENABLE_OFFS		3
+#define MV_GMAC_PORT_CTRL1_PFC_CASCADE_PORT_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_PFC_CASCADE_PORT_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_DIS_EXCESSIVE_COL_OFFS		4
+#define MV_GMAC_PORT_CTRL1_DIS_EXCESSIVE_COL_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_DIS_EXCESSIVE_COL_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_GMII_LOOPBACK_OFFS		5
+#define MV_GMAC_PORT_CTRL1_GMII_LOOPBACK_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_GMII_LOOPBACK_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_PCS_LOOPBACK_OFFS		6
+#define MV_GMAC_PORT_CTRL1_PCS_LOOPBACK_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_PCS_LOOPBACK_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_FC_SA_ADDR_LO_OFFS		7
+#define MV_GMAC_PORT_CTRL1_FC_SA_ADDR_LO_MASK    \
+		(0x000000ff << MV_GMAC_PORT_CTRL1_FC_SA_ADDR_LO_OFFS)
+
+#define MV_GMAC_PORT_CTRL1_EN_SHORT_PREAMBLE_OFFS		15
+#define MV_GMAC_PORT_CTRL1_EN_SHORT_PREAMBLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL1_EN_SHORT_PREAMBLE_OFFS)
+
+
+/* Port Mac Control2 */
+#define MV_GMAC_PORT_CTRL2_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0008 + (port) * 0x1000)
+#define MV_GMAC_PORT_CTRL2_SGMII_MODE_OFFS		0
+#define MV_GMAC_PORT_CTRL2_SGMII_MODE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_SGMII_MODE_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_FC_MODE_OFFS		1
+#define MV_GMAC_PORT_CTRL2_FC_MODE_MASK    \
+		(0x00000003 << MV_GMAC_PORT_CTRL2_FC_MODE_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_PCS_EN_OFFS		3
+#define MV_GMAC_PORT_CTRL2_PCS_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_PCS_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_RGMII_MODE_OFFS		4
+#define MV_GMAC_PORT_CTRL2_RGMII_MODE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_RGMII_MODE_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS		5
+#define MV_GMAC_PORT_CTRL2_DIS_PADING_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_DIS_PADING_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_PORTMACRESET_OFFS		6
+#define MV_GMAC_PORT_CTRL2_PORTMACRESET_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_PORTMACRESET_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_TX_DRAIN_OFFS		7
+#define MV_GMAC_PORT_CTRL2_TX_DRAIN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_TX_DRAIN_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_EN_MII_ODD_PRE_OFFS		8
+#define MV_GMAC_PORT_CTRL2_EN_MII_ODD_PRE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_EN_MII_ODD_PRE_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_CLK_125_BYPS_EN_OFFS		9
+#define MV_GMAC_PORT_CTRL2_CLK_125_BYPS_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_CLK_125_BYPS_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_PRBS_CHECK_EN_OFFS		10
+#define MV_GMAC_PORT_CTRL2_PRBS_CHECK_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_PRBS_CHECK_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_PRBS_GEN_EN_OFFS		11
+#define MV_GMAC_PORT_CTRL2_PRBS_GEN_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_PRBS_GEN_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_SELECT_DATA_TO_TX_OFFS		12
+#define MV_GMAC_PORT_CTRL2_SELECT_DATA_TO_TX_MASK    \
+		(0x00000003 << MV_GMAC_PORT_CTRL2_SELECT_DATA_TO_TX_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_EN_COL_ON_BP_OFFS		14
+#define MV_GMAC_PORT_CTRL2_EN_COL_ON_BP_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_EN_COL_ON_BP_OFFS)
+
+#define MV_GMAC_PORT_CTRL2_EARLY_REJECT_MODE_OFFS		15
+#define MV_GMAC_PORT_CTRL2_EARLY_REJECT_MODE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL2_EARLY_REJECT_MODE_OFFS)
+
+
+/* Port Auto-negotiation Configuration */
+#define MV_GMAC_PORT_AUTO_NEG_CFG_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x000c + (port) * 0x1000)
+#define MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_DOWN_OFFS		0
+#define MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_DOWN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_DOWN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_UP_OFFS		1
+#define MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_UP_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_FORCE_LINK_UP_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_OFFS		2
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_EN_PCS_AN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_OFFS		3
+#define MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_AN_BYPASS_EN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_INBAND_RESTARTAN_OFFS		4
+#define MV_GMAC_PORT_AUTO_NEG_CFG_INBAND_RESTARTAN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_INBAND_RESTARTAN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_OFFS		5
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_SET_MII_SPEED_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_OFFS		6
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_SET_GMII_SPEED_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_OFFS		7
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_OFFS		9
+#define MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_ADV_PAUSE_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_OFFS		10
+#define MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_ADV_ASM_PAUSE_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_OFFS			11
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_EN_FC_AN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_OFFS		12
+#define MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_SET_FULL_DX_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_OFFS		13
+#define MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_PHY_MODE_OFFS		14
+#define MV_GMAC_PORT_AUTO_NEG_CFG_PHY_MODE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_PHY_MODE_OFFS)
+
+#define MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_OFFS		15
+#define MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_MASK    \
+		(0x00000001 << MV_GMAC_PORT_AUTO_NEG_CFG_CHOOSE_SAMPLE_TX_CONFIG_OFFS)
+
+
+/* Port Status0 */
+#define MV_GMAC_PORT_STATUS0_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0010 + (port) * 0x1000)
+#define MV_GMAC_PORT_STATUS0_LINKUP_OFFS		0
+#define MV_GMAC_PORT_STATUS0_LINKUP_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_LINKUP_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_GMIISPEED_OFFS		1
+#define MV_GMAC_PORT_STATUS0_GMIISPEED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_GMIISPEED_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_MIISPEED_OFFS		2
+#define MV_GMAC_PORT_STATUS0_MIISPEED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_MIISPEED_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_FULLDX_OFFS		3
+#define MV_GMAC_PORT_STATUS0_FULLDX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_FULLDX_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_RXFCEN_OFFS		4
+#define MV_GMAC_PORT_STATUS0_RXFCEN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_RXFCEN_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_TXFCEN_OFFS		5
+#define MV_GMAC_PORT_STATUS0_TXFCEN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_TXFCEN_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_PORTRXPAUSE_OFFS		6
+#define MV_GMAC_PORT_STATUS0_PORTRXPAUSE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_PORTRXPAUSE_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_PORTTXPAUSE_OFFS		7
+#define MV_GMAC_PORT_STATUS0_PORTTXPAUSE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_PORTTXPAUSE_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_PORTIS_DOINGPRESSURE_OFFS		8
+#define MV_GMAC_PORT_STATUS0_PORTIS_DOINGPRESSURE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_PORTIS_DOINGPRESSURE_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_PORTBUFFULL_OFFS		9
+#define MV_GMAC_PORT_STATUS0_PORTBUFFULL_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_PORTBUFFULL_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_SYNCFAIL10MS_OFFS		10
+#define MV_GMAC_PORT_STATUS0_SYNCFAIL10MS_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_SYNCFAIL10MS_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_ANDONE_OFFS		11
+#define MV_GMAC_PORT_STATUS0_ANDONE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_ANDONE_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_INBAND_AUTONEG_BYPASSACT_OFFS		12
+#define MV_GMAC_PORT_STATUS0_INBAND_AUTONEG_BYPASSACT_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_INBAND_AUTONEG_BYPASSACT_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_SERDESPLL_LOCKED_OFFS		13
+#define MV_GMAC_PORT_STATUS0_SERDESPLL_LOCKED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_SERDESPLL_LOCKED_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_SYNCOK_OFFS		14
+#define MV_GMAC_PORT_STATUS0_SYNCOK_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_SYNCOK_OFFS)
+
+#define MV_GMAC_PORT_STATUS0_SQUELCHNOT_DETECTED_OFFS		15
+#define MV_GMAC_PORT_STATUS0_SQUELCHNOT_DETECTED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS0_SQUELCHNOT_DETECTED_OFFS)
+
+
+/* Port Serial Parameters Configuration */
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0014 + (port) * 0x1000)
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_UNIDIRECTIONAL_ENABLE_OFFS	0
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_UNIDIRECTIONAL_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_UNIDIRECTIONAL_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_RETRANSMIT_COLLISION_DOMAIN_OFFS		1
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_RETRANSMIT_COLLISION_DOMAIN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_RETRANSMIT_COLLISION_DOMAIN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PUMA2_BTS1444_EN_OFFS		2
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PUMA2_BTS1444_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_PUMA2_BTS1444_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_FORWARD_802_3X_FC_EN_OFFS		3
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_FORWARD_802_3X_FC_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_FORWARD_802_3X_FC_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_BP_EN_OFFS		4
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_BP_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_BP_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_RX_NEGEDGE_SAMPLE_EN_OFFS		5
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_RX_NEGEDGE_SAMPLE_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_RX_NEGEDGE_SAMPLE_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_COL_DOMAIN_LIMIT_OFFS		6
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_COL_DOMAIN_LIMIT_MASK    \
+		(0x0000003f << MV_GMAC_PORT_SERIAL_PARAM_CFG_COL_DOMAIN_LIMIT_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PERIODIC_TYPE_SELECT_OFFS		12
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PERIODIC_TYPE_SELECT_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_PERIODIC_TYPE_SELECT_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PER_PRIORITY_FC_EN_OFFS		13
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_PER_PRIORITY_FC_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_PER_PRIORITY_FC_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_TX_STANDARD_PRBS7_OFFS		14
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_TX_STANDARD_PRBS7_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_TX_STANDARD_PRBS7_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_REVERSE_PRBS_RX_OFFS		15
+#define MV_GMAC_PORT_SERIAL_PARAM_CFG_REVERSE_PRBS_RX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_CFG_REVERSE_PRBS_RX_OFFS)
+
+
+/* Port Fifo Configuration 0 */
+#define MV_GMAC_PORT_FIFO_CFG_0_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0018 + (port) * 0x1000)
+#define MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_HIGH_WM_OFFS		0
+#define MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_HIGH_WM_MASK    \
+		(0x000000ff << MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_HIGH_WM_OFFS)
+
+#define MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_LOW_WM_OFFS		8
+#define MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_LOW_WM_MASK    \
+		(0x000000ff << MV_GMAC_PORT_FIFO_CFG_0_TX_FIFO_LOW_WM_OFFS)
+
+
+/* Port Fifo Configuration 1 */
+#define MV_GMAC_PORT_FIFO_CFG_1_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x001c + (port) * 0x1000)
+#define MV_GMAC_PORT_FIFO_CFG_1_RX_FIFO_MAX_TH_OFFS		0
+#define MV_GMAC_PORT_FIFO_CFG_1_RX_FIFO_MAX_TH_MASK    \
+		(0x0000003f << MV_GMAC_PORT_FIFO_CFG_1_RX_FIFO_MAX_TH_OFFS)
+
+#define MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS		6
+#define MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_MASK    \
+		(0x000000ff << MV_GMAC_PORT_FIFO_CFG_1_TX_FIFO_MIN_TH_OFFS)
+
+#define MV_GMAC_PORT_FIFO_CFG_1_PORT_EN_FIX_EN_OFFS		15
+#define MV_GMAC_PORT_FIFO_CFG_1_PORT_EN_FIX_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_FIFO_CFG_1_PORT_EN_FIX_EN_OFFS)
+
+
+/* Port Serdes Configuration0 */
+#define MV_GMAC_PORT_SERDES_CFG0_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0028 + (port) * 0x1000)
+#define MV_GMAC_PORT_SERDES_CFG0_SERDESRESET_OFFS		0
+#define MV_GMAC_PORT_SERDES_CFG0_SERDESRESET_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_SERDESRESET_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_PU_TX_OFFS		1
+#define MV_GMAC_PORT_SERDES_CFG0_PU_TX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_PU_TX_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_PU_RX_OFFS		2
+#define MV_GMAC_PORT_SERDES_CFG0_PU_RX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_PU_RX_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_PU_PLL_OFFS		3
+#define MV_GMAC_PORT_SERDES_CFG0_PU_PLL_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_PU_PLL_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_PU_IVREF_OFFS		4
+#define MV_GMAC_PORT_SERDES_CFG0_PU_IVREF_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_PU_IVREF_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_TESTEN_OFFS		5
+#define MV_GMAC_PORT_SERDES_CFG0_TESTEN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_TESTEN_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_DPHER_EN_OFFS		6
+#define MV_GMAC_PORT_SERDES_CFG0_DPHER_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_DPHER_EN_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_RUDI_INVALID_ENABLE_OFFS		7
+#define MV_GMAC_PORT_SERDES_CFG0_RUDI_INVALID_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_RUDI_INVALID_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_ACK_OVERRIDE_ENABLE_OFFS		8
+#define MV_GMAC_PORT_SERDES_CFG0_ACK_OVERRIDE_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_ACK_OVERRIDE_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_CONFIG_WORD_ENABLE_OFFS		9
+#define MV_GMAC_PORT_SERDES_CFG0_CONFIG_WORD_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_CONFIG_WORD_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_SYNC_FAIL_INT_ENABLE_OFFS		10
+#define MV_GMAC_PORT_SERDES_CFG0_SYNC_FAIL_INT_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_SYNC_FAIL_INT_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_MASTER_MODE_ENABLE_OFFS		11
+#define MV_GMAC_PORT_SERDES_CFG0_MASTER_MODE_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_MASTER_MODE_ENABLE_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_TERM75_TX_OFFS		12
+#define MV_GMAC_PORT_SERDES_CFG0_TERM75_TX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_TERM75_TX_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_OUTAMP_OFFS		13
+#define MV_GMAC_PORT_SERDES_CFG0_OUTAMP_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_OUTAMP_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_BTS712_FIX_EN_OFFS		14
+#define MV_GMAC_PORT_SERDES_CFG0_BTS712_FIX_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_BTS712_FIX_EN_OFFS)
+
+#define MV_GMAC_PORT_SERDES_CFG0_BTS156_FIX_EN_OFFS		15
+#define MV_GMAC_PORT_SERDES_CFG0_BTS156_FIX_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERDES_CFG0_BTS156_FIX_EN_OFFS)
+
+
+/* Port Serdes Configuration1 */
+#define MV_GMAC_PORT_SERDES_CFG1_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x002c + (port) * 0x1000)
+#define MV_GMAC_PORT_SERDES_CFG1_SMII_RX_10MB_CLK_EDGE_SEL_OFFS	0
+#define MV_GMAC_PORT_SERDES_CFG1_SMII_RX_10MB_CLK_EDGE_SEL_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_SMII_RX_10MB_CLK_EDGE_SEL_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_SMII_TX_10MB_CLK_EDGE_SEL_OFFS	1
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_SMII_TX_10MB_CLK_EDGE_SEL_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_SMII_TX_10MB_CLK_EDGE_SEL_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_MEN_OFFS		2
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_MEN_MASK    \
+		(0x00000003 << MV_GMAC_GMAC_PORT_SERDES_CFG1_MEN_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_VCMS_OFFS		4
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_VCMS_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_VCMS_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_USE_SIGDET_OFFS		5
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_USE_SIGDET_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_USE_SIGDET_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_EN_CRS_MASK_TX_OFFS		6
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_EN_CRS_MASK_TX_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_EN_CRS_MASK_TX_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_ENABLE_OFFS		7
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_ENABLE_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_PHY_ADDRESS_OFFS		8
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_PHY_ADDRESS_MASK    \
+		(0x0000001f << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_PHY_ADDRESS_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SIGDET_POLARITY_OFFS		13
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SIGDET_POLARITY_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SIGDET_POLARITY_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_INTERRUPT_POLARITY_OFFS		14
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_INTERRUPT_POLARITY_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_INTERRUPT_POLARITY_OFFS)
+
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SERDES_POLARITY_OFFS		15
+#define MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SERDES_POLARITY_MASK    \
+		(0x00000001 << MV_GMAC_GMAC_PORT_SERDES_CFG1_100FX_PCS_SERDES_POLARITY_OFFS)
+
+
+/* Port Serdes Configuration2 */
+#define MV_GMAC_PORT_SERDES_CFG2_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0030 + (port) * 0x1000)
+#define MV_GMAC_PORT_SERDES_CFG2_AN_ADV_CONFIGURATION_OFFS	0
+#define MV_GMAC_PORT_SERDES_CFG2_AN_ADV_CONFIGURATION_MASK    \
+		(0x0000ffff << MV_GMAC_PORT_SERDES_CFG2_AN_ADV_CONFIGURATION_OFFS)
+
+
+/* Port Serdes Configuration3 */
+#define MV_GMAC_PORT_SERDES_CFG3_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0034 + (port) * 0x1000)
+#define MV_GMAC_PORT_SERDES_CFG3_ABILITY_MATCH_STATUS_OFFS		0
+#define MV_GMAC_PORT_SERDES_CFG3_ABILITY_MATCH_STATUS_MASK    \
+		(0x0000ffff << MV_GMAC_PORT_SERDES_CFG3_ABILITY_MATCH_STATUS_OFFS)
+
+
+/* Port Prbs Status */
+#define MV_GMAC_PORT_PRBS_STATUS_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0038 + (port) * 0x1000)
+#define MV_GMAC_PORT_PRBS_STATUS_PRBSCHECK_LOCKED_OFFS		0
+#define MV_GMAC_PORT_PRBS_STATUS_PRBSCHECK_LOCKED_MASK    \
+		(0x00000001 << MV_GMAC_PORT_PRBS_STATUS_PRBSCHECK_LOCKED_OFFS)
+
+#define MV_GMAC_PORT_PRBS_STATUS_PRBSCHECKRDY_OFFS		1
+#define MV_GMAC_PORT_PRBS_STATUS_PRBSCHECKRDY_MASK    \
+		(0x00000001 << MV_GMAC_PORT_PRBS_STATUS_PRBSCHECKRDY_OFFS)
+
+
+/* Port Prbs Error Counter */
+#define MV_GMAC_PORT_PRBS_ERR_CNTR_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x003c + (port) * 0x1000)
+#define MV_GMAC_PORT_PRBS_ERR_CNTR_PRBSBITERRCNT_OFFS		0
+#define MV_GMAC_PORT_PRBS_ERR_CNTR_PRBSBITERRCNT_MASK    \
+		(0x0000ffff << MV_GMAC_PORT_PRBS_ERR_CNTR_PRBSBITERRCNT_OFFS)
+
+
+/* Port Status1 */
+#define MV_GMAC_PORT_STATUS1_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0040 + (port) * 0x1000)
+#define MV_GMAC_PORT_STATUS1_MEDIAACTIVE_OFFS		0
+#define MV_GMAC_PORT_STATUS1_MEDIAACTIVE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_STATUS1_MEDIAACTIVE_OFFS)
+
+
+/* Port Mib Counters Control */
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0044 + (port) * 0x1000)
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_COPY_TRIGGER_OFFS	0
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_COPY_TRIGGER_MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_COPY_TRIGGER_OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_CLEAR_ON_READ__OFFS		1
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_CLEAR_ON_READ__MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_CLEAR_ON_READ__OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_RX_HISTOGRAM_EN_OFFS		2
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_RX_HISTOGRAM_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_RX_HISTOGRAM_EN_OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_TX_HISTOGRAM_EN_OFFS		3
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_TX_HISTOGRAM_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_TX_HISTOGRAM_EN_OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__OFFS		4
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_XCAT_BTS_340_EN__OFFS		5
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_XCAT_BTS_340_EN__MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_XCAT_BTS_340_EN__OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_OFFS		6
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_OFFS)
+
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_OFFS		7
+#define MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_MASK    \
+		(0x00000001 << MV_GMAC_PORT_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_OFFS)
+
+
+/* Port Mac Control3 */
+#define MV_GMAC_PORT_CTRL3_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0048 + (port) * 0x1000)
+#define MV_GMAC_PORT_CTRL3_BUF_SIZE_OFFS		0
+#define MV_GMAC_PORT_CTRL3_BUF_SIZE_MASK    \
+		(0x0000003f << MV_GMAC_PORT_CTRL3_BUF_SIZE_OFFS)
+
+#define MV_GMAC_PORT_CTRL3_IPG_DATA_OFFS		6
+#define MV_GMAC_PORT_CTRL3_IPG_DATA_MASK    \
+		(0x000001ff << MV_GMAC_PORT_CTRL3_IPG_DATA_OFFS)
+
+#define MV_GMAC_PORT_CTRL3_LLFC_GLOBAL_FC_ENABLE_OFFS		15
+#define MV_GMAC_PORT_CTRL3_LLFC_GLOBAL_FC_ENABLE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL3_LLFC_GLOBAL_FC_ENABLE_OFFS)
+
+
+/* QSGMII */
+#define MV_GMAC_QSGMII_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x004c + (port) * 0x1000)
+#define MV_GMAC_QSGMII_QSGMII_REG_OFFS		0
+#define MV_GMAC_QSGMII_QSGMII_REG_MASK    \
+		(0x0000ffff << MV_GMAC_QSGMII_QSGMII_REG_OFFS)
+
+
+/* Qsgmii Status */
+#define MV_GMAC_QSGMII_STATUS_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0050 + (port) * 0x1000)
+#define MV_GMAC_QSGMII_STATUS_QSGMII_STATUS_OFFS		0
+#define MV_GMAC_QSGMII_STATUS_QSGMII_STATUS_MASK    \
+		(0x000000ff << MV_GMAC_QSGMII_STATUS_QSGMII_STATUS_OFFS)
+
+
+/* Qsgmii Prbs Counter */
+#define MV_GMAC_QSGMII_PRBS_CNTR_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0054 + (port) * 0x1000)
+#define MV_GMAC_QSGMII_PRBS_CNTR_QSGMII_PRBS_ERR_CNT_REG_OFFS		0
+#define MV_GMAC_QSGMII_PRBS_CNTR_QSGMII_PRBS_ERR_CNT_REG_MASK    \
+		(0x0000ffff << MV_GMAC_QSGMII_PRBS_CNTR_QSGMII_PRBS_ERR_CNT_REG_OFFS)
+
+
+/* Ccfc Port Speed Timer%p */
+#define MV_GMAC_CCFC_PORT_SPEED_TIMER_REG(port, t)		(MV_GMAC_UNIT_OFFSET + 0x0058 + t*4 + (port) * 0x1000)
+#define MV_GMAC_CCFC_PORT_SPEED_TIMER_PORTSPEEDTIMER_OFFS		0
+#define MV_GMAC_CCFC_PORT_SPEED_TIMER_PORTSPEEDTIMER_MASK    \
+		(0x0000ffff << MV_GMAC_CCFC_PORT_SPEED_TIMER_PORTSPEEDTIMER_OFFS)
+
+
+/* Fc Dsa Tag %n */
+#define MV_GMAC_FC_DSA_TAG_REG(port, n)			(MV_GMAC_UNIT_OFFSET + 0x0078 + 4*n + (port) * 0x1000)
+#define MV_GMAC_FC_DSA_TAG_DSATAGREGN_OFFS		0
+#define MV_GMAC_FC_DSA_TAG_DSATAGREGN_MASK    \
+		(0x0000ffff << MV_GMAC_FC_DSA_TAG_DSATAGREGN_OFFS)
+
+
+/* Link Level Flow Control Window Reg 0 */
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_0(port)		(MV_GMAC_UNIT_OFFSET + 0x0088 + (port) * 0x1000)
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_0_LLFC_FC_WINDOW_REG0_OFFS		0
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_0_LLFC_FC_WINDOW_REG0_MASK    \
+		(0x0000ffff << MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_0_LLFC_FC_WINDOW_REG0_OFFS)
+
+
+/* Link Level Flow Control Window Reg 1 */
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1(port)		(MV_GMAC_UNIT_OFFSET + 0x008c + (port) * 0x1000)
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_FC_WINDOW_REG1_OFFS		0
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_FC_WINDOW_REG1_MASK    \
+		(0x00007fff << MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_FC_WINDOW_REG1_OFFS)
+
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_RATE_LIMIT_EN_OFFS		15
+#define MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_RATE_LIMIT_EN_MASK    \
+		(0x00000001 << MV_GMAC_LINK_LEVEL_FLOW_CTRL_WINDOW_REG_1_LLFC_RATE_LIMIT_EN_OFFS)
+
+
+/* Port Mac Control4 */
+#define MV_GMAC_PORT_CTRL4_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x0090 + (port) * 0x1000)
+#define MV_GMAC_PORT_CTRL4_EXT_PIN_GMII_SEL_OFFS		0
+#define MV_GMAC_PORT_CTRL4_EXT_PIN_GMII_SEL_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_EXT_PIN_GMII_SEL_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_PREAMBLE_FIX_OFFS		1
+#define MV_GMAC_PORT_CTRL4_PREAMBLE_FIX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_PREAMBLE_FIX_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_SQ_DETECT_FIX_EN_OFFS		2
+#define MV_GMAC_PORT_CTRL4_SQ_DETECT_FIX_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_SQ_DETECT_FIX_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_FC_EN_RX_OFFS		3
+#define MV_GMAC_PORT_CTRL4_FC_EN_RX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_FC_EN_RX_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_FC_EN_TX_OFFS		4
+#define MV_GMAC_PORT_CTRL4_FC_EN_TX_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_FC_EN_TX_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_DP_CLK_SEL_OFFS		5
+#define MV_GMAC_PORT_CTRL4_DP_CLK_SEL_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_DP_CLK_SEL_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_SYNC_BYPASS_OFFS		6
+#define MV_GMAC_PORT_CTRL4_SYNC_BYPASS_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_SYNC_BYPASS_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_OFFS		7
+#define MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_QSGMII_BYPASS_ACTIVE_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_COUNT_EXTERNAL_FC_EN_OFFS		8
+#define MV_GMAC_PORT_CTRL4_COUNT_EXTERNAL_FC_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_COUNT_EXTERNAL_FC_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_MARVELL_HEADER_EN_OFFS		9
+#define MV_GMAC_PORT_CTRL4_MARVELL_HEADER_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_CTRL4_MARVELL_HEADER_EN_OFFS)
+
+#define MV_GMAC_PORT_CTRL4_LEDS_NUMBER_OFFS		10
+#define MV_GMAC_PORT_CTRL4_LEDS_NUMBER_MASK    \
+		(0x0000003f << MV_GMAC_PORT_CTRL4_LEDS_NUMBER_OFFS)
+
+
+/* Port Serial Parameters 1 Configuration */
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0094 + (port) * 0x1000)
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_RX_STANDARD_PRBS7_OFFS		0
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_RX_STANDARD_PRBS7_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_1_CFG_RX_STANDARD_PRBS7_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_PFC_EN_OFFS		1
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_PFC_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_PFC_EN_OFFS)
+
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_UNKNOWN_FC_EN_OFFS		2
+#define MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_UNKNOWN_FC_EN_MASK    \
+		(0x00000001 << MV_GMAC_PORT_SERIAL_PARAM_1_CFG_FORWARD_UNKNOWN_FC_EN_OFFS)
+
+
+/* Lpi Control 0 */
+#define MV_GMAC_LPI_CTRL_0_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x00c0 + (port) * 0x1000)
+#define MV_GMAC_LPI_CTRL_0_LI_LIMIT_OFFS		0
+#define MV_GMAC_LPI_CTRL_0_LI_LIMIT_MASK    \
+		(0x000000ff << MV_GMAC_LPI_CTRL_0_LI_LIMIT_OFFS)
+
+#define MV_GMAC_LPI_CTRL_0_TS_LIMIT_OFFS		8
+#define MV_GMAC_LPI_CTRL_0_TS_LIMIT_MASK    \
+		(0x000000ff << MV_GMAC_LPI_CTRL_0_TS_LIMIT_OFFS)
+
+
+/* Lpi Control 1 */
+#define MV_GMAC_LPI_CTRL_1_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x00c4 + (port) * 0x1000)
+#define MV_GMAC_LPI_CTRL_1_LPI_REQUEST_EN_OFFS		0
+#define MV_GMAC_LPI_CTRL_1_LPI_REQUEST_EN_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_1_LPI_REQUEST_EN_OFFS)
+
+#define MV_GMAC_LPI_CTRL_1_LPI_REQUEST_FORCE_OFFS		1
+#define MV_GMAC_LPI_CTRL_1_LPI_REQUEST_FORCE_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_1_LPI_REQUEST_FORCE_OFFS)
+
+#define MV_GMAC_LPI_CTRL_1_LPI_MANUAL_MODE_OFFS		2
+#define MV_GMAC_LPI_CTRL_1_LPI_MANUAL_MODE_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_1_LPI_MANUAL_MODE_OFFS)
+
+#define MV_GMAC_LPI_CTRL_1_EN_GTX_CLK_HALT_OFFS		3
+#define MV_GMAC_LPI_CTRL_1_EN_GTX_CLK_HALT_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_1_EN_GTX_CLK_HALT_OFFS)
+
+#define MV_GMAC_LPI_CTRL_1_TW_LIMIT_OFFS		4
+#define MV_GMAC_LPI_CTRL_1_TW_LIMIT_MASK    \
+		(0x00000fff << MV_GMAC_LPI_CTRL_1_TW_LIMIT_OFFS)
+
+
+/* Lpi Control 2 */
+#define MV_GMAC_LPI_CTRL_2_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x00c8 + (port) * 0x1000)
+#define MV_GMAC_LPI_CTRL_2_LPI_CLK_DIV_OFFS		0
+#define MV_GMAC_LPI_CTRL_2_LPI_CLK_DIV_MASK    \
+		(0x0000007f << MV_GMAC_LPI_CTRL_2_LPI_CLK_DIV_OFFS)
+
+#define MV_GMAC_LPI_CTRL_2_PCS_RX_ER_MASK_DISABLE_OFFS		7
+#define MV_GMAC_LPI_CTRL_2_PCS_RX_ER_MASK_DISABLE_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_2_PCS_RX_ER_MASK_DISABLE_OFFS)
+
+#define MV_GMAC_LPI_CTRL_2_EN_GMII2MII_LPI_FIX_OFFS		8
+#define MV_GMAC_LPI_CTRL_2_EN_GMII2MII_LPI_FIX_MASK    \
+		(0x00000001 << MV_GMAC_LPI_CTRL_2_EN_GMII2MII_LPI_FIX_OFFS)
+
+
+/* Lpi Status */
+#define MV_GMAC_LPI_STATUS_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x00cc + (port) * 0x1000)
+#define MV_GMAC_LPI_STATUS_PCS_RX_LPI_STATUS_OFFS		0
+#define MV_GMAC_LPI_STATUS_PCS_RX_LPI_STATUS_MASK    \
+		(0x00000001 << MV_GMAC_LPI_STATUS_PCS_RX_LPI_STATUS_OFFS)
+
+#define MV_GMAC_LPI_STATUS_PCS_TX_LPI_STATUS_OFFS		1
+#define MV_GMAC_LPI_STATUS_PCS_TX_LPI_STATUS_MASK    \
+		(0x00000001 << MV_GMAC_LPI_STATUS_PCS_TX_LPI_STATUS_OFFS)
+
+#define MV_GMAC_LPI_STATUS_MAC_RX_LP_IDLE_STATUS_OFFS		2
+#define MV_GMAC_LPI_STATUS_MAC_RX_LP_IDLE_STATUS_MASK    \
+		(0x00000001 << MV_GMAC_LPI_STATUS_MAC_RX_LP_IDLE_STATUS_OFFS)
+
+#define MV_GMAC_LPI_STATUS_MAC_TX_LP_WAIT_STATUS_OFFS		3
+#define MV_GMAC_LPI_STATUS_MAC_TX_LP_WAIT_STATUS_MASK    \
+		(0x00000001 << MV_GMAC_LPI_STATUS_MAC_TX_LP_WAIT_STATUS_OFFS)
+
+#define MV_GMAC_LPI_STATUS_MAC_TX_LP_IDLE_STATUS_OFFS		4
+#define MV_GMAC_LPI_STATUS_MAC_TX_LP_IDLE_STATUS_MASK    \
+		(0x00000001 << MV_GMAC_LPI_STATUS_MAC_TX_LP_IDLE_STATUS_OFFS)
+
+
+/* Lpi Counter */
+#define MV_GMAC_LPI_CNTR_REG(port)				(MV_GMAC_UNIT_OFFSET + 0x00d0 + (port) * 0x1000)
+#define MV_GMAC_LPI_CNTR_LPI_COUNTER_OFFS		0
+#define MV_GMAC_LPI_CNTR_LPI_COUNTER_MASK    \
+		(0x0000ffff << MV_GMAC_LPI_CNTR_LPI_COUNTER_OFFS)
+
+
+/* Pulse 1 Ms Low */
+#define MV_GMAC_PULSE_1_MS_LOW_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x00d4 + (port) * 0x1000)
+#define MV_GMAC_PULSE_1_MS_LOW_PULSE_1MS_MAX_LOW_OFFS		0
+#define MV_GMAC_PULSE_1_MS_LOW_PULSE_1MS_MAX_LOW_MASK    \
+		(0x0000ffff << MV_GMAC_PULSE_1_MS_LOW_PULSE_1MS_MAX_LOW_OFFS)
+
+
+/* Pulse 1 Ms High */
+#define MV_GMAC_PULSE_1_MS_HIGH_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x00d8 + (port) * 0x1000)
+#define MV_GMAC_PULSE_1_MS_HIGH_PULSE_1MS_MAX_HIGH_OFFS		0
+#define MV_GMAC_PULSE_1_MS_HIGH_PULSE_1MS_MAX_HIGH_MASK    \
+		(0x0000ffff << MV_GMAC_PULSE_1_MS_HIGH_PULSE_1MS_MAX_HIGH_OFFS)
+
+/* Port Interrupt Cause */
+#define MV_GMAC_INTERRUPT_CAUSE_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0020 + (port) * 0x1000)
+/* Port Interrupt Mask */
+#define MV_GMAC_INTERRUPT_MASK_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x0024 + (port) * 0x1000)
+#define MV_GMAC_INTERRUPT_CAUSE_LINK_CHANGE_OFFS		1
+#define MV_GMAC_INTERRUPT_CAUSE_LINK_CHANGE_MASK		(0x1 << MV_GMAC_INTERRUPT_CAUSE_LINK_CHANGE_OFFS)
+
+/* Port Interrupt Summary Cause */
+#define MV_GMAC_INTERRUPT_SUM_CAUSE_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x00A0 + (port) * 0x1000)
+/* Port Interrupt Summary Mask */
+#define MV_GMAC_INTERRUPT_SUM_MASK_REG(port)			(MV_GMAC_UNIT_OFFSET + 0x00A4 + (port) * 0x1000)
+#define MV_GMAC_INTERRUPT_SUM_CAUSE_LINK_CHANGE_OFFS		1
+#define MV_GMAC_INTERRUPT_SUM_CAUSE_LINK_CHANGE_MASK		(0x1 << MV_GMAC_INTERRUPT_SUM_CAUSE_LINK_CHANGE_OFFS)
+
+#endif /* __mv_gmac_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.c b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.c
new file mode 100644
index 0000000..ac5bcff
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.c
@@ -0,0 +1,432 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mac/mv_xlg_mac_if.h"
+#include "gop/mac/mv_xlg_mac_regs.h"
+
+
+/* print value of unit registers */
+void mv_xlg_mac_regs_dump(int port)
+{
+	int timer;
+	char reg_name[16];
+
+	mv_gop_reg_print("PORT_MAC_CTRL0", MV_XLG_PORT_MAC_CTRL0_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL1", MV_XLG_PORT_MAC_CTRL1_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL2", MV_XLG_PORT_MAC_CTRL2_REG(port));
+	mv_gop_reg_print("PORT_STATUS", MV_XLG_MAC_PORT_STATUS_REG(port));
+	mv_gop_reg_print("PORT_FIFOS_THRS_CFG", MV_XLG_PORT_FIFOS_THRS_CFG_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL3", MV_XLG_PORT_MAC_CTRL3_REG(port));
+	mv_gop_reg_print("PORT_PER_PRIO_FLOW_CTRL_STATUS", MV_XLG_PORT_PER_PRIO_FLOW_CTRL_STATUS_REG(port));
+	mv_gop_reg_print("DEBUG_BUS_STATUS", MV_XLG_DEBUG_BUS_STATUS_REG(port));
+	mv_gop_reg_print("PORT_METAL_FIX", MV_XLG_PORT_METAL_FIX_REG(port));
+	mv_gop_reg_print("XG_MIB_CNTRS_CTRL", MV_XLG_MIB_CNTRS_CTRL_REG(port));
+	for (timer = 0; timer < 8; timer++) {
+		sprintf(reg_name, "CNCCFC_TIMER%d", timer);
+		mv_gop_reg_print(reg_name, MV_XLG_CNCCFC_TIMERI_REG(port, timer));
+	}
+	mv_gop_reg_print("PPFC_CTRL", MV_XLG_MAC_PPFC_CTRL_REG(port));
+	mv_gop_reg_print("FC_DSA_TAG_0", MV_XLG_MAC_FC_DSA_TAG_0_REG(port));
+	mv_gop_reg_print("FC_DSA_TAG_1", MV_XLG_MAC_FC_DSA_TAG_1_REG(port));
+	mv_gop_reg_print("FC_DSA_TAG_2", MV_XLG_MAC_FC_DSA_TAG_2_REG(port));
+	mv_gop_reg_print("FC_DSA_TAG_3", MV_XLG_MAC_FC_DSA_TAG_3_REG(port));
+	mv_gop_reg_print("DIC_BUDGET_COMPENSATION", MV_XLG_MAC_DIC_BUDGET_COMPENSATION_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL4", MV_XLG_PORT_MAC_CTRL4_REG(port));
+	mv_gop_reg_print("PORT_MAC_CTRL5", MV_XLG_PORT_MAC_CTRL5_REG(port));
+	mv_gop_reg_print("EXT_CTRL", MV_XLG_MAC_EXT_CTRL_REG(port));
+	mv_gop_reg_print("MACRO_CTRL", MV_XLG_MAC_MACRO_CTRL_REG(port));
+	mv_gop_reg_print("MACRO_CTRL", MV_XLG_MAC_MACRO_CTRL_REG(port));
+	mv_gop_reg_print("PORT_INT_MASK", MV_XLG_INTERRUPT_MASK_REG(port));
+	mv_gop_reg_print("EXTERNAL_INT_MASK", MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(port));
+}
+
+/* Set the MAC to reset or exit from reset */
+int mv_xlg_mac_reset(int mac_num, enum mv_reset reset)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_XLG_PORT_MAC_CTRL0_REG(mac_num);
+
+	/* read - modify - write */
+	val = mv_gop_reg_read(reg_addr);
+	if (reset == RESET)
+		val &= ~MV_XLG_MAC_CTRL0_MACRESETN_MASK;
+	else
+		val |= MV_XLG_MAC_CTRL0_MACRESETN_MASK;
+	mv_gop_reg_write(reg_addr, val);
+
+	return 0;
+}
+
+/* Set the internal mux's to the required MAC in the GOP */
+int mv_xlg_mac_mode_cfg(int mac_num, int num_of_act_lanes)
+{
+	u32 reg_addr;
+	u32 val;
+
+	/* Set TX FIFO thresholds */
+	reg_addr = MV_XLG_PORT_FIFOS_THRS_CFG_REG(mac_num);
+	val = mv_gop_reg_read(reg_addr);
+	MV_U32_SET_FIELD(val, MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXRDTHR_MASK,
+		(6 << MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXRDTHR_OFFS));
+	mv_gop_reg_write(reg_addr, val);
+
+	/* configure 10G MAC mode */
+	reg_addr = MV_XLG_PORT_MAC_CTRL3_REG(mac_num);
+	val = mv_gop_reg_read(reg_addr);
+	MV_U32_SET_FIELD(val, MV_XLG_MAC_CTRL3_MACMODESELECT_MASK,
+		(1 << MV_XLG_MAC_CTRL3_MACMODESELECT_OFFS));
+	mv_gop_reg_write(reg_addr, val);
+
+	reg_addr = MV_XLG_PORT_MAC_CTRL4_REG(mac_num);
+
+	/* read - modify - write */
+	val = mv_gop_reg_read(reg_addr);
+	MV_U32_SET_FIELD(val, 0x1F10, 0x310);
+	mv_gop_reg_write(reg_addr, val);
+
+	/* Jumbo frame support - 0x1400*2= 0x2800 bytes */
+	val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL1_REG(mac_num));
+	MV_U32_SET_FIELD(val, 0x1FFF, 0x1400);
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL1_REG(mac_num), val);
+
+	/* mask all port interrupts */
+	mv_xlg_port_link_event_mask(mac_num);
+
+	/* unmask link change interrupt */
+	val = mv_gop_reg_read(MV_XLG_INTERRUPT_MASK_REG(mac_num));
+	val |= MV_XLG_INTERRUPT_LINK_CHANGE_MASK;
+	val |= 1; /* unmask summary bit */
+	mv_gop_reg_write(MV_XLG_INTERRUPT_MASK_REG(mac_num), val);
+
+
+	return 0;
+}
+
+/* Configure MAC loopback */
+int mv_xlg_mac_loopback_cfg(int mac_num, enum mv_lb_type type)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_XLG_PORT_MAC_CTRL1_REG(mac_num);
+	val = mv_gop_reg_read(reg_addr);
+	switch (type) {
+	case MV_DISABLE_LB:
+		val &= ~MV_XLG_MAC_CTRL1_MACLOOPBACKEN_MASK;
+		val &= ~MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_MASK;
+		break;
+	case MV_RX_2_TX_LB:
+		val &= ~MV_XLG_MAC_CTRL1_MACLOOPBACKEN_MASK;
+		val |= MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_MASK;
+		break;
+	case MV_TX_2_RX_LB:
+		val |= MV_XLG_MAC_CTRL1_MACLOOPBACKEN_MASK;
+		val |= MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_MASK;
+		break;
+	default:
+		return -1;
+	}
+	mv_gop_reg_write(reg_addr, val);
+	return 0;
+}
+
+/* Get MAC link status */
+bool mv_xlg_mac_link_status_get(int mac_num)
+{
+
+	if (mv_gop_reg_read(MV_XLG_MAC_PORT_STATUS_REG(mac_num)) & 1)
+		return true;
+
+	return false;
+}
+
+
+/* Enable port and MIB counters update */
+void mv_xlg_mac_port_enable(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+	reg_val |= MV_XLG_MAC_CTRL0_PORTEN_MASK;
+	reg_val &= ~MV_XLG_MAC_CTRL0_MIBCNTDIS_MASK;
+
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL0_REG(mac_num), reg_val);
+}
+
+/* Disable port */
+void mv_xlg_mac_port_disable(int mac_num)
+{
+	u32 reg_val;
+
+	/* mask all port interrupts */
+	mv_xlg_port_link_event_mask(mac_num);
+
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+	reg_val &= ~MV_XLG_MAC_CTRL0_PORTEN_MASK;
+
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL0_REG(mac_num), reg_val);
+}
+
+void mv_xlg_mac_port_periodic_xon_set(int mac_num, int enable)
+{
+	u32 reg_val;
+
+	reg_val =  mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+
+	if (enable)
+		reg_val |= MV_XLG_MAC_CTRL0_PERIODICXONEN_MASK;
+	else
+		reg_val &= ~MV_XLG_MAC_CTRL0_PERIODICXONEN_MASK;
+
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL0_REG(mac_num), reg_val);
+}
+
+int mv_xlg_mac_link_status(int mac_num, struct mv_port_link_status *pstatus)
+{
+	u32 reg_val;
+	u32 mac_mode;
+	u32 fc_en;
+
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL3_REG(mac_num));
+	mac_mode = (reg_val & MV_XLG_MAC_CTRL3_MACMODESELECT_MASK) >> MV_XLG_MAC_CTRL3_MACMODESELECT_OFFS;
+
+	/* speed  and duplex */
+	switch (mac_mode) {
+	case 0:
+		pstatus->speed = MV_PORT_SPEED_1000;
+		pstatus->duplex = MV_PORT_DUPLEX_AN;
+		break;
+	case 1:
+		pstatus->speed = MV_PORT_SPEED_10000;
+		pstatus->duplex = MV_PORT_DUPLEX_FULL;
+		break;
+	default:
+		return -1;
+	}
+
+	/* link status */
+	reg_val = mv_gop_reg_read(MV_XLG_MAC_PORT_STATUS_REG(mac_num));
+	if (reg_val & MV_XLG_MAC_PORT_STATUS_LINKSTATUS_MASK)
+		pstatus->linkup = 1 /*TRUE*/;
+	else
+		pstatus->linkup = 0 /*FALSE*/;
+
+	/* flow control status */
+	fc_en = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+	if (reg_val & MV_XLG_MAC_PORT_STATUS_PORTTXPAUSE_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ACTIVE;
+	else if (fc_en & MV_XLG_MAC_CTRL0_TXFCEN_MASK)
+		pstatus->tx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->tx_fc = MV_PORT_FC_DISABLE;
+
+	if (reg_val & MV_XLG_MAC_PORT_STATUS_PORTRXPAUSE_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ACTIVE;
+	else if (fc_en & MV_XLG_MAC_CTRL0_RXFCEN_MASK)
+		pstatus->rx_fc = MV_PORT_FC_ENABLE;
+	else
+		pstatus->rx_fc = MV_PORT_FC_DISABLE;
+
+	return 0;
+}
+
+/* Change maximum receive size of the port */
+int mv_xlg_mac_max_rx_size_set(int mac_num, int max_rx_size)
+{
+	u32	reg_val;
+
+	reg_val =  mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL1_REG(mac_num));
+	reg_val &= ~MV_XLG_MAC_CTRL1_FRAMESIZELIMIT_MASK;
+	reg_val |= (((max_rx_size - MV_MH_SIZE) / 2) << MV_XLG_MAC_CTRL1_FRAMESIZELIMIT_OFFS);
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL1_REG(mac_num), reg_val);
+
+	return 0;
+}
+
+/* Sets "Force Link Pass" and "Do Not Force Link Fail" bits.
+*  This function should only be called when the port is disabled.
+* INPUT:
+*	int  port		- port number
+*	bool force_link_pass	- Force Link Pass
+*	bool force_link_fail - Force Link Failure
+*		0, 0 - normal state: detect link via PHY and connector
+*		1, 1 - prohibited state.
+*/
+int mv_xlg_mac_force_link_mode_set(int mac_num, bool force_link_up, bool force_link_down)
+{
+	u32 reg_val;
+
+	/* Can't force link pass and link fail at the same time */
+	if ((force_link_up) && (force_link_down))
+		return -EINVAL;
+
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+
+	if (force_link_up)
+		reg_val |= MV_XLG_MAC_CTRL0_FORCELINKPASS_MASK;
+	else
+		reg_val &= ~MV_XLG_MAC_CTRL0_FORCELINKPASS_MASK;
+
+	if (force_link_down)
+		reg_val |= MV_XLG_MAC_CTRL0_FORCELINKDOWN_MASK;
+	else
+		reg_val &= ~MV_XLG_MAC_CTRL0_FORCELINKDOWN_MASK;
+
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL0_REG(mac_num), reg_val);
+
+	return 0;
+}
+
+/* Sets port speed to Auto Negotiation / 1000 / 100 / 10 Mbps.
+*  Sets port duplex to Auto Negotiation / Full / Half Duplex.
+*/
+int mv_xlg_mac_speed_duplex_set(int mac_num, enum mv_port_speed speed, enum mv_port_duplex duplex)
+{
+	/* not supported */
+	return -1;
+}
+
+/* Gets port speed and duplex */
+int mv_xlg_mac_speed_duplex_get(int mac_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex)
+{
+	/* not supported */
+	return -1;
+}
+
+/* Configure the port's Flow Control properties */
+int mv_xlg_mac_fc_set(int mac_num, enum mv_port_fc fc)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+
+	switch (fc) {
+	case MV_PORT_FC_DISABLE:
+		reg_val &= ~MV_XLG_MAC_CTRL0_RXFCEN_MASK;
+		reg_val &= ~MV_XLG_MAC_CTRL0_TXFCEN_MASK;
+		break;
+
+	case MV_PORT_FC_ENABLE:
+		reg_val |= MV_XLG_MAC_CTRL0_RXFCEN_MASK;
+		reg_val |= MV_XLG_MAC_CTRL0_TXFCEN_MASK;
+		break;
+
+	case MV_PORT_FC_AN_NO:
+	case MV_PORT_FC_AN_SYM:
+	case MV_PORT_FC_AN_ASYM:
+	default:
+		pr_err("XLG MAC: Unexpected FlowControl value %d\n", fc);
+		return -EINVAL;
+	}
+
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL0_REG(mac_num), reg_val);
+	return 0;
+}
+
+/* Get Flow Control configuration of the port */
+void mv_xlg_mac_fc_get(int mac_num, enum mv_port_fc *fc)
+{
+	u32 reg_val;
+
+	/* No auto negotiation for flow control */
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL0_REG(mac_num));
+
+	if ((reg_val & MV_XLG_MAC_CTRL0_RXFCEN_MASK) && (reg_val & MV_XLG_MAC_CTRL0_TXFCEN_MASK))
+		*fc = MV_PORT_FC_ENABLE;
+	else
+		*fc = MV_PORT_FC_DISABLE;
+}
+
+int mv_xlg_mac_port_link_speed_fc(int mac_num, enum mv_port_speed speed, int force_link_up)
+{
+	if (force_link_up) {
+		if (mv_xlg_mac_fc_set(mac_num, MV_PORT_FC_ENABLE)) {
+			pr_err("mv_xlg_mac_fc_set failed\n");
+			return -EPERM;
+		}
+		if (mv_xlg_mac_force_link_mode_set(mac_num, 1, 0)) {
+			pr_err("mv_xlg_mac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+	} else {
+		if (mv_xlg_mac_force_link_mode_set(mac_num, 0, 0)) {
+			pr_err("mv_xlg_mac_force_link_mode_set failed\n");
+			return -EPERM;
+		}
+		if (mv_xlg_mac_fc_set(mac_num, MV_PORT_FC_AN_SYM)) {
+			pr_err("mv_xlg_mac_fc_set failed\n");
+			return -EPERM;
+		}
+	}
+
+	return 0;
+}
+
+void mv_xlg_port_link_event_mask(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(mac_num));
+	reg_val &= ~(1 << 1);
+	mv_gop_reg_write(MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(mac_num), reg_val);
+}
+
+void mv_xlg_port_external_event_unmask(int mac_num, int bit_2_open)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(mac_num));
+	reg_val |= (1 << bit_2_open);
+	reg_val |= 1; /* unmask summary bit */
+	mv_gop_reg_write(MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(mac_num), reg_val);
+}
+
+void mv_xlg_port_link_event_clear(int mac_num)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_XLG_INTERRUPT_CAUSE_REG(mac_num));
+}
+
+void mv_xlg_2_gig_mac_cfg(int mac_num)
+{
+	u32 reg_val;
+
+	/* relevant only for MAC0 (XLG0 and GMAC0) */
+	if (mac_num > 0)
+		return;
+
+	/* configure 1Gig MAC mode */
+	reg_val = mv_gop_reg_read(MV_XLG_PORT_MAC_CTRL3_REG(mac_num));
+	MV_U32_SET_FIELD(reg_val, MV_XLG_MAC_CTRL3_MACMODESELECT_MASK,
+		(0 << MV_XLG_MAC_CTRL3_MACMODESELECT_OFFS));
+	mv_gop_reg_write(MV_XLG_PORT_MAC_CTRL3_REG(mac_num), reg_val);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.h b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.h
new file mode 100644
index 0000000..f54df31
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_if.h
@@ -0,0 +1,69 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_xlg_mac_if_h__
+#define __mv_xlg_mac_if_h__
+
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+
+
+/* print value of unit registers */
+void mv_xlg_mac_regs_dump(int port);
+/* Set the MAC to reset or exit from reset */
+int mv_xlg_mac_reset(int mac_num, enum mv_reset reset);
+/* Set the internal mux's to the required MAC in the GOP */
+int mv_xlg_mac_mode_cfg(int mac_num, int num_of_lanes);
+/* Configure MAC loopback */
+int mv_xlg_mac_loopback_cfg(int mac_num, enum mv_lb_type type);
+/* Get MAC link status */
+bool mv_xlg_mac_link_status_get(int mac_num);
+/* Enable port and MIB counters */
+void mv_xlg_mac_port_enable(int mac_num);
+/* Disable port */
+void mv_xlg_mac_port_disable(int mac_num);
+void mv_xlg_mac_port_periodic_xon_set(int mac_num, int enable);
+int mv_xlg_mac_link_status(int mac_num, struct mv_port_link_status *pstatus);
+/* Change maximum receive size of the port */
+int mv_xlg_mac_max_rx_size_set(int mac_num, int max_rx_size);
+int mv_xlg_mac_force_link_mode_set(int mac_num, bool force_link_up, bool force_link_down);
+int mv_xlg_mac_speed_duplex_set(int mac_num, enum mv_port_speed speed, enum mv_port_duplex duplex);
+/* Gets port speed and duplex */
+int mv_xlg_mac_speed_duplex_get(int mac_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex);
+/* Configure the port's Flow Control properties */
+int mv_xlg_mac_fc_set(int mac_num, enum mv_port_fc fc);
+/* Get Flow Control configuration of the port */
+void mv_xlg_mac_fc_get(int mac_num, enum mv_port_fc *fc);
+int mv_xlg_mac_port_link_speed_fc(int port, enum mv_port_speed speed, int force_link_up);
+/* Link Interrupt Handle */
+void mv_xlg_port_link_event_unmask(int mac_num);
+void mv_xlg_port_link_event_mask(int mac_num);
+void mv_xlg_port_external_event_unmask(int mac_num, int bit_2_open);
+void mv_xlg_port_link_event_clear(int mac_num);
+void mv_xlg_2_gig_mac_cfg(int mac_num);
+
+#endif /* __mv_xlg_mac_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_regs.h
new file mode 100644
index 0000000..0be5a99
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mac/mv_xlg_mac_regs.h
@@ -0,0 +1,580 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_xlg_mac_regs_h__
+#define __mv_xlg_mac_regs_h__
+
+/* includes */
+
+/* unit offset */
+#define MV_PP3_XLG_MAC_UNIT_OFFSET		0x030C0000
+
+
+/* Port Mac Control0 */
+#define MV_XLG_PORT_MAC_CTRL0_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0000 + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL0_PORTEN_OFFS		0
+#define MV_XLG_MAC_CTRL0_PORTEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_PORTEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_MACRESETN_OFFS		1
+#define MV_XLG_MAC_CTRL0_MACRESETN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_MACRESETN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_FORCELINKDOWN_OFFS		2
+#define MV_XLG_MAC_CTRL0_FORCELINKDOWN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_FORCELINKDOWN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_FORCELINKPASS_OFFS		3
+#define MV_XLG_MAC_CTRL0_FORCELINKPASS_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_FORCELINKPASS_OFFS)
+
+#define MV_XLG_MAC_CTRL0_TXIPGMODE_OFFS		5
+#define MV_XLG_MAC_CTRL0_TXIPGMODE_MASK    \
+		(0x00000003 << MV_XLG_MAC_CTRL0_TXIPGMODE_OFFS)
+
+#define MV_XLG_MAC_CTRL0_RXFCEN_OFFS		7
+#define MV_XLG_MAC_CTRL0_RXFCEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_RXFCEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_TXFCEN_OFFS		8
+#define MV_XLG_MAC_CTRL0_TXFCEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_TXFCEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_RXCRCCHECKEN_OFFS		9
+#define MV_XLG_MAC_CTRL0_RXCRCCHECKEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_RXCRCCHECKEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_PERIODICXONEN_OFFS		10
+#define MV_XLG_MAC_CTRL0_PERIODICXONEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_PERIODICXONEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_RXCRCSTRIPEN_OFFS		11
+#define MV_XLG_MAC_CTRL0_RXCRCSTRIPEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_RXCRCSTRIPEN_OFFS)
+
+#define MV_XLG_MAC_CTRL0_PADDINGDIS_OFFS		13
+#define MV_XLG_MAC_CTRL0_PADDINGDIS_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_PADDINGDIS_OFFS)
+
+#define MV_XLG_MAC_CTRL0_MIBCNTDIS_OFFS		14
+#define MV_XLG_MAC_CTRL0_MIBCNTDIS_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_MIBCNTDIS_OFFS)
+
+#define MV_XLG_MAC_CTRL0_PFC_CASCADE_PORT_ENABLE_OFFS		15
+#define MV_XLG_MAC_CTRL0_PFC_CASCADE_PORT_ENABLE_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL0_PFC_CASCADE_PORT_ENABLE_OFFS)
+
+
+/* Port Mac Control1 */
+#define MV_XLG_PORT_MAC_CTRL1_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0004 + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL1_FRAMESIZELIMIT_OFFS		0
+#define MV_XLG_MAC_CTRL1_FRAMESIZELIMIT_MASK    \
+		(0x00001fff << MV_XLG_MAC_CTRL1_FRAMESIZELIMIT_OFFS)
+
+#define MV_XLG_MAC_CTRL1_MACLOOPBACKEN_OFFS		13
+#define MV_XLG_MAC_CTRL1_MACLOOPBACKEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL1_MACLOOPBACKEN_OFFS)
+
+#define MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_OFFS		14
+#define MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL1_XGMIILOOPBACKEN_OFFS)
+
+#define MV_XLG_MAC_CTRL1_LOOPBACKCLOCKSELECT_OFFS		15
+#define MV_XLG_MAC_CTRL1_LOOPBACKCLOCKSELECT_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL1_LOOPBACKCLOCKSELECT_OFFS)
+
+
+/* Port Mac Control2 */
+#define MV_XLG_PORT_MAC_CTRL2_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0008 + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL2_SALOW_7_0_OFFS		0
+#define MV_XLG_MAC_CTRL2_SALOW_7_0_MASK    \
+		(0x000000ff << MV_XLG_MAC_CTRL2_SALOW_7_0_OFFS)
+
+#define MV_XLG_MAC_CTRL2_UNIDIRECTIONALEN_OFFS		8
+#define MV_XLG_MAC_CTRL2_UNIDIRECTIONALEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL2_UNIDIRECTIONALEN_OFFS)
+
+#define MV_XLG_MAC_CTRL2_FIXEDIPGBASE_OFFS		9
+#define MV_XLG_MAC_CTRL2_FIXEDIPGBASE_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL2_FIXEDIPGBASE_OFFS)
+
+#define MV_XLG_MAC_CTRL2_PERIODICXOFFEN_OFFS		10
+#define MV_XLG_MAC_CTRL2_PERIODICXOFFEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL2_PERIODICXOFFEN_OFFS)
+
+#define MV_XLG_MAC_CTRL2_SIMPLEXMODEEN_OFFS		13
+#define MV_XLG_MAC_CTRL2_SIMPLEXMODEEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL2_SIMPLEXMODEEN_OFFS)
+
+#define MV_XLG_MAC_CTRL2_FC_MODE_OFFS		14
+#define MV_XLG_MAC_CTRL2_FC_MODE_MASK    \
+		(0x00000003 << MV_XLG_MAC_CTRL2_FC_MODE_OFFS)
+
+
+/* Port Status */
+#define MV_XLG_MAC_PORT_STATUS_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x000c + (port) * 0x1000))
+#define MV_XLG_MAC_PORT_STATUS_LINKSTATUS_OFFS		0
+#define MV_XLG_MAC_PORT_STATUS_LINKSTATUS_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_LINKSTATUS_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_REMOTEFAULT_OFFS		1
+#define MV_XLG_MAC_PORT_STATUS_REMOTEFAULT_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_REMOTEFAULT_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_LOCALFAULT_OFFS		2
+#define MV_XLG_MAC_PORT_STATUS_LOCALFAULT_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_LOCALFAULT_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_LINKSTATUSCLEAN_OFFS		3
+#define MV_XLG_MAC_PORT_STATUS_LINKSTATUSCLEAN_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_LINKSTATUSCLEAN_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_LOCALFAULTCLEAN_OFFS		4
+#define MV_XLG_MAC_PORT_STATUS_LOCALFAULTCLEAN_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_LOCALFAULTCLEAN_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_REMOTEFAULTCLEAN_OFFS		5
+#define MV_XLG_MAC_PORT_STATUS_REMOTEFAULTCLEAN_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_REMOTEFAULTCLEAN_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_PORTRXPAUSE_OFFS		6
+#define MV_XLG_MAC_PORT_STATUS_PORTRXPAUSE_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_PORTRXPAUSE_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_PORTTXPAUSE_OFFS		7
+#define MV_XLG_MAC_PORT_STATUS_PORTTXPAUSE_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_PORTTXPAUSE_OFFS)
+
+#define MV_XLG_MAC_PORT_STATUS_PFC_SYNC_FIFO_FULL_OFFS		8
+#define MV_XLG_MAC_PORT_STATUS_PFC_SYNC_FIFO_FULL_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_STATUS_PFC_SYNC_FIFO_FULL_OFFS)
+
+
+/* Port Fifos Thresholds Configuration */
+#define MV_XLG_PORT_FIFOS_THRS_CFG_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0010 + (port) * 0x1000))
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_RXFULLTHR_OFFS		0
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_RXFULLTHR_MASK    \
+		(0x0000001f << MV_XLG_MAC_PORT_FIFOS_THRS_CFG_RXFULLTHR_OFFS)
+
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXFIFOSIZE_OFFS		5
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXFIFOSIZE_MASK    \
+		(0x0000003f << MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXFIFOSIZE_OFFS)
+
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXRDTHR_OFFS		11
+#define MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXRDTHR_MASK    \
+		(0x0000001f << MV_XLG_MAC_PORT_FIFOS_THRS_CFG_TXRDTHR_OFFS)
+
+
+/* Port Mac Control3 */
+#define MV_XLG_PORT_MAC_CTRL3_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x001c + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL3_BUFSIZE_OFFS		0
+#define MV_XLG_MAC_CTRL3_BUFSIZE_MASK    \
+		(0x0000003f << MV_XLG_MAC_CTRL3_BUFSIZE_OFFS)
+
+#define MV_XLG_MAC_CTRL3_XTRAIPG_OFFS		6
+#define MV_XLG_MAC_CTRL3_XTRAIPG_MASK    \
+		(0x0000007f << MV_XLG_MAC_CTRL3_XTRAIPG_OFFS)
+
+#define MV_XLG_MAC_CTRL3_MACMODESELECT_OFFS		13
+#define MV_XLG_MAC_CTRL3_MACMODESELECT_MASK    \
+		(0x00000007 << MV_XLG_MAC_CTRL3_MACMODESELECT_OFFS)
+
+
+/* Port Per Prio Flow Control Status */
+#define MV_XLG_PORT_PER_PRIO_FLOW_CTRL_STATUS_REG(port)      (MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0020 + (port) * 0x1000))
+#define MV_XLG_MAC_PORT_PER_PRIO_FLOW_CTRL_STATUS_PRIONSTATUS_OFFS		0
+#define MV_XLG_MAC_PORT_PER_PRIO_FLOW_CTRL_STATUS_PRIONSTATUS_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_PER_PRIO_FLOW_CTRL_STATUS_PRIONSTATUS_OFFS)
+
+
+/* Debug Bus Status */
+#define MV_XLG_DEBUG_BUS_STATUS_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0024 + (port) * 0x1000))
+#define MV_XLG_MAC_DEBUG_BUS_STATUS_DEBUG_BUS_OFFS		0
+#define MV_XLG_MAC_DEBUG_BUS_STATUS_DEBUG_BUS_MASK    \
+		(0x0000ffff << MV_XLG_MAC_DEBUG_BUS_STATUS_DEBUG_BUS_OFFS)
+
+
+/* Port Metal Fix */
+#define MV_XLG_PORT_METAL_FIX_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x002c + (port) * 0x1000))
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_EOP_IN_FIFO__OFFS		0
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_EOP_IN_FIFO__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_EOP_IN_FIFO__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_LTF_FIX__OFFS		1
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_LTF_FIX__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_LTF_FIX__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_HOLD_FIX__OFFS		2
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_HOLD_FIX__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_HOLD_FIX__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_LED_FIX__OFFS		3
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_LED_FIX__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_LED_FIX__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_PAD_PROTECT__OFFS		4
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_PAD_PROTECT__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_PAD_PROTECT__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS44__OFFS		5
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS44__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS44__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS42__OFFS		6
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS42__MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_NX_BTS42__OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_FLUSH_FIX_OFFS		7
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_FLUSH_FIX_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_FLUSH_FIX_OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_PORT_EN_FIX_OFFS		8
+#define MV_XLG_MAC_PORT_METAL_FIX_EN_PORT_EN_FIX_MASK    \
+		(0x00000001 << MV_XLG_MAC_PORT_METAL_FIX_EN_PORT_EN_FIX_OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF0_BITS_OFFS		9
+#define MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF0_BITS_MASK    \
+		(0x0000000f << MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF0_BITS_OFFS)
+
+#define MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF1_BITS_OFFS		13
+#define MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF1_BITS_MASK    \
+		(0x00000007 << MV_XLG_MAC_PORT_METAL_FIX_SPARE_DEF1_BITS_OFFS)
+
+
+/* Xg Mib Counters Control */
+#define MV_XLG_MIB_CNTRS_CTRL_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0030 + (port) * 0x1000))
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGCAPTURETRIGGER_OFFS		0
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGCAPTURETRIGGER_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGCAPTURETRIGGER_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGDONTCLEARAFTERREAD_OFFS		1
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGDONTCLEARAFTERREAD_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGDONTCLEARAFTERREAD_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGRXHISTOGRAMEN_OFFS		2
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGRXHISTOGRAMEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGRXHISTOGRAMEN_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGTXHISTOGRAMEN_OFFS		3
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGTXHISTOGRAMEN_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_XGTXHISTOGRAMEN_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__OFFS		4
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MFA1_BTT940_FIX_ENABLE__OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_LEDS_NUMBER_OFFS		5
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_LEDS_NUMBER_MASK    \
+		(0x0000003f << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_LEDS_NUMBER_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_OFFS		11
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_COUNT_HIST_OFFS)
+
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_OFFS		12
+#define MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_MASK    \
+		(0x00000001 << MV_XLG_MAC_XG_MIB_CNTRS_CTRL_MIB_4_LIMIT_1518_1522_OFFS)
+
+
+/* Cn/ccfc Timer%i */
+#define MV_XLG_CNCCFC_TIMERI_REG(port, t)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0038 + (port) * 0x1000 + t*4))
+#define MV_XLG_MAC_CNCCFC_TIMERI_PORTSPEEDTIMER_OFFS	0
+#define MV_XLG_MAC_CNCCFC_TIMERI_PORTSPEEDTIMER_MASK    \
+		(0x0000ffff << MV_XLG_MAC_CNCCFC_TIMERI_PORTSPEEDTIMER_OFFS)
+
+
+/* Ppfc Control */
+#define MV_XLG_MAC_PPFC_CTRL_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0060 + (port) * 0x1000))
+#define MV_XLG_MAC_PPFC_CTRL_GLOBAL_PAUSE_ENI_OFFS		0
+#define MV_XLG_MAC_PPFC_CTRL_GLOBAL_PAUSE_ENI_MASK    \
+		(0x00000001 << MV_XLG_MAC_PPFC_CTRL_GLOBAL_PAUSE_ENI_OFFS)
+
+#define MV_XLG_MAC_PPFC_CTRL_DIP_BTS_677_EN_OFFS		9
+#define MV_XLG_MAC_PPFC_CTRL_DIP_BTS_677_EN_MASK    \
+		(0x00000001 << MV_XLG_MAC_PPFC_CTRL_DIP_BTS_677_EN_OFFS)
+
+
+/* Fc Dsa Tag 0 */
+#define MV_XLG_MAC_FC_DSA_TAG_0_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0068 + (port) * 0x1000))
+#define MV_XLG_MAC_FC_DSA_TAG_0_DSATAGREG0_OFFS		0
+#define MV_XLG_MAC_FC_DSA_TAG_0_DSATAGREG0_MASK    \
+		(0x0000ffff << MV_XLG_MAC_FC_DSA_TAG_0_DSATAGREG0_OFFS)
+
+
+/* Fc Dsa Tag 1 */
+#define MV_XLG_MAC_FC_DSA_TAG_1_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x006c + (port) * 0x1000))
+#define MV_XLG_MAC_FC_DSA_TAG_1_DSATAGREG1_OFFS		0
+#define MV_XLG_MAC_FC_DSA_TAG_1_DSATAGREG1_MASK    \
+		(0x0000ffff << MV_XLG_MAC_FC_DSA_TAG_1_DSATAGREG1_OFFS)
+
+
+/* Fc Dsa Tag 2 */
+#define MV_XLG_MAC_FC_DSA_TAG_2_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0070 + (port) * 0x1000))
+#define MV_XLG_MAC_FC_DSA_TAG_2_DSATAGREG2_OFFS		0
+#define MV_XLG_MAC_FC_DSA_TAG_2_DSATAGREG2_MASK    \
+		(0x0000ffff << MV_XLG_MAC_FC_DSA_TAG_2_DSATAGREG2_OFFS)
+
+
+/* Fc Dsa Tag 3 */
+#define MV_XLG_MAC_FC_DSA_TAG_3_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0074 + (port) * 0x1000))
+#define MV_XLG_MAC_FC_DSA_TAG_3_DSATAGREG3_OFFS		0
+#define MV_XLG_MAC_FC_DSA_TAG_3_DSATAGREG3_MASK    \
+		(0x0000ffff << MV_XLG_MAC_FC_DSA_TAG_3_DSATAGREG3_OFFS)
+
+
+/* Dic Budget Compensation */
+#define MV_XLG_MAC_DIC_BUDGET_COMPENSATION_REG(port)	(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0080 + (port) * 0x1000))
+#define MV_XLG_MAC_DIC_BUDGET_COMPENSATION_DIC_COUNTER_TO_ADD_8BYTES_OFFS		0
+#define MV_XLG_MAC_DIC_BUDGET_COMPENSATION_DIC_COUNTER_TO_ADD_8BYTES_MASK    \
+		(0x0000ffff << MV_XLG_MAC_DIC_BUDGET_COMPENSATION_DIC_COUNTER_TO_ADD_8BYTES_OFFS)
+
+
+/* Port Mac Control4 */
+#define MV_XLG_PORT_MAC_CTRL4_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0084 + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL4_LLFC_GLOBAL_FC_ENABLE_OFFS		0
+#define MV_XLG_MAC_CTRL4_LLFC_GLOBAL_FC_ENABLE_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_LLFC_GLOBAL_FC_ENABLE_OFFS)
+
+#define MV_XLG_MAC_CTRL4_LED_STREAM_SELECT_OFFS		1
+#define MV_XLG_MAC_CTRL4_LED_STREAM_SELECT_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_LED_STREAM_SELECT_OFFS)
+
+#define MV_XLG_MAC_CTRL4_DEBUG_BUS_SELECT_OFFS		2
+#define MV_XLG_MAC_CTRL4_DEBUG_BUS_SELECT_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_DEBUG_BUS_SELECT_OFFS)
+
+#define MV_XLG_MAC_CTRL4_MASK_PCS_RESET_OFFS		3
+#define MV_XLG_MAC_CTRL4_MASK_PCS_RESET_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_MASK_PCS_RESET_OFFS)
+
+#define MV_XLG_MAC_CTRL4_ENABLE_SHORT_PREAMBLE_FOR_XLG_OFFS		4
+#define MV_XLG_MAC_CTRL4_ENABLE_SHORT_PREAMBLE_FOR_XLG_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_ENABLE_SHORT_PREAMBLE_FOR_XLG_OFFS)
+
+#define MV_XLG_MAC_CTRL4_FORWARD_802_3X_FC_EN_OFFS		5
+#define MV_XLG_MAC_CTRL4_FORWARD_802_3X_FC_EN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_FORWARD_802_3X_FC_EN_OFFS)
+
+#define MV_XLG_MAC_CTRL4_FORWARD_PFC_EN_OFFS		6
+#define MV_XLG_MAC_CTRL4_FORWARD_PFC_EN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_FORWARD_PFC_EN_OFFS)
+
+#define MV_XLG_MAC_CTRL4_FORWARD_UNKNOWN_FC_EN_OFFS		7
+#define MV_XLG_MAC_CTRL4_FORWARD_UNKNOWN_FC_EN_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_FORWARD_UNKNOWN_FC_EN_OFFS)
+
+#define MV_XLG_MAC_CTRL4_USE_XPCS_OFFS		8
+#define MV_XLG_MAC_CTRL4_USE_XPCS_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_USE_XPCS_OFFS)
+
+#define MV_XLG_MAC_CTRL4_DMA_INTERFACE_IS_64_BIT_OFFS		9
+#define MV_XLG_MAC_CTRL4_DMA_INTERFACE_IS_64_BIT_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_DMA_INTERFACE_IS_64_BIT_OFFS)
+
+#define MV_XLG_MAC_CTRL4_TX_DMA_INTERFACE_BITS_OFFS		10
+#define MV_XLG_MAC_CTRL4_TX_DMA_INTERFACE_BITS_MASK    \
+		(0x00000003 << MV_XLG_MAC_CTRL4_TX_DMA_INTERFACE_BITS_OFFS)
+
+#define MV_XLG_MAC_CTRL4_MAC_MODE_DMA_1G_OFFS		12
+#define MV_XLG_MAC_CTRL4_MAC_MODE_DMA_1G_MASK    \
+		(0x00000001 << MV_XLG_MAC_CTRL4_MAC_MODE_DMA_1G_OFFS)
+
+
+/* Port Mac Control5 */
+#define MV_XLG_PORT_MAC_CTRL5_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0088 + (port) * 0x1000))
+#define MV_XLG_MAC_CTRL5_TXIPGLENGTH_OFFS		0
+#define MV_XLG_MAC_CTRL5_TXIPGLENGTH_MASK    \
+		(0x0000000f << MV_XLG_MAC_CTRL5_TXIPGLENGTH_OFFS)
+
+#define MV_XLG_MAC_CTRL5_PREAMBLELENGTHTX_OFFS		4
+#define MV_XLG_MAC_CTRL5_PREAMBLELENGTHTX_MASK    \
+		(0x00000007 << MV_XLG_MAC_CTRL5_PREAMBLELENGTHTX_OFFS)
+
+#define MV_XLG_MAC_CTRL5_PREAMBLELENGTHRX_OFFS		7
+#define MV_XLG_MAC_CTRL5_PREAMBLELENGTHRX_MASK    \
+		(0x00000007 << MV_XLG_MAC_CTRL5_PREAMBLELENGTHRX_OFFS)
+
+#define MV_XLG_MAC_CTRL5_TXNUMCRCBYTES_OFFS		10
+#define MV_XLG_MAC_CTRL5_TXNUMCRCBYTES_MASK    \
+		(0x00000007 << MV_XLG_MAC_CTRL5_TXNUMCRCBYTES_OFFS)
+
+#define MV_XLG_MAC_CTRL5_RXNUMCRCBYTES_OFFS		13
+#define MV_XLG_MAC_CTRL5_RXNUMCRCBYTES_MASK    \
+		(0x00000007 << MV_XLG_MAC_CTRL5_RXNUMCRCBYTES_OFFS)
+
+
+/* External Control */
+#define MV_XLG_MAC_EXT_CTRL_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0090 + (port) * 0x1000))
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL0_OFFS		0
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL0_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL0_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL1_OFFS		1
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL1_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL1_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL2_OFFS		2
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL2_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL2_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL3_OFFS		3
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL3_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL3_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL4_OFFS		4
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL4_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL4_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL5_OFFS		5
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL5_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL5_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL6_OFFS		6
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL6_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL6_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL7_OFFS		7
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL7_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL7_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL8_OFFS		8
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL8_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL8_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL9_OFFS		9
+#define MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL9_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXTERNAL_CTRL9_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_10_OFFS		10
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_10_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_10_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_11_OFFS		11
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_11_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_11_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_12_OFFS		12
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_12_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_12_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_13_OFFS		13
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_13_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_13_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_14_OFFS		14
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_14_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_14_OFFS)
+
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_15_OFFS		15
+#define MV_XLG_MAC_EXT_CTRL_EXT_CTRL_15_MASK    \
+		(0x00000001 << MV_XLG_MAC_EXT_CTRL_EXT_CTRL_15_OFFS)
+
+
+/* Macro Control */
+#define MV_XLG_MAC_MACRO_CTRL_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0094 + (port) * 0x1000))
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_0_OFFS		0
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_0_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_0_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_1_OFFS		1
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_1_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_1_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_2_OFFS		2
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_2_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_2_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_3_OFFS		3
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_3_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_3_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_4_OFFS		4
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_4_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_4_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_5_OFFS		5
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_5_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_5_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_6_OFFS		6
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_6_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_6_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_7_OFFS		7
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_7_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_7_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_8_OFFS		8
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_8_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_8_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_9_OFFS		9
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_9_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_9_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_10_OFFS		10
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_10_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_10_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_11_OFFS		11
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_11_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_11_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_12_OFFS		12
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_12_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_12_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_13_OFFS		13
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_13_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_13_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_14_OFFS		14
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_14_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_14_OFFS)
+
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_15_OFFS		15
+#define MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_15_MASK    \
+		(0x00000001 << MV_XLG_MAC_MACRO_CTRL_MACRO_CTRL_15_OFFS)
+
+#define MV_XLG_MAC_DIC_PPM_IPG_REDUCE_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0094 + (port) * 0x1000))
+
+/* Port Interrupt Cause */
+#define MV_XLG_INTERRUPT_CAUSE_REG(port)		(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0014 + (port) * 0x1000))
+/* Port Interrupt Mask */
+#define MV_XLG_INTERRUPT_MASK_REG(port)			(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0018 + (port) * 0x1000))
+#define MV_XLG_INTERRUPT_LINK_CHANGE_OFFS		1
+#define MV_XLG_INTERRUPT_LINK_CHANGE_MASK		(0x1 << MV_XLG_INTERRUPT_LINK_CHANGE_OFFS)
+
+/* Port Interrupt Summary Cause */
+#define MV_XLG_EXTERNAL_INTERRUPT_CAUSE_REG(port)	(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x0058 + (port) * 0x1000))
+/* Port Interrupt Summary Mask */
+#define MV_XLG_EXTERNAL_INTERRUPT_MASK_REG(port)	(MV_PP3_XLG_MAC_UNIT_OFFSET + (0x005C + (port) * 0x1000))
+#define MV_XLG_EXTERNAL_INTERRUPT_LINK_CHANGE_OFFS	1
+#define MV_XLG_EXTERNAL_INTERRUPT_LINK_CHANGE_MASK	(0x1 << MV_XLG_EXTERNAL_INTERRUPT_LINK_CHANGE_OFFS)
+
+
+#endif /* __mv_xlg_mac_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.c b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.c
new file mode 100644
index 0000000..a8b2925
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.c
@@ -0,0 +1,703 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "gop/a390_mg_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mac/mv_gmac_if.h"
+#include "gop/mac/mv_xlg_mac_if.h"
+#include "gop/pcs/mv_gpcs_if.h"
+#include "gop/pcs/mv_xpcs_if.h"
+#include "gop/serdes/mv_serdes_if.h"
+
+
+struct mv_io_addr *gop_regs_addrs_size;
+static void __iomem		*gop_vbase_address;
+static enum mv_gop_access_mode	gop_access_mode;
+static struct gop_port_ctrl	*gop_ports;
+static int			gop_ports_num;
+
+void mv_gop_init(struct mv_io_addr *gop_regs, int ports_num, enum mv_gop_access_mode mode)
+{
+	int i;
+
+	gop_ports = kzalloc(sizeof(struct gop_port_ctrl) * ports_num, GFP_KERNEL);
+	if (gop_ports == NULL) {
+		pr_err("%s: Can't allocated %d bytes of memory\n",
+				__func__, sizeof(struct gop_port_ctrl) * ports_num);
+		return;
+	}
+	gop_regs_addrs_size = gop_regs;
+	gop_ports_num = ports_num;
+	gop_access_mode = mode;
+	gop_vbase_address = gop_regs->vaddr;
+	if (mode == INDIRECT_MG_ACCESS)
+		a390_addr_completion_init(gop_vbase_address);
+
+	for (i = 0; i < ports_num; i++)
+		gop_ports[i].flags = (1 << NOT_CREATED);
+}
+
+int mv_gop_addrs_size_get(u32 *va_base, u32 *pa_base, u32 *size)
+{
+	*va_base = (u32)gop_regs_addrs_size->vaddr;
+	*pa_base = (u32)gop_regs_addrs_size->paddr;
+	*size = (u32)gop_regs_addrs_size->size;
+	if (gop_access_mode != INDIRECT_MG_ACCESS)
+		return -1; /* gop-base is valid for indirect only */
+	return 0;
+}
+
+/* return read register value */
+u32 mv_gop_reg_read(u32 reg_addr)
+{
+	u32 access_addr;
+
+	if (gop_access_mode == INDIRECT_MG_ACCESS)
+		access_addr = a390_addr_completion_cfg(reg_addr);
+	else
+		access_addr = reg_addr;
+
+	return readl((void *)(access_addr + gop_vbase_address));
+}
+
+/* write data to register */
+void mv_gop_reg_write(u32 reg_addr, u32 data)
+{
+	u32 access_addr;
+
+	if (gop_access_mode == INDIRECT_MG_ACCESS)
+		access_addr = a390_addr_completion_cfg(reg_addr);
+	else
+		access_addr = reg_addr;
+#ifdef PP3_DEBUG
+	pr_info("\nwrite reg 0x%x, data 0x%x", reg_addr, data);
+#endif
+	writel(data, (void *)(access_addr + gop_vbase_address));
+}
+
+void mv_gop_reg_print(char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg, mv_gop_reg_read(reg));
+}
+
+/*******************************************************************************
+* mv_port_init
+*
+* DESCRIPTION:
+*       Init physical port. Configures the port mode and all it's elements
+*       accordingly.
+*       Does not verify that the selected mode/port number is valid at the
+*       core level.
+*
+* INPUTS:
+*       port_num    - physical port number
+*       port_mode   - port standard metric
+*
+* OUTPUTS:
+*       None.
+*
+* RETURNS:
+*       0  - on success
+*       1  - on error
+*
+*******************************************************************************/
+int mv_pp3_gop_port_init(int port_num, enum mv_port_mode port_mode)
+{
+	int num_of_act_lanes;
+	int mac_num;
+
+	if (port_num >= gop_ports_num) {
+		pr_err("%s: illegal port number %d", __func__, port_num);
+		return -1;
+	}
+
+	switch (port_mode) {
+	case MV_PORT_RGMII:
+		mac_num = port_num;
+		mv_gmac_reset(mac_num, RESET);
+		/* configure PCS */
+		mv_gpcs_mode_cfg(mac_num, false);
+
+		/* configure MAC */
+		mv_gmac_mode_cfg(mac_num, port_mode);
+		/* pcs unreset */
+		mv_gpcs_reset(port_num, UNRESET);
+		/* mac unreset */
+		mv_gmac_reset(mac_num, UNRESET);
+	break;
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		num_of_act_lanes = 1;
+		mac_num = port_num;
+		/* configure PCS */
+		mv_gpcs_mode_cfg(mac_num, true);
+
+		/* configure MAC */
+		mv_gmac_mode_cfg(mac_num, port_mode);
+		/* select proper Mac mode */
+		mv_xlg_2_gig_mac_cfg(mac_num);
+
+		/* pcs unreset */
+		mv_gpcs_reset(port_num, UNRESET);
+		/* mac unreset */
+		mv_gmac_reset(mac_num, UNRESET);
+	break;
+	case MV_PORT_XAUI:
+		num_of_act_lanes = 4;
+		mac_num = 0;
+		/* configure PCS */
+		mv_xpcs_mode(num_of_act_lanes);
+		/* configure MAC */
+		mv_xlg_mac_mode_cfg(mac_num, num_of_act_lanes);
+
+		/* pcs unreset */
+		mv_xpcs_reset(UNRESET);
+		/* mac unreset */
+		mv_xlg_mac_reset(mac_num, UNRESET);
+	break;
+	case MV_PORT_RXAUI:
+		num_of_act_lanes = 2;
+		mv_serdes_init(0, MV_RXAUI); /* mapped to serdes 6 */
+		mv_serdes_init(1, MV_RXAUI); /* mapped to serdes 5 */
+
+		mac_num = 0;
+		/* configure PCS */
+		mv_xpcs_mode(num_of_act_lanes);
+		/* configure MAC */
+		mv_xlg_mac_mode_cfg(mac_num, num_of_act_lanes);
+
+		/* pcs unreset */
+		mv_xpcs_reset(UNRESET);
+
+		/* mac unreset */;
+		mv_xlg_mac_reset(mac_num, UNRESET);
+	break;
+	default:
+		pr_err("%s: Requested port mode (%d) not supported", __func__, port_mode);
+		return -1;
+	}
+
+	gop_ports[port_num].port_mode = port_mode;
+	gop_ports[port_num].flags = (1 << CREATED);
+
+	return 0;
+}
+
+static inline int mv_pp3_check_gop_port_num(const char *msg, int port_num)
+{
+	int rc = 0;
+
+	if (port_num >= gop_ports_num) {
+		pr_err("%s: illegal port #%d", msg, port_num);
+		rc = -1;
+	}
+
+	if (gop_ports[port_num].flags & (1 << NOT_CREATED)) {
+		pr_err("%s: no port mode defined on port #%d\n", msg, port_num);
+		rc = -1;
+	}
+
+	return rc;
+}
+
+/*******************************************************************************
+* mv_port_reset
+*
+* DESCRIPTION:
+*       Clears the port mode and release all its resources according to selected.
+*       Does not verify that the selected mode/port number is valid at the core
+*       level and actual terminated mode.
+*
+* INPUTS:
+*       port_num   - physical port number
+*       port_mode  - port standard metric
+*       action     - Power down or reset
+*
+* OUTPUTS:
+*       None.
+*
+* RETURNS:
+*       0  - on success
+*       1  - on error
+*
+*******************************************************************************/
+int mv_pp3_gop_port_reset(int port_num)
+{
+	int mac_num;
+
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mac_num = port_num;
+		/* pcs unreset */
+		mv_gpcs_reset(port_num, RESET);
+		/* mac unreset */
+		mv_gmac_reset(mac_num, RESET);
+	break;
+	case MV_PORT_XAUI:
+		mac_num = 0;
+		/* pcs unreset */
+		mv_xpcs_reset(RESET);
+		/* mac unreset */
+		mv_xlg_mac_reset(mac_num, RESET);
+	break;
+	case MV_PORT_RXAUI:
+		mac_num = 0;
+		/* pcs unreset */
+		mv_xpcs_reset(RESET);
+		/* mac unreset */
+		mv_xlg_mac_reset(mac_num, RESET);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+
+	gop_ports[port_num].flags |= (1 << UNDER_RESET);
+
+	/* TBD:serdes reset or power down if needed*/
+
+	return 0;
+}
+
+/*-------------------------------------------------------------------*/
+void mv_pp3_gop_port_enable(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_enable(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		/* run digital reset / unreset */
+		mv_serdes_reset(0, false, false, true);
+		mv_serdes_reset(1, false, false, true);
+		mv_serdes_reset(0, false, false, false);
+		mv_serdes_reset(1, false, false, false);
+		mv_xlg_mac_port_enable(port_num);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return;
+	}
+
+	gop_ports[port_num].flags |= (1 << ENABLED);
+}
+
+void mv_pp3_gop_port_disable(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_disable(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_mac_port_disable(0);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return;
+	}
+
+	gop_ports[port_num].flags &= ~(1 << ENABLED);
+}
+
+void mv_pp3_gop_port_periodic_xon_set(int port_num, int enable)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_periodic_xon_set(port_num, enable);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_mac_port_periodic_xon_set(port_num, enable);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return;
+	}
+}
+
+bool mv_pp3_gop_port_is_link_up(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return false;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		return mv_gmac_link_status_get(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		udelay(1000);
+		return mv_xlg_mac_link_status_get(port_num);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return false;
+	}
+}
+
+int mv_pp3_gop_port_link_status(int port_num, struct mv_port_link_status *pstatus)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_QSGMII:
+		mv_gmac_link_status(port_num, pstatus);
+	break;
+	case MV_PORT_SGMII2_5:
+		mv_gmac_link_status(port_num, pstatus);
+		if (pstatus->speed == MV_PORT_SPEED_1000)
+			pstatus->speed = MV_PORT_SPEED_2000;
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_mac_link_status(port_num, pstatus);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_port_regs(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		pr_info("\n[gop GMAC #%d registers]\n", port_num);
+		mv_gmac_regs_dump(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		pr_info("\n[gop XLG MAC #%d registers]\n", port_num);
+		mv_xlg_mac_regs_dump(port_num);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_port_events_mask(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_link_event_mask(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_port_link_event_mask(port_num);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_port_events_unmask(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_link_event_unmask(port_num);
+		/* gige interrupt cause connected to CPU via XLG external interrupt cause */
+		mv_xlg_port_external_event_unmask(0, 2);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_port_external_event_unmask(port_num, 1);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_port_events_clear(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_link_event_clear(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_port_link_event_clear(port_num);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_status_show(int port_num)
+{
+	struct mv_port_link_status port_status;
+	bool port_en;
+
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	mv_pp3_gop_port_link_status(port_num, &port_status);
+	port_en = (gop_ports[port_num].flags & (1 << ENABLED)) ? true : false;
+
+	pr_info("-------------- Port %d configuration ----------------", port_num);
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+		pr_info("Port mode               : RGMII");
+	break;
+	case MV_PORT_SGMII:
+		pr_info("Port mode               : SGMII");
+	break;
+	case MV_PORT_SGMII2_5:
+		pr_info("Port mode               : SGMII2_5");
+	break;
+	case MV_PORT_QSGMII:
+		pr_info("Port mode               : QSGMII");
+	break;
+	case MV_PORT_XAUI:
+		pr_info("Port mode               : XAUI");
+	break;
+	case MV_PORT_RXAUI:
+		pr_info("Port mode               : RXAUI");
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	pr_info("\nMAC status              : %s", (port_en) ? "enable" : "disable");
+	pr_info("\nLink status             : %s", (port_status.linkup) ? "link up" : "link down");
+	pr_info("\n");
+
+	if ((gop_ports[port_num].port_mode == MV_PORT_SGMII2_5) && (port_status.speed == MV_PORT_SPEED_1000))
+		port_status.speed = MV_PORT_SPEED_2000;
+
+	switch (port_status.speed) {
+	case MV_PORT_SPEED_AN:
+		pr_info("Port speed              : AutoNeg");
+	break;
+	case MV_PORT_SPEED_10:
+		pr_info("Port speed              : 10M");
+	break;
+	case MV_PORT_SPEED_100:
+		pr_info("Port speed              : 100M");
+	break;
+	case MV_PORT_SPEED_1000:
+		pr_info("Port speed              : 1G");
+	break;
+	case MV_PORT_SPEED_2000:
+		pr_info("Port speed              : 2.5G");
+	break;
+	case MV_PORT_SPEED_10000:
+		pr_info("Port speed              : 10G");
+	break;
+	default:
+		pr_err("%s: Wrong port speed (%d)\n", __func__, port_status.speed);
+		return -1;
+	}
+	pr_info("\n");
+	switch (port_status.duplex) {
+	case MV_PORT_DUPLEX_AN:
+		pr_info("Port duplex             : AutoNeg");
+	break;
+	case MV_PORT_DUPLEX_HALF:
+		pr_info("Port duplex             : half");
+	break;
+	case MV_PORT_DUPLEX_FULL:
+		pr_info("Port duplex             : full");
+	break;
+	default:
+		pr_err("%s: Wrong port duplex (%d)", __func__, port_status.duplex);
+		return -1;
+	}
+	pr_info("\n");
+
+	return 0;
+}
+
+/* get port speed and duplex */
+int mv_pp3_gop_speed_duplex_get(int port_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_speed_duplex_get(port_num, speed, duplex);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_mac_speed_duplex_get(port_num, speed, duplex);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+/* set port speed and duplex */
+int mv_pp3_gop_speed_duplex_set(int port_num, enum mv_port_speed speed, enum mv_port_duplex duplex)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_speed_duplex_set(port_num, speed, duplex);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		mv_xlg_mac_speed_duplex_set(port_num, speed, duplex);
+	break;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_autoneg_restart(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	break;
+	case MV_PORT_SGMII:
+	case MV_PORT_SGMII2_5:
+	case MV_PORT_QSGMII:
+		mv_gmac_port_autoneg_restart(port_num);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		pr_err("%s: on supported for port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
+int mv_pp3_gop_fl_cfg(int port_num)
+{
+	if (mv_pp3_check_gop_port_num(__func__, port_num))
+		return -1;
+
+	switch (gop_ports[port_num].port_mode) {
+	case MV_PORT_RGMII:
+	case MV_PORT_SGMII:
+	case MV_PORT_QSGMII:
+		/* disable AN */
+		mv_pp3_gop_speed_duplex_set(port_num, MV_PORT_SPEED_1000, MV_PORT_DUPLEX_FULL);
+		/* force link */
+		mv_gmac_force_link_mode_set(port_num, true, false);
+	break;
+	case MV_PORT_SGMII2_5:
+		/* disable AN */
+		mv_pp3_gop_speed_duplex_set(port_num, MV_PORT_SPEED_2000, MV_PORT_DUPLEX_FULL);
+		/* force link */
+		mv_gmac_force_link_mode_set(port_num, true, false);
+	break;
+	case MV_PORT_XAUI:
+	case MV_PORT_RXAUI:
+		return 0;
+	default:
+		pr_err("%s: Wrong port mode (%d)", __func__, gop_ports[port_num].port_mode);
+		return -1;
+	}
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.h b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.h
new file mode 100644
index 0000000..eee8bc7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_if.h
@@ -0,0 +1,106 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gop_if_h__
+#define __mv_gop_if_h__
+
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include "common/mv_sw_if.h"
+
+
+/* pp3_gop_ctrl flags */
+#define mv_gop_F_DEBUG_BIT		0
+#define mv_gop_F_ATTACH_BIT		1
+
+#define mv_gop_F_DEBUG		(1 << mv_gop_F_DEBUG_BIT)
+#define mv_gop_F_ATTACH		(1 << mv_gop_F_ATTACH_BIT)
+
+enum gop_port_flags {NOT_CREATED, CREATED, UNDER_RESET, ENABLED};
+enum mv_gop_access_mode {DIRECT_ACCESS, INDIRECT_MG_ACCESS};
+
+struct gop_port_ctrl {
+	enum mv_port_mode port_mode;
+	u32  flags;
+};
+
+/* gop access init */
+void mv_gop_init(struct mv_io_addr *gop_regs, int ports_num, enum mv_gop_access_mode mode);
+int mv_gop_addrs_size_get(u32 *va_base, u32 *pa_base, u32 *size);
+
+/* port configuration function */
+int  mv_pp3_gop_port_init(int port_num, enum mv_port_mode port_mode);
+int  mv_pp3_gop_port_reset(int port_num);
+void mv_pp3_gop_port_enable(int port_num);
+void mv_pp3_gop_port_disable(int port_num);
+void mv_pp3_gop_port_periodic_xon_set(int port_num, int enable);
+void mv_pp3_gop_port_lb_set(int port_num, int is_gmii, int is_pcs_en);
+bool mv_pp3_gop_port_is_link_up(int port_num);
+int  mv_pp3_gop_port_link_status(int port_num, struct mv_port_link_status *pstatus);
+
+/* get port speed and duplex */
+int mv_pp3_gop_speed_duplex_get(int port_num, enum mv_port_speed *speed, enum mv_port_duplex *duplex);
+/* set port speed and duplex */
+int mv_pp3_gop_speed_duplex_set(int port_num, enum mv_port_speed speed, enum mv_port_duplex duplex);
+int mv_pp3_gop_autoneg_restart(int port_num);
+int mv_pp3_gop_fl_cfg(int port_num);
+
+/* sysfs functions */
+int mv_pp3_gop_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_gop_sysfs_exit(struct kobject *pp3_kobj);
+int mv_pp3_gop_port_regs(int port_num);
+int mv_pp3_gop_status_show(int port_num);
+
+/* interrupt processing */
+int mv_pp3_gop_port_events_unmask(int port_num);
+int mv_pp3_gop_port_events_mask(int port_num);
+int mv_pp3_gop_port_events_clear(int port_num);
+
+/******************************************************************************/
+/*                      GOP register acceess Functions                        */
+/******************************************************************************/
+u32  mv_gop_reg_read(u32 reg_addr);
+void mv_gop_reg_write(u32 reg_addr, u32 data);
+void mv_gop_reg_print(char *reg_name, u32 reg);
+
+void mv_gop_isr_summary_mask(int port);
+void mv_gop_isr_summary_unmask(int port);
+u32 mv_gop_isr_summary_cause_get(int port);
+u32 mv_gop_port_isr_cause_get(int port);
+void mv_gop_port_isr_mask(int port);
+void mv_gop_port_isr_unmask(int port);
+void mv_gop_port_sum_isr_mask(int port);
+void mv_gop_port_sum_isr_unmask(int port);
+
+/******************************************************************************/
+/*                         MIB Counters Functions                             */
+/******************************************************************************/
+u32 mv_pp3_gop_mib_counter_get(int port, u32 offset, u32 *p_high_32);
+void mv_pp3_gop_mib_counters_clear(int port);
+void mv_pp3_gop_mib_counters_show(int port);
+
+#endif /* __mv_gop_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_gop_sysfs.c b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_sysfs.c
new file mode 100644
index 0000000..0667f56
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_gop_sysfs.c
@@ -0,0 +1,402 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_if.h"
+#include "gop/mv_tai_regs.h"
+#include "gop/pcs/mv_xpcs_if.h"
+#include "gop/serdes/mv_serdes_if.h"
+#ifdef CONFIG_ARCH_MVEBU
+#include "net_complex/mv_net_complex_a39x.h"
+#include "gop/mac/mv_xlg_mac_if.h"
+#endif
+
+static ssize_t mv_gop_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cd                     ptp         - go to PTP and TAI units configuration sub directory\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]             > status      - show GOP port configuration\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]             > regs        - show GOP port registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [lane]          > xpcs_regs   - show XPCS lane registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [lane]          > serdes_regs - show Serdes lane registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]             > mib_cntrs   - show port MIB counters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]             > clear_cntrs - clear port MIB counters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [u] [v]         > reg_write   - write register: address [u], value [v]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [u]             > reg_read    - read register: address [u]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [u] [s:e] [v]   > reg_modify  - read, modify, write gop register\n");
+#ifdef CONFIG_ARCH_MVEBU
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [mode]      > port_mode   - change mode of lanes 6,5 connected to port [p]\n");
+#endif
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [p]	- mac number\n");
+#ifdef CONFIG_ARCH_MVEBU
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mode]	- rxaui:    switch to RXAUI\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "		- sgmii:    switch to SGMII\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "		- sgmii2_5: switch to SGMII 2.5\n");
+#endif
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_gop_ptp_help(char *b)
+{
+	int o = 0;
+	/* NOTE: the sysfs-show limited with PAGE_SIZE. Current help-size is about 1.28kB */
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat              tai_regs  - show TAI unit registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat              tai_tod   - show TAI time capture values\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]       > ptp_regs  - show PTP unit registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p] [0/1] > ptp_en    - enable(1) / disable(0) PTP unit\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [p]       > ptp_reset - reset given port PTP unit\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     [p] - mac (port) number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "----\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [h] [l] [n] > tai_tod_load_value  - set TAI TOD with DECimal\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "         [h] hig16bit sec, [l] low32bit sec, [n] - nanosec\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "--- TAI TOD operationS (HEX parameters)---\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [o] [h] [l] [n] > tai_op\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "         [h] high sec, [l] low sec, [n] nanosec (HEX)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     [o] OPeration (HEX all parameters)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "   ToD time:      [h]=0 must be present\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     1c -increment[l+n], 1c0 -graceful inc[l+n]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     dc -decrement[l+n], 1d0 -graceful dec[l+n]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "   FREQ:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     F1c / Fdc - inc/dec by value [h]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "   SYNC ToD time from/to linux or Sys/kernel:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     41 - from linux, 21 - to linux\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     45 - from Sys/kernel, 47,46 -print ToD and System time\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "   Tai-Clock cfg:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     CE1 - Clock External Increment [h] seconds\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     CED - Clock External Decrement [h] seconds\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     CEA - Clock External Absolute set [h] seconds\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     CEC - Clock External Check stability & counter\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     C1  - Clock Internal (free-running)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     C0  - Clock Off\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     CEB11 - Blink led on gpio=11\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "   DEBUG:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "     deb h l n  - DEBug-op with up to 3 parameters\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_gop_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		off = mv_gop_help(buf);
+	else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t mv_gop_ptp_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help_ptp"))
+		off = mv_gop_ptp_help(buf);
+	else if (!strcmp(name, "tai_regs"))
+		mv_pp3_tai_reg_dump();
+	else if (!strcmp(name, "tai_tod"))
+		mv_pp3_tai_tod_dump();
+	else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t mv_gop_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, u, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "reg_modify")) {
+		u32	ret;
+		u32 start_bit, end_bit, mask;
+
+		ret = sscanf(buf, "%x %d:%d %x", &p, &start_bit, &end_bit, &u);
+
+		if ((end_bit < start_bit) || ((end_bit - start_bit + 1) > 32))
+			return -EINVAL;
+
+		if ((end_bit - start_bit + 1) == 32)
+			mask = 0xFFFFFFFF;
+		else
+			mask = (1 << (end_bit - start_bit + 1)) - 1;
+
+		local_irq_save(flags);
+
+		v = mv_gop_reg_read(p);
+		MV_U32_SET_FIELD(v, (mask << start_bit), ((u & mask) << start_bit));
+		mv_gop_reg_write(p, v);
+
+		local_irq_restore(flags);
+		return len;
+	}
+
+	/* TAI TOD commands: tai_tod_load_value, tai_op */
+	if (!strcmp(name, "tai_tod_load_value")) {
+		u32	ret;
+		u32 h, l, n;
+
+		n = 0;
+		ret = sscanf(buf, "%d %d %d", &h, &l, &n);
+		if (ret < 2)
+			return -EINVAL;
+		/* Case (!op & !h && !l && !n) is valid to set TAI-TOD ZERO */
+		local_irq_save(flags);
+		mv_pp3_tai_tod_load_set(h, l, n, 0);
+		local_irq_restore(flags);
+		return len;
+	}
+	if (!strcmp(name, "tai_op")) {
+		u32	ret;
+		u32 h, l, n, op;
+
+		h = l = n = 0;
+		ret = sscanf(buf, "%x %x %x %x", &op, &h, &l, &n);
+		if (ret < 1)
+			return -EINVAL;
+		if (!op)
+			return -EINVAL; /* likely wrong OP */
+		local_irq_save(flags);
+		mv_pp3_tai_tod_load_set(h, l, n, op);
+		local_irq_restore(flags);
+		return len;
+	}
+
+#ifdef CONFIG_ARCH_MVEBU
+	if (!strcmp(name, "port_mode")) {
+		char	str_mode[10];
+		u32	lane_mode; /* mode for SERDES 6, 5 */
+		u32	ret;
+		int	mac_num;
+		enum mv_port_mode mode;
+
+		ret = sscanf(buf, "%d %9s", &mac_num, str_mode);
+		if (ret != 2)
+			return -EINVAL;
+
+		local_irq_save(flags);
+
+		if (!strcmp(str_mode, "rxaui")) {
+			pr_info("\nSwitch to RXAUI\n");
+			mode = MV_PORT_RXAUI;
+			lane_mode = MV_NETCOMP_GE_MAC0_2_RXAUI;
+		} else {
+			if (mac_num == 0)
+				lane_mode = MV_NETCOMP_GE_MAC0_2_SGMII_L6;
+			else if (mac_num == 3)
+				lane_mode = MV_NETCOMP_GE_MAC3_2_SGMII_L6;
+			else
+				return -EINVAL;
+
+			if (!strcmp(str_mode, "sgmii")) {
+				pr_info("\nSwitch to SGMII\n");
+				mode = MV_PORT_SGMII;
+			} else if (!strcmp(str_mode, "sgmii2_5")) {
+				pr_info("\nSwitch to SGMII 2.5G\n");
+				mode = MV_PORT_SGMII2_5;
+			} else
+				return -EINVAL;
+		}
+
+		mv_pp3_gop_port_reset(mac_num);
+		mv_net_complex_dynamic_init(lane_mode);
+		mv_pp3_gop_port_init(mac_num, mode);
+
+		local_irq_restore(flags);
+		return len;
+	}
+#endif /* CONFIG_ARCH_MVEBU */
+
+	/* Read port and value */
+	err = p = u = v = 0;
+	sscanf(buf, "%x %x %x", &p, &u, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "regs"))
+		mv_pp3_gop_port_regs(p);
+	else if (!strcmp(name, "status"))
+		mv_pp3_gop_status_show(p);
+	else if (!strcmp(name, "mib_cntrs"))
+		mv_pp3_gop_mib_counters_show(p);
+	else if (!strcmp(name, "clear_cntrs"))
+		mv_pp3_gop_mib_counters_clear(p);
+	else if (!strcmp(name, "ptp_en"))
+		mv_pp3_ptp_enable(p, (u) ? true : false);
+	else if (!strcmp(name, "ptp_reset"))
+		mv_pp3_ptp_reset(p);
+	else if (!strcmp(name, "ptp_regs"))
+		mv_pp3_ptp_reg_dump(p);
+	else if (!strcmp(name, "xpcs_regs")) {
+		mv_xpcs_gl_regs_dump();
+		mv_xpcs_lane_regs_dump(p);
+	} else if (!strcmp(name, "serdes_regs"))
+		mv_serdes_lane_regs_dump(p);
+	else if (!strcmp(name, "reg_write"))
+		mv_gop_reg_write(p, u);
+	else if (!strcmp(name, "reg_read")) {
+		v = mv_gop_reg_read(p);
+		pr_info("0x%x = 0x%x\n", p, v);
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, mv_gop_show, NULL);
+static DEVICE_ATTR(regs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(xpcs_regs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(serdes_regs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(reg_write,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(reg_read,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(reg_modify,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(status,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(mib_cntrs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(clear_cntrs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+#ifdef CONFIG_ARCH_MVEBU
+static DEVICE_ATTR(port_mode,	S_IWUSR, NULL, mv_gop_3_hex_store);
+#endif
+
+static struct attribute *mv_gop_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_serdes_regs.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_xpcs_regs.attr,
+	&dev_attr_reg_write.attr,
+	&dev_attr_reg_modify.attr,
+	&dev_attr_reg_read.attr,
+	&dev_attr_status.attr,
+	&dev_attr_mib_cntrs.attr,
+	&dev_attr_clear_cntrs.attr,
+#ifdef CONFIG_ARCH_MVEBU
+	&dev_attr_port_mode.attr,
+#endif
+	NULL
+};
+
+static DEVICE_ATTR(help_ptp,		S_IRUSR, mv_gop_ptp_show, NULL);
+static DEVICE_ATTR(tai_regs,		S_IRUSR, mv_gop_ptp_show, NULL);
+static DEVICE_ATTR(tai_tod,		S_IRUSR, mv_gop_ptp_show, NULL);
+static DEVICE_ATTR(tai_tod_load_value,	S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(tai_op,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(ptp_regs,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(ptp_en,		S_IWUSR, NULL, mv_gop_3_hex_store);
+static DEVICE_ATTR(ptp_reset,		S_IWUSR, NULL, mv_gop_3_hex_store);
+
+static struct attribute *mv_gop_ptp_attrs[] = {
+	&dev_attr_help_ptp.attr,
+	&dev_attr_tai_regs.attr,
+	&dev_attr_tai_tod.attr,
+	&dev_attr_tai_tod_load_value.attr,
+	&dev_attr_tai_op.attr,
+	&dev_attr_ptp_regs.attr,
+	&dev_attr_ptp_en.attr,
+	&dev_attr_ptp_reset.attr,
+	NULL
+};
+
+static struct attribute_group mv_gop_group = {
+	.attrs = mv_gop_attrs,
+};
+
+static struct attribute_group mv_gop_ptp_group = {
+	.name = "ptp",
+	.attrs = mv_gop_ptp_attrs,
+};
+
+
+int mv_pp3_gop_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+	struct kobject *dev_kobj;
+
+	dev_kobj = kobject_create_and_add("gop", pp3_kobj);
+	if (!dev_kobj) {
+		pr_err("%s: cannot create gop kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(dev_kobj, &mv_gop_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", mv_gop_group.name, err);
+		return err;
+	}
+	err = sysfs_create_group(dev_kobj, &mv_gop_ptp_group);
+	if (err) {
+		pr_err("sysfs group failed for dev debug%d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_gop_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &mv_gop_group);
+
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_mib_cntrs.c b/drivers/net/ethernet/marvell/pp3/gop/mv_mib_cntrs.c
new file mode 100644
index 0000000..01640bf
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_mib_cntrs.c
@@ -0,0 +1,213 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3_defs.h"
+#include "gop/mv_gop_if.h"
+#include "mv_mib_regs.h"
+
+
+static u32 pp3_port_mib_shadow[MV_PP3_GOP_MAC_NUM][MV_PP3_MIB_LATE_COLLISION/sizeof(u32)+1];
+
+/*******************************************************************************
+* mv_pp3_mib_counter_read - Read a MIB counter
+*
+* DESCRIPTION:
+*       This function reads a MIB counter of a specific ethernet port.
+*       NOTE - Read from MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW or
+*              MV_PP3_MIB_GOOD_OCTETS_SENT_LOW counters will return 64 bits value,
+*              so p_high_32 pointer should not be NULL in this case.
+*
+* INPUT:
+*       port     - Ethernet Port number.
+*       offset   - MIB counter offset.
+*
+* OUTPUT:
+*       p_high_32 - pointer to place where 32 most significant bits
+*                   of the counter will be stored.
+*
+* RETURN:
+*       32 low significant bits of MIB counter value.
+*
+*******************************************************************************/
+static u32 pp3_gop_mib_counter_read(int port, unsigned int offset, u32 *p_high_32)
+{
+	u32 val_low_32, val_high_32;
+	int abs_offset;
+
+	val_low_32 = mv_gop_reg_read(MV_PP3_MIB_COUNTERS_BASE(port) + offset);
+	pp3_port_mib_shadow[port][offset/sizeof(u32)] += val_low_32;
+
+	/* Implement FEr ETH. Erroneous Value when Reading the Upper 32-bits    */
+	/* of a 64-bit MIB Counter.                                             */
+	if ((offset == MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW) || (offset == MV_PP3_MIB_GOOD_OCTETS_SENT_LOW)) {
+		abs_offset = MV_PP3_MIB_COUNTERS_BASE(port) + offset + 4;
+
+		val_high_32 = mv_gop_reg_read(abs_offset);
+		pp3_port_mib_shadow[port][(offset + 4)/sizeof(u32)] += val_high_32;
+
+		if (p_high_32 != NULL)
+			*p_high_32 = pp3_port_mib_shadow[port][(offset + 4)/sizeof(u32)];
+	}
+	return pp3_port_mib_shadow[port][offset/sizeof(u32)];
+}
+
+/*******************************************************************************
+* mv_pp3_mib_counters_clear - Clear all MIB counters
+*
+* DESCRIPTION:
+*       This function clears all MIB counters
+*
+* INPUT:
+*       port      - Ethernet Port number.
+*
+* RETURN:   void
+*
+*******************************************************************************/
+void mv_pp3_gop_mib_counters_clear(int port)
+{
+	int i, abs_offset;
+
+	if (port >= MV_PP3_GOP_MAC_NUM) {
+		pr_err("%s: illegal port number %d", __func__, port);
+		return;
+	}
+
+	/* clear counters shadow */
+	memset(pp3_port_mib_shadow[port], 0, MV_PP3_MIB_LATE_COLLISION);
+	/* Perform dummy reads from MIB counters */
+	/* Read of last counter clear all counter were read before */
+	for (i = MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW; i <= MV_PP3_MIB_LATE_COLLISION; i += 4) {
+		abs_offset = MV_PP3_MIB_COUNTERS_BASE(port) + i;
+		mv_gop_reg_read(abs_offset);
+	}
+}
+
+static void pp3_mib_print(int port, u32 offset, char *mib_name)
+{
+	u32 reg_low, reg_high = 0;
+
+	reg_low = pp3_gop_mib_counter_read(port, offset, &reg_high);
+
+	if (!reg_high)
+		pr_info("  %-32s: 0x%02x = %u\n", mib_name, offset, reg_low);
+	else
+		pr_info("  %-32s: 0x%02x = 0x%08x%08x\n", mib_name, offset, reg_high, reg_low);
+
+}
+
+/*******************************************************************************
+* mv_pp3_gop_mib_counter_get - return a MIB counter
+*
+* DESCRIPTION:
+*       This function reads a MIB counter of a specific ethernet port.
+*       NOTE - Read from MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW or
+*              MV_PP3_MIB_GOOD_OCTETS_SENT_LOW counters will return 64 bits value,
+*              so p_high_32 pointer should not be NULL in this case.
+*
+* INPUT:
+*       port     - Ethernet Port number.
+*       offset   - MIB counter offset.
+*
+* OUTPUT:
+*       p_high_32 - pointer to place where 32 most significant bits
+*                   of the counter will be stored.
+*
+* RETURN:
+*       32 low significant bits of MIB counter value.
+*
+*******************************************************************************/
+u32 mv_pp3_gop_mib_counter_get(int port, unsigned int offset, u32 *p_high_32)
+{
+	int i;
+
+	if (port >= MV_PP3_GOP_MAC_NUM) {
+		pr_err("%s: illegal port number %d", __func__, port);
+		return 0;
+	}
+
+	/* Read all MIB counters */
+	for (i = MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW; i <= MV_PP3_MIB_LATE_COLLISION; i += 4)
+		pp3_gop_mib_counter_read(port, i, p_high_32);
+
+	/* return specific counter value from shadow */
+	if ((offset == MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW) || (offset == MV_PP3_MIB_GOOD_OCTETS_SENT_LOW)) {
+		if (p_high_32 != NULL)
+			*p_high_32 = pp3_port_mib_shadow[port][(offset + 4)/sizeof(u32)];
+	}
+	return pp3_port_mib_shadow[port][offset/sizeof(u32)];
+}
+
+/* Print MIB counters of the Ethernet port */
+void mv_pp3_gop_mib_counters_show(int port)
+{
+	if (port >= MV_PP3_GOP_MAC_NUM) {
+		pr_err("%s: illegal port number %d", __func__, port);
+		return;
+	}
+
+	pr_info("\nMIBs: port=%d, base=0x%x\n", port, MV_PP3_MIB_COUNTERS_BASE(port));
+
+	pr_info("\n[Rx]\n");
+	pp3_mib_print(port, MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW, "GOOD_OCTETS_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_BAD_OCTETS_RECEIVED, "BAD_OCTETS_RECEIVED");
+
+	pp3_mib_print(port, MV_PP3_MIB_UNICAST_FRAMES_RECEIVED, "UNCAST_FRAMES_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_BROADCAST_FRAMES_RECEIVED, "BROADCAST_FRAMES_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_MULTICAST_FRAMES_RECEIVED, "MULTICAST_FRAMES_RECEIVED");
+
+	pr_info("\n[RMON]\n");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_64_OCTETS, "FRAMES_64_OCTETS");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_65_TO_127_OCTETS, "FRAMES_65_TO_127_OCTETS");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_128_TO_255_OCTETS, "FRAMES_128_TO_255_OCTETS");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_256_TO_511_OCTETS, "FRAMES_256_TO_511_OCTETS");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_512_TO_1023_OCTETS, "FRAMES_512_TO_1023_OCTETS");
+	pp3_mib_print(port, MV_PP3_MIB_FRAMES_1024_TO_MAX_OCTETS, "FRAMES_1024_TO_MAX_OCTETS");
+
+	pr_info("\n[Tx]\n");
+	pp3_mib_print(port, MV_PP3_MIB_GOOD_OCTETS_SENT_LOW, "GOOD_OCTETS_SENT");
+	pp3_mib_print(port, MV_PP3_MIB_UNICAST_FRAMES_SENT, "UNICAST_FRAMES_SENT");
+	pp3_mib_print(port, MV_PP3_MIB_MULTICAST_FRAMES_SENT, "MULTICAST_FRAMES_SENT");
+	pp3_mib_print(port, MV_PP3_MIB_BROADCAST_FRAMES_SENT, "BROADCAST_FRAMES_SENT");
+	pp3_mib_print(port, MV_PP3_MIB_CRC_ERRORS_SENT, "CRC_ERRORS_SENT");
+
+	pr_info("\n[FC control]\n");
+	pp3_mib_print(port, MV_PP3_MIB_FC_RECEIVED, "FC_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_FC_SENT, "FC_SENT");
+
+	pr_info("\n[Errors]\n");
+	pp3_mib_print(port, MV_PP3_MIB_RX_FIFO_OVERRUN, "MV_PP3_MIB_RX_FIFO_OVERRUN");
+	pp3_mib_print(port, MV_PP3_MIB_UNDERSIZE_RECEIVED, "UNDERSIZE_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_FRAGMENTS_RECEIVED, "FRAGMENTS_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_OVERSIZE_RECEIVED, "OVERSIZE_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_JABBER_RECEIVED, "JABBER_RECEIVED");
+	pp3_mib_print(port, MV_PP3_MIB_MAC_RECEIVE_ERROR, "MAC_RECEIVE_ERROR");
+	pp3_mib_print(port, MV_PP3_MIB_BAD_CRC_EVENT, "BAD_CRC_EVENT");
+	pp3_mib_print(port, MV_PP3_MIB_COLLISION, "COLLISION");
+	/* This counter must be read last. Read it clear all the counters */
+	pp3_mib_print(port, MV_PP3_MIB_LATE_COLLISION, "LATE_COLLISION");
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_mib_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mv_mib_regs.h
new file mode 100644
index 0000000..15ca876
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_mib_regs.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_mib_regs_h__
+#define __mv_mib_regs_h__
+
+#define MV_PP3_MIB_COUNTERS_REG_BASE		0x02000000
+
+#define MV_PP3_MIB_PORT_OFFSET(port)		((port) * 0x400)
+#define MV_PP3_MIB_COUNTERS_BASE(port)		(MV_PP3_MIB_COUNTERS_REG_BASE + MV_PP3_MIB_PORT_OFFSET(port))
+
+/* GMAC_MIB Counters register definitions */
+#define MV_PP3_MIB_GOOD_OCTETS_RECEIVED_LOW	0x0
+#define MV_PP3_MIB_GOOD_OCTETS_RECEIVED_HIGH	0x4
+#define MV_PP3_MIB_BAD_OCTETS_RECEIVED		0x8
+#define MV_PP3_MIB_CRC_ERRORS_SENT		0xc
+#define MV_PP3_MIB_UNICAST_FRAMES_RECEIVED	0x10
+/* Reserved					0x14 */
+#define MV_PP3_MIB_BROADCAST_FRAMES_RECEIVED	0x18
+#define MV_PP3_MIB_MULTICAST_FRAMES_RECEIVED	0x1c
+#define MV_PP3_MIB_FRAMES_64_OCTETS		0x20
+#define MV_PP3_MIB_FRAMES_65_TO_127_OCTETS	0x24
+#define MV_PP3_MIB_FRAMES_128_TO_255_OCTETS	0x28
+#define MV_PP3_MIB_FRAMES_256_TO_511_OCTETS	0x2c
+#define MV_PP3_MIB_FRAMES_512_TO_1023_OCTETS	0x30
+#define MV_PP3_MIB_FRAMES_1024_TO_MAX_OCTETS	0x34
+#define MV_PP3_MIB_GOOD_OCTETS_SENT_LOW		0x38
+#define MV_PP3_MIB_GOOD_OCTETS_SENT_HIGH	0x3c
+#define MV_PP3_MIB_UNICAST_FRAMES_SENT		0x40
+/* Reserved					0x44 */
+#define MV_PP3_MIB_MULTICAST_FRAMES_SENT	0x48
+#define MV_PP3_MIB_BROADCAST_FRAMES_SENT	0x4c
+/* Reserved					0x50 */
+#define MV_PP3_MIB_FC_SENT			0x54
+#define MV_PP3_MIB_FC_RECEIVED			0x58
+#define MV_PP3_MIB_RX_FIFO_OVERRUN		0x5c
+#define MV_PP3_MIB_UNDERSIZE_RECEIVED		0x60
+#define MV_PP3_MIB_FRAGMENTS_RECEIVED		0x64
+#define MV_PP3_MIB_OVERSIZE_RECEIVED		0x68
+#define MV_PP3_MIB_JABBER_RECEIVED		0x6c
+#define MV_PP3_MIB_MAC_RECEIVE_ERROR		0x70
+#define MV_PP3_MIB_BAD_CRC_EVENT		0x74
+#define MV_PP3_MIB_COLLISION			0x78
+#define MV_PP3_MIB_LATE_COLLISION		0x7c
+
+#endif /* mv_mib_regs_h */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_nss_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mv_nss_regs.h
new file mode 100644
index 0000000..6bfdf24
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_nss_regs.h
@@ -0,0 +1,549 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_nss_regs_h__
+#define __mv_nss_regs_h__
+
+/* includes */
+#include "common/mv_hw_if.h"
+
+/* unit offset */
+#define MV_PP3_NSS_UNIT_OFFSET		0x00010000
+
+
+/* Power Management Clock Gating Control 1 */
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_REG				0x8a00
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_S_AMB_PWR_UP_OFFS		0
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_S_AMB_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_S_AMB_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M0_AMB_PWR_UP_OFFS		1
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M0_AMB_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M0_AMB_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M1_AMB_PWR_UP_OFFS		2
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M1_AMB_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_M1_AMB_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_EIP150_AMB_PWR_UP_OFFS		3
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_EIP150_AMB_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_EIP150_AMB_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_NSS_PWR_OFFS		4
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_NSS_PWR_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_NSS_PWR_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_CORE_PWR_OFFS		5
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_CORE_PWR_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_MG_CORE_PWR_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_DP_PWR_UP_OFFS		6
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_DP_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_DP_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_NSS_PWR_UP_OFFS		7
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_NSS_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_GOP_NSS_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_X2_PWR_UP_OFFS		8
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_X2_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_X2_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_PWR_UP_OFFS		9
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_SRAM_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_CMAC_PWR_UP_OFFS		10
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_CMAC_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_CMAC_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_PWR_UP_OFFS		11
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_NSS_PWR_UP_OFFS		12
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_NSS_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_PPC_NSS_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_CMAC_PWR_UP_OFFS		13
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_CMAC_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_CMAC_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_PWR_UP_OFFS		14
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_MACS_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM2_PWR_UP_OFFS		15
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM2_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM2_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_X2_PWR_UP_OFFS		16
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_X2_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_X2_PWR_UP_OFFS)
+
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_PWR_UP_OFFS		17
+#define MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_PWR_UP_MASK    \
+		(0x00000001 << MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_NSS_QM1_PWR_UP_OFFS)
+
+
+/* System Soft Reset 1 */
+#define MV_NSS_SYSTEM_SOFT_RESET_1_REG						0x8a08
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_S_AMB_SW_RESET__OFFS		0
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_S_AMB_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_S_AMB_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M0_AMB_SW_RESET__OFFS		1
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M0_AMB_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M0_AMB_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M1_AMB_SW_RESET__OFFS		2
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M1_AMB_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_M1_AMB_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_EIP150_AMB_SW_RESET__OFFS		3
+#define MV_NSS_SYSTEM_SOFT_RESET_1_EIP150_AMB_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_EIP150_AMB_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_NSS_SW_RESET__OFFS		4
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_NSS_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_MG_NSS_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_CORE_SW_RESET__OFFS		5
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_CORE_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_MG_CORE_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_RESET__OFFS		6
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_LOAD_CONFIG__OFFS		8
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_RESET__OFFS		9
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_LOAD_CONFIG__OFFS		10
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_SRAM_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_RESET__OFFS		11
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_LOAD_CONFIG__OFFS		12
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_PPC_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_RESET__OFFS		13
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_LOAD_CONFIG__OFFS		14
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_MACS_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM2_SW_RESET__OFFS		15
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM2_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM2_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_RESET__OFFS		16
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_RESET__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_RESET__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_LOAD_CONFIG__OFFS		17
+#define MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_NSS_QM1_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD0_SW_LOAD_CONFIG__OFFS		18
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD0_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD0_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD1_SW_LOAD_CONFIG__OFFS		19
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD1_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD1_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD2_SW_LOAD_CONFIG__OFFS		20
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD2_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD2_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD3_SW_LOAD_CONFIG__OFFS		21
+#define MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD3_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_GOP_SD3_SW_LOAD_CONFIG__OFFS)
+
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_SW_LOAD_CONFIG__OFFS		22
+#define MV_NSS_SYSTEM_SOFT_RESET_1_MG_SW_LOAD_CONFIG__MASK    \
+		(0x00000001 << MV_NSS_SYSTEM_SOFT_RESET_1_MG_SW_LOAD_CONFIG__OFFS)
+
+
+/* Ports Control 0 */
+#define MV_NSS_PORTS_CTRL_0_REG						0x8a10
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_EN_DEVICE_OFFS		0
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_EN_DEVICE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_EN_DEVICE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_HALF_BUS_MODE_OFFS		1
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_HALF_BUS_MODE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_HALF_BUS_MODE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_XPCS_USE_EXT_TX_CLK__OFFS		2
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_XPCS_USE_EXT_TX_CLK__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_XPCS_USE_EXT_TX_CLK__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P0_PAUSE__OFFS		3
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P0_PAUSE__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P0_PAUSE__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P1_PAUSE__OFFS		4
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P1_PAUSE__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P1_PAUSE__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P2_PAUSE__OFFS		5
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P2_PAUSE__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P2_PAUSE__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P3_PAUSE__OFFS		6
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P3_PAUSE__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_BM2P3_PAUSE__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_GLOBAL_XOFF__OFFS		7
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_GLOBAL_XOFF__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_GLOBAL_XOFF__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_SERDES_LB_CLK_SEL_OFFS		8
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_SERDES_LB_CLK_SEL_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_SERDES_LB_CLK_SEL_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_HI_Z_ALL__OFFS		9
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_HI_Z_ALL__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_MG_HI_Z_ALL__OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_IO_DEBUG_BUS_EN_OFFS		10
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_IO_DEBUG_BUS_EN_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_IO_DEBUG_BUS_EN_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_DEBUG_CTRL_OFFS		11
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_DEBUG_CTRL_MASK    \
+		(0x000003ff << MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_DEBUG_CTRL_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_NUM_DEBUG_OFFS		21
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_NUM_DEBUG_MASK    \
+		(0x0000003f << MV_NSS_PORTS_CTRL_0_CONF_GOP_PORT_NUM_DEBUG_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_DEBUG_EN_OFFS		27
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_DEBUG_EN_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_MG_DEBUG_EN_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_IO_DEBUG_BUS_EN_OFFS		28
+#define MV_NSS_PORTS_CTRL_0_CONF_MG_IO_DEBUG_BUS_EN_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_MG_IO_DEBUG_BUS_EN_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_RXDATA_SAMP_SEL_OFFS		29
+#define MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_RXDATA_SAMP_SEL_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_RXDATA_SAMP_SEL_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_TXDATA_SAMP_SEL_OFFS		30
+#define MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_TXDATA_SAMP_SEL_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_SD_GIG_RF_TXDATA_SAMP_SEL_OFFS)
+
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_CLK_DIV_PHASE_SET__OFFS		31
+#define MV_NSS_PORTS_CTRL_0_CONF_GOP_CLK_DIV_PHASE_SET__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_0_CONF_GOP_CLK_DIV_PHASE_SET__OFFS)
+
+
+/* Ports Control 1 */
+#define MV_NSS_PORTS_CTRL_1_REG								0x8a14
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_ACTIVE_OFFS		0
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_ACTIVE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_ACTIVE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_ACTIVE_OFFS		1
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_ACTIVE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_ACTIVE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_ACTIVE_OFFS		2
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_ACTIVE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_ACTIVE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_ACTIVE_OFFS		3
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_ACTIVE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_ACTIVE_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_NUM_OFFS		4
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_NUM_MASK    \
+		(0x0000003f << MV_NSS_PORTS_CTRL_1_CONF_GOP_P0_PORT_NUM_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_NUM_OFFS		10
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_NUM_MASK    \
+		(0x0000003f << MV_NSS_PORTS_CTRL_1_CONF_GOP_P1_PORT_NUM_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_NUM_OFFS		16
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_NUM_MASK    \
+		(0x0000003f << MV_NSS_PORTS_CTRL_1_CONF_GOP_P2_PORT_NUM_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_NUM_OFFS		22
+#define MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_NUM_MASK    \
+		(0x0000003f << MV_NSS_PORTS_CTRL_1_CONF_GOP_P3_PORT_NUM_OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_P0_SD_GIG_RF_RESET__OFFS		28
+#define MV_NSS_PORTS_CTRL_1_CONF_P0_SD_GIG_RF_RESET__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_P0_SD_GIG_RF_RESET__OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_P1_SD_GIG_RF_RESET__OFFS		29
+#define MV_NSS_PORTS_CTRL_1_CONF_P1_SD_GIG_RF_RESET__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_P1_SD_GIG_RF_RESET__OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_P2_SD_GIG_RF_RESET__OFFS		30
+#define MV_NSS_PORTS_CTRL_1_CONF_P2_SD_GIG_RF_RESET__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_P2_SD_GIG_RF_RESET__OFFS)
+
+#define MV_NSS_PORTS_CTRL_1_CONF_P3_SD_GIG_RF_RESET__OFFS		31
+#define MV_NSS_PORTS_CTRL_1_CONF_P3_SD_GIG_RF_RESET__MASK    \
+		(0x00000001 << MV_NSS_PORTS_CTRL_1_CONF_P3_SD_GIG_RF_RESET__OFFS)
+
+
+/* Ports Control 2 */
+#define MV_NSS_PORTS_CTRL_2_REG								0x8a18
+#define MV_NSS_PORTS_CTRL_2_CONF_SD0_IN_HF_CC_DELAY_OFFS		0
+#define MV_NSS_PORTS_CTRL_2_CONF_SD0_IN_HF_CC_DELAY_MASK    \
+		(0x0000000f << MV_NSS_PORTS_CTRL_2_CONF_SD0_IN_HF_CC_DELAY_OFFS)
+
+#define MV_NSS_PORTS_CTRL_2_CONF_SD1_IN_HF_CC_DELAY_OFFS		4
+#define MV_NSS_PORTS_CTRL_2_CONF_SD1_IN_HF_CC_DELAY_MASK    \
+		(0x0000000f << MV_NSS_PORTS_CTRL_2_CONF_SD1_IN_HF_CC_DELAY_OFFS)
+
+#define MV_NSS_PORTS_CTRL_2_CONF_SD2_IN_HF_CC_DELAY_OFFS		8
+#define MV_NSS_PORTS_CTRL_2_CONF_SD2_IN_HF_CC_DELAY_MASK    \
+		(0x0000000f << MV_NSS_PORTS_CTRL_2_CONF_SD2_IN_HF_CC_DELAY_OFFS)
+
+#define MV_NSS_PORTS_CTRL_2_CONF_SD3_IN_HF_CC_DELAY_OFFS		12
+#define MV_NSS_PORTS_CTRL_2_CONF_SD3_IN_HF_CC_DELAY_MASK    \
+		(0x0000000f << MV_NSS_PORTS_CTRL_2_CONF_SD3_IN_HF_CC_DELAY_OFFS)
+
+
+/* Ports Status 0 */
+#define MV_NSS_PORTS_STATUS_0_REG							0x8a1c
+#define MV_NSS_PORTS_STATUS_0_GOP_P0_LINK_ENABLE_OFFS		0
+#define MV_NSS_PORTS_STATUS_0_GOP_P0_LINK_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_STATUS_0_GOP_P0_LINK_ENABLE_OFFS)
+
+#define MV_NSS_PORTS_STATUS_0_GOP_P1_LINK_ENABLE_OFFS		1
+#define MV_NSS_PORTS_STATUS_0_GOP_P1_LINK_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_STATUS_0_GOP_P1_LINK_ENABLE_OFFS)
+
+#define MV_NSS_PORTS_STATUS_0_GOP_P2_LINK_ENABLE_OFFS		2
+#define MV_NSS_PORTS_STATUS_0_GOP_P2_LINK_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_STATUS_0_GOP_P2_LINK_ENABLE_OFFS)
+
+#define MV_NSS_PORTS_STATUS_0_GOP_P3_LINK_ENABLE_OFFS		3
+#define MV_NSS_PORTS_STATUS_0_GOP_P3_LINK_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_PORTS_STATUS_0_GOP_P3_LINK_ENABLE_OFFS)
+
+
+/* Networking Complex Control 0 */
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_REG						0x8a20
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P0_SGMII_XMII_MODE_OFFS		0
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P0_SGMII_XMII_MODE_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P0_SGMII_XMII_MODE_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P1_SGMII_XMII_MODE_OFFS		1
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P1_SGMII_XMII_MODE_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_P1_SGMII_XMII_MODE_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_FORCE_SPEED_OFFS		4
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_FORCE_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_FORCE_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_GMII_SPEED_OFFS		5
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_GMII_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_GMII_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_MII_SPEED_OFFS		6
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_MII_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P0_RFU_MII_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_FORCE_SPEED_OFFS		7
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_FORCE_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_FORCE_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_GMII_SPEED_OFFS		8
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_GMII_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_GMII_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_MII_SPEED_OFFS		9
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_MII_SPEED_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_P1_RFU_MII_SPEED_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_RXAUI_ENABLE_OFFS		10
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_RXAUI_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_RXAUI_ENABLE_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_XAUI_ENABLE_OFFS		11
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_XAUI_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_XAUI_ENABLE_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_TRIG_GEN_OE__OFFS		12
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_TRIG_GEN_OE__MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_TRIG_GEN_OE__OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_EVENT_REQ_OE__OFFS		13
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_EVENT_REQ_OE__MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_NSS_PTP_EVENT_REQ_OE__OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_EIP_INT_ACCESS_EN_OFFS		14
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_EIP_INT_ACCESS_EN_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_EIP_INT_ACCESS_EN_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_GIG_PLL_LOCK_OFFS		16
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_GIG_PLL_LOCK_MASK    \
+		(0x0000000f << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_GIG_PLL_LOCK_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_INV_SIGDET_OFFS		20
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_INV_SIGDET_MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_GOP_INV_SIGDET_OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G0_TXCLK__OFFS		28
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G0_TXCLK__MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G0_TXCLK__OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G1_TXCLK__OFFS		29
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G1_TXCLK__MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_G1_TXCLK__OFFS)
+
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_GOP1_TXCLK__OFFS		31
+#define MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_GOP1_TXCLK__MASK    \
+		(0x00000001 << MV_NSS_NETWORKING_COMPLEX_CTRL_0_CONF_FORCE_GOP1_TXCLK__OFFS)
+
+
+/* Jtag Control */
+#define MV_NSS_JTAG_CTRL_REG								0x8a50
+#define MV_NSS_JTAG_CTRL_JCON_JT_RST_OFFS		1
+#define MV_NSS_JTAG_CTRL_JCON_JT_RST_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_JCON_JT_RST_OFFS)
+
+#define MV_NSS_JTAG_CTRL_JCON_JT_TDI_OFFS		2
+#define MV_NSS_JTAG_CTRL_JCON_JT_TDI_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_JCON_JT_TDI_OFFS)
+
+#define MV_NSS_JTAG_CTRL_JCON_JT_TMS_OFFS		3
+#define MV_NSS_JTAG_CTRL_JCON_JT_TMS_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_JCON_JT_TMS_OFFS)
+
+#define MV_NSS_JTAG_CTRL_JCON_JT_CLK_OFFS		4
+#define MV_NSS_JTAG_CTRL_JCON_JT_CLK_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_JCON_JT_CLK_OFFS)
+
+#define MV_NSS_JTAG_CTRL_JCON_JT_TDO_EN__OFFS		30
+#define MV_NSS_JTAG_CTRL_JCON_JT_TDO_EN__MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_JCON_JT_TDO_EN__OFFS)
+
+#define MV_NSS_JTAG_CTRL_CONF_JCON_JT_TDO_OFFS		31
+#define MV_NSS_JTAG_CTRL_CONF_JCON_JT_TDO_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CTRL_CONF_JCON_JT_TDO_OFFS)
+
+
+/* Jtag Chains Configuration */
+#define MV_NSS_JTAG_CHAINS_CFG_REG							0x8a54
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_BYPASS_NSS_JTAG_OFFS		0
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_BYPASS_NSS_JTAG_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_BYPASS_NSS_JTAG_OFFS)
+
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_JTAG_CHAIN_SELECT_OFFS		1
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_JTAG_CHAIN_SELECT_MASK    \
+		(0x00000003 << MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_JTAG_CHAIN_SELECT_OFFS)
+
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_ENABLE_OFFS		3
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_ENABLE_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CHAINS_CFG_CONF_JCON_ENABLE_OFFS)
+
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_DEBUG_CONFIG_ONGOING_OFFS		8
+#define MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_DEBUG_CONFIG_ONGOING_MASK    \
+		(0x00000001 << MV_NSS_JTAG_CHAINS_CFG_CONF_NSS_DEBUG_CONFIG_ONGOING_OFFS)
+
+
+/* Nss Master  Amb Access Control 0 */
+#define MV_NSS_MASTER_AMB_ACC_CTRL_0_REG(n)						(0x8ac0 + 0x20*n)
+#define MV_NSS_MASTER_AMB_ACC_CTRL_0_CONF_A2M_INT_VAL0_OFFS			0
+
+/* Nss Master  Amb Access Control 1 */
+#define MV_NSS_MASTER_AMB_ACC_CTRL_1_REG(n)						(0x8ac4 + 0x20*n)
+#define MV_NSS_MASTER_AMB_ACC_CTRL_1_CONF_A2M_INT_VAL1_OFFS		0
+
+/* Nss Master  Amb Access Mask 0 */
+#define MV_NSS_MASTER_AMB_ACC_MASK_0_REG(n)						(0x8ad0 + 0x20*n)
+#define MV_NSS_MASTER_AMB_ACC_MASK_0_CONF_A2M_INT_MASK0_OFFS		0
+
+/* Nss Master  Amb Access Mask 1 */
+#define MV_NSS_MASTER_AMB_ACC_MASK_1_REG(n)						(0x8ad4 + 0x20*n)
+#define MV_NSS_MASTER_AMB_ACC_MASK_1_CONF_A2M_INT_MASK1_OFFS		0
+
+/******************************************************************************/
+/*                       Register acceess Functions                           */
+/******************************************************************************/
+static inline u32  mv_pp3_nss_reg_read(u32 reg_addr)
+{
+	u32 reg_data;
+
+	mv_pp3_hw_read(reg_addr + MV_PP3_NSS_UNIT_OFFSET, 1, &reg_data);
+
+	return reg_data;
+}
+
+static inline void mv_pp3_nss_reg_print(char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg, mv_pp3_nss_reg_read(reg));
+}
+
+static inline void mv_pp3_nss_reg_dump(void)
+{
+	int n;
+	char reg_name[32];
+
+	mv_pp3_nss_reg_print("POWER_MNG_CLOCK_GATING_CTRL_1", MV_NSS_POWER_MNG_CLOCK_GATING_CTRL_1_REG);
+	mv_pp3_nss_reg_print("SYSTEM_SOFT_RESET_1", MV_NSS_SYSTEM_SOFT_RESET_1_REG);
+	mv_pp3_nss_reg_print("PORTS_CTRL_0", MV_NSS_PORTS_CTRL_0_REG);
+	mv_pp3_nss_reg_print("PORTS_CTRL_1", MV_NSS_PORTS_CTRL_1_REG);
+	mv_pp3_nss_reg_print("PORTS_CTRL_2", MV_NSS_PORTS_CTRL_2_REG);
+	mv_pp3_nss_reg_print("PORTS_STATUS_0", MV_NSS_PORTS_STATUS_0_REG);
+	mv_pp3_nss_reg_print("NETWORKING_COMPLEX_CTRL_0", MV_NSS_NETWORKING_COMPLEX_CTRL_0_REG);
+	mv_pp3_nss_reg_print("JTAG_CTRL", MV_NSS_JTAG_CTRL_REG);
+	mv_pp3_nss_reg_print("JTAG_CHAINS_CFG", MV_NSS_JTAG_CHAINS_CFG_REG);
+	for (n = 0; n < 2; n++) {
+		sprintf(reg_name, "NSS_MASTER_%d_AMB_ACC_CTRL_0", n);
+		mv_pp3_nss_reg_print(reg_name, MV_NSS_MASTER_AMB_ACC_CTRL_0_REG(n));
+		sprintf(reg_name, "NSS_MASTER_%d_AMB_ACC_CTRL_1", n);
+		mv_pp3_nss_reg_print(reg_name, MV_NSS_MASTER_AMB_ACC_CTRL_1_REG(n));
+		sprintf(reg_name, "NSS_MASTER_%d_AMB_ACC_MASK_0", n);
+		mv_pp3_nss_reg_print(reg_name, MV_NSS_MASTER_AMB_ACC_MASK_0_REG(n));
+		sprintf(reg_name, "NSS_MASTER_%d_AMB_ACC_MASK_1", n);
+		mv_pp3_nss_reg_print(reg_name, MV_NSS_MASTER_AMB_ACC_MASK_1_REG(n));
+	}
+}
+
+#endif /* __mv_nss_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.c b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.c
new file mode 100644
index 0000000..6cebb173
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.c
@@ -0,0 +1,362 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+/*****************************************************************
+ * This file contains
+ *    PTP (timestamp) hw config and access utilities
+ *    TAI-Clock       hw config and access utilities
+ *    TAI/ToD         up-level operations
+ * Refer also
+ *    mv_pp3_ptp_reg_read      - inline in .H
+ *    mv_pp3_ptp_reg_write     - inline in .H
+ ***************************************************************
+ */
+
+/* includes */
+#include <linux/kernel.h>
+#include "gop/a390_mg_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_regs.h"
+#include "gop/mv_tai_regs.h"
+#include "gop/mv_ptp_if.h"
+#include "net_dev/mv_ptp_service.h"
+#include "platform/mv_pp3_defs.h"
+
+static u32 ptp_tclk_hz;
+static u32 ptp_ports_enabled; /* used to reset ports on tai_clock */
+static u32 ptp_tai_clock_in_cntr;
+static bool ptp_tai_clock_enabled;
+static bool ptp_tai_clock_external_cfg;
+
+
+/************************************************************************/
+/*********    HW-level utilities     ************************************/
+/************************************************************************/
+
+/* ------------------------------------------------------------*/
+/* -------   TAI Clock  (hw-level)   --------------------------*/
+/* ------------------------------------------------------------*/
+
+/* Set Tclock value [Hz] from dtb "clock-frequency" */
+int mv_pp3_ptp_tclk_hz_set(u32 tclk_hz)
+{
+	ptp_tclk_hz = tclk_hz;
+	return 0;
+}
+
+void mv_pp3_tai_clock_stable_status_set(bool on)
+{
+	/* Save to "free" REG, PTP-Application could poll it
+	 * like the mv_pp3_tai_clock_stable_status_get() does
+	 * DRIFT_THR_CFG_HIGH is chosen as free
+	 * Reg's Init-value=0xFFFF, keep it when stable otherwise 0.
+	 */
+	const u32 reg_init_val = 0x0000ffff;
+	u32 regv = (on) ? reg_init_val : 0;
+	mv_pp3_ptp_reg_write(MV_TAI_DRIFT_THR_CFG_HIGH_REG, regv);
+}
+
+bool mv_pp3_tai_clock_stable_status_get(void)
+{
+	u32 regv = mv_pp3_ptp_reg_read(MV_TAI_DRIFT_THR_CFG_HIGH_REG);
+	return (bool)regv & ptp_tai_clock_enabled;
+}
+
+bool mv_pp3_tai_clock_enable_get(void)
+{
+	return ptp_tai_clock_enabled;
+}
+
+u16 mv_pp3_tai_clock_in_cntr_get(u32 *accumulated)
+{
+	/* The HW 1PPS-in-Counter is reset upon reading
+	 * If some contexts are using this the "accumulated" is prefered
+	 */
+	u32 regv = mv_pp3_ptp_reg_read(MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_REG);
+	regv &= MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_CLOCK_CNTR_BITS_0_15_MASK;
+	ptp_tai_clock_in_cntr += regv;
+	if (accumulated)
+		*accumulated = ptp_tai_clock_in_cntr;
+	return (u16)regv;
+}
+
+void mv_pp3_tai_set_nop(void)
+{
+	u32 regv;
+	regv = mv_pp3_ptp_reg_read(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG);
+	regv = MV_TAI_CNTR_TIME_FUNC_BITSET(MV_TAI_NOP, regv);
+	mv_pp3_ptp_reg_write(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG, regv);
+}
+
+void mv_pp3_tai_clock_cfg_external(bool from_external)
+{
+	/* "external" is from GPS vs free-running/Generate */
+	u32 regv, mghz_tclk, tclk_step_nsec, clock_mode;
+
+	mv_pp3_tai_clock_stable_status_set(0);
+
+#ifdef MV_PP3_DEDICATED_MG_REGION
+	/* Configure Register access (multiple call is safe) */
+	a390_addr_completion_fixed_init(MV_PP3_DEDICATED_MG_REGION, MV_PP3_PTP_TAI_UNIT_OFFSET);
+#endif
+	/* Init, Activate TAI Clock RESET (set bit=0) */
+	regv = mv_pp3_ptp_reg_read(MV_TAI_CTRL_REG0_REG);
+	regv = MV_SET_BIT(regv, MV_TAI_CTRL_REG0_SW_RESET_OFFS, 0);
+	mv_pp3_ptp_reg_write(MV_TAI_CTRL_REG0_REG, regv);
+
+	/* Set clock step (e.g. 4nsec for frequency 250MHz) */
+	if (ptp_tclk_hz) {
+		mghz_tclk  = ptp_tclk_hz / 1000000;
+		tclk_step_nsec = 1000 / mghz_tclk;
+	} else {
+		/* Set value good for succesfull bootup but definitelly invalid for TAI */
+		tclk_step_nsec = 200;
+		WARN_ONCE(1, "%s: Tclock is not initialized by .DTB\n", PTP_TAI_PRT_STR);
+	}
+	mv_pp3_ptp_reg_write(MV_TAI_TOD_STEP_NANO_CFG_REG, tclk_step_nsec);
+
+	/* Generate 1PPS-Out cycle = 1 sec */
+	mv_pp3_ptp_reg_write(MV_TAI_CLOCK_CYCLE_CFG_HIGH_REG, 0x4000);
+	mv_pp3_ptp_reg_write(MV_TAI_CLOCK_CYCLE_CFG_LOW_REG, 0);
+
+	/* Configure TAI clock: */
+	regv = 0;
+	regv = MV_TAI_CNTR_TIME_FUNC_BITSET(MV_TAI_NOP, regv);
+	/* MV_TAI_TIME_CNTR_FUNC_CFG_0_INT_CLOCK_GENERATOR_EN keep disable */
+	clock_mode = (from_external) ? 2 : 1; /* 2=Reception : 1=Generate */
+	MV_U32_SET_FIELD(regv, MV_TAI_TIME_CNTR_FUNC_CFG_0_CLOCK_MODE_MASK,
+		clock_mode << MV_TAI_TIME_CNTR_FUNC_CFG_0_CLOCK_MODE_OFFS);
+	regv = MV_SET_BIT(regv, MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_COUNTER_START_OFFS, 1);
+	regv = MV_SET_BIT(regv, MV_TAI_TIME_CNTR_FUNC_CFG_0_CAPTURE_OVERWRITE_EN_OFFS, 1);
+	mv_pp3_ptp_reg_write(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG, regv);
+
+	/* start clock - Deactivate TAI Clock RESET (by set bit=1) */
+	regv = mv_pp3_ptp_reg_read(MV_TAI_CTRL_REG0_REG);
+	regv = MV_SET_BIT(regv, MV_TAI_CTRL_REG0_SW_RESET_OFFS, 1);
+	mv_pp3_ptp_reg_write(MV_TAI_CTRL_REG0_REG, regv);
+	ptp_tai_clock_enabled = true;
+	ptp_tai_clock_external_cfg = from_external;
+	if (!from_external)
+		mv_pp3_tai_clock_stable_status_set(1);
+}
+
+void mv_pp3_tai_clock_disable(void)
+{
+	u32 regv;
+	mv_pp3_tai_clock_stable_status_set(0);
+	/* stop clock by placing TAI into RESET state */
+	regv = mv_pp3_ptp_reg_read(MV_TAI_CTRL_REG0_REG);
+	regv = MV_SET_BIT(regv, MV_TAI_CTRL_REG0_SW_RESET_OFFS, 0);
+	mv_pp3_ptp_reg_write(MV_TAI_CTRL_REG0_REG, regv);
+	ptp_tai_clock_enabled = false;
+	mv_pp3_tai_clock_in_cntr_get(NULL); /*reset the HW counter */
+	ptp_tai_clock_in_cntr = 0; /* reset the SW accumulated */
+}
+
+void mv_pp3_tai_clock_init(struct platform_device *pdev)
+{
+	/* Enable counting ClockIn - once forever (for Internal&External) */
+	mv_pp3_ptp_reg_write(MV_TAI_INCOMING_CLOCKIN_CNTING_EN_REG, 1);
+
+	ptp_tai_clock_external_cfg = mv_pp3_tai_clock_external_init(pdev);
+	mv_pp3_tai_clock_cfg_external(ptp_tai_clock_external_cfg); /*hw here*/
+	mv_pp3_tai_clock_external_init2(ptp_tai_clock_external_cfg);
+}
+
+
+/* ------------------------------------------------------------*/
+/* -------   PTP timestamp  (hw-level)   ----------------------*/
+/* ------------------------------------------------------------*/
+void mv_pp3_ptp_reset(int port)
+{
+	u32 reg_data;
+	if (port >= MV_PP3_EMAC_NUM) /* Could be from sysfs command */
+		return;
+	if (!(ptp_ports_enabled & (1 << port)))
+		return;
+
+	reg_data = mv_pp3_ptp_reg_read(MV_PTP_GENERAL_CTRL_REG(port));
+		/* activate reset */
+	reg_data &= ~MV_PTP_GENERAL_CTRL_PTP_RESET_MASK;
+	mv_pp3_ptp_reg_write(MV_PTP_GENERAL_CTRL_REG(port), reg_data);
+	udelay(1);
+		/* unreset unit */
+	reg_data |= MV_PTP_GENERAL_CTRL_PTP_RESET_MASK;
+	mv_pp3_ptp_reg_write(MV_PTP_GENERAL_CTRL_REG(port), reg_data);
+}
+
+void mv_pp3_ptp_reset_all_ptp_ports(void)
+{
+	/* Required for TAI-Clock-External sync down-up recovery */
+	int port;
+	for (port = 0; port < MV_PP3_EMAC_NUM; port++)
+		mv_pp3_ptp_reset(port); /* only enabled would be reset */
+}
+
+int mv_pp3_ptp_enable(int port, bool enable)
+{
+	u32 reg_data;
+
+	if (port >= MV_PP3_EMAC_NUM) {
+		/* Could be from sysfs command */
+		pr_info("%s: wrong port number %d\n", PTP_TAI_PRT_STR, port);
+		return -1;
+	}
+	if (enable) {
+		ptp_ports_enabled |= 1 << port;
+		reg_data = mv_pp3_ptp_reg_read(MV_PTP_GENERAL_CTRL_REG(port));
+		reg_data |= MV_PTP_GENERAL_CTRL_PTP_UNIT_ENABLE_MASK;
+		reg_data |= MV_PTP_GENERAL_CTRL_TS_QUEUE_OVER_WRITE_ENABLE_MASK;
+		mv_pp3_ptp_reg_write(MV_PTP_GENERAL_CTRL_REG(port), reg_data);
+
+		/* unreset PTP unit */
+		reg_data |= MV_PTP_GENERAL_CTRL_PTP_RESET_MASK;
+		mv_pp3_ptp_reg_write(MV_PTP_GENERAL_CTRL_REG(port), reg_data);
+
+		mv_pp3_ptp_reset(port);
+		mv_ptp_hook_enable(port, true);
+	} else {
+		ptp_ports_enabled &= ~(1 << port);
+		mv_ptp_hook_enable(port, false);
+		reg_data = mv_pp3_ptp_reg_read(MV_PTP_GENERAL_CTRL_REG(port));
+		reg_data &= ~MV_PTP_GENERAL_CTRL_PTP_UNIT_ENABLE_MASK;
+		/* disable PTP */
+		mv_pp3_ptp_reg_write(MV_PTP_GENERAL_CTRL_REG(port), reg_data);
+	}
+	return 0;
+}
+
+/*****************************************************************************/
+/*********    UP-level utilities     *****************************************/
+/*****************************************************************************/
+int mv_pp3_tai_tod_op_read_captured(struct mv_pp3_tai_tod *ts, u32 *p_status)
+{
+	/* Called as Global after synched GET_CAPTURE request */
+	const u32 wait_max = 8;
+	u32 wait = wait_max;
+	u32 status, tmp;
+
+	if (p_status) {
+		/* Check/wait for ready */
+		do {
+			if (!wait--) {
+				pr_err("%s: cannot read tod timestamp after %d retries\n",
+					PTP_TAI_PRT_STR, wait_max);
+				return -1;
+			}
+			status = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_STATUS_REG);
+		} while (!(status & MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_0_VALID_MASK));
+	} else {
+		status = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_STATUS_REG);
+		/* Go ahead even with status=0 */
+	}
+
+	/* SEC_HIGH and FRAC are always zero but read needed to unlock the hw-queue */
+	ts->sec_msb_16b = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_REG)/*& 0xFFFF*/;
+	ts->sec_lsb_32b = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_REG) << 16)
+			| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_REG) & 0xFFFF);
+	ts->nsec = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_REG) << 16)
+		| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_REG) & 0xFFFF);
+	ts->nfrac = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_REG) << 16)
+		| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_REG) & 0xFFFF);
+
+	if (status > 1) {
+		/* flush capture-fifo */
+		tmp = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_REG)/*& 0xFFFF*/;
+		tmp = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_REG) << 16)
+				| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_REG) & 0xFFFF);
+		tmp = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_REG) << 16)
+			| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_REG) & 0xFFFF);
+		tmp = (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_REG) << 16)
+			| (mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_REG) & 0xFFFF);
+		if (p_status)
+			pr_info("ptp/tai: capture-0 loss and taken to capture-1\n");
+	}
+	return 0;
+}
+
+int mv_pp3_tai_tod_op(enum mv_pp3_tai_ptp_op op, struct mv_pp3_tai_tod *ts,
+			int synced_op)
+{
+	u32 ctrl, ctrl_new, status;
+	int rc = 0;
+	bool keep_last_op = (bool)synced_op;
+	u32 trigger_bit = synced_op ? 0 : 1;
+
+	if (unlikely((u32)op >= MV_TAI_PTP_SW_OP)) {
+		if (op == MV_TAI_TO_LINUX) {
+			mv_pp3_tai_tod_to_linux(ts);
+			return 0;
+		} else if (op == MV_TAI_FROM_LINUX) {
+			mv_pp3_tai_tod_from_linux(ts);
+			return 0;
+		} else {
+			pr_err("%s: wrong operation=%d requested\n", PTP_TAI_PRT_STR, op);
+			return -1;
+		}
+	}
+
+	/* mutex_lock - if needed, place here*/
+
+	if (unlikely(op == MV_TAI_NOP)) {
+		ctrl = mv_pp3_ptp_reg_read(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG);
+		ctrl_new = MV_TAI_CNTR_TIME_FUNC_BITSET(op, ctrl);
+		goto exit;
+	}
+
+	if (op == MV_TAI_GET_CAPTURE) {
+		/* GET-exec first, then Read from CAPTURE */
+		ctrl = mv_pp3_ptp_reg_read(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG);
+		ctrl_new = MV_TAI_CNTR_TIME_FUNC_BITSET(op, ctrl);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG, ctrl_new | trigger_bit);
+		/* Check "ready" and read captured into ts */
+		if (!synced_op)
+			rc  = mv_pp3_tai_tod_op_read_captured(ts, &status);
+	} else {
+		/* All operations are "setting": load SHADOW first */
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_SEC_MED_REG, ts->sec_lsb_32b >> 16);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_SEC_LOW_REG, ts->sec_lsb_32b & 0xFFFF);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_REG, ts->nsec >> 16);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_NANO_LOW_REG, ts->nsec & 0xFFFF);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_REG, ts->sec_msb_16b & 0xFFFF);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_REG, ts->nfrac >> 16);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_REG, ts->nfrac & 0xFFFF);
+
+		/* Lock-exec new SHADOW/LOAD into tai-tod */
+		ctrl = mv_pp3_ptp_reg_read(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG);
+		ctrl_new = MV_TAI_CNTR_TIME_FUNC_BITSET(op, ctrl);
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG, ctrl_new | trigger_bit);
+	}
+
+exit:
+	if ((!keep_last_op) && (ctrl_new != ctrl)) /* restore original */
+		mv_pp3_ptp_reg_write(MV_TAI_TIME_CNTR_FUNC_CFG_0_REG, ctrl);
+
+	/* mutex_unlock - if needed, place here*/
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.h b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.h
new file mode 100644
index 0000000..1f5cd7d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if.h
@@ -0,0 +1,58 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef _mv_ptp_if_h_
+#define _mv_ptp_if_h_
+
+/* includes */
+#include "gop/mv_tai_regs.h"
+
+#define PTP_TAI_PRT_STR	"TAI/PTP"
+
+int mv_pp3_ptp_tclk_hz_set(u32 tclk_hz); /* from dtb "clock-frequency" */
+void mv_pp3_tai_clock_init(struct platform_device *pdev);
+bool mv_pp3_tai_clock_external_init(struct platform_device *pdev);
+void mv_pp3_tai_clock_external_init2(bool from_external);
+void mv_pp3_tai_set_nop(void);
+void mv_pp3_tai_clock_cfg_external(bool from_external);
+void mv_pp3_tai_clock_disable(void);
+bool mv_pp3_tai_clock_enable_get(void);
+void mv_pp3_tai_clock_stable_status_set(bool on);
+bool mv_pp3_tai_clock_stable_status_get(void);
+u16 mv_pp3_tai_clock_in_cntr_get(u32 *accumulated);
+int mv_pp3_ptp_event_led_sysfs(unsigned led_gpio);
+
+int mv_pp3_ptp_enable(int port, bool state);
+void mv_pp3_ptp_reset(int port);
+void mv_pp3_ptp_reset_all_ptp_ports(void);
+
+int mv_pp3_tai_tod_op(enum mv_pp3_tai_ptp_op op, struct mv_pp3_tai_tod *ts,
+			int synced_op);
+int mv_pp3_tai_tod_op_read_captured(struct mv_pp3_tai_tod *ts, u32 *status);
+
+void mv_pp3_tai_clock_from_external_sync(u32 start, u32 sec, int d_sec);
+
+void mv_pp3_ptp_reg_dump(int port);
+void mv_pp3_tai_tod_dump_util(struct mv_pp3_tai_tod *ts);
+void mv_pp3_tai_tod_from_linux(struct mv_pp3_tai_tod *ts);
+void mv_pp3_tai_tod_to_linux(struct mv_pp3_tai_tod *ts);
+void mv_pp3_tai_reg_dump(void);
+void mv_pp3_tai_tod_dump(void);
+int mv_pp3_tai_tod_load_set(u32 sec_h, u32 sec_l, u32 nano, u32 frac);
+
+#endif /* _mv_ptp_if_h_ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if_serv.c b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if_serv.c
new file mode 100644
index 0000000..b8649bb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_if_serv.c
@@ -0,0 +1,417 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/***************************************************************
+ * This file contains:  UP-level utilities used by sysfs
+ ***************************************************************
+ */
+
+/* includes */
+#include <linux/kernel.h>
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_regs.h"
+#include "gop/mv_tai_regs.h"
+#include "gop/mv_ptp_if.h"
+#include "net_dev/mv_ptp_service.h"
+
+static void mv_pp3_tai_tod_from_kernel(int prt_off_on_extend);
+static void mv_pp3_tai_tod_and_kernel_print(int prt_off_on_extend);
+
+int mv_pp3_tai_tod_load_set(u32 sec_h, u32 sec_l, u32 nano, u32 op)
+{
+	/* Generic TAI TOD operationS */
+	struct mv_pp3_tai_tod ts;
+	u32 value;
+
+	ts.sec_msb_16b = sec_h;
+	ts.sec_lsb_32b = sec_l;
+	ts.nsec = nano;
+	ts.nfrac = 0;
+
+	switch (op) {
+	/* LOAD-SET ToD with sec_high, sec_low, nsec */
+	case 0:
+		mv_pp3_tai_tod_op(MV_TAI_SET_UPDATE, &ts, 0);
+		break;
+
+	/* SYNC ToD time from/to linux or Sys/kernel */
+	case 0x21:
+		mv_pp3_tai_tod_op(MV_TAI_TO_LINUX, &ts, 0);
+		break;
+	case 0x41:
+		mv_pp3_tai_tod_op(MV_TAI_FROM_LINUX, &ts, 0);
+		break;
+	case 0x45:
+		/* Do twice. First is for cache loading */
+		mv_pp3_tai_tod_from_kernel(0);
+		mv_pp3_tai_tod_from_kernel(2);
+		break;
+	case 0x46:
+		mv_pp3_tai_tod_and_kernel_print(0);
+		mv_pp3_tai_tod_and_kernel_print(1);
+		break;
+	case 0x47:
+		mv_pp3_tai_tod_and_kernel_print(0);
+		mv_pp3_tai_tod_and_kernel_print(2);
+		break;
+
+	/* ToD time Increment/Decrement */
+	case 0x1c:
+		mv_pp3_tai_tod_op(MV_TAI_INCREMENT, &ts, 0);
+		break;
+	case 0xdc:
+		mv_pp3_tai_tod_op(MV_TAI_DECREMENT, &ts, 0);
+		break;
+	case 0x1c0:
+		mv_pp3_tai_tod_op(MV_TAI_INCREMENT_GRACEFUL, &ts, 0);
+		break;
+	case 0xdc0:
+		mv_pp3_tai_tod_op(MV_TAI_DECREMENT_GRACEFUL, &ts, 0);
+		break;
+
+	/* FREQ update */
+	case 0xf1c:
+		ts.sec_msb_16b = 0;
+		ts.sec_lsb_32b = 0;
+		ts.nsec = 0;
+		ts.nfrac = sec_h;
+		mv_pp3_tai_tod_op(MV_TAI_FREQ_UPDATE, &ts, 0);
+		break;
+	case 0xfdc:
+		ts.sec_msb_16b = 0;
+		ts.sec_lsb_32b = 0;
+		ts.nsec = 0;
+		ts.nfrac = -sec_h;
+		mv_pp3_tai_tod_op(MV_TAI_FREQ_UPDATE, &ts, 0);
+		break;
+
+	/* TAI/ToD Clock configuration */
+	case 0xce1: /* External, Increment [h] seconds */
+	case 0xced: /* External, Decrement [h] seconds */
+		if (sec_h) { /* ToD Inc/Dec required */
+			sec_h = (op == 0xce1) ? sec_h : -sec_h;
+			sec_l = 0;
+		} else { /* sync but keep current ToD */
+			sec_h = 1;
+			sec_l = 1;
+		}
+		mv_pp3_tai_clock_from_external_sync(1, sec_l, sec_h);
+		break;
+	case 0xcea: /* External, Absolute set [h] seconds */
+		mv_pp3_tai_clock_from_external_sync(1, sec_h, 0);
+		break;
+	case 0xcec: /* Check stability status */
+		mv_pp3_tai_clock_in_cntr_get(&value);
+		pr_info("TAI/ToD clock: stability=%d, counter=%u\n",
+			mv_pp3_tai_clock_stable_status_get(), value);
+		break;
+	case 0xc1: /* Internal */
+		mv_pp3_tai_clock_from_external_sync(0, 0, 0);
+		mv_pp3_tai_clock_cfg_external(false);
+		break;
+	case 0xc0: /* Off */
+		mv_pp3_tai_clock_from_external_sync(0, 0, 0);
+		mv_pp3_tai_clock_disable();
+		break;
+	case 0xceb11: /* Blink led on gpio=11 */
+		mv_pp3_ptp_event_led_sysfs(11);
+		break;
+
+	/* DEBUG with 3 "just generic" param-values passed transparently */
+	case 0xdeb:
+		mv_ptp_hook_extra_op(sec_h, sec_l, nano);
+		break;
+
+	default:
+		pr_info("tai_op: Wrong parameter\n"
+			"Supported HEX: 0; 21,41,45,46,47; 1c,dc,1c0,dc0; f1c,fdc;"
+			" ce1,ceD,ceA,ceC,c1,c0; deb\n");
+		return -EINVAL;
+	}
+	return 0;
+}
+
+void mv_pp3_tai_tod_to_linux(struct mv_pp3_tai_tod *ts)
+{
+	struct timespec tv;
+	unsigned long flag;
+	int rc;
+	rc = mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, ts, 0);
+	if (rc)
+		return;
+	tv.tv_sec = ts->sec_lsb_32b;
+	tv.tv_nsec = ts->nsec;
+	flag = irqs_disabled();
+	if (flag) {
+		/* write over sysfs runs under IRQ-DISABLE (versus regular sys-call)
+		 * To avoid deadlock in settimeofday() between cpuA and cpuB waiting
+		 * each to other (refer smp.c:WARN_ON_ONCE) we must enable irq here
+		 */
+		local_irq_enable();
+	}
+	do_settimeofday(&tv);
+	if (flag)
+		local_irq_disable();
+}
+
+void mv_pp3_tai_tod_from_linux(struct mv_pp3_tai_tod *ts)
+{
+	struct timeval tv;
+	do_gettimeofday(&tv);
+	ts->sec_msb_16b = 0;
+	ts->sec_lsb_32b = tv.tv_sec;
+	ts->nsec = tv.tv_usec * 1000;
+	mv_pp3_tai_tod_op(MV_TAI_SET_UPDATE, ts, 0);
+}
+
+static void mv_pp3_tai_tod_from_kernel(int prt_off_on_extend)
+{
+	struct mv_pp3_tai_tod ts;
+	u64 cl;
+	u32 sec, nsec;
+
+	ts.sec_msb_16b = 0;
+	ts.nfrac = 0;
+
+	cl = local_clock();
+	sec = (u32)div_u64_rem(cl, 1000000000, &nsec);
+
+	ts.sec_lsb_32b = sec;
+	ts.nsec = nsec;
+	mv_pp3_tai_tod_op(MV_TAI_SET_UPDATE, &ts, 0);
+	if (prt_off_on_extend) {
+		/* Adjust delta between K-get and ToD real set
+		 * With double exec silent=1/0 (for caching) and
+		 * adjust value 0x200 the +/- 0x14 deviation found
+		 * "Cached" ToD read/write takes >4200nsec
+		 */
+		ts.nsec = 0x200;
+		ts.sec_lsb_32b = 0;
+		mv_pp3_tai_tod_op(MV_TAI_INCREMENT, &ts, 0);
+	}
+	mv_pp3_tai_tod_and_kernel_print(prt_off_on_extend);
+}
+
+static void mv_pp3_tai_tod_and_kernel_print(int prt_off_on_extend)
+{
+	struct mv_pp3_tai_tod ts;
+	u64 cl[2], tod64;
+	u32 sec[2], nsec[2], d;
+	char sign;
+
+	cl[0] = local_clock();
+	mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, &ts, 0);
+	cl[1] = local_clock();
+
+	if (!prt_off_on_extend) /* only cache adjust requested */
+		return;
+
+	tod64 = ts.sec_lsb_32b * 1000000000 + ts.nsec;
+	pr_info("  Kclock - ToD = %d\n", (int)(cl[0] - tod64));
+
+	if (prt_off_on_extend == 1)
+		return;
+
+	/* Account and print the buffered results */
+	sec[0] = (u32)div_u64_rem(cl[0], 1000000000, &nsec[0]);
+	sec[1] = (u32)div_u64_rem(cl[1], 1000000000, &nsec[1]);
+	pr_info("Kclock=%u.%09u  ToD=%u.%09u  Kclock=%u.%09u\n",
+		sec[0], nsec[0], ts.sec_lsb_32b, ts.nsec, sec[1], nsec[1]);
+
+	if (nsec[0] > ts.nsec) {
+		d = nsec[0] - ts.nsec;
+		sign = '+';
+	} else {
+		d = ts.nsec - nsec[0];
+		sign = '-';
+	}
+	pr_info("  hex-delta nsec: (Kclock=%08x) - (ToD=%08x) = %c%04x\n\n",
+		nsec[0], ts.nsec, sign, d);
+}
+
+
+/*****************************************************************************/
+/*****************************************************************************/
+static inline void mv_pp3_ptp_reg_print(char *reg_name, u32 reg)
+{
+	pr_info("  %-45s: 0x%x = 0x%08x\n", reg_name, MV_PP3_PTP_UNIT_OFFSET + reg, mv_pp3_ptp_reg_read(reg));
+}
+
+
+/* Time Counter Function Configuration 0 Register 0x03180A10
+ The field bits[4:2] defines "Time Counter Function" to be performed
+  when CPU sets bit_0 "Time Counter Function Trigger"
+	0 = Update    : Copies the value FROM the SHADOW timer TO the TIMER register
+	1 = FreqUpdate: Copies the value FROM the SHADOW timer TO the fractional nanosecond drift register.
+	2= Increment  : Adds the value of the shadow timer to the timer register.
+	3= Decrement  : Subtracts the value of the shadow timer from the timer register.
+	4= Capture    : Copies the value of the TIMER TO the SHADOW timer register.
+	5= GracefulInc: Gracefully increment the value of the shadow timer to the timer.
+	6= GracefulDec: Gracefully decrement the value of the shadow timer from the timer.
+	7= NOP        : No operation is performed
+
+  There are 2 sets of CAPTURE registers: VALUE_0_xx and VALUE_1_xx, and
+  "Capture Status Register" 0x03180AA4 bit_0 and bit_1 reflecting which one (or both)
+  is ready and waiting for read. The Status-bit is auto-cleared after VALUE_n_xx reading.
+  The Capture and Status behavior also depends upon 0x03180A10 bit6 "Capture Overwrite":
+  With 0x03180A10[6]=0 the Status=[1][1] would go tp [0][0] upon "new capture before reading".
+*/
+void mv_pp3_tai_tod_dump_util(struct mv_pp3_tai_tod *ts)
+{
+	u32 high, low, med;
+
+	if (!ts->sec_msb_16b)
+		pr_info("  %-45s: 0x%08x (%u)\n", "TIME_CAPTURE_VALUE_0_SEC", ts->sec_lsb_32b, ts->sec_lsb_32b);
+	else
+		pr_info("  %-45s: 0x%04x%08x\n", "TIME_CAPTURE_VALUE_0_SEC", ts->sec_msb_16b, ts->sec_lsb_32b);
+
+	pr_info("  %-45s: 0x%08x (%u)\n", "TIME_CAPTURE_VALUE_0_NANO", ts->nsec, ts->nsec);
+
+	high = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_REG);
+	low = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_REG);
+	pr_info("  %-45s: 0x%08x\n", "TIME_CAPTURE_VALUE_0_FRAC", ((high << 16) + low));
+
+	high = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_REG);
+	med = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_REG);
+	low = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_REG);
+	if (!high)
+		pr_info("  %-45s: 0x%08x\n", "TIME_CAPTURE_VALUE_1_SEC", ((med << 16) + low));
+	else
+		pr_info("  %-45s: 0x%08x%08x\n", "TIME_CAPTURE_VALUE_1_SEC", high, ((med << 16) + low));
+
+	high = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_REG);
+	low = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_REG);
+	pr_info("  %-45s: 0x%08x\n", "TIME_CAPTURE_VALUE_1_NANO", ((high << 16) + low));
+
+	high = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_REG);
+	low = mv_pp3_ptp_reg_read(MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_REG);
+	pr_info("  %-45s: 0x%08x\n", "TIME_CAPTURE_VALUE_1_FRAC", ((high << 16) + low));
+}
+
+void mv_pp3_tai_tod_dump(void)
+{
+	struct mv_pp3_tai_tod ts;
+	mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, &ts, 0);
+	mv_pp3_tai_tod_dump_util(&ts);
+}
+
+void mv_pp3_ptp_reg_dump(int port)
+{
+	/* Read interrupt-status clears it. Disable this print if IRQ-handler to be used */
+	mv_pp3_ptp_reg_print("PTP_INT_STATUS_TS", MV_PTP_INT_STATUS_TS_REG(port));
+
+	mv_pp3_ptp_reg_print("PTP_GENERAL_CTRL", MV_PTP_GENERAL_CTRL_REG(port));
+	mv_pp3_ptp_reg_print("TOTAL_PTP_PCKTS_CNTR", MV_PTP_TOTAL_PTP_PCKTS_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("PTPV1_PCKT_CNTR", MV_PTP_PTPV1_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("PTPV2_PCKT_CNTR", MV_PTP_PTPV2_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("Y1731_PCKT_CNTR", MV_PTP_Y1731_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("NTPTS_PCKT_CNTR", MV_PTP_NTPTS_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("NTPRECEIVE_PCKT_CNTR", MV_PTP_NTPRECEIVE_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("NTPTRANSMIT_PCKT_CNTR", MV_PTP_NTPTRANSMIT_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("WAMP_PCKT_CNTR", MV_PTP_WAMP_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("NONE_ACTION_PCKT_CNTR", MV_PTP_NONE_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("FORWARD_ACTION_PCKT_CNTR", MV_PTP_FORWARD_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("DROP_ACTION_PCKT_CNTR", MV_PTP_DROP_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("CAPTURE_ACTION_PCKT_CNTR", MV_PTP_CAPTURE_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("ADD_TIME_ACTION_PCKT_CNTR", MV_PTP_ADDTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("ADD_CORRECT_TIME_ACTION_PCKT_CNTR", MV_PTP_ADDCORRECTEDTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("CAPTURE_TIME_ACTION_PCKT_CNTR", MV_PTP_CAPTUREADDTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("CAPTURE_CORRECT_TIME_ACTION_PCKT_CNTR",
+		MV_PTP_CAPTUREADDCORRECTEDTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("ADD_INGRESS_TIME_ACTION_PCKT_CNTR", MV_PTP_ADDINGRESSTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("CAPTURE_ADD_INGRESS_TIME_ACTION_PCKT_CNTR",
+		MV_PTP_CAPTUREADDINGRESSTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("CAPTURE_INGRESS_TIME_ACTION_PCKT_CNTR",
+		MV_PTP_CAPTUREINGRESSTIME_ACTION_PCKT_CNTR_REG(port));
+	mv_pp3_ptp_reg_print("NTP_PTP_OFFSET_HIGH", MV_PTP_NTP_PTP_OFFSET_HIGH_REG(port));
+	mv_pp3_ptp_reg_print("NTP_PTP_OFFSET_LOW", MV_PTP_NTP_PTP_OFFSET_LOW_REG(port));
+}
+
+void mv_pp3_tai_reg_dump(void)
+{
+	mv_pp3_ptp_reg_print("TAI_CTRL_REG0", MV_TAI_CTRL_REG0_REG);
+	mv_pp3_ptp_reg_print("TAI_CTRL_REG1", MV_TAI_CTRL_REG1_REG);
+	mv_pp3_ptp_reg_print("TIME_CNTR_FUNC_CFG_0", MV_TAI_TIME_CNTR_FUNC_CFG_0_REG);
+	mv_pp3_ptp_reg_print("TIME_CNTR_FUNC_CFG_1", MV_TAI_TIME_CNTR_FUNC_CFG_1_REG);
+	mv_pp3_ptp_reg_print("TIME_CNTR_FUNC_CFG_2", MV_TAI_TIME_CNTR_FUNC_CFG_2_REG);
+	mv_pp3_ptp_reg_print("FREQUENCY_ADJUST_TIME_WINDOW", MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_REG);
+	mv_pp3_ptp_reg_print("TOD_STEP_NANO_CFG", MV_TAI_TOD_STEP_NANO_CFG_REG);
+	mv_pp3_ptp_reg_print("TOD_STEP_FRAC_CFG_HIGH", MV_TAI_TOD_STEP_FRAC_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("TOD_STEP_FRAC_CFG_LOW", MV_TAI_TOD_STEP_FRAC_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH",
+		MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW",
+		MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_SEC_HIGH", MV_TAI_TRIGGER_GENERATION_TOD_SEC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_SEC_MED", MV_TAI_TRIGGER_GENERATION_TOD_SEC_MED_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_SEC_LOW", MV_TAI_TRIGGER_GENERATION_TOD_SEC_LOW_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_NANO_HIGH", MV_TAI_TRIGGER_GENERATION_TOD_NANO_HIGH_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_NANO_LOW", MV_TAI_TRIGGER_GENERATION_TOD_NANO_LOW_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_FRAC_HIGH", MV_TAI_TRIGGER_GENERATION_TOD_FRAC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TRIGGER_GENERATION_TOD_FRAC_LOW", MV_TAI_TRIGGER_GENERATION_TOD_FRAC_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_SEC_HIGH", MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_SEC_MED", MV_TAI_TIME_LOAD_VALUE_SEC_MED_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_SEC_LOW", MV_TAI_TIME_LOAD_VALUE_SEC_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_NANO_HIGH", MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_NANO_LOW", MV_TAI_TIME_LOAD_VALUE_NANO_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_FRAC_HIGH", MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_LOAD_VALUE_FRAC_LOW", MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_REG);
+
+	/* Read STATUS first since it is cleared after VALUExx reading */
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_STATUS", MV_TAI_TIME_CAPTURE_STATUS_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_SEC_HIGH", MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_SEC_MED", MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_SEC_LOW", MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_NANO_HIGH", MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_NANO_LOW", MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_FRAC_HIGH", MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_0_FRAC_LOW", MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_SEC_HIGH", MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_SEC_MED", MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_SEC_LOW", MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_NANO_HIGH", MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_NANO_LOW", MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_FRAC_HIGH", MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_REG);
+	mv_pp3_ptp_reg_print("TIME_CAPTURE_VALUE_1_FRAC_LOW", MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_REG);
+
+	mv_pp3_ptp_reg_print("TIME_UPDATE_CNTR_LSB", MV_TAI_TIME_UPDATE_CNTR_LSB_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_SEC_HIGH", MV_TAI_GENERATE_FUNCTION_MASK_SEC_HIGH_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_SEC_MED", MV_TAI_GENERATE_FUNCTION_MASK_SEC_MED_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_SEC_LOW", MV_TAI_GENERATE_FUNCTION_MASK_SEC_LOW_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_NANO_HIGH", MV_TAI_GENERATE_FUNCTION_MASK_NANO_HIGH_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_NANO_LOW", MV_TAI_GENERATE_FUNCTION_MASK_NANO_LOW_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_FRAC_HIGH", MV_TAI_GENERATE_FUNCTION_MASK_FRAC_HIGH_REG);
+	mv_pp3_ptp_reg_print("GENERATE_FUNCTION_MASK_FRAC_LOW", MV_TAI_GENERATE_FUNCTION_MASK_FRAC_LOW_REG);
+	mv_pp3_ptp_reg_print("DRIFT_ADJUSTMENT_CFG_HIGH", MV_TAI_DRIFT_ADJUSTMENT_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("DRIFT_ADJUSTMENT_CFG_LOW", MV_TAI_DRIFT_ADJUSTMENT_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("CAPTURE_TRIGGER_CNTR", MV_TAI_CAPTURE_TRIGGER_CNTR_REG);
+	mv_pp3_ptp_reg_print("PCLK_CLOCK_CYCLE_CFG_HIGH", MV_TAI_PCLK_CLOCK_CYCLE_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("PCLK_CLOCK_CYCLE_CFG_LOW", MV_TAI_PCLK_CLOCK_CYCLE_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("DRIFT_THR_CFG_HIGH", MV_TAI_DRIFT_THR_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("DRIFT_THR_CFG_LOW", MV_TAI_DRIFT_THR_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("CLOCK_CYCLE_CFG_HIGH", MV_TAI_CLOCK_CYCLE_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("CLOCK_CYCLE_CFG_LOW", MV_TAI_CLOCK_CYCLE_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH",
+		MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH_REG);
+	mv_pp3_ptp_reg_print("EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW",
+		MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("INCOMING_CLOCKIN_CNTING_EN", MV_TAI_INCOMING_CLOCKIN_CNTING_EN_REG);
+	mv_pp3_ptp_reg_print("INCOMING_CLOCKIN_CNTING_CFG_LOW", MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_REG);
+	mv_pp3_ptp_reg_print("TIME_UPDATE_CNTR_MSB", MV_TAI_TIME_UPDATE_CNTR_MSB_REG);
+	mv_pp3_ptp_reg_print("INCOMING_CLOCKIN_CNTING_CFG_HIGH", MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_HIGH_REG);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_regs.h
new file mode 100644
index 0000000..ee1f3d2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_ptp_regs.h
@@ -0,0 +1,330 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef _mv_ptp_regs_h_
+#define _mv_ptp_regs_h_
+
+#ifdef __KERNEL__
+/* includes */
+#include "common/mv_hw_if.h"
+#else
+/* This "mv_*_regs.h is also included in User-space UIO */
+#endif
+
+/* unit offset (there are TAI & PTP which are the one same HW) */
+#define MV_PP3_PTP_TAI_UNIT_OFFSET		0x03180000
+#define MV_PP3_PTP_UNIT_OFFSET		MV_PP3_PTP_TAI_UNIT_OFFSET
+
+/* Ptp Interrupt Cause (Timestamp status) */
+#define MV_PTP_INT_STATUS_TS_REG(port)			(port * 0x1000 + 0x0800)
+#define MV_PTP_INT_STATUS_TS_Q1_FULL_OFFS		8
+#define MV_PTP_INT_STATUS_TS_Q0_FULL_OFFS		7
+#define MV_PTP_INT_STATUS_TS_Q1_NEW_OFFS		6
+#define MV_PTP_INT_STATUS_TS_Q0_NEW_OFFS		5
+#define MV_PTP_INT_STATUS_TS_Q1_RX_WR_ERR_OFFS		4
+#define MV_PTP_INT_STATUS_TS_Q0_RX_RD_ERR_OFFS		3
+#define MV_PTP_INT_STATUS_TS_Q1_RX_FULL_OFFS		2
+#define MV_PTP_INT_STATUS_TS_Q0_RX_FULL_OFFS		1
+
+#define MV_PTP_INT_STATUS_TS_Q1_FULL_MASK      (1 << MV_PTP_INT_STATUS_TS_Q1_FULL_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q0_FULL_MASK      (1 << MV_PTP_INT_STATUS_TS_Q0_FULL_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q1_NEW_MASK       (1 << MV_PTP_INT_STATUS_TS_Q1_NEW_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q0_NEW_MASK       (1 << MV_PTP_INT_STATUS_TS_Q0_NEW_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q1_RX_WR_ERR_MASK (1 << MV_PTP_INT_STATUS_TS_Q1_RX_WR_ERR_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q0_RX_RD_ERR_MASK (1 << MV_PTP_INT_STATUS_TS_Q0_RX_RD_ERR_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q1_RX_FULL_MASK   (1 << MV_PTP_INT_STATUS_TS_Q1_RX_FULL_OFFS)
+#define MV_PTP_INT_STATUS_TS_Q0_RX_FULL_MASK   (1 << MV_PTP_INT_STATUS_TS_Q0_RX_FULL_OFFS)
+
+
+/* Ptp General Control */
+#define MV_PTP_GENERAL_CTRL_REG(port)						(port * 0x1000 + 0x0808)
+#define MV_PTP_GENERAL_CTRL_PTP_UNIT_ENABLE_OFFS		0
+#define MV_PTP_GENERAL_CTRL_PTP_UNIT_ENABLE_MASK    \
+		(0x00000001 << MV_PTP_GENERAL_CTRL_PTP_UNIT_ENABLE_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_PTP_RESET_OFFS		1
+#define MV_PTP_GENERAL_CTRL_PTP_RESET_MASK    \
+		(0x00000001 << MV_PTP_GENERAL_CTRL_PTP_RESET_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_INTERFACE_WIDTH_SELECT_OFFS		2
+#define MV_PTP_GENERAL_CTRL_INTERFACE_WIDTH_SELECT_MASK    \
+		(0x00000003 << MV_PTP_GENERAL_CTRL_INTERFACE_WIDTH_SELECT_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_CLEAR_COUNTERS_OFFS		4
+#define MV_PTP_GENERAL_CTRL_CLEAR_COUNTERS_MASK    \
+		(0x00000001 << MV_PTP_GENERAL_CTRL_CLEAR_COUNTERS_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_TAI_SELECT_OFFS		5
+#define MV_PTP_GENERAL_CTRL_TAI_SELECT_MASK    \
+		(0x00000001 << MV_PTP_GENERAL_CTRL_TAI_SELECT_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_TS_QUEUE_OVER_WRITE_ENABLE_OFFS		6
+#define MV_PTP_GENERAL_CTRL_TS_QUEUE_OVER_WRITE_ENABLE_MASK    \
+		(0x00000001 << MV_PTP_GENERAL_CTRL_TS_QUEUE_OVER_WRITE_ENABLE_OFFS)
+
+#define MV_PTP_GENERAL_CTRL_TAI_ACK_DELAY_OFFS		7
+#define MV_PTP_GENERAL_CTRL_TAI_ACK_DELAY_MASK    \
+		(0x0000001f << MV_PTP_GENERAL_CTRL_TAI_ACK_DELAY_OFFS)
+
+
+/* Ptp Tx Timestamp Queue0 Reg0 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_REG(port)					(port * 0x1000 + 0x080c)
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_PTP_TX_TIMESTAMP_QUEUE0_VALID_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_PTP_TX_TIMESTAMP_QUEUE0_VALID_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_PTP_TX_TIMESTAMP_QUEUE0_VALID_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_QUEUE_ID_OFFS		1
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_QUEUE_ID_MASK    \
+		(0x000003ff << MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_QUEUE_ID_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TAI_SELECT_OFFS		11
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TAI_SELECT_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TAI_SELECT_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TOD_UPDATE_FLAG_OFFS		12
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TOD_UPDATE_FLAG_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TOD_UPDATE_FLAG_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TIMESTAMP_BITS_0_2_OFFS		13
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TIMESTAMP_BITS_0_2_MASK    \
+		(0x00000007 << MV_PTP_TX_TIMESTAMP_QUEUE0_REG0_TIMESTAMP_BITS_0_2_OFFS)
+
+
+/* Ptp Tx Timestamp Queue0 Reg1 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG1_REG(port)					(port * 0x1000 + 0x0810)
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG1_TIMESTAMP_BITS_3_18_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG1_TIMESTAMP_BITS_3_18_MASK    \
+		(0x0000ffff << MV_PTP_TX_TIMESTAMP_QUEUE0_REG1_TIMESTAMP_BITS_3_18_OFFS)
+
+
+/* Ptp Tx Timestamp Queue0 Reg2 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG2_REG(port)					(port * 0x1000 + 0x0814)
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG2_TIMESTAMP_BITS_19_31_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE0_REG2_TIMESTAMP_BITS_19_31_MASK    \
+		(0x00001fff << MV_PTP_TX_TIMESTAMP_QUEUE0_REG2_TIMESTAMP_BITS_19_31_OFFS)
+
+
+/* Ptp Tx Timestamp Queue1 Reg0 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_REG(port)					(port * 0x1000 + 0x0818)
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_PTP_TX_TIMESTAMP_QUEUE1_VALID_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_PTP_TX_TIMESTAMP_QUEUE1_VALID_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_PTP_TX_TIMESTAMP_QUEUE1_VALID_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_QUEUE_ID_OFFS		1
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_QUEUE_ID_MASK    \
+		(0x000003ff << MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_QUEUE_ID_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TAI_SELECT_OFFS		11
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TAI_SELECT_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TAI_SELECT_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TOD_UPDATE_FLAG_OFFS		12
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TOD_UPDATE_FLAG_MASK    \
+		(0x00000001 << MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TOD_UPDATE_FLAG_OFFS)
+
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TIMESTAMP_BITS_0_2_OFFS		13
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TIMESTAMP_BITS_0_2_MASK    \
+		(0x00000007 << MV_PTP_TX_TIMESTAMP_QUEUE1_REG0_TIMESTAMP_BITS_0_2_OFFS)
+
+
+/* Ptp Tx Timestamp Queue1 Reg1 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG1_REG(port)					(port * 0x1000 + 0x081c)
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG1_TIMESTAMP_BITS_3_18_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG1_TIMESTAMP_BITS_3_18_MASK    \
+		(0x0000ffff << MV_PTP_TX_TIMESTAMP_QUEUE1_REG1_TIMESTAMP_BITS_3_18_OFFS)
+
+
+/* Ptp Tx Timestamp Queue1 Reg2 */
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG2_REG(port)					(port * 0x1000 + 0x0820)
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG2_TIMESTAMP_BITS_19_31_OFFS		0
+#define MV_PTP_TX_TIMESTAMP_QUEUE1_REG2_TIMESTAMP_BITS_19_31_MASK    \
+		(0x00001fff << MV_PTP_TX_TIMESTAMP_QUEUE1_REG2_TIMESTAMP_BITS_19_31_OFFS)
+
+
+/* Total Ptp Packets Counter */
+#define MV_PTP_TOTAL_PTP_PCKTS_CNTR_REG(port)						(port * 0x1000 + 0x0824)
+#define MV_PTP_TOTAL_PTP_PCKTS_CNTR_TOTAL_PTP_PACKETS_COUNTER_OFFS		0
+#define MV_PTP_TOTAL_PTP_PCKTS_CNTR_TOTAL_PTP_PACKETS_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_TOTAL_PTP_PCKTS_CNTR_TOTAL_PTP_PACKETS_COUNTER_OFFS)
+
+
+/* Ptpv1 Packet Counter */
+#define MV_PTP_PTPV1_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x0828)
+#define MV_PTP_PTPV1_PCKT_CNTR_PTPV1_PACKET_COUNTER_OFFS		0
+#define MV_PTP_PTPV1_PCKT_CNTR_PTPV1_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_PTPV1_PCKT_CNTR_PTPV1_PACKET_COUNTER_OFFS)
+
+
+/* Ptpv2 Packet Counter */
+#define MV_PTP_PTPV2_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x082c)
+#define MV_PTP_PTPV2_PCKT_CNTR_PTPV2_PACKET_COUNTER_OFFS		0
+#define MV_PTP_PTPV2_PCKT_CNTR_PTPV2_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_PTPV2_PCKT_CNTR_PTPV2_PACKET_COUNTER_OFFS)
+
+
+/* Y1731 Packet Counter */
+#define MV_PTP_Y1731_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x0830)
+#define MV_PTP_Y1731_PCKT_CNTR_Y1731_PACKET_COUNTER_OFFS		0
+#define MV_PTP_Y1731_PCKT_CNTR_Y1731_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_Y1731_PCKT_CNTR_Y1731_PACKET_COUNTER_OFFS)
+
+
+/* Ntpts Packet Counter */
+#define MV_PTP_NTPTS_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x0834)
+#define MV_PTP_NTPTS_PCKT_CNTR_NTPTS_PACKET_COUNTER_OFFS		0
+#define MV_PTP_NTPTS_PCKT_CNTR_NTPTS_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_NTPTS_PCKT_CNTR_NTPTS_PACKET_COUNTER_OFFS)
+
+
+/* Ntpreceive Packet Counter */
+#define MV_PTP_NTPRECEIVE_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x0838)
+#define MV_PTP_NTPRECEIVE_PCKT_CNTR_NTPRX_PACKET_COUNTER_OFFS		0
+#define MV_PTP_NTPRECEIVE_PCKT_CNTR_NTPRX_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_NTPRECEIVE_PCKT_CNTR_NTPRX_PACKET_COUNTER_OFFS)
+
+
+/* Ntptransmit Packet Counter */
+#define MV_PTP_NTPTRANSMIT_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x083c)
+#define MV_PTP_NTPTRANSMIT_PCKT_CNTR_NTPTX_PACKET_COUNTER_OFFS		0
+#define MV_PTP_NTPTRANSMIT_PCKT_CNTR_NTPTX_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_NTPTRANSMIT_PCKT_CNTR_NTPTX_PACKET_COUNTER_OFFS)
+
+
+/* Wamp Packet Counter */
+#define MV_PTP_WAMP_PCKT_CNTR_REG(port)							(port * 0x1000 + 0x0840)
+#define MV_PTP_WAMP_PCKT_CNTR_WAMP_PACKET_COUNTER_OFFS		0
+#define MV_PTP_WAMP_PCKT_CNTR_WAMP_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_WAMP_PCKT_CNTR_WAMP_PACKET_COUNTER_OFFS)
+
+
+/* None Action Packet Counter */
+#define MV_PTP_NONE_ACTION_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x0844)
+#define MV_PTP_NONE_ACTION_PCKT_CNTR_NONE_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_NONE_ACTION_PCKT_CNTR_NONE_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_NONE_ACTION_PCKT_CNTR_NONE_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Forward Action Packet Counter */
+#define MV_PTP_FORWARD_ACTION_PCKT_CNTR_REG(port)					(port * 0x1000 + 0x0848)
+#define MV_PTP_FORWARD_ACTION_PCKT_CNTR_FORWARD_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_FORWARD_ACTION_PCKT_CNTR_FORWARD_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_FORWARD_ACTION_PCKT_CNTR_FORWARD_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Drop Action Packet Counter */
+#define MV_PTP_DROP_ACTION_PCKT_CNTR_REG(port)						(port * 0x1000 + 0x084c)
+#define MV_PTP_DROP_ACTION_PCKT_CNTR_DROP_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_DROP_ACTION_PCKT_CNTR_DROP_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_DROP_ACTION_PCKT_CNTR_DROP_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Capture Action Packet Counter */
+#define MV_PTP_CAPTURE_ACTION_PCKT_CNTR_REG(port)					(port * 0x1000 + 0x0850)
+#define MV_PTP_CAPTURE_ACTION_PCKT_CNTR_CAPTURE_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_CAPTURE_ACTION_PCKT_CNTR_CAPTURE_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_CAPTURE_ACTION_PCKT_CNTR_CAPTURE_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Addtime Action Packet Counter */
+#define MV_PTP_ADDTIME_ACTION_PCKT_CNTR_REG(port)					(port * 0x1000 + 0x0854)
+#define MV_PTP_ADDTIME_ACTION_PCKT_CNTR_ADDTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_ADDTIME_ACTION_PCKT_CNTR_ADDTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_ADDTIME_ACTION_PCKT_CNTR_ADDTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Addcorrectedtime Action Packet Counter */
+#define MV_PTP_ADDCORRECTEDTIME_ACTION_PCKT_CNTR_REG(port)				(port * 0x1000 + 0x0858)
+#define MV_PTP_ADDCORRECTEDTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_ADDCORRECTEDTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_ADDCORRECTEDTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Captureaddtime Action Packet Counter */
+#define MV_PTP_CAPTUREADDTIME_ACTION_PCKT_CNTR_REG(port)				(port * 0x1000 + 0x085c)
+#define MV_PTP_CAPTUREADDTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_CAPTUREADDTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_CAPTUREADDTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Captureaddcorrectedtime Action Packet Counter */
+#define MV_PTP_CAPTUREADDCORRECTEDTIME_ACTION_PCKT_CNTR_REG(port)			(port * 0x1000 + 0x0860)
+#define MV_PTP_CAPTUREADDCORRECTEDTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_CAPTUREADDCORRECTEDTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_CAPTUREADDCORRECTEDTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Addingresstime Action Packet Counter */
+#define MV_PTP_ADDINGRESSTIME_ACTION_PCKT_CNTR_REG(port)				(port * 0x1000 + 0x0864)
+#define MV_PTP_ADDINGRESSTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_ADDINGRESSTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_ADDINGRESSTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Captureaddingresstime Action Packet Counter */
+#define MV_PTP_CAPTUREADDINGRESSTIME_ACTION_PCKT_CNTR_REG(port)				(port * 0x1000 + 0x0868)
+#define MV_PTP_CAPTUREADDINGRESSTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_CAPTUREADDINGRESSTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_CAPTUREADDINGRESSTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Captureingresstime Action Packet Counter */
+#define MV_PTP_CAPTUREINGRESSTIME_ACTION_PCKT_CNTR_REG(port)				(port * 0x1000 + 0x086c)
+#define MV_PTP_CAPTUREINGRESSTIME_ACTION_PACKET_COUNTER_OFFS		0
+#define MV_PTP_CAPTUREINGRESSTIME_ACTION_PACKET_COUNTER_MASK    \
+		(0x000000ff << MV_PTP_CAPTUREINGRESSTIME_ACTION_PACKET_COUNTER_OFFS)
+
+
+/* Ntp Ptp Offset High */
+#define MV_PTP_NTP_PTP_OFFSET_HIGH_REG(port)						(port * 0x1000 + 0x0870)
+#define MV_PTP_NTP_PTP_OFFSET_HIGH_PTP_NTP_OFFSET_HIGH_OFFS		0
+#define MV_PTP_NTP_PTP_OFFSET_HIGH_PTP_NTP_OFFSET_HIGH_MASK    \
+		(0x0000ffff << MV_PTP_NTP_PTP_OFFSET_HIGH_PTP_NTP_OFFSET_HIGH_OFFS)
+
+
+/* Ntp Ptp Offset Low */
+#define MV_PTP_NTP_PTP_OFFSET_LOW_REG(port)						(port * 0x1000 + 0x0874)
+#define MV_PTP_NTP_PTP_OFFSET_LOW_PTP_NTP_OFFSET_LOW_OFFS		0
+#define MV_PTP_NTP_PTP_OFFSET_LOW_PTP_NTP_OFFSET_LOW_MASK    \
+		(0x0000ffff << MV_PTP_NTP_PTP_OFFSET_LOW_PTP_NTP_OFFSET_LOW_OFFS)
+
+/*                       Register acceess Functions                           */
+/******************************************************************************/
+
+#ifdef __KERNEL__
+static inline u32 mv_pp3_ptp_reg_read(u32 reg_addr)
+{
+	return mv_gop_reg_read(reg_addr + MV_PP3_PTP_UNIT_OFFSET);
+}
+
+static inline void mv_pp3_ptp_reg_write(u32 reg_addr, u32 reg_data)
+{
+	return mv_gop_reg_write(reg_addr + MV_PP3_PTP_UNIT_OFFSET, reg_data);
+}
+
+#endif/*__KERNEL__*/
+#endif /* _mv_ptp_regs_h_ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_smi.c b/drivers/net/ethernet/marvell/pp3/gop/mv_smi.c
new file mode 100644
index 0000000..9b0cc47
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_smi.c
@@ -0,0 +1,56 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_smi_regs.h"
+
+
+/*******************************************************************************
+* mv_gop_smi_init
+*******************************************************************************/
+int mv_gop_smi_init(void)
+{
+	u32 val;
+
+	/* not invert MDC */
+	val = mv_gop_reg_read(MV_SMI_MISC_CFG_REG);
+	val &= ~MV_SMI_MISC_CFG_INVERT_MDC_MASK;
+	mv_gop_reg_write(MV_SMI_MISC_CFG_REG, val);
+
+	return 0;
+}
+
+/*******************************************************************************
+* mv_gop_phy_addr_cfg
+*******************************************************************************/
+int mv_gop_phy_addr_cfg(int port, int addr)
+{
+	mv_gop_reg_write(MV_SMI_PHY_ADDRESS_REG(port), addr);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_smi.h b/drivers/net/ethernet/marvell/pp3/gop/mv_smi.h
new file mode 100644
index 0000000..d875380
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_smi.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gop_smi_h__
+#define __mv_gop_smi_h__
+
+#include <linux/kernel.h>
+
+int mv_gop_smi_init(void);
+int mv_gop_phy_addr_cfg(int port, int addr);
+
+#endif /* __mv_gop_smi_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_smi_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mv_smi_regs.h
new file mode 100644
index 0000000..8a87ebc
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_smi_regs.h
@@ -0,0 +1,154 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_smi_regs_h__
+#define __mv_smi_regs_h__
+
+/* includes */
+
+
+/* SMI_MANAGEMENT Register */
+#define MV_SMI_MANAGEMENT_REG					(0x5000000)
+
+#define MV_SMI_MANAGEMENT_BUSY_OFFS						28
+#define MV_SMI_MANAGEMENT_BUSY_MASK						\
+	(0x1 << MV_SMI_MANAGEMENT_BUSY_OFFS)
+#define MV_SMI_MANAGEMENT_READ_VALID_OFFS					27
+#define MV_SMI_MANAGEMENT_READ_VALID_MASK					\
+	(0x1 << MV_SMI_MANAGEMENT_READ_VALID_OFFS)
+#define MV_SMI_MANAGEMENT_OPCODE_OFFS					26
+#define MV_SMI_MANAGEMENT_OPCODE_MASK					\
+	(0x1 << MV_SMI_MANAGEMENT_OPCODE_OFFS)
+#define MV_SMI_MANAGEMENT_REGAD_OFFS					21
+#define MV_SMI_MANAGEMENT_REGAD_MASK					\
+	(0x1F << MV_SMI_MANAGEMENT_REGAD_OFFS)
+#define MV_SMI_MANAGEMENT_PHYAD_OFFS					16
+#define MV_SMI_MANAGEMENT_PHYAD_MASK					\
+	(0x1F << MV_SMI_MANAGEMENT_PHYAD_OFFS)
+#define MV_SMI_MANAGEMENT_DATA_OFFS						0
+#define MV_SMI_MANAGEMENT_DATA_MASK						\
+	(0xFFFF << MV_SMI_MANAGEMENT_DATA_OFFS)
+
+/* SMI_MISC_CFG Register */
+#define MV_SMI_MISC_CFG_REG							(0x5000004)
+
+#define MV_SMI_MISC_CFG_SMI_ACCELERATE_OFFS					0
+#define MV_SMI_MISC_CFG_SMI_ACCELERATE_MASK					\
+	(0x1 << MV_SMI_MISC_CFG_SMI_ACCELERATE_OFFS)
+#define MV_SMI_MISC_CFG_SMI_FASTMDC_OFFS					1
+#define MV_SMI_MISC_CFG_SMI_FASTMDC_MASK					\
+	(0x1 << MV_SMI_MISC_CFG_SMI_FASTMDC_OFFS)
+#define MV_SMI_MISC_CFG_FAST_MDC_DIVISION_SELECTOR_OFFS			2
+#define MV_SMI_MISC_CFG_FAST_MDC_DIVISION_SELECTOR_MASK			\
+	(0x3 << MV_SMI_MISC_CFG_FAST_MDC_DIVISION_SELECTOR_OFFS)
+#define MV_SMI_MISC_CFG_ENABLE_MDIO_OUT_LATENCY_OFFS			4
+#define MV_SMI_MISC_CFG_ENABLE_MDIO_OUT_LATENCY_MASK			\
+	(0x1 << MV_SMI_MISC_CFG_ENABLE_MDIO_OUT_LATENCY_OFFS)
+#define MV_SMI_MISC_CFG_AUTOPOLLNUMOFPORTS_OFFS				5
+#define MV_SMI_MISC_CFG_AUTOPOLLNUMOFPORTS_MASK				\
+	(0x1F << MV_SMI_MISC_CFG_AUTOPOLLNUMOFPORTS_OFFS)
+#define MV_SMI_MISC_CFG_ENABLE_POLLING_OFFS					10
+#define MV_SMI_MISC_CFG_ENABLE_POLLING_MASK					\
+	(0x1 << MV_SMI_MISC_CFG_ENABLE_POLLING_OFFS)
+#define MV_SMI_MISC_CFG_INVERT_MDC_OFFS					11
+#define MV_SMI_MISC_CFG_INVERT_MDC_MASK					\
+	(0x1 << MV_SMI_MISC_CFG_INVERT_MDC_OFFS)
+
+/* PHY_AN_CFG Register */
+#define MV_SMI_PHY_AN_CFG_REG							(0x5000008)
+
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT0_OFFS					0
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT0_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT0_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT1_OFFS					1
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT1_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT1_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT2_OFFS					2
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT2_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT2_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT3_OFFS					3
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT3_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT3_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT4_OFFS					4
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT4_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT4_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT5_OFFS					5
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT5_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT5_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT6_OFFS					6
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT6_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT6_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT7_OFFS					7
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT7_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT7_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT8_OFFS					8
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT8_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT8_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT9_OFFS					9
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT9_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT9_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT10_OFFS				10
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT10_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT10_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT11_OFFS				11
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT11_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT11_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT12_OFFS				12
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT12_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT12_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT13_OFFS				13
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT13_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT13_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT14_OFFS				14
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT14_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT14_OFFS)
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT15_OFFS				15
+#define MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT15_MASK				\
+	(0x1 << MV_SMI_PHY_AN_CFG_AUTOMEDIA_SELECTEN_PORT15_OFFS)
+#define MV_SMI_PHY_AN_CFG_SKIPSWRESET_SMI_OFFS					16
+#define MV_SMI_PHY_AN_CFG_SKIPSWRESET_SMI_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_SKIPSWRESET_SMI_OFFS)
+#define MV_SMI_PHY_AN_CFG_STOP_AUTONEGSMI_OFFS					17
+#define MV_SMI_PHY_AN_CFG_STOP_AUTONEGSMI_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_STOP_AUTONEGSMI_OFFS)
+#define MV_SMI_PHY_AN_CFG_MASTERSMI_OFFS					18
+#define MV_SMI_PHY_AN_CFG_MASTERSMI_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_MASTERSMI_OFFS)
+#define MV_SMI_PHY_AN_CFG_SGMIIINBANDFCEN_OFFS					19
+#define MV_SMI_PHY_AN_CFG_SGMIIINBANDFCEN_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_SGMIIINBANDFCEN_OFFS)
+#define MV_SMI_PHY_AN_CFG_FCADVSETFIBER_OFFS					20
+#define MV_SMI_PHY_AN_CFG_FCADVSETFIBER_MASK					\
+	(0x1 << MV_SMI_PHY_AN_CFG_FCADVSETFIBER_OFFS)
+
+/* PHY_ADDRESS_REGISTER0 Register */
+#define MV_SMI_PHY_ADDRESS_REG(n)						(0x500000C + 0x4*n)
+#define MV_SMI_PHY_ADDRESS_PHYAD_OFFS						0
+#define MV_SMI_PHY_ADDRESS_PHYAD_MASK						\
+	(0x1F << MV_SMI_PHY_ADDRESS_PHYAD_OFFS)
+
+#endif /* __mv_smi_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_tai_clock.c b/drivers/net/ethernet/marvell/pp3/gop/mv_tai_clock.c
new file mode 100644
index 0000000..80f5d58
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_tai_clock.c
@@ -0,0 +1,558 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2016 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/**************************************************************************
+**
+**  This file implements HW->SW workaround
+**  needed for sync from External 1PPS signal coming from GPS
+**  (e.g. for "Sync TAI clock from GPS" is on PTP GRAND-MASTER system).
+**  If PTP GRAND-MASTER is not required, the code has no any impact
+**
+***************************************************************************
+*/
+
+/* includes */
+#include <linux/kernel.h>
+#include <linux/timer.h>
+#include <linux/gpio.h>
+
+#include "gop/mv_ptp_if.h"
+#include "net_dev/mv_ptp_service.h"
+
+#include <linux/err.h>
+#include <linux/pinctrl/consumer.h>
+
+#define DFLT_CLOCK_IS_EXTERNAL	true /* true or false */
+
+#define MV_PTP_EVENT_MPP_DTB_STRING	"ptp-event-pin"
+#define MV_PTP_EVENT_DEV_DTB_STRING	"ptp-event"
+#define MV_PTP_1PPS_LED_DTB_STRING	"ptp-1pps-led"
+
+#define MV_PTP_GPS_DOWN2UP_PULSES	2
+#define MSEC_1PPS_D(DELTA)	(jiffies + msecs_to_jiffies(1000 + (DELTA)))
+#define MSEC_DELAY(MSEC)	(jiffies + msecs_to_jiffies(MSEC))
+/* MSEC_BEFORE_1PPS should be shortest but enough for finishing all
+ * contexts' jobs (even under high-loaded CPU) before 1PPS occurred
+ */
+#define MSEC_BEFORE_1PPS	20
+
+enum mv_ptp_event_clock_state {
+	PTP_CLK_FREE_RUN = 0,
+	PTP_CLK_SYNC_START,
+	PTP_CLK_SYNC_START_TIMER,
+	PTP_CLK_HW_SYNC,
+	PTP_CLK_GPS_UP,
+	PTP_CLK_GPS_DOWN,
+};
+
+struct mv_ptp_event {
+	const char *name;
+
+	struct pinctrl *pinctrl;
+	struct pinctrl_state *pin_gpio_state;
+	struct pinctrl_state *pin_ptp_state;
+
+	unsigned gpio;
+	int gpio2irq;
+	bool gpio_irq_engaged;
+
+	enum mv_ptp_event_clock_state state;
+	int state_cntr;
+	bool gps_up_already_printed;
+	struct work_struct work_q;
+	struct timer_list timer;
+
+	u32 sec;   /* Absolute set seconds to TAI/ToD */
+	int d_sec; /* Relative Inc/Dec delta to TAI/ToD */
+	/* if both are 0 - only sync without set requested */
+	/* if both are 1 - sync but try to keep current ToD */
+
+	unsigned led;
+	int led_val;
+};
+
+struct mv_ptp_event mv_ptp_event;
+
+
+/***************************************************************************/
+int mv_pp3_ptp_event_led_sysfs(unsigned led_gpio)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	if (ev->led) {
+		pr_info("%s: GPIO-1PPS led is already on pin %d\n", PTP_TAI_PRT_STR, ev->led);
+		return -EINVAL;
+	}
+	if (!gpio_request_one(led_gpio, GPIOF_DIR_OUT, ev->name)) {
+		gpio_direction_output(led_gpio, ev->led_val);
+		ev->led = led_gpio; /* this must be last */
+	} else {
+		pr_info("%s: GPIO-1PPS led config failed\n", PTP_TAI_PRT_STR);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static inline void ptp_event_led_init(struct platform_device *pdev)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	struct device_node *np = pdev->dev.of_node;
+	if (of_property_read_u32(np, MV_PTP_1PPS_LED_DTB_STRING, &ev->led))
+		return;
+	if (!ev->led)
+		return; /* Zero is invalid parameter */
+	if (!gpio_request_one(ev->led, GPIOF_DIR_OUT, ev->name))
+		gpio_direction_output(ev->led, ev->led_val);
+	else
+		ev->led = 0;
+}
+
+static inline void ptp_event_led_blink(struct mv_ptp_event *ev, int req)
+{
+	int val;
+	if (ev->led) {
+		val = (req < 0) ? ~ev->led_val : !!(req);
+		ev->led_val = val;
+		gpio_set_value(ev->led, val);
+	}
+}
+
+/***************************************************************************/
+static irqreturn_t ptp_gpio_isr(int irq, void *data)
+{
+	struct mv_ptp_event *ev = data;
+	if (!ev->gpio_irq_engaged)
+		return IRQ_HANDLED;
+
+	switch (ev->state) {
+	case PTP_CLK_SYNC_START:
+		ev->state = PTP_CLK_SYNC_START_TIMER;
+		mod_timer(&ev->timer, MSEC_1PPS_D(-MSEC_BEFORE_1PPS));
+		break;
+	case PTP_CLK_GPS_UP:
+		/* Restart GPS-Up watchdog  */
+		mod_timer(&ev->timer, MSEC_1PPS_D(30));
+		ptp_event_led_blink(ev, -1); /*toggle*/
+		break;
+	case PTP_CLK_GPS_DOWN:
+		/* GPS Up-and-Down timer */
+		mod_timer(&ev->timer, MSEC_1PPS_D(20));
+		schedule_work(&ev->work_q);
+		break;
+	default: /* ignore _FREE_RUN, _SYNC_START_TIMER, _HW_SYNC */
+		break;
+	}
+	return IRQ_HANDLED;
+}
+
+static int ptp_event_ptp_gpioirq(int ptp_hw, int gpio_irq)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	int ret = 0;
+
+	if (ptp_hw && gpio_irq)
+		ptp_hw = gpio_irq = 0;
+
+	/* Clean pending irq by pair free_irq/request_irq */
+	if (ev->gpio_irq_engaged) {
+		ev->gpio_irq_engaged = false;
+		free_irq(ev->gpio2irq, &mv_ptp_event);
+	}
+	if (ptp_hw)
+		pinctrl_select_state(ev->pinctrl, ev->pin_ptp_state);
+	else
+		pinctrl_select_state(ev->pinctrl, ev->pin_gpio_state);
+
+	if (!ptp_hw && gpio_irq) {
+		ev->gpio_irq_engaged = false;
+		ret = request_irq(ev->gpio2irq,
+					ptp_gpio_isr,
+					IRQF_TRIGGER_RISING,
+					ev->name,
+					ev);
+		ev->gpio_irq_engaged = !ret;
+		if (ret)
+			pr_err("%s: event request_irq failed\n", PTP_TAI_PRT_STR);
+	}
+	return ret;
+}
+
+/***************************************************************************/
+static void ptp_tai_tod_set_synchronous(u32 sec, int d_sec)
+{
+	/* This one is called only in very specific time -
+	 * just before expected (next) 1PPS signal obtaining
+	 */
+	struct mv_pp3_tai_tod ts;
+	int clock_restart;
+
+	memset(&ts, 0, sizeof(ts));
+
+	if (!sec && !d_sec)
+		sec = 1;
+	clock_restart = (d_sec <= 0) || (d_sec > 2);
+
+	if (sec && !d_sec) {
+		/* Absolute set required */
+		ts.sec_lsb_32b = sec;
+	} else {
+		/* Get current time, reset-sync and set current+delta */
+		mv_pp3_tai_tod_op_read_captured(&ts, NULL); /*cleanup*/
+		mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, &ts, 0);
+		if (sec && d_sec)
+			d_sec = 0; /* keep current requested */
+		ts.sec_lsb_32b += d_sec;
+	}
+	ts.nsec = 1000000000 - 1000;
+	if (clock_restart)
+		mv_pp3_tai_clock_cfg_external(true);
+	mv_pp3_tai_tod_op(MV_TAI_SET_UPDATE, &ts, 1);
+}
+
+/***************************************************************************/
+static void ptp_event_work_cb(struct work_struct *work)
+{
+	/* EVENT threaded state machine driven by timer */
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	enum mv_ptp_event_clock_state curr = ev->state;
+	struct mv_pp3_tai_tod ts;
+	u16 in_cntr_1pps;
+
+	switch (curr) {
+	case PTP_CLK_SYNC_START_TIMER:
+		ptp_tai_tod_set_synchronous(ev->sec, ev->d_sec);
+		/* hw-sync/stabilization takes 3*1PPS cycles */
+		if (ev->sec || ev->d_sec) {
+			ev->state = PTP_CLK_HW_SYNC;
+			mv_pp3_tai_clock_in_cntr_get(NULL); /*cleanup*/
+			ptp_event_ptp_gpioirq(1, 0);
+			/* Pin-function "ptp" but not "gpio" now.
+			 * TAI controlled by HW which could make collision with SW,
+			 * Make this period as short as possible.
+			 * No gpio-irq available, poll clock_in_cntr with 1msec
+			 */
+			ev->state_cntr = MSEC_BEFORE_1PPS * 4;
+			mod_timer(&ev->timer, MSEC_DELAY(1));
+			ev->sec = ev->d_sec = 0;
+			break;
+		} else {
+			ev->state_cntr = -1;
+		}
+		/* fallthrough */
+	case PTP_CLK_HW_SYNC:
+		if (ev->state_cntr > 0) {
+			in_cntr_1pps = mv_pp3_tai_clock_in_cntr_get(NULL);
+			if (!in_cntr_1pps) {
+				mod_timer(&ev->timer, MSEC_DELAY(1));
+				break; /* keep state, continue polling */
+			}
+			/* in_cntr_1pps incremented. Stop polling */
+		} else if (!ev->state_cntr) {
+			pr_warn("%s: guard timer expired\n", PTP_TAI_PRT_STR);
+		}
+		/* NEXT STATE */
+		ev->state = PTP_CLK_GPS_UP;
+		mv_pp3_tai_set_nop();
+		ptp_event_ptp_gpioirq(0, 1);
+		mv_pp3_tai_tod_op_read_captured(&ts, NULL); /*cleanup*/
+		mv_pp3_ptp_reset_all_ptp_ports();
+		mv_pp3_tai_clock_stable_status_set(1); /* Now stable */
+		/* GPS-Up pulse-presence watchdog start */
+		mod_timer(&ev->timer, MSEC_1PPS_D(30));
+		if (!ev->gps_up_already_printed) {
+			ev->gps_up_already_printed = true;
+			pr_info("GPS 1PPS is Up\n");
+			ptp_event_led_blink(ev, 1);
+		}
+		break;
+	case PTP_CLK_GPS_UP:
+		ev->state = PTP_CLK_GPS_DOWN;
+		/* clock is free-running but stable */
+		pr_info("GPS 1PPS is Down\n");
+		ptp_event_led_blink(ev, 0);
+		ev->gps_up_already_printed = false;
+		ev->state_cntr = 0;
+		ptp_event_ptp_gpioirq(0, 1);
+		break;
+	case PTP_CLK_GPS_DOWN:
+		/* Skip some pulses till stable */
+		if (++ev->state_cntr >= MV_PTP_GPS_DOWN2UP_PULSES) {
+			del_timer(&ev->timer);
+			/* 1PPS present again. Restart whole state machine */
+			mv_pp3_tai_clock_stable_status_set(0); /* Now unstable */
+			ev->state = PTP_CLK_SYNC_START;
+			ev->sec = ev->d_sec = 1;
+			ptp_event_ptp_gpioirq(0, 1);
+		}
+		break;
+
+	case PTP_CLK_FREE_RUN:
+	case PTP_CLK_SYNC_START:
+	default:
+		pr_err("%s: event work called on wrong state %d\n",
+			PTP_TAI_PRT_STR, curr);
+		return;
+		break;
+	}
+}
+
+static void ptp_event_timer_cb(unsigned long data)
+{
+	/* EVENT timer-swirq state machine driven by timer and HW isr */
+	struct mv_ptp_event *ev = (struct mv_ptp_event *)data;
+	enum mv_ptp_event_clock_state state = ev->state;
+
+	switch (state) {
+	case PTP_CLK_HW_SYNC:
+		ev->state_cntr--; /*threshold*/
+		schedule_work(&ev->work_q);
+		break;
+
+	case PTP_CLK_SYNC_START_TIMER:
+	case PTP_CLK_GPS_UP:
+		schedule_work(&ev->work_q);
+		break;
+
+	case PTP_CLK_GPS_DOWN:
+		ev->state_cntr = 0; /*failed again */
+		break;
+
+	case PTP_CLK_FREE_RUN:
+		/* Could be upon frequent asynchronous sysfs
+		 * mv_pp3_tai_clock_from_external_sync()
+		 */
+	case PTP_CLK_SYNC_START:
+	default:
+		pr_warn("%s: event timer called on wrong state %d\n",
+			PTP_TAI_PRT_STR, state);
+		break;
+	}
+}
+
+/***************************************************************************/
+static int ptp_event_monitor_start(void)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	int rc;
+
+	if (ev->state != PTP_CLK_FREE_RUN)
+		return 0; /* already done */
+
+	ev->gpio2irq = gpio_to_irq(ev->gpio);
+
+	INIT_WORK(&ev->work_q, ptp_event_work_cb);
+	init_timer(&ev->timer);
+	ev->timer.data = (unsigned long)ev;
+	ev->timer.function = ptp_event_timer_cb;
+
+	/* To disable MPP HW "ptp-event" set MPP to GPIO */
+	rc = gpio_request_one(ev->gpio, GPIOF_DIR_IN, ev->name);
+	if (rc) {
+		pr_err("%s: gpio_request failed\n", PTP_TAI_PRT_STR);
+		return -2;
+	}
+	ptp_event_ptp_gpioirq(0, 0);
+	return 0;
+}
+
+static void ptp_event_monitor_stop(void) /* == deinit */
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+
+	if (ev->state != PTP_CLK_FREE_RUN) {
+		del_timer(&ev->timer);
+		pinctrl_select_state(ev->pinctrl, ev->pin_gpio_state);
+		if (ev->gpio_irq_engaged)
+			free_irq(ev->gpio2irq, &mv_ptp_event);
+		gpio_free(ev->gpio);
+		ev->gpio_irq_engaged = false;
+		ev->state = PTP_CLK_FREE_RUN;
+		ev->gps_up_already_printed = false;
+	}
+}
+
+
+void mv_pp3_tai_clock_from_external_sync(u32 start, u32 sec, int d_sec)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+
+	if (!ev->pinctrl || !ev->gpio) {
+		if (start)
+			pr_info("TAI/ToD: clock sync from external GPS not configured\n");
+		return;
+	}
+	if (start) {
+		/* if both sec/d_sec == 0 - sync without set ToD requested
+		 * if both sec/d_sec == 1 - sync with keep current ToD
+		 */
+		if (d_sec && !mv_pp3_tai_clock_enable_get())
+			d_sec = 0;
+		ev->sec = sec;
+		ev->d_sec = d_sec;
+		ptp_event_monitor_start();
+		ev->state = PTP_CLK_SYNC_START;
+		ptp_event_ptp_gpioirq(0, 1);
+	} else {
+		ptp_event_monitor_stop();
+	}
+}
+
+bool mv_pp3_tai_clock_external_init(struct platform_device *pdev)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	struct device_node *np = pdev->dev.of_node;
+	u32 gpio;
+	bool is_external = DFLT_CLOCK_IS_EXTERNAL;
+	int rc;
+
+	ev->name = MV_PTP_EVENT_DEV_DTB_STRING;
+
+	if (of_property_read_u32(np, MV_PTP_EVENT_MPP_DTB_STRING, &gpio)) {
+		pr_info("%s: \"%s\" name not found in .dtb. Sync from GPS is disabled\n",
+			PTP_TAI_PRT_STR, MV_PTP_EVENT_MPP_DTB_STRING);
+		return false;
+	}
+	ev->gpio = gpio;
+	/* Request (and free) gpio to avoid MPP10 impact */
+	rc = gpio_request_one(ev->gpio, GPIOF_DIR_IN, ev->name);
+	gpio_free(ev->gpio);
+	if (rc) {
+		is_external = false;
+		pr_err("%s: gpio_request failed on init\n", PTP_TAI_PRT_STR);
+	}
+	ptp_event_led_init(pdev);
+	return is_external;
+}
+
+
+void mv_pp3_tai_clock_external_init2(bool from_external)
+{
+	/* Start TAI-ToD with it Linux ToD */
+	static int tod_linux_is_set;
+	struct mv_ptp_event *ev = &mv_ptp_event;
+	struct mv_pp3_tai_tod ts;
+
+	if (!tod_linux_is_set) {
+		tod_linux_is_set = 1;
+		mv_pp3_tai_tod_from_linux(&ts);
+	}
+	if (!ev->pinctrl || !ev->gpio)
+		return;
+
+	if (from_external)
+		mv_pp3_tai_clock_from_external_sync(1, 1, 1);
+}
+
+
+/******************************************************************************
+* PTP-Event is a physical pulse obtained over MV_PTP_EVENT_MPP_DTB_STRING pin.
+*  Whilst the TAI-Clock-External is working it needs MPP function alternating
+*  between "gpio" and "ptp".
+*  This func-alternating is quite non-trivial requiring special Device Tree.
+*  1). It requires 2 sets of pin/function declaration:
+*	pinctrl {
+*		ptp_event_pin_gpio: ptp_event_pin_gpio {
+*			marvell,pins = "mpp10";
+*			marvell,function = "gpio";
+*		};
+*		ptp_event_pin_ptp: ptp_event_pin_ptp {
+*			marvell,pins = "mpp10";
+*			marvell,function = "ptp";
+*		};
+*	};
+*
+*  2). Special pincontrol device to alternate the above sets:
+*	pp3_ptp_event: ptp-event {
+*		compatible = "marvell,ptp-event";
+*		status = "okay";
+*		pinctrl-0 = <&ptp_event_pin_gpio>;
+*		pinctrl-1 = <&ptp_event_pin_ptp>;
+*		pinctrl-names = "gpio", "ptp";
+*	};
+*
+*  3). Device probe making:
+*	pinctrl = devm_pinctrl_get(&pdev->dev);
+*	pin_gpio_state = pinctrl_lookup_state(pinctrl, "gpio");
+*	pin_ptp_state  = pinctrl_lookup_state(pinctrl, "ptp");
+*
+*  4). So finalyy run-time code could alternate by:
+*	pinctrl_select_state(pinctrl, pin_gpio_state);
+*                     or
+*	pinctrl_select_state(pinctrl, pin_ptp_state);
+*
+*  NOTE: if MV_PTP_EVENT_DEV_DTB_STRING="ptp-event" or
+*           MV_PTP_EVENT_MPP_DTB_STRING="ptp-event-pin"
+*  not present in the DTB file, the TAI-Clock-External is disabled
+*  and only TAI-Clock-Internal is available.
+******************************************************************************
+*/
+static int ptp_event_dev(struct platform_device *pdev)
+{
+	struct mv_ptp_event *ev = &mv_ptp_event;
+
+	if (ev->pinctrl)
+		goto err; /* wrong init ordering */
+
+	ev->pinctrl = devm_pinctrl_get(&pdev->dev);
+
+	if (PTR_ERR_OR_ZERO(ev->pinctrl))
+		goto err;
+
+	ev->pin_gpio_state = pinctrl_lookup_state(ev->pinctrl, "gpio");
+	ev->pin_ptp_state  = pinctrl_lookup_state(ev->pinctrl, "ptp");
+	if (PTR_ERR_OR_ZERO(ev->pin_gpio_state) || PTR_ERR_OR_ZERO(ev->pin_ptp_state))
+		goto err;
+
+	pinctrl_select_state(ev->pinctrl, ev->pin_gpio_state);
+	if (DFLT_CLOCK_IS_EXTERNAL)
+		mv_pp3_tai_clock_external_init2(true);
+	return 0;
+
+err:
+	pr_info("%s: cannot init \"%s\". Sync from GPS is disabled\n",
+		PTP_TAI_PRT_STR, MV_PTP_EVENT_DEV_DTB_STRING);
+	ev->pinctrl = NULL;
+	return 0; /* This service is optional => say OK */
+}
+
+
+static const struct of_device_id ptp_event_dev_match[] = {
+	{ .compatible = "marvell," MV_PTP_EVENT_DEV_DTB_STRING },
+	{}
+};
+MODULE_DEVICE_TABLE(of, mv_pp3_shared_match);
+
+static struct platform_driver ptp_event_driver = {
+	.probe		= ptp_event_dev,
+	.driver = {
+		.name	= MV_PTP_EVENT_DEV_DTB_STRING,
+		.owner	= THIS_MODULE,
+		.of_match_table = ptp_event_dev_match,
+	},
+};
+
+static int __init ptp_event_init_module(void)
+{
+	if (platform_driver_register(&ptp_event_driver))
+		pr_err("%s: Can't register %s\n", PTP_TAI_PRT_STR, MV_PTP_EVENT_DEV_DTB_STRING);
+	return 0;
+}
+module_init(ptp_event_init_module);
+
+MODULE_DESCRIPTION("Marvell PPv3 PTP Pin Event driver - www.marvell.com");
+MODULE_AUTHOR("Yan Markman <ymarkman@marvell.com>");
+MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/marvell/pp3/gop/mv_tai_regs.h b/drivers/net/ethernet/marvell/pp3/gop/mv_tai_regs.h
new file mode 100644
index 0000000..9b3eca6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/mv_tai_regs.h
@@ -0,0 +1,593 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef _mv_tai_regs_h_
+#define _mv_tai_regs_h_
+
+#ifdef __KERNEL__
+/* includes */
+#include "common/mv_hw_if.h"
+#else
+/* This "mv_*_regs.h is also included in User-space UIO */
+#endif
+
+/* unit offset (there are TAI & PTP which are the one same HW) */
+#define MV_PP3_PTP_TAI_UNIT_OFFSET		0x03180000
+#define MV_PP3_TAI_UNIT_OFFSET		MV_PP3_PTP_TAI_UNIT_OFFSET
+
+/* Tai Control Reg0 */
+#define MV_TAI_CTRL_REG0_REG								(0x0a08)
+#define MV_TAI_CTRL_REG0_SW_RESET_OFFS		0
+#define MV_TAI_CTRL_REG0_SW_RESET_MASK    \
+		(0x00000001 << MV_TAI_CTRL_REG0_SW_RESET_OFFS)
+
+/* Tai Control Reg1 */
+#define MV_TAI_CTRL_REG1_REG						(0x0a0c)
+#define MV_TAI_CTRL_REG1_TOD_INTERFACE_RATE_OFFS		0
+#define MV_TAI_CTRL_REG1_TOD_INTERFACE_RATE_MASK    \
+		(0x00000007 << MV_TAI_CTRL_REG1_TOD_INTERFACE_RATE_OFFS)
+
+/* Time Counter Function Configuration 0 */
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_REG					(0x0a10)
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_TRIGGER_OFFS		0
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_TRIGGER_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_TRIGGER_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TRIGGER_GENERATE_EN_OFFS		1
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TRIGGER_GENERATE_EN_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_TRIGGER_GENERATE_EN_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_OFFS		2
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_MASK    \
+		(0x00000007 << MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_EN_INCOMING_TRIGGER_CNTING_OFFS		5
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_EN_INCOMING_TRIGGER_CNTING_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_EN_INCOMING_TRIGGER_CNTING_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_CAPTURE_OVERWRITE_EN_OFFS		6
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_CAPTURE_OVERWRITE_EN_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_CAPTURE_OVERWRITE_EN_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_DRIFT_ADJUSTMENT_EN_OFFS		7
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_DRIFT_ADJUSTMENT_EN_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_DRIFT_ADJUSTMENT_EN_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_INT_CLOCK_GENERATOR_EN_OFFS		8
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_INT_CLOCK_GENERATOR_EN_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_INT_CLOCK_GENERATOR_EN_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_CLOCK_MODE_OFFS		9
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_CLOCK_MODE_MASK    \
+		(0x00000003 << MV_TAI_TIME_CNTR_FUNC_CFG_0_CLOCK_MODE_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_COUNTER_START_OFFS		11
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_COUNTER_START_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_PCLK_COUNTER_START_OFFS)
+
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_ONE_SHOT_UPDATE_OFFS		12
+#define MV_TAI_TIME_CNTR_FUNC_CFG_0_ONE_SHOT_UPDATE_MASK    \
+		(0x00000001 << MV_TAI_TIME_CNTR_FUNC_CFG_0_ONE_SHOT_UPDATE_OFFS)
+
+
+/* Time Counter Function Configuration 1 */
+#define MV_TAI_TIME_CNTR_FUNC_CFG_1_REG					(0x0a14)
+#define MV_TAI_TIME_CNTR_FUNC_CFG_1_PULSE_WIDTH_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CNTR_FUNC_CFG_1_PULSE_WIDTH_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CNTR_FUNC_CFG_1_PULSE_WIDTH_BITS_0_15_OFFS)
+
+
+/* Time Counter Function Configuration 2 */
+#define MV_TAI_TIME_CNTR_FUNC_CFG_2_REG					(0x0a18)
+#define MV_TAI_TIME_CNTR_FUNC_CFG_2_PULSE_WIDTH_BITS_16_27_OFFS		0
+#define MV_TAI_TIME_CNTR_FUNC_CFG_2_PULSE_WIDTH_BITS_16_27_MASK    \
+		(0x00000fff << MV_TAI_TIME_CNTR_FUNC_CFG_2_PULSE_WIDTH_BITS_16_27_OFFS)
+
+
+/* Frequency Adjust Time Window */
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_REG				(0x0a1c)
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_FREQUENCY_ADJUST_TIME_WINDOW_OFFS		0
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_FREQUENCY_ADJUST_TIME_WINDOW_MASK    \
+		(0x00000007 << MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_FREQUENCY_ADJUST_TIME_WINDOW_OFFS)
+
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_CLOCK_GEN_SM_DIVIDER_OFFS		3
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_CLOCK_GEN_SM_DIVIDER_MASK    \
+		(0x00000003 << MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_CLOCK_GEN_SM_DIVIDER_OFFS)
+
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_DRIFT_ADJUST_VALUE_OFFS		5
+#define MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_DRIFT_ADJUST_VALUE_MASK    \
+		(0x00000001 << MV_TAI_FREQUENCY_ADJUST_TIME_WINDOW_DRIFT_ADJUST_VALUE_OFFS)
+
+
+/* Tod Step Nano Configuration */
+#define MV_TAI_TOD_STEP_NANO_CFG_REG						(0x0a20)
+#define MV_TAI_TOD_STEP_NANO_CFG_TOD_STEP_NANOSECONDS_OFFS		0
+#define MV_TAI_TOD_STEP_NANO_CFG_TOD_STEP_NANOSECONDS_MASK    \
+		(0x0000ffff << MV_TAI_TOD_STEP_NANO_CFG_TOD_STEP_NANOSECONDS_OFFS)
+
+
+/* Tod Step Frac Configuration High */
+#define MV_TAI_TOD_STEP_FRAC_CFG_HIGH_REG						(0x0a24)
+#define MV_TAI_TOD_STEP_FRAC_CFG_HIGH_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_16_31_OFFS		0
+#define MV_TAI_TOD_STEP_FRAC_CFG_HIGH_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TOD_STEP_FRAC_CFG_HIGH_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_16_31_OFFS)
+
+
+/* Tod Step Frac Configuration Low */
+#define MV_TAI_TOD_STEP_FRAC_CFG_LOW_REG						(0x0a28)
+#define MV_TAI_TOD_STEP_FRAC_CFG_LOW_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_0_15_OFFS		0
+#define MV_TAI_TOD_STEP_FRAC_CFG_LOW_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TOD_STEP_FRAC_CFG_LOW_TOD_STEP_FRACTIONAL_NANOSECONDS_BITS_0_15_OFFS)
+
+
+/* Time Adjustment Propagation Delay Configuration High */
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH_REG			(0x0a2c)
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH_PULSE_DELAY_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH_PULSE_DELAY_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_HIGH_PULSE_DELAY_BITS_16_31_OFFS)
+
+
+/* Time Adjustment Propagation Delay Configuration Low */
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW_REG			(0x0a30)
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW_PULSE_DELAY_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW_PULSE_DELAY_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_ADJUSTMENT_PROPAGATION_DELAY_CFG_LOW_PULSE_DELAY_BITS_0_15_OFFS)
+
+
+/* Trigger Generation Tod Sec High */
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_HIGH_REG					(0x0a34)
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_HIGH_TRIGGER_GENERATION_TOD_SEC_BITS_32_47_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_HIGH_TRIGGER_GENERATION_TOD_SEC_BITS_32_47_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_SEC_HIGH_TRIGGER_GENERATION_TOD_SEC_BITS_32_47_OFFS)
+
+
+/* Trigger Generation Tod Sec Med */
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_MED_REG					(0x0a38)
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_MED_TRIGGER_GENERATION_TOD_SEC_BITS_16_31_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_MED_TRIGGER_GENERATION_TOD_SEC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_SEC_MED_TRIGGER_GENERATION_TOD_SEC_BITS_16_31_OFFS)
+
+
+/* Trigger Generation Tod Sec Low */
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_LOW_REG					(0x0a3c)
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_LOW_TRIGGER_GENERATION_TOD_SEC_BITS_0_15_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_SEC_LOW_TRIGGER_GENERATION_TOD_SEC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_SEC_LOW_TRIGGER_GENERATION_TOD_SEC_BITS_0_15_OFFS)
+
+
+/* Trigger Generation Tod Nano High */
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_HIGH_REG					(0x0a40)
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_HIGH_TRIGGER_GENERATION_TOD_NANO_BITS_16_31_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_HIGH_TRIGGER_GENERATION_TOD_NANO_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_NANO_HIGH_TRIGGER_GENERATION_TOD_NANO_BITS_16_31_OFFS)
+
+
+/* Trigger Generation Tod Nano Low */
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_LOW_REG					(0x0a44)
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_LOW_TRIGGER_GENERATION_TOD_NANO_BITS_0_15_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_NANO_LOW_TRIGGER_GENERATION_TOD_NANO_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_NANO_LOW_TRIGGER_GENERATION_TOD_NANO_BITS_0_15_OFFS)
+
+
+/* Trigger Generation Tod Frac High */
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_HIGH_REG					(0x0a48)
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_HIGH_TRIGGER_GENERATION_TOD_FRAC_BITS_16_31_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_HIGH_TRIGGER_GENERATION_TOD_FRAC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_FRAC_HIGH_TRIGGER_GENERATION_TOD_FRAC_BITS_16_31_OFFS)
+
+
+/* Trigger Generation Tod Frac Low */
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_LOW_REG					(0x0a4c)
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_LOW_TRIGGER_GENERATION_TOD_FRAC_BITS_0_15_OFFS		0
+#define MV_TAI_TRIGGER_GENERATION_TOD_FRAC_LOW_TRIGGER_GENERATION_TOD_FRAC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TRIGGER_GENERATION_TOD_FRAC_LOW_TRIGGER_GENERATION_TOD_FRAC_BITS_0_15_OFFS)
+
+
+/* Time Load Value Sec High */
+#define MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_REG						(0x0a50)
+#define MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_TIME_LOAD_VALUE_SEC_BITS_32_47_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_TIME_LOAD_VALUE_SEC_BITS_32_47_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_SEC_HIGH_TIME_LOAD_VALUE_SEC_BITS_32_47_OFFS)
+
+
+/* Time Load Value Sec Med */
+#define MV_TAI_TIME_LOAD_VALUE_SEC_MED_REG						(0x0a54)
+#define MV_TAI_TIME_LOAD_VALUE_SEC_MED_TIME_LOAD_VALUE_SEC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_SEC_MED_TIME_LOAD_VALUE_SEC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_SEC_MED_TIME_LOAD_VALUE_SEC_BITS_16_31_OFFS)
+
+
+/* Time Load Value Sec Low */
+#define MV_TAI_TIME_LOAD_VALUE_SEC_LOW_REG						(0x0a58)
+#define MV_TAI_TIME_LOAD_VALUE_SEC_LOW_TIME_LOAD_VALUE_SEC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_SEC_LOW_TIME_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_SEC_LOW_TIME_LOAD_VALUE_SEC_BITS_0_15_OFFS)
+
+
+/* Time Load Value Nano High */
+#define MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_REG					(0x0a5c)
+#define MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_TIME_LOAD_VALUE_NANO_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_TIME_LOAD_VALUE_NANO_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_NANO_HIGH_TIME_LOAD_VALUE_NANO_BITS_16_31_OFFS)
+
+
+/* Time Load Value Nano Low */
+#define MV_TAI_TIME_LOAD_VALUE_NANO_LOW_REG						(0x0a60)
+#define MV_TAI_TIME_LOAD_VALUE_NANO_LOW_TIME_LOAD_VALUE_NANO_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_NANO_LOW_TIME_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_NANO_LOW_TIME_LOAD_VALUE_NANO_BITS_0_15_OFFS)
+
+
+/* Time Load Value Frac High */
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_REG					(0x0a64)
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_TIME_LOAD_VALUE_FRAC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_TIME_LOAD_VALUE_FRAC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_FRAC_HIGH_TIME_LOAD_VALUE_FRAC_BITS_16_31_OFFS)
+
+
+/* Time Load Value Frac Low */
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_REG						(0x0a68)
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_TIME_LOAD_VALUE_FRAC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_TIME_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_LOAD_VALUE_FRAC_LOW_TIME_LOAD_VALUE_FRAC_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 0 Sec High */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_REG					(0x0a6c)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_TIME_CAPTURE_VALUE_0_SEC_BITS_32_47_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_TIME_CAPTURE_VALUE_0_SEC_BITS_32_47_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_SEC_HIGH_TIME_CAPTURE_VALUE_0_SEC_BITS_32_47_OFFS)
+
+
+/* Time Capture Value 0 Sec Med */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_REG					(0x0a70)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_TIME_CAPTURE_VALUE_0_SEC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_TIME_CAPTURE_VALUE_0_SEC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_SEC_MED_TIME_CAPTURE_VALUE_0_SEC_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 0 Sec Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_REG					(0x0a74)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_TIME_CAPTURE_VALUE_0_SEC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_TIME_CAPTURE_VALUE_0_SEC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_SEC_LOW_TIME_CAPTURE_VALUE_0_SEC_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 0 Nano High */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_REG					(0x0a78)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_TIME_CAPTURE_VALUE_0_NANO_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_TIME_CAPTURE_VALUE_0_NANO_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_NANO_HIGH_TIME_CAPTURE_VALUE_0_NANO_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 0 Nano Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_REG					(0x0a7c)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_TIME_CAPTURE_VALUE_0_NANO_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_TIME_CAPTURE_VALUE_0_NANO_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_NANO_LOW_TIME_CAPTURE_VALUE_0_NANO_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 0 Frac High */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_REG					(0x0a80)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_TIME_CAPTURE_VALUE_0_FRAC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_TIME_CAPTURE_VALUE_0_FRAC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_HIGH_TIME_CAPTURE_VALUE_0_FRAC_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 0 Frac Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_REG					(0x0a84)
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_TIME_CAPTURE_VALUE_0_FRAC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_TIME_CAPTURE_VALUE_0_FRAC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_0_FRAC_LOW_TIME_CAPTURE_VALUE_0_FRAC_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 1 Sec High */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_REG					(0x0a88)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_TIME_CAPTURE_VALUE_1_SEC_BITS_32_47_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_TIME_CAPTURE_VALUE_1_SEC_BITS_32_47_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_SEC_HIGH_TIME_CAPTURE_VALUE_1_SEC_BITS_32_47_OFFS)
+
+
+/* Time Capture Value 1 Sec Med */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_REG					(0x0a8c)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_TIME_CAPTURE_VALUE_1_SEC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_TIME_CAPTURE_VALUE_1_SEC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_SEC_MED_TIME_CAPTURE_VALUE_1_SEC_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 1 Sec Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_REG					(0x0a90)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_TIME_CAPTURE_VALUE_1_SEC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_TIME_CAPTURE_VALUE_1_SEC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_SEC_LOW_TIME_CAPTURE_VALUE_1_SEC_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 1 Nano High */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_REG					(0x0a94)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_TIME_CAPTURE_VALUE_1_NANO_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_TIME_CAPTURE_VALUE_1_NANO_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_NANO_HIGH_TIME_CAPTURE_VALUE_1_NANO_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 1 Nano Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_REG					(0x0a98)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_TIME_CAPTURE_VALUE_1_NANO_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_TIME_CAPTURE_VALUE_1_NANO_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_NANO_LOW_TIME_CAPTURE_VALUE_1_NANO_BITS_0_15_OFFS)
+
+
+/* Time Capture Value 1 Frac High */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_REG					(0x0a9c)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_TIME_CAPTURE_VALUE_1_FRAC_BITS_16_31_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_TIME_CAPTURE_VALUE_1_FRAC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_HIGH_TIME_CAPTURE_VALUE_1_FRAC_BITS_16_31_OFFS)
+
+
+/* Time Capture Value 1 Frac Low */
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_REG					(0x0aa0)
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_TIME_CAPTURE_VALUE_1_FRAC_BITS_0_15_OFFS		0
+#define MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_TIME_CAPTURE_VALUE_1_FRAC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_TIME_CAPTURE_VALUE_1_FRAC_LOW_TIME_CAPTURE_VALUE_1_FRAC_BITS_0_15_OFFS)
+
+
+/* Time Capture Status */
+#define MV_TAI_TIME_CAPTURE_STATUS_REG						(0x0aa4)
+#define MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_0_VALID_OFFS		0
+#define MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_0_VALID_MASK    \
+		(0x00000001 << MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_0_VALID_OFFS)
+
+#define MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_1_VALID_OFFS		1
+#define MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_1_VALID_MASK    \
+		(0x00000001 << MV_TAI_TIME_CAPTURE_STATUS_CAPTURE_1_VALID_OFFS)
+
+
+/* Time Update Counter LSB */
+#define MV_TAI_TIME_UPDATE_CNTR_LSB_REG						(0x0aa8)
+#define MV_TAI_TIME_UPDATE_CNTR_LSB_TIME_UPDATE_CNTR_LSB_OFFS		0
+#define MV_TAI_TIME_UPDATE_CNTR_LSB_TIME_UPDATE_CNTR_LSB_MASK    \
+		(0x0000ffff << MV_TAI_TIME_UPDATE_CNTR_LSB_TIME_UPDATE_CNTR_LSB_OFFS)
+
+
+/* Generate Function Mask Sec High */
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_HIGH_REG					(0x0aac)
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_HIGH_GENERATE_FUNCTION_MASK_SEC_BITS_32_47_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_HIGH_GENERATE_FUNCTION_MASK_SEC_BITS_32_47_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_SEC_HIGH_GENERATE_FUNCTION_MASK_SEC_BITS_32_47_OFFS)
+
+
+/* Generate Function Mask Sec Med */
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_MED_REG					(0x0ab0)
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_MED_GENERATE_FUNCTION_MASK_SEC_BITS_16_31_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_MED_GENERATE_FUNCTION_MASK_SEC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_SEC_MED_GENERATE_FUNCTION_MASK_SEC_BITS_16_31_OFFS)
+
+
+/* Generate Function Mask Sec Low */
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_LOW_REG					(0x0ab4)
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_LOW_GENERATE_FUNCTION_MASK_SEC_BITS_0_15_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_SEC_LOW_GENERATE_FUNCTION_MASK_SEC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_SEC_LOW_GENERATE_FUNCTION_MASK_SEC_BITS_0_15_OFFS)
+
+
+/* Generate Function Mask Nano High */
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_HIGH_REG					(0x0ab8)
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_HIGH_GENERATE_FUNCTION_MASK_NANO_BITS_16_31_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_HIGH_GENERATE_FUNCTION_MASK_NANO_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_NANO_HIGH_GENERATE_FUNCTION_MASK_NANO_BITS_16_31_OFFS)
+
+
+/* Generate Function Mask Nano Low */
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_LOW_REG					(0x0abc)
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_LOW_GENERATE_FUNCTION_MASK_NANO_BITS_0_15_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_NANO_LOW_GENERATE_FUNCTION_MASK_NANO_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_NANO_LOW_GENERATE_FUNCTION_MASK_NANO_BITS_0_15_OFFS)
+
+
+/* Generate Function Mask Frac High */
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_HIGH_REG					(0x0ac0)
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_HIGH_GENERATE_FUNCTION_MASK_FRAC_BITS_16_31_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_HIGH_GENERATE_FUNCTION_MASK_FRAC_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_FRAC_HIGH_GENERATE_FUNCTION_MASK_FRAC_BITS_16_31_OFFS)
+
+
+/* Generate Function Mask Frac Low */
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_LOW_REG					(0x0ac4)
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_LOW_GENERATE_FUNCTION_MASK_FRAC_BITS_0_15_OFFS		0
+#define MV_TAI_GENERATE_FUNCTION_MASK_FRAC_LOW_GENERATE_FUNCTION_MASK_FRAC_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_GENERATE_FUNCTION_MASK_FRAC_LOW_GENERATE_FUNCTION_MASK_FRAC_BITS_0_15_OFFS)
+
+
+/* Drift Adjustment Configuration High */
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_HIGH_REG					(0x0ac8)
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_HIGH_FRACTIONAL_NANOSECOND_DRIFT_BITS_16_31_OFFS		0
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_HIGH_FRACTIONAL_NANOSECOND_DRIFT_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_DRIFT_ADJUSTMENT_CFG_HIGH_FRACTIONAL_NANOSECOND_DRIFT_BITS_16_31_OFFS)
+
+
+/* Drift Adjustment Configuration Low */
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_LOW_REG						(0x0acc)
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_LOW_FRACTIONAL_NANOSECOND_DRIFT_BITS_0_15_OFFS		0
+#define MV_TAI_DRIFT_ADJUSTMENT_CFG_LOW_FRACTIONAL_NANOSECOND_DRIFT_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_DRIFT_ADJUSTMENT_CFG_LOW_FRACTIONAL_NANOSECOND_DRIFT_BITS_0_15_OFFS)
+
+
+/* Capture Trigger Counter */
+#define MV_TAI_CAPTURE_TRIGGER_CNTR_REG						(0x0ad0)
+#define MV_TAI_CAPTURE_TRIGGER_CNTR_TRIGGER_CNTR_OFFS		0
+#define MV_TAI_CAPTURE_TRIGGER_CNTR_TRIGGER_CNTR_MASK    \
+		(0x000000ff << MV_TAI_CAPTURE_TRIGGER_CNTR_TRIGGER_CNTR_OFFS)
+
+
+/* Pclk Clock Cycle Configuration High */
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_HIGH_REG					(0x0ad4)
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_HIGH_PCLK_CLOCK_CYCLE_BITS_16_31_OFFS		0
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_HIGH_PCLK_CLOCK_CYCLE_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_PCLK_CLOCK_CYCLE_CFG_HIGH_PCLK_CLOCK_CYCLE_BITS_16_31_OFFS)
+
+
+/* Pclk Clock Cycle Configuration Low */
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_LOW_REG						(0x0ad8)
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_LOW_PCLK_CLOCK_CYCLE_BITS_0_15_OFFS		0
+#define MV_TAI_PCLK_CLOCK_CYCLE_CFG_LOW_PCLK_CLOCK_CYCLE_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_PCLK_CLOCK_CYCLE_CFG_LOW_PCLK_CLOCK_CYCLE_BITS_0_15_OFFS)
+
+
+/* Drift Threshold Configuration High */
+#define MV_TAI_DRIFT_THR_CFG_HIGH_REG						(0x0adc)
+#define MV_TAI_DRIFT_THR_CFG_HIGH_DRIFT_EXCEP_THR_BITS_8_23_OFFS		0
+#define MV_TAI_DRIFT_THR_CFG_HIGH_DRIFT_EXCEP_THR_BITS_8_23_MASK    \
+		(0x0000ffff << MV_TAI_DRIFT_THR_CFG_HIGH_DRIFT_EXCEP_THR_BITS_8_23_OFFS)
+
+
+/* Drift Threshold Configuration Low */
+#define MV_TAI_DRIFT_THR_CFG_LOW_REG						(0x0ae0)
+#define MV_TAI_DRIFT_THR_CFG_LOW_MINIMAL_DRIFT_OFFS		0
+#define MV_TAI_DRIFT_THR_CFG_LOW_MINIMAL_DRIFT_MASK    \
+		(0x000000ff << MV_TAI_DRIFT_THR_CFG_LOW_MINIMAL_DRIFT_OFFS)
+
+#define MV_TAI_DRIFT_THR_CFG_LOW_DRIFT_EXCEP_THR_BITS_0_7_OFFS		8
+#define MV_TAI_DRIFT_THR_CFG_LOW_DRIFT_EXCEP_THR_BITS_0_7_MASK    \
+		(0x000000ff << MV_TAI_DRIFT_THR_CFG_LOW_DRIFT_EXCEP_THR_BITS_0_7_OFFS)
+
+
+/* Clock Cycle Configuration High */
+#define MV_TAI_CLOCK_CYCLE_CFG_HIGH_REG						(0x0ae4)
+#define MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_NANOSECONDS_BITS_16_29_OFFS		0
+#define MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_NANOSECONDS_BITS_16_29_MASK    \
+		(0x00003fff << MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_NANOSECONDS_BITS_16_29_OFFS)
+
+#define MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_SECONDS_OFFS		14
+#define MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_SECONDS_MASK    \
+		(0x00000003 << MV_TAI_CLOCK_CYCLE_CFG_HIGH_CLOCK_CYCLE_SECONDS_OFFS)
+
+
+/* Clock Cycle Configuration Low */
+#define MV_TAI_CLOCK_CYCLE_CFG_LOW_REG						(0x0ae8)
+#define MV_TAI_CLOCK_CYCLE_CFG_LOW_CLOCK_CYCLE_NANOSECONDS_BITS_0_15_OFFS		0
+#define MV_TAI_CLOCK_CYCLE_CFG_LOW_CLOCK_CYCLE_NANOSECONDS_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_CLOCK_CYCLE_CFG_LOW_CLOCK_CYCLE_NANOSECONDS_BITS_0_15_OFFS)
+
+
+/* External Clock Propagation Delay Configuration High */
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH_REG				(0x0aec)
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH_CLOCK_DELAY_BITS_16_31_OFFS		0
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH_CLOCK_DELAY_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_HIGH_CLOCK_DELAY_BITS_16_31_OFFS)
+
+
+/* External Clock Propagation Delay Configuration Low */
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW_REG				(0x0af0)
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW_CLOCK_DELAY_BITS_0_15_OFFS		0
+#define MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW_CLOCK_DELAY_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_EXT_CLOCK_PROPAGATION_DELAY_CFG_LOW_CLOCK_DELAY_BITS_0_15_OFFS)
+
+
+/* Incoming Clockin Counting Enable */
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_EN_REG					(0x0af4)
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_EN_EN_INCOMING_CLOCK_CNTING_OFFS		0
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_EN_EN_INCOMING_CLOCK_CNTING_MASK    \
+		(0x00000001 << MV_TAI_INCOMING_CLOCKIN_CNTING_EN_EN_INCOMING_CLOCK_CNTING_OFFS)
+
+
+/* Incoming Clockin Counting Configuration Low */
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_REG					(0x0af8)
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_CLOCK_CNTR_BITS_0_15_OFFS		0
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_CLOCK_CNTR_BITS_0_15_MASK    \
+		(0x0000ffff << MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_LOW_CLOCK_CNTR_BITS_0_15_OFFS)
+
+
+/* Time Update Counter MSB */
+#define MV_TAI_TIME_UPDATE_CNTR_MSB_REG						(0x0afc)
+#define MV_TAI_TIME_UPDATE_CNTR_MSB_TIME_UPDATE_CNTR_MSB_OFFS		0
+#define MV_TAI_TIME_UPDATE_CNTR_MSB_TIME_UPDATE_CNTR_MSB_MASK    \
+		(0x0000ffff << MV_TAI_TIME_UPDATE_CNTR_MSB_TIME_UPDATE_CNTR_MSB_OFFS)
+
+
+/* Incoming Clockin Counting Configuration High */
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_HIGH_REG					(0x0b00)
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_HIGH_CLOCK_CNTR_BITS_16_31_OFFS		0
+#define MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_HIGH_CLOCK_CNTR_BITS_16_31_MASK    \
+		(0x0000ffff << MV_TAI_INCOMING_CLOCKIN_CNTING_CFG_HIGH_CLOCK_CNTR_BITS_16_31_OFFS)
+
+#define MV_TAI_CNTR_TIME_FUNC_BITSET(op, reg_val) \
+	((reg_val & ~MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_MASK) \
+	| (op << MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC_OFFS))
+
+
+/* Generic HW and SW operations' enum */
+enum mv_pp3_tai_ptp_op {
+	/* HW: MV_TAI_TIME_CNTR_FUNC_CFG_0_TIME_CNTR_FUNC bit set
+	 * (these enums are HW, do not change them)
+	 */
+	MV_TAI_SET_UPDATE = 0,	/* from shadow to tai/tod */
+	MV_TAI_FREQ_UPDATE = 1,
+	MV_TAI_INCREMENT = 2,
+	MV_TAI_DECREMENT = 3,
+	MV_TAI_GET_CAPTURE = 4,
+	MV_TAI_INCREMENT_GRACEFUL = 5,
+	MV_TAI_DECREMENT_GRACEFUL = 6,
+	MV_TAI_NOP = 7,
+
+	/* SW operation enum (values are free) */
+	MV_TAI_PTP_SW_OP,
+	MV_TAI_TO_LINUX,
+	MV_TAI_FROM_LINUX,
+	MV_TAI_FROM_KERNEL,
+
+	MV_TAI_PTP_TX_TS,	/* Timestamp of TX/Egress packet */
+	/*MV_TAI_PTP_RX_TS - RX is not needed. Read from CFH into PTP pack-payload */
+	MV_TAI_PTP_ENABLE,	/* Total complete enable/disable */
+	MV_TAI_PTP_DISABLE,	/* for TAI and PTP HW, and SW    */
+	MV_TAI_CLOCK_INTERNAL,
+	MV_TAI_CLOCK_EXTERNAL,
+	MV_TAI_NOP_RESERVE3,
+	MV_TAI_NOP_RESERVE2,
+	MV_TAI_NOP_RESERVE1,
+	MV_TAI_OP_MAX
+};
+
+
+#define MV_TAI_TOD_SKIP_ZERO_REGS /* sec_msb_16b, nfrac */
+
+/* Generic HW and SW structure used for TAI operation INP and/or OUT */
+struct mv_pp3_tai_tod {
+	/* 4 bytes for User/Kernel communication only */
+	u8 zero_byte_non_ascii; /* should be always ZERO */
+	u8 ts_is_32bits; /* if(1) sec_lsb_32b contains 2bits sec + 30bits nsec */
+	u8 operation; /* enum mv_pp3_tai_ptp_op */
+	u8 pad;
+
+	/* timestamp in 16+32+32 format, or 2+30 */
+	/* in LittleEndian ordering so the *u64 could be used */
+	u32	nsec;
+	u32	sec_lsb_32b;
+	u32	sec_msb_16b;
+	u32	nfrac;
+};
+
+#endif /* _mv_tai_regs_h_ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.c b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.c
new file mode 100644
index 0000000..cea3365
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.c
@@ -0,0 +1,98 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mac/mv_gmac_regs.h"
+
+/*******************************************************************************
+* mv_gpcs_mode_cfg
+*
+* DESCRIPTION:
+	Configure port to working with Gig PCS or don't.
+*
+* INPUTS:
+*       pcs_num   - physical PCS number
+*       en        - true to enable PCS
+*
+* OUTPUTS:
+*       None.
+*
+* RETURNS:
+*       0  - on success
+*       1  - on error
+*
+*******************************************************************************/
+int mv_gpcs_mode_cfg(int pcs_num, bool en)
+{
+	u32 val;
+
+	val = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(pcs_num));
+
+	if (en)
+		val |= MV_GMAC_PORT_CTRL2_PCS_EN_MASK;
+	else
+		val &= ~MV_GMAC_PORT_CTRL2_PCS_EN_MASK;
+
+	/* enable / disable PCS on this port */
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(pcs_num), val);
+
+	return 0;
+}
+
+/*******************************************************************************
+* mv_gpcs_reset
+*
+* DESCRIPTION:
+*       Set the selected PCS number to reset or exit from reset.
+*
+* INPUTS:
+*       pcs_num    - physical PCS number
+*       action    - reset / unreset
+*
+* OUTPUTS:
+*       None.
+*
+* RETURNS:
+*       0  - on success
+*       1  - on error
+*
+*******************************************************************************/
+int  mv_gpcs_reset(int pcs_num, enum mv_reset act)
+{
+	u32 reg_data;
+
+	reg_data = mv_gop_reg_read(MV_GMAC_PORT_CTRL2_REG(pcs_num));
+	if (act == RESET)
+		MV_U32_SET_FIELD(reg_data, MV_GMAC_PORT_CTRL2_SGMII_MODE_MASK, 0);
+	else
+		MV_U32_SET_FIELD(reg_data, MV_GMAC_PORT_CTRL2_SGMII_MODE_MASK,
+			1 << MV_GMAC_PORT_CTRL2_SGMII_MODE_OFFS);
+
+	mv_gop_reg_write(MV_GMAC_PORT_CTRL2_REG(pcs_num), reg_data);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.h b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.h
new file mode 100644
index 0000000..693fd57
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_gpcs_if.h
@@ -0,0 +1,38 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_gpcs_if_h__
+#define __mv_gpcs_if_h__
+
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+
+int mv_gpcs_mode_cfg(int pcs_num, bool en);
+int mv_gpcs_reset(int pcs_num, enum mv_reset act);
+
+
+#endif /* __mv_gpcs_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.c b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.c
new file mode 100644
index 0000000..d00b4bd
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.c
@@ -0,0 +1,118 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/pcs/mv_xpcs_regs.h"
+
+
+/* print value of unit registers */
+void mv_xpcs_gl_regs_dump(void)
+{
+	pr_info("\nXPCS Global registers]\n");
+	mv_gop_reg_print("GLOBAL_CFG_0", MV_XPCS_GLOBAL_CFG_0_REG);
+	mv_gop_reg_print("GLOBAL_CFG_1", MV_XPCS_GLOBAL_CFG_1_REG);
+	mv_gop_reg_print("GLOBAL_FIFO_THR_CFG", MV_XPCS_GLOBAL_FIFO_THR_CFG_REG);
+	mv_gop_reg_print("GLOBAL_MAX_IDLE_CNTR", MV_XPCS_GLOBAL_MAX_IDLE_CNTR_REG);
+	mv_gop_reg_print("GLOBAL_STATUS", MV_XPCS_GLOBAL_STATUS_REG);
+	mv_gop_reg_print("GLOBAL_DESKEW_ERR_CNTR", MV_XPCS_GLOBAL_DESKEW_ERR_CNTR_REG);
+	mv_gop_reg_print("TX_PCKTS_CNTR_LSB", MV_XPCS_TX_PCKTS_CNTR_LSB_REG);
+	mv_gop_reg_print("TX_PCKTS_CNTR_MSB", MV_XPCS_TX_PCKTS_CNTR_MSB_REG);
+
+}
+
+/* print value of unit registers */
+void mv_xpcs_lane_regs_dump(int lane)
+{
+	pr_info("\nXPCS Lane #%d registers]\n", lane);
+	mv_gop_reg_print("LANE_CFG_0", MV_XPCS_LANE_CFG_0_REG(lane));
+	mv_gop_reg_print("LANE_CFG_1", MV_XPCS_LANE_CFG_1_REG(lane));
+	mv_gop_reg_print("LANE_STATUS", MV_XPCS_LANE_STATUS_REG(lane));
+	mv_gop_reg_print("SYMBOL_ERR_CNTR", MV_XPCS_SYMBOL_ERR_CNTR_REG(lane));
+	mv_gop_reg_print("DISPARITY_ERR_CNTR", MV_XPCS_DISPARITY_ERR_CNTR_REG(lane));
+	mv_gop_reg_print("PRBS_ERR_CNTR", MV_XPCS_PRBS_ERR_CNTR_REG(lane));
+	mv_gop_reg_print("RX_PCKTS_CNTR_LSB", MV_XPCS_RX_PCKTS_CNTR_LSB_REG(lane));
+	mv_gop_reg_print("RX_PCKTS_CNTR_MSB", MV_XPCS_RX_PCKTS_CNTR_MSB_REG(lane));
+	mv_gop_reg_print("RX_BAD_PCKTS_CNTR_LSB", MV_XPCS_RX_BAD_PCKTS_CNTR_LSB_REG(lane));
+	mv_gop_reg_print("RX_BAD_PCKTS_CNTR_MSB", MV_XPCS_RX_BAD_PCKTS_CNTR_MSB_REG(lane));
+	mv_gop_reg_print("CYCLIC_DATA_0", MV_XPCS_CYCLIC_DATA_0_REG(lane));
+	mv_gop_reg_print("CYCLIC_DATA_1", MV_XPCS_CYCLIC_DATA_1_REG(lane));
+	mv_gop_reg_print("CYCLIC_DATA_2", MV_XPCS_CYCLIC_DATA_2_REG(lane));
+	mv_gop_reg_print("CYCLIC_DATA_3", MV_XPCS_CYCLIC_DATA_3_REG(lane));
+}
+
+/* Set PCS to reset or exit from reset */
+int mv_xpcs_reset(enum mv_reset reset)
+{
+	u32 reg_addr;
+	u32 val;
+
+	reg_addr = MV_XPCS_GLOBAL_CFG_0_REG;
+
+	/* read - modify - write */
+	val = mv_gop_reg_read(reg_addr);
+	if (reset == RESET)
+		val &= ~MV_XPCS_GLOBAL_CFG_0_PCSRESET_MASK;
+	else
+		val |= MV_XPCS_GLOBAL_CFG_0_PCSRESET_MASK;
+	mv_gop_reg_write(reg_addr, val);
+
+	return 0;
+}
+
+/* Set the internal mux's to the required PCS in the PI */
+int mv_xpcs_mode(int num_of_lanes)
+{
+	u32 reg_addr;
+	u32 val;
+	int lane;
+
+	switch (num_of_lanes) {
+	case 1:
+		lane = 0;
+	break;
+	case 2:
+		lane = 1;
+	break;
+	case 4:
+		lane = 2;
+	break;
+	default:
+		return -1;
+	}
+
+	/* configure XG MAC mode */
+	reg_addr = MV_XPCS_GLOBAL_CFG_0_REG;
+	val = mv_gop_reg_read(reg_addr);
+	val &= ~MV_XPCS_GLOBAL_CFG_0_PCSMODE_MASK;
+	MV_U32_SET_FIELD(val, MV_XPCS_GLOBAL_CFG_0_PCSMODE_MASK, 0);
+	MV_U32_SET_FIELD(val, MV_XPCS_GLOBAL_CFG_0_LANEACTIVE_MASK, (2 * lane) << MV_XPCS_GLOBAL_CFG_0_LANEACTIVE_OFFS);
+	mv_gop_reg_write(reg_addr, val);
+
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.h b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.h
new file mode 100644
index 0000000..a5a89ba1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_if.h
@@ -0,0 +1,44 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_xpcs_if_h__
+#define __mv_xpcs_if_h__
+
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+
+/* print value of unit registers */
+void mv_xpcs_gl_regs_dump(void);
+/* print value of unit registers */
+void mv_xpcs_lane_regs_dump(int lane);
+/* Set PCS to reset or exit from reset */
+int mv_xpcs_reset(enum mv_reset reset);
+/* Set the internal mux's to the required PCS in the PI */
+int mv_xpcs_mode(int num_of_lanes);
+
+
+#endif /* __mv_xpcs_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_regs.h b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_regs.h
new file mode 100644
index 0000000..93b85c7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/pcs/mv_xpcs_regs.h
@@ -0,0 +1,368 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_xpcs_regs_h__
+#define __mv_xpcs_regs_h__
+
+/* includes */
+
+/* unit offset */
+#define MV_PP3_XPCS_UNIT_OFFSET		0x03180000
+
+/* Global Configuration 0 */
+#define MV_XPCS_GLOBAL_CFG_0_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0400)
+#define MV_XPCS_GLOBAL_CFG_0_PCSRESET_OFFS		0
+#define MV_XPCS_GLOBAL_CFG_0_PCSRESET_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_PCSRESET_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_DESKEWRESET_OFFS		1
+#define MV_XPCS_GLOBAL_CFG_0_DESKEWRESET_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_DESKEWRESET_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_TXRESET_OFFS		2
+#define MV_XPCS_GLOBAL_CFG_0_TXRESET_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_TXRESET_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_PCSMODE_OFFS		3
+#define MV_XPCS_GLOBAL_CFG_0_PCSMODE_MASK    \
+		(0x00000003 << MV_XPCS_GLOBAL_CFG_0_PCSMODE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_LANEACTIVE_OFFS		5
+#define MV_XPCS_GLOBAL_CFG_0_LANEACTIVE_MASK    \
+		(0x00000003 << MV_XPCS_GLOBAL_CFG_0_LANEACTIVE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_INDIVIDUALMODE_OFFS		7
+#define MV_XPCS_GLOBAL_CFG_0_INDIVIDUALMODE_MASK    \
+		(0x0000003f << MV_XPCS_GLOBAL_CFG_0_INDIVIDUALMODE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_TXSMMODE_OFFS		13
+#define MV_XPCS_GLOBAL_CFG_0_TXSMMODE_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_TXSMMODE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_TXSMIDLECNTDISABLE_OFFS		14
+#define MV_XPCS_GLOBAL_CFG_0_TXSMIDLECNTDISABLE_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_TXSMIDLECNTDISABLE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_0_COMMADETCT2NDSYNCSMEN_OFFS		15
+#define MV_XPCS_GLOBAL_CFG_0_COMMADETCT2NDSYNCSMEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_0_COMMADETCT2NDSYNCSMEN_OFFS)
+
+
+/* Global Configuration 1 */
+#define MV_XPCS_GLOBAL_CFG_1_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0404)
+#define MV_XPCS_GLOBAL_CFG_1_MACLOOPBACKEN_OFFS		0
+#define MV_XPCS_GLOBAL_CFG_1_MACLOOPBACKEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_MACLOOPBACKEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_PCSLOOPBACKEN_OFFS		1
+#define MV_XPCS_GLOBAL_CFG_1_PCSLOOPBACKEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_PCSLOOPBACKEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_REPEATERMODEEN_OFFS		2
+#define MV_XPCS_GLOBAL_CFG_1_REPEATERMODEEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_REPEATERMODEEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_LOOPBACKCLKSEL_OFFS		3
+#define MV_XPCS_GLOBAL_CFG_1_LOOPBACKCLKSEL_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_LOOPBACKCLKSEL_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_DESKEWCLKSEL_OFFS		4
+#define MV_XPCS_GLOBAL_CFG_1_DESKEWCLKSEL_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_DESKEWCLKSEL_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_TXSMREPEATERMODE_OFFS		5
+#define MV_XPCS_GLOBAL_CFG_1_TXSMREPEATERMODE_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_TXSMREPEATERMODE_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_RXLOCKBYPASSEN_OFFS		6
+#define MV_XPCS_GLOBAL_CFG_1_RXLOCKBYPASSEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_RXLOCKBYPASSEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_TXLOCKBYPASSEN_OFFS		7
+#define MV_XPCS_GLOBAL_CFG_1_TXLOCKBYPASSEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_TXLOCKBYPASSEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_REMOTEFAULTDIS_OFFS		8
+#define MV_XPCS_GLOBAL_CFG_1_REMOTEFAULTDIS_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_REMOTEFAULTDIS_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_SIGNALDETDOWNLOCALFAULTGENDIS_OFFS		9
+#define MV_XPCS_GLOBAL_CFG_1_SIGNALDETDOWNLOCALFAULTGENDIS_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_SIGNALDETDOWNLOCALFAULTGENDIS_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_CJPATGENEN_OFFS		10
+#define MV_XPCS_GLOBAL_CFG_1_CJPATGENEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_CJPATGENEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_CRPATGENEN_OFFS		11
+#define MV_XPCS_GLOBAL_CFG_1_CRPATGENEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_CRPATGENEN_OFFS)
+
+#define MV_XPCS_GLOBAL_CFG_1_CJRFORCEDISPEN_OFFS		12
+#define MV_XPCS_GLOBAL_CFG_1_CJRFORCEDISPEN_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_CFG_1_CJRFORCEDISPEN_OFFS)
+
+
+/* Global Fifo Threshold Configuration */
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0408)
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWTIMEOUTLIMIT_OFFS		0
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWTIMEOUTLIMIT_MASK    \
+		(0x0000000f << MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWTIMEOUTLIMIT_OFFS)
+
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFOWRADDRFIX_OFFS		4
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFOWRADDRFIX_MASK    \
+		(0x0000001f << MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFOWRADDRFIX_OFFS)
+
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFORDTH_OFFS		9
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFORDTH_MASK    \
+		(0x0000000f << MV_XPCS_GLOBAL_FIFO_THR_CFG_DESKEWFIFORDTH_OFFS)
+
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFORDTH_OFFS		13
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFORDTH_MASK    \
+		(0x00000007 << MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFORDTH_OFFS)
+
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFOEXTRAIDLECHKDIS_OFFS		16
+#define MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFOEXTRAIDLECHKDIS_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_FIFO_THR_CFG_PPMFIFOEXTRAIDLECHKDIS_OFFS)
+
+
+/* Global Max Idle Counter */
+#define MV_XPCS_GLOBAL_MAX_IDLE_CNTR_REG			(MV_PP3_XPCS_UNIT_OFFSET + 0x040c)
+#define MV_XPCS_GLOBAL_MAX_IDLE_CNTR_MAXIDLECNT_OFFS		0
+#define MV_XPCS_GLOBAL_MAX_IDLE_CNTR_MAXIDLECNT_MASK    \
+		(0x0000ffff << MV_XPCS_GLOBAL_MAX_IDLE_CNTR_MAXIDLECNT_OFFS)
+
+
+/* Global Status */
+#define MV_XPCS_GLOBAL_STATUS_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0410)
+#define MV_XPCS_GLOBAL_STATUS_LINKUP_OFFS		0
+#define MV_XPCS_GLOBAL_STATUS_LINKUP_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_STATUS_LINKUP_OFFS)
+
+#define MV_XPCS_GLOBAL_STATUS_DESKEWACQUIRED_OFFS		1
+#define MV_XPCS_GLOBAL_STATUS_DESKEWACQUIRED_MASK    \
+		(0x00000001 << MV_XPCS_GLOBAL_STATUS_DESKEWACQUIRED_OFFS)
+
+
+/* Global Deskew Error Counter */
+#define MV_XPCS_GLOBAL_DESKEW_ERR_CNTR_REG			(MV_PP3_XPCS_UNIT_OFFSET + 0x0420)
+#define MV_XPCS_GLOBAL_DESKEW_ERR_CNTR_DESKEWERRCNT_OFFS		0
+#define MV_XPCS_GLOBAL_DESKEW_ERR_CNTR_DESKEWERRCNT_MASK    \
+		(0x0000ffff << MV_XPCS_GLOBAL_DESKEW_ERR_CNTR_DESKEWERRCNT_OFFS)
+
+
+/* Tx Packets Counter LSB */
+#define MV_XPCS_TX_PCKTS_CNTR_LSB_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0430)
+#define MV_XPCS_TX_PCKTS_CNTR_LSB_TXPCKTCNTRLSB_OFFS		0
+#define MV_XPCS_TX_PCKTS_CNTR_LSB_TXPCKTCNTRLSB_MASK    \
+		(0x0000ffff << MV_XPCS_TX_PCKTS_CNTR_LSB_TXPCKTCNTRLSB_OFFS)
+
+
+/* Tx Packets Counter MSB */
+#define MV_XPCS_TX_PCKTS_CNTR_MSB_REG				(MV_PP3_XPCS_UNIT_OFFSET + 0x0434)
+#define MV_XPCS_TX_PCKTS_CNTR_MSB_TXPCKTCNTRMSB_OFFS		0
+#define MV_XPCS_TX_PCKTS_CNTR_MSB_TXPCKTCNTRMSB_MASK    \
+		(0x0000ffff << MV_XPCS_TX_PCKTS_CNTR_MSB_TXPCKTCNTRMSB_OFFS)
+
+/* XPCS per Lane registers */
+
+
+/* Lane Configuration 0 */
+#define MV_XPCS_LANE_CFG_0_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x0450 + lane * 0x44))
+#define MV_XPCS_LANE_CFG_0_TXRESETIND_OFFS		0
+#define MV_XPCS_LANE_CFG_0_TXRESETIND_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_TXRESETIND_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_RXRESETIND_OFFS		1
+#define MV_XPCS_LANE_CFG_0_RXRESETIND_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_RXRESETIND_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_INDIVIDUALLOOPBACK_OFFS		2
+#define MV_XPCS_LANE_CFG_0_INDIVIDUALLOOPBACK_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_INDIVIDUALLOOPBACK_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_INDIVIDUALLINELOOPBACK_OFFS		3
+#define MV_XPCS_LANE_CFG_0_INDIVIDUALLINELOOPBACK_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_INDIVIDUALLINELOOPBACK_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_TXSMBYPASSEN_OFFS		4
+#define MV_XPCS_LANE_CFG_0_TXSMBYPASSEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_TXSMBYPASSEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_RXIDLEGENBYPASSEN_OFFS		5
+#define MV_XPCS_LANE_CFG_0_RXIDLEGENBYPASSEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_RXIDLEGENBYPASSEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_SIGNALDETECTBYPASSEN_OFFS		6
+#define MV_XPCS_LANE_CFG_0_SIGNALDETECTBYPASSEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_SIGNALDETECTBYPASSEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_CJPATCHKEN_OFFS		7
+#define MV_XPCS_LANE_CFG_0_CJPATCHKEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_CJPATCHKEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_CRPATCHKEN_OFFS		8
+#define MV_XPCS_LANE_CFG_0_CRPATCHKEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_CRPATCHKEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_PRBSCHECKEN_OFFS		11
+#define MV_XPCS_LANE_CFG_0_PRBSCHECKEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_PRBSCHECKEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_TESTGENEN_OFFS		12
+#define MV_XPCS_LANE_CFG_0_TESTGENEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_TESTGENEN_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_TESTMODE_OFFS		13
+#define MV_XPCS_LANE_CFG_0_TESTMODE_MASK    \
+		(0x00000003 << MV_XPCS_LANE_CFG_0_TESTMODE_OFFS)
+
+#define MV_XPCS_LANE_CFG_0_TESTMODEEN_OFFS		15
+#define MV_XPCS_LANE_CFG_0_TESTMODEEN_MASK    \
+		(0x00000001 << MV_XPCS_LANE_CFG_0_TESTMODEEN_OFFS)
+
+
+/* Lane Configuration 1 */
+#define MV_XPCS_LANE_CFG_1_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x0454 + lane * 0x44))
+#define MV_XPCS_LANE_CFG_1_LED0CTRL_OFFS		0
+#define MV_XPCS_LANE_CFG_1_LED0CTRL_MASK    \
+		(0x0000000f << MV_XPCS_LANE_CFG_1_LED0CTRL_OFFS)
+
+#define MV_XPCS_LANE_CFG_1_LED1CTRL_OFFS		4
+#define MV_XPCS_LANE_CFG_1_LED1CTRL_MASK    \
+		(0x0000000f << MV_XPCS_LANE_CFG_1_LED1CTRL_OFFS)
+
+#define MV_XPCS_LANE_CFG_1_TXSWPSEL_OFFS		8
+#define MV_XPCS_LANE_CFG_1_TXSWPSEL_MASK    \
+		(0x00000007 << MV_XPCS_LANE_CFG_1_TXSWPSEL_OFFS)
+
+#define MV_XPCS_LANE_CFG_1_RXSWPSEL_OFFS		11
+#define MV_XPCS_LANE_CFG_1_RXSWPSEL_MASK    \
+		(0x00000007 << MV_XPCS_LANE_CFG_1_RXSWPSEL_OFFS)
+
+
+/* Lane Status */
+#define MV_XPCS_LANE_STATUS_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x045c + lane * 0x44))
+#define MV_XPCS_LANE_STATUS_PRBSCHECKLOCKED_OFFS		0
+#define MV_XPCS_LANE_STATUS_PRBSCHECKLOCKED_MASK    \
+		(0x00000001 << MV_XPCS_LANE_STATUS_PRBSCHECKLOCKED_OFFS)
+
+#define MV_XPCS_LANE_STATUS_PLLLOCKED_OFFS		1
+#define MV_XPCS_LANE_STATUS_PLLLOCKED_MASK    \
+		(0x00000001 << MV_XPCS_LANE_STATUS_PLLLOCKED_OFFS)
+
+#define MV_XPCS_LANE_STATUS_SIGNALDETECTED_OFFS		2
+#define MV_XPCS_LANE_STATUS_SIGNALDETECTED_MASK    \
+		(0x00000001 << MV_XPCS_LANE_STATUS_SIGNALDETECTED_OFFS)
+
+#define MV_XPCS_LANE_STATUS_COMMADETECTED_OFFS		3
+#define MV_XPCS_LANE_STATUS_COMMADETECTED_MASK    \
+		(0x00000001 << MV_XPCS_LANE_STATUS_COMMADETECTED_OFFS)
+
+#define MV_XPCS_LANE_STATUS_SYNCOK_OFFS		4
+#define MV_XPCS_LANE_STATUS_SYNCOK_MASK    \
+		(0x00000001 << MV_XPCS_LANE_STATUS_SYNCOK_OFFS)
+
+
+/* Symbol Error Counter */
+#define MV_XPCS_SYMBOL_ERR_CNTR_REG(lane)		(MV_PP3_XPCS_UNIT_OFFSET + (0x0468 + lane * 0x44))
+#define MV_XPCS_SYMBOL_ERR_CNTR_SYMBOLERRCNT_OFFS	0
+#define MV_XPCS_SYMBOL_ERR_CNTR_SYMBOLERRCNT_MASK    \
+		(0x0000ffff << MV_XPCS_SYMBOL_ERR_CNTR_SYMBOLERRCNT_OFFS)
+
+
+/* Disparity Error Counter */
+#define MV_XPCS_DISPARITY_ERR_CNTR_REG(lane)		(MV_PP3_XPCS_UNIT_OFFSET + (0x046c + lane * 0x44))
+#define MV_XPCS_DISPARITY_ERR_CNTR_DISPARITYERRCNT_OFFS		0
+#define MV_XPCS_DISPARITY_ERR_CNTR_DISPARITYERRCNT_MASK    \
+		(0x0000ffff << MV_XPCS_DISPARITY_ERR_CNTR_DISPARITYERRCNT_OFFS)
+
+
+/* Prbs Error Counter */
+#define MV_XPCS_PRBS_ERR_CNTR_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x0470 + lane * 0x44))
+#define MV_XPCS_PRBS_ERR_CNTR_PRBSERRCNT_OFFS		0
+#define MV_XPCS_PRBS_ERR_CNTR_PRBSERRCNT_MASK    \
+		(0x0000ffff << MV_XPCS_PRBS_ERR_CNTR_PRBSERRCNT_OFFS)
+
+
+/* Rx Packets Counter LSB */
+#define MV_XPCS_RX_PCKTS_CNTR_LSB_REG(lane)		(MV_PP3_XPCS_UNIT_OFFSET + (0x0474 + lane * 0x44))
+#define MV_XPCS_RX_PCKTS_CNTR_LSB_RXPCKTCNTRLSB_OFFS		0
+#define MV_XPCS_RX_PCKTS_CNTR_LSB_RXPCKTCNTRLSB_MASK    \
+		(0x0000ffff << MV_XPCS_RX_PCKTS_CNTR_LSB_RXPCKTCNTRLSB_OFFS)
+
+
+/* Rx Packets Counter MSB */
+#define MV_XPCS_RX_PCKTS_CNTR_MSB_REG(lane)		(MV_PP3_XPCS_UNIT_OFFSET + (0x0478 + lane * 0x44))
+#define MV_XPCS_RX_PCKTS_CNTR_MSB_RXPCKTCNTRMSB_OFFS	0
+#define MV_XPCS_RX_PCKTS_CNTR_MSB_RXPCKTCNTRMSB_MASK    \
+		(0x0000ffff << MV_XPCS_RX_PCKTS_CNTR_MSB_RXPCKTCNTRMSB_OFFS)
+
+
+/* Rx Bad Packets Counter LSB */
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_LSB_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x047c + lane * 0x44))
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_LSB_RXBADPCKTCNTRLSB_OFFS		0
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_LSB_RXBADPCKTCNTRLSB_MASK    \
+		(0x0000ffff << MV_XPCS_RX_BAD_PCKTS_CNTR_LSB_RXBADPCKTCNTRLSB_OFFS)
+
+
+/* Rx Bad Packets Counter MSB */
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_MSB_REG(lane)			(MV_PP3_XPCS_UNIT_OFFSET + (0x0480 + lane * 0x44))
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_MSB_RXBADPCKTCNTRMSB_OFFS		0
+#define MV_XPCS_RX_BAD_PCKTS_CNTR_MSB_RXBADPCKTCNTRMSB_MASK    \
+		(0x0000ffff << MV_XPCS_RX_BAD_PCKTS_CNTR_MSB_RXBADPCKTCNTRMSB_OFFS)
+
+
+/* Cyclic Data 0 */
+#define MV_XPCS_CYCLIC_DATA_0_REG(lane)				(MV_PP3_XPCS_UNIT_OFFSET + (0x0484 + lane * 0x44))
+#define MV_XPCS_CYCLIC_DATA_0_CYCLICDATA0_OFFS		0
+#define MV_XPCS_CYCLIC_DATA_0_CYCLICDATA0_MASK    \
+		(0x000003ff << MV_XPCS_CYCLIC_DATA_0_CYCLICDATA0_OFFS)
+
+
+/* Cyclic Data 1 */
+#define MV_XPCS_CYCLIC_DATA_1_REG(lane)				(MV_PP3_XPCS_UNIT_OFFSET + (0x0488 + lane * 0x44))
+#define MV_XPCS_CYCLIC_DATA_1_CYCLICDATA1_OFFS		0
+#define MV_XPCS_CYCLIC_DATA_1_CYCLICDATA1_MASK    \
+		(0x000003ff << MV_XPCS_CYCLIC_DATA_1_CYCLICDATA1_OFFS)
+
+
+/* Cyclic Data 2 */
+#define MV_XPCS_CYCLIC_DATA_2_REG(lane)				(MV_PP3_XPCS_UNIT_OFFSET + (0x048c + lane * 0x44))
+#define MV_XPCS_CYCLIC_DATA_2_CYCLICDATA2_OFFS		0
+#define MV_XPCS_CYCLIC_DATA_2_CYCLICDATA2_MASK    \
+		(0x000003ff << MV_XPCS_CYCLIC_DATA_2_CYCLICDATA2_OFFS)
+
+
+/* Cyclic Data 3 */
+#define MV_XPCS_CYCLIC_DATA_3_REG(lane)				(MV_PP3_XPCS_UNIT_OFFSET + (0x0490 + lane * 0x44))
+#define MV_XPCS_CYCLIC_DATA_3_CYCLICDATA3_OFFS		0
+#define MV_XPCS_CYCLIC_DATA_3_CYCLICDATA3_MASK    \
+		(0x000003ff << MV_XPCS_CYCLIC_DATA_3_CYCLICDATA3_OFFS)
+
+
+#endif /* __mv_xpcs_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.c b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.c
new file mode 100644
index 0000000..d5a701f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.c
@@ -0,0 +1,90 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/serdes/mv_serdes_if.h"
+#include "gop/serdes/mv_serdes_regs.h"
+
+
+/* print value of unit registers */
+void mv_serdes_lane_regs_dump(int lane)
+{
+	pr_info("\nSerdes Lane #%d registers]\n", lane);
+	mv_gop_reg_print("MV_PP3_SERDES_CFG_0_REG", MV_PP3_SERDES_CFG_0_REG(lane));
+	mv_gop_reg_print("MV_PP3_SERDES_CFG_1_REG", MV_PP3_SERDES_CFG_1_REG(lane));
+	mv_gop_reg_print("MV_PP3_SERDES_CFG_2_REG", MV_PP3_SERDES_CFG_2_REG(lane));
+	mv_gop_reg_print("MV_PP3_SERDES_CFG_3_REG", MV_PP3_SERDES_CFG_3_REG(lane));
+	mv_gop_reg_print("MV_PP3_SERDES_MISC_REG", MV_PP3_SERDES_MISC_REG(lane));
+}
+
+void mv_serdes_init(int lane, enum sd_media_mode mode)
+{
+	u32 reg_val;
+
+	/* Media Interface Mode */
+	reg_val = mv_gop_reg_read(MV_PP3_SERDES_CFG_0_REG(lane));
+	if (mode == MV_RXAUI)
+		reg_val |= MV_PP3_SERDES_CFG_0_MEDIA_MODE_MASK;
+	else
+		reg_val &= ~MV_PP3_SERDES_CFG_0_MEDIA_MODE_MASK;
+
+	/* Pull-Up PLL to StandAlone mode */
+	reg_val |= MV_PP3_SERDES_CFG_0_PU_PLL_MASK;
+	/* powers up the SD Rx/Tx PLL */
+	reg_val |= MV_PP3_SERDES_CFG_0_RX_PLL_MASK;
+	reg_val |= MV_PP3_SERDES_CFG_0_TX_PLL_MASK;
+	mv_gop_reg_write(MV_PP3_SERDES_CFG_0_REG(lane), reg_val);
+
+	mv_serdes_reset(lane, false, false, false);
+
+	reg_val = 0x17f;
+	mv_gop_reg_write(MV_PP3_SERDES_MISC_REG(lane), reg_val);
+}
+
+void mv_serdes_reset(int lane, bool analog_reset, bool core_reset, bool digital_reset)
+{
+	u32 reg_val;
+
+	reg_val = mv_gop_reg_read(MV_PP3_SERDES_CFG_1_REG(lane));
+	if (analog_reset)
+		reg_val &= ~MV_PP3_SERDES_CFG_1_ANALOG_RESET_MASK;
+	else
+		reg_val |= MV_PP3_SERDES_CFG_1_ANALOG_RESET_MASK;
+
+	if (core_reset)
+		reg_val &= ~MV_PP3_SERDES_CFG_1_CORE_RESET_MASK;
+	else
+		reg_val |= MV_PP3_SERDES_CFG_1_CORE_RESET_MASK;
+
+	if (digital_reset)
+		reg_val &= ~MV_PP3_SERDES_CFG_1_DIGITAL_RESET_MASK;
+	else
+		reg_val |= MV_PP3_SERDES_CFG_1_DIGITAL_RESET_MASK;
+
+	mv_gop_reg_write(MV_PP3_SERDES_CFG_1_REG(lane), reg_val);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.h b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.h
new file mode 100644
index 0000000..87beaaa
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_if.h
@@ -0,0 +1,43 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_serdes_if_h__
+#define __mv_serdes_if_h__
+
+#include "common/mv_sw_if.h"
+#include "gop/mv_gop_if.h"
+
+enum sd_media_mode {MV_RXAUI, MV_XAUI};
+
+/* print value of Serdes Lane registers */
+void mv_serdes_lane_regs_dump(int lane);
+
+/* Init Serdes lane registers */
+void mv_serdes_init(int lane, enum sd_media_mode mode);
+void mv_serdes_reset(int lane, bool analog_reset, bool core_reset, bool digital_reset);
+
+#endif /* __mv_serdes_if_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_regs.h b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_regs.h
new file mode 100644
index 0000000..deef359
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/gop/serdes/mv_serdes_regs.h
@@ -0,0 +1,69 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_serdes_regs_h__
+#define __mv_serdes_regs_h__
+
+/* includes */
+
+/* unit offset */
+#define MV_PP3_SERDES_UNIT_OFFSET		0x04000000
+
+#define MV_PP3_SERDES_CFG_0_REG(lane)		(MV_PP3_SERDES_UNIT_OFFSET + 0x00 + (lane * 0x1000))
+
+#define MV_PP3_SERDES_CFG_0_PU_PLL_OFFS		1
+#define MV_PP3_SERDES_CFG_0_PU_PLL_MASK		(0x00000001 << MV_PP3_SERDES_CFG_0_PU_PLL_OFFS)
+#define MV_PP3_SERDES_CFG_0_RX_PLL_OFFS		11
+#define MV_PP3_SERDES_CFG_0_RX_PLL_MASK		(0x00000001 << MV_PP3_SERDES_CFG_0_RX_PLL_OFFS)
+#define MV_PP3_SERDES_CFG_0_TX_PLL_OFFS		12
+#define MV_PP3_SERDES_CFG_0_TX_PLL_MASK		(0x00000001 << MV_PP3_SERDES_CFG_0_TX_PLL_OFFS)
+#define MV_PP3_SERDES_CFG_0_MEDIA_MODE_OFFS	15
+#define MV_PP3_SERDES_CFG_0_MEDIA_MODE_MASK	(0x00000001 << MV_PP3_SERDES_CFG_0_MEDIA_MODE_OFFS)
+
+#define MV_PP3_SERDES_CFG_1_REG(lane)		(MV_PP3_SERDES_UNIT_OFFSET + 0x04 + (lane * 0x1000))
+#define MV_PP3_SERDES_CFG_1_ANALOG_RESET_OFFS		3
+#define MV_PP3_SERDES_CFG_1_ANALOG_RESET_MASK    \
+		(0x00000001 << MV_PP3_SERDES_CFG_1_ANALOG_RESET_OFFS)
+
+#define MV_PP3_SERDES_CFG_1_CORE_RESET_OFFS		5
+#define MV_PP3_SERDES_CFG_1_CORE_RESET_MASK    \
+		(0x00000001 << MV_PP3_SERDES_CFG_1_CORE_RESET_OFFS)
+
+#define MV_PP3_SERDES_CFG_1_DIGITAL_RESET_OFFS		6
+#define MV_PP3_SERDES_CFG_1_DIGITAL_RESET_MASK    \
+		(0x00000001 << MV_PP3_SERDES_CFG_1_DIGITAL_RESET_OFFS)
+
+#define MV_PP3_SERDES_CFG_1_TX_SYNC_EN_OFFS		7
+#define MV_PP3_SERDES_CFG_1_TX_SYNC_EN_MASK    \
+		(0x00000001 << MV_PP3_SERDES_CFG_1_TX_SYNC_EN_OFFS)
+
+#define MV_PP3_SERDES_CFG_2_REG(lane)		(MV_PP3_SERDES_UNIT_OFFSET + 0x08 + (lane * 0x1000))
+#define MV_PP3_SERDES_CFG_3_REG(lane)		(MV_PP3_SERDES_UNIT_OFFSET + 0x0c + (lane * 0x1000))
+#define MV_PP3_SERDES_MISC_REG(lane)		(MV_PP3_SERDES_UNIT_OFFSET + 0x14 + (lane * 0x1000))
+
+#endif /* __mv_serdes_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
new file mode 100644
index 0000000..6522706
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
@@ -0,0 +1,919 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "platform/mv_pp3.h"
+#include "hmac/mv_hmac.h"
+
+#ifdef PP3_DEBUG
+#define PP3_HMAC_DEBUG pr_info("\n%s::", __func__)
+#else
+#define PP3_HMAC_DEBUG
+#endif
+
+int mv_pp3_hmac_debug_flags;
+int mv_pp3_hmac_hz_tclk;
+
+struct mv_unit_info pp3_hmac_gl;
+struct mv_unit_info pp3_hmac_fr;
+
+/* Array of pointers to HMAC queue control structure */
+struct mv_pp3_hmac_queue_ctrl *mv_hmac_rxq_handle[MV_PP3_HFRM_NUM][MV_PP3_HFRM_Q_NUM];
+struct mv_pp3_hmac_queue_ctrl *mv_hmac_txq_handle[MV_PP3_HFRM_NUM][MV_PP3_HFRM_Q_NUM];
+
+/* local functions declaration */
+static int mv_pp3_hmac_queue_create(struct mv_pp3_hmac_queue_ctrl *q_ctrl);
+
+/* platform pointer for dma operation */
+static struct mv_pp3 *pp3_priv;
+
+/* general functions */
+/* HMAC unit init */
+void mv_pp3_hmac_init(struct mv_pp3 *priv)
+{
+	void __iomem *base = mv_pp3_nss_regs_vaddr_get();
+
+	mv_pp3_hmac_hz_tclk = mv_pp3_silicon_tclk_get();
+	mv_pp3_hmac_gl_unit_base(base);
+	mv_pp3_hmac_frame_unit_base(base, MV_PP3_HMAC_FR_INST_OFFSET);
+	pp3_priv = priv;
+}
+
+/* store unit base address = silicon base address + unit offset */
+void mv_pp3_hmac_gl_unit_base(void __iomem *unit_base)
+{
+	pp3_hmac_gl.base_addr = unit_base;
+	pp3_hmac_gl.ins_offs = 0;
+}
+
+/* store unit base address = silicon base address + unit offset */
+/* store unit instance offset                                   */
+void mv_pp3_hmac_frame_unit_base(void __iomem *unit_base, unsigned int ins_offset)
+{
+	pp3_hmac_fr.base_addr = unit_base;
+	pp3_hmac_fr.ins_offs = ins_offset;
+}
+
+/* configure rxq packets coalesing profile */
+void mv_pp3_hmac_rxq_time_coal_profile_set(int frame, int queue, int profile)
+{
+	u32 reg_data;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+
+	if (profile)
+		reg_data |= MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_MASK;
+	else
+		reg_data &= ~MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_MASK;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_RX_Q_CTRL_REG(queue), reg_data);
+}
+
+/* configure frame time coalesing profile
+   inputs:
+	frame - frame id
+	profile - time profile num (0 or 1)
+	usec - time in micro seconds, if usec is zero time timer is disabled
+*/
+void mv_pp3_hmac_frame_time_coal_set(int frame, int profile, int usec)
+{
+	u32 reg_data;
+	int t_clk_usec;
+
+	/* Register contains interrupt time in units of 256 core clock cycles */
+
+	t_clk_usec = mv_pp3_hmac_hz_tclk / 1000000;
+	t_clk_usec = MV_ALIGN_UP(t_clk_usec * usec, 256);
+
+	if ((t_clk_usec != 0) && (t_clk_usec < 256))
+		t_clk_usec = 256;
+
+	t_clk_usec = t_clk_usec / 256;
+
+	reg_data = mv_pp3_hmac_gl_reg_read(MV_HMAC_RX_Q_TIMEOUT_REG(frame));
+	if (profile) {
+		reg_data &= ~MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_MASK;
+		reg_data |= ((t_clk_usec) << MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_OFFS);
+	} else {
+		reg_data &= ~MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_MASK;
+		reg_data |= ((t_clk_usec) << MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_OFFS);
+	}
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_RX_Q_TIMEOUT_REG(frame), reg_data);
+}
+
+/* configure frame parameters */
+void mv_pp3_hmac_frame_cfg(u32 frame, u8 vm_id)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+	reg_data = mv_pp3_hmac_gl_reg_read(MV_HMAC_VMID_FRAME_REG(frame));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_VMID_FRAME_CONTEXT_ID_MASK,
+		(vm_id & MV_HMAC_VMID_FRAME_CONTEXT_ID_MASK) << MV_HMAC_VMID_FRAME_CONTEXT_ID_OFFS);
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_VMID_FRAME_AXI_PROT_PRIVILEGE_MASK,
+			((vm_id >> 6) & 1) << MV_HMAC_VMID_FRAME_AXI_PROT_PRIVILEGE_OFFS);
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_VMID_FRAME_REG(frame), reg_data);
+
+	reg_data = mv_pp3_hmac_gl_reg_read(MV_HMAC_AXI_PROT_SECURE_REG(frame));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_MASK,
+	((vm_id >> 7) & MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_MASK) << MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_OFFS);
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_AXI_PROT_SECURE_REG(frame), reg_data);
+#ifdef CONFIG_MV_PP3_FPGA
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_ADDR_LOW_REG(frame), 0);
+	/* disable all frame events */
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_MASK_REG(frame), MV_HMAC_EVENT_MASK_GROUP_DIS_MASK);
+#else
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_ADDR_LOW_REG(frame),
+		mv_pp3_internal_regs_paddr_get(pp3_priv) + MV_A390_GIC_INTERRUPT_REG(frame));
+#endif
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_ADDR_HIGH_REG(frame), 0);
+}
+
+
+/* configure queue to be used like BM queue */
+void mv_pp3_hmac_queue_bm_mode_cfg(int frame, int queue)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_Q_MODE_MASK, 1 << MV_HMAC_SEND_Q_CTRL_Q_MODE_OFFS);
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_MASK, 1 << MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_OFFS);
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+}
+
+/* configure queue parameters used by QM queue
+ * qm_num - is a number of QM queue                   */
+void mv_pp3_hmac_queue_qm_mode_cfg(int frame, int queue, int qm_num)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+	/* configure queue to be QM queue */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_Q_MODE_MASK, 0);
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+	/* map QM queue number */
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_NUM_BPID_REG(queue), qm_num);
+}
+
+/* Allocate queue memory and queue control structure
+ * size is a queue size in datagrams (16 bytes each) will align to 8 datagramms
+ * Returns - pointer to HMAC queue structure */
+static void *mv_pp3_hmac_queue_alloc(int size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
+
+	if (size > MV_PP3_HMAC_Q_SIZE_MASK) {
+		pr_err("%s: cannot create HMAC RX queue, size %d too big", __func__, size);
+		return NULL;
+	}
+
+	if (MV_IS_NOT_ALIGN(size, MV_PP3_CFH_DG_MAX_NUM)) {
+		pr_err("%s: Illegal queue size %d.", __func__, size);
+		return NULL;
+	}
+
+	/* 140 DG - HMAC internal FIFO size */
+	/* 32 DG - BP Hysteresis recomented value */
+	if (size <= (140 + 32)) {
+		pr_err("%s: cannot create HMAC RX queue, size %d too small", __func__, size);
+		return NULL;
+	}
+
+	/* allocate hmac queue control stucture */
+	qctrl = kmalloc(sizeof(struct mv_pp3_hmac_queue_ctrl), GFP_KERNEL);
+	if (qctrl == NULL) {
+		pr_err("%s: cannot create HMAC RX queue, no memory", __func__);
+		return NULL;
+	}
+
+	qctrl->size = size;
+	if (mv_pp3_hmac_queue_create(qctrl) != 0) {
+		kfree(qctrl);
+		return NULL;
+	}
+
+	/* default capacity is a queue size */
+	qctrl->capacity = size;
+
+	return qctrl;
+}
+
+/************************ RX queue functions **************************************************/
+/* Allocate memory and init RX queue HW facility
+ * size is a queue size in datagrams (16 bytes each) will align to 8 datagramms
+ * Returns - pointer to HMAC RX queue structure */
+void *mv_pp3_hmac_rxq_init(int frame, int queue, int size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
+	u32 reg_data;
+	u32 phys_addr;
+
+	PP3_HMAC_DEBUG;
+
+	if (mv_hmac_rxq_handle[frame][queue] == NULL) {
+		qctrl = mv_pp3_hmac_queue_alloc(size);
+		if (qctrl == NULL)
+			return qctrl;
+		mv_hmac_rxq_handle[frame][queue] = qctrl;
+	} else
+		qctrl = mv_hmac_rxq_handle[frame][queue];
+
+	/* Write pointer to allocated memory */
+	phys_addr = mv_pp3_os_dma_map_single(mv_pp3_dev_get(pp3_priv), qctrl->first, size, DMA_FROM_DEVICE);
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_ADDR_LOW(queue), phys_addr);
+	/* Store queue size in rq_size table, number of 16B units */
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_SIZE(queue), (u32)qctrl->size);
+
+	/* disable all queue events */
+	reg_data = MV_PP3_HMAC_RQ_EVENT0_DIS_MASK | MV_PP3_HMAC_RQ_EVENT1_DIS_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+
+	return qctrl;
+}
+
+int mv_pp3_hmac_rxq_bp_thresh_set(int frame, int queue, int thresh_dg)
+{
+	u32 reg_data;
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_rxq_handle[frame][queue];
+
+	if (qctrl == NULL) {
+		pr_err("%s: HMAC rxq: frame=%d, rxq=%d doesn't exist\n", __func__,
+			frame, queue);
+		return -1;
+	}
+
+	if (thresh_dg > qctrl->size) {
+		pr_err("%s: XOFF threshold #%d [dg] is too large. Maximum is #%d [dg]\n", __func__,
+			thresh_dg, qctrl->size);
+		return -1;
+	}
+	/* maximum XOFF threshold must be less than RQ allocated size by 140 dg */
+	if (thresh_dg > (qctrl->size - 140))
+		thresh_dg = qctrl->size - 140;
+
+	reg_data = (thresh_dg << MV_PP3_HMAC_RQ_BP_XOFF_THRESH_OFFS);
+
+	/* XON threshold must be less than XOFF threshold (32 dg) */
+	reg_data |= ((thresh_dg - 32) << MV_PP3_HMAC_RQ_BP_XON_THRESH_OFFS);
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_BACK_PRES0(queue), reg_data);
+
+	return 0;
+}
+
+/* Configure Receive queue threshold.
+* node_type	- BP levels: Q=0, A=1, B=2, C=3, P=4
+* node_id	- number of node type
+* BP threshold set to maximum possible value accordingly with allocated RQ size
+*/
+void mv_pp3_hmac_rxq_bp_node_set(int frame, int queue, enum mv_qm_node_type node_type, int node_id)
+{
+	u32 reg_data;
+
+	reg_data = (node_type << 12); /* BP levels: Q=0, A=1, B=2, C=3, P=4 */
+	reg_data |= node_id;          /* BP node number */
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_BACK_PRES1(queue), reg_data);
+}
+
+void mv_pp3_hmac_rxq_flush(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Enable queue flush*/
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+	reg_data |= MV_HMAC_RX_Q_CTRL_RCV_Q_FLUSH_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_RX_Q_CTRL_REG(queue), reg_data);
+
+	/* clear the reflected pointers and HMAC internal registers */
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_OCC_STATUS(queue), 0);
+
+	/* Disable queue flush*/
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+	reg_data &= ~MV_HMAC_RX_Q_CTRL_RCV_Q_FLUSH_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_RX_Q_CTRL_REG(queue), reg_data);
+}
+
+void mv_pp3_hmac_rxq_enable(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Enable queue */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_RX_Q_CTRL_RCV_Q_EN_MASK, 1 << MV_HMAC_RX_Q_CTRL_RCV_Q_EN_OFFS);
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_RX_Q_CTRL_REG(queue), reg_data);
+}
+
+void mv_pp3_hmac_rxq_disable(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Disable queue */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_RX_Q_CTRL_RCV_Q_EN_MASK, 0);
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_RX_Q_CTRL_REG(queue), reg_data);
+}
+
+/* Connect one of queue RX events to SPI interrupt group
+Inputs:
+	event - HMAC Rx event
+	 * 0 - QM queue - Timeout or new items added to the queue
+	 *     BM queue - allocate completed
+	 * 1 - QM queue only - Receive queue almost full
+	group - SPI group for event (0 - 7)
+*/
+void mv_pp3_hmac_rxq_event_cfg(int frame, int queue, int event, int group)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+	/* Configure event group */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	if (event == 0) {
+		/* set group for event 0 */
+		MV_U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT0_GROUP_MASK, group << MV_PP3_HMAC_RQ_EVENT0_GROUP_OFFS);
+		/* enable event,  0 is active */
+		reg_data &= ~MV_PP3_HMAC_RQ_EVENT0_DIS_MASK;
+	} else if (event == 1) {
+		MV_U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT1_GROUP_MASK, group << MV_PP3_HMAC_RQ_EVENT1_GROUP_OFFS);
+		/* enable event */
+		reg_data &= ~MV_PP3_HMAC_RQ_EVENT1_DIS_MASK;
+	}
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+}
+
+/* Disable RX events on queue
+	QM queue - Timeout or new items added to the queue
+	BM queue - allocate completed
+*/
+void mv_pp3_hmac_rxq_event_disable(int frame, int queue)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	reg_data |= MV_PP3_HMAC_RQ_EVENT0_DIS_MASK;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+}
+
+/* Enable RX events on queue
+	QM queue - Timeout or new items added to the queue
+	BM queue - allocate completed
+*/
+void mv_pp3_hmac_rxq_event_enable(int frame, int queue)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	reg_data &= ~MV_PP3_HMAC_RQ_EVENT0_DIS_MASK;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+}
+
+/* Pause RX events on queue */
+void mv_pp3_hmac_rxq_pause(int frame, int queue)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	reg_data |= MV_PP3_HMAC_RQ_EVENT0_DIS_MASK;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+}
+
+/* Resume RX events on queue */
+void mv_pp3_hmac_rxq_resume(int frame, int queue)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	reg_data &= ~MV_PP3_HMAC_RQ_EVENT0_DIS_MASK;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+	/* clear the reflected pointers and HMAC internal registers */
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_OCC_STATUS(queue), 0);
+}
+
+/************************ TX queue functions **************************************************/
+/* Allocate memory and init TX queue HW facility
+ * size - queue size in datagrams (16 bytes each)
+ * cfh_size - if not 0, define queue with constant CFH size (number of datagrams in CFH)
+ * Returns - pointer to HMAC TX queue structure */
+void *mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
+	u32 reg_data;
+	u32 phys_addr;
+
+	PP3_HMAC_DEBUG;
+
+	if (mv_hmac_txq_handle[frame][queue] == NULL) {
+		qctrl = mv_pp3_hmac_queue_alloc(size);
+		if (qctrl == NULL)
+			return qctrl;
+		mv_hmac_txq_handle[frame][queue] = qctrl;
+	} else
+		qctrl = mv_hmac_txq_handle[frame][queue];
+
+	qctrl->cfh_size = cfh_size;
+
+	/* Write pointer to allocated memory */
+	phys_addr = mv_pp3_os_dma_map_single(mv_pp3_dev_get(pp3_priv), qctrl->first, size, DMA_TO_DEVICE);
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_ADDR_LOW(queue), phys_addr);
+	/* Store queue size in rq_size table, number of 16B units */
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_SIZE(queue), (u32)qctrl->size);
+
+	/* disable all queue events */
+	reg_data = MV_PP3_HMAC_SQ_EVENT_DIS_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_EVENT_GROUP(queue), reg_data);
+
+	return qctrl;
+}
+
+void mv_pp3_hmac_txq_flush(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Enable queue flush */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	reg_data |= MV_HMAC_SEND_Q_CTRL_SEND_Q_FLUSH_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+
+	/* clear reflected pointers and HMAC internal registers */
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue), 0);
+
+	/* Disable queue flush */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	reg_data &= ~MV_HMAC_SEND_Q_CTRL_SEND_Q_FLUSH_MASK;
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+}
+
+void mv_pp3_hmac_txq_enable(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Enable queue */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_MASK, 1 << MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_OFFS);
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+}
+
+void mv_pp3_hmac_txq_disable(int frame, int queue)
+{
+	u32 reg_data;
+
+	/* Disable queue */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	MV_U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_MASK, 0);
+	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
+}
+
+/* Local functions */
+static int mv_pp3_hmac_queue_create(struct mv_pp3_hmac_queue_ctrl *q_ctrl)
+{
+	int size;
+	int tail_room = MV_PP3_HMAC_Q_ALIGN;
+
+	/* CFH buffer must be aligned to 256B */
+	size = q_ctrl->size * MV_PP3_CFH_DG_SIZE; /* in bytes */
+	/* Allocate memory for queue. Add tail buffer to handle split CFH. */
+	q_ctrl->first = kzalloc(size + tail_room, GFP_ATOMIC);
+	if (q_ctrl->first) {
+		if (MV_IS_NOT_ALIGN((u32)(q_ctrl->first), MV_PP3_HMAC_Q_ALIGN)) {
+			pr_err("%s: Allocate not aligned pointer 0x%p (%d bytes)\n", __func__, q_ctrl->first, size);
+			q_ctrl->first = 0;
+			return -1;
+		}
+	}
+	if (q_ctrl->first == NULL) {
+		pr_err("%s: Can't allocate %d bytes for HMAC queue.\n", __func__, size);
+		return -1;
+	}
+
+	q_ctrl->next_proc = q_ctrl->first;
+	q_ctrl->occ_dg = 0;
+	q_ctrl->dummy_dg = 0;
+	q_ctrl->cfh_size = 0;
+	q_ctrl->end = q_ctrl->first + size;
+
+	return 0;
+}
+
+/* Connect queue TX event to SPI interrupt group (BM queue only)
+Inputs:
+	group - SPI group for event (0 - 7)
+*/
+void mv_pp3_hmac_txq_event_cfg(int frame, int queue, int group)
+{
+	u32 reg_data;
+
+	PP3_HMAC_DEBUG;
+	/* Configure event group */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_EVENT_GROUP(queue));
+	/* set group for event 0 */
+	MV_U32_SET_FIELD(reg_data, MV_PP3_HMAC_SQ_EVENT_GROUP_MASK, group << MV_PP3_HMAC_SQ_EVENT_GROUP_OFFS);
+	/* enable event */
+	MV_U32_SET_FIELD(reg_data, MV_PP3_HMAC_SQ_EVENT_DIS_MASK, 1 << MV_PP3_HMAC_SQ_EVENT_DIS_OFFS);
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_EVENT_GROUP(queue), reg_data);
+}
+
+/************************ Print HMAC Frame unit register **************************************/
+static void mv_pp3_hmac_fr_reg_print(int frame, char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%04x = 0x%08x\n", reg_name, reg, mv_pp3_hmac_frame_reg_read(frame, reg));
+}
+
+static void mv_pp3_hmac_global_reg_print(char *reg_name, u32 reg)
+{
+	pr_info("  %-32s: 0x%04x = 0x%08x\n", reg_name, reg, mv_pp3_hmac_gl_reg_read(reg));
+}
+
+/* dump hmac queue registers */
+void mv_pp3_hmac_rxq_regs_dump(int frame, int queue)
+{
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	pr_info("\n-------------- HMAC RX (frame = %d, queue = %d) regs (%p)-----------\n",
+		frame, queue, pp3_hmac_fr.base_addr + pp3_hmac_fr.ins_offs * frame);
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE CONTROL", MV_HMAC_RX_Q_CTRL_REG(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE STATUS", MV_HMAC_RX_Q_STATUS_REG(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE ADDRESS LOW", MV_PP3_HMAC_RQ_ADDR_LOW(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE SIZE", MV_PP3_HMAC_RQ_SIZE(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "OCCUPIED STATUS", MV_PP3_HMAC_RQ_OCC_STATUS(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "AXI ATTRIBUTES", MV_PP3_HMAC_RQ_AXI_ATTR(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "EVENT GROUP", MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "INTERRUPT THRESHOLD", MV_PP3_HMAC_RQ_INT_THRESH(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "BACK PRESSURE 0", MV_PP3_HMAC_RQ_BACK_PRES0(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "BACK PRESSURE 1", MV_PP3_HMAC_RQ_BACK_PRES1(queue));
+}
+
+/* dump hmac queue registers */
+void mv_pp3_hmac_txq_regs_dump(int frame, int queue)
+{
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	pr_info("\n-------------- HMAC TX (frame = %d, queue = %d) regs (%p)-----------\n",
+		frame, queue, pp3_hmac_fr.base_addr + pp3_hmac_fr.ins_offs * frame);
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE CONTROL", MV_HMAC_SEND_Q_CTRL_REG(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE NUMBER BPID", MV_HMAC_SEND_Q_NUM_BPID_REG(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE STATUS", MV_HMAC_SEND_Q_STATUS_REG(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE ADDRESS LOW", MV_PP3_HMAC_SQ_ADDR_LOW(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "QUEUE SIZE", MV_PP3_HMAC_SQ_SIZE(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "OCCUPIED STATUS", MV_PP3_HMAC_SQ_OCC_STATUS(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "AXI ATTRIBUTES", MV_PP3_HMAC_SQ_AXI_ATTR(queue));
+	mv_pp3_hmac_fr_reg_print(frame, "EVENT GROUP", MV_PP3_HMAC_SQ_EVENT_GROUP(queue));
+}
+
+void mv_pp3_hmac_frame_regs_dump(int frame)
+{
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+
+	pr_info("\n-------------- HMAC Frame %d regs -----------\n", frame);
+	mv_pp3_hmac_global_reg_print("VMID", MV_HMAC_VMID_FRAME_REG(frame));
+	mv_pp3_hmac_global_reg_print("EVENT ADDRESS LOW", MV_HMAC_EVENT_ADDR_LOW_REG(frame));
+	mv_pp3_hmac_global_reg_print("EVENT ADDRESS HIGH", MV_HMAC_EVENT_ADDR_HIGH_REG(frame));
+	mv_pp3_hmac_global_reg_print("EVENT MASK", MV_HMAC_EVENT_MASK_REG(frame));
+	mv_pp3_hmac_global_reg_print("AXI PROTECTION SECURE", MV_HMAC_AXI_PROT_SECURE_REG(frame));
+	mv_pp3_hmac_global_reg_print("RX TIMEOUT", MV_HMAC_RX_Q_TIMEOUT_REG(frame));
+	mv_pp3_hmac_global_reg_print("TX TIMEOUT", MV_HMAC_SEND_Q_TIMEOUT_REG(frame));
+}
+
+void mv_pp3_hmac_global_regs_dump(void)
+{
+	pr_info("\n-------------- HMAC Golbal regs (%p) -----------\n", pp3_hmac_gl.base_addr);
+	mv_pp3_hmac_global_reg_print("ECO", MV_HMAC_ECO_REG);
+	mv_pp3_hmac_global_reg_print("RECEIVE QM Port", MV_HMAC_RX_QM_PORT_NUMBER_REG);
+	mv_pp3_hmac_global_reg_print("AXI INTERRUPT CAUSE", MV_HMAC_AXI_INT_CAUSE);
+	mv_pp3_hmac_global_reg_print("AXI INTERRUPT MASK", MV_HMAC_AXI_INT_MASK);
+	mv_pp3_hmac_global_reg_print("AXI INTERRUPT SYNDROME", MV_HMAC_AXI_INT_SYNDROME);
+	mv_pp3_hmac_global_reg_print("MISC INTERRUPT CAUSE", MV_HMAC_MISC_INT_CAUSE);
+	mv_pp3_hmac_global_reg_print("MISC INTERRUPT MASK", MV_HMAC_MISC_INT_MASK);
+	mv_pp3_hmac_global_reg_print("MISC INTERRUPT SYNDROME", MV_HMAC_MISC_INT_SYNDROME);
+	mv_pp3_hmac_global_reg_print("HMAC BUSY", MV_HMAC_BUSY_REG);
+}
+
+static void mv_pp3_hmac_rxq_queue_show(int frame, int queue)
+{
+	struct mv_pp3_hmac_queue_ctrl *rxq = mv_hmac_rxq_handle[frame][queue];
+	u32 reg_data;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_SIZE(queue));
+	pr_info("Size in datargams          : %-4d\t\t(%d)\n", MV_PP3_HMAC_Q_SIZE_MASK & reg_data, rxq->size);
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_ADDR_LOW(queue));
+	pr_info("First CFH                  : 0x%08x\t\t(0x%p)\n", reg_data, rxq->first);
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_OCC_STATUS(queue));
+	pr_info("Next to process            : 0x%04x\t\t(0x%p)\n",
+		((reg_data >> 16) & MV_PP3_HMAC_OCC_COUNTER_MASK) * 16, rxq->next_proc);
+	pr_info("Occupated datagrams        : %-4d\n", reg_data & MV_PP3_HMAC_OCC_COUNTER_MASK);
+
+	return;
+}
+
+static void mv_pp3_hmac_txq_queue_show(int frame, int queue)
+{
+	struct mv_pp3_hmac_queue_ctrl *txq = mv_hmac_txq_handle[frame][queue];
+	u32 reg_data;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_SIZE(queue));
+	pr_info("Capacity in datagrams      : %-4d\n", txq->capacity);
+	pr_info("Size in datargams          : %-4d\t\t(%d)\n", MV_PP3_HMAC_Q_SIZE_MASK & reg_data, txq->size);
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_ADDR_LOW(queue));
+	pr_info("First CFH                  : 0x%08x\t\t(0x%p)\n", reg_data, txq->first);
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue));
+	pr_info("Next to process            : 0x%04x\t\t(0x%p)\n",
+			((reg_data >> 16) & MV_PP3_HMAC_OCC_COUNTER_MASK) * 16,	txq->next_proc);
+	pr_info("Occupied datagrams         : %-4d\t\t(%d)\n", reg_data & MV_PP3_HMAC_OCC_COUNTER_MASK, txq->occ_dg);
+	if (txq->cfh_size)
+		/* relevant for txq with constant CFH size */
+		pr_info("CFH size                   : %d\n", txq->cfh_size);
+
+	return;
+}
+
+static void mv_pp3_hmac_queue_dump(struct mv_pp3_hmac_queue_ctrl *qctrl, bool print_all)
+{
+	struct cfh_common_format *cfh;
+	u32 *tmp_cfh;
+	u8  *cfh_curr;
+	unsigned int cfh_size; /* real CFH size aligned to 16 bytes in bytes */
+	int i, j;
+
+	j = 1;
+	cfh = (struct cfh_common_format *)qctrl->first;
+	cfh_curr = (u8 *)qctrl->first;
+	do {
+		cfh_size = cfh->cfh_length;
+		tmp_cfh = (u32 *)cfh_curr;
+		pr_info("%3d. cfh_ptr=0x%p: cfh_length=%3d, pkt_length=%5d, qm_cntrl=0x%04x, cfh_format=0x%02x, bp_id=%2d\n",
+			j++, cfh, cfh_size, cfh->pkt_length, cfh->qm_cntrl, cfh->cfh_format, cfh->bp_id);
+		pr_info("     Common CFH   : ");
+		for (i = 0; i < 32/4; i++)
+			pr_cont("0x%08x ", tmp_cfh[i]);
+
+		if (print_all && (cfh_size > 32)) {
+			u8 *tmp;
+			pr_info("     Data         : ");
+			tmp = (u8 *)&tmp_cfh[8];
+			for (i = 0; i < cfh_size - 32; i++) {
+				if ((i != 0) && ((i%32) == 0))
+					pr_cont("\n                    ");
+				pr_cont("%02x ", tmp[i]);
+			}
+			pr_info("\n");
+		}
+		cfh_size = MV_ALIGN_UP(cfh_size, 16);
+		cfh_curr += cfh_size;
+		cfh = (struct cfh_common_format *)cfh_curr;
+	} while ((cfh_size > 0) && ((u8 *)cfh < qctrl->end));
+	pr_info("\n");
+}
+
+void mv_pp3_hmac_rxq_bp_show(int frame, int queue)
+{
+	u32 reg_data;
+	char level;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_BACK_PRES1(queue));
+
+	switch ((reg_data >> 12) & 7) {
+	case 0:
+		level = 'Q';
+		break;
+	case 1:
+		level = 'A';
+		break;
+	case 2:
+		level = 'B';
+		break;
+	case 3:
+		level = 'C';
+		break;
+	case 4:
+		level = 'P';
+		break;
+	default:
+		level = 'N';
+		break;
+	}
+	pr_info("Back pressure node         : %c %d\n", level, reg_data & 0xFFF);
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_BACK_PRES0(queue));
+	pr_info("Back pressure ON (dg)      : %d\n", (reg_data >> 16) & 0xFFFF);
+	pr_info("Back pressure OFF (dg)     : %d\n", reg_data & 0xFFFF);
+}
+
+void mv_pp3_hmac_rxq_coal_get(int frame, int queue, int *profile, int *dg_num)
+{
+	u32 reg_data;
+
+	if (profile) {
+		reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+		*profile = (reg_data >> MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_OFFS) & 1;
+	}
+
+	if (dg_num)
+		*dg_num = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_INT_THRESH(queue));
+}
+
+void mv_pp3_hmac_frame_time_coal_get(int frame, int profile, int *usec)
+{
+	int tmp;
+	u32 reg_data;
+
+	reg_data = mv_pp3_hmac_gl_reg_read(MV_HMAC_RX_Q_TIMEOUT_REG(frame));
+	tmp = (profile) ? (reg_data >> MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_OFFS) & 0x7FF :
+		(reg_data >> MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_OFFS) & 0x7FF;
+
+	/* Register contains interrupt time in units of 256 core clock cycles */
+	*usec = tmp * 256 / (mv_pp3_hmac_hz_tclk / 1000000);
+}
+
+void mv_pp3_hmac_rxq_coal_show(int frame, int queue)
+{
+	int profile, time, dg;
+
+	mv_pp3_hmac_rxq_coal_get(frame, queue, &profile, &dg);
+	mv_pp3_hmac_frame_time_coal_get(frame, profile, &time);
+	pr_info("Interrupt coal (datagrams) : %d\n", dg);
+	pr_info("Interrupt time coal (usec) : %d\t\t(profile %d)\n", time, profile);
+}
+
+static void mv_pp3_hmac_rxq_status_show(int frame, int queue)
+{
+	u32 reg_data;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_CTRL_REG(queue));
+	pr_info("Queue status               : ");
+	if (reg_data & MV_HMAC_RX_Q_CTRL_RCV_Q_EN_MASK)
+		pr_cont("enabled");
+	else
+		pr_cont("disabled");
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_STATUS_REG(queue));
+	if (reg_data & MV_HMAC_RX_Q_STATUS_RQ_BUSY_MASK)
+		pr_cont(", busy");
+
+	pr_info("\n");
+}
+
+static void mv_pp3_hmac_txq_status_show(int frame, int queue)
+{
+	u32 reg_data, status;
+
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
+	pr_info("Queue status               : ");
+	if (reg_data & MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_MASK)
+		pr_cont("enabled");
+	else
+		pr_cont("disabled");
+	status = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_STATUS_REG(queue));
+	if (status & MV_HMAC_SEND_Q_STATUS_SQ_BUSY_MASK)
+		pr_cont(", busy");
+	if (status & MV_HMAC_SEND_Q_STATUS_SQ_QM_BP_OFF_OFFS)
+		pr_cont(", BP OFF");
+
+	if (reg_data & MV_HMAC_SEND_Q_CTRL_Q_MODE_MASK) {
+		pr_info("BM queue                   : ");
+		if (reg_data & MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_MASK)
+			pr_cont("double PE");
+		else
+			pr_cont("single PE");
+	}
+	pr_info("\n");
+}
+
+
+void mv_pp3_hmac_rx_queue_show(int frame, int queue)
+{
+	pr_info("\n-------------- HMAC RX frame: #%d, queue: #%d --------------\n", frame, queue);
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	mv_pp3_hmac_rxq_status_show(frame, queue);
+
+	if (!mv_hmac_rxq_handle[frame][queue])
+		return;
+
+	mv_pp3_hmac_rxq_queue_show(frame, queue);
+	mv_pp3_hmac_rxq_bp_show(frame, queue);
+	mv_pp3_hmac_rxq_coal_show(frame, queue);
+}
+
+void mv_pp3_hmac_tx_queue_show(int frame, int queue)
+{
+	pr_info("\n-------------- HMAC TX frame: #%d, queue: #%d -------------\n", frame, queue);
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	mv_pp3_hmac_txq_status_show(frame, queue);
+
+	if (!mv_hmac_txq_handle[frame][queue]) {
+		pr_info("\n");
+		return;
+	}
+
+	mv_pp3_hmac_txq_queue_show(frame, queue);
+	pr_info("\n");
+}
+
+/* queue dump functions */
+void mv_pp3_hmac_rx_queue_dump(int frame, int queue, bool mode)
+{
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	if (!mv_hmac_rxq_handle[frame][queue])
+		return;
+
+	pr_info("\n-------------- HMAC RX frame: #%d, queue: #%d -----------", frame, queue);
+	mv_pp3_hmac_queue_dump(mv_hmac_rxq_handle[frame][queue], mode);
+}
+
+void mv_pp3_hmac_tx_queue_dump(int frame, int queue, bool mode)
+{
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return;
+
+	if (!mv_hmac_txq_handle[frame][queue])
+		return;
+
+	pr_info("\n-------------- HMAC TX frame: #%d, queue: #%d -----------", frame, queue);
+	mv_pp3_hmac_queue_dump(mv_hmac_txq_handle[frame][queue], mode);
+}
+
+/* debug functions */
+void mv_pp3_hmac_debug_cfg(int flags)
+{
+	mv_pp3_hmac_debug_flags = flags;
+}
+
+void mv_pp3_hmac_txq_delete(int frame, int queue)
+{
+	if (!mv_hmac_txq_handle[frame][queue])
+		return;
+
+	kfree(mv_hmac_txq_handle[frame][queue]->first);
+	kfree(mv_hmac_txq_handle[frame][queue]);
+
+	mv_hmac_txq_handle[frame][queue] = NULL;
+}
+
+void mv_pp3_hmac_rxq_delete(int frame, int queue)
+{
+	if (!mv_hmac_rxq_handle[frame][queue])
+		return;
+
+	kfree(mv_hmac_rxq_handle[frame][queue]->first);
+	kfree(mv_hmac_rxq_handle[frame][queue]);
+
+	mv_hmac_rxq_handle[frame][queue] = NULL;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
new file mode 100644
index 0000000..ba0b935
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
@@ -0,0 +1,529 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_hmac_h__
+#define __mv_hmac_h__
+
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_cfh.h"
+#include "platform/a390_gic_odmi_if.h"
+#include "qm/mv_qm.h"
+#include "hmac/mv_hmac_regs.h"
+
+#define MV_PP3_HMAC_Q_ALIGN			(256)
+#define MV_PP3_HMAC_CFH_DUMMY			(0x8000)
+#define MV_PP3_HMAC_PHYS_SWQ_NUM(queue, frame)	((queue) + MV_PP3_HFRM_Q_NUM * (frame))
+#define MV_PP3_HFRM_TIME_COAL			(64) /* Default time coalescing */
+
+extern struct mv_unit_info pp3_hmac_gl;
+extern struct mv_unit_info pp3_hmac_fr;
+extern struct mv_pp3_hmac_queue_ctrl *mv_hmac_rxq_handle[MV_PP3_HFRM_NUM][MV_PP3_HFRM_Q_NUM];
+extern struct mv_pp3_hmac_queue_ctrl *mv_hmac_txq_handle[MV_PP3_HFRM_NUM][MV_PP3_HFRM_Q_NUM];
+
+struct mv_pp3_hmac_queue_ctrl {
+	u8 *first;	/* pointer to first (virtual) byte in queue */
+	u8 *next_proc;	/* pointer to next CFH to procces in queue */
+	u8 *end;	/* pointer to first byte not belong to queue */
+	int occ_dg;	/* number of occupated datagrams in queue */
+	int dummy_dg;	/* number of dummy datagrams added by last wraparound */
+	int size;	/* number of 16 bytes units (datagram) in queue */
+	int cfh_size;	/* for queue with constant CFH size is number of datargarms in CFH, (or 0) */
+	int capacity;	/* max number of occupated datagrams allowed for queue */
+};
+
+/* CFH structure */
+struct cfh_common_format {
+
+	unsigned short pkt_length;
+	unsigned short seq_id_qe_cntrl;
+	unsigned short qm_cntrl;
+	unsigned char  cfh_length;	/* bytes */
+	unsigned char  cfh_format;
+	unsigned int   tag1;
+	unsigned int   tag2;
+	unsigned int   addr_low;
+	unsigned short addr_high;
+	unsigned char  vm_id;
+	unsigned char  bp_id;
+	unsigned int   marker_low;
+	unsigned char  marker_high;
+	unsigned char  reserved0;
+	unsigned short qc_cntrl;
+};
+
+/* debug print flags definition */
+#define MV_PP3_HMAC_READ_DEBUG_BIT	0
+#define MV_PP3_HMAC_WRITE_DEBUG_BIT	1
+#define MV_PP3_HMAC_TX_WA_DEBUG_BIT	2
+
+#define MV_PP3_HMAC_READ_DEBUG		(1 << MV_PP3_HMAC_READ_DEBUG_BIT)
+#define MV_PP3_HMAC_WRITE_DEBUG		(1 << MV_PP3_HMAC_WRITE_DEBUG_BIT)
+#define MV_PP3_HMAC_TX_WA_DEBUG		(1 << MV_PP3_HMAC_TX_WA_DEBUG_BIT)
+
+extern int mv_pp3_hmac_debug_flags;
+
+/*****************************************
+ *     Reigister acccess functions       *
+ *****************************************/
+static inline u32 mv_pp3_hmac_gl_reg_read(u32 reg)
+{
+	u32 reg_data;
+
+	mv_pp3_hw_read(reg + pp3_hmac_gl.base_addr, 1, &reg_data);
+
+	/* debug print */
+	if (mv_pp3_hmac_debug_flags & MV_PP3_HMAC_READ_DEBUG)
+		pr_info("read     : %8p = 0x%08x\n", reg + pp3_hmac_gl.base_addr, reg_data);
+
+	return reg_data;
+}
+
+static inline u32 mv_pp3_hmac_frame_reg_read(int frame_id, u32 reg)
+{
+	void __iomem *reg_addr;
+	u32 reg_data;
+
+	if (mv_pp3_max_check(frame_id, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return 0;
+
+	reg_addr = pp3_hmac_fr.base_addr + pp3_hmac_fr.ins_offs * frame_id + reg;
+	reg_data = mv_pp3_hw_reg_read(reg_addr);
+
+	/* debug print */
+	if (mv_pp3_hmac_debug_flags & MV_PP3_HMAC_READ_DEBUG)
+		pr_info("read     : %8p = 0x%08x\n", reg_addr, reg_data);
+
+	return reg_data;
+}
+
+static inline void mv_pp3_hmac_gl_reg_write(u32 reg, u32 data)
+{
+	mv_pp3_hw_reg_write(reg + pp3_hmac_gl.base_addr, data);
+	/* debug print */
+	if (mv_pp3_hmac_debug_flags & MV_PP3_HMAC_WRITE_DEBUG)
+		pr_info("write    : %8p = 0x%08x\n", reg + pp3_hmac_gl.base_addr, data);
+}
+
+static inline void mv_pp3_hmac_frame_reg_write(int frame_id, u32 reg, u32 data)
+{
+	void __iomem *reg_addr;
+
+	if (mv_pp3_max_check(frame_id, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return;
+
+	reg_addr = pp3_hmac_fr.base_addr + pp3_hmac_fr.ins_offs * frame_id + reg;
+	mv_pp3_hw_reg_write(reg_addr, data);
+	/* debug print */
+	if (mv_pp3_hmac_debug_flags & MV_PP3_HMAC_WRITE_DEBUG)
+		pr_info("write    : %8p = 0x%08x\n", reg_addr, data);
+}
+
+/*****************************************
+ *        HMAC unit init functions       *
+ *****************************************/
+void mv_pp3_hmac_init(struct mv_pp3 *priv);
+/* Init HMAC global unit base address
+ * unit_offset = silicon base address + unit offset  */
+void mv_pp3_hmac_gl_unit_base(void __iomem *unit_base);
+/* Init HMAC Frame first unit base address
+ * unit_offset = silicon base address + unit offset
+ * frame_offset - is an next frame unit offset       */
+void mv_pp3_hmac_frame_unit_base(void __iomem *unit_base, u32 frame_offset);
+
+/*****************************************
+ *        Frame init functions           *
+ *****************************************/
+void mv_pp3_hmac_frame_cfg(u32 frame_id, u8 vm_id);
+
+/*****************************************
+ *           RX queue functions          *
+ *****************************************/
+/* Allocate memory and init RX queue HW facility
+ * size is a queue size in datagrams (16 bytes each) */
+void *mv_pp3_hmac_rxq_init(int frame, int queue, int size);
+void mv_pp3_hmac_rxq_delete(int frame, int queue);
+void mv_pp3_hmac_rxq_flush(int frame, int queue);
+void mv_pp3_hmac_rxq_enable(int frame, int queue);
+void mv_pp3_hmac_rxq_disable(int frame, int queue);
+void mv_pp3_hmac_rxq_event_cfg(int frame, int queue, int event, int group);
+void mv_pp3_hmac_rxq_event_disable(int frame, int queue);
+void mv_pp3_hmac_rxq_event_enable(int frame, int queue);
+void mv_pp3_hmac_rxq_bp_node_set(int frame, int queue, enum mv_qm_node_type node_type, int node_id);
+int mv_pp3_hmac_rxq_bp_thresh_set(int frame, int queue, int thresh_dg);
+void mv_pp3_hmac_rxq_time_coal_profile_set(int frame, int queue, int profile);
+void mv_pp3_hmac_frame_time_coal_set(int frame, int profile, int usec);
+void mv_pp3_hmac_rxq_coal_get(int frame, int queue, int *profile, int *dq_num);
+void mv_pp3_hmac_frame_time_coal_get(int frame, int profile, int *usec);
+
+void mv_pp3_hmac_rxq_pause(int frame, int queue);
+void mv_pp3_hmac_rxq_resume(int frame, int queue);
+
+/* Return number of received datagrams */
+static inline int mv_pp3_hmac_rxq_occ_get(int frame, int queue)
+{
+	return mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_OCC_STATUS(queue)) & MV_PP3_HMAC_OCC_COUNTER_MASK;
+}
+
+/* Write a number of processed datagram (16 bytes each) */
+static inline void mv_pp3_hmac_rxq_occ_set(int frame, int queue, int size)
+{
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_OCC_STATUS(queue), size);
+}
+
+/* Returns pointer to next recieved CFH buffer and it */
+/* size - number of datagram                          */
+static inline u8 *mv_pp3_hmac_rxq_next_cfh(int frame, int queue, int *size)
+{
+	struct cfh_common_format *cfh;
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_rxq_handle[frame][queue];
+	unsigned int cfh_size; /* real CFH size aligned to 16 bytes in bytes */
+
+	/* Read 16 bytes of CFH pointed by "next_proc" field and calculate size of CFH in bytes */
+	cfh = (struct cfh_common_format *)qctrl->next_proc;
+	cfh_size = MV_ALIGN_UP(cfh->cfh_length, MV_PP3_CFH_DG_SIZE);
+
+	if (cfh_size == 0) {
+		pr_err("%s: error CFH 0x%p with wrong size %d (%d) on frame %d, queue %d\n",
+			__func__, cfh, cfh_size, cfh->cfh_length, frame, queue);
+		*size = 0;
+		return NULL;
+	}
+
+	/* Move "next_proc" pointer to next CFH ("next_proc" + size) */
+	qctrl->next_proc += cfh_size;
+	*size = cfh_size / MV_PP3_CFH_DG_SIZE;
+	/* check if there is an end of queue */
+	if (qctrl->next_proc >= qctrl->end) {
+		if (qctrl->next_proc == qctrl->end)
+			qctrl->next_proc = qctrl->first;
+		else {
+			memcpy(qctrl->end, qctrl->first, qctrl->next_proc - qctrl->end);
+			qctrl->next_proc = qctrl->first + (qctrl->next_proc - qctrl->end);
+		}
+	}
+
+	/* if get empty CFH with "W" bit set, return NULL */
+	if (cfh->qm_cntrl & MV_PP3_HMAC_CFH_DUMMY) {
+		return NULL;
+	}
+
+	/* return real CFH pointer */
+	return (u8 *)cfh;
+}
+
+/* set next CFH pointer = current - size * 16 */
+static inline u8 *mv_pp3_hmac_rxq_cfh_free(int frame, int queue, int size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_rxq_handle[frame][queue];
+	int dg = (qctrl->next_proc - qctrl->first) / MV_PP3_CFH_DG_SIZE;
+
+	if (dg < size) {
+		size -= dg;
+		qctrl->next_proc = qctrl->end;
+	}
+
+	qctrl->next_proc -= (size * MV_PP3_CFH_DG_SIZE);
+
+	return qctrl->next_proc;
+}
+
+/* configure rxq packets coalesing profile */
+static inline void mv_pp3_hmac_rxq_pkt_coal_set(int frame, int queue, int dg_num)
+{
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_INT_THRESH(queue), dg_num);
+}
+
+/*****************************************
+ *           TX queue functions          *
+ *****************************************/
+/* Allocate memory and init TX queue HW facility:
+ * size is a queue size in datagrams (16 bytes each) */
+void *mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size);
+void mv_pp3_hmac_txq_delete(int frame, int queue);
+void mv_pp3_hmac_txq_flush(int frame, int queue);
+void mv_pp3_hmac_txq_enable(int frame, int queue);
+void mv_pp3_hmac_txq_disable(int frame, int queue);
+void mv_pp3_hmac_txq_event_cfg(int frame, int queue, int group);
+
+/* Check for space in the queue.
+ * Return 0 for positive answer, or 1 for negative.
+ * dg_num - number of datagrams we are looking for */
+static inline int mv_pp3_hmac_txq_check_for_space(int frame, int queue, int dg_num)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	if ((qctrl->capacity - qctrl->occ_dg) >= dg_num)
+		return 0;
+
+	qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
+					MV_PP3_HMAC_OCC_COUNTER_MASK;
+	return ((qctrl->capacity - qctrl->occ_dg) >= dg_num) ? 0 : 1;
+}
+
+/* Return number of free space in the end of queue (in datagrams) */
+static inline int mv_pp3_hmac_txq_free_room(struct mv_pp3_hmac_queue_ctrl *qctrl)
+{
+	return (qctrl->end - qctrl->next_proc) / MV_PP3_CFH_DG_SIZE;
+}
+
+/* Return number of currently occupated datagrams in queue */
+static inline int mv_pp3_hmac_txq_occ_get(int frame, int queue)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
+					MV_PP3_HMAC_OCC_COUNTER_MASK;
+	return qctrl->occ_dg;
+}
+
+/* Return pointer to first free one CFH from queue with constant CFH size
+ * (do queue wraparound, if needed) */
+static inline u8 *mv_pp3_hmac_const_txq_next_cfh(int frame, int queue)
+{
+	u8 *cfh_ptr;
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	/* check queue capacity */
+	if ((qctrl->occ_dg + qctrl->cfh_size) > qctrl->capacity) {
+		/* update from HW number of occupited DG */
+		qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
+						MV_PP3_HMAC_OCC_COUNTER_MASK;
+		if ((qctrl->occ_dg + qctrl->cfh_size) > qctrl->capacity)
+			return NULL;
+	}
+
+	cfh_ptr = qctrl->next_proc;
+	qctrl->next_proc += (qctrl->cfh_size * MV_PP3_CFH_DG_SIZE);
+	qctrl->occ_dg += qctrl->cfh_size;
+
+	if (qctrl->next_proc == qctrl->end)
+		qctrl->next_proc = qctrl->first;
+
+	return cfh_ptr;
+}
+
+static void mv_pp3_dummy_message_print(char *str, char *cfh_ptr, int size)
+{
+	u32  *tmp;
+	int i;
+
+	pr_info("\n%s on cpu %d with data length %d 0x%p:", str, smp_processor_id(), size, cfh_ptr);
+
+	tmp = (u32 *)cfh_ptr;
+	pr_info("Message header: ");
+	for (i = 0; i < 4; i++)
+		pr_cont("%08x ", tmp[i]);
+	pr_info("\n");
+}
+
+/* Return last allocated unused CFHs.
+ * size is CFH size in datagrams (16 bytes each)     */
+static inline u8 *mv_pp3_hmac_txq_cfh_free(int frame, int queue, int size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	/* check queue occupation */
+	if (qctrl->occ_dg < size)
+		return NULL;
+
+	qctrl->occ_dg -= size;
+
+	if (qctrl->next_proc == qctrl->first) {
+		qctrl->next_proc = qctrl->end;
+		if (qctrl->dummy_dg) {
+			qctrl->next_proc -= (qctrl->dummy_dg * MV_PP3_CFH_DG_SIZE);
+			qctrl->occ_dg -= qctrl->dummy_dg;
+			qctrl->dummy_dg = 0;
+		}
+	}
+
+	qctrl->next_proc -= (size * MV_PP3_CFH_DG_SIZE);
+
+	return qctrl->next_proc;
+}
+
+/* Return pointer to first free one CFH (run queue wraparound, if needed) :
+ * size is CFH size in datagrams (16 bytes each)     */
+static inline u8 *mv_pp3_hmac_txq_next_cfh(int frame, int queue, int size)
+{
+	u8 *cfh_ptr;
+	int end_free_dg;	/* number of free datagram in the queue end */
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	/* check queue capacity */
+	if ((qctrl->occ_dg + size) > qctrl->capacity) {
+		/* update from HW number of occupited DG */
+		qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
+						MV_PP3_HMAC_OCC_COUNTER_MASK;
+
+		if ((qctrl->occ_dg + size) > qctrl->capacity)
+			return NULL;
+	}
+
+	/* calculate number of unused datagram in the queue end */
+	end_free_dg = (qctrl->end - qctrl->next_proc) / MV_PP3_CFH_DG_SIZE;
+	if (end_free_dg >= size) {
+		cfh_ptr = qctrl->next_proc;
+		qctrl->next_proc += (size * MV_PP3_CFH_DG_SIZE);
+		qctrl->occ_dg += size;
+		return cfh_ptr;
+	}
+
+	/* There is not enough space in the queue end. */
+	/* return pointer to fisrt CFH and move next pointer to second CFH in queue */
+	if (end_free_dg > 0) {
+		/* do wraparound with dummy CFH sent */
+		struct cfh_common_format *cfh = (struct cfh_common_format *)qctrl->next_proc;
+		u32 dummy_dg;
+
+		/* check queue capacity include dummy WA CFH */
+		if ((qctrl->occ_dg + size + end_free_dg) > qctrl->capacity) {
+			/* update from HW number of occupited DG */
+			qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
+						MV_PP3_HMAC_OCC_COUNTER_MASK;
+
+			if ((qctrl->occ_dg + size + end_free_dg) > qctrl->capacity)
+				return NULL;
+		}
+
+		memset(cfh, 0, (end_free_dg * MV_PP3_CFH_DG_SIZE));
+
+		qctrl->dummy_dg = end_free_dg;
+		qctrl->occ_dg += end_free_dg;
+		do {
+			dummy_dg = MV_MIN(end_free_dg, MV_PP3_CFH_DG_MAX_NUM);
+
+			cfh->cfh_length = dummy_dg * MV_PP3_CFH_DG_SIZE;
+			cfh->qm_cntrl = MV_PP3_HMAC_CFH_DUMMY; /* set bit 'W' */
+
+			if (mv_pp3_hmac_debug_flags & MV_PP3_HMAC_TX_WA_DEBUG)
+				mv_pp3_dummy_message_print("Sent Dummy", qctrl->next_proc, cfh->cfh_length);
+
+			qctrl->next_proc += cfh->cfh_length;
+			cfh = (struct cfh_common_format *)qctrl->next_proc;
+			end_free_dg -= dummy_dg;
+
+		} while (end_free_dg);
+	}
+	qctrl->next_proc = qctrl->first + (size * MV_PP3_CFH_DG_SIZE);
+	qctrl->occ_dg += size;
+
+	return qctrl->first;
+}
+static inline u32 mv_pp3_hmac_txq_dummy_dg_get(int frame, int queue)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+	u32 size = qctrl->dummy_dg;
+
+	qctrl->dummy_dg = 0;
+	return size;
+}
+/* size - is number of datagrams to transmit         */
+static inline void mv_pp3_hmac_txq_send(int frame, int queue, int size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	size += qctrl->dummy_dg;
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue), size);
+
+	qctrl->dummy_dg = 0;
+}
+
+/* Update sw counter of TX queue occupited datagrams */
+/* Must be called through TX Done processing */
+static inline void mv_pp3_hmac_txq_occ_upd(int frame, int queue, int dg_num)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
+	(dg_num < qctrl->occ_dg) ? qctrl->occ_dg -= dg_num : 0;
+}
+
+/* Configure queue capacity */
+static inline int mv_pp3_hmac_txq_capacity_cfg(int frame, int queue, int cap)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
+
+	if (mv_pp3_max_check(frame, MV_PP3_HFRM_NUM, "HMAC frame"))
+		return -1;
+	if (mv_pp3_max_check(queue, MV_PP3_HFRM_Q_NUM, "HMAC queue"))
+		return -1;
+
+	qctrl = mv_hmac_txq_handle[frame][queue];
+
+	if ((cap > qctrl->size) || (cap < MV_PP3_CFH_DG_MAX_NUM)) {
+		pr_err("%s: HMAC TXQ size #%d [dg] is out of range: [%d..%d]\n", __func__,
+			cap, MV_PP3_CFH_DG_MAX_NUM, qctrl->size);
+		return -1;
+	}
+
+	qctrl->capacity = cap;
+	return 0;
+}
+
+/* Unmask all events on group in frame */
+static inline void mv_pp3_hmac_group_event_unmask(int frame, int event_group)
+{
+	u32 reg_val;
+
+	reg_val = (1 << event_group);
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_MASK_REG(frame), reg_val);
+}
+
+/* Mask all events on group in frame */
+static inline void mv_pp3_hmac_group_event_mask(int frame, int event_group)
+{
+	u32 reg_val;
+
+	reg_val = (1 << (event_group + MV_HMAC_EVENT_MASK_GROUP_DIS_MASK_OFFS));
+	mv_pp3_hmac_gl_reg_write(MV_HMAC_EVENT_MASK_REG(frame), reg_val);
+}
+
+/* configure queue parameters used by BM queue       */
+void mv_pp3_hmac_queue_bm_mode_cfg(int frame, int queue);
+/* configure queue parameters used by QM queue
+ * q_num - is a number of QM queue                   */
+void mv_pp3_hmac_queue_qm_mode_cfg(int frame, int queue, int q_num);
+
+/* dump hmac queue registers */
+void mv_pp3_hmac_rxq_regs_dump(int frame, int queue);
+void mv_pp3_hmac_txq_regs_dump(int frame, int queue);
+void mv_pp3_hmac_frame_regs_dump(int frame);
+void mv_pp3_hmac_global_regs_dump(void);
+/* queue show functions */
+void mv_pp3_hmac_rx_queue_show(int frame, int queue);
+void mv_pp3_hmac_tx_queue_show(int frame, int queue);
+/* queue dump functions */
+void mv_pp3_hmac_rx_queue_dump(int frame, int queue, bool mode);
+void mv_pp3_hmac_tx_queue_dump(int frame, int queue, bool mode);
+/* debug functions */
+void mv_pp3_hmac_debug_cfg(int flags);
+/* sysfs functions */
+int mv_pp3_hmac_sysfs_init(struct kobject *kobj);
+int mv_pp3_hmac_sysfs_exit(struct kobject *kobj);
+
+#endif /* __mv_hmac_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
new file mode 100644
index 0000000..0f85d4b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
@@ -0,0 +1,151 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_hmac_bm_h__
+#define __mv_hmac_bm_h__
+
+#include "hmac/mv_hmac_regs.h"
+#include "hmac/mv_hmac.h"
+
+#define MV_PP3_BM_PE_SIZE  (16) /* bytes in 2-PE format */
+#define MV_PP3_BM_PE_DG    (1)  /* PE size = 1 datagram */
+
+#define MV_PP3_HMAC_BM_BUSY_TIMEOUT	(10000)
+
+/* max number of buffers that can be requested by one register access */
+#define MV_PP3_REQ_BUF_NUM_MAX		(8)
+
+struct mv_pp3_hmac_bm_cfh {
+	u32 buffer_addr_low;
+	u8  buffer_addr_high;
+	u8  reserved0;
+	u8  vm_id;
+	u8  bp_id;
+	u32 marker_low;
+	u8  marker_high;
+	u8  reserved1;
+	u16 reserved2;
+};
+
+/* configure queue parameters used by BM queue       */
+static inline int mv_pp3_hmac_bm_queue_init(int frame, int queue, int q_size)
+{
+	int size;
+	void *rxq_ctrl, *txq_ctrl;
+
+	size = MV_PP3_BM_PE_DG * q_size;
+	rxq_ctrl = mv_pp3_hmac_rxq_init(frame, queue, size);
+	txq_ctrl = mv_pp3_hmac_txq_init(frame, queue, size, MV_PP3_BM_PE_DG);
+	if ((rxq_ctrl == NULL) || (txq_ctrl == NULL))
+		return -1;
+
+	mv_pp3_hmac_queue_bm_mode_cfg(frame, queue);
+	mv_pp3_hmac_rxq_enable(frame, queue);
+	mv_pp3_hmac_txq_enable(frame, queue);
+
+	return 0;
+}
+
+static inline int mv_pp3_hmac_bm_busy(int frame, int queue)
+{
+	int iter = 0;
+	u32 reg_val = 0;
+
+	while (iter++ < MV_PP3_HMAC_BM_BUSY_TIMEOUT) {
+		reg_val = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_RX_Q_STATUS_REG(queue));
+		/* check BM Allocate Busy bit */
+		if (!(reg_val & MV_HMAC_RX_Q_STATUS_BM_ALLOCATE_BUSY_MASK))
+			return 0;
+	}
+	pr_info("%s: BM busy (%d:%d) for %d times, value is 0x%x", __func__, frame, queue, iter, reg_val);
+	return -1;
+}
+
+/* send to BM pool (bp_id) request for (buff_num) buffers */
+static inline int mv_pp3_hmac_bm_buff_request(int frame, int queue, int bp_id, int buff_num)
+{
+	u32 data;
+	int req_num;
+
+	/* on one register access 8 buffers can be requested (zero based counter) */
+	req_num = buff_num * MV_PP3_BM_PE_DG; /* number of buffer per datagram */
+	if (req_num) {
+		data = ((req_num - 1) << MV_HMAC_SEND_Q_NUM_BPID_BM_ALLOC_COUNT_OFFS) + bp_id;
+		mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_NUM_BPID_REG(queue), data);
+	}
+	return 0;
+}
+
+/* process BM pool (bp_id) responce for (buff_num) buffers
+ * return pool ID, physical and virtual address of buffer  */
+static inline int mv_pp3_hmac_bm_buff_get(int frame, int queue, int *bp_id, u32 *ph_addr, u32 *vr_addr)
+{
+	struct mv_pp3_hmac_bm_cfh *bm_cfh;
+	struct mv_pp3_hmac_queue_ctrl *rxq_ctrl = mv_hmac_rxq_handle[frame][queue];
+
+	bm_cfh = (struct mv_pp3_hmac_bm_cfh *)(rxq_ctrl->next_proc);
+	/* move queue current pointer to next CFH (each CFH 32 bytes) */
+	if ((rxq_ctrl->next_proc + MV_PP3_BM_PE_SIZE) >= rxq_ctrl->end)
+		rxq_ctrl->next_proc = rxq_ctrl->first;
+	else
+		rxq_ctrl->next_proc += MV_PP3_BM_PE_SIZE;
+
+	*bp_id = bm_cfh->bp_id;
+	*ph_addr = bm_cfh->buffer_addr_low;
+	*vr_addr = bm_cfh->marker_low;
+
+	return 0;
+}
+
+/* fill request for BM buffer release.
+ * return ERROR, if no space for message */
+static inline int mv_pp3_hmac_bm_buff_put(int frame, int queue, int bp_id, u32 ph_addr, u32 vr_addr)
+{
+	struct mv_pp3_hmac_bm_cfh *bm_cfh;
+	struct mv_pp3_hmac_queue_ctrl *txq_ctrl = mv_hmac_txq_handle[frame][queue];
+
+	if ((txq_ctrl->cfh_size + txq_ctrl->occ_dg) > txq_ctrl->size)
+		return -1;
+
+	/* get pointer to PE and write parameters */
+	bm_cfh = (struct mv_pp3_hmac_bm_cfh *)(txq_ctrl->next_proc);
+	txq_ctrl->next_proc += MV_PP3_BM_PE_SIZE;
+	txq_ctrl->occ_dg += MV_PP3_BM_PE_DG;
+
+	/* do WA, if needed */
+	if (txq_ctrl->next_proc == txq_ctrl->end)
+		txq_ctrl->next_proc = txq_ctrl->first;
+
+	bm_cfh->buffer_addr_low = ph_addr;
+	bm_cfh->marker_low = vr_addr;
+	bm_cfh->bp_id = bp_id;
+
+	return 0;
+}
+
+#endif /* __mv_hmac_bm_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
new file mode 100644
index 0000000..3d3e983
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
@@ -0,0 +1,313 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_hmac_regs_h__
+#define __mv_hmac_regs_h__
+
+/* includes */
+
+/* unit offset */
+#define MV_PP3_HMAC_FR_INST_OFFSET	0x010000
+
+/************************** HMAC GLOBAL regs *********************************************************/
+
+/* Hmac_eco */
+#define MV_HMAC_ECO_REG								0xF0000
+#define MV_HMAC_ECO_GENERAL_PURPOSE_ECO_OFFS		0
+
+/* Hmac_rec_qm_port_number */
+#define MV_HMAC_RX_QM_PORT_NUMBER_REG								0xF0008
+#define MV_HMAC_RX_QM_PORT_NUMBER_RQ_QM_HMAC_PORT_NUM_OFFS		0
+#define MV_HMAC_RX_QM_PORT_NUMBER_RQ_QM_HMAC_PORT_NUM_MASK    \
+		(0x00000fff << MV_HMAC_RX_QM_PORT_NUMBER_RQ_QM_HMAC_PORT_NUM_OFFS)
+
+
+/* Hmac_vmid_frame_%m */
+#define MV_HMAC_VMID_FRAME_REG(m)							(0xF0010 + 4*m)
+#define MV_HMAC_VMID_FRAME_CONTEXT_ID_OFFS		0
+#define MV_HMAC_VMID_FRAME_CONTEXT_ID_MASK    \
+		(0x0000003f << MV_HMAC_VMID_FRAME_CONTEXT_ID_OFFS)
+
+#define MV_HMAC_VMID_FRAME_AXI_PROT_PRIVILEGE_OFFS		16
+#define MV_HMAC_VMID_FRAME_AXI_PROT_PRIVILEGE_MASK    \
+		(0x00000001 << MV_HMAC_VMID_FRAME_AXI_PROT_PRIVILEGE_OFFS)
+
+#define MV_HMAC_VMID_FRAME_AW_QOS_OFFS		20
+#define MV_HMAC_VMID_FRAME_AW_QOS_MASK    \
+		(0x00000003 << MV_HMAC_VMID_FRAME_AW_QOS_OFFS)
+
+#define MV_HMAC_VMID_FRAME_AR_QOS_OFFS		24
+#define MV_HMAC_VMID_FRAME_AR_QOS_MASK    \
+		(0x00000003 << MV_HMAC_VMID_FRAME_AR_QOS_OFFS)
+
+
+/* Hmac_event_addr_low_%m */
+#define MV_HMAC_EVENT_ADDR_LOW_REG(m)							(0xF0050 + 8*m)
+#define MV_HMAC_EVENT_ADDR_LOW_EVENT_ADDRESS_LOW_OFFS		0
+#define MV_HMAC_EVENT_ADDR_LOW_EVENT_ADDRESS_LOW_MASK    \
+		(0x00ffffff << MV_HMAC_EVENT_ADDR_LOW_EVENT_ADDRESS_LOW_OFFS)
+
+
+/* Hmac_event_addr_high_%m */
+#define MV_HMAC_EVENT_ADDR_HIGH_REG(m)							(0xF0054 + 8*m)
+#define MV_HMAC_EVENT_ADDR_HIGH_EVENT_ADDRESS_HIGH_OFFS		0
+#define MV_HMAC_EVENT_ADDR_HIGH_EVENT_ADDRESS_HIGH_MASK    \
+		(0x000000ff << MV_HMAC_EVENT_ADDR_HIGH_EVENT_ADDRESS_HIGH_OFFS)
+
+
+/* HMAC AXI Interrupt Cause */
+#define MV_HMAC_AXI_INT_CAUSE								(0xF0200)
+#define MV_HMAC_AXI_INT_MASK								(0xF0204)
+#define MV_HMAC_AXI_INT_SYNDROME							(0xF0208)
+#define MV_HMAC_MISC_INT_CAUSE								(0xF0210)
+#define MV_HMAC_MISC_INT_MASK								(0xF0214)
+#define MV_HMAC_MISC_INT_SYNDROME							(0xF0218)
+
+#define MV_HMAC_EVENT_AXI_ATTRIBUTES_REG						(0xF0150)
+#define MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_DOMAIN_OFFS		0
+#define MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_DOMAIN_MASK    \
+		(0x00000003 << MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_DOMAIN_OFFS)
+
+#define MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_CACHE_OFFS		2
+#define MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_CACHE_MASK    \
+		(0x0000000f << MV_HMAC_EVENT_AXI_ATTRIBUTES_EVENT_AW_CACHE_OFFS)
+
+/* HMAC Event Mask %m */
+#define MV_HMAC_EVENT_MASK_REG(m)							(0xF0160 + 4*m)
+#define MV_HMAC_EVENT_MASK_GROUP_DIS_MASK_OFFS					16
+#define MV_HMAC_EVENT_MASK_GROUP_DIS_MASK					\
+	(0xFF << MV_HMAC_EVENT_MASK_GROUP_DIS_MASK_OFFS)
+#define MV_HMAC_EVENT_MASK_GROUP_EN_MASK_OFFS					0
+#define MV_HMAC_EVENT_MASK_GROUP_EN_MASK					\
+	(0xFF << MV_HMAC_EVENT_MASK_GROUP_EN_MASK_OFFS)
+
+/* Hmac Axi Read Port Fifo Fill Debug */
+#define MV_HMAC_AXI_READ_PORT_FIFO_FILL_DEBUG_REG					(0xF0228)
+
+/* Hmac Axi Write Port Fifo Fill Debug */
+#define MV_HMAC_AXI_WRITE_PORT_FIFO_FILL_DEBUG_REG					(0xF022c)
+
+/* Hmac Ppc Debug Mode */
+#define MV_HMAC_PPC_DEBUG_MODE_REG							(0xF0230)
+#define MV_HMAC_PPC_DEBUG_MODE_HMAC_PPC_DBG_MODE_OFFS		0
+#define MV_HMAC_PPC_DEBUG_MODE_HMAC_PPC_DBG_MODE_MASK    \
+		(0x00000001 << MV_HMAC_PPC_DEBUG_MODE_HMAC_PPC_DBG_MODE_OFFS)
+
+/* HMAC Busy */
+#define MV_HMAC_BUSY_REG								(0xF0234)
+#define MV_HMAC_BUSY_HMAC_BUSY_OFFS				0
+#define MV_HMAC_BUSY_HMAC_BUSY_MASK				\
+		(0x00000001 << MV_HMAC_BUSY_HMAC_BUSY_OFFS)
+#define MV_HMAC_BUSY_HMAC_PENDING_DATA_IN_QM_OFFS		1
+#define MV_HMAC_BUSY_HMAC_PENDING_DATA_IN_QM_MASK		\
+	(0x1 << MV_HMAC_BUSY_HMAC_PENDING_DATA_IN_QM_OFFS)
+#define MV_HMAC_BUSY_HMAC_DEBUG_BUSY_OFFS			2
+#define MV_HMAC_BUSY_HMAC_DEBUG_BUSY_MASK			\
+	(0xF << MV_HMAC_BUSY_HMAC_DEBUG_BUSY_OFFS)
+
+/* HMAC_OUTSTANDING_LIMIT Register */
+#define MV_HMAC_OUTSTANDING_LIMIT_REG							(0xF0238)
+#define MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_1_OFFS		10
+#define MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_1_MASK		\
+	(0xF << MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_1_OFFS)
+#define MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_0_OFFS		2
+#define MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_0_MASK		\
+	(0xF << MV_HMAC_OUTSTANDING_LIMIT_OUTSTANDING_LIMIT_0_OFFS)
+
+
+/* HMAC_REC_Q_TIMEOUT_0 Register */
+#define MV_HMAC_RX_Q_TIMEOUT_REG(m)							(0xF0240 + 4*m)
+#define MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_OFFS					5
+#define MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_MASK					\
+	(0x7FF << MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_0_OFFS)
+#define MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_OFFS					21
+#define MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_MASK					\
+	(0x7FF << MV_HMAC_RX_Q_TIMEOUT_RQ_TIMEOUT_1_OFFS)
+
+/* HMAC_SEND_Q_TIMEOUT_0 Register */
+#define MV_HMAC_SEND_Q_TIMEOUT_REG(m)							(0xF0280 + 4*m)
+#define MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_1_OFFS					21
+#define MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_1_MASK					\
+	(0x7FF << MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_1_OFFS)
+#define MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_0_OFFS					5
+#define MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_0_MASK					\
+	(0x7FF << MV_HMAC_SEND_Q_TIMEOUT_SQ_TIMEOUT_0_OFFS)
+
+/* Hmac_axi_prot_secure_%m */
+#define MV_HMAC_AXI_PROT_SECURE_REG(m)							(0xF0300 + 4*m)
+#define MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_OFFS		0
+#define MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_MASK    \
+		(0x00000001 << MV_HMAC_AXI_PROT_SECURE_AXI_PROT_SECURE_OFFS)
+
+/* HMAC_RECEIVE_QUEUES_BUSY_0 Register */
+#define MV_HMAC_RECEIVE_QUEUES_BUSY_REG(m)						(0xF0340 + 4*m)
+#define MV_HMAC_RECEIVE_QUEUES_BUSY_RQS_BUSY_OFFS			0
+#define MV_HMAC_RECEIVE_QUEUES_BUSY_RQS_BUSY_MASK			\
+	(0xFFFF << MV_HMAC_RECEIVE_QUEUES_BUSY_RQS_BUSY_OFFS)
+
+/************************** HMAC FRAME regs *********************************************************/
+
+/* Hmac_%m_rec_q_%n_control */
+#define MV_HMAC_RX_Q_CTRL_REG(n)							(0x108000 + 0x100*n)
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_EN_OFFS		0
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_EN_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_CTRL_RCV_Q_EN_OFFS)
+
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_FLUSH_OFFS		1
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_FLUSH_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_CTRL_RCV_Q_FLUSH_OFFS)
+
+#define MV_HMAC_RX_Q_CTRL_Q_DLB_EN_OFFS		8
+#define MV_HMAC_RX_Q_CTRL_Q_DLB_EN_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_CTRL_Q_DLB_EN_OFFS)
+
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_OFFS		12
+#define MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_CTRL_RCV_Q_TIMER_SEL_OFFS)
+
+/* Hmac_%m_rec_q_%n_status */
+#define MV_HMAC_RX_Q_STATUS_REG(n)							(0x10800c + 0x100*n)
+#define MV_HMAC_RX_Q_STATUS_RQ_BUSY_OFFS		0
+#define MV_HMAC_RX_Q_STATUS_RQ_BUSY_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_STATUS_RQ_BUSY_OFFS)
+
+#define MV_HMAC_RX_Q_STATUS_RQ_REMAINDER_NEMPTY_OFFS		1
+#define MV_HMAC_RX_Q_STATUS_RQ_REMAINDER_NEMPTY_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_STATUS_RQ_REMAINDER_NEMPTY_OFFS)
+
+#define MV_HMAC_RX_Q_STATUS_BM_ALLOCATE_BUSY_OFFS		2
+#define MV_HMAC_RX_Q_STATUS_BM_ALLOCATE_BUSY_MASK    \
+		(0x00000001 << MV_HMAC_RX_Q_STATUS_BM_ALLOCATE_BUSY_OFFS)
+
+/* Hmac_%m_send_q_%n_control */
+#define MV_HMAC_SEND_Q_CTRL_REG(n)							(0x108040 + 0x100*n)
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_OFFS						0
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_OFFS)
+
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_FLUSH_OFFS						1
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_FLUSH_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_CTRL_SEND_Q_FLUSH_OFFS)
+
+#define MV_HMAC_SEND_Q_CTRL_Q_MODE_OFFS							4
+#define MV_HMAC_SEND_Q_CTRL_Q_MODE_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_CTRL_Q_MODE_OFFS)
+
+#define MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_OFFS						8
+#define MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_CTRL_BM_PE_FORMAT_OFFS)
+
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_TIMER_SEL_OFFS					12
+#define MV_HMAC_SEND_Q_CTRL_SEND_Q_TIMER_SEL_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_CTRL_SEND_Q_TIMER_SEL_OFFS)
+
+#define MV_HMAC_SEND_Q_CTRL_SQ_LIMIT_SELECTION_OFFS					13
+#define MV_HMAC_SEND_Q_CTRL_SQ_LIMIT_SELECTION_MASK					\
+	(0x1 << MV_HMAC_SEND_Q_CONTROL_SQ_LIMIT_SELECTION_OFFS)
+
+/* Hmac_%m_send_q_%n_q_num_bpid */
+#define MV_HMAC_SEND_Q_NUM_BPID_REG(n)							(0x108048 + 0x100*n)
+#define MV_HMAC_SEND_Q_NUM_BPID_QNUM_OFFS		0
+#define MV_HMAC_SEND_Q_NUM_BPID_QNUM_MASK    \
+		(0x00000fff << MV_HMAC_SEND_Q_NUM_BPID_QNUM_OFFS)
+
+#define MV_HMAC_SEND_Q_NUM_BPID_BPID_OFFS		0
+#define MV_HMAC_SEND_Q_NUM_BPID_BPID_MASK    \
+		(0x000000ff << MV_HMAC_SEND_Q_NUM_BPID_BPID_OFFS)
+
+#define MV_HMAC_SEND_Q_NUM_BPID_BM_ALLOC_COUNT_OFFS		8
+#define MV_HMAC_SEND_Q_NUM_BPID_BM_ALLOC_COUNT_MASK    \
+		(0x00000007 << MV_HMAC_SEND_Q_NUM_BPID_BM_ALLOC_COUNT_OFFS)
+
+
+/* Hmac_%m_send_q_%n_status */
+#define MV_HMAC_SEND_Q_STATUS_REG(n)							(0x10804c + 0x100*n)
+#define MV_HMAC_SEND_Q_STATUS_SQ_BUSY_OFFS		0
+#define MV_HMAC_SEND_Q_STATUS_SQ_BUSY_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_STATUS_SQ_BUSY_OFFS)
+
+#define MV_HMAC_SEND_Q_STATUS_SQ_PENDING_AXI_READ_OFFS		1
+#define MV_HMAC_SEND_Q_STATUS_SQ_PENDING_AXI_READ_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_STATUS_SQ_PENDING_AXI_READ_OFFS)
+
+#define MV_HMAC_SEND_Q_STATUS_SQ_REMAINDER_NEMPTY_OFFS		2
+#define MV_HMAC_SEND_Q_STATUS_SQ_REMAINDER_NEMPTY_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_STATUS_SQ_REMAINDER_NEMPTY_OFFS)
+
+#define MV_HMAC_SEND_Q_STATUS_SQ_QM_BP_OFF_OFFS		3
+#define MV_HMAC_SEND_Q_STATUS_SQ_QM_BP_OFF_MASK    \
+		(0x00000001 << MV_HMAC_SEND_Q_STATUS_SQ_QM_BP_OFF_OFFS)
+
+/* HMAC Frame unit tables offsets */
+#define MV_PP3_HMAC_RQ_ADDR_LOW(n)		(0x100000 + 0x100*n)
+#define MV_PP3_HMAC_RQ_ADDR_HIGH(n)		(0x100004 + 0x100*n)
+#define MV_PP3_HMAC_RQ_SIZE(n)			(0x100008 + 0x100*n)
+#define MV_PP3_HMAC_RQ_OCC_STATUS(n)		(0x10000C + 0x100*n)
+#define MV_PP3_HMAC_RQ_AXI_ATTR(n)		(0x100010 + 0x100*n)
+#define MV_PP3_HMAC_RQ_EVENT_GROUP(n)		(0x100014 + 0x100*n)
+#define MV_PP3_HMAC_RQ_INT_THRESH(n)		(0x100018 + 0x100*n)
+
+#define MV_PP3_HMAC_RQ_INT_THRESH_OFFS		0
+#define MV_PP3_HMAC_RQ_INT_THRESH_MASK		(0xFFFF)
+
+#define MV_PP3_HMAC_RQ_BACK_PRES0(n)		(0x10001c + 0x100*n)
+#define MV_PP3_HMAC_RQ_BACK_PRES1(n)		(0x100020 + 0x100*n)
+
+#define MV_PP3_HMAC_RQ_BP_XOFF_THRESH_OFFS	0
+#define MV_PP3_HMAC_RQ_BP_XON_THRESH_OFFS	16
+#define MV_PP3_HMAC_RQ_BP_THRESH_MASK		(0xFFFF)
+
+#define MV_PP3_HMAC_SQ_ADDR_LOW(n)		(0x100040 + 0x100*n)
+#define MV_PP3_HMAC_SQ_ADDR_HIGH(n)		(0x100044 + 0x100*n)
+#define MV_PP3_HMAC_SQ_SIZE(n)			(0x100048 + 0x100*n)
+#define MV_PP3_HMAC_SQ_OCC_STATUS(n)		(0x10004C + 0x100*n)
+#define MV_PP3_HMAC_SQ_AXI_ATTR(n)		(0x100050 + 0x100*n)
+#define MV_PP3_HMAC_SQ_EVENT_GROUP(n)		(0x100054 + 0x100*n)
+#define MV_PP3_HMAC_SQ_SW_QNUM_TDEST(n)		(0x100058 + 0x100*n)
+
+#define MV_PP3_HMAC_OCC_COUNTER_MASK		(0xFFFF)
+
+#define MV_PP3_HMAC_RQ_EVENT0_GROUP_OFFS	0
+#define MV_PP3_HMAC_RQ_EVENT0_GROUP_MASK	(0x7)
+#define MV_PP3_HMAC_RQ_EVENT0_DIS_OFFS		3
+#define MV_PP3_HMAC_RQ_EVENT0_DIS_MASK		(1 << MV_PP3_HMAC_RQ_EVENT0_DIS_OFFS)
+
+#define MV_PP3_HMAC_RQ_EVENT1_GROUP_OFFS	4
+#define MV_PP3_HMAC_RQ_EVENT1_GROUP_MASK	(0x7)
+#define MV_PP3_HMAC_RQ_EVENT1_DIS_OFFS		7
+#define MV_PP3_HMAC_RQ_EVENT1_DIS_MASK		(1 << MV_PP3_HMAC_RQ_EVENT1_DIS_OFFS)
+
+#define MV_PP3_HMAC_SQ_EVENT_GROUP_OFFS		0
+#define MV_PP3_HMAC_SQ_EVENT_GROUP_MASK		(0x7)
+#define MV_PP3_HMAC_SQ_EVENT_DIS_OFFS		3
+#define MV_PP3_HMAC_SQ_EVENT_DIS_MASK		(1 << MV_PP3_HMAC_SQ_EVENT_DIS_OFFS)
+
+#define MV_PP3_HMAC_Q_SIZE_MASK			(0xFFFF)
+/**/
+
+#endif /* __mv_hmac_regs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_sysfs.c b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_sysfs.c
new file mode 100644
index 0000000..932b968
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_sysfs.c
@@ -0,0 +1,219 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "hmac/mv_hmac.h"
+
+static ssize_t mv_hmac_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f]         > f_regs      - dump global unit frame registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [q]     > rxq_regs    - dump frame RX queue registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [q]     > txq_regs    - dump frame TX queue registers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [q] [m] > rxq_show    - show RX queue status\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [q] [m] > txq_show    - show TX queue status\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [q] [c] > txq_cap     - change TX queue capacity in datagrams\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [u]         > reg_read    - read global unit register\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [u] [v]     > reg_write   - write global unit register\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [u]     > f_reg_read  - read frame unit register\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [f] [u] [v] > f_reg_write - write frame unit register\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [v]         > debug       - 0 disable, bit0 enable read, bit1 enable write debug outputs\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [f] frame number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [q] queue number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [u] hex register address\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [v] hex value\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [c] max number of datagrams\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [m] mode: 0 - brief (status only) display, 1 - full (status + dump) display\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_hmac_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	/* const char      *name = attr->attr.name; */
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_hmac_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_hmac_3_hex_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, u, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read first 3 parameters */
+	err = p = u = v = 0;
+	sscanf(buf, "%x %x %x", &p, &u, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "reg_write"))
+		mv_pp3_hmac_gl_reg_write(p, u);
+	else if (!strcmp(name, "reg_read")) {
+		v = mv_pp3_hmac_gl_reg_read(p);
+		pr_info("0x%x = 0x%x\n", p, v);
+	} else if (!strcmp(name, "f_reg_write"))
+		mv_pp3_hmac_frame_reg_write(p, u, v);
+	else if (!strcmp(name, "f_reg_read")) {
+		v = mv_pp3_hmac_frame_reg_read(p, u);
+		pr_info("0x%x = 0x%x\n", u, v);
+	} else if (!strcmp(name, "debug"))
+		mv_pp3_hmac_debug_cfg(p);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_hmac_3_dec_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, u, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read first 3 parameters */
+	err = p = u = v = 0;
+	sscanf(buf, "%d %d %d", &p, &u, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "f_regs")) {
+		mv_pp3_hmac_global_regs_dump();
+		mv_pp3_hmac_frame_regs_dump(p);
+	} else if (!strcmp(name, "rxq_regs"))
+		mv_pp3_hmac_rxq_regs_dump(p, u);
+	else if (!strcmp(name, "txq_regs"))
+		mv_pp3_hmac_txq_regs_dump(p, u);
+	else if (!strcmp(name, "txq_cap")) {
+		if (mv_pp3_hmac_txq_capacity_cfg(p, u, v) != 0)
+			pr_err("Bad queue capacity value %d. Must be large than 8 and less than queue size\n", v);
+	} else if (!strcmp(name, "rxq_show")) {
+		mv_pp3_hmac_rx_queue_show(p, u);
+		if (v > 0) {
+			bool print_all;
+
+			print_all = (v == 2) ? true : false;
+			mv_pp3_hmac_rx_queue_dump(p, u, print_all);
+		}
+	} else if (!strcmp(name, "txq_show")) {
+		mv_pp3_hmac_tx_queue_show(p, u);
+		if (v > 0) {
+			bool print_all;
+
+			print_all = (v == 2) ? true : false;
+			mv_pp3_hmac_tx_queue_dump(p, u, print_all);
+		}
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help, S_IRUSR, mv_hmac_show, NULL);
+static DEVICE_ATTR(f_regs, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(rxq_regs, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(txq_regs, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(txq_cap, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(rxq_show, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(txq_show, S_IWUSR, NULL, mv_hmac_3_dec_store);
+static DEVICE_ATTR(reg_write, S_IWUSR, NULL, mv_hmac_3_hex_store);
+static DEVICE_ATTR(reg_read, S_IWUSR, NULL, mv_hmac_3_hex_store);
+static DEVICE_ATTR(f_reg_write, S_IWUSR, NULL, mv_hmac_3_hex_store);
+static DEVICE_ATTR(f_reg_read, S_IWUSR, NULL, mv_hmac_3_hex_store);
+static DEVICE_ATTR(debug, S_IWUSR, NULL, mv_hmac_3_hex_store);
+
+
+static struct attribute *mv_hmac_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_f_regs.attr,
+	&dev_attr_rxq_regs.attr,
+	&dev_attr_txq_regs.attr,
+	&dev_attr_txq_cap.attr,
+	&dev_attr_rxq_show.attr,
+	&dev_attr_txq_show.attr,
+	&dev_attr_reg_write.attr,
+	&dev_attr_reg_read.attr,
+	&dev_attr_f_reg_write.attr,
+	&dev_attr_f_reg_read.attr,
+	&dev_attr_debug.attr,
+	NULL
+};
+
+static struct attribute_group mv_hmac_group = {
+	.name = "hmac",
+	.attrs = mv_hmac_attrs,
+};
+
+int mv_pp3_hmac_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &mv_hmac_group);
+	if (err) {
+		pr_err("sysfs group failed %d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_hmac_sysfs_exit(struct kobject *hmac_kobj)
+{
+	sysfs_remove_group(hmac_kobj, &mv_hmac_group);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg.h b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg.h
new file mode 100644
index 0000000..e3d7f36
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg.h
@@ -0,0 +1,96 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_msg_h__
+#define __mv_pp3_msg_h__
+
+/* max channel number */
+#define MV_PP3_MAX_CHAN_NUM 16
+
+/* Message flags definition */
+#define MV_PP3_F_CFH_MSG_ACK		(0x1)
+#define MV_PP3_F_CFH_EXT_HDR		(0x2)
+
+/* Clients name */
+extern unsigned char *mv_pp3_sys_clients[];
+
+/* Receive message callback prototype
+Inputs:
+	chan - unique channel id as returned by mv_pp3_chan_add() function
+	msg  - pointer to received message
+	size - size of message
+	seq_num - message sequence number
+	flags - message flags:
+		Bit 0 - Acknowledge or Reply is received.
+		Bit 1 - Buffer extension header existence
+	msg_opcode - unique message type identifier.
+	ret_code - status returned by the Firmware for the whole request.
+	num_ok - number of messages successfully processed by FW.
+*/
+typedef void (*mv_pp3_chan_rcv_func)(int chan, void *msg, int size, int seq_num, int flags, u16 msg_opcode,
+		int ret_code, int num_ok);
+
+/* Create communication channel (bi-directional)
+Inputs:
+	client_id - channel client ID
+	size - number of CFHs with maximum CFH size (128 byte)
+	rcv_cb - callback function to be called when message from Firmware is received on this channel.
+Return:
+	 0 - success
+	-1 - fail
+*/
+int mv_pp3_chan_create(unsigned char client_id, int size, mv_pp3_chan_rcv_func rcv_cb);
+
+/* Prepare message CFH and trigger it sending to firmware.
+Inputs:
+	chan - unique channel id
+	msg  - pointer to message to send
+	size - size of message (in bytes)
+	flags - message flags
+	msg_opcode - one from known opcodes (see enum mv_pp3_fw_nic_msg_opcode)
+	msg_seq_num - message sequence number managed by sender
+	num  - number of instances for bulk requests support
+Return:
+	0  - Message accepted and/or sent to firmware.
+	-1 - Failure: Queue is full, etc
+*/
+int mv_pp3_msg_send(int chan, void *msg, int size, int flags, u16 msg_opcode, int msg_seq_num, int num);
+
+/* Registerate RX channel event to specified cpu
+Inputs:
+	chan - unique channel id
+	cpu - cpu number
+Return:
+	0  - success.
+	-1 - failure
+*/
+int mv_pp3_channel_reg(int chan, int cpu_num);
+
+/* Close communication channel
+Inputs:
+	chan - unique channel id
+eturn:
+	 0 - success
+	-1 - fail
+*/
+int mv_pp3_chan_delete(int chan);
+
+/* Enable / disable print out of sent / received messages */
+void mv_pp3_debug_message_print_en(bool rx_en, bool tx_en);
+
+#endif /* __mv_pp3_msg_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.c b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.c
new file mode 100644
index 0000000..afc3b78
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.c
@@ -0,0 +1,698 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/* includes */
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+#include "common/mv_sw_if.h"
+#include "common/mv_stack.h"
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "platform/mv_pp3_fw_opcodes.h"
+#include "hmac/mv_hmac.h"
+#include "hmac/mv_hmac_bm.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "mv_pp3_msg.h"
+#include "mv_pp3_msg_chan.h"
+
+/* platform pointer for dma operation */
+static struct mv_pp3 *pp3_priv;
+
+/* channel info */
+static struct mv_pp3_channel mv_pp3_chan_ctrl[MV_PP3_MAX_CHAN_NUM];
+/* number of active channels */
+static int mv_pp3_active_chan_num;
+
+/* global one lock for all channels */
+static spinlock_t msngr_channel_lock;
+static bool msngr_free;
+
+/* debug print configuration variables */
+static bool mv_pp3_rx_msg_print_en;
+static bool mv_pp3_tx_msg_print_en;
+
+static u32 __percpu *mv_pp3_ch_bmp;
+
+/* forward function declaration */
+static void mv_pp3_chan_rx_event(struct mv_pp3_channel *chan);
+static void mv_pp3_message_print(char *str, struct host_msg *cfh_ptr, int size, int num, int opcode, int chan);
+
+/* Return number of active channels */
+int mv_pp3_chan_num_get(void)
+{
+	return mv_pp3_active_chan_num;
+}
+
+/* Return pointer to channel sturcture or NULL if ch_num is invalid */
+struct mv_pp3_channel *mv_pp3_chan_get(int ch_num)
+{
+	if (ch_num >= mv_pp3_active_chan_num)
+		return NULL;
+
+	return &mv_pp3_chan_ctrl[ch_num];
+}
+
+
+/* Init messenger facility - call ones */
+int mv_pp3_messenger_init(struct mv_pp3 *priv)
+{
+	int id;
+
+	pp3_priv = priv;
+
+	mv_pp3_ch_bmp = alloc_percpu(sizeof(u32));
+
+	/* create lock mechanism */
+	spin_lock_init(&msngr_channel_lock);
+	msngr_free = true;
+
+	/* create default channel for messenger control nessages */
+	id = mv_pp3_chan_create(MV_DRIVER_CL_ID, 100, NULL);
+	if (id < 0) {
+		pr_err("%s: Failed to create default messenger channel\n", __func__);
+		return -1;
+	}
+	mv_pp3_channel_reg(id, 0);
+
+	return 0;
+}
+
+/* Interrupt handling */
+irqreturn_t mv_msg_isr(int irq, void *pchan)
+{
+	struct mv_pp3_channel *chan_ctrl = (struct mv_pp3_channel *)pchan;
+
+	chan_ctrl->ch_stat.events_cntr++;
+
+	/* Mask all RX events of relevant queue */
+	mv_pp3_hmac_rxq_event_disable(chan_ctrl->frame, chan_ctrl->hmac_sw_rxq);
+
+	tasklet_schedule(&chan_ctrl->channel_tasklet);
+
+	return IRQ_HANDLED;
+}
+
+void mv_pp3_msg_tasklet(unsigned long data)
+{
+	struct mv_pp3_channel *chan_ctrl = (struct mv_pp3_channel *)data;
+
+	/* TODO: verify that interrupt occured */
+
+	if (chan_ctrl->status & MV_PP3_F_CHANNEL_CREATED)
+		mv_pp3_chan_rx_event(chan_ctrl);
+
+	/* Unmask all RX events of relevant queue */
+	mv_pp3_hmac_rxq_event_enable(chan_ctrl->frame, chan_ctrl->hmac_sw_rxq);
+}
+
+
+/* Create communication channel (bi-directional)
+Inputs:
+	client_id - channel client ID
+	size - number of CFHs with maximum CFH size (128 byte)
+	rcv_cb - callback function to be called when message from Firmware is received on this channel.
+Return:
+	positive - unique channel ID,
+	negative - failure
+*/
+int mv_pp3_chan_create(unsigned char client_id, int size, mv_pp3_chan_rcv_func rcv_cb)
+{
+	struct mv_pp3_fw_msg_chan_cfg msg;
+	int chan_num;
+	int frame, queue;
+	int msg_flags;
+	int group, irq_num;
+	unsigned char txq;
+	unsigned long iflags = 0;
+
+	if (pp3_priv == NULL) {
+		pr_err("%s: system doesn't configure properly\n", __func__);
+		return -1;
+	}
+	if (mv_pp3_active_chan_num == MV_PP3_MAX_CHAN_NUM)
+		return -1;
+
+	MV_LOCK(&msngr_channel_lock, iflags);
+	/* get ID of current channnel */
+	chan_num = mv_pp3_active_chan_num++;
+	MV_UNLOCK(&msngr_channel_lock, iflags);
+
+	/* get free frame number and queue number to use by channel */
+	if (mv_pp3_cfg_chan_sw_params_get(chan_num, &frame, &queue, &group, &irq_num))
+		return -1;
+
+	/* create HMAC queue pair */
+	if (mv_pp3_hmac_rxq_init(frame, queue, size*MV_PP3_CFH_MAX_SIZE/MV_PP3_CFH_DG_SIZE) == NULL)
+		return -1;
+	if (mv_pp3_hmac_txq_init(frame, queue, size*MV_PP3_CFH_MAX_SIZE/MV_PP3_CFH_DG_SIZE, 0) == NULL)
+		return -1;
+
+	mv_pp3_chan_ctrl[chan_num].size = size;
+	/* create array to store size of "ready to send" CFHs */
+	mv_pp3_chan_ctrl[chan_num].ready_to_send = kzalloc(size*4, GFP_KERNEL);
+	if (mv_pp3_chan_ctrl[chan_num].ready_to_send == NULL) {
+		pr_err("%s: Failed to allocate %d bytes for channel %d\n", __func__, size*4, chan_num);
+		return -1;
+	}
+	mv_pp3_chan_ctrl[chan_num].ready_to_send_ind = 0;
+	mv_pp3_chan_ctrl[chan_num].free_ind = 0;
+
+	mv_pp3_chan_ctrl[chan_num].hmac_sw_rxq = queue;
+	mv_pp3_chan_ctrl[chan_num].hmac_sw_txq = queue;
+	mv_pp3_chan_ctrl[chan_num].event_group = group;
+	mv_pp3_chan_ctrl[chan_num].rcv_func = rcv_cb;
+	mv_pp3_chan_ctrl[chan_num].frame = frame;
+	mv_pp3_chan_ctrl[chan_num].id = chan_num;
+	mv_pp3_chan_ctrl[chan_num].status = 0;
+	memset(&mv_pp3_chan_ctrl[chan_num].ch_stat, 0, sizeof(struct mv_pp3_chan_cntrs));
+
+	/* connect HMAC queue to interrupt group */
+	mv_pp3_hmac_rxq_event_cfg(frame, queue, MV_PP3_RX_CFH, group);
+
+	/*  get HW q numbers and BM ID */
+	if (mv_pp3_cfg_chan_hw_params_get(chan_num, &msg.hmac_hw_rxq, &txq))
+		return -1;
+	/* configure back pressure on HW queue */
+	mv_pp3_hmac_rxq_bp_node_set(frame, queue, MV_QM_Q_NODE, msg.hmac_hw_rxq);
+
+	mv_pp3_chan_ctrl[chan_num].hmac_hw_rxq = msg.hmac_hw_rxq;
+	mv_pp3_chan_ctrl[chan_num].hmac_hw_txq = txq;
+
+	mv_pp3_hmac_queue_qm_mode_cfg(mv_pp3_chan_ctrl[chan_num].frame, mv_pp3_chan_ctrl[chan_num].hmac_sw_rxq, txq);
+
+	/* enable channel */
+	mv_pp3_hmac_rxq_enable(mv_pp3_chan_ctrl[chan_num].frame, mv_pp3_chan_ctrl[chan_num].hmac_sw_rxq);
+	mv_pp3_hmac_txq_enable(mv_pp3_chan_ctrl[chan_num].frame, mv_pp3_chan_ctrl[chan_num].hmac_sw_txq);
+
+	/* build channel create message with SW and HW queues numbers */
+	msg.chan_id = chan_num;
+	msg.hmac_sw_rxq = queue + MV_PP3_HFRM_Q_NUM * frame;
+	msg.hmac_hw_rxq = cpu_to_be16(msg.hmac_hw_rxq);
+
+	/* create tasklet for interrupt handling */
+	tasklet_init(&mv_pp3_chan_ctrl[chan_num].channel_tasklet, mv_pp3_msg_tasklet,
+		(unsigned long)&mv_pp3_chan_ctrl[chan_num]);
+
+	/* connect ISR to IRQ */
+	sprintf(mv_pp3_chan_ctrl[chan_num].mv_chan_isr, "pp3_channel_%d", chan_num);
+	if (request_irq(irq_num, mv_msg_isr, IRQF_SHARED | IRQF_TRIGGER_RISING,
+			mv_pp3_chan_ctrl[chan_num].mv_chan_isr, &mv_pp3_chan_ctrl[chan_num]))
+		pr_err("Failed to assign IRQ %d to channel %d\n", irq_num, chan_num);
+	else
+		pr_info("Assign IRQ %d to channel %d\n", irq_num, chan_num);
+	mv_pp3_chan_ctrl[chan_num].irq_num = irq_num;
+
+	/* send message with channel info on default channel used only for system control */
+	msg_flags = MV_PP3_F_CFH_MSG_ACK;
+	mv_pp3_msg_send(mv_pp3_chan_ctrl[0].id, &msg, sizeof(msg), msg_flags, MV_FW_MSG_CHAN_SET, 0, 1);
+	mv_pp3_chan_ctrl[chan_num].status |= MV_PP3_F_CHANNEL_CREATED;
+
+	/* Enable events on HMAC only */
+	mv_pp3_hmac_group_event_unmask(frame, group);
+
+	return chan_num;
+}
+EXPORT_SYMBOL(mv_pp3_chan_create);
+
+/* Registerate RX channel event to specified cpu
+Inputs:
+	chan - unique channel id
+	cpu - cpu number
+Return:
+	0  - success.
+	-1 - failure
+*/
+int mv_pp3_channel_reg(int chan, int cpu)
+{
+	if (!(mv_pp3_chan_ctrl[chan].status & MV_PP3_F_CHANNEL_CREATED))
+		/* channel not created */
+		return -1;
+
+	*(per_cpu_ptr(mv_pp3_ch_bmp, cpu)) |= (1 << chan);
+
+	if (irq_set_affinity(mv_pp3_chan_ctrl[chan].irq_num, cpumask_of(cpu)))
+		pr_err("Failed to set affinity IRQ %d to cpu %d device\n",
+			mv_pp3_chan_ctrl[chan].irq_num, cpu);
+
+	mv_pp3_chan_ctrl[chan].cpu_mask |= (1 << cpu);
+
+	return 0;
+
+}
+EXPORT_SYMBOL(mv_pp3_channel_reg);
+
+/* Prepare message CFH and trigger it sending to firmware.
+Inputs:
+	chan - unique channel id
+	msg  - pointer to message to send
+	size - size of message (in bytes)
+	flags - message flags
+	msg_opcode - one from known opcodes (see enum mv_pp3_fw_nic_msg_opcode)
+	msg_seq_num - message sequence number managed by sender
+	num  - number of instances for bulk requests support
+Return:
+	0  - Message accepted and/or sent to firmware.
+	-1 - Failure: Queue is full, etc
+*/
+int mv_pp3_msg_send(int chan, void *msg, int size, int flags, u16 msg_opcode, int msg_seq_num, int num)
+{
+	struct host_msg *cfh_ptr;
+	int msg_size;
+	int cfh_size;		/* CFH size in datagrams (16 bytes each) */
+	unsigned long iflags = 0;
+
+	if (!(mv_pp3_chan_ctrl[chan].status & MV_PP3_F_CHANNEL_CREATED) && (msg_opcode != MV_FW_MSG_CHAN_SET)) {
+		/* channel wasn't created */
+		pr_err("\n%s:: try send message to unknown channel %d", __func__, chan);
+		return -1;
+	}
+
+	/* calculate real FW message size = user msg + msg header */
+	msg_size = size + MV_CFH_FW_MSG_HEADER_BYTES;
+	if (msg_size > MV_PP3_MSG_BUFF_SIZE) {
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx_err++;
+		pr_err("\n%s:: channel %d: cannot send message of %d bytes", __func__, chan, msg_size);
+		return -1;
+	}
+
+	if (msg_size > (MV_PP3_CFH_MAX_SIZE - MV_PP3_CFH_HDR_SIZE))
+
+		/* send message in buffer (by pointer) */
+		/* calc CFH size */
+		cfh_size = (MV_PP3_CFH_HDR_SIZE + MV_CFH_FW_MSG_HEADER_BYTES)/MV_PP3_CFH_DG_SIZE;
+	else {
+		/* send in CFH */
+		/* calc CFH size alligned to 16 bytes (1 datagram) */
+		cfh_size = (MV_ALIGN_UP(msg_size, MV_PP3_CFH_DG_SIZE) +
+			MV_PP3_CFH_HDR_SIZE)/MV_PP3_CFH_DG_SIZE;
+	}
+
+	MV_LOCK(&msngr_channel_lock, iflags);
+	/* get pointer to CFH */
+	cfh_ptr = (struct host_msg *)mv_pp3_hmac_txq_next_cfh(mv_pp3_chan_ctrl[chan].frame,
+		mv_pp3_chan_ctrl[chan].hmac_sw_txq, cfh_size);
+
+	/* check CFH pointer */
+	if (cfh_ptr == NULL) {
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx_err++;
+		pr_err("\n%s:: channel %d: no free CFH", __func__, chan);
+		MV_UNLOCK(&msngr_channel_lock, iflags);
+		return -1;	/* no free CFH in queue */
+	}
+
+	/* ONLY for debug phase:: clean CFH memory */
+	memset(cfh_ptr, 0, (cfh_size * MV_PP3_CFH_DG_SIZE));
+
+	/* build message header and convert it to BE from native cpu format */
+	cfh_ptr->msg_header.word0 = cpu_to_be32(MV_HOST_MSG_INST_NUM_SET(num) |
+		MV_HOST_MSG_SIZE_SET(msg_size));
+
+	cfh_ptr->msg_header.word1 = MV_HOST_MSG_OPCODE_SET(msg_opcode);
+	cfh_ptr->msg_header.word1 |= MV_HOST_MSG_SEQ_NUM_SET(msg_seq_num);
+	if (flags & MV_PP3_F_CFH_EXT_HDR)
+		cfh_ptr->msg_header.word1 |= MV_HOST_MSG_EXT_HDR_SET(1);
+	if (flags & MV_PP3_F_CFH_MSG_ACK)
+		cfh_ptr->msg_header.word1 |= MV_HOST_MSG_ACK_SET(1);
+	cfh_ptr->msg_header.word1 = cpu_to_be32(cfh_ptr->msg_header.word1);
+
+	/* fill common CFH fields */
+	cfh_ptr->common_cfh[2] = MV_HOST_MSG_CHAN_ID(chan);
+
+	/* up message size to 16 bytes only for common CFH part */
+	/* in message header put real msg_size */
+	if (msg_size < MV_PP3_CFH_DG_SIZE)
+		msg_size = MV_PP3_CFH_DG_SIZE;
+
+	if (msg_size > (MV_PP3_CFH_MAX_SIZE - MV_PP3_CFH_HDR_SIZE)) {
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx_err++;
+		pr_err("\n%s:: channel %d: message too large (%d)", __func__, chan, msg_size);
+		MV_UNLOCK(&msngr_channel_lock, iflags);
+		return -1;
+	} else {
+		/* send message in CFH (by value) by write all relevant data to CFH */
+		/* BUILD CFH in descriptor mode (not message mode) */
+		cfh_ptr->common_cfh[0] = MV_HOST_MSG_PACKET_LENGTH(msg_size) + MV_HOST_MSG_DESCR_MODE;
+		cfh_ptr->common_cfh[1] = (MV_HOST_MSG_CFH_LENGTH(msg_size + MV_PP3_CFH_HDR_SIZE)) +
+			(HMAC_CFH << MV_CFH_MODE_OFFS) + (PP_TX_MESSAGE << MV_CFH_PP_MODE_OFFS);
+		if (size > 0)
+			memcpy((char *)(cfh_ptr->fw_msg), msg, size);
+	}
+
+	cfh_size += mv_pp3_hmac_txq_dummy_dg_get(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_txq);
+
+	if (msngr_free) {
+		msngr_free = false;
+		/* send CFH to FW */
+		wmb();
+		if (mv_pp3_tx_msg_print_en)
+			mv_pp3_message_print("Sent", cfh_ptr, size, msg_seq_num, msg_opcode, chan);
+		mv_pp3_hmac_txq_send(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_txq, cfh_size);
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx++;
+	} else {
+		if (mv_pp3_tx_msg_print_en)
+			mv_pp3_message_print("Pend", cfh_ptr, size, msg_seq_num, msg_opcode, chan);
+		/* store message for send it later */
+		mv_pp3_chan_ctrl[chan].ready_to_send[mv_pp3_chan_ctrl[chan].free_ind] = cfh_size;
+		mv_pp3_chan_ctrl[chan].free_ind++;
+		if (mv_pp3_chan_ctrl[chan].free_ind == mv_pp3_chan_ctrl[chan].size)
+			mv_pp3_chan_ctrl[chan].free_ind = 0;
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx_pend++;
+	}
+	MV_UNLOCK(&msngr_channel_lock, iflags);
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_msg_send);
+
+
+static void mv_pp3_send_pend_msg(int bitmap)
+{
+	static int last_proc;   /* last channel with pending CFH that was sent */
+	u16 cfh_ind;
+	int cfh_size;
+	int chan = 0, i;
+
+	/* choose channel for transmit */
+	/* channel 0 must be handle first */
+
+	if (!bitmap)
+		return;
+	else if (bitmap & 1)
+		chan = 0;
+	else if (bitmap & (~(1 << last_proc))) {
+		bitmap &= ~(1 << last_proc);
+		for (i = 0; i < mv_pp3_active_chan_num; i++) {
+			if ((bitmap >> i) & 1) {
+				chan = i;
+				last_proc = i;
+				break;
+			}
+		}
+	} else if (bitmap & (1 << last_proc))
+		chan = last_proc;
+
+	cfh_ind = mv_pp3_chan_ctrl[chan].ready_to_send_ind;
+
+	if (mv_pp3_chan_ctrl[chan].ready_to_send[cfh_ind] != 0) {
+
+		cfh_size = mv_pp3_chan_ctrl[chan].ready_to_send[cfh_ind];
+
+		if (mv_pp3_tx_msg_print_en)
+			pr_info("%s: send message (%d) size (%d) on channel %d\n", __func__, cfh_ind, cfh_size, chan);
+
+		/* Memory barrier before start transmit */
+		wmb();
+
+		mv_pp3_hmac_txq_send(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_txq, cfh_size);
+		mv_pp3_chan_ctrl[chan].ready_to_send[cfh_ind] = 0;
+		mv_pp3_chan_ctrl[chan].ready_to_send_ind++;
+		if (mv_pp3_chan_ctrl[chan].ready_to_send_ind == mv_pp3_chan_ctrl[chan].size)
+			mv_pp3_chan_ctrl[chan].ready_to_send_ind = 0;
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx++;
+		mv_pp3_chan_ctrl[chan].ch_stat.msg_tx_pend--;
+	}
+}
+
+/* Rx message event handler.
+Inputs:
+	chan - unique channel id
+*/
+static void mv_pp3_chan_rx_event(struct mv_pp3_channel *chan)
+{
+	struct host_msg *cfh_ptr;
+	int dg_num, proc_dg;
+	int cfh_size;
+	bool ack_rec = false;
+	int msg_seq_num;
+	u16 msg_opcode;
+	int msg_size;
+	u32 word0, word1;
+	unsigned long iflags = 0;
+	int msg_flags;
+	int ret_code, num_ok;
+
+	if (chan) {
+		if (!(chan->status & MV_PP3_F_CHANNEL_CREATED))
+			return; /* channel wasn't created */
+
+		/* get number of recieved DG */
+		dg_num = proc_dg = mv_pp3_hmac_rxq_occ_get(chan->frame, chan->hmac_sw_rxq);
+		if (dg_num > chan->size*MV_PP3_CFH_MAX_SIZE/MV_PP3_CFH_DG_SIZE) {
+			pr_err("%s: bad occupite datagramm counter %d received on channel %d: frame %d, queue %d.",
+				__func__, dg_num, chan->id, chan->frame, chan->hmac_sw_rxq);
+			return;
+		}
+		mv_pp3_os_cache_io_sync(mv_pp3_dev_get(pp3_priv));
+
+		while (proc_dg > 0) {
+			/* get msg from HMAC RX queue */
+			cfh_ptr = (struct host_msg *)
+				mv_pp3_hmac_rxq_next_cfh(chan->frame, chan->hmac_sw_rxq, &cfh_size);
+			if ((cfh_size == 0) || (cfh_size > MV_PP3_CFH_MAX_SIZE) || (cfh_size > proc_dg)) {
+				chan->ch_stat.msg_rx_err++;
+				pr_err("%s: error CFH with wrong size %d received on channel %d (%d). Frame %d, queue %d.",
+					__func__, cfh_size, chan->id, dg_num, chan->frame, chan->hmac_sw_rxq);
+				break;
+			}
+			if (cfh_size > proc_dg) {
+				mv_pp3_hmac_rxq_cfh_free(chan->frame, chan->hmac_sw_rxq, cfh_size);
+				/* only part of CFH is moved to DRAM */
+				/* in next interrupt will processed full CFH */
+				break;
+			}
+			proc_dg -= cfh_size;
+			if (cfh_ptr == NULL)
+				continue; /* get WA CFH */
+			chan->ch_stat.msg_rx++;
+			/* convert BE message header to native cpu format */
+			word0 = be32_to_cpu(cfh_ptr->msg_header.word0);
+			word1 = be32_to_cpu(cfh_ptr->msg_header.word1);
+
+			msg_flags = 0;
+			if (MV_HOST_MSG_ACK_GET(word1)) {
+				ack_rec = true;
+				msg_flags |= MV_PP3_F_CFH_MSG_ACK;
+			}
+			if (MV_HOST_MSG_EXT_HDR_GET(word1))
+				msg_flags |= MV_PP3_F_CFH_EXT_HDR;
+
+			/* get message header fields */
+			num_ok = MV_HOST_MSG_INST_NUM_GET(word0);
+			msg_opcode = MV_HOST_MSG_OPCODE_GET(word1);
+			msg_size = MV_HOST_MSG_SIZE_GET(word0) - MV_CFH_FW_MSG_HEADER_BYTES;
+
+			msg_seq_num = MV_HOST_MSG_SEQ_NUM_GET(word1);
+			ret_code = MV_HOST_MSG_RC_GET(word1);
+
+			if (mv_pp3_rx_msg_print_en) {
+				MV_LOCK(&msngr_channel_lock, iflags);
+				mv_pp3_message_print("Receive", cfh_ptr, msg_size, msg_seq_num, msg_opcode, chan->id);
+				MV_UNLOCK(&msngr_channel_lock, iflags);
+			}
+
+			if (chan->rcv_func == NULL)
+				continue;
+
+			chan->rcv_func(chan->id, (char *)cfh_ptr->fw_msg, msg_size, msg_seq_num, msg_flags,
+				msg_opcode, ret_code, num_ok);
+		}
+		if (ack_rec) {
+			u16 cfh_ind;
+			int i;
+			u32 bitmap = 0;
+			MV_LOCK(&msngr_channel_lock, iflags);
+
+			/* scan all channels and build bitmap of candidate with pending req */
+			for (i = 0; i < mv_pp3_active_chan_num; i++) {
+				if (mv_pp3_chan_ctrl[i].size == 0)
+					continue;
+				cfh_ind = mv_pp3_chan_ctrl[i].ready_to_send_ind;
+				if (mv_pp3_chan_ctrl[i].ready_to_send &&
+					(mv_pp3_chan_ctrl[i].ready_to_send[cfh_ind] != 0))
+					bitmap |= (1 << i);
+			}
+
+			if (bitmap == 0)
+				msngr_free = true;
+			else
+				mv_pp3_send_pend_msg(bitmap);
+
+			MV_UNLOCK(&msngr_channel_lock, iflags);
+		}
+
+		/* Write a number of processed datagram */
+		if ((dg_num - proc_dg) > 0)
+			mv_pp3_hmac_rxq_occ_set(chan->frame, chan->hmac_sw_rxq, dg_num - proc_dg);
+	}
+
+	return;
+}
+
+/*********************** sysFS functions *******************************/
+void mv_pp3_channel_show(int ch_num)
+{
+	struct mv_pp3_channel *ch_ptr = &mv_pp3_chan_ctrl[ch_num];
+
+	if (ch_ptr->rcv_func == NULL)
+		pr_info("\nChannel %d: no callback function connected", ch_num);
+	else
+		pr_info("\nChannel %d:", ch_num);
+	pr_info("\tHMAC: frame %d, RXQ %d, TXQ %d", ch_ptr->frame, ch_ptr->hmac_sw_rxq, ch_ptr->hmac_sw_txq);
+	pr_info("\tStatistics:");
+	pr_info("\t\tNumber of sent messages              :%10d\n", ch_ptr->ch_stat.msg_tx);
+	pr_info("\t\tNext index to add pended message     :%10d\n", ch_ptr->free_ind);
+	pr_info("\t\tNext index to send pended message    :%10d\n", ch_ptr->ready_to_send_ind);
+	pr_info("\t\tNumber of received messages          :%10d\n", ch_ptr->ch_stat.msg_rx);
+	pr_info("\t\tNumber of errors through messages TX :%10d\n", ch_ptr->ch_stat.msg_tx_err);
+	pr_info("\t\tNumber of errors through messages RX :%10d\n", ch_ptr->ch_stat.msg_rx_err);
+	pr_info("\t\tNumber of messages waited for tx     :%10d\n", ch_ptr->ch_stat.msg_tx_pend);
+	pr_info("\t\tNumber of rx events                  :%10d\n", ch_ptr->ch_stat.events_cntr);
+	pr_info("\n");
+
+	return;
+}
+
+/*************************************** debug functions **********************************************/
+void mv_pp3_msg_receive(int chan)
+{
+	struct mv_pp3_channel *ch_ptr = &mv_pp3_chan_ctrl[chan];
+
+	mv_pp3_chan_rx_event(ch_ptr);
+}
+
+/* Channel callback
+Inputs:
+	chan - unique channel id
+	msg  - pointer to message to send
+	size - size of message (in bytes)
+	seq_num - message sequence number
+	flags - message flags:
+		Bit 0 - Acknowledge or Reply is received.
+		Bit 1 - Buffer extension header existence
+	msg_opcode - unique message type identifier.
+	ret_code - status returned by the Firmware for the whole request.
+	num_ok - number of messages successfully processed by FW.
+*/
+void pp3_msg_chan_callback(int chan, void *msg, int size, int seq_num, int flags, u16 msg_opcode,
+		int ret_code, int num_ok)
+{
+	int i;
+	u8 *msg_ptr = (u8 *)msg;
+
+	pr_info("\nReceive %d bytes MSG seq_num=%d, flags=%d, msg_opcode=%d ::\n", size, seq_num, flags, msg_opcode);
+	for (i = 0; i < size; i++)
+		pr_info("0x%x ", msg_ptr[i]);
+}
+
+void mv_pp3_chan_create_cmd(int size, int flags)
+{
+	int chan;
+
+	chan = mv_pp3_chan_create(MV_DRIVER_CL_ID, size, pp3_msg_chan_callback);
+
+	pr_info("Create HOST <-> FW channel %d\n", chan);
+}
+
+void mv_pp3_msg_rx_poll(int cpu)
+{
+	int i;
+
+	/* check RX occup counter on each active channel */
+	for (i = 0; i < MV_PP3_MAX_CHAN_NUM; i++) {
+		if ((mv_pp3_chan_ctrl[i].status & MV_PP3_F_CHANNEL_CREATED) &&
+		    (*(per_cpu_ptr(mv_pp3_ch_bmp, cpu)) & (1 << i)))
+			mv_pp3_chan_rx_event(&mv_pp3_chan_ctrl[i]);
+	}
+}
+
+/* Close communication channel
+Inputs:
+	chan - unique channel id
+eturn:
+	 0 - success
+	-1 - fail
+*/
+int mv_pp3_chan_delete(int chan)
+{
+	if (!(mv_pp3_chan_ctrl[chan].status & MV_PP3_F_CHANNEL_CREATED)) {
+		pr_err("Channel %d wasn't created", chan);
+		return -1;
+	}
+	/* disconnect IRQ */
+	disable_irq(mv_pp3_chan_ctrl[chan].irq_num);
+	free_irq(mv_pp3_chan_ctrl[chan].irq_num, (void *)&mv_pp3_chan_ctrl[chan]);
+
+	/* disable channel */
+	mv_pp3_hmac_rxq_flush(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_rxq);
+	mv_pp3_hmac_rxq_delete(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_rxq);
+	mv_pp3_hmac_txq_flush(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_txq);
+	mv_pp3_hmac_txq_delete(mv_pp3_chan_ctrl[chan].frame, mv_pp3_chan_ctrl[chan].hmac_sw_txq);
+	kfree(mv_pp3_chan_ctrl[chan].ready_to_send);
+	memset(&mv_pp3_chan_ctrl[chan], 0, sizeof(struct mv_pp3_channel));
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_pp3_chan_delete);
+
+static void mv_pp3_message_print(char *str, struct host_msg *cfh_ptr, int size, int num, int opcode, int chan)
+{
+
+	u8  *tmp;
+	int i;
+
+	pr_info("\n%s on cpu %d message N%d opcode %d with data length %d to channel %d:",
+		str, smp_processor_id(), num, opcode, size + MV_CFH_FW_MSG_HEADER_BYTES, chan);
+
+	tmp = (u8 *)&(cfh_ptr->msg_header);
+	pr_info("Message header: ");
+	for (i = 0; i < 8; i++)
+		pr_cont("%02x ", tmp[i]);
+	pr_info("Message data  : ");
+	tmp = (u8 *)cfh_ptr->fw_msg;
+	for (i = 0; i < size; i++) {
+		if ((i != 0) && ((i%16) == 0))
+			pr_cont("\n                ");
+		pr_cont("%02x ", tmp[i]);
+	}
+	pr_info("\n");
+}
+
+/* Enable / disable print out of sent / received messages */
+void mv_pp3_debug_message_print_en(bool rx_en, bool tx_en)
+{
+	mv_pp3_rx_msg_print_en = rx_en;
+	mv_pp3_tx_msg_print_en = tx_en;
+}
+
+void mv_pp3_messenger_close(void)
+{
+	int i;
+
+	/* delete all channels */
+	for (i = 0; i < MV_PP3_MAX_CHAN_NUM; i++) {
+		if (mv_pp3_chan_ctrl[i].status & MV_PP3_F_CHANNEL_CREATED)
+			mv_pp3_chan_delete(i);
+	}
+
+	/* number of active channels */
+	mv_pp3_active_chan_num = 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.h b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.h
new file mode 100644
index 0000000..699a270
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_chan.h
@@ -0,0 +1,116 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_msg_chan_h__
+#define __mv_pp3_msg_chan_h__
+
+#include <linux/interrupt.h>
+
+#include "platform/mv_pp3.h"
+#include "common/mv_sw_if.h"
+#include "fw/mv_fw_shared.h"
+#include "msg/mv_pp3_msg.h"
+
+#define MV_PP3_MSG_BUF_HROOM	32
+
+#ifdef CONFIG_MV_CHAN_STAT_INF
+#define CHAN_STAT_INFO(c) c
+#else
+#define CHAN_STAT_INFO(c)
+#endif
+
+
+/*
+	event - HMAC Rx event
+	 * 0 - QM queue - Timeout or new items added to the queue
+	 *     BM queue - allocate completed
+ */
+enum mv_pp3_hmac_rx_event {
+	MV_PP3_RX_CFH = 0,
+	MV_PP3_QU_FULL
+};
+
+/* Channel flags definition */
+#define MV_PP3_F_CHANNEL_CREATED	(0x1)
+
+/* channel counters */
+struct mv_pp3_chan_cntrs {
+	u32 msg_tx;		/* total number of sent messages */
+	u32 msg_tx_pend;	/* total number of pended messages */
+	u32 msg_rx;		/* number of received messages */
+	u32 msg_tx_err;		/* number of didn't sent messages */
+	u32 msg_rx_err;		/* number of errors through message rx */
+	u32 events_cntr;	/* number of ISR calls */
+};
+
+/* channel configuration parameters */
+struct mv_pp3_channel {
+	u8			id;		/* channel number */
+	u8			cpu_mask;	/* channel cpu mask */
+	u8			frame;		/* HMAC frame number */
+	u8			hmac_sw_rxq;	/* HMAC queue number in frame */
+	u8			hmac_sw_txq;	/* HMAC queue number in frame */
+	u16			hmac_hw_rxq;	/* HMAC queue number in frame */
+	u16			hmac_hw_txq;	/* HMAC queue number in frame */
+	u16			size;		/* max number of messages in queue */
+	u8			event_group;	/* Rx queue event group number */
+	u8			bm_pool_id;	/* used for messages that Host send to Firmware */
+	u8			buf_headroom;	/* headroom defined for BM pool buffer */
+	u32			status;
+	int			*ready_to_send;		/* list of CFH sizes waiting for send */
+	u16			ready_to_send_ind;	/* CFH index - ready_to_send */
+	u16			free_ind;		/* free index in ready for send */
+	mv_pp3_chan_rcv_func	rcv_func;
+	struct mv_pp3_chan_cntrs ch_stat;	/* channel statistics */
+	struct tasklet_struct	channel_tasklet;
+	int			irq_num;	/* IRQ number */
+	char			mv_chan_isr[15];
+};
+
+/* HOST <-> FW message format and fields definition */
+struct host_msg {
+	u32				common_cfh[MV_PP3_CFH_COMMON_WORDS];
+	struct mv_pp3_fw_msg_header	msg_header;
+	u32				fw_msg[1];
+};
+
+
+/* Init messenger facility - call ones
+Return:
+	>= 0 - unique channel ID,
+	-1   - failure
+*/
+int mv_pp3_messenger_init(struct mv_pp3 *priv);
+void mv_pp3_messenger_close(void);
+
+/* internal channel interface functions declartion */
+void mv_pp3_msg_receive(int chan);
+void mv_pp3_chan_create_cmd(int size, int flags);
+
+void mv_pp3_msg_rx_poll(int cpu);
+
+/* sysfs related */
+void mv_pp3_channel_show(int ch_num);
+int mv_pp3_chan_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_chan_sysfs_exit(struct kobject *hmac_kobj);
+
+/* debug related */
+struct mv_pp3_channel *mv_pp3_chan_get(int ch_num);
+int mv_pp3_chan_num_get(void);
+
+#endif /* __mv_pp3_msg_chan_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.c b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.c
new file mode 100644
index 0000000..f14b851
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.c
@@ -0,0 +1,262 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/* includes */
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/list.h>
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "msg/mv_pp3_msg.h"
+#include "msg/mv_pp3_msg_drv.h"
+#include "fw/mv_fw_shared.h"
+
+#ifdef PP3_DEBUG
+#define PP3_MSG_DEBUG
+#endif
+
+static spinlock_t dev_msg_lock;
+
+/* channell usage mode - CPU shared or channel per CPU */
+static bool mv_msg_chan_share;
+
+/* store here all driver messages sent to FW on channel */
+static struct list_head sent_msg_list[MV_PP3_MAX_CHAN_NUM];
+/* message sequentail number */
+static int msg_seq_num;
+
+/* driver messages channel ID for each cpu */
+static int drv_chan_id[CONFIG_NR_CPUS];
+
+static void pp3_chan_callback(int chan, void *msg, int size, int seq_num, int flags, u16 msg_opcode,
+		int ret_code, int num_ok);
+
+/* Init driver messenger mechanism for driver request HOST <-> FW messages.
+ * Create channel (or channels) according to "share_ch" flag
+Inputs:
+	num_of_msg - max number of messages in channel
+	share_ch   - if true, one channel is created for used by each cpu
+		     if false, create channel per cpu
+Return:
+	0  - success
+	-1 - failure
+*/
+int mv_pp3_drv_messenger_init(int num_of_msg, bool share_ch)
+{
+	int chan_id;
+	int cpu;
+
+	/* create lock mechanism */
+	spin_lock_init(&dev_msg_lock);
+
+	if (share_ch) {
+		cpu = smp_processor_id();
+		/* created one channell for all CPUs */
+		chan_id = mv_pp3_chan_create(MV_DRIVER_CL_ID, num_of_msg, pp3_chan_callback);
+		if (chan_id < 0)
+			return -1;
+		INIT_LIST_HEAD(&sent_msg_list[chan_id]);
+		for_each_possible_cpu(cpu) {
+			drv_chan_id[cpu] = chan_id;
+			mv_pp3_channel_reg(chan_id, cpu);
+		}
+		mv_msg_chan_share = true;
+	} else {
+		/* created channel per CPU */
+		for_each_possible_cpu(cpu) {
+			chan_id = mv_pp3_chan_create(MV_DRIVER_CL_ID, num_of_msg, pp3_chan_callback);
+			if (chan_id < 0)
+				return -1;
+			drv_chan_id[cpu] = chan_id;
+			INIT_LIST_HEAD(&sent_msg_list[chan_id]);
+			mv_pp3_channel_reg(chan_id, cpu);
+			mv_msg_chan_share = false;
+		}
+	}
+
+	return 0;
+}
+
+/* Close driver messenger mechanism
+ * Delete channel (or channels) according to "share_ch" flag and clear all global configuration
+ * parameters
+*/
+void mv_pp3_drv_messenger_close(void)
+{
+	struct msg_reply_info *msg_info;
+	int cpu, chan_id;
+
+	for_each_possible_cpu(cpu) {
+		if (drv_chan_id[cpu]) {
+			chan_id = drv_chan_id[cpu];
+			while (!list_empty(&sent_msg_list[chan_id])) {
+				msg_info = list_first_entry(&sent_msg_list[chan_id], struct msg_reply_info,
+						sent_msg);
+				/* delete message from list */
+				list_del(&msg_info->sent_msg);
+				kfree(msg_info);
+			}
+		}
+		mv_pp3_chan_delete(drv_chan_id[cpu]);
+	}
+
+	msg_seq_num = 0;
+}
+
+/* Send driver message to FW
+Inputs:
+	req_info   - message info needed by request/reply.
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure: Queue is full, etc
+*/
+int mv_pp3_drv_request_send(struct request_info *req_info)
+{
+	struct msg_reply_info *msg_info;
+	int ret_val;
+	int cpu = smp_processor_id();
+	int chan_id;
+	unsigned long iflags = 0;
+	int cur_msg_num;
+
+	chan_id = drv_chan_id[cpu];
+
+	msg_info = kzalloc(sizeof(struct msg_reply_info), GFP_ATOMIC);
+	if (msg_info == NULL)
+		return -1;
+
+	MV_RES_LOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	cur_msg_num = msg_info->seq_num = msg_seq_num++;
+	if (msg_seq_num > MV_HOST_MSG_SEQ_NUM_MASK)
+		msg_seq_num = 0;
+
+	MV_RES_UNLOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+
+	if (req_info->req_cb) {
+		/* add message to list */
+		msg_info->size_of_reply = req_info->size_of_output;
+		msg_info->output_buf = req_info->out_buff;
+		msg_info->msg_cb = req_info->req_cb;
+		msg_info->p1 = req_info->cb_params;
+		MV_RES_LOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+		list_add_tail(&msg_info->sent_msg, &sent_msg_list[chan_id]);
+		MV_RES_UNLOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+#ifdef PP3_MSG_DEBUG
+		pr_info("Add req (%p) for message N%d, opcode %d\n",
+			msg_info, msg_info->seq_num, req_info->msg_opcode);
+#endif
+	}
+	MV_RES_LOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	ret_val = mv_pp3_msg_send(chan_id, req_info->in_param, req_info->size_of_input, MV_PP3_F_CFH_MSG_ACK,
+		req_info->msg_opcode, msg_info->seq_num, req_info->num_of_ints);
+	MV_RES_UNLOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+
+	if (!req_info->req_cb)
+		kfree(msg_info);
+
+	return cur_msg_num;
+}
+
+/* Delete driver request message from the list of requests
+Inputs:
+	req_num    - request sequence number
+Return:
+	0  - success
+	-1 - failure
+*/
+int mv_pp3_drv_request_delete(unsigned int req_num)
+{
+	struct msg_reply_info *msg_info;
+	int cpu = smp_processor_id();
+	int chan_id;
+	unsigned long iflags = 0;
+
+	chan_id = drv_chan_id[cpu];
+	/* get message request from the list head */
+	MV_RES_LOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	if (!list_empty(&sent_msg_list[chan_id]))
+		msg_info = list_first_entry(&sent_msg_list[chan_id], struct msg_reply_info, sent_msg);
+	else
+		msg_info = NULL;
+	MV_RES_UNLOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	/* compare message data */
+	if ((msg_info == NULL) || (msg_info->seq_num != req_num)) {
+		pr_err("Cannot delete request N%d", req_num);
+		return -1;
+	}
+	/* delete message from list */
+	list_del(&msg_info->sent_msg);
+	kfree(msg_info);
+
+	return 0;
+}
+
+static void pp3_chan_callback(int chan, void *msg, int size, int seq_num, int flags, u16 msg_opcode,
+		int ret_code, int num_ok)
+{
+	struct msg_reply_info *msg_info;
+	unsigned long iflags = 0;
+
+	/* get message request from the list head */
+	MV_RES_LOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	if (!list_empty(&sent_msg_list[chan]))
+		msg_info = list_first_entry(&sent_msg_list[chan], struct msg_reply_info, sent_msg);
+	else
+		msg_info = NULL;
+	MV_RES_UNLOCK(mv_msg_chan_share, &dev_msg_lock, iflags);
+	/* verify response to request */
+	if (msg_info == NULL)
+		return;
+	if ((msg_info != NULL) && (msg_info->seq_num != seq_num)) {
+		/*pr_err("%s: Receive unexpected reply N%d for request N%d.", __func__, seq_num, msg_info->seq_num);*/
+		return;
+	}
+#ifdef PP3_MSG_DEBUG
+	{
+	int i; u8 *tmp = msg;
+	pr_info("Receive reply (%p) for request N%d (%d), opcode %d, return code %d\n",
+		msg_info, seq_num, msg_info->seq_num, msg_opcode, ret_code);
+	pr_info("size = %d, msg_info->size_of_reply = %d\naddress=%p, ", size, msg_info->size_of_reply,
+		msg_info->output_buf);
+	for (i = 0; i < size; i++, tmp++)
+		pr_cont("%x ", *tmp);
+	}
+#endif
+	/* copy response buffer */
+	if ((msg != NULL) && (msg_info->output_buf)) {
+		if (size <= msg_info->size_of_reply)
+			memcpy(msg_info->output_buf, msg, size);
+		else {
+			memcpy(msg_info->output_buf, msg, msg_info->size_of_reply);
+			pr_err("Receive reply for request N%d with size(%d) > size_of_reply(%d)\n",
+				seq_num, size, msg_info->size_of_reply);
+		}
+	}
+
+	if (msg_info->msg_cb) {
+		struct drv_msg_cb_params *p;
+		p = (struct drv_msg_cb_params *)msg_info->p1;
+		p->req_num = seq_num;
+		p->ret_code = ret_code;
+		p->num_ok = num_ok;
+		p->size_of_reply = size;
+		msg_info->msg_cb((void *)msg_info->p1);
+	}
+	mv_pp3_drv_request_delete(seq_num);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.h b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.h
new file mode 100644
index 0000000..0e8e687
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_drv.h
@@ -0,0 +1,88 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_msg_drv_h__
+#define __mv_pp3_msg_drv_h__
+
+/* driver request message node */
+struct msg_reply_info {
+	struct list_head sent_msg;
+	unsigned int seq_num;
+	int size_of_reply;
+	void *output_buf;
+	void (*msg_cb)(void *p1);
+	void *p1;
+};
+/* driver request parameters */
+struct request_info {
+	unsigned int msg_opcode;
+	void *in_param;
+	int size_of_input;
+	void *out_buff;
+	int size_of_output;
+	int num_of_ints;
+	void (*req_cb)(void *);
+	void *cb_params;
+};
+/* driver request callback parameters */
+struct drv_msg_cb_params {
+	struct completion complete;
+	int req_num;
+	int ret_code;
+	int num_ok;
+	int size_of_reply;
+};
+
+/* Init driver messenger mechanism for driver request HOST <-> FW messages.
+ * Create channel (or channels) according to "share_ch" flag
+Inputs:
+	num_of_msg - max number of messages in channel
+	share_ch   - if true, one channel is created for used by each cpu
+		     if false, create channel per cpu
+Return:
+	0  - success
+	-1 - failure
+*/
+int mv_pp3_drv_messenger_init(int num_of_msg, bool share_ch);
+
+/* Close driver messenger mechanism
+ * Delete channel (or channels) according to "share_ch" flag and clear all global configuration
+ * parameters
+*/
+void mv_pp3_drv_messenger_close(void);
+
+/* Send driver message to FW
+Inputs:
+	req_info   - message info needed by request/reply.
+Return:
+	>= 0- Message sequence number (message accepted and sent to firmware).
+	< 0 - Failure: Queue is full, etc
+*/
+int mv_pp3_drv_request_send(struct request_info *msg_info);
+
+/* Delete driver request message from the list of requests
+Inputs:
+	req_num    - request sequence number
+Return:
+	0  - success
+	-1 - failure
+*/
+int mv_pp3_drv_request_delete(unsigned int req_num);
+
+
+#endif /* __mv_pp3_msg_drv_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_sysfs.c b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_sysfs.c
new file mode 100644
index 0000000..006104f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/msg/mv_pp3_msg_sysfs.c
@@ -0,0 +1,141 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include "common/mv_sw_if.h"
+#include "mv_pp3_msg.h"
+#include "mv_pp3_msg_chan.h"
+
+static ssize_t mv_channel_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [n] [f]     > create_chan  - Create host <-> fw channel\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [c]         > chan_show    - Show message channel status and statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [c] [t] [s] > send_msg     - Send message [s] opcode [t] to channel [c]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [c]         > rx_msg       - Receive all messages from channel [c]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [rx] [tx]   > debug        - Enable/disable debug messages print out\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [n] max number of messages in channel\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [f] channel flags\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [c] channel number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [t] message opcode\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [s] string\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [rx/tx] 0 - disable, 1 - enable\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_channel_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_channel_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_channel_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err, ret;
+	unsigned int    c;
+	unsigned int  type;
+	char msg[256];
+	unsigned char imsg[128];
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read first 3 parameters */
+	err = c = 0;
+	ret = sscanf(buf, "%x %d %s", &c, &type, msg);
+
+	if (!strcmp(name, "chan_show"))
+		mv_pp3_channel_show(c);
+	else if (!strcmp(name, "send_msg")) {
+		str_to_hex(msg, strlen(msg), imsg, strlen(msg)/2);
+		mv_pp3_msg_send(c, imsg, strlen(msg)/2, MV_PP3_F_CFH_MSG_ACK, (u16) type, 0, 1);
+	} else if (!strcmp(name, "rx_msg"))
+		mv_pp3_msg_receive(c);
+	else if (!strcmp(name, "create_chan"))
+		mv_pp3_chan_create_cmd(c, type);
+	else if (!strcmp(name, "debug")) {
+		bool rx_en, tx_en;
+
+		rx_en = (c) ? true : false;
+		tx_en = (type) ? true : false;
+		mv_pp3_debug_message_print_en(rx_en, tx_en);
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help, S_IRUSR, mv_channel_show, NULL);
+static DEVICE_ATTR(create_chan, S_IWUSR, NULL, mv_channel_store);
+static DEVICE_ATTR(chan_show, S_IWUSR, NULL, mv_channel_store);
+static DEVICE_ATTR(send_msg, S_IWUSR, NULL, mv_channel_store);
+static DEVICE_ATTR(rx_msg, S_IWUSR, NULL, mv_channel_store);
+static DEVICE_ATTR(debug, S_IWUSR, NULL, mv_channel_store);
+
+
+static struct attribute *mv_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_create_chan.attr,
+	&dev_attr_chan_show.attr,
+	&dev_attr_send_msg.attr,
+	&dev_attr_rx_msg.attr,
+	&dev_attr_debug.attr,
+	NULL
+};
+
+static struct attribute_group mv_chan_group = {
+	.name = "msg",
+	.attrs = mv_attrs,
+};
+
+int mv_pp3_chan_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &mv_chan_group);
+	if (err) {
+		pr_err("sysfs group failed %d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_chan_sysfs_exit(struct kobject *hmac_kobj)
+{
+	sysfs_remove_group(hmac_kobj, &mv_chan_group);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_bpi_sysfs.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_bpi_sysfs.c
new file mode 100644
index 0000000..51d0148
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_bpi_sysfs.c
@@ -0,0 +1,160 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "mv_netdev.h"
+#include "mv_dev_vq.h"
+
+
+static ssize_t pp3_dev_bpi_help(char *b)
+{
+	int o = 0;
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                     > tx_bpi_show   - Show BPI configuration for network interface\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [emac]         > tx_vq_emac    - Set egress virtual queue to send packets to [emac]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [on] [off]     > tx_bpi_thresh - Set x[on] and x[off] BPI thresholds for egress packets\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq]                > tx_vq_del     - Delete egress virtual queue BPI configuration\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters: all values are decimal\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "    [ifname]    - network interface name e.g. nic0, nic1, nss0\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "    [emac]      - EMAC number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "    [vq]        - virtual queue number in range of [0..16]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "    [on] [off]  - internal back pressure Xon and Xoff thresholds in units of bytes\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "    [l]         - BPI level: 0 - emac2hmac, 1 - cmac2hmac,  2 - cmac2cmac   3 - emac2cmac\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "                  level 0 valid only for VQs that send packets to EMAC directly\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "                  level 1-3 valid only for VQss that send packets to EMAC via CMAC\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t pp3_dev_bpi_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) {
+		off = pp3_dev_bpi_help(buf);
+
+	} else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	return off;
+}
+
+
+static ssize_t pp3_dev_bpi_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    vq, a, b, c;
+	unsigned long   flags;
+	char		if_name[10];
+	struct net_device *netdev;
+	struct	pp3_dev_priv *dev_priv;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = a = b = c = vq = 0;
+
+	if (sscanf(buf, "%s %d %d %d %d", if_name, &vq, &a, &b, &c) <= 0) {
+		err = 1;
+		goto exit;
+	}
+
+	netdev = dev_get_by_name(&init_net, if_name);
+
+	if (!netdev) {
+		pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+		return -EINVAL;
+	}
+
+	dev_priv = MV_PP3_PRIV(netdev);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "tx_vq_emac"))
+		err = mv_pp3_egress_vq_emac_set(netdev, vq, a);
+	else if (!strcmp(name, "tx_bpi_thresh"))
+		err = mv_pp3_egress_vq_bpi_thresh_set(netdev, vq, a, b);
+	else if (!strcmp(name, "tx_vq_del"))
+		pr_info("not supported yet\n");
+	else if (!strcmp(name, "tx_bpi_show"))
+		mv_pp3_egress_bpi_dump(netdev);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+	dev_put(netdev);
+exit:
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_bpi_show, NULL);
+static DEVICE_ATTR(tx_bpi_show,		S_IWUSR, NULL, pp3_dev_bpi_store);
+static DEVICE_ATTR(tx_vq_emac,		S_IWUSR, NULL, pp3_dev_bpi_store);
+static DEVICE_ATTR(tx_bpi_thresh,	S_IWUSR, NULL, pp3_dev_bpi_store);
+static DEVICE_ATTR(tx_vq_del,		S_IWUSR, NULL, pp3_dev_bpi_store);
+
+
+static struct attribute *pp3_dev_bpi_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_tx_bpi_show.attr,
+	&dev_attr_tx_vq_emac.attr,
+	&dev_attr_tx_bpi_thresh.attr,
+	&dev_attr_tx_vq_del.attr,
+	NULL
+};
+
+
+static struct attribute_group pp3_dev_bpi_group = {
+	.name = "bpi",
+	.attrs = pp3_dev_bpi_attrs,
+};
+
+int mv_pp3_dev_bpi_sysfs_init(struct kobject *dev_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(dev_kobj, &pp3_dev_bpi_group);
+
+	if (err)
+		pr_err("sysfs group failed for bpi path\n");
+
+	return err;
+}
+
+int mv_pp3_dev_bpi_sysfs_exit(struct kobject *dev_kobj)
+{
+	sysfs_remove_group(dev_kobj, &pp3_dev_bpi_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.c
new file mode 100644
index 0000000..9e4c303
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.c
@@ -0,0 +1,1504 @@
+/*******************************************************************************t
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/skbuff.h>
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "bm/mv_bm.h"
+#include "hmac/mv_hmac.h"
+#include "hmac/mv_hmac_bm.h"
+#include "emac/mv_emac.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "mv_netdev_structs.h"
+#include "mv_netdev.h"
+#include "mv_dev_vq.h"
+#include "vport/mv_pp3_vq.h"
+#include "vport/mv_pp3_vport.h"
+#include "vport/mv_pp3_cpu.h"
+#include "vport/mv_pp3_pool.h"
+#include "msg/mv_pp3_msg_chan.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_mib_regs.h"
+
+#ifdef CONFIG_MV_PP3_TM_SUPPORT
+#include "tm/mv_tm.h"
+#include "tm/wrappers/mv_tm_scheme.h"
+#endif
+
+#define PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus, name)\
+	pp3_dbg_pools_stats_dump(pools, num, cpus, offsetof(struct pp3_pool_stats, name)/4, #name)
+
+
+void pp3_dbg_separate_line_print(int length)
+{
+	int i;
+
+	for (i = 0; i < length; i++)
+		pr_cont("-");
+
+	pr_cont("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_ingress_vqs_show(struct net_device *dev)
+{
+	int vq, vqs_num;
+	u16 pkts;
+	struct	pp3_dev_priv *dev_priv;
+	struct mv_nss_drop drop;
+	struct mv_nss_sched sched;
+
+	if (!dev) {
+		pr_info("%s: Error - Input pointer is NULL\n", __func__);
+		return;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("Error - Can't show ingress virtual queues map, %s is not initialized\n", dev->name);
+		return;
+	}
+	if (mv_pp3_dev_ingress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of ingress virtual queues\n", dev->name);
+		return;
+	}
+
+	pr_info("\n");
+	pr_info("vq: %8s %8s %8s %8s  %8s %8s\n", "length", "prio", "weight", "DWRR", "TD", "RED");
+	pr_info("    %8s %8s %8s %8s  %8s %8s\n", "[pkts]", "[0-7]", "", "[E/D]", "[KB]", "[KB]");
+
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		if (mv_pp3_dev_ingress_vq_size_get(dev, vq, &pkts))
+			pkts = -1;
+
+		if (mv_pp3_dev_ingress_vq_drop_get(dev, vq, &drop))
+			memset(&drop, 0, sizeof(drop));
+
+		if (mv_pp3_dev_ingress_vq_sched_get(dev, vq, &sched))
+			memset(&sched, 0, sizeof(sched));
+
+		pr_info("%-2d: %8d %8d %8d %8s %8d %8d\n", vq, pkts,
+			sched.priority,	sched.weight, (sched.wrr_enable) ? "En" : "Dis",
+			drop.td, drop.red);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_ingress_vqs_print(struct net_device *dev)
+{
+	int vq, vqs_num, cpu, anode, bnode;
+	struct pp3_vport *vp;
+	struct	pp3_dev_priv *dev_priv;
+	struct pp3_vq *vq_priv;
+
+	if (!dev) {
+		pr_info("%s: Error - Input pointer is NULL\n", __func__);
+		return;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("Error - Can't show ingress virtual queues map, %s is not initialized\n", dev->name);
+		return;
+	}
+
+	pr_cont("\n");
+
+	pr_cont("        ");
+	for_each_possible_cpu(cpu) {
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			pr_cont("            CPU[%d]                  ", cpu);
+	}
+	pr_cont("\n");
+
+	pr_cont("vq:     ");
+
+	for_each_possible_cpu(cpu) {
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			pr_cont("frame  swq   hwq   anode   bnode    ");
+	}
+
+	pr_cont("\n");
+
+	if (mv_pp3_dev_ingress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of ingress virtual queues\n", dev->name);
+		return;
+	}
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		pr_cont("%-2d:       ", vq);
+		for_each_possible_cpu(cpu) {
+
+			vp = dev_priv->cpu_vp[cpu];
+			if (!vp)
+				continue;
+
+			vq_priv = vp->rx_vqs[vq];
+			if (!vq_priv || !vq_priv->swq)
+				continue;
+
+			/* Get parent Anode for HWQ */
+			if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode)) {
+				pr_err("%s: can't get bnode for anode %d\n", __func__, anode);
+				anode = -1;
+			} else if (mv_tm_scheme_parent_node_get(TM_A_LEVEL, anode, &bnode)) {
+				pr_err("%s: can't get bnode for anode %d\n", __func__, anode);
+				bnode = -1;
+			}
+			pr_cont("%d    %2d    %3d    %3d    %3d        ",
+				vq_priv->swq->frame_num, vq_priv->swq->swq, vq_priv->hwq,
+				anode, bnode);
+		}
+		pr_cont("\n");
+	}
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+
+void pp3_dbg_egress_vqs_show(struct net_device *dev)
+{
+	int vq, vqs_num;
+	u16 pkts;
+	struct pp3_dev_priv *dev_priv;
+	struct mv_nss_meter shaper;
+	struct mv_nss_sched sched;
+	struct mv_nss_drop drop;
+
+	if (!dev) {
+		pr_info("%s: Error - Input pointer is NULL\n", __func__);
+		return;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("Error - Can't show egress virtual queues configuration, %s in not initialized\n", dev->name);
+		return;
+	}
+	if (mv_pp3_dev_egress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of egress virtual queues\n", dev->name);
+		return;
+	}
+
+	pr_info("\n");
+	pr_info("vq:   %6s %8s  %8s %8s %8s %8s %8s %8s %8s %8s\n",
+		"length", "prio", "weight", "DWRR", "TD", "RED", "CIR", "EIR", "CBS", "EBS");
+	pr_info("      %6s %8s  %8s %8s %8s %8s %8s %8s %8s %8s\n",
+		"[pkts]", "[0-7]", "", "[E/D]", "[KB]", "[KB]", "[Mbps]", "[Mbps]", "[KB]", "[KB]");
+
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		if (mv_pp3_dev_egress_vq_size_get(dev, vq, &pkts))
+			pkts = -1;
+
+		if (mv_pp3_dev_egress_vq_rate_limit_get(dev, vq, &shaper))
+			memset(&shaper, 0, sizeof(shaper));
+
+		if (mv_pp3_dev_egress_vq_sched_get(dev, vq, &sched))
+			memset(&sched, 0, sizeof(sched));
+
+		if (mv_pp3_dev_egress_vq_drop_get(dev, vq, &drop))
+			memset(&drop, 0, sizeof(drop));
+
+		pr_info("%-2d: %8d %8d %8d  %8s %8d %8d %8d %8d %8d %8d\n",
+			vq, pkts, sched.priority,
+			sched.weight, (sched.wrr_enable) ? "En " : "Dis",
+			drop.td, drop.red,
+			shaper.cir, shaper.eir, shaper.cbs, shaper.ebs);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_egress_vqs_print(struct net_device *dev)
+{
+	int vq, vqs_num, cpu, anode, bnode;
+	struct pp3_dev_priv *dev_priv;
+	struct pp3_vport *vp, *emac_vp = NULL;
+	struct pp3_vq *vq_priv;
+
+	if (!dev) {
+		pr_info("%s: Error - Input pointer is NULL\n", __func__);
+		return;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("Error - Can't show egress virtual queues map, %s is not initialized\n", dev->name);
+		return;
+	}
+	if (mv_pp3_dev_egress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of ingress virtual queues\n", dev->name);
+		return;
+	}
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH))
+		emac_vp = vp;
+
+	pr_cont("\n");
+
+	pr_cont("        ");
+	for_each_possible_cpu(cpu)
+		pr_cont("            CPU[%d]                   ", cpu);
+
+	if (emac_vp)
+		pr_cont("EMAC[%d]  ", emac_vp->vport);
+
+	pr_cont("\n");
+
+	pr_cont("vq:     ");
+
+	for_each_possible_cpu(cpu)
+		pr_cont("frame  swq   hwq   anode   bnode     ");
+
+	if (emac_vp)
+		pr_cont("  hwq    ");
+
+	pr_cont("\n");
+
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		pr_cont("%-2d:       ", vq);
+		for_each_possible_cpu(cpu) {
+
+			vp = dev_priv->cpu_vp[cpu];
+			if (!vp)
+				continue;
+
+			vq_priv = vp->tx_vqs[vq];
+			if (!vq_priv || !vq_priv->swq)
+				break;
+
+			/* Get parent Anode for HWQ */
+			if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode)) {
+				pr_err("%s: can't get bnode for anode %d\n", __func__, anode);
+				anode = -1;
+			} else if (mv_tm_scheme_parent_node_get(TM_A_LEVEL, anode, &bnode)) {
+				pr_err("%s: can't get bnode for anode %d\n", __func__, anode);
+				bnode = -1;
+			}
+			pr_cont("%d    %2d    %3d    %3d    %3d         ",
+				vq_priv->swq->frame_num, vq_priv->swq->swq, vq_priv->hwq,
+				anode, bnode);
+		}
+		if (emac_vp) {
+			vq_priv = emac_vp->tx_vqs[vq];
+			if (vq_priv)
+				pr_cont("%3d      ", vq_priv->hwq);
+		}
+		pr_cont("\n");
+	}
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+/*TODO: currently print only HWQ - improve this function */
+static void pp3_dbg_dev_emacs_resources_line_dump(struct pp3_vport *emac_vp)
+{
+	int i;
+
+	pr_info("\nemac%d:  TX%-35s", emac_vp->vport, "");
+
+	if (!(emac_vp->port.emac.flags & BIT(MV_PP3_EMAC_F_INIT_BIT)))
+		/* emac not initialized */
+		return;
+
+	for (i = 0; i < emac_vp->tx_vqs_num; i++) {
+		if (!(emac_vp->tx_vqs[i]))
+			continue;
+
+		pr_cont("%-3d ", emac_vp->tx_vqs[i]->hwq);
+	}
+
+	pr_info("        RX%-35s", "");
+
+	for (i = 0; i < emac_vp->rx_vqs_num; i++) {
+		if (!(emac_vp->rx_vqs[i]))
+			continue;
+
+		pr_cont("%-3d ", emac_vp->rx_vqs[i]->hwq);
+
+	}
+}
+
+/*---------------------------------------------------------------------------
+pp3_dbg_dev_emacs_resources_dump
+	print display EMACs HW resources that PP3 driver uses for all purposes
+	inputs:
+---------------------------------------------------------------------------*/
+void pp3_dbg_dev_emacs_resources_dump(void)
+{
+	int i;
+
+	if (!pp3_vports) {
+		pr_info("System is not initialzied\n");
+		return;
+	}
+
+	for (i = 0; i < mv_pp3_ports_num_get(pp3_device); i++)
+		if ((pp3_vports[i]) && (pp3_vports[i]->type == MV_PP3_NSS_PORT_ETH))
+			pp3_dbg_dev_emacs_resources_line_dump(pp3_vports[i]);
+
+	pr_cont("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------
+pp3_dbg_dev_channel_resources_dump
+	print out Sw and HW resources used by channels
+	inputs:
+---------------------------------------------------------------------------*/
+static void pp3_dbg_dev_channel_resources_dump(void)
+{
+	struct mv_pp3_channel *chan_ctrl;
+	int i, j, chan_num;
+	int node, cpu;
+	char cpu_str[20], tmp[3];
+
+	chan_num = mv_pp3_chan_num_get();
+
+	for (i = 0; i < chan_num; i++) {
+		chan_ctrl = mv_pp3_chan_get(i);
+
+		mv_pp3_cfg_hmac_tx_anode_get(chan_ctrl->hmac_hw_txq, &node);
+		pr_info("\nchan%d:  TX   ", i);
+		pr_cont("%-4s %-5s %-6d %-6s %-6d %-32d %-28d %2d (ppc0)   %-4s", "NA", "NA", chan_ctrl->frame, "NA",
+				chan_ctrl->hmac_sw_txq, chan_ctrl->hmac_hw_txq, node,
+				mv_pp3_cfg_hmac_pnode_get(PP3_PPC0_DP), "NA");
+		pr_info("%-8s", "");
+
+		j = 0;
+		cpu_str[0] = '\0';
+		for_each_possible_cpu(cpu) {
+			if ((chan_ctrl->cpu_mask >> cpu) & 1) {
+				sprintf(tmp, " %d", cpu);
+				strcat(cpu_str, tmp);
+				if (j++)
+					strcat(cpu_str, ",");
+			}
+		}
+
+		mv_pp3_cfg_hmac_rx_anode_get(chan_ctrl->hmac_hw_rxq, &node);
+		pr_cont("RX   %-4s %-5d %-6d %-6d %-6d %-32d %-28d %2d (hmac)   %-4s\n", cpu_str, chan_ctrl->irq_num,
+				chan_ctrl->frame, chan_ctrl->event_group, chan_ctrl->hmac_sw_rxq,
+				chan_ctrl->hmac_hw_rxq, node, mv_pp3_cfg_hmac_pnode_get(PP3_HMAC_RX), "NA");
+	}
+}
+
+/*---------------------------------------------------------------------------
+pp3_dbg_dev_bm_resources_dump
+	print out Sw and HW resources used by channels
+	inputs:
+---------------------------------------------------------------------------*/
+static void pp3_dbg_dev_bm_resources_dump(void)
+{
+	struct pp3_cpu *cpu_ctrl;
+	int cpu;
+
+	pr_info("\nbm_put: TX   ");
+	for_each_possible_cpu(cpu) {
+
+		cpu_ctrl = pp3_cpus[cpu];
+		pr_cont("%-4d %-5s %-6d %-6s %-6d", cpu, "NA", cpu_ctrl->bm_frame, "NA", cpu_ctrl->bm_swq);
+		pr_info("%-13s", "");
+	}
+	pr_info("\nbm_get: RX   ");
+	for_each_possible_cpu(cpu) {
+		struct pp3_cpu *cpu_ctrl;
+
+		cpu_ctrl = pp3_cpus[cpu];
+		pr_cont("%-4d %-5s %-6d %-6s %-6d", cpu, "NA", cpu_ctrl->bm_frame, "NA", cpu_ctrl->bm_swq);
+		pr_info("%-13s", "");
+	}
+	pr_cont("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+static void pp3_dbg_dev_rx_resources_line_dump(struct pp3_dev_priv *dev_priv)
+{
+	int cpu, q, node;
+	struct pp3_vport *cpu_vp;
+	char queues[64];
+	char anodes[64];
+	char tmp[16];
+
+	pr_info("\n        RX   ");
+	for_each_possible_cpu(cpu) {
+		memset(queues, 0, sizeof(queues));
+		memset(anodes, 0, sizeof(anodes));
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || !cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		pr_cont("%-4d %-5d %-6d", cpu, cpu_vp->port.cpu.irq_num, cpu_vp->rx_vqs[0]->swq->frame_num);
+		pr_cont(" %-6d", cpu_vp->rx_vqs[0]->swq->queue.rx.irq_group);
+
+		pr_cont("%2d:%-2d ", cpu_vp->rx_vqs[0]->swq->swq, cpu_vp->rx_vqs[cpu_vp->rx_vqs_num-1]->swq->swq);
+
+		pr_cont("%-2s", "");
+		for (q = 0; (q < cpu_vp->rx_vqs_num) && (q < 8); q++) {
+			sprintf(tmp, "%d ", cpu_vp->rx_vqs[q]->hwq);
+
+			strcat(queues, tmp);
+			mv_pp3_cfg_hmac_rx_anode_get(cpu_vp->rx_vqs[q]->hwq, &node);
+			sprintf(tmp, "%d ", node);
+			strcat(anodes, tmp);
+		}
+		pr_cont("%-32s %-28s ", queues, anodes);
+
+		/* TODO print pools per interface and not per group */
+		pr_cont("%2d (hmac)   %-2d (L) %-2d (S)", mv_pp3_cfg_hmac_pnode_get(PP3_HMAC_RX),
+			dev_priv->cpu_shared->long_pool ? dev_priv->cpu_shared->long_pool->pool : -1,
+			dev_priv->cpu_shared->short_pool ? dev_priv->cpu_shared->short_pool->pool : -1);
+
+		if (cpu_vp->rx_vqs_num > 8) {
+			memset(queues, 0, sizeof(queues));
+			memset(anodes, 0, sizeof(anodes));
+
+			pr_info("%-45s", "");
+			for (q = 8; (q < cpu_vp->rx_vqs_num); q++) {
+				sprintf(tmp, "%d ", cpu_vp->rx_vqs[q]->hwq);
+
+				strcat(queues, tmp);
+				mv_pp3_cfg_hmac_rx_anode_get(cpu_vp->rx_vqs[q]->hwq + q, &node);
+				sprintf(tmp, "%d ", node);
+				strcat(anodes, tmp);
+			}
+			pr_cont("%-32s %-28s ", queues, anodes);
+		}
+		pr_info("%-13s", "");
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+static void pp3_dbg_dev_tx_resources_line_dump(struct pp3_dev_priv *dev_priv)
+{
+	int cpu, q, node;
+	struct pp3_vport *cpu_vp;
+	struct pp3_pool *ppool;
+	char queues[64];
+	char anodes[64];
+	char tmp[16];
+
+	pr_info("\n%-5s:  TX   ", dev_priv->dev->name);
+	for_each_possible_cpu(cpu) {
+		memset(queues, 0, sizeof(queues));
+		memset(anodes, 0, sizeof(anodes));
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		pr_cont("%-4d %-5s %-6d %-6s", cpu, "NA", cpu_vp->tx_vqs[0]->swq->frame_num, "NA");
+
+		pr_cont("%2d:%-2d ", cpu_vp->tx_vqs[0]->swq->swq, cpu_vp->tx_vqs[cpu_vp->tx_vqs_num-1]->swq->swq);
+
+		pr_cont("%-2s", "");
+
+		for (q = 0; (q < cpu_vp->tx_vqs_num) && (q < 8); q++) {
+			sprintf(tmp, "%d ", cpu_vp->tx_vqs[q]->hwq);
+			strcat(queues, tmp);
+			mv_pp3_cfg_hmac_tx_anode_get(cpu_vp->tx_vqs[q]->hwq, &node);
+			sprintf(tmp, "%d ", node);
+			strcat(anodes, tmp);
+		}
+		pr_cont("%-32s %-28s ", queues, anodes);
+
+		ppool = dev_priv->cpu_shared->txdone_pool;
+
+		pr_cont("%2d (ppc0)   %-2d (txdone)",
+			mv_pp3_cfg_hmac_pnode_get(PP3_PPC0_DP),
+			ppool ? ppool->pool : -1);
+
+		if (cpu_vp->tx_vqs_num > 8) {
+			memset(queues, 0, sizeof(queues));
+			memset(anodes, 0, sizeof(anodes));
+
+			pr_info("%-45s", "");
+			for (q = 8; (q < cpu_vp->tx_vqs_num); q++) {
+				sprintf(tmp, "%d ", cpu_vp->tx_vqs[q]->hwq);
+				strcat(queues, tmp);
+				mv_pp3_cfg_hmac_tx_anode_get(cpu_vp->tx_vqs[q]->hwq, &node);
+				sprintf(tmp, "%d ", node);
+				strcat(anodes, tmp);
+			}
+			pr_cont("%-32s %-28s ", queues, anodes);
+		}
+		pr_info("%-13s", "");
+	}
+}
+
+/*---------------------------------------------------------------------------
+pp3_dbg_dev_resources_dump
+	print display HW resources that PP3 driver uses for all purposes
+	inputs:
+---------------------------------------------------------------------------*/
+void pp3_dbg_dev_resources_dump(void)
+{
+	int i;
+	struct pp3_dev_priv *dev_priv;
+
+	if (!mv_pp3_shared_initialized(pp3_device)) {
+		pr_info("System is not initialzied\n");
+		return;
+	}
+
+	pr_info("\n------Linux----------");
+	pr_cont("   ------HMAC--------");
+	pr_cont("   -------------------QM--------------------------------------------------");
+	pr_cont("   -----BM------");
+	pr_info("\nName    Dir  CPU  IRQ");
+	pr_cont("   Frame  ISR   SWQs");
+	pr_cont("    HWQs                             A node                        P node ");
+	pr_cont("    BM Pool");
+	for (i = 0; i < mv_pp3_dev_num_get(); i++) {
+		dev_priv = mv_pp3_dev_priv_get(i);
+
+		if (!dev_priv || !(dev_priv->flags & MV_PP3_F_INIT))
+			continue;
+
+		pp3_dbg_dev_tx_resources_line_dump(dev_priv);
+		pp3_dbg_dev_rx_resources_line_dump(dev_priv);
+	}
+	pr_info("\n");
+	pr_info("-----------------------------------------------------------------------------------------------");
+	pr_cont("-------------------------------------\n");
+	pp3_dbg_dev_channel_resources_dump();
+	pr_info("-----------------------------------------------------------------------------------------------");
+	pr_cont("-------------------------------------\n");
+	pp3_dbg_dev_emacs_resources_dump();
+	pr_info("-----------------------------------------------------------------------------------------------");
+	pr_cont("-------------------------------------\n");
+	pp3_dbg_dev_bm_resources_dump();
+}
+
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+void pp3_dbg_dev_mac_mc_print(struct net_device *dev)
+{
+	struct list_head *mc_addr;
+	struct mac_mc_info *mc_addr_node;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int i = 0;
+
+	pr_info("Port %d MAC Multicast Addresses:", dev_priv->vport->vport);
+	list_for_each(mc_addr, &dev_priv->mac_list) {
+		mc_addr_node = (struct mac_mc_info *)mc_addr;
+		pr_info("#%d\t%02x:%02x:%02x:%02x:%02x:%02x", i++,
+			mc_addr_node->mac[0], mc_addr_node->mac[1], mc_addr_node->mac[2],
+			mc_addr_node->mac[3], mc_addr_node->mac[4], mc_addr_node->mac[5]);
+	}
+	pr_info("\n");
+}
+
+/*---------------------------------------------------------------------------*/
+/* Calculate SUM of RXQs and TXQs counters in the group and update group statistics */
+static void pp3_dbg_dev_nic_cnt_update_all(struct pp3_dev_priv *dev_priv)
+{
+	int q, cpu;
+	struct pp3_vport *cpu_vp;
+	struct pp3_swq *rx_swq;
+	struct pp3_swq *tx_swq;
+
+	/* Update calculated counters by sum of the counter for all queues */
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		/* Clear RX calculated statistics before update */
+		cpu_vp->port.cpu.stats.rx_pkt_calc = 0;
+		cpu_vp->port.cpu.stats.rx_drop_calc = 0;
+		cpu_vp->port.cpu.stats.rx_cfh_dummy_calc = 0;
+		cpu_vp->port.cpu.stats.rx_cfh_invalid_calc = 0;
+		cpu_vp->port.cpu.stats.rx_cfh_reassembly_calc = 0;
+
+		for (q = 0; q < MV_PP3_VQ_NUM; q++) {
+			if (cpu_vp->rx_vqs[q]) {
+				rx_swq = cpu_vp->rx_vqs[q]->swq;
+				cpu_vp->port.cpu.stats.rx_pkt_calc += rx_swq->stats.pkts;
+				cpu_vp->port.cpu.stats.rx_drop_calc += rx_swq->stats.pkts_drop;
+				/*cpu_vp->port.cpu.stats.rx_cfh_dummy_calc += rx_swq->stats.rx_cfh_dummy;
+				cpu_vp->port.cpu.stats.rx_cfh_invalid_calc += rx_swq->stats.rx_cfh_invalid;
+				cpu_vp->port.cpu.stats.rx_cfh_reassembly_calc += rx_swq->stats.rx_cfh_reassembly;*/
+			}
+		}
+		/* Clear TX calculated statistics before update */
+		cpu_vp->port.cpu.stats.tx_pkt_calc = 0;
+		cpu_vp->port.cpu.stats.tx_drop_calc = 0;
+		cpu_vp->port.cpu.stats.tx_no_resource_calc = 0;
+		for (q = 0; q < MV_PP3_VQ_NUM; q++) {
+			if (cpu_vp->tx_vqs[q]) {
+				tx_swq = cpu_vp->tx_vqs[q]->swq;
+				cpu_vp->port.cpu.stats.tx_pkt_calc += tx_swq->stats.pkts;
+				cpu_vp->port.cpu.stats.tx_drop_calc += tx_swq->stats.pkts_drop;
+				cpu_vp->port.cpu.stats.tx_no_resource_calc += tx_swq->stats.pkts_errors;
+			}
+		}
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear Host software collected statistics of network interface */
+static void pp3_dbg_dev_nic_stats_clear(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp)
+			memset(&cpu_vp->port.cpu.stats, 0, sizeof(struct pp3_cpu_vp_stats));
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print Host software collected statistics of network interface */
+static void pp3_dbg_dev_nic_stats_dump(struct pp3_dev_priv *dev_priv)
+{
+	char name[100];
+
+	sprintf(name, "\n%s stats:", dev_priv->dev->name);
+	pr_cont("\n%-24s", name);
+
+	mv_pp3_cpu_vport_cnt_dump(dev_priv->cpu_vp, CONFIG_NR_CPUS);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Calculate SUM of single counter from TXQ statistics for all TXQs in virtual port */
+static int pp3_dbg_sum_txqs_cnt_get(struct pp3_vport *vp, int cnt_index)
+{
+	int q, sum = 0;
+	unsigned int *stats;
+
+	for (q = 0; q < MV_PP3_VQ_NUM; q++)
+		if (vp->tx_vqs[q]) {
+			stats = (unsigned int *)&vp->tx_vqs[q]->swq->stats;
+			sum += stats[cnt_index];
+		}
+
+	return sum;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear statistics for all TXQs belong the virtual port */
+void pp3_dbg_vport_txqs_stats_clear(struct pp3_vport *vp)
+{
+	int q;
+
+	for (q = 0; q < MV_PP3_VQ_NUM; q++)
+		if ((vp->type == MV_PP3_NSS_PORT_CPU) && (vp->tx_vqs[q])) {
+			memset(&vp->tx_vqs[q]->swq->stats, 0, sizeof(struct pp3_swq_stats));
+			pp3_fw_clear_stat_set(MV_PP3_FW_SWQ_STAT, vp->tx_vqs[q]->swq->swq);
+			pp3_fw_clear_stat_set(MV_PP3_FW_HWQ_STAT, vp->tx_vqs[q]->hwq);
+		}
+}
+
+/* Clear statistics for all TXQs belong the network interface */
+void pp3_dbg_txqs_stats_clear(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+
+	/* clear emac txqs stats */
+	if (dev_priv->vport)
+		pp3_dbg_vport_txqs_stats_clear(dev_priv->vport);
+
+	/* clear cpu txqs stats */
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		pp3_dbg_vport_txqs_stats_clear(cpu_vp);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear statistics for all TXQs belong the virtual port */
+void pp3_dbg_vport_rxqs_stats_clear(struct pp3_vport *vp)
+{
+	int q;
+
+	for (q = 0; q < MV_PP3_VQ_NUM; q++)
+		if ((vp->type == MV_PP3_NSS_PORT_CPU) && (vp->rx_vqs[q])) {
+			memset(&vp->rx_vqs[q]->swq->stats, 0, sizeof(struct pp3_swq_stats));
+			pp3_fw_clear_stat_set(MV_PP3_FW_SWQ_STAT, vp->rx_vqs[q]->swq->swq);
+			pp3_fw_clear_stat_set(MV_PP3_FW_HWQ_STAT, vp->rx_vqs[q]->hwq);
+			vp->rx_vqs[q]->swq->stats_reset_flag = true;
+		}
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear statistics for all RXQs belong the network interface */
+void pp3_dbg_rxqs_stats_clear(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+
+	/* clear emac rxqs stats */
+	if (dev_priv->vport)
+		pp3_dbg_vport_rxqs_stats_clear(dev_priv->vport);
+
+	/* clear cpu txqs stats */
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		pp3_dbg_vport_rxqs_stats_clear(cpu_vp);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print statistics for all RX and TX VQs belong the network interface */
+void pp3_dbg_dev_vqs_stats_dump(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+
+	pr_info("%s: queues stats\n", dev_priv->dev->name);
+	mv_pp3_vqueue_cnt_dump_header(MV_MAX(dev_priv->rxqs_per_cpu, dev_priv->txqs_per_cpu));
+
+	/* print cpu rxqs stats */
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus)) {
+			mv_pp3_vqueue_cnt_dump("rx_", cpu_vp->port.cpu.cpu_num,
+					cpu_vp->rx_vqs, cpu_vp->rx_vqs_num, true);
+		}
+	}
+	/* print cpu txqs stats */
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		/* print txqs stats */
+		mv_pp3_vqueue_cnt_dump("tx_", cpu_vp->port.cpu.cpu_num, cpu_vp->tx_vqs, cpu_vp->tx_vqs_num, true);
+	}
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+/* Dump single counter for number of BM pools.
+   if cpus_num = 0 - only sum of all CPUs numer will be printed
+*/
+static void pp3_dbg_pools_stats_dump(struct pp3_pool *pools[], int num, u32 cpus_num,
+					int cnt_index, const char *name)
+{
+	u32 total;
+	u32 *stats;
+	struct pp3_pool *ppool;
+	int pool, cpu;
+
+	/* Each line contains 3 colomns per pool: CPU0, CPU1 and SUM */
+	pr_cont("%-24s", name);
+	for (pool = 0; pool < num; pool++) {
+		total = 0;
+		ppool = pools[pool];
+		if (!ppool)
+			continue;
+
+		for_each_possible_cpu(cpu) {
+			if (cpu >= cpus_num)
+				break;
+
+			if (cnt_index == -1) {
+				pr_cont("%-15u", cpu);
+				continue;
+			}
+			stats = (u32 *)PPOOL_STATS(ppool, cpu);
+			pr_cont("%-15u", stats[cnt_index]);
+
+			total += stats[cnt_index];
+		}
+		if (cnt_index == -1)
+			pr_cont("%-15s", "SUM");
+		else
+			pr_cont("%-15u", total);
+	}
+	pr_cont("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear statistics for all BM pools belong network interface */
+static void pp3_dbg_dev_pool_stats_clear(struct pp3_dev_priv *dev_priv)
+{
+	if (!dev_priv->cpu_shared)
+		return;
+
+	/* Clear short pool statistics */
+	if (dev_priv->cpu_shared->short_pool)
+		pp3_dbg_pool_stats_clear(dev_priv->cpu_shared->short_pool->pool);
+
+	/* Clear long pool statistics */
+	if (dev_priv->cpu_shared->long_pool)
+		pp3_dbg_pool_stats_clear(dev_priv->cpu_shared->long_pool->pool);
+
+	/* Clear LRO pool statistics */
+	if (dev_priv->cpu_shared->lro_pool)
+		pp3_dbg_pool_stats_clear(dev_priv->cpu_shared->lro_pool->pool);
+
+	/* Clear TX Done pools statistics for all CPUs */
+	pp3_dbg_pool_stats_clear(dev_priv->cpu_shared->txdone_pool->pool);
+}
+/*---------------------------------------------------------------------------*/
+
+static void pp3_dbg_dev_lnx_pools_stats_dump(struct pp3_dev_priv *dev_priv)
+{
+	char name[15];
+	struct pp3_pool *pools[CONFIG_NR_CPUS];
+	int cpu, num = 0;
+	int cpu_num = 0;
+
+	pools[num] = dev_priv->cpu_shared->txdone_pool;
+
+	pr_cont("\n%-24s", "Linux pools stats:");
+	for_each_possible_cpu(cpu) {
+		sprintf(name, "cpu%d-[%d]", cpu, pools[num] ? pools[num]->pool : -1);
+		pr_cont("%-15s", name);
+		cpu_num++;
+	}
+	pr_cont("%-15s\n", "SUM");
+	pp3_dbg_separate_line_print(24 + 15 * (cpu_num + 1));
+
+	num++;
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_get_timeout_err);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_get_request);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_get);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_get_zero);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_get_dummy);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_free);
+#ifdef CONFIG_MV_PP3_TSO
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpu_num, buff_free_tso);
+#endif
+}
+/*---------------------------------------------------------------------------*/
+
+static void pp3_dbg_dev_rx_pools_stats_dump(struct pp3_dev_priv *dev_priv)
+{
+	char name[15];
+	struct pp3_pool *pools[2];
+	int i, num = 0;
+	u32 cpus_num;
+
+	pr_cont("\n%-24s", "RX pools stats:");
+	pools[num] = dev_priv->cpu_shared->long_pool;
+	sprintf(name, "Long-[%d]", pools[num] ? pools[num]->pool : -1);
+	pr_cont("%-45s", name);
+	num++;
+
+	if (dev_priv->cpu_shared->short_pool) {
+		pools[num] = dev_priv->cpu_shared->short_pool;
+		sprintf(name, "Short-[%d]", pools[num] ? pools[num]->pool : -1);
+		pr_cont("%-45s", name);
+		num++;
+	}
+	pr_cont("\n");
+	pp3_dbg_separate_line_print(24 + (45 * num));
+
+	pr_cont("%-24s", "buff_num");
+	for (i = 0; i < num; i++)
+		pr_cont("%-45u", pools[i]->buf_num);
+
+	pr_cont("\n");
+	pr_cont("%-24s", "buff_in_use");
+	for (i = 0; i < num; i++)
+		pr_cont("%-45u", atomic_read(&pools[i]->in_use));
+
+	pr_info("\n");
+
+	cpus_num = num_possible_cpus();
+	pp3_dbg_pools_stats_dump(pools, num, cpus_num, -1, "CPUs");
+	pp3_dbg_separate_line_print(24 + (45 * num));
+
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_rx);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_put);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_alloc);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_alloc_err);
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_recycled_ok);
+	PP3_DBG_POOLS_STATS_DUMP(pools, num, cpus_num, buff_recycled_err);
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear global statistics for all CPUs */
+void pp3_dbg_cpu_stats_clear(void)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu)
+		memset(&pp3_cpus[cpu]->stats, 0, sizeof(struct pp3_cpu_stats));
+
+}
+
+/*---------------------------------------------------------------------------*/
+/* Clear timers statistics relevant for network device */
+static void pp3_dbg_dev_timers_stats_clear(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		memset(&cpu_vp->port.cpu.txdone_timer.stats, 0, sizeof(struct pp3_timer_stats));
+	}
+}
+/*---------------------------------------------------------------------------*/
+/* Print timers statistics relevant for network device */
+static void pp3_dbg_dev_timers_stats_dump(struct net_device *dev)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	/* print CPU statistics */
+	pr_cont("\n%-24s", "timers stats:");
+
+	for_each_possible_cpu(cpu)
+		pr_cont("CPU%-10d", cpu);
+
+	pr_info("-------------------------------------------------------------\n");
+
+	pr_cont("%-24s", "timer_add");
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp)
+			pr_cont("%-13u", cpu_vp->port.cpu.txdone_timer.stats.timer_add);
+	}
+
+	pr_cont("\n%-24s", "timer_sched");
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp)
+			pr_cont("%-13u", cpu_vp->port.cpu.txdone_timer.stats.timer_sched);
+	}
+
+
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print Firmware statistics relevant for network device */
+void pp3_dbg_dev_fw_stats_dump(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	pr_info("%s: Firmware stats\n", dev_priv->dev->name);
+	if (dev_priv->vport)
+		mv_pp3_vport_fw_stats_dump(dev_priv->vport->vport);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Clear all Host software collected statistics relevant for network interface */
+void pp3_dbg_dev_stats_clear(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (dev_priv->vport)
+		mv_pp3_vport_fw_stats_clear(dev_priv->vport->vport);
+
+	/* Clear global statistics */
+	pp3_dbg_cpu_stats_clear();
+
+	/* Clear tx done timer statistics */
+	pp3_dbg_dev_timers_stats_clear(dev_priv);
+
+	/* Clear BM pool statistics */
+	pp3_dbg_dev_pool_stats_clear(dev_priv);
+
+	/* Clear RXQs and TXQs statistics */
+	pp3_dbg_txqs_stats_clear(dev_priv);
+	pp3_dbg_rxqs_stats_clear(dev_priv);
+
+	/* Clear Group statistics */
+	pp3_dbg_dev_nic_stats_clear(dev_priv);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print all Host software collected statistics relevant for network interface */
+void pp3_dbg_dev_pools_stats_dump(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	/* print BM pool statistics */
+	pp3_dbg_dev_rx_pools_stats_dump(dev_priv);
+	pp3_dbg_dev_lnx_pools_stats_dump(dev_priv);
+}
+
+/* Print all Host software collected statistics relevant for network interface */
+void pp3_dbg_dev_stats_dump(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	/*Print timers statistics */
+	pp3_dbg_dev_timers_stats_dump(dev);
+
+	/* aggregation of rxqs and txqs counters */
+	pp3_dbg_dev_nic_cnt_update_all(dev_priv);
+
+	pr_cont("\n");
+
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("Error: Can't show statistics, %s in not initialized\n", dev->name);
+		return;
+	}
+	/* print BM pool statistics */
+	pp3_dbg_dev_rx_pools_stats_dump(dev_priv);
+	pp3_dbg_dev_lnx_pools_stats_dump(dev_priv);
+
+	/* NIC statistics */
+	pp3_dbg_dev_nic_stats_dump(dev_priv);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print all Host software queues collected statistics relevant for network interface */
+void pp3_dbg_dev_queues_stats_dump(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	pr_cont("\n");
+
+	pp3_dbg_dev_vqs_stats_dump(dev_priv);
+
+	pr_cont("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_dev_status_print(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int cpu;
+	char cpus_str[16];
+
+	scnprintf(cpus_str, sizeof(cpus_str), "%*pb", cpumask_pr_args(&dev_priv->rx_cpus));
+
+	pr_info("\n");
+	pr_info("Interface %s:\n", dev->name);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	pr_info("Flags                       : 0x%x\n", dev_priv->flags);
+	pr_info("GNSS ops                    : %p\n", dev_priv->cpu_shared->gnss_ops);
+#endif
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+	pr_info("SKB recycle                 : %s\n",  mv_pp3_is_nic_skb_recycle() ? "Enable" : "Disable");
+#endif
+
+	pr_info("RX packet mode              : %s\n", mv_pp3_pkt_mode_str(dev_priv->cpu_shared->rx_pkt_mode));
+	pr_info("RX CPUs mask                : 0x%s\n", cpus_str);
+	pr_info("RX default CPU              : %d\n", MV_PP3_CPU_VPORT_TO_CPU(dev_priv->vport->dest_vp));
+	pr_info("RXQ maximum capacity [pkts] : %d\n", dev_priv->rxq_capacity);
+	pr_info("TXQ maximum capacity [pkts] : %d\n", dev_priv->txq_capacity);
+	pr_info("RX coalescing [pkts]        : %d\n", dev_priv->rx_pkt_coal);
+	pr_info("RX time coalescing [usec]   : %d\n", dev_priv->rx_time_coal);
+
+	pr_info("Long pool                   : %d\n",
+		dev_priv->cpu_shared->long_pool ? dev_priv->cpu_shared->long_pool->pool : -1);
+
+	pr_info("Short pool                  : %d\n",
+		dev_priv->cpu_shared->short_pool ? dev_priv->cpu_shared->short_pool->pool : -1);
+
+	if (dev_priv->cpu_shared->lro_pool)
+		pr_info("LRO pool                    : %d\n", dev_priv->cpu_shared->lro_pool->pool);
+
+	pr_info("Internal CPU vports         : ");
+	for_each_possible_cpu(cpu) {
+		if (dev_priv->cpu_vp[cpu])
+			pr_cont("%d   ", dev_priv->cpu_vp[cpu]->vport);
+	}
+	pr_info("Number of ingress VQs       : ");
+	for_each_possible_cpu(cpu) {
+		if (dev_priv->cpu_vp[cpu])
+			pr_cont("%d   ", dev_priv->cpu_vp[cpu]->rx_vqs_num);
+	}
+	pr_info("Number of egress VQs        : ");
+	for_each_possible_cpu(cpu) {
+		if (dev_priv->cpu_vp[cpu])
+			pr_cont("%d   ", dev_priv->cpu_vp[cpu]->tx_vqs_num);
+	}
+
+	if (dev_priv->vport->type == MV_PP3_NSS_PORT_ETH)
+		pr_info("EMAC vport                  : %d\n", dev_priv->vport->vport);
+	else if (dev_priv->vport->type == MV_PP3_NSS_PORT_EXT)
+		pr_info("External vport              : %d\n", dev_priv->vport->vport);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_dev_pools_status_print(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv || !(dev_priv->flags & MV_PP3_F_INIT)) {
+		pr_err("%s in not initialized yet\n", dev->name);
+		return;
+	}
+
+	if (dev_priv->cpu_shared->long_pool)
+		pp3_dbg_pool_status_print(dev_priv->cpu_shared->long_pool->pool);
+
+	if (dev_priv->cpu_shared->short_pool)
+		pp3_dbg_pool_status_print(dev_priv->cpu_shared->short_pool->pool);
+
+	if (dev_priv->cpu_shared->lro_pool)
+		pp3_dbg_pool_status_print(dev_priv->cpu_shared->lro_pool->pool);
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_dev_flags(struct net_device *dev, u32 flag, u32 en)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	u32 bit_flag;
+
+	bit_flag = (fls(flag) - 1);
+
+	if (en)
+		dev_priv->flags |= (1 << bit_flag);
+	else
+		dev_priv->flags &= ~(1 << bit_flag);
+
+	return;
+}
+
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_cpu_flags(int cpu, u32 flag, u32 en)
+{
+	u32 bit_flag;
+
+	bit_flag = (fls(flag) - 1);
+
+	if (en)
+		pp3_cpus[cpu]->flags |= (1 << bit_flag);
+	else
+		pp3_cpus[cpu]->flags &= ~(1 << bit_flag);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_dev_mac_show(struct net_device *dev)
+{
+	struct netdev_hw_addr *ha;
+	int i;
+	char prefix[16], suffix[32];
+
+	pr_info("%s: MAC addresses\n", dev->name);
+	mv_mac_addr_print("device_addr   : ", dev->dev_addr, NULL);
+	mv_mac_addr_print("permanent_addr: ", dev->perm_addr, NULL);
+
+	i = 0;
+	pr_info("\nunicast list: dev->uc\n");
+	netdev_for_each_uc_addr(ha, dev) {
+		sprintf(prefix, "%2d: ", i++);
+		sprintf(suffix, " - ref = %d, global = %s",
+			ha->refcount, ha->global_use ? "true" : "false");
+		mv_mac_addr_print(prefix, ha->addr, suffix);
+	}
+	i = 0;
+	pr_info("\nmulticast list: dev->mc\n");
+	netdev_for_each_mc_addr(ha, dev) {
+		sprintf(prefix, "%2d: ", i++);
+		sprintf(suffix, " - ref = %d, global = %s",
+			ha->refcount, ha->global_use ? "true" : "false");
+		mv_mac_addr_print(prefix, ha->addr, suffix);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_skb_dump(struct sk_buff *skb)
+{
+	pr_info("skb=%p: head=%p, data=%p, tail=%p, end=%p, ksize(head)=%d\n",
+			skb, skb->head, skb->data, skb->tail, skb->end, ksize(skb->head));
+	pr_info("\t mac=%p, network=%p, transport=%p, headroom=%d, end_offs=%d\n",
+			skb_mac_header(skb), skb_network_header(skb), skb_transport_header(skb),
+			skb_headroom(skb), skb_end_offset(skb));
+	pr_info("\t truesize=%d, len=%d, data_len=%d, mac_len=%d\n",
+			skb->truesize, skb->len, skb->data_len, skb->mac_len);
+	pr_info("\t users=%d, dataref=%d, nr_frags=%d, gso_size=%d, gso_segs=%d\n",
+			atomic_read(&skb->users), atomic_read(&skb_shinfo(skb)->dataref),
+			skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size, skb_shinfo(skb)->gso_segs);
+	pr_info("\t proto=%d, ip_summed=%d, priority=%d cloned=%d\n\n",
+			ntohs(skb->protocol), skb->ip_summed, skb->priority, skb->cloned);
+}
+/*---------------------------------------------------------------------------*/
+
+char *pp3_dbg_l3_info_str(unsigned int l3_info)
+{
+	switch (l3_info) {
+
+	case L3_RX_IP4:
+		return "ipv4";
+	case L3_RX_IP4_FRAG:
+		return "ipv4 frag";
+	case L3_RX_IP4_OPT:
+		return "ipv4 opt";
+	case L3_RX_IP4_ERR:
+		return "ipv4 error";
+	case L3_RX_IP6:
+		return "ipv6";
+	case L3_RX_IP6_EXT:
+		return "ipv6 ext";
+	case L3_RX_ARP:
+		return "arp";
+	default:
+		return "Unknown";
+	}
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+char *pp3_dbg_l4_info_str(unsigned int l4_info)
+{
+	switch (l4_info) {
+
+	case L4_RX_TCP:
+		return "tcp";
+	case L4_RX_TCP_CS_ERR:
+		return "tcp(csum=BAD)";
+	case L4_RX_UDP:
+		return "udp";
+	case L4_RX_UDP_LITE:
+		return "udp lite";
+	case L4_RX_UDP_CS_ERR:
+		return "udp(csum=BAD)";
+	case L4_RX_IGMP:
+		return "igmp";
+	default:
+		return "Unknown";
+	}
+
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+char *pp3_dbg_l2_info_str(unsigned int l2_info)
+{
+	switch (l2_info) {
+
+	case L2_UCAST:
+		return "ucast";
+	case L2_MCAST:
+		return "mcast";
+	case L2_IP_MCAST:
+		return "ip_mcast";
+	case L2_BCAST:
+		return "bcast";
+
+	default:
+		return "Unknown";
+	}
+
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+char *pp3_dbg_vlan_info_str(unsigned int vlan_info)
+{
+	switch (vlan_info) {
+
+	case VLAN_UNTAGGED:
+		return "untagged";
+	case VLAN_SINGLE:
+		return "single";
+	case VLAN_DOUBLE:
+		return "double";
+	default:
+		return "Unknown";
+	}
+
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+void pp3_dbg_cfh_hdr_dump(struct mv_cfh_common *cfh)
+{
+	if (!cfh)
+		return;
+
+	pr_info("cfh_hdr:\n");
+	pr_info("%p:  0x%8.8X 0x%8.8X 0x%8.8X 0x%8.8X 0x%8.8X 0x%8.8X 0x%8.8X 0x%8.8X\n",
+		cfh, cfh->plen_order, cfh->ctrl, cfh->tag1, cfh->tag2,
+		cfh->phys_l, cfh->vm_bp, cfh->marker_l, cfh->l3_l4_info);
+}
+
+/*---------------------------------------------------------------------------*/
+void pp3_dbg_cfh_common_dump(struct mv_cfh_common *cfh)
+{
+	int data_size, cfh_len, pkt_len;
+
+	cfh_len = MV_CFH_LEN_GET(cfh->ctrl);
+	pkt_len = MV_CFH_PKT_LEN_GET(cfh->plen_order);
+
+	data_size = MV_MIN(cfh_len - MV_PP3_CFH_HDR_SIZE, pkt_len);
+
+	pp3_dbg_cfh_hdr_dump(cfh);
+
+	if (data_size > 0) {
+		u8 *tmp = (u8 *)(cfh+1);
+		pr_info("cfh data:");
+		mv_debug_mem_dump((void *)tmp, data_size, 1);
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+int pp3_dbg_cfh_rx_checker(struct pp3_dev_priv *dev_priv, u32 *ptr)
+{
+	int bpid, pkt_len, cfh_len, wr_offset, cpu, swq, q;
+	struct mv_cfh_common *cfh = (struct mv_cfh_common *) ptr;
+	struct pp3_vport *cpu_vp;
+	bool flag = false;
+
+	cfh_len = MV_CFH_LEN_GET(cfh->ctrl);
+	bpid = MV_CFH_BPID_GET(cfh->vm_bp);
+	pkt_len = MV_CFH_PKT_LEN_GET(cfh->plen_order);
+	wr_offset = MV_CFH_WR_GET(cfh->ctrl) * MV_CFH_WR_RES;
+
+	/* The following cases are supported:
+	*  1. cfh_len is 64 bytes, the whole packet is in DRAM buffer
+	*  2. cfh_len is always 128 bytes, packet header is in CFH.
+	*/
+	if ((cfh_len != (MV_PP3_CFH_HDR_SIZE + MV_PP3_CFH_MDATA_SIZE)) && (cfh_len != MV_PP3_CFH_MAX_SIZE)) {
+		pr_err("%s: invalid cfh_length %d\n", __func__, cfh_len);
+		goto err;
+	}
+
+	if ((pkt_len <= (cfh_len - MV_PP3_CFH_HDR_SIZE)) && (cfh->phys_l)) {
+		pr_err("%s: unneseccary BM buffer allocate by FW\n", __func__);
+		pr_err("%s: cfh_len = %d, pkt_len = %d phys_l = 0x%8x\n", __func__, cfh_len, pkt_len, cfh->phys_l);
+		goto err;
+	}
+
+	if ((pkt_len - MV_PP3_CFH_MDATA_SIZE) > MV_RX_PKT_SIZE(dev_priv->dev->mtu)) {
+		pr_err("%s: Invalid packet length %d, MTU = %d, max packet length = %d",
+				__func__, pkt_len, dev_priv->dev->mtu, MV_RX_PKT_SIZE(dev_priv->dev->mtu));
+		goto err;
+	}
+
+	if (cfh_len == MV_PP3_CFH_MAX_SIZE) {
+		pkt_len -= MV_PP3_CFH_MDATA_SIZE;
+		if (pkt_len >= MV_PP3_CFH_PAYLOAD_MAX_SIZE) {
+			pr_err("%s: Unexpected Split packet", __func__);
+			goto err;
+		}
+	}
+
+	cpu = smp_processor_id();
+	if (!dev_priv->cpu_vp[cpu])
+		goto err;
+
+	cpu_vp = dev_priv->cpu_vp[cpu];
+	/* validate SWQ number */
+	swq = MV_CFH_SWQ_GET(cfh->ctrl);
+
+	for (q = 0; q < cpu_vp->rx_vqs_num; q++) {
+		struct pp3_swq *rxq_ctrl = cpu_vp->rx_vqs[q]->swq;
+
+		if (rxq_ctrl && (swq == MV_PP3_HMAC_PHYS_SWQ_NUM(rxq_ctrl->swq, rxq_ctrl->frame_num))) {
+			flag = true;
+			break;
+		}
+	}
+	if (!flag) {
+		pr_err("%s: invalid swq number %d\n", __func__, swq);
+		goto err;
+	}
+
+	/* validate BM pool number and buffer pointers */
+	if (cfh->phys_l) {
+		struct sk_buff *skb = (struct sk_buff *)cfh->marker_l;
+
+		if (!skb) {
+			pr_err("%s: invalid marker_l\n", __func__);
+			goto err;
+		}
+
+		if ((dev_priv->cpu_shared->long_pool && (dev_priv->cpu_shared->long_pool->pool != bpid)) &&
+		   (dev_priv->cpu_shared->short_pool && (dev_priv->cpu_shared->short_pool->pool != bpid)) &&
+		   (dev_priv->cpu_shared->lro_pool && (dev_priv->cpu_shared->lro_pool->pool != bpid))) {
+			pr_err("%s: invalid bm pool %d\n", __func__, bpid);
+			goto err;
+		}
+
+		if (virt_to_phys(skb->head) != cfh->phys_l) {
+			pr_err("%s: incorrect BM pointers\n", __func__);
+			pr_err("%s: virt_l: skb=%p, head=%p (0x%x), phys_l: 0x%0x\n",
+				__func__, skb, skb->head, virt_to_phys(skb->head), cfh->phys_l);
+			goto err;
+		}
+	}
+	return 0;
+
+err:
+	pr_err("%s: Error - invalid CFH found\n", dev_priv->dev->name);
+	pp3_dbg_cfh_rx_dump(cfh);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+void pp3_dbg_cfh_rx_dump(struct mv_cfh_common *rx_cfh)
+{
+	pp3_dbg_cfh_common_dump(rx_cfh);
+
+	if (MV_CFH_PP_MODE_GET(rx_cfh->ctrl) == PP_RX_REASEM_PACKET) {
+		pr_info("Reassembly CFH, skip over 32 bytes");
+		rx_cfh++;
+	}
+
+	pr_info("cfh=0x%p, pp_mode = %d, pkt_len=%d, wr_offs=%d, sw_q=%d, cfh_len=%d, mdata = %d\n",
+			rx_cfh,
+			MV_CFH_PP_MODE_GET(rx_cfh->ctrl),
+			MV_CFH_PKT_LEN_GET(rx_cfh->plen_order),
+			MV_CFH_WR_GET(rx_cfh->ctrl),
+			MV_CFH_SWQ_GET(rx_cfh->ctrl),
+			MV_CFH_LEN_GET(rx_cfh->ctrl),
+			MV_CFH_MDATA_BIT_GET(rx_cfh->ctrl));
+
+	pr_info("phys_addr=0x%02x%08x, virt_add= 0x%02x%08x, pool_id=%d\n",
+			MV_CFH_PHYS_H_GET(rx_cfh->vm_bp), rx_cfh->phys_l,
+			MV_CFH_VIRT_H_GET(rx_cfh->l3_l4_info), rx_cfh->marker_l, MV_CFH_BPID_GET(rx_cfh->vm_bp));
+
+	pr_info("L2_info=%s, Vlan_info=%s, L3_offs=%d, L3_info=%s, IP_hlen=%d, L4_info=%s\n",
+		pp3_dbg_l2_info_str(MV_CFH_L2_INFO_GET(rx_cfh->l3_l4_info)),
+		pp3_dbg_vlan_info_str(MV_CFH_VLAN_INFO_GET(rx_cfh->l3_l4_info)),
+		MV_CFH_L3_OFFS_GET(rx_cfh->l3_l4_info),
+		pp3_dbg_l3_info_str(MV_CFH_L3_INFO_RX_GET(rx_cfh->l3_l4_info)),
+		MV_CFH_IPHDR_LEN_GET(rx_cfh->l3_l4_info),
+		pp3_dbg_l4_info_str(MV_CFH_L4_INFO_RX_GET(rx_cfh->l3_l4_info)));
+
+	pr_info("Mgmt=%d, Mac2Me=%d\n",
+			MV_CFH_MGMT_BIT_GET(rx_cfh->l3_l4_info),
+			MV_CFH_MACME_BIT_GET(rx_cfh->l3_l4_info));
+}
+/*---------------------------------------------------------------------------*/
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.h
new file mode 100644
index 0000000..d4a8e46
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_dbg.h
@@ -0,0 +1,65 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "platform/mv_pp3.h"
+
+void pp3_dbg_dev_resources_dump(void);
+void pp3_dbg_dev_txq_status_print(struct net_device *dev, int queue);
+void pp3_dbg_dev_rxq_status_print(struct net_device *dev, int queue);
+void pp3_dbg_dev_flags(struct net_device *dev, u32 flag, u32 en);
+void pp3_dbg_dev_status_print(struct net_device *dev);
+void pp3_dbg_dev_pools_status_print(struct net_device *dev);
+void pp3_dbg_dev_mac_mc_print(struct net_device *dev);
+void pp3_dbg_cpu_status_print(void);
+void pp3_dbg_cpu_flags(int cpu, u32 flag, u32 en);
+void pp3_dbg_skb_dump(struct sk_buff *skb);
+void pp3_dbg_dev_stats_dump(struct net_device *dev);
+void pp3_dbg_dev_queues_stats_dump(struct net_device *dev);
+void pp3_dbg_dev_pools_stats_dump(struct net_device *dev);
+void pp3_dbg_dev_fw_stats_dump(struct net_device *dev);
+void pp3_dbg_dev_stats_clear(struct net_device *dev);
+void pp3_dbg_cfh_common_dump(struct mv_cfh_common *cfh);
+void pp3_dbg_cfh_rx_dump(struct mv_cfh_common *rx_cfh);
+void pp3_dbg_cfh_hdr_dump(struct mv_cfh_common *cfh);
+int pp3_dbg_cfh_rx_checker(struct pp3_dev_priv *dev_priv, u32 *ptr);
+void pp3_dbg_txdone_occ_show(int cpu);
+void pp3_dbg_dev_path_stats_dump(struct pp3_dev_priv *dev_src, struct pp3_dev_priv *dev_dst);
+
+void pp3_dbg_ingress_vqs_print(struct net_device *dev);
+void pp3_dbg_ingress_vqs_show(struct net_device *dev);
+void pp3_dbg_ingress_qos_show(struct net_device *dev);
+
+void pp3_dbg_egress_vqs_print(struct net_device *dev);
+void pp3_dbg_egress_vqs_show(struct net_device *dev);
+void pp3_dbg_egress_qos_show(struct net_device *dev);
+
+void pp3_dbg_dev_mac_show(struct net_device *dev);
+char *pp3_dbg_l2_info_str(unsigned int l2_info);
+char *pp3_dbg_vlan_info_str(unsigned int vlan_info);
+char *pp3_dbg_l3_info_str(unsigned int l3_info);
+char *pp3_dbg_l4_info_str(unsigned int l4_info);
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_debug_sysfs.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_debug_sysfs.c
new file mode 100644
index 0000000..88f5057
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_debug_sysfs.c
@@ -0,0 +1,257 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_netdev.h"
+#include "mv_netdev_structs.h"
+#include "mv_dev_vq.h"
+#include "mv_dev_dbg.h"
+#include "common/mv_hw_if.h"
+
+
+static ssize_t pp3_dev_debug_help(char *b)
+{
+	int o = 0;
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                                     help           - show this help\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                         > mac_show       - show MAC addresses for network interface\n");
+#if 0
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [cpu]                            > txdone_history - show tx done history staistics\n");
+#endif
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [0|1]                            > internal_debug - enable/disable internal debug checkers\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [mask]                  > debug          - enable/disable network interface debug messages\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [cir] [eir] [cbs] [ebs] > tx_shaper      - set shaping rates and burst sizes for egress emac port\n");
+#if 0
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [cpu] [mask]                     > cpu_debug      - enable/disable cpu debug messages\n");
+#ifndef CONFIG_MV_PP3_FPGA
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [0|1]                            > rx_isr_mode    - set rx ISR mode for all network interfaces. 0-poll, 1-isr\n");
+#endif /* CONFIG_MV_PP3_FPGA */
+#endif
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [rx] [tx]               > create         - create new virtual network device (no emac connectivity)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ifname]    - network interface name e.g. nic0, nic1, etc\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mode]      - 0 for 4 HWQ per SWQ, 1 for 1 HWQ per SWQ\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mask]      - for debug command: b0-rx, b1-tx, b2-isr, b3-poll\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "                  - for cpu_devug command: b0-buff push, b1-buff pop\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [rx]        - number of rx virtual queueus\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [tx]        - number of tx virtual queueus\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [cir]       - committed information rate in [Mbps] units, granularity of [10 Mbps]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [eir]       - excessive information rate in [Mbps] units, granularity of [10 Mbps]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [cbs]       - committed burst size in [KBytes]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ebs]       - excessive burst size in [KBytes]\n");
+#endif
+	return o;
+}
+
+
+static ssize_t pp3_dev_debug_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = pp3_dev_debug_help(buf);
+
+	return off;
+}
+
+ssize_t pp3_dev_debug_dec_store(struct device *dev, struct device_attribute *attr,
+					const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             fields, err = 1;
+	unsigned int    p;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	p = 0;
+	fields = sscanf(buf, "%d", &p);
+
+	local_irq_save(flags);
+
+#ifdef PP3_INTERNAL_DEBUG
+	if (!strcmp(name, "internal_debug")) {
+		if (fields == 1)
+			err = mv_pp3_ctrl_internal_debug_set(p);
+	}
+#endif
+
+	if (err)
+		pr_err("%s: operation <%s> FAILED. err = %d\n", __func__, name, err);
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t pp3_dev_debug_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             fields, err = 1;
+	unsigned int    a, b, c, d;
+	unsigned long   flags;
+	char		if_name[10];
+	struct net_device *netdev;
+	struct	pp3_dev_priv *dev_priv;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = b = c = 0;
+
+	fields = sscanf(buf, "%s %d %d %d %d", if_name, &a, &b, &c, &d);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "debug")) {
+		if (fields == 2) {
+			netdev = dev_get_by_name(&init_net, if_name);
+			if (!netdev) {
+				pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+				return -EINVAL;
+			}
+
+			dev_priv = MV_PP3_PRIV(netdev);
+			pp3_dbg_dev_flags(netdev, MV_PP3_F_DBG_RX, a & 0x1);
+			pp3_dbg_dev_flags(netdev, MV_PP3_F_DBG_TX, a & 0x2);
+			pp3_dbg_dev_flags(netdev, MV_PP3_F_DBG_ISR, a & 0x4);
+			pp3_dbg_dev_flags(netdev, MV_PP3_F_DBG_POLL, a & 0x8);
+			pp3_dbg_dev_flags(netdev, MV_PP3_F_DBG_SG, a & 0x80);
+			dev_put(netdev);
+			err = 0;
+		}
+	} else if (!strcmp(name, "mac_show")) {
+		if (fields == 1) {
+			netdev = dev_get_by_name(&init_net, if_name);
+			if (!netdev) {
+				pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+				return -EINVAL;
+			}
+			pp3_dbg_dev_mac_show(netdev);
+			dev_put(netdev);
+			err = 0;
+		}
+	} else if (!strcmp(name, "tx_shaper")) {
+		if (fields == 5) {
+			struct mv_nss_meter meter;
+
+			netdev = dev_get_by_name(&init_net, if_name);
+			if (!netdev) {
+				pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+				return -EINVAL;
+			}
+			meter.cir = a;
+			meter.eir = b;
+			meter.cbs = c;
+			meter.ebs = d;
+			meter.enable = true;
+			err = mv_pp3_dev_egress_vport_shaper_set(netdev, &meter);
+			dev_put(netdev);
+		}
+	} else if (!strcmp(name, "create")) {
+		if (fields == 3) {
+			if (mv_pp3_netdev_init(if_name, a, b) != NULL)
+				err = 0;
+		}
+	} else {
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_debug_show, NULL);
+static DEVICE_ATTR(internal_debug,	S_IWUSR, NULL, pp3_dev_debug_dec_store);
+static DEVICE_ATTR(debug,		S_IWUSR, NULL, pp3_dev_debug_store);
+static DEVICE_ATTR(mac_show,		S_IWUSR, NULL, pp3_dev_debug_store);
+static DEVICE_ATTR(tx_shaper,		S_IWUSR, NULL, pp3_dev_debug_store);
+static DEVICE_ATTR(create,		S_IWUSR, NULL, pp3_dev_debug_store);
+
+#if 0
+static DEVICE_ATTR(txdone_history,	S_IWUSR, NULL, pp3_dev_debug_hex_store);
+static DEVICE_ATTR(cpu_debug,		S_IWUSR, NULL, pp3_dev_debug_hex_store);
+#ifndef CONFIG_MV_PP3_FPGA
+static DEVICE_ATTR(rx_isr_mode,		S_IWUSR, NULL, pp3_dev_debug_hex_store);
+#endif /* !CONFIG_MV_PP3_FPGA */
+#endif
+
+static struct attribute *pp3_dev_debug_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_debug.attr,
+	&dev_attr_mac_show.attr,
+	&dev_attr_tx_shaper.attr,
+	&dev_attr_create.attr,
+	&dev_attr_internal_debug.attr,
+#if 0
+	&dev_attr_cpu_debug.attr,
+	&dev_attr_txdone_history.attr,
+#ifndef CONFIG_MV_PP3_FPGA
+	&dev_attr_rx_isr_mode.attr,
+#endif	/* !CONFIG_MV_PP3_FPGA */
+#endif
+	NULL
+};
+
+static struct attribute_group pp3_dev_debug_group = {
+	.name = "debug",
+	.attrs = pp3_dev_debug_attrs,
+};
+
+int mv_pp3_dev_debug_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp3_kobj, &pp3_dev_debug_group);
+	if (err) {
+		pr_err("sysfs group failed for dev debug%d\n", err);
+		return err;
+	}
+
+	return 0;
+}
+
+int mv_pp3_dev_debug_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &pp3_dev_debug_group);
+
+	return 0;
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_init_sysfs.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_init_sysfs.c
new file mode 100644
index 0000000..7adcb4d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_init_sysfs.c
@@ -0,0 +1,171 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "gnss/mv_pp3_gnss_api.h"
+#include "mv_netdev.h"
+
+static ssize_t pp3_dev_init_sysfs_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]         > dev_show       - show initialization time parameters for network interface\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [n]     > vq_rxqs_num    - set number of ingress VQs [n] for network interface\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [n]     > vq_txqs_num    - set number of egress VQs [n] for network interface\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [mask]  > rx_cpus        - set CPUs [mask] can RX on the network interface\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ifname]    - network interface name e.g. nic0, nic1, nic2, etc\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "                  nss: any interface which name stared with nss e.g. nss16, nss17, etc\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [n]         - number of queues in decimal [0..16]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mask]      - CPUs mask in decimal: bit0 = cpu0, bit1 = cpu1, etc\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t pp3_dev_init_sysfs_show(struct device *dev,
+			  struct device_attribute *attr, char *buf)
+{
+	const char *name = attr->attr.name;
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "show"))
+		pr_info("Not supported yet\n");
+	else
+		off = pp3_dev_init_sysfs_help(buf);
+
+	return off;
+}
+
+static ssize_t pp3_dev_init_netdev_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    a;
+	unsigned long   flags;
+	char		if_name[10];
+	struct net_device *netdev = NULL;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read interface name and value */
+	err = a = 0;
+
+	if (sscanf(buf, "%s %d", if_name, &a) <= 0) {
+		err = 1;
+		goto exit;
+	}
+
+	if (strcmp(if_name, "nss")) {
+		netdev = dev_get_by_name(&init_net, if_name);
+		if (!netdev) {
+			pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+			return -EINVAL;
+		}
+	}
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "dev_show"))
+		if (netdev)
+			mv_pp3_dev_init_show(netdev);
+		else
+			mv_pp3_gnss_dev_init_show();
+	else if (!strcmp(name, "vq_rxqs_num"))
+		if (netdev)
+			err = mv_pp3_dev_rxqs_set(netdev, a);
+		else
+			err = mv_pp3_gnss_dev_rxqs_set(a);
+	else if (!strcmp(name, "vq_txqs_num"))
+		if (netdev)
+			err = mv_pp3_dev_txqs_set(netdev, a);
+		else
+			err = mv_pp3_gnss_dev_txqs_set(a);
+	else if (!strcmp(name, "rx_cpus"))
+		if (netdev)
+			err = mv_pp3_dev_rx_cpus_set(netdev, a);
+		else
+			err = mv_pp3_gnss_dev_rx_cpus_set(a);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+	if (netdev)
+		dev_put(netdev);
+exit:
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_init_sysfs_show, NULL);
+static DEVICE_ATTR(dev_show,		S_IWUSR, NULL, pp3_dev_init_netdev_store);
+static DEVICE_ATTR(vq_rxqs_num,		S_IWUSR, NULL, pp3_dev_init_netdev_store);
+static DEVICE_ATTR(vq_txqs_num,		S_IWUSR, NULL, pp3_dev_init_netdev_store);
+static DEVICE_ATTR(rx_cpus,		S_IWUSR, NULL, pp3_dev_init_netdev_store);
+
+static struct attribute *pp3_dev_init_sysfs_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_dev_show.attr,
+	&dev_attr_vq_rxqs_num.attr,
+	&dev_attr_vq_txqs_num.attr,
+	&dev_attr_rx_cpus.attr,
+	NULL
+};
+
+
+static struct attribute_group pp3_dev_init_sysfs_group = {
+	.name = "init",
+	.attrs = pp3_dev_init_sysfs_attrs,
+};
+
+int mv_pp3_dev_init_sysfs_init(struct kobject *dev_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(dev_kobj, &pp3_dev_init_sysfs_group);
+
+	if (err)
+		pr_err("sysfs group failed for vq path\n");
+
+	return err;
+}
+
+int mv_pp3_dev_init_sysfs_exit(struct kobject *dev_kobj)
+{
+	sysfs_remove_group(dev_kobj, &pp3_dev_init_sysfs_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.c
new file mode 100644
index 0000000..b9f5605
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.c
@@ -0,0 +1,254 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_netdev.h"
+#include "mv_netdev_structs.h"
+#include "mv_dev_dbg.h"
+#include "common/mv_hw_if.h"
+#include "mv_dev_sysfs.h"
+
+
+static ssize_t pp3_dev_help(char *b)
+{
+	int o = 0;
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cd                        init             - go to init time configuration sub directory\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cd                        debug            - go to debug configuration sub directory\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "cd                        vq               - go to virtual queues configuration sub directory\n");
+#if 0
+	o += scnprintf(b+o, PAGE_SIZE-o, "cd                        bpi              - go to internal back pressure configuration sub directory\n");
+#endif
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                       sys_conf         - show HW resources allocation\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > status           - show network interface status\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > stats            - show network interface statistics (per CPU details)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > q_stats          - show network interface statistics (per SW queue details)\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > pool_stats       - show network interface BM pools statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > fw_stats         - show network interface FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]           > clear_stats      - clear network interface statistics\n");
+#if 0
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [mode]    > rx_pkt_mode      - set RX mode for packets ingress from the network interface\n");
+#endif
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [cpu]     > cpu_affinity     - set default CPU to process packets from the network interface\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [ifname]                     - network interface name e.g. nic0, nic1, etc\n");
+#if 0
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [mode]                       - RX packets mode: 0 - the whole packet is in DRAM, 1 - packet header is in CFH\n");
+#endif
+	return o;
+}
+
+static ssize_t pp3_dev_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char *name = attr->attr.name;
+	int err;
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		off = pp3_dev_help(buf);
+	else if (!strcmp(name, "sys_conf"))
+		pp3_dbg_dev_resources_dump();
+/*
+	else if (!strcmp(name, "cpu_status"))
+		pp3_dbg_cpu_status_print();
+*/
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t pp3_dev_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    b, c;
+	unsigned long   flags;
+	char		if_name[10];
+	struct net_device *netdev;
+	struct	pp3_dev_priv *dev_priv;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = b = c = 0;
+
+	sscanf(buf, "%s %d %d", if_name, &b, &c);
+
+
+	netdev = dev_get_by_name(&init_net, if_name);
+
+	if (!netdev) {
+		pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+		return -EINVAL;
+	}
+
+	dev_priv = MV_PP3_PRIV(netdev);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "status")) {
+		pp3_dbg_dev_status_print(netdev);
+		pp3_dbg_dev_pools_status_print(netdev);
+	} else if (!strcmp(name, "cpu_affinity")) {
+		mv_pp3_cpu_affinity_set(netdev, b);
+	} else if (!strcmp(name, "stats")) {
+		pp3_dbg_dev_stats_dump(netdev);
+	} else if (!strcmp(name, "q_stats")) {
+		pp3_dbg_dev_queues_stats_dump(netdev);
+	} else if (!strcmp(name, "fw_stats")) {
+		pp3_dbg_dev_fw_stats_dump(netdev);
+	} else if (!strcmp(name, "clear_stats")) {
+		pp3_dbg_dev_stats_clear(netdev);
+	} else if (!strcmp(name, "pool_stats")) {
+		pp3_dbg_dev_pools_stats_dump(netdev);
+#if 0
+	} else if (!strcmp(name, "rx_pkt_mode")) {
+		mv_pp3_rx_pkt_mode_set(netdev, b);
+#endif /* if 0 */
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+	dev_put(netdev);
+
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(status,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(cpu_affinity,	S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(q_stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(clear_stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(pool_stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(fw_stats,		S_IWUSR, NULL, pp3_dev_store);
+#if 0
+static DEVICE_ATTR(rx_pkt_mode,		S_IWUSR, NULL, pp3_dev_store);
+#endif
+static DEVICE_ATTR(sys_conf,		S_IRUSR, pp3_dev_show, NULL);
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_show, NULL);
+
+static struct attribute *pp3_dev_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_sys_conf.attr,
+	&dev_attr_status.attr,
+	&dev_attr_cpu_affinity.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_q_stats.attr,
+	&dev_attr_fw_stats.attr,
+	&dev_attr_clear_stats.attr,
+	&dev_attr_pool_stats.attr,
+#if 0
+	&dev_attr_rx_pkt_mode.attr,
+#endif
+	NULL
+};
+
+static struct attribute_group pp3_dev_group = {
+	.attrs = pp3_dev_attrs,
+};
+
+
+int mv_pp3_dev_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+	struct kobject *dev_kobj;
+
+	dev_kobj = kobject_create_and_add("dev", pp3_kobj);
+	if (!dev_kobj) {
+		printk(KERN_ERR"%s: cannot create dev kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(dev_kobj, &pp3_dev_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", pp3_dev_group.name, err);
+		return err;
+	}
+	err = mv_pp3_dev_vq_sysfs_init(dev_kobj);
+	if (err)
+		return err;
+
+#if 0
+	err = mv_pp3_dev_bpi_sysfs_init(dev_kobj);
+	if (err)
+		return err;
+#endif /*if 0 */
+
+	err = mv_pp3_dev_init_sysfs_init(dev_kobj);
+	if (err)
+		return err;
+
+	err = mv_pp3_dev_debug_sysfs_init(dev_kobj);
+	if (err)
+		return err;
+
+	return 0;
+}
+
+int mv_pp3_dev_sysfs_exit(struct kobject *pp3_kobj)
+{
+	int err;
+#if 0
+
+	err = mv_pp3_dev_bpi_sysfs_exit(pp3_kobj);
+	if (err)
+		return err;
+#endif
+
+	err = mv_pp3_dev_init_sysfs_exit(pp3_kobj);
+	if (err)
+		return err;
+
+	err = mv_pp3_dev_debug_sysfs_exit(pp3_kobj);
+	if (err)
+		return err;
+
+	err = mv_pp3_dev_vq_sysfs_exit(pp3_kobj);
+	if (err)
+		return err;
+
+	sysfs_remove_group(pp3_kobj, &pp3_dev_group);
+
+	return 0;
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.h
new file mode 100644
index 0000000..f4b256b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_sysfs.h
@@ -0,0 +1,56 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_dev_sysfs_h__
+#define __mv_dev_sysfs_h__
+
+int mv_pp3_dev_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_dev_sysfs_exit(struct kobject *pp3_kobj);
+
+int mv_pp3_dev_init_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_init_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_debug_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_debug_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_vq_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_vq_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_qos_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_qos_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_rss_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_rss_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_bpi_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_bpi_sysfs_exit(struct kobject *dev_kobj);
+
+int mv_pp3_dev_fp_sysfs_init(struct kobject *dev_kobj);
+int mv_pp3_dev_fp_sysfs_exit(struct kobject *dev_kobj);
+
+#endif /* __mv_dev_sysfs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.c
new file mode 100644
index 0000000..019b946
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.c
@@ -0,0 +1,963 @@
+/*******************************************************************************
+ropyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "mv_netdev_structs.h"
+#include "mv_netdev.h"
+#include "mv_dev_vq.h"
+#include "tm/wrappers/mv_tm_drop.h"
+#include "hmac/mv_hmac.h"
+
+/* global lock for ingress VQ priority change */
+static DEFINE_SPINLOCK(napi_list_lock);
+
+/*---------------------------------------------------------------------------*/
+/* Ingress virtual queue (vq) configurations.                                */
+/*---------------------------------------------------------------------------*/
+
+/* Get number of ingress virtual queues of the network device */
+int mv_pp3_dev_ingress_vqs_num_get(struct net_device *dev, int *vqs_num)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	/* Number of ingress VQs is the same for for both CPUs - return first found */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp && cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			break;
+	}
+	if (cpu_vp) {
+		*vqs_num = cpu_vp->rx_vqs_num;
+		return 0;
+	}
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_ingress_cos_show(struct net_device *netdev)
+{
+	int cos;
+	int vqs[MV_PP3_PRIO_NUM];
+
+	pr_info("\n%s: ingress CoS to VQ mapping\n", netdev->name);
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++) {
+		if (mv_pp3_dev_ingress_cos_to_vq_get(netdev, cos, &vqs[cos]))
+			vqs[cos] = -1;
+	}
+	pr_cont("\n");
+	pr_cont("cos:  ");
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++)
+		pr_cont("%2d  ", cos);
+
+	pr_cont("vq :  ");
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++)
+		pr_cont("%2d  ", vqs[cos]);
+
+	pr_info("\n");
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Map cos value to ingress virtual queue [vq] of the network device */
+int mv_pp3_dev_ingress_cos_to_vq_set(struct net_device *dev, int cos, int vq)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	/* on ingress only CPU internal ports support cos to vq mapping */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || (vq >= cpu_vp->rx_vqs_num))
+			continue;
+
+		rc = mv_pp3_ingress_cos_to_vq_set(cpu_vp, cos, vq);
+		if (rc)
+			goto err;
+	}
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get ingress virtual queue [vq] mapped on [cos] value for network device */
+int mv_pp3_dev_ingress_cos_to_vq_get(struct net_device *dev, int cos, int *vq)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+	/* on ingress only CPU internal ports support cos to vq mapping */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp && cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			break;
+	}
+	if (cpu_vp) {
+		rc = mv_pp3_ingress_cos_to_vq_get(cpu_vp, cos, vq);
+		return rc;
+	}
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set tail drop (TD) and random early drop (RED) values for given ingress virtual queue (vq) */
+int mv_pp3_dev_ingress_vq_drop_set(struct net_device *dev, int vq, struct mv_nss_drop *drop)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	/* On ingress drop configuration supported only for CPU internal ports */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || (vq >= cpu_vp->rx_vqs_num))
+			continue;
+
+		rc = mv_pp3_ingress_vq_drop_set(cpu_vp, vq, drop);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_ingress_vq_drop_get(struct net_device *dev, int vq, struct mv_nss_drop *drop)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		/* drop configurations must be same for both CPUs - return first found */
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp && cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_ingress_vq_drop_get(cpu_vp, vq, drop);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set priority for given ingress virtual queue (vq) */
+int mv_pp3_dev_ingress_vq_prio_set(struct net_device *dev, int vq, u16 prio)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || (vq >= cpu_vp->rx_vqs_num))
+			continue;
+
+		rc = mv_pp3_ingress_vq_prio_set(cpu_vp, vq, prio);
+		if (rc)
+			break;
+	}
+	mv_pp3_dev_napi_queue_update(dev);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set weight for given ingress virtual queue (vq) */
+int mv_pp3_dev_ingress_vq_weight_set(struct net_device *dev, int vq, u16 weight)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || (vq >= cpu_vp->rx_vqs_num))
+			continue;
+
+		rc = mv_pp3_ingress_vq_weight_set(cpu_vp, vq, dev->mtu, weight);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_ingress_vq_sched_get(struct net_device *dev, int vq, struct mv_nss_sched *sched)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		/* drop configurations must be same for both CPUs - return first found */
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp && cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_ingress_vq_sched_get(cpu_vp, vq, sched);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set size (Xoff) [pkts] given ingress virtual queue (vq) */
+int mv_pp3_dev_ingress_vq_size_set(struct net_device *dev, int vq, u16 size)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp || (vq >= cpu_vp->rx_vqs_num))
+			continue;
+
+		rc = mv_pp3_ingress_vq_size_set(cpu_vp, vq, size);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_ingress_vq_size_get(struct net_device *dev, int vq, u16 *size)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		/* drop configurations must be same for both CPUs - return first found */
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp && cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_ingress_vq_size_get(cpu_vp, vq, size);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_ingress_vqs_defaults_set(struct net_device *dev)
+{
+	int vq, vqs_num, prio;
+	struct mv_nss_drop drop;
+
+	if (mv_pp3_dev_ingress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of ingress virtual queues\n", dev->name);
+		return -1;
+	}
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		prio = vq;
+		if (prio >= MV_PP3_SCHED_PRIO_NUM)
+			prio = (MV_PP3_SCHED_PRIO_NUM - 1);
+
+		if (mv_pp3_dev_ingress_vq_prio_set(dev, vq, prio))
+			return -1;
+
+		/* Disable DWRR by default */
+		if (mv_pp3_dev_ingress_vq_weight_set(dev, vq, 0))
+			return -1;
+
+		/* Set default TD and RED thresholds */
+		drop.td = MV_PP3_INGRESS_TD_DEF;
+		drop.red = MV_PP3_INGRESS_RED_DEF;
+		drop.enable = true;
+		if (mv_pp3_dev_ingress_vq_drop_set(dev, vq, &drop))
+			return -1;
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/* Egress virtual queue (vq) configurations                                  */
+/*---------------------------------------------------------------------------*/
+
+/* Get number of egress virtual queues of the network device */
+int mv_pp3_dev_egress_vqs_num_get(struct net_device *dev, int *vqs_num)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	/* Number of egress VQs is the same for for both CPUs - return first found */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp)
+			break;
+	}
+	if (cpu_vp) {
+		*vqs_num = cpu_vp->tx_vqs_num;
+		return 0;
+	}
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_egress_cos_show(struct net_device *netdev)
+{
+	int cos;
+	int vqs[MV_PP3_PRIO_NUM];
+
+	pr_info("\n%s: egress CoS to VQ mapping\n", netdev->name);
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++) {
+		if (mv_pp3_dev_egress_cos_to_vq_get(netdev, cos, &vqs[cos]))
+			vqs[cos] = -1;
+	}
+	pr_cont("cos:  ");
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++)
+		pr_cont("%2d  ", cos);
+
+	pr_cont("\n");
+	pr_cont("vq :  ");
+	for (cos = 0; cos < MV_PP3_PRIO_NUM; cos++)
+		pr_cont("%2d  ", vqs[cos]);
+
+	pr_info("\n");
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Map cos value to virtual queue [q] */
+int mv_pp3_dev_egress_cos_to_vq_set(struct net_device *dev, int cos, int vq)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	/* Single EMAC / External virtual port support cos to vq mapping */
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH)) {
+		if (mv_pp3_egress_cos_to_vq_set(vp, cos, vq))
+			goto err;
+	}
+	/* internal CPU ports support cos to vq mapping */
+	for_each_possible_cpu(cpu) {
+		vp = dev_priv->cpu_vp[cpu];
+		if (!vp)
+			continue;
+
+		if (mv_pp3_egress_cos_to_vq_set(vp, cos, vq))
+			goto err;
+	}
+	return rc;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get egress virtual queue [vq] mapped on [cos] value for network device */
+int mv_pp3_dev_egress_cos_to_vq_get(struct net_device *dev, int cos, int *vq)
+{
+	int cpu;
+	struct pp3_vport *vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	/*
+	vp = dev_priv->vport;
+	if (vp) {
+		*vq = mv_pp3_egress_cos_to_vq_get(vp, cos);
+		return 0;
+	}
+	*/
+	/* CoS to VQ mapping is the same for all vports of network device */
+	for_each_possible_cpu(cpu) {
+		vp = dev_priv->cpu_vp[cpu];
+		if (vp)
+			break;
+	}
+	if (vp) {
+		*vq = mv_pp3_egress_cos_to_vq_get(vp, cos);
+		return 0;
+	}
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set tail drop (TD) and random early drop (RED) values for given egress virtual queue (vq) */
+int mv_pp3_dev_egress_vq_drop_set(struct net_device *dev, int vq, struct mv_nss_drop *drop)
+{
+	int rc = -1;
+	struct pp3_vport *vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	/* For egress direction drop configuration supported only for EMAC virtual ports */
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH))
+		rc = mv_pp3_egress_vq_drop_set(vp, vq, drop);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get tail drop (TD) and random early drop (RED) values for given egress virtual queue (vq) */
+int mv_pp3_dev_egress_vq_drop_get(struct net_device *dev, int vq, struct mv_nss_drop *drop)
+{
+	int rc = -1;
+	struct pp3_vport *vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	/* For egress direction drop configuration supported only for EMAC virtual ports */
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH))
+		rc = mv_pp3_egress_vq_drop_get(vp, vq, drop);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set priority for given egress virtual queue (vq) */
+int mv_pp3_dev_egress_vq_prio_set(struct net_device *dev, int vq, u16 prio)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp, *vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH)) {
+		rc = mv_pp3_egress_vq_prio_set(vp, vq, prio);
+		if (rc)
+			return rc;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		rc = mv_pp3_egress_vq_prio_set(cpu_vp, vq, prio);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set weight for given egress virtual queue (vq) */
+int mv_pp3_dev_egress_vq_weight_set(struct net_device *dev, int vq, u16 weight)
+{
+	int cpu, rc = 0;
+	struct pp3_vport *cpu_vp, *vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	vp = dev_priv->vport;
+	if (vp && (vp->type == MV_PP3_NSS_PORT_ETH)) {
+		rc = mv_pp3_egress_vq_weight_set(vp, vq, dev->mtu, weight);
+		if (rc)
+			return rc;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		rc = mv_pp3_egress_vq_weight_set(cpu_vp, vq, dev->mtu, weight);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_egress_vq_sched_get(struct net_device *dev, int vq, struct mv_nss_sched *sched)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		/* drop configurations must be same for both CPUs - return first found */
+		break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_egress_vq_sched_get(cpu_vp, vq, sched);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set size [pkts] given egress virtual queue (vq) */
+int mv_pp3_dev_egress_vq_size_set(struct net_device *dev, int vq, u16 size)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		rc = mv_pp3_egress_vq_size_set(cpu_vp, vq, size);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_egress_vq_size_get(struct net_device *dev, int vq, u16 *size)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		/* VQ size must be same for both CPUs - return first found */
+		break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_egress_vq_size_get(cpu_vp, vq, size);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set rate limit values to hmac_to_ppc Anodes */
+int mv_pp3_dev_egress_vq_rate_limit_set(struct net_device *dev, int vq, struct mv_nss_meter *meter)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		rc = mv_pp3_egress_vq_rate_limit_set(cpu_vp, vq, meter);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get rate limit values for hmac_to_ppc Anodes */
+int mv_pp3_dev_egress_vq_rate_limit_get(struct net_device *dev, int vq, struct mv_nss_meter *meter)
+{
+	int cpu, rc = -1;
+	struct pp3_vport *cpu_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (cpu_vp)
+			break;
+	}
+	if (cpu_vp)
+		rc = mv_pp3_egress_vq_rate_limit_get(cpu_vp, vq, meter);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set rate limit values to hmac_to_ppc Anodes */
+int mv_pp3_dev_egress_vport_shaper_set(struct net_device *dev, struct mv_nss_meter *meter)
+{
+	int rc = -1;
+	struct pp3_vport *emac_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+	emac_vp = dev_priv->vport;
+	if (emac_vp && (emac_vp->type == MV_PP3_NSS_PORT_ETH))
+		rc = mv_pp3_egress_vport_shaper_set(emac_vp, meter);
+	else
+		pr_err("%s: Vport shaper is not supported\n", dev->name);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_egress_vqs_defaults_set(struct net_device *dev)
+{
+	int vq, vqs_num, prio;
+	struct mv_nss_meter meter;
+	struct pp3_vport *emac_vp = NULL;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s in not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	if (mv_pp3_dev_egress_vqs_num_get(dev, &vqs_num)) {
+		pr_err("%s: Error - Can't get number of egress virtual queues\n", dev->name);
+		return -1;
+	}
+	/* set default values cir and eir values for all VQs */
+	/* No EMAC   : cir =  2000 Mbps, eir = 0 Mbps, cbs = 16 KBytes, ebs = 16 KBytes */
+	/* RXAUI 10G : cir = 10000 Mbps, eir = 0 Mbps, cbs = 64 KBytes, ebs = 64 KBytes */
+	/* SGMII 2.5G: cir =  2500 Mbps, eir = 0 Mbps, cbs = 16 KBytes, ebs = 16 KBytes */
+	/* Others 1G : cir =  1000 Mbps, eir = 0 Mbps, cbs = 16 KBytes, ebs = 16 KBytes */
+	if (dev_priv->vport && (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		meter.cir = 2000;
+		meter.eir = 0;
+		meter.cbs = 16;
+		meter.ebs = 16;
+	} else {
+		emac_vp = dev_priv->vport;
+		if (!emac_vp)
+			return -1;
+
+		if (emac_vp->port.emac.port_mode == MV_PORT_RXAUI) {
+			meter.cir = 10000;
+			meter.eir = 0;
+			meter.cbs = 64;
+			meter.ebs = 64;
+		} else if (emac_vp->port.emac.port_mode == MV_PORT_SGMII2_5) {
+			meter.cir = 2500;
+			meter.eir = 0;
+			meter.cbs = 16;
+			meter.ebs = 16;
+		} else {
+			meter.cir = 1000;
+			meter.eir = 0;
+			meter.cbs = 16;
+			meter.ebs = 16;
+		}
+	}
+
+	for (vq = 0; vq < vqs_num; vq++) {
+
+		prio = vq;
+		if (prio >= MV_PP3_SCHED_PRIO_NUM)
+			prio = (MV_PP3_SCHED_PRIO_NUM - 1);
+
+		if (mv_pp3_dev_egress_vq_prio_set(dev, vq, prio)) {
+			pr_err("%s: Can't set priority %d for vq #%d\n", dev->name, prio, vq);
+			return -1;
+		}
+
+		/* Disable DWRR by default */
+		if (mv_pp3_dev_egress_vq_weight_set(dev, vq, 0)) {
+			pr_err("%s: Can't set weight 0 (disable( for vq #%d\n", dev->name, vq);
+			return -1;
+		}
+		if (mv_pp3_dev_egress_vq_rate_limit_set(dev, vq, &meter))
+			return -1;
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static void mv_pp3_vq_prio_sort(struct pp3_vq **vq_list, int *napi_rxq, int q_nums)
+{
+	int tmp, i, j;
+
+	for (i = 0; i < (q_nums - 1); i++) {
+		for (j = 0; j < q_nums - 1 - i; j++) {
+			if (!(vq_list[napi_rxq[j]]) || !(vq_list[napi_rxq[j+1]]))
+				continue;
+			if (vq_list[napi_rxq[j]]->sched->priority > vq_list[napi_rxq[j+1]]->sched->priority) {
+				tmp = napi_rxq[j+1];
+				napi_rxq[j+1] = napi_rxq[j];
+				napi_rxq[j] = tmp;
+			}
+		}
+	}
+}
+
+static inline int mv_pp3_free_array_ind_get(struct pp3_cpu_port *cpu)
+{
+	int i;
+
+	/* find free queues list for changes */
+	for (i = 0; i < 3; i++)
+		if ((i != cpu->napi_master_array) && (i != cpu->napi_next_array))
+			return i;
+
+	return -1;
+}
+
+void mv_pp3_dev_napi_queue_update(struct net_device *dev)
+{
+	int cpu;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	unsigned long flags = 0;
+	int array_ind, i;
+	struct pp3_vport *cpu_vp;
+
+	MV_LOCK(&napi_list_lock, flags);
+	for_each_possible_cpu(cpu) {
+
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+
+		/* find free queues list for changes */
+		array_ind = mv_pp3_free_array_ind_get(&cpu_vp->port.cpu);
+		if (array_ind < 0)
+			continue;
+
+		/* build new list of valid napi queues */
+		for (i = 0; i < cpu_vp->rx_vqs_num; i++)
+			if (cpu_vp->rx_vqs[i]->valid)
+				cpu_vp->port.cpu.napi_proc_qs[array_ind][i] = cpu_vp->rx_vqs[i]->vq;
+
+		mv_pp3_vq_prio_sort(cpu_vp->rx_vqs, cpu_vp->port.cpu.napi_proc_qs[array_ind], cpu_vp->rx_vqs_num);
+		cpu_vp->port.cpu.napi_next_array = array_ind;
+	}
+	MV_UNLOCK(&napi_list_lock, flags);
+}
+
+/* disable RX queue for napi processing */
+static void mv_pp3_dev_vq_napi_disable(struct pp3_vport *cpu_vp, int vq)
+{
+	struct pp3_cpu_port *cpu = &cpu_vp->port.cpu;
+	int array_ind;
+	int i, j;
+
+	/* find free queues list for changes */
+	array_ind = mv_pp3_free_array_ind_get(cpu);
+	if (array_ind < 0)
+		return;
+
+	/* to disable, remove queue from the list of napi queues */
+	for (i = 0; i < cpu->napi_q_num; i++) {
+		if (vq == cpu->napi_proc_qs[array_ind][i]) {
+			if ((i + 1) < cpu->napi_q_num) {
+				for (j = i; (j + 1) < cpu->napi_q_num; j++)
+					cpu->napi_proc_qs[array_ind][j] = cpu->napi_proc_qs[array_ind][j + 1];
+			}
+			cpu->napi_next_array = array_ind;
+			break;
+		}
+	}
+	cpu->napi_q_num--;
+	cpu_vp->rx_vqs[vq]->valid = false;
+}
+
+/* enable RX queue for napi processing */
+static void mv_pp3_dev_vq_napi_enable(struct pp3_vport *cpu_vp, int vq)
+{
+	struct pp3_cpu_port *cpu = &cpu_vp->port.cpu;
+	int array_ind;
+
+	/* find free queues list for changes */
+	array_ind = mv_pp3_free_array_ind_get(cpu);
+	if (array_ind < 0)
+		return;
+
+	/* to enable, add queue to the list of napi queues according to its priority */
+	cpu->napi_proc_qs[array_ind][cpu->napi_q_num] = vq;
+	cpu->napi_q_num++;
+	cpu_vp->rx_vqs[vq]->valid = true;
+	mv_pp3_vq_prio_sort(cpu_vp->rx_vqs, cpu->napi_proc_qs[array_ind], cpu->napi_q_num);
+	cpu->napi_next_array = array_ind;
+}
+
+/* disable / enable RX queue for napi processing */
+/* this function can be called only in NAPI context runs on specific CPU */
+int mv_pp3_dev_vqs_proc_cfg(struct net_device *dev, int vq, bool q_enable)
+{
+	struct pp3_vport *cpu_vp;
+	unsigned long flags = 0;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int cpu;
+
+	if (!dev_priv) {
+		pr_err("%s: Error - %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	MV_LOCK(&napi_list_lock, flags);
+	for_each_possible_cpu(cpu) {
+
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+
+		if (mv_pp3_max_check(vq, cpu_vp->rx_vqs_num, "vq"))
+			break;
+
+		if (q_enable) {
+			if (cpu_vp->rx_vqs[vq]->valid)
+				continue;
+			mv_pp3_dev_vq_napi_enable(cpu_vp, vq);
+			mv_pp3_hmac_rxq_resume(cpu_vp->rx_vqs[vq]->swq->frame_num, cpu_vp->rx_vqs[vq]->swq->swq);
+			STAT_INFO(cpu_vp->rx_vqs[vq]->swq->stats.resumed++);
+		} else {
+			if (!cpu_vp->rx_vqs[vq]->valid)
+				continue;
+			mv_pp3_hmac_rxq_pause(cpu_vp->rx_vqs[vq]->swq->frame_num, cpu_vp->rx_vqs[vq]->swq->swq);
+			mv_pp3_dev_vq_napi_disable(cpu_vp, vq);
+			STAT_INFO(cpu_vp->rx_vqs[vq]->swq->stats.suspend++);
+		}
+	}
+	MV_UNLOCK(&napi_list_lock, flags);
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.h
new file mode 100644
index 0000000..da9d58b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq.h
@@ -0,0 +1,86 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_dev_vq_h__
+#define __mv_dev_vq_h__
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "vport/mv_pp3_vq.h"
+
+/* Ingress VQs configuration APIs - for all interfaces */
+int mv_pp3_dev_ingress_vqs_num_get(struct net_device *dev, int *vqs_num);
+int mv_pp3_dev_ingress_vqs_defaults_set(struct net_device *dev);
+int mv_pp3_dev_ingress_vq_drop_set(struct net_device *dev, int vq, struct mv_nss_drop *drop);
+int mv_pp3_dev_ingress_vq_drop_get(struct net_device *dev, int vq, struct mv_nss_drop *drop);
+
+int mv_pp3_dev_ingress_vq_prio_set(struct net_device *dev, int vq, u16 prio);
+int mv_pp3_dev_ingress_vq_weight_set(struct net_device *dev, int vq, u16 weight);
+int mv_pp3_dev_ingress_vq_sched_get(struct net_device *dev, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_dev_ingress_cos_show(struct net_device *netdev);
+int mv_pp3_dev_ingress_cos_to_vq_set(struct net_device *dev, int cos, int vq);
+int mv_pp3_dev_ingress_cos_to_vq_get(struct net_device *dev, int cos, int *vq);
+
+int mv_pp3_dev_ingress_vq_size_set(struct net_device *dev, int vq, u16 length);
+int mv_pp3_dev_ingress_vq_size_get(struct net_device *dev, int vq, u16 *length);
+
+/* Egress VQs configuration APIs - for all interfaces */
+int mv_pp3_dev_egress_vqs_num_get(struct net_device *dev, int *vqs_num);
+int mv_pp3_dev_egress_vqs_defaults_set(struct net_device *dev);
+int mv_pp3_dev_egress_vq_drop_set(struct net_device *dev, int vq, struct mv_nss_drop *drop);
+int mv_pp3_dev_egress_vq_drop_get(struct net_device *dev, int vq, struct mv_nss_drop *drop);
+
+int mv_pp3_dev_egress_vq_prio_set(struct net_device *dev, int vq, u16 prio);
+int mv_pp3_dev_egress_vq_weight_set(struct net_device *dev, int vq, u16 weight);
+int mv_pp3_dev_egress_vq_sched_get(struct net_device *dev, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_dev_egress_cos_show(struct net_device *netdev);
+int mv_pp3_dev_egress_cos_to_vq_set(struct net_device *dev, int cos, int vq);
+int mv_pp3_dev_egress_cos_to_vq_get(struct net_device *dev, int cos, int *vq);
+
+int mv_pp3_dev_egress_vq_size_set(struct net_device *dev, int vq, u16 length);
+int mv_pp3_dev_egress_vq_size_get(struct net_device *dev, int vq, u16 *length);
+
+int mv_pp3_dev_egress_vq_rate_limit_set(struct net_device *dev, int vq, struct mv_nss_meter *meter);
+int mv_pp3_dev_egress_vq_rate_limit_get(struct net_device *dev, int vq, struct mv_nss_meter *meter);
+
+int mv_pp3_dev_egress_vport_shaper_set(struct net_device *dev, struct mv_nss_meter *meter);
+
+void mv_pp3_dev_napi_queue_update(struct net_device *dev);
+int mv_pp3_dev_vqs_proc_cfg(struct net_device *dev, int vq, bool q_enable);
+
+#if 0
+int mv_pp3_egress_vq_emac_set(struct net_device *dev, int vq, u32 emac);
+int mv_pp3_egress_vq_bpi_thresh_set(struct net_device *dev, int vq, int xon, int xoff, enum mv_pp3_bpi_level level);
+int mv_pp3_ingress_vq_bpi_thresh_set(int xon, int xoff);
+int mv_pp3_egress_bpi_dump(struct net_device *dev);
+
+#endif
+
+#endif /* __mv_dev_vq_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq_sysfs.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq_sysfs.c
new file mode 100644
index 0000000..02b5a11
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_dev_vq_sysfs.c
@@ -0,0 +1,250 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "mv_netdev.h"
+#include "mv_dev_vq.h"
+
+
+static ssize_t pp3_dev_vq_help(char *b)
+{
+	int o = 0;
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                              > rx_cos_show  - show ingress CoS values to virtual queues mapping\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                              > rx_vq_show   - show ingress virtual queues configuration for network interface\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [prio]                  > rx_vq_prio   - set scheduling priority [prio] for ingress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [weight]                > rx_vq_wrr    - set WRR [weight] for ingress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [length]                > rx_vq_length - set [length] in packets for ingress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [td] [red]              > rx_vq_drop   - set [td] and [red] thresholds for ingress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [cir] [eir] [cbs] [ebs] > rx_vq_limit  - set limit rates and burst sizes for ingress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [cos] [vq]                   > rx_cos_vq    - set ingress virtual queue [vq] for [cos] value\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                              > tx_cos_show  - show egress CoS values to virtual queues mapping\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname]                              > tx_vq_show   - show egress virtual queues configuration for network interface\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [prio]                  > tx_vq_prio   - set scheduling priority [prio] for egress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [weight]                > tx_vq_wrr    - set WRR weight [weight] for egress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [length]                > tx_vq_length - set [length] in packets for egress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [td] [red]              > tx_vq_drop   - set [td] and [red] thresholds for egress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [vq] [cir] [eir] [cbs] [ebs] > tx_vq_limit  - set limit rates and burst sizes for egress virtual queue [vq]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [ifname] [cos] [vq]                   > tx_cos_vq    - set ingress virtual queue [vq] for [cos] value\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters: all values are decimal\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[ifname]    - network interface name e.g. nic0, nic1, nss0\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[vq]        - virtual queue number in range of [0..16]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[cos]       - class of service value in range of [0..16]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[length]    - virtual queue length in [pkts]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[td]        - tail drop threshold in [KBytes]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[red]       - random early drop threshold in [KBytes]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[prio]      - scheduling priority in range of [0..7]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[weight]    - WRR weight\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[cir]       - committed information rate in [Mbps] units, granularity of [10 Mbps]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[eir]       - excessive information rate in [Mbps] units, granularity of [10 Mbps]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[cbs]       - committed burst size in [KBytes]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "	[ebs]       - excessive burst size in [KBytes]\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+
+	return o;
+}
+
+static ssize_t pp3_dev_vq_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = pp3_dev_vq_help(buf);
+
+	return off;
+}
+
+
+static ssize_t pp3_dev_vq_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    vq, a, b, c, d;
+	unsigned long   flags;
+	char		if_name[10];
+	struct net_device *netdev;
+	struct	pp3_dev_priv *dev_priv;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = a = b = vq = 0;
+
+	if (sscanf(buf, "%s %d %d %d %d %d", if_name, &vq, &a, &b, &c, &d) <= 0) {
+		err = 1;
+		goto exit;
+	}
+
+	netdev = dev_get_by_name(&init_net, if_name);
+
+	if (!netdev) {
+		pr_err("%s: illegal interface <%s>\n", __func__, if_name);
+		return -EINVAL;
+	}
+
+	dev_priv = MV_PP3_PRIV(netdev);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "rx_vq_show")) {
+		pp3_dbg_ingress_vqs_print(netdev);
+		pp3_dbg_ingress_vqs_show(netdev);
+	} else if (!strcmp(name, "tx_vq_show")) {
+		pp3_dbg_egress_vqs_print(netdev);
+		pp3_dbg_egress_vqs_show(netdev);
+	} else if (!strcmp(name, "rx_cos_show"))
+		err = mv_pp3_dev_ingress_cos_show(netdev);
+	else if (!strcmp(name, "tx_cos_show"))
+		err = mv_pp3_dev_egress_cos_show(netdev);
+	else if (!strcmp(name, "rx_vq_prio"))
+		err = mv_pp3_dev_ingress_vq_prio_set(netdev, vq, a);
+	else if (!strcmp(name, "rx_vq_wrr"))
+		err = mv_pp3_dev_ingress_vq_weight_set(netdev, vq, a);
+	else if (!strcmp(name, "rx_vq_drop")) {
+		struct mv_nss_drop drop;
+
+		drop.td = a;
+		drop.red = b;
+		drop.enable = true;
+		err = mv_pp3_dev_ingress_vq_drop_set(netdev, vq, &drop);
+	} else if (!strcmp(name, "rx_cos_vq"))
+		err = mv_pp3_dev_ingress_cos_to_vq_set(netdev, vq, a);
+	else if (!strcmp(name, "tx_vq_prio"))
+		err = mv_pp3_dev_egress_vq_prio_set(netdev, vq, a);
+	else if (!strcmp(name, "tx_vq_wrr"))
+		err = mv_pp3_dev_egress_vq_weight_set(netdev, vq, a);
+	else if (!strcmp(name, "tx_vq_drop")) {
+		struct mv_nss_drop drop;
+
+		drop.td = a;
+		drop.red = b;
+		drop.enable = true;
+		err = mv_pp3_dev_egress_vq_drop_set(netdev, vq, &drop);
+	} else if (!strcmp(name, "tx_cos_vq"))
+		err = mv_pp3_dev_egress_cos_to_vq_set(netdev, vq, a);
+#if 0
+	else if (!strcmp(name, "rx_vq_limit"))
+		err = mv_pp3_dev_ingress_vq_limit_set(netdev, vq, a, b, c, d);
+#endif
+	else if (!strcmp(name, "tx_vq_limit")) {
+		struct mv_nss_meter meter;
+
+		meter.cir = a;
+		meter.eir = b;
+		meter.cbs = c;
+		meter.ebs = d;
+		meter.enable = true;
+		err = mv_pp3_dev_egress_vq_rate_limit_set(netdev, vq, &meter);
+	} else if (!strcmp(name, "rx_vq_length"))
+		err = mv_pp3_dev_ingress_vq_size_set(netdev, vq, a);
+	else if (!strcmp(name, "tx_vq_length"))
+		err = mv_pp3_dev_egress_vq_size_set(netdev, vq, a);
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+	dev_put(netdev);
+exit:
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_vq_show, NULL);
+static DEVICE_ATTR(rx_cos_show,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_show,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_prio,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_wrr,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_drop,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_length,	S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_vq_limit,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(rx_cos_vq,		S_IWUSR, NULL, pp3_dev_vq_store);
+
+static DEVICE_ATTR(tx_cos_show,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_show,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_prio,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_wrr,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_drop,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_length,	S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_vq_limit,		S_IWUSR, NULL, pp3_dev_vq_store);
+static DEVICE_ATTR(tx_cos_vq,		S_IWUSR, NULL, pp3_dev_vq_store);
+
+
+static struct attribute *pp3_dev_vq_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_rx_cos_show.attr,
+	&dev_attr_rx_vq_show.attr,
+	&dev_attr_rx_vq_prio.attr,
+	&dev_attr_rx_vq_wrr.attr,
+	&dev_attr_rx_vq_drop.attr,
+	&dev_attr_rx_vq_length.attr,
+	&dev_attr_rx_vq_limit.attr,
+	&dev_attr_rx_cos_vq.attr,
+
+	&dev_attr_tx_cos_show.attr,
+	&dev_attr_tx_vq_show.attr,
+	&dev_attr_tx_vq_prio.attr,
+	&dev_attr_tx_vq_wrr.attr,
+	&dev_attr_tx_vq_drop.attr,
+	&dev_attr_tx_vq_length.attr,
+	&dev_attr_tx_vq_limit.attr,
+	&dev_attr_tx_cos_vq.attr,
+	NULL
+};
+
+
+static struct attribute_group pp3_dev_vq_group = {
+	.name = "vq",
+	.attrs = pp3_dev_vq_attrs,
+};
+
+int mv_pp3_dev_vq_sysfs_init(struct kobject *dev_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(dev_kobj, &pp3_dev_vq_group);
+
+	if (err)
+		pr_err("sysfs group failed for vq path\n");
+
+	return err;
+}
+
+int mv_pp3_dev_vq_sysfs_exit(struct kobject *dev_kobj)
+{
+	sysfs_remove_group(dev_kobj, &pp3_dev_vq_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.c
new file mode 100644
index 0000000..df6f3d1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.c
@@ -0,0 +1,355 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/etherdevice.h>
+#include <linux/netdevice.h>
+#include <linux/mv_pp3.h>
+#include "common/mv_sw_if.h"
+
+#ifdef CONFIG_MV_PP3_FPGA
+#include "gmac/mv_gmac.h"
+#else /* CONFIG_MV_PP3_FPGA */
+#include "gop/mv_gop_if.h"
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+#include "mv_netdev.h"
+#include "mv_netdev_structs.h"
+#include "fw/mv_fw_shared.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "fw/mv_pp3_fw_msg_structs.h"
+
+
+/******************************************************************************
+* mv_pp3_eth_tool_get_settings
+* Description:
+*	ethtool get standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		command (settings)
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_pp3_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
+{
+	struct pp3_dev_priv		*priv = MV_PP3_PRIV(netdev);
+	enum mv_port_speed		speed;
+	enum mv_port_duplex		duplex;
+	struct mv_port_link_status	status;
+	enum mv_port_mode		port_mode;
+
+	cmd->phy_address = priv->mac_data.phy_addr;
+	port_mode = (enum mv_port_mode)priv->mac_data.port_mode;
+	cmd->speed  = SPEED_UNKNOWN;
+	cmd->duplex = SPEED_UNKNOWN;
+
+	if (priv->flags & MV_PP3_F_INIT) {
+
+		mv_pp3_gop_port_link_status(priv->id, &status);
+
+		if (status.linkup == true) {
+			switch (status.speed) {
+			case MV_PORT_SPEED_10000:
+				cmd->speed = SPEED_10000;
+				break;
+			case MV_PORT_SPEED_1000:
+				cmd->speed = SPEED_1000;
+				break;
+			case MV_PORT_SPEED_100:
+				cmd->speed = SPEED_100;
+				break;
+			case MV_PORT_SPEED_10:
+				cmd->speed = SPEED_10;
+				break;
+			default:
+				return -EINVAL;
+			}
+			if (status.duplex == MV_PORT_DUPLEX_FULL)
+				cmd->duplex = 1;
+			else
+				cmd->duplex = 0;
+		} else {
+			cmd->speed  = SPEED_UNKNOWN;
+			cmd->duplex = SPEED_UNKNOWN;
+		}
+		/* check if speed and duplex are AN */
+		speed = MV_PORT_SPEED_AN;
+		duplex = MV_PORT_DUPLEX_AN;
+		if ((port_mode == MV_PORT_RXAUI) || (port_mode == MV_PORT_XAUI))
+			cmd->autoneg = AUTONEG_DISABLE;
+		else {
+			mv_pp3_gop_speed_duplex_get(priv->id, &speed, &duplex);
+			if (speed == MV_PORT_SPEED_AN && duplex == MV_PORT_DUPLEX_AN) {
+				cmd->lp_advertising = cmd->advertising = 0;
+				cmd->autoneg = AUTONEG_ENABLE;
+			} else
+				cmd->autoneg = AUTONEG_DISABLE;
+		}
+	}
+
+	if ((port_mode == MV_PORT_RXAUI) || (port_mode == MV_PORT_XAUI)) {
+		cmd->supported = (SUPPORTED_FIBRE | SUPPORTED_10000baseT_Full);
+		cmd->supported = (SUPPORTED_10000baseT_Full | SUPPORTED_FIBRE);
+		cmd->advertising = (ADVERTISED_10000baseT_Full | ADVERTISED_FIBRE);
+		cmd->port = PORT_FIBRE;
+		cmd->transceiver = XCVR_EXTERNAL;
+		cmd->speed = SPEED_10000;
+		cmd->duplex = 1;
+	} else {
+		cmd->supported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full | SUPPORTED_100baseT_Half
+			| SUPPORTED_100baseT_Full | SUPPORTED_Autoneg | SUPPORTED_TP | SUPPORTED_MII
+			| SUPPORTED_1000baseT_Full);
+		cmd->transceiver = XCVR_INTERNAL;
+		cmd->port = PORT_MII;
+	}
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_pp3_eth_tool_set_settings
+* Description:
+*	ethtool set standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		command (settings)
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_pp3_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct pp3_dev_priv		*priv = MV_PP3_PRIV(dev);
+	enum mv_port_speed		speed;
+	enum mv_port_duplex		duplex;
+	enum mv_port_mode		port_mode;
+	int err;
+
+	if (!(priv->flags & MV_PP3_F_INIT)) {
+		pr_err("%s: interface %s is not initialized\n", __func__, dev->name);
+		return -EOPNOTSUPP;
+	}
+
+	port_mode = (enum mv_port_mode)priv->mac_data.port_mode;
+	if ((port_mode == MV_PORT_RXAUI) || (port_mode == MV_PORT_XAUI)) {
+		pr_info("cannot change port setting for %s interface", dev->name);
+		return -EOPNOTSUPP;
+	}
+	if (cmd->autoneg == AUTONEG_DISABLE) {
+		switch (cmd->speed) {
+		case SPEED_10:
+			speed = MV_PORT_SPEED_10;
+			break;
+		case SPEED_100:
+			speed = MV_PORT_SPEED_100;
+			break;
+		case SPEED_1000:
+			speed = MV_PORT_SPEED_1000;
+			break;
+		default:
+			return -EINVAL;
+		}
+
+		switch (cmd->duplex) {
+		case DUPLEX_HALF:
+			duplex = MV_PORT_DUPLEX_HALF;
+			break;
+		case DUPLEX_FULL:
+			duplex = MV_PORT_DUPLEX_FULL;
+			break;
+		default:
+			return -EINVAL;
+		}
+		err = mv_pp3_gop_speed_duplex_set(priv->id, speed, duplex);
+
+	} else if (cmd->autoneg == AUTONEG_ENABLE)
+		err = mv_pp3_gop_speed_duplex_set(priv->id, MV_PORT_SPEED_AN, MV_PORT_DUPLEX_AN);
+	else
+		err = -EINVAL;
+
+	return err;
+}
+
+/******************************************************************************
+* mv_pp3_eth_tool_get_drvinfo
+* Description:
+*	ethtool get driver information
+* INPUT:
+*	netdev		Network device structure pointer
+*	info		driver information
+* OUTPUT
+*	info		driver information
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_pp3_eth_tool_get_drvinfo(struct net_device *netdev, struct ethtool_drvinfo *info)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(netdev);
+	struct mv_pp3_version fw_ver, *drv_ver;
+
+	drv_ver = mv_pp3_get_driver_version();
+	/* get from FW run version for each client */
+	if (dev_priv->flags & MV_PP3_F_INIT) {
+		pp3_fw_version_get(&fw_ver);
+		sprintf(info->fw_version, "%d.%d.%d", fw_ver.major_x, fw_ver.minor_y, fw_ver.local_z);
+	} else
+		strcpy(info->fw_version, "N/A");
+
+	strlcpy(info->driver, MV_PP3_PORT_NAME, sizeof(info->driver));
+	sprintf(info->version, "%d.%d.%d", drv_ver->major_x, drv_ver->minor_y, drv_ver->local_z);
+	strcpy(info->bus_info, "N/A");
+
+	info->n_stats = 0;
+	info->testinfo_len = 0;
+	info->regdump_len = 0;
+	info->eedump_len = 0;
+}
+
+/******************************************************************************
+* mv_pp3_eth_tool_get_link
+* Description:
+*	ethtool get link status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 if link is down, 1 if link is up
+*
+*******************************************************************************/
+u32 mv_pp3_eth_tool_get_link(struct net_device *netdev)
+{
+	struct pp3_dev_priv	*priv = MV_PP3_PRIV(netdev);
+
+	return mv_pp3_gop_port_is_link_up(priv->id);
+}
+
+/******************************************************************************
+* mv_pp3_eth_tool_get_coalesce
+* Description:
+*	ethtool get RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		Coalesce parameters
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_pp3_eth_tool_get_coalesce(struct net_device *netdev, struct ethtool_coalesce *cmd)
+{
+	mv_pp3_rx_time_coal_get(netdev, &cmd->rx_coalesce_usecs);
+	mv_pp3_rx_pkt_coal_get(netdev, &cmd->rx_max_coalesced_frames);
+	mv_pp3_txdone_time_coal_get(netdev, &cmd->tx_coalesce_usecs);
+	mv_pp3_txdone_pkt_coal_get(netdev, &cmd->tx_max_coalesced_frames);
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_pp3_eth_tool_set_coalesce
+* Description:
+*	ethtool set RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		Coalesce parameters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_pp3_eth_tool_set_coalesce(struct net_device *netdev, struct ethtool_coalesce *cmd)
+{
+	int rx_time_coal;
+	int rx_pkt_coal;
+	int tx_pkt_coal;
+
+	if (cmd->rx_coalesce_usecs) {
+		mv_pp3_rx_time_coal_get(netdev, &rx_time_coal);
+		if (rx_time_coal != cmd->rx_coalesce_usecs)
+			mv_pp3_rx_time_coal_set(netdev, cmd->rx_coalesce_usecs);
+	}
+	if (cmd->rx_max_coalesced_frames) {
+		mv_pp3_rx_pkt_coal_get(netdev, &rx_pkt_coal);
+		if (rx_pkt_coal != cmd->rx_max_coalesced_frames)
+			mv_pp3_rx_pkt_coal_set(netdev, cmd->rx_max_coalesced_frames);
+	}
+	if (cmd->tx_max_coalesced_frames) {
+		mv_pp3_txdone_pkt_coal_get(netdev, &tx_pkt_coal);
+		if (tx_pkt_coal != cmd->tx_max_coalesced_frames)
+			mv_pp3_txdone_pkt_coal_set(netdev, cmd->tx_max_coalesced_frames);
+	}
+	if (cmd->tx_coalesce_usecs)
+		mv_pp3_txdone_time_coal_set(netdev, cmd->tx_coalesce_usecs);
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_pp3_eth_tool_nway_reset
+* Description:
+*	ethtool restart auto negotiation
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_pp3_eth_tool_nway_reset(struct net_device *dev)
+{
+	struct pp3_dev_priv *priv = MV_PP3_PRIV(dev);
+
+	if (!(priv->flags & MV_PP3_F_INIT)) {
+		pr_err("%s: interface %s is not initialized\n", __func__, dev->name);
+		return -EOPNOTSUPP;
+	}
+
+	mv_pp3_gop_autoneg_restart(priv->id);
+
+	return 0;
+}
+
+/* NIC ports ethtool functions */
+const struct ethtool_ops mv_pp3_ethtool_ops = {
+	.get_drvinfo				= mv_pp3_eth_tool_get_drvinfo,
+	.get_link				= mv_pp3_eth_tool_get_link,
+	.get_settings				= mv_pp3_eth_tool_get_settings,
+	.set_settings				= mv_pp3_eth_tool_set_settings,
+	.get_coalesce				= mv_pp3_eth_tool_get_coalesce,
+	.set_coalesce				= mv_pp3_eth_tool_set_coalesce,
+	.nway_reset				= mv_pp3_eth_tool_nway_reset,
+};
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.h
new file mode 100644
index 0000000..e7cd34a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ethtool.h
@@ -0,0 +1,35 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_ethtool_h__
+#define __mv_ethtool_h__
+
+#include <linux/ethtool.h>
+
+extern const struct ethtool_ops mv_pp3_ethtool_ops;
+
+#endif /* __mv_ethtool_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_gnss_wrap.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_gnss_wrap.h
new file mode 100644
index 0000000..12fcd554
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_gnss_wrap.h
@@ -0,0 +1,87 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <net/gnss/mv_nss_metadata.h>
+#include <net/gnss/mv_nss_ops.h>
+#include "vport/mv_pp3_cpu.h"
+#include "mv_netdev_structs.h"
+
+
+/*---------------------------------------------------------------------------*/
+static inline struct mv_nss_ops *mv_pp3_gnss_ops_get(struct net_device *dev)
+{
+	if (dev) {
+		struct pp3_dev_priv *dev_priv =  MV_PP3_PRIV(dev);
+
+		if (dev_priv && dev_priv->cpu_shared)
+			return dev_priv->cpu_shared->gnss_ops;
+	}
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+/*			GNSS WRAPPERS					     */
+/*---------------------------------------------------------------------------*/
+static inline struct sk_buff *mv_pp3_gnss_skb_alloc(struct net_device *dev, int pkt_size, gfp_t gfp_mask)
+{
+	struct sk_buff *skb;
+	struct mv_nss_ops *gnss_ops = mv_pp3_gnss_ops_get(dev);
+
+	if (gnss_ops && gnss_ops->alloc_skb)
+		skb = gnss_ops->alloc_skb(pkt_size, GFP_DMA | gfp_mask);
+	else
+		skb = __dev_alloc_skb(pkt_size, GFP_DMA | gfp_mask);
+
+	return skb;
+}
+/*---------------------------------------------------------------------------*/
+static inline void mv_pp3_gnss_skb_free(struct net_device *dev, struct sk_buff *skb)
+{
+	struct mv_nss_ops *gnss_ops = mv_pp3_gnss_ops_get(dev);
+	struct mv_gnss_metadata *pmdata = NULL;
+
+	if (gnss_ops && gnss_ops->free_skb && gnss_ops->get_metadata_skb)
+		pmdata =  gnss_ops->get_metadata_skb(skb);
+
+	pmdata ? gnss_ops->free_skb(skb) : dev_kfree_skb_any(skb);
+}
+/*---------------------------------------------------------------------------*/
+static inline int  mv_pp3_gnss_skb_receive(struct net_device *dev, struct sk_buff *skb)
+{
+	int status;
+	struct mv_nss_ops *gnss_ops = mv_pp3_gnss_ops_get(dev);
+
+	if (gnss_ops && gnss_ops->receive_skb) {
+		skb->dev = dev;
+		status = gnss_ops->receive_skb(skb);
+	} else {
+		skb->protocol = eth_type_trans(skb, dev);
+		status =  netif_receive_skb(skb);
+	}
+	return status;
+}
+/*---------------------------------------------------------------------------*/
+static inline u32 *mv_pp3_gnss_skb_mdata_get(struct net_device *dev, struct sk_buff *skb)
+{
+	struct mv_nss_metadata *pmdata = NULL;
+	struct mv_nss_ops *gnss_ops = mv_pp3_gnss_ops_get(dev);
+
+	if (gnss_ops && gnss_ops->get_metadata_skb)
+		pmdata = gnss_ops->get_metadata_skb(skb);
+
+	return (u32 *)pmdata;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.c
new file mode 100644
index 0000000..af8329a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.c
@@ -0,0 +1,3322 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <linux/module.h>
+#include <linux/inetdevice.h>
+#include <linux/interrupt.h>
+#include <linux/mbus.h>
+#include <linux/prefetch.h>
+#include <asm/setup.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <linux/list.h>
+#include <linux/firmware.h>
+#include <linux/of_irq.h>
+#ifdef CONFIG_MV_PP3_FPGA
+#include <linux/pci.h>
+#endif
+#include <linux/phy.h>
+#include <linux/of_irq.h>
+#include <linux/clk.h>
+#include <linux/of_address.h>
+#include <linux/dma-mapping.h>
+
+#include <net/gnss/mv_nss_defs.h>
+#include <net/gnss/mv_nss_metadata.h>
+#include <net/gnss/mv_nss_ops.h>
+#include "mv_gnss_wrap.h"
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "hmac/mv_hmac.h"
+#include "hmac/mv_hmac_bm.h"
+#include "emac/mv_emac.h"
+#include "emac/mv_emac_regs.h"
+#include "cmac/mv_cmac.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "fw/mv_fw.h"
+#include "bm/mv_bm.h"
+#include "mv_netdev.h"
+#include "vport/mv_pp3_vport.h"
+#include "vport/mv_pp3_vq.h"
+#include "mv_netdev_structs.h"
+#include "msg/mv_pp3_msg_drv.h"
+#include "bm/mv_bm.h"
+#include "qm/mv_qm.h"
+#ifdef CONFIG_MV_PP3_TM_SUPPORT
+#include "tm/mv_tm.h"
+#endif
+
+#include "mv_dev_sysfs.h"
+#include "mv_dev_vq.h"
+#include "mv_ethtool.h"
+
+#ifdef CONFIG_MV_PP3_FPGA
+#include "gmac/mv_gmac.h"
+#else
+#include "gop/mv_gop_if.h"
+#include "gop/mv_smi.h"
+#include "gop/mv_ptp_regs.h"
+#endif
+
+#ifdef CONFIG_MV_PP3_PTP_SERVICE
+#include "net_dev/mv_ptp_hook.c"
+#endif
+
+static struct mv_nss_if_ops mv_pp3_nss_if_ops = {
+	.recv_pause     = mv_pp3_dev_rx_pause,
+	.recv_resume    = mv_pp3_dev_rx_resume,
+	/* .shutdown  */
+};
+
+/* debug parameters */
+#ifdef PP3_INTERNAL_DEBUG
+static bool internal_debug_en;
+static bool debug_stop_rx;
+
+bool mv_pp3_is_internal_debug(void)
+{
+	return internal_debug_en;
+}
+
+int mv_pp3_ctrl_internal_debug_set(int en)
+{
+	internal_debug_en = (en != 0);
+	return 0;
+}
+#endif /* PP3_INTERNAL_DEBUG */
+
+/* global data */
+static int pp3_ports_num;
+static struct pp3_dev_priv **pp3_netdev;
+static int pp3_netdev_next;
+/* sysfs related */
+static struct platform_device *pp3_sysfs;
+
+/* ISR related */
+static bool mv_pp3_run_hmac_interrupts;
+static int mv_pp3_irq_rx_base;
+static struct mv_pp3 *pp3_priv;
+
+static const struct net_device_ops mv_pp3_netdev_ops;
+
+/* functions */
+static int mv_pp3_tx_done(struct net_device *dev, int tx_todo);
+static void mv_pp3_txdone_timer_callback(unsigned long data);
+static int mv_pp3_check_mtu_valid(int mtu);
+static int mv_pp3_rx(struct net_device *dev, struct pp3_vport *cpu_vp, struct pp3_vq *rx_vq, int budget);
+
+#ifndef CONFIG_MV_PP3_FPGA
+static int mv_pp3_affinity_notifier_release(int irq_num);
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+static bool mv_pp3_skb_recycle = CONFIG_MV_PP3_SKB_RECYCLE_DEF;
+
+
+int mv_pp3_ctrl_nic_skb_recycle(int en)
+{
+	mv_pp3_skb_recycle = (en != 0);
+	return 0;
+}
+
+bool mv_pp3_is_nic_skb_recycle(void)
+{
+	return mv_pp3_skb_recycle;
+}
+#else
+static bool mv_pp3_skb_recycle;
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+
+int mv_pp3_dev_num_get(void)
+{
+	return pp3_ports_num;
+}
+
+struct pp3_dev_priv *mv_pp3_dev_priv_get(int i)
+{
+	if (mv_pp3_max_check(i, pp3_ports_num, "netdev"))
+		return NULL;
+
+	if (pp3_netdev == NULL)
+		return NULL;
+
+	return  pp3_netdev[i];
+}
+
+int mv_pp3_dev_cpu_inuse(struct net_device *dev, int cpu)
+{
+	struct pp3_dev_priv *dev_priv;
+	if (!dev)
+		return -1;
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv->cpu_vp[cpu])
+		return 0;
+
+	return cpumask_test_cpu(cpu, &dev_priv->rx_cpus);
+}
+
+int mv_pp3_dev_rxvq_num_get(struct net_device *dev, int cpu)
+{
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev)
+		goto err;
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv->cpu_vp[cpu])
+		goto err;
+
+
+	return dev_priv->cpu_vp[cpu]->rx_vqs_num;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+/*
+   Get EMAC or external virtual port number and
+   return network device if such vport found,
+   otherwise return NULL.
+*/
+struct net_device *mv_pp3_vport_dev_get(int vport)
+{
+	int i;
+
+	for (i = 0; i < pp3_netdev_next; i++)
+
+		if (pp3_netdev[i] && pp3_netdev[i]->vport &&
+			(pp3_netdev[i]->vport->vport == vport))
+				return pp3_netdev[i]->dev;
+	return NULL;
+}
+
+static inline struct pp3_dev_priv *mv_pp3_emac_dev_priv_get(int emac_num)
+{
+	struct pp3_dev_priv *p;
+	int i;
+	for (i = 0; i < pp3_netdev_next; i++) {
+		p = pp3_netdev[i];
+		if (p && p->vport && (p->vport->port.emac.emac_num == emac_num))
+				return p;
+	}
+	pr_err("%s: private device for emac port %d not exist\n", __func__, emac_num);
+	return NULL;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Update FW according to port sw structure
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+static int mv_pp3_dev_fw_update(struct pp3_dev_priv *dev_priv)
+{
+	int cpu, global_cpu_vp;
+	struct pp3_vport *cpu_vp;
+
+	/*set pools*/
+	if (mv_pp3_cpu_shared_fw_set_pools(dev_priv->cpu_shared)) {
+		pr_err("%s: error initiating pools\n", __func__);
+		return -1;
+	}
+
+	if (pp3_fw_sync()) {
+		pr_err("%s: Error setting pools in FW\n", __func__);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		if (pp3_cpu_vport_fw_set(cpu_vp)) {
+			pr_err("%s:Error, %s cpu_vport:%d cpu:%d set failed\n", __func__,
+					dev_priv->dev->name, cpu_vp->vport, cpu);
+			return -1;
+		}
+	}
+
+	if (pp3_fw_sync()) {
+		pr_err("%s: Error setting CPU vports in FW\n", __func__);
+		return -1;
+	}
+
+	if (dev_priv->vport) {
+		if (dev_priv->vport->type == MV_PP3_NSS_PORT_ETH) {
+			if (pp3_emac_vport_fw_set(dev_priv->vport, dev_priv->dev->dev_addr)) {
+				pr_err("%s:Error, %s emac_vport:%d set failed\n", __func__,
+					dev_priv->dev->name, dev_priv->vport->vport);
+				return -1;
+			}
+		}
+
+		for_each_possible_cpu(cpu) {
+			cpu_vp = dev_priv->cpu_vp[cpu];
+			if (!cpu_vp)
+				continue;
+
+			if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+				continue;
+
+			global_cpu_vp = MV_PP3_CPU_VPORT_ID(cpu);
+
+			/* map EMAC/WLAN virtual port to CPU virtual port */
+			if (pp3_fw_cpu_vport_map(dev_priv->vport->vport,
+				global_cpu_vp, cpu_vp->vport) < 0) {
+				pr_err("%s:Error, emac_vport %d map failed\n", __func__, dev_priv->vport->vport);
+				return -1;
+			}
+		}
+	}
+
+	return pp3_fw_sync();
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_config_show(void)
+{
+	struct mv_pp3_version *drv_ver;
+
+	drv_ver = mv_pp3_get_driver_version();
+	pr_info("\nmv_pp3 driver version: \t%s:%d.%d.%d.%d",
+			drv_ver->name, drv_ver->major_x, drv_ver->minor_y, drv_ver->local_z, drv_ver->debug_d);
+
+	if (pp3_priv)
+		pr_info("  o %d Network interfaces supported\n", mv_pp3_ports_num_get(pp3_priv));
+
+	pr_info("  o %d PPCs num supported\n", mv_pp3_fw_ppc_num_get());
+
+#ifdef CONFIG_ARCH_MVEBU
+	pr_info("  o Cache coherency mode: %s\n", coherency_available() ? "HW" : "SW");
+#endif
+
+#ifdef CONFIG_MV_PP3_STAT_ERR
+	pr_info("  o ERROR statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_PP3_STAT_INF
+	pr_info("  o INFO statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_PP3_STAT_DBG
+	pr_info("  o DEBUG statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	pr_info("  o Debug messages enabled\n");
+#endif
+
+#ifdef PP3_INTERNAL_DEBUG
+	pr_info("  o Internal DEBUG mode (%s)\n",  mv_pp3_is_internal_debug() ? "Enabled" : "Disabled");
+#endif
+
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+	pr_info("  o NIC SKB recycle supported (%s)\n", mv_pp3_skb_recycle ? "Enabled" : "Disabled");
+#endif
+
+}
+
+static inline struct sk_buff *mv_pp3_skb_alloc(struct net_device *dev, int pkt_size, gfp_t gfp_mask,
+										unsigned long *phys_addr)
+{
+	static struct device *pdev;
+	static struct sk_buff *skb;
+
+	skb = mv_pp3_gnss_skb_alloc(dev, pkt_size, gfp_mask);
+
+	if (!skb)
+		return NULL;
+
+	/* if network device is unknown used shared_pdev for cache operations */
+	if (dev)
+		pdev = dev->dev.parent;
+	else
+		pdev = &pp3_priv->pdev->dev;
+
+	if (phys_addr)
+		*phys_addr = mv_pp3_os_dma_map_single(pdev, skb->head, pkt_size + skb_headroom(skb), DMA_FROM_DEVICE);
+
+	return skb;
+}
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_skb_free(struct net_device *dev, struct sk_buff *skb)
+{
+	mv_pp3_gnss_skb_free(dev, skb);
+}
+/*---------------------------------------------------------------------------*/
+/* Allocate RX buffer */
+static inline void *mv_pp3_pool_buff_alloc(struct net_device *dev, struct pp3_pool *ppool, gfp_t gfp_mask,
+					unsigned long *phys_addr)
+{
+	static struct sk_buff *skb;
+
+	skb = mv_pp3_skb_alloc(dev, ppool->pkt_max_size, gfp_mask, phys_addr);
+
+	if (!skb) {
+		STAT_ERR(PPOOL_STATS(ppool, smp_processor_id())->buff_alloc_err++);
+		pr_err("can't allocate %d bytes buffer for pool #%d\n",
+			ppool->buf_size, ppool->pool);
+		return NULL;
+	}
+	/* TODO inc atomic */
+	STAT_DBG(PPOOL_STATS(ppool, smp_processor_id())->buff_alloc++);
+	return skb;
+}
+/*---------------------------------------------------------------------------*/
+/* Free buffer */
+static inline void mv_pp3_pool_buff_free(struct net_device *dev, struct pp3_pool *ppool, void *virt)
+{
+	mv_pp3_skb_free(dev, (struct sk_buff *)virt);
+
+	/* TODO inc atomic */
+	STAT_DBG(PPOOL_STATS(ppool, smp_processor_id())->buff_free++);
+}
+/*---------------------------------------------------------------------------*/
+/* Allocate new buffer and push it to bm pool */
+static inline int mv_pp3_pool_refill(struct net_device *dev, struct pp3_pool *ppool,
+					gfp_t gfp_mask,	int buf_num)
+{
+	void *virt;
+	unsigned long phys_addr = 0;
+	unsigned long flags  = 0;
+	int i, extra = 0;
+
+
+	for (i = 0; i < (buf_num + extra); i++) {
+		virt = mv_pp3_pool_buff_alloc(dev, ppool, gfp_mask, &phys_addr);
+		if (virt == NULL)
+			break;
+
+		MV_LIGHT_LOCK(flags);
+		if (mv_pp3_pool_buff_put(ppool->pool, virt, phys_addr)) {
+			mv_pp3_pool_buff_free(dev, ppool, virt);
+			MV_LIGHT_UNLOCK(flags);
+			break;
+		}
+		MV_LIGHT_UNLOCK(flags);
+	}
+
+	return i;
+}
+
+/* Flush cache of skb that doesn't copied to CFH */
+static inline dma_addr_t mv_pp3_skb_cache_flush(struct net_device *dev, struct sk_buff *skb, int offset)
+{
+	if (skb->len > offset)
+		mv_pp3_os_dma_map_single(dev->dev.parent, skb->data + offset, skb->len - offset, DMA_TO_DEVICE);
+
+	return virt_to_phys(skb->head);
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_rx_time_coal_set(struct net_device *dev, int usec)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		mv_pp3_cpu_vport_rx_time_coal_set(dev_priv->cpu_vp[cpu], usec);
+	}
+	dev_priv->rx_time_coal = usec;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_rx_time_coal_get(struct net_device *dev, int *usec)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!usec)
+		goto err;
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	*usec = dev_priv->rx_time_coal;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_rx_pkt_coal_set(struct net_device *dev, int pkts_num)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		if (mv_pp3_cpu_vport_rx_pkt_coal_set(cpu_vp, pkts_num))
+			goto err;
+	}
+	dev_priv->rx_pkt_coal = pkts_num;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_rx_pkt_coal_get(struct net_device *dev, int *pkts_num)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!pkts_num)
+		goto err;
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	*pkts_num = dev_priv->rx_pkt_coal;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_txdone_pkt_coal_set(struct net_device *dev, int pkts_num)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		return -1;
+	}
+
+	dev_priv->tx_done_pkt_coal = MV_ALIGN_DOWN(pkts_num, MV_PP3_BUF_REQUEST_SIZE);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_txdone_pkt_coal_get(struct net_device *dev, int *pkts_num)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!pkts_num)
+		goto err;
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	*pkts_num = dev_priv->tx_done_pkt_coal;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_txdone_time_coal_set(struct net_device *dev, unsigned int usec)
+{
+	int cpu;
+	struct pp3_vport *cpu_vp;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		if (mv_pp3_timer_usec_set(&cpu_vp->port.cpu.txdone_timer, usec) < 0)
+			goto err;
+	}
+
+	dev_priv->tx_done_time_coal = usec;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_txdone_time_coal_get(struct net_device *dev, unsigned int *usec)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (!usec)
+		goto err;
+
+	if (!dev_priv) {
+		pr_err("%s: Interface %s is not initialized\n", __func__, dev->name);
+		goto err;
+	}
+
+	*usec = dev_priv->tx_done_time_coal;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/*				link functions				     */
+/*---------------------------------------------------------------------------*/
+/* Set net device all virtual ports state in FW to disable */
+static void mv_pp3_dev_fw_down(struct pp3_dev_priv *dev_priv)
+{
+	if (dev_priv->vport) {
+		dev_priv->vport->state = false;
+		pp3_fw_vport_state_set(dev_priv->vport->vport, 0);
+	}
+}
+/*---------------------------------------------------------------------------*/
+/* Set net device all virtual ports state in FW to enable */
+static void mv_pp3_dev_fw_up(struct pp3_dev_priv *dev_priv)
+{
+	if (dev_priv->vport) {
+		dev_priv->vport->state = true;
+		pp3_fw_vport_state_set(dev_priv->vport->vport, 1);
+	}
+}
+/*---------------------------------------------------------------------------*/
+/* Set net device linux link status to up */
+static void mv_pp3_dev_up(struct pp3_dev_priv *dev_priv)
+{
+	netif_carrier_on(dev_priv->dev);
+	netif_tx_wake_all_queues(dev_priv->dev);
+	set_bit(MV_PP3_F_IF_LINK_UP_BIT, &(dev_priv->flags));
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+/* Set net device linux link status to doen */
+static void mv_pp3_dev_down(struct pp3_dev_priv *dev_priv)
+{
+	clear_bit(MV_PP3_F_IF_LINK_UP_BIT, &(dev_priv->flags));
+	netif_carrier_off(dev_priv->dev);
+	netif_tx_stop_all_queues(dev_priv->dev);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_dev_link_event(struct pp3_dev_priv *dev_priv)
+{
+	struct mv_port_link_status link_status;
+	int hw_link, sw_link, emac;
+	char link_str[100];
+
+	if (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH) {
+		pr_err("%s: error, this function relevant only for EMAC virtual ports\n", __func__);
+		return;
+	}
+
+	emac = dev_priv->vport->port.emac.emac_num;
+	mv_pp3_gop_port_link_status(emac, &link_status);
+	mv_link_to_str(link_status, link_str);
+
+	sw_link = test_bit(MV_PP3_F_IF_LINK_UP_BIT, &(dev_priv->flags)) ? true : false;
+	hw_link = link_status.linkup ? true : false;
+
+	/* Check Link status on ethernet port and update SW, FW and HW relevant components */
+	if (hw_link && !sw_link) {
+		mv_pp3_dev_up(dev_priv); /* this function set SW link */
+		pp3_fw_link_changed(emac, true);
+		mv_pp3_emac_rx_enable(emac, true);
+		mv_link_to_str(link_status, link_str);
+		pr_info("%s %s\n", dev_priv->dev->name, link_str);
+		return;
+	}
+	if (!hw_link && sw_link) {
+		mv_pp3_emac_rx_enable(emac, false);
+		pp3_fw_link_changed(emac, false);
+		mv_pp3_dev_down(dev_priv); /* this function clear SW link */
+		mv_link_to_str(link_status, link_str);
+		pr_info("%s %s\n", dev_priv->dev->name, link_str);
+		return;
+	}
+}
+
+/*---------------------------------------------------------------------------*/
+/* N msec periodic callback for polling					     */
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_txdone_timer_callback(unsigned long data)
+{
+	unsigned long flags = 0;
+	struct pp3_vport *cpu_vp = (struct pp3_vport *)data;
+	struct mv_pp3_timer *pp3_timer = &cpu_vp->port.cpu.txdone_timer;
+	int tx_todo, total_free;
+
+	if (cpu_vp->port.cpu.cpu_num != smp_processor_id()) {
+		pr_err("timer run on incorrect CPU (%d)\n", smp_processor_id());
+		mv_pp3_timer_complete(pp3_timer);
+		return;
+	}
+
+	tx_todo = cpu_vp->port.cpu.txdone_todo;
+	if (tx_todo) {
+		MV_LIGHT_LOCK(flags);
+		STAT_INFO(cpu_vp->port.cpu.stats.txdone++);
+		total_free = mv_pp3_tx_done((struct net_device *)cpu_vp->root, tx_todo);
+		cpu_vp->port.cpu.txdone_todo -= total_free;
+		MV_LIGHT_UNLOCK(flags);
+	}
+
+	mv_pp3_timer_complete(pp3_timer);
+
+	if (cpu_vp->port.cpu.txdone_todo)
+		mv_pp3_timer_add(pp3_timer);
+}
+#ifndef CONFIG_MV_PP3_FPGA
+/*---------------------------------------------------------------------------*/
+/* mac link change event interrupt handle (IRQ 81 - 84)                      */
+/*---------------------------------------------------------------------------*/
+static irqreturn_t mv_pp3_link_change_isr(int irq, void *data)
+{
+	struct pp3_vport *emac_vp = (struct pp3_vport *)data;
+
+	/* mask all events from this mac */
+	mv_pp3_gop_port_events_mask(emac_vp->port.emac.emac_num);
+	/* read cause register to clear event */
+	mv_pp3_gop_port_events_clear(emac_vp->port.emac.emac_num);
+
+	tasklet_schedule(&emac_vp->port.emac.lc_tasklet);
+
+	return IRQ_HANDLED;
+
+}
+
+void mv_pp3_link_change_tasklet(unsigned long data)
+{
+	struct pp3_dev_priv *dev_priv = (struct pp3_dev_priv *)data;
+
+	mv_pp3_dev_link_event(dev_priv);
+	/* Unmask interrupt */
+	mv_pp3_gop_port_events_unmask(dev_priv->vport->port.emac.emac_num);
+}
+
+/*---------------------------------------------------------------------------*/
+/* rx events , group interrupt handle					     */
+/*---------------------------------------------------------------------------*/
+irqreturn_t mv_pp3_rx_isr(int irq, void *data)
+{
+	int group, frame;
+	struct pp3_vport *cpu_vp = (struct pp3_vport *)data;
+	struct pp3_cpu_port *cpu_port = &cpu_vp->port.cpu;
+
+	STAT_INFO(cpu_port->stats.irq++);
+
+	frame = MV_PP3_SW_IRQ_2_HFRAME(irq - mv_pp3_irq_rx_base);
+	group = MV_PP3_SW_IRQ_2_GROUP(irq - mv_pp3_irq_rx_base);
+
+	/* TODO: frame, group validation */
+
+	mv_pp3_hmac_group_event_mask(frame, group);
+
+	if (napi_schedule_prep(&cpu_port->napi)) {
+		/* schedule NAPI */
+		__napi_schedule(&cpu_port->napi);
+		STAT_INFO(cpu_port->stats.napi_sched++);
+	}
+	return IRQ_HANDLED;
+}
+
+/*---------------------------------------------------------------------------*/
+/*  free group RX and link IRQs						     */
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_dev_rx_irqs_free(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *cpu_vp;
+	int cpu;
+
+	if (!dev_priv)
+		return;
+
+	for_each_online_cpu(cpu) {
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		disable_irq(cpu_vp->port.cpu.irq_num);
+#ifdef CONFIG_SMP
+		mv_pp3_affinity_notifier_release(cpu_vp->port.cpu.irq_num);
+#endif
+		free_irq(cpu_vp->port.cpu.irq_num, (void *)cpu_vp);
+	}
+}
+
+
+/*---------------------------------------------------------------------------*/
+/*  free net_device RX and link IRQs					     */
+/*---------------------------------------------------------------------------*/
+
+static void mv_pp3_dev_irqs_free(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *vp_priv;
+
+	if (!dev_priv || !mv_pp3_run_hmac_interrupts)
+		return;
+
+	vp_priv = dev_priv->vport;
+
+	if (vp_priv->type == MV_PP3_NSS_PORT_ETH) {
+		disable_irq(vp_priv->port.emac.lc_irq_num);
+		free_irq(vp_priv->port.emac.lc_irq_num, (void *)vp_priv);
+	}
+
+	/* free rx interrupts */
+	mv_pp3_dev_rx_irqs_free(dev_priv);
+}
+
+/* Get CPU number for specidfied IRQ number connected to net device */
+static int mv_pp3_irq_to_cpu(int irq_num)
+{
+	int i, j;
+
+	for (i = 0; i < pp3_netdev_next; i++) {
+
+		if (pp3_netdev[i]) {
+			for (j = 0 ; j < CONFIG_NR_CPUS; j++) {
+				if (pp3_netdev[i]->cpu_vp[j]) {
+					if (pp3_netdev[i]->cpu_vp[j]->port.cpu.irq_num == irq_num)
+						return pp3_netdev[i]->cpu_vp[j]->port.cpu.cpu_num;
+				}
+			}
+		}
+	}
+	pr_err("%s: no network device reserved on IRQ %d\n", __func__,  irq_num);
+
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+/* SMP affinity change notifier                                              */
+/*---------------------------------------------------------------------------*/
+#ifdef CONFIG_SMP
+static void mv_pp3_affinity_notify(struct irq_affinity_notify *notify, const struct cpumask *mask)
+{
+	const struct cpumask *irq_mask;
+	int   cpu_num;
+
+	cpu_num = mv_pp3_irq_to_cpu(notify->irq);
+
+	irq_mask = cpumask_of(cpu_num);
+	/* in case affinity not change return */
+	if (cpumask_equal(mask, irq_mask))
+		return;
+
+	pr_info("SMP affinity change for IRQ %d isn't supported\n", notify->irq);
+	/* over role the affinity value */
+	if (irq_set_affinity(notify->irq, irq_mask)) {
+		pr_err("Failed to set affinity IRQ %d to cpu %d device\n",
+			notify->irq, cpu_num);
+	}
+}
+
+static void mv_pp3_affinity_release(struct kref *ref)
+{
+	struct irq_affinity_notify *notify = container_of(ref, struct irq_affinity_notify, kref);
+	kfree(notify);
+}
+
+/**
+ * mv_pp3_affinity_notifier - function to register the affinity change notifier
+ *
+ * This adds an IRQ affinity notifier that will prevent affinity modification.
+ *
+ */
+static int mv_pp3_affinity_notifier(int irq_num)
+{
+
+	struct irq_affinity_notify *notify = kzalloc(sizeof(*notify), GFP_KERNEL);
+	int rc;
+
+	if (!notify)
+		return -ENOMEM;
+	notify->notify = mv_pp3_affinity_notify;
+	notify->release = mv_pp3_affinity_release;
+	rc = irq_set_affinity_notifier(irq_num, notify);
+	if (rc)
+		kfree(notify);
+
+	return rc;
+}
+
+
+/**
+ * mv_pp3_affinity_notifier_init - function to un-register the affinity notifier
+ *
+ */
+static int mv_pp3_affinity_notifier_release(int irq_num)
+{
+
+	return irq_set_affinity_notifier(irq_num, NULL);
+}
+#endif
+
+/*---------------------------------------------------------------------------*/
+/*  initialize group RX and link IRQs					     */
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_rx_irq_init(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *cpu_vp;
+	int cpu;
+
+	for_each_online_cpu(cpu) {
+
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (!cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			continue;
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		sprintf(cpu_vp->port.cpu.irq_name, "%s_cpu%d", dev_priv->dev->name, cpu);
+
+		/* connect to ISR */
+		if (request_irq(cpu_vp->port.cpu.irq_num, mv_pp3_rx_isr,
+			IRQF_SHARED | IRQF_TRIGGER_RISING,
+			cpu_vp->port.cpu.irq_name, (void *)cpu_vp)) {
+
+				pr_err("%s: Failed to assign RX IRQ %d\n",
+					 dev_priv->dev->name, cpu_vp->port.cpu.irq_num);
+				goto err;
+		}
+
+		if (irq_set_affinity(cpu_vp->port.cpu.irq_num, cpumask_of(cpu_vp->port.cpu.cpu_ctrl->cpu))) {
+			pr_err("%s: Failed to set affinity IRQ %d to cpu %d device\n",
+				dev_priv->dev->name, cpu_vp->port.cpu.irq_num, cpu_vp->port.cpu.cpu_ctrl->cpu);
+			goto err;
+		}
+
+		pr_info("%s: Assign RX IRQ %d to %s device on cpu %d\n",
+			dev_priv->dev->name, cpu_vp->port.cpu.irq_num, cpu_vp->port.cpu.irq_name, cpu);
+
+#ifdef CONFIG_SMP
+		if (mv_pp3_affinity_notifier(cpu_vp->port.cpu.irq_num)) {
+			pr_err("%s: Failed to set affinity Notifier IRQ %d\n",
+				dev_priv->dev->name, cpu_vp->port.cpu.irq_num);
+			goto err;
+		}
+#endif
+	}
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	mv_pp3_dev_rx_irqs_free(dev_priv);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+/*  initialize net_device RX and link IRQs				     */
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_dev_irqs_init(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *vp_priv;
+
+	vp_priv = dev_priv->vport;
+
+	if (vp_priv->type == MV_PP3_NSS_PORT_ETH) {
+		sprintf(vp_priv->port.emac.lc_irq_name, "mv_mac%d_link",
+						vp_priv->port.emac.emac_num);
+
+		/* connect link change interrupt handler to IRQ */
+		if (request_irq(vp_priv->port.emac.lc_irq_num, mv_pp3_link_change_isr,
+			IRQF_SHARED, vp_priv->port.emac.lc_irq_name, (void *)vp_priv)) {
+				pr_err("%s: Failed to assign link change IRQ (%d)\n",
+					dev_priv->dev->name, vp_priv->port.emac.lc_irq_num);
+				goto err;
+		}
+
+		pr_info("%s: Assign link IRQ %d\n", dev_priv->dev->name, vp_priv->port.emac.lc_irq_num);
+	}
+
+	/* connect RX interrupts handlers (one per CPU) to IRQs */
+	if (mv_pp3_run_hmac_interrupts)
+		if (mv_pp3_dev_rx_irq_init(dev_priv) < 0)
+			goto err;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+
+	if (vp_priv->type == MV_PP3_NSS_PORT_ETH) {
+		disable_irq(vp_priv->port.emac.lc_irq_num);
+		free_irq(vp_priv->port.emac.lc_irq_num, (void *)vp_priv);
+	}
+	return -1;
+}
+#endif /* !CONFIG_MV_PP3_FPGA */
+
+/*---------------------------------------------------------------------------*/
+/*---------------------------------------------------------------------------*/
+
+
+/* Copy metadata from CFH to skb by words */
+static inline int mv_pp3_mdata_copy_to_skb(struct net_device *dev, struct sk_buff *skb, struct mv_cfh_common *cfh)
+{
+	int i;
+	u32 *mdata_src, *pmdata;
+
+	pmdata = mv_pp3_gnss_skb_mdata_get(dev, skb);
+	if (pmdata) {
+		mdata_src = (((u32 *)cfh) + MV_PP3_CFH_COMMON_WORDS);
+
+		for (i = 0; i < MV_PP3_CFH_MDATA_SIZE / 4; i++)
+			pmdata[i] = mdata_src[i];
+
+		return 0;
+	}
+
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+/* Copy metadata from skb to CFH by words */
+static inline void mv_pp3_mdata_copy_to_cfh(u32 *pmdata, struct mv_cfh_common *cfh)
+{
+	int i;
+	u32 *mdata_dest;
+
+	mdata_dest = (((u32 *)cfh) + MV_PP3_CFH_COMMON_WORDS);
+
+	for (i = 0; i < MV_PP3_CFH_MDATA_SIZE / 4; i++)
+		mdata_dest[i] = pmdata[i];
+}
+/*---------------------------------------------------------------------------*/
+
+/* Build metadata on CFH directly */
+static inline void mv_pp3_mdata_build_on_cfh(u16 port_src, u16 port_dst, u8 cos, struct mv_cfh_common *cfh)
+{
+	u32 *pmdata;
+
+	/* skip first 32 bytes to meda data*/
+	pmdata = (((u32 *)cfh) + MV_PP3_CFH_COMMON_WORDS);
+
+	/* We sould not use cpu_to_be16 here, data swapped by FW */
+	((struct mv_nss_metadata *)pmdata)->port_dst = port_dst;
+	((struct mv_nss_metadata *)pmdata)->port_src = port_src;
+	((struct mv_nss_metadata *)pmdata)->type = 0;
+	((struct mv_nss_metadata *)pmdata)->cos = cos;
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/* call to mv_pp3_rx for group's rxqs					     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_poll(struct napi_struct *napi, int budget)
+{
+	int rx_pkt_done = 0;
+	struct pp3_vq *rx_vq;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(napi->dev);
+	int cpu = smp_processor_id();
+	int i, count;
+	struct pp3_vport *cpu_vp = dev_priv->cpu_vp[cpu];
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_POLL)
+		pr_info("%s: ENTER: netif:%s, cpu=%d, budget=%d\n",
+				__func__, napi->dev->name, cpu, budget);
+#endif
+
+	STAT_INFO(cpu_vp->port.cpu.stats.napi_enter++);
+
+	cpu_vp->port.cpu.napi_master_array = cpu_vp->port.cpu.napi_next_array;
+
+	/* check all queues belong to current group */
+	/* start from high priority queue */
+	for (i = cpu_vp->port.cpu.napi_q_num - 1; i >= 0; i--) {
+#ifdef PP3_INTERNAL_DEBUG
+		if (debug_stop_rx) {
+			napi_complete(napi);
+			STAT_INFO(cpu_vp->port.cpu.stats.napi_complete++);
+			return rx_pkt_done;
+		}
+#endif
+		rx_vq = cpu_vp->rx_vqs[MV_PP3_PROC_RXQ_INDEX_GET(cpu_vp->port.cpu, i)];
+
+		/* process packet in that rx queue */
+		count = mv_pp3_rx(napi->dev, cpu_vp, rx_vq, budget);
+
+		rx_pkt_done += count;
+		budget -= count;
+
+		if (budget <= 0)
+			break;
+	}
+
+	if (budget > 0) {
+		napi_complete(napi);
+		STAT_INFO(cpu_vp->port.cpu.stats.napi_complete++);
+
+		if (mv_pp3_run_hmac_interrupts) {
+			int frame = MV_PP3_SW_IRQ_2_HFRAME(cpu_vp->port.cpu.irq_num - mv_pp3_irq_rx_base);
+			int irq_group = MV_PP3_SW_IRQ_2_GROUP(cpu_vp->port.cpu.irq_num - mv_pp3_irq_rx_base);
+			mv_pp3_hmac_group_event_unmask(frame, irq_group);
+		}
+	}
+	return rx_pkt_done;
+}
+
+/*------------------------------------------------------------------------------*/
+/* pp3_pool_bufs_free_internal							*/
+/*	Get buf_num buffers from the pool (via HMAC queue in BM mode)		*/
+/*      Free the valid (non-zero) buffers					*/
+/*	return number of released buffers					*/
+/*------------------------------------------------------------------------------*/
+static inline int pp3_pool_bufs_free_internal(int buf_num, struct net_device *dev, struct pp3_pool *ppool)
+{
+	int buffs_req, buffs_free, total_free = 0;
+	u32  ph_addr[MV_PP3_BUF_REQUEST_SIZE], vr_addr[MV_PP3_BUF_REQUEST_SIZE], pool_id[MV_PP3_BUF_REQUEST_SIZE];
+	int time_out = 0, occ, i;
+	struct pp3_cpu	*cpu_ctrl = pp3_cpus[smp_processor_id()];
+	int frame = cpu_ctrl->bm_frame;
+	int queue = cpu_ctrl->bm_swq;
+	bool zero_flag;
+
+	static int time_out_max = 100;
+
+	buffs_req = MV_MIN(buf_num, MV_PP3_BUF_REQUEST_SIZE);
+
+	mv_pp3_hmac_bm_buff_request(frame, queue, ppool->pool, buffs_req);
+
+	while (buf_num > 0) {
+
+		STAT_INFO(PPOOL_STATS(ppool, cpu_ctrl->cpu)->buff_get_request++);
+
+		time_out = 0;
+		occ = 0;
+
+		/* Wait for all requested buffers are got */
+		while ((time_out++ < time_out_max) && (occ < buffs_req))
+			occ = mv_pp3_hmac_rxq_occ_get(frame, queue);
+
+		if (time_out >=  time_out_max) {
+			STAT_ERR(PPOOL_STATS(ppool, cpu_ctrl->cpu)->buff_get_timeout_err++);
+			pr_err("%s: hmac (%d:%d): timeout error on pool #%d, cpu #%d\n",
+				__func__, frame, queue, ppool->pool, smp_processor_id());
+			pr_err("\twaiting for %d buffers, received %d\n", buffs_req, occ);
+#ifdef PP3_INTERNAL_DEBUG
+			debug_stop_rx = true;
+#endif
+			return -1;
+		}
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+		if (cpu_ctrl->occ_cur_buf < MV_PP3_DEBUG_BUFFER)
+			cpu_ctrl->occ_debug_buf[cpu_ctrl->occ_cur_buf++] = time_out;
+
+		if (cpu_ctrl->debug_txdone_occ < time_out)
+			cpu_ctrl->debug_txdone_occ = time_out;
+#endif
+
+		mv_pp3_os_cache_io_sync(&pp3_priv->pdev->dev);
+		zero_flag = false;
+
+		for (i = 0; i < occ; i++) {
+
+			mv_pp3_hmac_bm_buff_get(frame, queue, &pool_id[i], &ph_addr[i], &vr_addr[i]);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+			if (cpu_ctrl->flags & MV_PP3_CPU_F_DBG_BUF_POP)
+				if (vr_addr[i] || ph_addr[i])
+					pr_info("cpu #%d pop: pool #%d, phys = 0x%08x, virt = 0x%08x\n",
+						cpu_ctrl->cpu, pool_id[i], ph_addr[i], vr_addr[i]);
+#endif
+			STAT_DBG(PPOOL_STATS(ppool, cpu_ctrl->cpu)->buff_get++);
+			if (!ph_addr[i]) {
+				STAT_INFO(PPOOL_STATS(ppool, cpu_ctrl->cpu)->buff_get_zero++);
+				zero_flag = true;
+			}
+		}
+
+		mv_pp3_hmac_rxq_occ_set(frame, queue, buffs_req);
+		buf_num -= buffs_req;
+		buffs_req = MV_MIN(buf_num, MV_PP3_BUF_REQUEST_SIZE);
+		if ((buffs_req > 0) && (!zero_flag))
+			mv_pp3_hmac_bm_buff_request(frame, queue, ppool->pool, buffs_req);
+
+		buffs_free = 0;
+		for (i = 0; i < occ; i++) {
+			if (!ph_addr[i])
+				continue;
+
+			if (unlikely(!vr_addr[i])) {
+				STAT_DBG(PPOOL_STATS(ppool, cpu_ctrl->cpu)->buff_get_dummy++);
+				continue;
+			}
+			mv_pp3_pool_buff_free(dev, ppool, (void *)vr_addr[i]);
+
+			buffs_free++;
+		}
+		ppool->buf_num -= buffs_free;
+		total_free += buffs_free;
+
+		if (zero_flag)
+			break;
+	}
+
+	return total_free;
+}
+/*---------------------------------------------------------------------------
+Function:
+	mv_pp3_tx_done
+Description:
+	Get and free buffers from Linux (tx_done) pool
+return values:
+	success - number of released buffers
+	failed - return -1
+---------------------------------------------------------------------------*/
+
+static inline int mv_pp3_tx_done(struct net_device *dev, int tx_todo)
+{
+	int total_free = 0;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (tx_todo) {
+		total_free = pp3_pool_bufs_free_internal(tx_todo, dev, dev_priv->cpu_shared->txdone_pool);
+
+#ifdef PP3_INTERNAL_DEBUG
+		if (total_free < 0) {
+			pr_err("%s: Invalid state, try to release %d. Total_free (%d) cannot be < 0\n",
+				__func__, tx_todo, total_free);
+			debug_stop_rx = true;
+			return -1;
+		}
+	}
+#endif
+	return total_free;
+}
+
+/*---------------------------------------------------------------------------*/
+/* Get SKB dscp */
+static inline int mv_pp3_skb_dscp_get(struct net_device *dev, struct sk_buff *skb)
+{
+	int dscp = 0; /* default dscp */
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+
+		dscp = TOS_TO_DSCP(iph->tos);
+	}
+	return dscp;
+}
+/* Get transmit SKB priority */
+static inline int mv_pp3_skb_egress_prio_get(struct net_device *dev, struct sk_buff *skb)
+{
+	int prio = 0; /* default priority */
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+
+		prio = DSCP_TO_PRIO(TOS_TO_DSCP(iph->tos));
+	}
+	return prio;
+}
+
+/*---------------------------------------------------------------------------*/
+/* Choose TX SWQ per CPU */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 14, 0)
+static inline u16 mv_pp3_select_txq(struct net_device *dev, struct sk_buff *skb)
+#else
+static inline u16 mv_pp3_select_txq(struct net_device *dev, struct sk_buff *skb,
+					void *accel_priv, select_queue_fallback_t fallback)
+#endif
+{
+	return smp_processor_id();
+}
+
+/*---------------------------------------------------------------------------*/
+static inline u32 mv_pp3_skb_tx_csum(struct sk_buff *skb, struct pp3_vport *cpu_vp)
+{
+	int cmd = 0;
+	int l3_valid, l4_valid, checksum_help;
+
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		struct iphdr *ip4h;
+		struct ipv6hdr *ip6h;
+		int   ip_hdr_len = 0;
+		unsigned char l4_proto;
+		u16 protocol;
+
+		if (skb->protocol == htons(ETH_P_8021Q))
+			protocol = vlan_eth_hdr(skb)->h_vlan_encapsulated_proto;
+		else
+			protocol = skb->protocol;
+
+		switch (protocol) {
+		case htons(ETH_P_IP):
+			/* Calculate IPv4 checksum and L4 checksum */
+			ip4h = ip_hdr(skb);
+			ip_hdr_len = ip4h->ihl;
+			l4_proto = ip4h->protocol;
+			break;
+		case htons(ETH_P_IPV6):
+			/* If not IPv4 - must be ETH_P_IPV6 - Calculate only L4 checksum */
+			ip6h = ipv6_hdr(skb);
+			/* Read l4_protocol from one of IPv6 extra headers */
+			if (skb_network_header_len(skb) > 0)
+				ip_hdr_len = (skb_network_header_len(skb) >> 2);
+			l4_proto = ip6h->nexthdr;
+			break;
+		default:
+			checksum_help = skb_checksum_help(skb);
+			if (checksum_help)
+				pr_err("virual port %d: cannot calculate IP TX checksum on packet with 0x%4x protocol\n",
+						cpu_vp->vport, protocol);
+
+			STAT_DBG((!checksum_help) ? cpu_vp->port.cpu.stats.tx_csum_sw++ : 0 ;)
+
+			return 0;
+		}
+		cmd = mv_pp3_cfh_tx_l3_csum_offload(true, skb_network_offset(skb), protocol, ip_hdr_len, &l3_valid);
+		cmd |= mv_pp3_cfh_tx_l4_csum_offload(true, l4_proto, &l4_valid);
+
+		if (l3_valid || l4_valid) {
+			STAT_DBG(cpu_vp->port.cpu.stats.tx_csum_hw++);
+			return cmd;
+		}
+	}
+
+	STAT_DBG(cpu_vp->port.cpu.stats.tx_csum_sw++);
+	return 0;
+}
+
+#if 0
+/*---------------------------------------------------------------------------*/
+/* mv_pp3_skb_pool_get - get the rx pool if skb recycle is enabled,	     */
+/*                       and reset skb					     */
+/* return val:	rx pool or NULL if recycle not available		     */
+/*									     */
+/*---------------------------------------------------------------------------*/
+static inline struct pp3_pool *mv_pp3_skb_recycle_pool_get(struct sk_buff *skb)
+{
+	struct pp3_pool *ppool = NULL;
+
+
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+	if (mv_pp3_skb_recycle) {
+		int bpid = mv_pp3_skb_recycle_bpid_get(skb);
+
+		if (bpid < 0)
+			return NULL;
+
+		ppool = pp3_pools[bpid];
+		if ((atomic_read(&ppool->in_use) > 0) && skb_is_recycleable(skb, ppool->pkt_max_size)) {
+			atomic_dec(&ppool->in_use);
+			STAT_DBG(PPOOL_STATS(ppool, smp_processor_id())->buff_recycled_ok++);
+		} else {
+			STAT_DBG(PPOOL_STATS(ppool, smp_processor_id())->buff_recycled_err++);
+			return NULL;
+		}
+	}
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+
+	return ppool;
+}
+
+/*---------------------------------------------------------------------------*/
+/* PP3 Driver NIC mode build cfhs fragmented skb function */
+static inline void mv_pp3_tx_frags(struct sk_buff *skb,
+				   struct mv_cfh_common *p_cfh,
+				   struct net_device *dev,
+				   struct pp3_tx_vq *vq_priv)
+{
+	int cpu = smp_processor_id();
+	skb_frag_t *frag = NULL;
+	int h_len = skb_headlen(skb);
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	struct pp3_group *group = dev_priv->groups[cpu];
+	int i;
+	unsigned int l3_l4_info;
+
+
+	/*STAT_DBG(group->stats.tx_sg_fsize[skb_shinfo(skb)->nr_frags]++);*/
+
+	p_cfh->ctrl = MV_CFH_RD_SET(0) | MV_CFH_LEN_SET(MV_PP3_CFH_PKT_SIZE) |
+		MV_CFH_MODE_SET(HMAC_CFH) | MV_CFH_PP_MODE_SET(PP_TX_PACKET);
+	p_cfh->plen_order = MV_CFH_PKT_LEN_SET(skb->len) | MV_CFH_REORDER_SET(REORD_NEW);
+	p_cfh->phys_l = 0;
+	p_cfh->marker_l = 0;
+	p_cfh->vm_bp = 0;
+
+	p_cfh->tag1 = MV_CFH_HWQ_SET(vq_priv->to_emac_hwq) |
+		MV_CFH_ADD_CRC_BIT_SET | MV_CFH_L2_PAD_BIT_SET;
+
+	l3_l4_info = mv_pp3_skb_tx_csum(skb, group);
+	if (l3_l4_info) {
+		/* QC bit set at cfh word1 only if l3 or l4 checksum are calc by HW*/
+		p_cfh->l3_l4_info = l3_l4_info;
+		p_cfh->ctrl |= MV_CFH_QC_BIT_SET;
+	}
+
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_SG) {
+		pr_cont("%s[(1st):tx-%d|sg_tx-%d|skb:%p|cfh:%p|ipsummed:%d]: ",
+			dev->name, group->stats.tx_bytes, group->stats.tx_sg_bytes, skb, p_cfh, skb->ip_summed);
+		pp3_dbg_skb_dump(skb);
+		pp3_dbg_cfh_hdr_dump(p_cfh);
+	}
+#endif
+
+	p_cfh++;
+
+	p_cfh->plen_order = MV_CFH_PKT_LEN_SET(h_len) | MV_CFH_REORDER_SET(REORD_NEW);
+	p_cfh->ctrl = MV_CFH_RD_SET(0) | MV_CFH_LEN_SET(MV_PP3_CFH_HDR_SIZE) |
+		MV_CFH_MODE_SET(HMAC_CFH) | MV_CFH_PP_MODE_SET(PP_TX_PACKET);
+
+	p_cfh->vm_bp = 0;
+	p_cfh->marker_l = 0;
+
+	p_cfh->phys_l = mv_pp3_os_dma_map_single(dev->dev.parent, skb->data, h_len, DMA_TO_DEVICE);
+	STAT_DBG(group->stats.tx_sg_frags++);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_SG) {
+		pr_cont("%s[sg_tx-%d|hd_len:%d(%p:%d) cfh:%p]: ", dev->name,
+			group->stats.tx_sg_bytes, h_len, skb->head, skb_headroom(skb), p_cfh);
+		pp3_dbg_cfh_hdr_dump(p_cfh);
+		mv_debug_mem_dump((void *)skb->head, h_len + skb_headroom(skb), 1);
+	}
+#endif
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		p_cfh++;
+
+		frag = &skb_shinfo(skb)->frags[i];
+		p_cfh->plen_order = MV_CFH_PKT_LEN_SET(frag->size) | MV_CFH_REORDER_SET(REORD_NEW);
+		p_cfh->ctrl = MV_CFH_RD_SET(0) | MV_CFH_LEN_SET(MV_PP3_CFH_PKT_SIZE) |
+			MV_CFH_MODE_SET(HMAC_CFH) | MV_CFH_PP_MODE_SET(PP_TX_PACKET);
+
+		p_cfh->vm_bp = 0;
+		p_cfh->marker_l = 0;
+
+		p_cfh->phys_l = mv_pp3_os_dma_map_page(dev->dev.parent, skb_frag_page(frag), frag->page_offset,
+							skb_frag_size(frag), DMA_TO_DEVICE);
+		STAT_DBG(group->stats.tx_sg_frags++);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+		if (dev_priv->flags & MV_PP3_F_DBG_SG) {
+			pr_cont("%s[sg_tx-%d|fr%d-%d(%p:%d) cfh:%p]: ", dev->name,
+				group->stats.tx_sg_bytes, i, skb_frag_size(frag), skb_frag_address(frag),
+				frag->page_offset, p_cfh);
+			pp3_dbg_cfh_hdr_dump(p_cfh);
+			mv_debug_mem_dump(skb_frag_address(frag), skb_frag_size(frag), 1);
+		}
+#endif
+	}
+
+	p_cfh->plen_order |= MV_CFH_LAST_BIT_SET;
+	p_cfh->marker_l = (unsigned int)skb;
+	p_cfh->vm_bp = MV_CFH_BPID_SET(pp3_cpus[cpu]->nic_txdone_pool->pool);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & (MV_PP3_F_DBG_SG | MV_PP3_F_DBG_TX)) {
+			pr_cont("%s:[(lst)tx-%d|sg_tx-%d|cfh:%p|skb:%p|ip_summed:%d]: ", dev->name,
+				group->stats.tx_bytes, group->stats.tx_sg_bytes, p_cfh, skb, skb->ip_summed);
+			pp3_dbg_cfh_hdr_dump(p_cfh);
+	}
+#endif
+
+	STAT_DBG(group->stats.tx_sg_bytes += (skb->len - MV_MH_SIZE));
+	STAT_DBG(group->stats.tx_sg_pkts++);
+}
+
+#endif /* if 0 */
+
+
+/*---------------------------------------------------------------------------*/
+/* PP3 Driver NIC mode get skb function only for case of CFH mode */
+static inline struct sk_buff *mv_pp3_skb_get(struct net_device *dev)
+{
+	/* TODO - support SKB recycle */
+	return mv_pp3_skb_alloc(dev, MV_PP3_CFH_PAYLOAD_MAX_SIZE, GFP_ATOMIC, NULL);
+}
+
+/*---------------------------------------------------------------------------*/
+/* PP3 driver receive function */
+static int mv_pp3_rx(struct net_device *dev, struct pp3_vport *cpu_vp, struct pp3_vq *rx_vq, int budget)
+{
+	struct pp3_swq *rx_swq = rx_vq->swq;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	struct pp3_cpu_shared *cpu_shared = cpu_vp->port.cpu.cpu_shared;
+	struct mv_cfh_common *cfh;
+	struct sk_buff *skb;
+	unsigned char *cfh_pdata;
+	struct pp3_pool *ppool;
+	int occ_dg, num_dg, cpu;
+	int wr_offset, cfh_data_len, pkt_len, cfh_len, buf_num, bpid = 0;
+	int rx_short = 0, rx_long = 0, rx_unknown = 0, rx_pkt_done = 0, rx_dg_done = 0;
+
+	occ_dg = mv_pp3_hmac_rxq_occ_get(rx_swq->frame_num, rx_swq->swq);
+	if (occ_dg == 0)
+		return 0;
+
+#ifdef PP3_INTERNAL_DEBUG
+	if (occ_dg > rx_swq->cur_size * MV_PP3_CFH_DG_MAX_NUM) {
+		debug_stop_rx = true;
+		pr_err("%s: bad occupied datagram counter %d received on frame %d, queue %d\n",
+				__func__, occ_dg, rx_swq->frame_num, rx_swq->swq);
+		return 0;
+	}
+#endif
+	mv_pp3_os_cache_io_sync(dev->dev.parent);
+
+	cpu = cpu_vp->port.cpu.cpu_ctrl->cpu;
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_RX) {
+		if (occ_dg)
+			pr_info("\n---------- %s [rx-%d]: rxq = %d:%d, cpu = %d, budget = %d, occ_dg = %d\n",
+				dev->name, DEV_PRIV_STATS(dev_priv, cpu)->rx_pkt_dev,
+				rx_swq->frame_num, rx_swq->swq, cpu, budget, occ_dg);
+	}
+#endif
+
+	while ((occ_dg > 0) && (rx_pkt_done < budget)) {
+
+		/* check if queue was paused through RX */
+		if (!rx_vq->valid)
+			break;
+
+		cfh = (struct mv_cfh_common *)mv_pp3_hmac_rxq_next_cfh(rx_swq->frame_num, rx_swq->swq, &num_dg);
+#ifdef PP3_INTERNAL_DEBUG
+		if (num_dg == 0) {
+			debug_stop_rx = true;
+			break;
+		}
+
+		if (num_dg > occ_dg) {
+			mv_pp3_hmac_rxq_cfh_free(rx_swq->frame_num, rx_swq->swq, num_dg);
+			/* only part of CFH is moved to DRAM */
+			/* in next interrupt will processed full CFH */
+			pr_info("%s: only part of CFH is moved to DRAM (num_dg = %d, occ_dg = %d)\n",
+				dev->name, num_dg, occ_dg);
+
+			debug_stop_rx = true;
+
+			break;
+		}
+#endif
+		occ_dg -= num_dg;
+		rx_dg_done += num_dg;
+
+		if (!cfh) {
+			STAT_INFO(rx_swq->stats.pkts_errors++);
+			continue;
+		}
+		/* Prefetch CFH */
+		prefetch(cfh);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+		if (dev_priv->flags & MV_PP3_F_DBG_RX) {
+			pr_cont("\n********** %s [rx-%d]: ",
+				dev->name, DEV_PRIV_STATS(dev_priv, cpu)->rx_pkt_dev + rx_pkt_done);
+			pp3_dbg_cfh_rx_dump(cfh);
+		}
+#endif
+
+#ifdef PP3_INTERNAL_DEBUG
+		if (pp3_dbg_cfh_rx_checker(dev_priv, (u32 *)cfh) < 0) {
+			/*debug_stop_rx = true;*/
+			break;
+		}
+#endif
+		skb = (struct sk_buff *)cfh->marker_l;
+		if (skb) {
+			bpid = MV_CFH_BPID_GET(cfh->vm_bp);
+			if (cpu_shared->short_pool && (bpid == cpu_shared->short_pool->pool)) {
+				ppool = cpu_shared->short_pool;
+				rx_short++;
+			} else if (bpid == cpu_shared->long_pool->pool) {
+				ppool = cpu_shared->long_pool;
+				rx_long++;
+			} else {
+				ppool = NULL;
+				rx_unknown++;
+			}
+		}
+		/* write offset in 32 bytes granularity */
+		wr_offset = MV_CFH_WR_GET(cfh->ctrl) * MV_CFH_WR_RES;
+		cfh_len = MV_CFH_LEN_GET(cfh->ctrl);
+
+		pkt_len = MV_CFH_PKT_LEN_GET(cfh->plen_order);
+
+		pkt_len -= MV_PP3_CFH_MDATA_SIZE;
+
+		/* The following cases are supported:
+		*  1. cfh_len is 64 bytes, the whole packet is in DRAM buffer
+		*  2. cfh_len is always 128 bytes, packet header is in CFH.
+		*/
+		if (num_dg == MV_PP3_CFH_PKT_DG_SIZE) {
+			/* No packet in CFH. Only Common CFH part (32) + MetaData (32) */
+			/* The whole packet is in BM buffer (DRAM) */
+
+			/* prefetch 2 cache lines of packet header for read */
+			prefetch(skb->data);
+			prefetch(skb->data + cache_line_size());
+
+			cfh_data_len = 0;
+			STAT_DBG(cpu_vp->port.cpu.stats.rx_buf_pkt++);
+
+		} else {
+
+			cfh_pdata = (unsigned char *)cfh + MV_PP3_CFH_PKT_SIZE;
+			cfh_data_len = MV_MIN(pkt_len, MV_PP3_CFH_PAYLOAD_MAX_SIZE);
+
+			if (pkt_len < MV_PP3_CFH_PAYLOAD_MAX_SIZE) {
+				/* The whole packet is located in CFH. DRAM buffer is empty */
+				STAT_DBG(cpu_vp->port.cpu.stats.rx_cfh_pkt++);
+
+				skb = mv_pp3_skb_alloc(dev, MV_PP3_CFH_PAYLOAD_MAX_SIZE, GFP_ATOMIC, NULL);
+				if (unlikely(!skb)) {
+					STAT_ERR(rx_swq->stats.pkts_drop++);
+					DEV_PRIV_STATS(dev_priv, cpu)->rx_drop_dev++;
+					continue;
+				}
+
+			} else {
+				int delta;
+				/* Packet is split. Header (64 bytes) is in CFH, the rest is in BM buffer (DRAM) */
+				STAT_DBG(cpu_vp->port.cpu.stats.rx_split_pkt++);
+				/* prefetch 2 cache lines of packet header for write */
+				prefetchw(skb->data);
+				prefetchw(skb->data + cache_line_size());
+
+				delta = wr_offset - (cfh_data_len + skb_headroom(skb));
+				if (delta)
+					skb_reserve(skb, delta);
+			}
+
+			/* Copy data including MH */
+			/* skb->data and cfh_pdata are always aligned 4 bytes */
+			memcpy(skb->data, cfh_pdata, cfh_data_len);
+		}
+
+#ifdef CONFIG_MV_PP3_PTP_SERVICE
+		mv_pp3_is_pkt_ptp_rx_proc(dev_priv, cfh, pkt_len, skb->data, rx_pkt_done);
+#endif
+
+		/* RX function processing */
+		skb_put(skb, pkt_len);
+		skb_pull_inline(skb, MV_MH_SIZE);
+
+		/*copy meta data form CFH to skb buffer */
+		mv_pp3_mdata_copy_to_skb(dev, skb, cfh);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+		if (dev_priv->flags & MV_PP3_F_DBG_RX) {
+			pr_info("\n");
+			pp3_dbg_skb_dump(skb);
+			mv_debug_mem_dump((void *)skb->head, skb->len + skb_headroom(skb), 1);
+		}
+#endif
+		skb->ip_summed  = mv_pp3_rx_csum(cpu_vp, cfh, skb) ? CHECKSUM_UNNECESSARY : CHECKSUM_NONE;
+
+		rx_pkt_done++;
+
+		DEV_PRIV_STATS(dev_priv, cpu)->rx_bytes_dev += pkt_len - MV_MH_SIZE;
+		STAT_DBG(cpu_vp->port.cpu.stats.rx_netif++);
+		/* TODO remove rx_bytes from vport stats, use swq stats */
+		STAT_DBG(cpu_vp->port.cpu.stats.rx_bytes += pkt_len - MV_MH_SIZE);
+		STAT_DBG(rx_swq->stats.bytes += pkt_len - MV_MH_SIZE);
+
+		if (mv_pp3_gnss_skb_receive(dev, skb))
+			STAT_DBG(cpu_vp->port.cpu.stats.rx_netif_drop++);
+
+	} /* while */
+
+	/* refill short and long pools */
+	if (rx_short) {
+		ppool = cpu_shared->short_pool;
+		STAT_DBG(PPOOL_STATS(ppool, cpu)->buff_rx += rx_short);
+		buf_num = mv_pp3_pool_refill(dev, ppool, GFP_ATOMIC, rx_short);
+
+#ifdef PP3_INTERNAL_DEBUG
+		if (buf_num != rx_short) {
+			pr_err("%s: Can't refill buffer to BM pool #%d on cpu #%d\n",
+				dev->name, bpid, cpu);
+			debug_stop_rx = true;
+		}
+#endif
+	}
+
+	if (rx_long) {
+		ppool = cpu_shared->long_pool;
+		STAT_DBG(PPOOL_STATS(ppool, cpu)->buff_rx += rx_long);
+		buf_num = mv_pp3_pool_refill(dev, ppool, GFP_ATOMIC, rx_long);
+
+#ifdef PP3_INTERNAL_DEBUG
+		if (buf_num != rx_long) {
+			pr_err("%s: Can't refill buffer to BM pool #%d on cpu #%d\n",
+				dev->name, bpid, cpu);
+			debug_stop_rx = true;
+		}
+#endif
+	}
+
+	if (rx_unknown) {
+		/* Increment counter for packets from unknown pool */
+		STAT_DBG(cpu_vp->port.cpu.stats.rx_no_pool += rx_unknown);
+	}
+
+	DEV_PRIV_STATS(dev_priv, cpu)->rx_pkt_dev += rx_pkt_done;
+	STAT_DBG(rx_swq->stats.pkts += rx_pkt_done);
+
+	if (rx_dg_done > 0)
+		mv_pp3_hmac_rxq_occ_set(rx_swq->frame_num, rx_swq->swq, rx_dg_done);
+
+	return rx_pkt_done;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_pool_bufs_add(int buf_num, struct net_device *dev, struct pp3_pool *ppool)
+{
+	int size, i;
+
+	size = ppool->buf_size;
+
+	if (size == 0) {
+		pr_err("%s: invalid pool #%d state: buf_size = %d\n", __func__, ppool->pool, size);
+		return -EINVAL;
+	}
+
+	i = mv_pp3_pool_refill(dev, ppool, GFP_KERNEL, buf_num);
+
+	if (i != buf_num)
+		pr_err("Can't add all required buffers to BM pool #%d on cpu #%d\n",
+			ppool->pool, smp_processor_id());
+
+	ppool->buf_num += i;
+
+	ppool->in_use_thresh = ppool->buf_num / 4;
+
+	pr_info("%s pool #%d:  buf_size=%4d - %d of %d buffers added\n",
+		mv_pp3_pool_name_get(ppool), ppool->pool, size, i, buf_num);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Free number of buffers [buf_num] from BM pool [pool] */
+int mv_pp3_pool_bufs_free(int buf_num, struct net_device *dev, struct pp3_pool *ppool)
+{
+	unsigned long flags = 0;
+	int cpu = smp_processor_id();
+	struct pp3_cpu *cpu_ctrl;
+	int free_buf = 0, time_out = 0, buf_num_old;
+	int time_out_max = 1000;
+
+	cpu_ctrl = pp3_cpus[cpu];
+
+	if (!cpu_ctrl) {
+		pr_err("%s: CPU %d pointer in NULL\n", __func__, cpu);
+		return -EINVAL;
+	}
+
+	if (!ppool) {
+		pr_err("%s: pool pointer in NULL\n", __func__);
+		return -EINVAL;
+	}
+
+	if (buf_num == 0)
+		return 0;
+
+
+	buf_num_old = ppool->buf_num;
+
+	if (ppool->buf_num < buf_num)
+		/* cannot release more bufers than exist in pool */
+		buf_num = ppool->buf_num;
+
+	MV_LIGHT_LOCK(flags);
+	while ((time_out++ < time_out_max) && (buf_num > 0)) {
+		free_buf = pp3_pool_bufs_free_internal(buf_num, dev, ppool);
+
+		if (free_buf < 0) {
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+			pr_err("%s: Error, function failed. Try to release %d buffers\n",
+				__func__, buf_num);
+#endif
+			MV_LIGHT_UNLOCK(flags);
+			return -1;
+		}
+		buf_num -= free_buf;
+	}
+	MV_LIGHT_UNLOCK(flags);
+
+	pr_info("%s pool #%d:  buf_size=%4d - free %d of %d buffers\n",
+		mv_pp3_pool_name_get(ppool),
+		ppool->pool, ppool->buf_size, buf_num_old - ppool->buf_num, buf_num_old);
+
+	if (time_out >= time_out_max) {
+		pr_err("%s: timeout - retries exceeded\n", __func__);
+		return -1;
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_set_mac_addr_internals(struct net_device *dev, u8 *mac)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int i;
+
+	if (mv_pp3_shared_initialized(pp3_priv)) {
+		if (pp3_fw_port_mac_addr(dev_priv->vport->vport, mac) < 0) {
+			pr_err("%s: MAC address set command failed\n", __func__);
+			return -1;
+		}
+	}
+	/* set addr in the device */
+	for (i = 0; i < MV_MAC_ADDR_SIZE; i++)
+		dev->dev_addr[i] = mac[i];
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_set_mac_addr(struct net_device *dev, void *p)
+{
+	struct sockaddr *addr = p;
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev || !addr) {
+		pr_err("%s: cannot change MAC for device %p", __func__, dev);
+		return -1;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (!is_valid_ether_addr(addr->sa_data))
+		return -EADDRNOTAVAIL;
+
+	if (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH) {
+		memcpy(dev->dev_addr, addr->sa_data, MV_MAC_ADDR_SIZE);
+		return 0;
+	}
+
+	if (!netif_running(dev)) {
+		if (mv_pp3_set_mac_addr_internals(dev, addr->sa_data) == -1)
+			goto error;
+	} else {
+		if (dev->netdev_ops->ndo_stop(dev)) {
+			pr_err("%s: stop interface failed\n", dev->name);
+			goto error;
+		}
+
+		if (mv_pp3_set_mac_addr_internals(dev, addr->sa_data) == -1)
+			goto error;
+
+		if (dev->netdev_ops->ndo_open(dev)) {
+			pr_err("%s: start interface failed\n", dev->name);
+			goto error;
+		}
+	}
+	return 0;
+error:
+	pr_err("%s: set mac addr failed\n", dev->name);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+struct net_device_stats *mv_pp3_get_stats(struct net_device *dev)
+{
+	struct pp3_netdev_stats *stats;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int cpu;
+
+	u32 tx_pkts, rx_pkts, tx_bytes, rx_bytes, tx_drp, rx_drp, rx_err;
+
+
+	tx_pkts = rx_pkts = tx_bytes = rx_bytes = tx_drp = rx_drp = rx_err = 0;
+
+	for_each_online_cpu(cpu) {
+		stats = per_cpu_ptr(dev_priv->dev_stats, cpu);
+
+		tx_pkts += stats->tx_pkt_dev;
+		rx_pkts += stats->rx_pkt_dev;
+
+		tx_bytes += stats->tx_bytes_dev;
+		rx_bytes += stats->rx_bytes_dev;
+
+		tx_drp += stats->tx_drop_dev;
+		rx_drp += stats->rx_drop_dev;
+
+		rx_err += stats->rx_err_dev;
+	}
+
+	dev->stats.tx_packets = tx_pkts;
+	dev->stats.rx_packets = rx_pkts;
+
+	dev->stats.tx_bytes = tx_bytes;
+	dev->stats.rx_bytes = rx_bytes;
+
+	dev->stats.tx_dropped = tx_drp;
+	dev->stats.rx_dropped = rx_drp;
+
+	dev->stats.rx_errors = rx_err;
+
+	return &(dev->stats);
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_proc_mac_mc(struct net_device *dev)
+{
+	int macs_list_size;
+	unsigned char *macs_list;
+	struct netdev_hw_addr *ha;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int err, offset = 0;
+
+	macs_list_size = netdev_hw_addr_list_count(&dev->mc);
+
+	/* currently FW support up to three mcast addresses */
+	if (macs_list_size >= MV_PP3_MAC_ADDR_NUM) {
+		/* in such case last addresses will not passed to FW */
+		pr_err("Error: support up to %d mcast address\n", MV_PP3_MAC_ADDR_NUM - 1);
+		return -1;
+	}
+
+	macs_list = kzalloc(macs_list_size * MV_MAC_ADDR_SIZE, GFP_ATOMIC);
+
+	if (!macs_list) {
+		pr_err("%s: out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	netdev_for_each_mc_addr(ha, dev) {
+		memcpy(&macs_list[offset], ha->addr, MV_MAC_ADDR_SIZE);
+/*
+		pr_info("%02x:%02x:%02x:%02x:%02x:%02x\n",
+			macs_list[offset + 0], macs_list[offset + 1], macs_list[offset + 2],
+			macs_list[offset + 3], macs_list[offset + 4], macs_list[offset + 5]);
+*/
+		offset += MV_MAC_ADDR_SIZE;
+	}
+
+	err = pp3_fw_vport_mac_list_set(dev_priv->vport->vport, macs_list_size, macs_list);
+	if (err < 0) {
+		pr_err("%s error: %s failed to send mcast list to FW\n", __func__, dev->name);
+		kfree(macs_list);
+		return -1;
+	}
+	kfree(macs_list);
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+void mv_pp3_set_rx_mode(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	unsigned char l2_ops;
+	int vport;
+
+	if (!mv_pp3_shared_initialized(pp3_priv))
+		return;
+
+	if (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)
+		return;
+
+	if (dev->flags & IFF_PROMISC)
+		/* Accept all */
+		l2_ops = MV_NSS_PROMISC_MODE;
+	else {
+		if (dev->flags & IFF_ALLMULTI)
+			/* Accept all multicast */
+			l2_ops = MV_NSS_ALL_MCAST_MODE;
+		else {
+			/* Accept Unicast to me */
+			l2_ops = MV_NSS_NON_PROMISC_MODE;
+			/* Accept initialized Multicast */
+			if (!netdev_mc_empty(dev))
+				if (mv_pp3_proc_mac_mc(dev) < 0) {
+					pr_err("%s: failed to set multicast list\n", __func__);
+					return;
+				}
+		}
+	}
+	vport = dev_priv->vport->vport;
+	/* set/clear relevant bits in fw l2 ops bitmap */
+	pp3_fw_port_l2_filter_mode(vport, MV_NSS_L2_UCAST_PROMISC, l2_ops & BIT(MV_NSS_L2_UCAST_PROMISC));
+	pp3_fw_port_l2_filter_mode(vport, MV_NSS_L2_MCAST_PROMISC, l2_ops & BIT(MV_NSS_L2_MCAST_PROMISC));
+	pp3_fw_port_l2_filter_mode(vport, MV_NSS_L2_BCAST_ADM, l2_ops & BIT(MV_NSS_L2_BCAST_ADM));
+
+	/* Update l2_options field in virtual port */
+	dev_priv->vport->port.emac.l2_options &=
+		~(BIT(MV_NSS_L2_UCAST_PROMISC) | BIT(MV_NSS_L2_MCAST_PROMISC) | BIT(MV_NSS_L2_BCAST_ADM));
+	dev_priv->vport->port.emac.l2_options |= l2_ops;
+}
+
+/* Set CPU affinity (default CPU) for network interface */
+/* This CPU will process ingress traffic if RSS is disabled */
+int mv_pp3_cpu_affinity_set(struct net_device *dev, int cpu)
+{
+	struct pp3_dev_priv *dev_priv;
+	struct pp3_vport *vp_priv;
+
+	if (mv_pp3_max_check(cpu, nr_cpu_ids, "cpu"))
+		return -1;
+
+	dev_priv = MV_PP3_PRIV(dev);
+	if (!dev_priv) {
+		pr_err("Can't set cpu affinity - %s in not initialized\n", dev->name);
+		return -1;
+	}
+	vp_priv = dev_priv->vport;
+	if (vp_priv) {
+		if (!dev_priv->cpu_vp[cpu] || !cpumask_test_cpu(cpu, &dev_priv->rx_cpus)) {
+			pr_err("%s: Unexpected CPU affinity %d\n", dev->name, cpu);
+			return -1;
+		}
+
+		if (pp3_fw_vport_def_dest_set(vp_priv->vport, MV_PP3_CPU_VPORT_ID(cpu)) < 0) {
+			pr_warn("%s Error: FW vport %d default destination update failed\n",
+				__func__, vp_priv->vport);
+			return -1;
+		}
+		vp_priv->dest_vp = MV_PP3_CPU_VPORT_ID(cpu);
+	}
+	return 0;
+}
+
+/*--------------------------------------------------------------------------- *
+ * mv_pp3_late_init							      *
+ * use this to any late stage initialion or semantic validattion.	      *
+ *----------------------------------------------------------------------------*/
+static int mv_pp3_late_init(struct net_device *dev)
+{
+	dev->features = NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_RXCSUM;
+
+	dev->hw_features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_RXCSUM;
+
+#ifdef CONFIG_MV_PP3_SG
+	dev->features |= NETIF_F_SG;
+	dev->hw_features |= NETIF_F_SG;
+
+#ifdef CONFIG_MV_PP3_TSO
+	dev->features |= NETIF_F_TSO;
+	dev->hw_features |= NETIF_F_TSO;
+#endif /* CONFIG_MV_PP3_TSO */
+#endif /* CONFIG_MV_PP3_SG */
+
+	dev->vlan_features |= dev->features;
+
+	return 0;
+}
+
+static netdev_features_t mv_pp3_netdev_fix_features(struct net_device *dev, netdev_features_t features)
+{
+	if (MV_MAX_PKT_SIZE(dev->mtu) > MV_PP3_TX_CSUM_MAX_SIZE) {
+		if (features & (NETIF_F_IP_CSUM | NETIF_F_TSO)) {
+			features &= ~(NETIF_F_IP_CSUM | NETIF_F_TSO);
+			pr_warn("%s: NETIF_F_IP_CSUM and NETIF_F_TSO not supported for packet size larger than %d bytes\n",
+					dev->name, MV_PP3_TX_CSUM_MAX_SIZE);
+		}
+	}
+	return features;
+}
+
+/*---------------------------------------------------------------------------*/
+/* Initialize emac data in network device interface			     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_netdev_set_emac_params(struct net_device *dev, struct device_node *np)
+{
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev) {
+		pr_err("%s: network device pointer is NULL\n", __func__);
+		goto err;
+	}
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (of_property_read_u32(np, "id", &dev_priv->id)) {
+		pr_err("could not get port ID\n");
+		goto err;
+	}
+	mv_pp3_ftd_mac_data_get(np, &dev_priv->mac_data);
+	mv_pp3_fdt_mac_address_get(np, dev_priv->dev->dev_addr);
+
+	dev->ethtool_ops = &mv_pp3_ethtool_ops;
+
+	/* set mac connectivity flag */
+	set_bit(MV_PP3_F_MAC_CONNECT_BIT, &(dev_priv->flags));
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_netdev_delete(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv;
+
+	if (!dev)
+		return;
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	if (!dev_priv)
+		return;
+
+	/*
+	TODO:
+	free cpu shared memory
+	dev statistics
+	unregister network device
+	mv_pp3_dev_priv_delete(dev_priv);
+	free_netdev(dev);
+	*/
+
+	pr_info("%s: not implemented yet\n", dev->name);
+}
+
+/*---------------------------------------------------------------------------*/
+/* Allocate and initialize net_device structures			     */
+/*---------------------------------------------------------------------------*/
+struct net_device *mv_pp3_netdev_init(const char *name, int rx_vqs, int tx_vqs)
+{
+	struct pp3_dev_priv *dev_priv;
+	struct net_device *dev;
+	int rxq_num, txq_num;
+	int mtu = 1500;
+
+	rxq_num = txq_num = nr_cpu_ids;
+
+	/* RXQs and TXQs per CPU */
+	dev = alloc_etherdev_mqs(sizeof(struct pp3_dev_priv), txq_num, rxq_num);
+	if (!dev)
+		return NULL;
+
+	dev->tx_queue_len = CONFIG_MV_PP3_TXQ_SIZE;
+	dev->watchdog_timeo = 5 * HZ;
+
+	SET_NETDEV_DEV(dev, mv_pp3_dev_get(pp3_priv));
+
+	dev->mtu = mv_pp3_check_mtu_valid(mtu);
+	if (dev->mtu < 0)
+		return NULL;
+
+	dev_priv = MV_PP3_PRIV(dev);
+
+	memset(dev_priv, 0, sizeof(struct pp3_dev_priv));
+
+	dev_priv->dev = dev;
+
+	dev_priv->rxqs_per_cpu = rx_vqs;
+	dev_priv->txqs_per_cpu = tx_vqs;
+	/* Init rxq size and txq size */
+	dev_priv->rxq_capacity = CONFIG_MV_PP3_RXQ_SIZE;
+	dev_priv->txq_capacity = CONFIG_MV_PP3_TXQ_SIZE;
+	cpumask_copy(&dev_priv->rx_cpus, cpu_possible_mask);
+
+	/* Init rx/tx time/packet coalesce */
+	dev_priv->rx_time_coal = CONFIG_MV_PP3_RX_COAL_USEC;
+	dev_priv->rx_pkt_coal = CONFIG_MV_PP3_RX_COAL_PKTS;
+	dev_priv->tx_done_pkt_coal = CONFIG_MV_PP3_TXDONE_COAL_PKTS;
+	dev_priv->tx_done_time_coal = MV_PP3_TXDONE_TIMER_USEC_PERIOD;
+
+	/* alloc shared cpu struct, long and short pools */
+	dev_priv->cpu_shared = mv_pp3_cpu_shared_alloc(pp3_priv);
+	if (!dev_priv->cpu_shared)
+		goto err_free_netdev;
+
+	dev_priv->dev_stats = alloc_percpu(struct pp3_netdev_stats);
+	if (!dev_priv->dev_stats)
+		goto err_free_netdev;
+
+	dev->netdev_ops = &mv_pp3_netdev_ops;
+
+	strcpy(dev->name, name);
+
+	if (register_netdev(dev) < 0) {
+		dev_err(&dev->dev, "failed to register\n");
+		goto err_free_netdev;
+	}
+
+#ifndef CONFIG_MV_PP3_GRO
+	/* register_netdev() always sets NETIF_F_GRO via NETIF_F_SOFT_FEATURES */
+	dev->features &= ~NETIF_F_GRO;
+#endif /* CONFIG_MV_PP3_GRO */
+
+	if (pp3_netdev_next < pp3_ports_num) {
+		pp3_netdev[pp3_netdev_next++] = dev_priv;
+		return dev;
+	}
+
+	pr_err("%s Error: driver support up to %d network devices\n", __func__, pp3_ports_num);
+
+err_free_netdev:
+	mv_pp3_netdev_delete(dev);
+	free_netdev(dev);
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_netdev_show(struct net_device *dev)
+{
+	char cpus_str[16];
+	struct pp3_pool *ppool;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	scnprintf(cpus_str, sizeof(cpus_str), "%*pb", cpumask_pr_args(&dev_priv->rx_cpus));
+
+	pr_info("  o Loading network interface %s: mtu = %d, cpu_mask = 0x%s\n",
+		dev->name, dev->mtu, cpus_str);
+
+	if (test_bit(MV_PP3_F_MAC_CONNECT_BIT, &dev_priv->flags)) {
+		pr_info("\t  o emac #%d         : %s (%d)\n", dev_priv->id,
+			mv_port_mode_str(dev_priv->mac_data.port_mode),
+			dev_priv->mac_data.port_mode);
+	}
+	pr_info("\t  o RX Queue support: %d VQs * %d CFHs\n",
+		dev_priv->rxqs_per_cpu, dev_priv->rxq_capacity);
+
+	pr_info("\t  o TX Queue support: %d VQs * %d CFHs\n",
+		dev_priv->txqs_per_cpu, dev_priv->txq_capacity);
+
+	ppool = dev_priv->cpu_shared->long_pool;
+	if (ppool) {
+		pr_cont("\t  o RX long pool    : capacity = %d packets - ", ppool->capacity);
+		pr_cont("%d bytes of coherent memory allocated\n", ppool->capacity * 2 * sizeof(unsigned int));
+	}
+
+	ppool = dev_priv->cpu_shared->short_pool;
+	if (ppool) {
+		pr_cont("\t  o RX short pool   : capacity = %d packets - ", ppool->capacity);
+		pr_cont("%d bytes of coherent memory allocated\n", ppool->capacity * 2 * sizeof(unsigned int));
+	}
+
+	ppool = dev_priv->cpu_shared->txdone_pool;
+	if (ppool) {
+		pr_info("\t  o TX done pool    : capacity = %d packets - ", ppool->capacity);
+		pr_cont("%d bytes of coherent memory allocated\n", ppool->capacity * 2 * sizeof(unsigned int));
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/* alloc global structure memory					     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_netdev_global_init(struct mv_pp3 *priv)
+{
+	/* interrupts mode */
+	mv_pp3_run_hmac_interrupts = 1;
+	mv_pp3_irq_rx_base = mv_pp3_irq_base_get(priv);
+	pp3_ports_num = MV_PP3_DEV_NUM;
+	pp3_netdev_next = 0;
+
+	pp3_netdev = kzalloc(pp3_ports_num * sizeof(struct pp3_dev_priv *), GFP_KERNEL);
+	if (!pp3_netdev)
+		return -ENOMEM;
+
+	pp3_priv = priv;
+
+	return 0;
+
+	kfree(pp3_netdev);
+
+	pr_err("%s: out of memory\n", __func__);
+	return -ENOMEM;
+}
+
+/*---------------------------------------------------------------------------*/
+/* return true if txdoen pool is empty, otherwise return false               */
+static bool mv_pp3_dev_txdone_is_empty(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *cpu_vp;
+	int cpu;
+
+	if (!dev_priv) {
+		pr_err("%s: invalid param", __func__);
+		return -1;
+	}
+
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+
+		if (cpu_vp && cpu_vp->port.cpu.txdone_todo)
+			return false;
+	}
+
+	return true;
+}
+
+/*---------------------------------------------------------------------------*/
+
+/* Update number of buffers in the pool accordingly with new value */
+static int mv_pp3_dev_pool_update(struct net_device *dev, struct pp3_pool *ppool, int size)
+{
+	int rc = 0;
+
+	if (size > ppool->capacity) {
+		ppool->pool_size = ppool->capacity;
+		pr_warn("%s: Warning! %d pool capacity %d is less than recommended value %d\n",
+			__func__, ppool->pool, ppool->capacity, size);
+	} else
+		ppool->pool_size = size;
+
+	if (ppool->buf_num < ppool->pool_size)
+		rc = mv_pp3_pool_bufs_add(ppool->pool_size - ppool->buf_num, dev, ppool);
+	else if (ppool->buf_num > ppool->pool_size)
+		rc = mv_pp3_pool_bufs_free(ppool->buf_num - ppool->pool_size, dev, ppool);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_dev_pools_empty(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_pool *ppool;
+
+	if (!dev_priv) {
+		pr_err("%s: invalid param", __func__);
+		return -1;
+	}
+
+	ppool = dev_priv->cpu_shared->long_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, atomic_read(&ppool->in_use));
+
+	ppool = dev_priv->cpu_shared->short_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, atomic_read(&ppool->in_use));
+
+	ppool = dev_priv->cpu_shared->lro_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, atomic_read(&ppool->in_use));
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_rx_pool_size_calc(struct pp3_dev_priv *dev_priv)
+{
+	int rxq, cpu, size = 0;
+	struct pp3_vport *vp;
+	struct pp3_vq *vq;
+
+	/* Number of buffers in the pool must be more than: */
+	/* number of CPUs * number of RXQs per CPU * maximum number of packets in each RX SWQ */
+	for_each_possible_cpu(cpu) {
+		vp = dev_priv->cpu_vp[cpu];
+		if (!vp)
+			continue;
+
+		for (rxq = 0; rxq < vp->rx_vqs_num; rxq++) {
+			vq = vp->rx_vqs[rxq];
+			if (!vq || !vq->swq)
+				continue;
+
+			size += dev_priv->rxq_capacity;
+		}
+	}
+	/* Add extra 2000 buffers for each pool */
+	size += MV_PP3_RX_BUFS_EXTRA;
+
+	return size;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_pools_fill(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_pool *ppool;
+	int size;
+
+	if (!dev_priv) {
+		pr_err("%s: invalid param", __func__);
+		return -1;
+	}
+
+	size = mv_pp3_dev_rx_pool_size_calc(dev_priv);
+
+
+	ppool = dev_priv->cpu_shared->long_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, size);
+
+	ppool = dev_priv->cpu_shared->short_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, size);
+
+	ppool = dev_priv->cpu_shared->lro_pool;
+	if (ppool)
+		mv_pp3_dev_pool_update(dev_priv->dev, ppool, size);
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_dev_napi_enable(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+	for_each_possible_cpu(cpu)
+		if (dev_priv->cpu_vp[cpu])
+			napi_enable(&dev_priv->cpu_vp[cpu]->port.cpu.napi);
+}
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_dev_napi_disable(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu)
+		if (dev_priv->cpu_vp[cpu]) {
+			/* wait until napi stop transmit */
+			napi_synchronize(&dev_priv->cpu_vp[cpu]->port.cpu.napi);
+			napi_disable(&dev_priv->cpu_vp[cpu]->port.cpu.napi);
+		}
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_rxq_proc_done(struct pp3_vq *rx_vq)
+{
+	int time_out = 0;
+	int swq = rx_vq->swq->swq;
+	int frame = rx_vq->swq->frame_num;
+	static int time_out_max = 1000;
+
+	while (mv_pp3_hmac_rxq_occ_get(frame, swq) &&
+			(time_out <= time_out_max))
+		time_out++;
+
+	if (time_out > time_out_max) {
+		pr_err("Error %s: frame %d, queue %d proc retries exceeded\n",
+			__func__, frame, swq);
+		return -1;
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_txq_proc_done(struct pp3_vq *tx_vq)
+{
+	int time_out = 0;
+	int swq = tx_vq->swq->swq;
+	int frame = tx_vq->swq->frame_num;
+	static int time_out_max = 1000;
+
+	/* Control path function  - do not remove delay from loop */
+
+	while (mv_pp3_hmac_txq_occ_get(frame, swq) &&
+			(time_out <= time_out_max)) {
+		mdelay(1);
+		time_out++;
+	}
+
+	if (time_out > time_out_max) {
+		pr_err("Error %s: frame %d, queue %d proc retries exceeded\n",
+			__func__, frame, swq);
+		return -1;
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_queues_proc_done(struct pp3_dev_priv *dev_priv)
+{
+	struct pp3_vport *cpu_vp;
+	int vq, cpu;
+
+
+	for_each_possible_cpu(cpu) {
+
+		cpu_vp = dev_priv->cpu_vp[cpu];
+
+		if (!cpu_vp)
+			continue;
+
+		for (vq = 0; vq < cpu_vp->rx_vqs_num; vq++) {
+
+			if (!cpu_vp->rx_vqs[vq])
+				continue;
+
+			if (mv_pp3_dev_rxq_proc_done(cpu_vp->rx_vqs[vq]))
+				return -1;
+		}
+
+		for (vq = 0; vq < cpu_vp->tx_vqs_num; vq++) {
+
+			if (!cpu_vp->tx_vqs[vq])
+				continue;
+
+			if (mv_pp3_dev_txq_proc_done(cpu_vp->tx_vqs[vq]))
+				return -1;
+		}
+	}
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+/*
+delete for network device next private fields
+	1 - CPU virtual port (per CPU)
+	2 - EMAC virtual port
+	3 - device statistics (per CPU)
+*/
+static void mv_pp3_dev_priv_delete(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+
+	if (!dev_priv)
+		return;
+
+	for_each_possible_cpu(cpu) {
+		mv_pp3_vport_delete(dev_priv->cpu_vp[cpu]);
+		dev_priv->cpu_vp[cpu] = NULL;
+	}
+
+	mv_pp3_vport_delete(dev_priv->vport);
+	dev_priv->vport = NULL;
+
+	free_percpu(dev_priv->dev_stats);
+}
+/*---------------------------------------------------------------------------*/
+/*
+alloc for network device next private fields
+	1 - CPU virtual port (per CPU)
+	2 - EMAC virtual port
+	3 - device statistics (per CPU)
+*/
+static int mv_pp3_dev_priv_alloc(struct pp3_dev_priv *dev_priv)
+{
+	static int cpu_vp_index = MV_PP3_INTERNAL_CPU_PORT_MIN;
+	int cpu, rx_vqs, tx_vqs;
+
+	if (!dev_priv)
+		goto err;
+
+	if (cpu_vp_index >= MV_PP3_INTERNAL_CPU_PORT_NUM)
+		goto err;
+
+	/* TODO: define default rxq_num and txq_num for emac virtual port */
+
+	tx_vqs = dev_priv->txqs_per_cpu;
+
+	if (test_bit(MV_PP3_F_MAC_CONNECT_BIT, &dev_priv->flags))
+		/* alloc emac virtual port */
+		dev_priv->vport = mv_pp3_vport_alloc(dev_priv->id, MV_PP3_NSS_PORT_ETH, 1, tx_vqs);
+	else
+		/* alloc external virtual port - vqs are not relevant */
+		dev_priv->vport = mv_pp3_vport_alloc(dev_priv->id, MV_PP3_NSS_PORT_EXT, 0, 0);
+
+	if (!dev_priv->vport)
+		goto oom;
+
+	for_each_possible_cpu(cpu) {
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus))
+			rx_vqs = dev_priv->rxqs_per_cpu;
+		else
+			rx_vqs = 0;
+		dev_priv->cpu_vp[cpu] = mv_pp3_vport_alloc(cpu_vp_index, MV_PP3_NSS_PORT_CPU, rx_vqs, tx_vqs);
+		if (!dev_priv->cpu_vp[cpu])
+			goto oom;
+
+		cpu_vp_index++;
+	}
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+oom:
+	mv_pp3_dev_priv_delete(dev_priv);
+	pr_err("%s: Out of memory\n", __func__);
+	return -ENOMEM;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_priv_sw_init(struct pp3_dev_priv *dev_priv)
+{
+	int cpu, ret_val;
+	struct pp3_vport *cpu_vp, *vp_priv;
+
+	if (!dev_priv)
+		goto err;
+
+	if (mv_pp3_cpu_shared_sw_init(dev_priv->cpu_shared, MV_RX_PKT_SIZE(dev_priv->dev->mtu)) < 0)
+		goto err;
+
+	vp_priv = dev_priv->vport;
+	/* Emac virtual port SW initialization. For emac interfaces ID == EMAC */
+	if (vp_priv->type == MV_PP3_NSS_PORT_ETH) {
+
+		/* eth interface use Linux standard functions, set ops to NULL */
+		dev_priv->cpu_shared->gnss_ops = NULL;
+
+		ret_val = mv_pp3_emac_vport_sw_init(vp_priv, dev_priv->id, &dev_priv->mac_data);
+		if (ret_val < 0)
+			goto err;
+
+		vp_priv->port.emac.mtu = dev_priv->dev->mtu;
+
+		/* create link change tasklet for interrupt handling */
+		tasklet_init(&vp_priv->port.emac.lc_tasklet,
+				mv_pp3_link_change_tasklet, (unsigned long)dev_priv);
+	} else {
+		/* set gnss ops to gnss (external) interface */
+		dev_priv->cpu_shared->gnss_ops = mv_nss_ops_get(dev_priv->dev);
+		if (dev_priv->cpu_shared->gnss_ops) {
+			if (dev_priv->cpu_shared->gnss_ops->register_iface(dev_priv->dev, &mv_pp3_nss_if_ops))
+				pr_err("%s: cannot register %s ops\n", __func__, dev_priv->dev->name);
+		} else
+			pr_err("%s: cannot get gnss ops for %s\n", __func__, dev_priv->dev->name);
+	}
+
+	/* Init cpu virtual ports */
+	for_each_possible_cpu(cpu) {
+		cpu_vp = dev_priv->cpu_vp[cpu];
+		if (!cpu_vp)
+			continue;
+
+		/* Init vport CPUs pointers */
+		cpu_vp->port.cpu.cpu_ctrl = mv_pp3_cpu_get(cpu);
+		cpu_vp->port.cpu.cpu_shared = dev_priv->cpu_shared;
+		cpu_vp->root = (void *)dev_priv->dev;
+
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus)) {
+			if (mv_pp3_cfg_dp_reserve_rxq(cpu_vp->vport, vp_priv->vport, cpu, cpu_vp->rx_vqs_num) < 0) {
+				pr_err("%s: vport #%d failed to reserve %d ingress vq on cpu %d\n", __func__,
+					cpu_vp->vport, cpu_vp->rx_vqs_num, cpu);
+				goto err;
+			}
+			/* set first cpu vport as emac vport dflt dest */
+			if (vp_priv->dest_vp == MV_NSS_PORT_NONE)
+				vp_priv->dest_vp = MV_PP3_CPU_VPORT_ID(cpu);
+		}
+
+		if (mv_pp3_cfg_dp_reserve_txq(cpu_vp->vport, vp_priv->vport, cpu, cpu_vp->tx_vqs_num) < 0) {
+			pr_err("%s: vport #%d failed to reserve %d egress vq on cpu %d\n", __func__,
+				cpu_vp->vport, cpu_vp->tx_vqs_num, cpu);
+			goto err;
+		}
+
+		if (mv_pp3_cpu_vport_sw_init(cpu_vp, &dev_priv->rx_cpus, cpu) < 0)
+			goto err;
+
+		/* Init cpu virtual port NAPI */
+		netif_napi_add(dev_priv->dev, &cpu_vp->port.cpu.napi, mv_pp3_poll, 64);
+
+		/* init txdone timer */
+		mv_pp3_timer_init(&cpu_vp->port.cpu.txdone_timer, cpu,
+					dev_priv->tx_done_time_coal, MV_PP3_TASKLET,
+					mv_pp3_txdone_timer_callback, (unsigned long)cpu_vp);
+
+
+		/* set cpu vport dflt dest to EMAC virtual port esle left unknown */
+		if (vp_priv->type == MV_PP3_NSS_PORT_ETH)
+			cpu_vp->dest_vp = vp_priv->vport;
+	}
+
+	/* init MC address link list */
+	INIT_LIST_HEAD(&dev_priv->mac_list);
+	dev_priv->mac_list_size = 0;
+
+	/* each emac interface placed in different frame, has its own profile N0 in frame */
+	/* all external interfaces work with time coalescing profile 1 has the same configuration */
+	if (vp_priv->type == MV_PP3_NSS_PORT_ETH)
+		dev_priv->rx_time_prof = 0;
+	else
+		dev_priv->rx_time_prof = 1;
+
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_dev_priv_hw_init(struct pp3_dev_priv *dev_priv)
+{
+	int cpu;
+
+	if (!dev_priv)
+		goto err;
+
+	if (mv_pp3_cpu_shared_hw_init(dev_priv->cpu_shared) < 0)
+		goto err;
+
+	if (dev_priv->vport->type == MV_PP3_NSS_PORT_ETH)
+		if (mv_pp3_emac_vport_hw_init(dev_priv->vport) < 0)
+			goto err;
+
+	for_each_possible_cpu(cpu) {
+		if (!dev_priv->cpu_vp[cpu])
+			continue;
+
+		if (mv_pp3_cpu_vport_hw_init(dev_priv->cpu_vp[cpu]) < 0)
+			goto err;
+
+		/* configure coalescing parameters */
+		if (cpumask_test_cpu(cpu, &dev_priv->rx_cpus)) {
+			if (mv_pp3_cpu_vport_rx_pkt_coal_set(dev_priv->cpu_vp[cpu], dev_priv->rx_pkt_coal) < 0)
+				goto err;
+			if (mv_pp3_cpu_vport_rx_time_prof_set(dev_priv->cpu_vp[cpu], dev_priv->rx_time_prof) < 0)
+				goto err;
+			if (mv_pp3_cpu_vport_rx_time_coal_set(dev_priv->cpu_vp[cpu], dev_priv->rx_time_coal) < 0)
+				goto err;
+		}
+	}
+	/* Configure default parameters for ingress VQs */
+	if (mv_pp3_dev_ingress_vqs_defaults_set(dev_priv->dev))
+		goto err;
+
+	/* Configure default parameters for egress VQs */
+	if (mv_pp3_dev_egress_vqs_defaults_set(dev_priv->dev))
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_open(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int emac;
+
+	/* link interrupts and emac are closed */
+
+	if (!mv_pp3_shared_initialized(pp3_priv))
+		if (mv_pp3_shared_start(pp3_priv)) {
+			pr_err("%s: mv_pp3_shared_start fail\n", __func__);
+			return -1;
+		}
+
+	if (!(dev_priv->flags & MV_PP3_F_INIT)) {
+		if (mv_pp3_dev_priv_alloc(dev_priv))
+			goto err;
+
+		if (mv_pp3_dev_priv_sw_init(dev_priv))
+			goto err;
+
+		if (mv_pp3_dev_priv_hw_init(dev_priv))
+			goto err;
+
+		if (mv_pp3_dev_fw_update(dev_priv))
+			goto err;
+
+		set_bit(MV_PP3_F_INIT_BIT, &(dev_priv->flags));
+	}
+
+	mv_pp3_dev_pools_fill(dev_priv);
+
+	mv_pp3_dev_napi_enable(dev_priv);
+
+	/* initialize net_device RX and link IRQs */
+	if (mv_pp3_dev_irqs_init(dev_priv))
+		goto err;
+
+	if (dev_priv->vport->type == MV_PP3_NSS_PORT_ETH) {
+		emac = dev_priv->vport->port.emac.emac_num;
+		/* config link according to status */
+		mv_pp3_dev_link_event(dev_priv);
+		/* Enable gop link event */
+		mv_pp3_gop_port_events_unmask(emac);
+	} else
+		mv_pp3_dev_up(dev_priv);
+
+	/* set device state in FW to enable */
+	mv_pp3_dev_fw_up(dev_priv);
+
+	set_bit(MV_PP3_F_IF_UP_BIT, &(dev_priv->flags));
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_dev_stop(struct net_device *dev)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	int emac;
+
+	clear_bit(MV_PP3_F_IF_UP_BIT, &(dev_priv->flags));
+
+	if (dev_priv->vport->type == MV_PP3_NSS_PORT_ETH) {
+		emac = dev_priv->vport->port.emac.emac_num;
+		/* Disable gop link event */
+		mv_pp3_gop_port_events_mask(emac);
+		/* disable EMAC RX processing */
+		mv_pp3_emac_rx_enable(emac, false);
+
+		mv_pp3_dev_down(dev_priv);
+	}
+
+	/* set device state in FW to disable */
+	mv_pp3_dev_fw_down(dev_priv);
+
+	mdelay(10);
+
+	mv_pp3_dev_napi_disable(dev_priv);
+
+	/* release network device RX and link IRQs */
+	mv_pp3_dev_irqs_free(dev_priv);
+
+	/* make sure that rxqs/txqs are empty*/
+	if (mv_pp3_dev_queues_proc_done(dev_priv))
+		return -1;
+
+	mv_pp3_dev_pools_empty(dev_priv);
+
+	if (!mv_pp3_dev_txdone_is_empty(dev_priv)) {
+		pr_err("%s: txdone pool is not empty\n", dev->name);
+		return -1;
+	}
+
+	pr_info("%s: stopped\n", dev->name);
+
+	return 0;
+}
+
+
+/* return positive if MTU is valid */
+static int mv_pp3_check_mtu_valid(int mtu)
+{
+	if (mtu < MV_MTU_MIN) {
+		pr_info("MTU value %d is too small, must be at least %d - Failed\n",
+			mtu, MV_MTU_MIN);
+		return -1;
+	}
+
+	if (mtu > MV_MTU_MAX) {
+		pr_info("MTU value %d is too large, set to %d\n",
+			mtu, MV_MTU_MAX);
+		mtu = MV_MTU_MAX;
+	}
+	return mtu;
+}
+
+static int mv_pp3_change_mtu_internals(struct net_device *dev, int mtu)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	struct pp3_pool *long_pool = dev_priv->cpu_shared->long_pool;
+	struct pp3_vport *emac_vp;
+
+	dev->mtu = mtu;
+
+	if (long_pool) {
+		mv_pp3_pool_long_sw_init(long_pool, long_pool->headroom,
+						MV_RX_PKT_SIZE(mtu));
+
+		if (pp3_fw_bm_pool_set(long_pool) < 0)
+			pr_warn("%s: FW long pool update failed\n", __func__);
+	}
+
+	emac_vp = dev_priv->vport;
+
+	emac_vp->port.emac.mtu = mtu;
+
+	if (pp3_fw_vport_mtu_set(emac_vp->vport, mtu) < 0)
+		pr_warn("%s: FW EMAC vport mtu set failed\n", __func__);
+
+	/* TODO - check if necessary */
+	/* netdev_update_features(dev); */
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static int mv_pp3_change_mtu(struct net_device *dev, int mtu)
+{
+	int is_up = 0;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	mtu = mv_pp3_check_mtu_valid(mtu);
+	if (mtu < 0)
+		return -EINVAL;
+
+	/* interface not initialized yet */
+	if (!test_bit(MV_PP3_F_INIT_BIT, &dev_priv->flags)) {
+		dev->mtu = mtu;
+		return 0;
+	}
+
+	/* Supported only for EMAC virtual ports */
+	if (!dev_priv->vport || (dev_priv->vport->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("%s: not supported for %s\n", __func__, dev->name);
+		return -1;
+	}
+
+	is_up = netif_running(dev);
+
+	if (is_up && dev->netdev_ops->ndo_stop(dev)) {
+		pr_err("%s: stop interface failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_pp3_change_mtu_internals(dev, mtu))
+		goto error;
+
+	if (is_up && dev->netdev_ops->ndo_open(dev)) {
+		pr_err("%s: start interface failed\n", dev->name);
+		goto error;
+	}
+
+	pr_info("%s: mtu changed\n", dev->name);
+	return 0;
+
+error:
+	pr_err("%s: change mtu failed\n", dev->name);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+#ifdef CONFIG_MV_PP3_FPGA
+static int mv_pp3_pci_probe(struct pci_dev *pdev,
+	const struct pci_device_id *ent)
+{
+	u32 gop_vbase, vbase_address;
+
+	/* code below relevant fot FPGA only */
+	if (pci_enable_device(pdev)) {
+		pr_err("Cannot enable PCI device, aborting\n");
+		return -1;
+	}
+
+	if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
+		pr_err("Cannot find proper PCI device base address, aborting\n");
+		return -ENODEV;
+	}
+
+	if (pci_request_regions(pdev, "mv_pp3_pci")) {
+		pr_err("Cannot obtain PCI resources, aborting\n");
+		return -ENODEV;
+	}
+
+	if (pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {
+		pr_err("No usable DMA configuration, aborting\n");
+		return -ENODEV;
+	}
+
+	vbase_address = (u32)pci_iomap(pdev, 0, 16*1024*1024);
+	if (!vbase_address)
+		pr_err("Cannot map device registers, aborting\n");
+
+	mv_hw_silicon_base_addr_set(vbase_address);
+	pr_info("NSS registers base      : VIRT = 0x%0x, size = %d KBytes\n", vbase_address, 16*1024);
+
+	gop_vbase = (u32)pci_iomap(pdev, 2, 64*1024);
+	if (!gop_vbase)
+		pr_err("Cannot map device GOP, aborting\n");
+	pr_info("GOP registers base      : VIRT = 0x%0x, size = %d KBytes\n", gop_vbase, 64);
+
+	pp3_gmac_base_addr_set(gop_vbase);
+
+	return 0;
+}
+
+static void mv_pp3_pci_remove(struct pci_dev *pdev)
+{
+	pr_err("%s:: called", __func__);
+}
+
+
+/*---------------------------------------------------------------------------*/
+static const struct pci_device_id fpga_id_table[] = {
+	{ 0x1234, 0x1234, PCI_ANY_ID, PCI_ANY_ID, 2, 0, },
+};
+
+MODULE_DEVICE_TABLE(pci, fpga_id_table);
+
+static struct pci_driver mv_pp3_pci_driver = {
+	.name	= "mv_pp3_pci",
+	.id_table = fpga_id_table,
+	.probe		= mv_pp3_pci_probe,
+	.remove		= mv_pp3_pci_remove,
+};
+#endif /* CONFIG_MV_PP3_FPGA */
+
+/*---------------------------------------------------------------------------*/
+
+MODULE_DESCRIPTION("Marvell PPv3 Network Driver - www.marvell.com");
+MODULE_AUTHOR("Dmitri Epshtein <dima@marvell.com>");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:" MV_PP3_SHARED_NAME);
+MODULE_ALIAS("platform:" MV_PP3_PORT_NAME);
+
+/*---------------------------------------------------------------------------*/
+static inline u8 mv_pp3_cos_get(struct sk_buff *skb)
+{
+	struct mv_nss_metadata *pmdata;
+
+	pmdata = (struct mv_nss_metadata *)mv_pp3_gnss_skb_mdata_get(skb->dev, skb);
+
+	if (pmdata)
+		return (u8)(pmdata->cos);
+
+	return skb->priority;
+}
+/*---------------------------------------------------------------------------*/
+/* PP3 Driver transmit function */
+static int mv_pp3_tx(struct sk_buff *skb, struct net_device *dev)
+{
+	struct mv_cfh_common *cfh;
+	int cpu = smp_processor_id();
+	int global_cpu_vp, vq = 0;
+	unsigned int l3_l4_info;
+	int total_free;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+	struct pp3_vport *cpu_vp = dev_priv->cpu_vp[cpu];
+	struct pp3_vq *tx_vq = NULL;
+	struct pp3_swq *tx_swq = NULL;
+	struct pp3_pool *ppool = NULL;
+	int pkt_len, rd_offs, cfh_data_len, cfh_dg_size, cfh_size;
+	unsigned long flags = 0;
+	bool pkt_in_cfh = false;
+	u8 cos;
+	u32 *pmdata;
+#ifdef CONFIG_MV_PP3_PTP_SERVICE
+	int ptp_ts_offs = 0;
+	int tx_ts_queue;
+#endif
+
+#ifdef PP3_INTERNAL_DEBUG
+	if (debug_stop_rx)
+		return NETDEV_TX_OK;
+#endif
+	MV_LIGHT_LOCK(flags);
+
+	/* No support for scatter-gather */
+	if (unlikely(skb_is_nonlinear(skb))) {
+		pr_err("%s: no support for scatter-gather\n", dev->name);
+		goto out;
+	}
+
+	/* get priority from mdata */
+	cos = mv_pp3_cos_get(skb);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (cos > MV_PP3_PRIO_NUM) {
+		pr_err("%s: cannot map packet priority %d to queue.\n", __func__, cos);
+		goto out;
+	}
+#endif
+
+	/* get vqueue mapped to priority */
+	vq = mv_pp3_egress_cos_to_vq_get(cpu_vp, cos);
+
+	/* virtual queue equal software queue */
+	tx_vq = cpu_vp->tx_vqs[vq];
+	tx_swq = tx_vq->swq;
+	/* Add dummy Marvell header to skb */
+	__skb_push(skb, MV_MH_SIZE);
+
+#ifdef CONFIG_MV_PP3_PTP_SERVICE
+	ptp_ts_offs = mv_pp3_is_pkt_ptp_tx(dev_priv, skb, &tx_ts_queue);
+	if (ptp_ts_offs > 0) {
+		/* Send filler or/and raise Queue priority if needed */
+		mv_pp3_send_filler_pkt_cfh(dev_priv, skb->data, cpu, &tx_vq, &tx_swq);
+	}
+#endif
+
+	pkt_len = skb_headlen(skb);
+	rd_offs = skb_headroom(skb);
+
+	pkt_in_cfh = (pkt_len <= MV_PP3_CFH_PAYLOAD_MAX_SIZE);
+	cfh_dg_size = MV_PP3_CFH_DG_MAX_NUM;
+	cfh_size = cfh_dg_size * MV_PP3_CFH_DG_SIZE;
+
+	/* get cfh*/
+	cfh = (struct mv_cfh_common *)mv_pp3_hmac_txq_next_cfh(tx_swq->frame_num, tx_swq->swq, cfh_dg_size);
+	if (!cfh) {
+		STAT_ERR(tx_swq->stats.pkts_errors++);
+		goto out;
+	}
+	prefetchw(cfh);
+
+	/* write meta data to CFH */
+	pmdata = mv_pp3_gnss_skb_mdata_get(skb->dev, skb);
+	if (pmdata)
+		mv_pp3_mdata_copy_to_cfh(pmdata, cfh);
+	else {
+		global_cpu_vp = MV_PP3_CPU_VPORT_ID(cpu_vp->port.cpu.cpu_num);
+		mv_pp3_mdata_build_on_cfh(global_cpu_vp, cpu_vp->dest_vp, cos, cfh);
+	}
+
+	cfh_data_len = MV_MIN(MV_PP3_CFH_PAYLOAD_MAX_SIZE, pkt_len);
+
+	/* Copy packet header to CFH */
+	memcpy((unsigned char *)cfh + MV_PP3_CFH_PKT_SIZE, skb->data, cfh_data_len);
+
+	cfh->plen_order = MV_CFH_PKT_LEN_SET(pkt_len + MV_PP3_CFH_MDATA_SIZE) |
+				MV_CFH_REORDER_SET(REORD_NEW) | MV_CFH_LAST_BIT_SET;
+
+	cfh->ctrl = MV_CFH_RD_SET(rd_offs + MV_PP3_CFH_PAYLOAD_MAX_SIZE) |
+			MV_CFH_LEN_SET(cfh_size) | MV_CFH_MDATA_BIT_SET |
+			MV_CFH_MODE_SET(HMAC_CFH) | MV_CFH_PP_MODE_SET(PP_TX_PACKET_NSS);
+
+	l3_l4_info = mv_pp3_skb_tx_csum(skb, cpu_vp);
+
+	if (l3_l4_info) {
+		/* QC bit set at cfh word1 only if l3 or l4 checksum are calc by HW*/
+		cfh->l3_l4_info = l3_l4_info;
+		cfh->ctrl |= MV_CFH_QC_BIT_SET;
+	}
+
+	if (pkt_in_cfh) {
+		/* CFH store packet data, pdata point to start point of payload data in cfh */
+
+		cfh->vm_bp = cfh->marker_l = cfh->phys_l = 0;
+
+		cfh->ctrl &= ~MV_CFH_RD_MASK;
+
+		/* TODO - add skb recycle support */
+		mv_pp3_skb_free(dev, skb);
+		STAT_DBG(cpu_vp->port.cpu.stats.tx_cfh_pkt++);
+	} else {
+		ppool = cpu_vp->port.cpu.cpu_shared->txdone_pool;
+		ppool->buf_num++;
+		cfh->vm_bp = MV_CFH_BPID_SET(ppool->pool);
+		cpu_vp->port.cpu.txdone_todo++;
+		cfh->marker_l = (unsigned int)skb;
+		/* Flush Cache */
+		cfh->phys_l = mv_pp3_os_dma_map_single(dev->dev.parent, skb->head,
+					       pkt_len + rd_offs, DMA_TO_DEVICE);
+	}
+
+	cfh->tag1 = MV_CFH_ADD_CRC_BIT_SET | MV_CFH_L2_PAD_BIT_SET;
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_TX) {
+		int pkt_num = DEV_PRIV_STATS(dev_priv, cpu)->tx_pkt_dev;
+
+		pr_cont("\n++++++++++ %s [tx-%d]: txq = %d:%d, cpu = %d\n",
+			dev->name, pkt_num, tx_swq->frame_num, tx_swq->swq, cpu);
+
+		pp3_dbg_cfh_hdr_dump(cfh);
+		pr_info("cfh metadata:\n");
+		mv_debug_mem_dump(((char *)(cfh) + MV_PP3_CFH_HDR_SIZE), MV_PP3_CFH_MDATA_SIZE, 1);
+		pr_info("cfh payload:\n");
+		mv_debug_mem_dump(((char *)(cfh) + MV_PP3_CFH_HDR_SIZE + MV_PP3_CFH_MDATA_SIZE),
+						cfh_size - (MV_PP3_CFH_HDR_SIZE + MV_PP3_CFH_MDATA_SIZE), 1);
+		pr_info("\n");
+		pp3_dbg_skb_dump(skb);
+		mv_debug_mem_dump((void *)skb->head, pkt_len + skb_headroom(skb), 1);
+	}
+#endif
+
+#ifdef CONFIG_MV_PP3_PTP_SERVICE
+	if (ptp_ts_offs > 0)
+		mv_pp3_ptp_pkt_proc_tx(dev_priv, cfh, pkt_len, ptp_ts_offs, tx_ts_queue);
+#endif
+
+	wmb();
+
+	/* transmit CFH */
+	mv_pp3_hmac_txq_send(tx_swq->frame_num, tx_swq->swq, cfh_dg_size);
+
+	DEV_PRIV_STATS(dev_priv, cpu)->tx_pkt_dev++;
+	DEV_PRIV_STATS(dev_priv, cpu)->tx_bytes_dev += (pkt_len - MV_MH_SIZE);
+
+	STAT_DBG(tx_swq->stats.pkts++);
+	STAT_DBG(cpu_vp->port.cpu.stats.tx_bytes += (pkt_len - MV_MH_SIZE));
+
+
+	if (ppool && (ppool->mode == POOL_MODE_TXDONE)) {
+		if (cpu_vp->port.cpu.txdone_todo > dev_priv->tx_done_pkt_coal) {
+			STAT_INFO(cpu_vp->port.cpu.stats.txdone++);
+			total_free = mv_pp3_tx_done(dev, dev_priv->tx_done_pkt_coal);
+			cpu_vp->port.cpu.txdone_todo -= total_free;
+		}
+		if (cpu_vp->port.cpu.txdone_todo)
+			mv_pp3_timer_add(&cpu_vp->port.cpu.txdone_timer);
+	}
+
+	MV_LIGHT_UNLOCK(flags);
+
+	return NETDEV_TX_OK;
+
+out:
+	mv_pp3_skb_free(dev, skb);
+
+	DEV_PRIV_STATS(dev_priv, cpu)->tx_drop_dev++;
+	STAT_INFO(tx_swq ? tx_swq->stats.pkts_drop++ : 0;);
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	if (dev_priv->flags & MV_PP3_F_DBG_TX)
+		pr_info("%s: packet is dropped.\n", __func__);
+#endif
+
+	MV_LIGHT_UNLOCK(flags);
+
+	return NETDEV_TX_OK;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_rx_cpus_set(struct net_device *dev, int mask)
+{
+	int cpu;
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (dev_priv->flags & MV_PP3_F_INIT) {
+		pr_err("%s: Can't set rx_cpus after init", dev->name);
+		return -1;
+	}
+	cpumask_clear(&dev_priv->rx_cpus);
+	for_each_possible_cpu(cpu) {
+		if (mask & BIT(cpu))
+			cpumask_set_cpu(cpu, &dev_priv->rx_cpus);
+	}
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_dev_rxqs_set(struct net_device *dev, int rxqs)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (dev_priv->flags & MV_PP3_F_INIT) {
+		pr_err("%s: Can't change number of RXQs after init", dev->name);
+		return -1;
+	}
+	dev_priv->rxqs_per_cpu = rxqs;
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dev_txqs_set(struct net_device *dev, int txqs)
+{
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	if (dev_priv->flags & MV_PP3_F_INIT) {
+		pr_err("%s: Can't change number of TXQs after init", dev->name);
+		return -1;
+	}
+
+	dev_priv->txqs_per_cpu = txqs;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_dev_init_show(struct net_device *dev)
+{
+	char cpus_str[16];
+	struct pp3_dev_priv *dev_priv = MV_PP3_PRIV(dev);
+
+	scnprintf(cpus_str, sizeof(cpus_str), "%*pb", cpumask_pr_args(&dev_priv->rx_cpus));
+
+	pr_info("------- %s parameters -------\n", dev->name);
+	pr_info("Number of RX VQs         : %d\n", dev_priv->rxqs_per_cpu);
+	pr_info("Number of TX VQs         : %d\n", dev_priv->txqs_per_cpu);
+	pr_info("CPUs mask                : 0x%s\n", cpus_str);
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_dev_rx_pause(struct net_device *dev, int cos)
+{
+	int vq;
+
+	if (mv_pp3_dev_ingress_cos_to_vq_get(dev, cos, &vq))
+		return;
+
+	mv_pp3_dev_vqs_proc_cfg(dev, vq, false);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_dev_rx_resume(struct net_device *dev, int cos)
+{
+	int vq;
+
+	if (mv_pp3_dev_ingress_cos_to_vq_get(dev, cos, &vq))
+		return;
+
+	mv_pp3_dev_vqs_proc_cfg(dev, vq, true);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+
+
+static const struct net_device_ops mv_pp3_netdev_ops = {
+	.ndo_open            = mv_pp3_dev_open,
+	.ndo_start_xmit      = mv_pp3_tx,
+	.ndo_get_stats	     = mv_pp3_get_stats,
+	.ndo_stop            = mv_pp3_dev_stop,
+	.ndo_change_mtu      = mv_pp3_change_mtu,
+	.ndo_set_rx_mode     = mv_pp3_set_rx_mode,
+	.ndo_set_mac_address = mv_pp3_set_mac_addr,
+	.ndo_init	     = mv_pp3_late_init,
+	.ndo_fix_features    = mv_pp3_netdev_fix_features,
+/*
+	.ndo_select_queue    = mv_pp3_select_txq,
+	.ndo_tx_timeout      = mv_pp3_tx_timeout,
+	.ndo_get_stats64     = mvneta_get_stats64,
+*/
+};
+
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.h
new file mode 100644
index 0000000..4a22644
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev.h
@@ -0,0 +1,260 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_netdev_h__
+#define __mv_netdev_h__
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/if_vlan.h>
+#include <linux/mv_pp3.h>
+#include <net/ip.h>
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "mv_netdev_structs.h"
+#include "mv_dev_dbg.h"
+#include "hmac/mv_hmac.h"
+#include "common/mv_stack.h"
+#include "vport/mv_pp3_vport.h"
+
+#define PP3_INTERNAL_DEBUG
+
+#ifdef PP3_INTERNAL_DEBUG
+int mv_pp3_ctrl_internal_debug_set(int en);
+bool mv_pp3_is_internal_debug(void);
+#endif
+
+#define TOS_TO_DSCP(tos)	((tos) >> 2)
+
+/* Default DSCP to Priority mapping: 0-7 -> 0, 8-15 -> 1, 16-23 -> 2, 56 - 63 -> 7 */
+#define DSCP_TO_PRIO(dscp)	(((dscp) >> 3) & 0x7)
+
+#define MV_PP3_PROC_RXQ_INDEX_GET(cpu, ind) (cpu.napi_proc_qs[cpu.napi_master_array][ind])
+
+/*---------------------------------------------------------------------------*/
+/*				Function prototypes                          */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_netdev_global_init(struct mv_pp3 *priv);
+int mv_pp3_netdev_close_all(void);
+int mv_pp3_netdev_close(struct net_device *dev);
+void mv_pp3_netdev_show(struct net_device *dev);
+int mv_pp3_dev_num_get(void);
+struct pp3_dev_priv *mv_pp3_dev_priv_get(int i);
+struct net_device *mv_pp3_vport_dev_get(int vport);
+struct net_device *mv_pp3_netdev_init(const char *name, int rx_vqs, int tx_vqs);
+void mv_pp3_netdev_delete(struct net_device *dev);
+int mv_pp3_netdev_set_emac_params(struct net_device *dev, struct device_node *np);
+int mv_pp3_rx_dg_to_pkts(struct pp3_dev_priv *dev_priv, int dg);
+int mv_pp3_rx_pkts_to_dg(struct pp3_dev_priv *dev_priv, int pkts);
+const char *mv_pp3_pool_name_get(struct pp3_pool *ppool);
+int mv_pp3_rx_hwq_alloc_mode_set(enum mv_hwq_alloc_mode mode);
+int mv_pp3_dev_rxqs_set(struct net_device *dev, int rxqs);
+int mv_pp3_dev_txqs_set(struct net_device *dev, int txqs);
+int mv_pp3_dev_rxvq_num_get(struct net_device *dev, int cpu);
+void mv_pp3_dev_init_show(struct net_device *dev);
+int mv_pp3_txdone_pkt_coal_set(struct net_device *dev, int pkts_num);
+int mv_pp3_txdone_pkt_coal_get(struct net_device *dev, int *pkts_num);
+int mv_pp3_txdone_time_coal_set(struct net_device *dev, unsigned int usec);
+int mv_pp3_txdone_time_coal_get(struct net_device *dev, unsigned int *usec);
+int mv_pp3_recycle_set(struct net_device *dev, int enable);
+int mv_pp3_rx_pkt_coal_set(struct net_device *dev, int pkts_num);
+int mv_pp3_rx_pkt_coal_get(struct net_device *dev, int *pkts_num);
+void mv_pp3_rx_time_coal_profile_set(struct net_device *dev, int profile);
+void mv_pp3_rx_time_coal_set(struct net_device *dev, int usec);
+int mv_pp3_rx_time_coal_get(struct net_device *dev, int *usec);
+int mv_pp3_cpu_affinity_set(struct net_device *dev, int cpu);
+int mv_pp3_rx_pkt_mode_set(struct net_device *dev, enum mv_pp3_pkt_mode mode);
+int mv_pp3_poll(struct napi_struct *napi, int budget);
+struct net_device_stats *mv_pp3_get_stats(struct net_device *dev);
+int mv_pp3_dev_open(struct net_device *dev);
+int mv_pp3_dev_stop(struct net_device *dev);
+int mv_pp3_ingress_vqs_priv_init(struct pp3_dev_priv *dev_priv, enum mv_hwq_alloc_mode rxq_mode);
+int mv_pp3_egress_vqs_priv_init(struct pp3_dev_priv *dev_priv);
+int mv_pp3_ingress_vqs_delete(struct pp3_dev_priv *dev_priv);
+int mv_pp3_egress_vqs_delete(struct pp3_dev_priv *dev_priv);
+int mv_pp3_dev_rx_cpus_set(struct net_device *dev, int cpus_mask);
+int mv_pp3_dev_cpu_inuse(struct net_device *dev, int cpu);
+void mv_pp3_dev_rx_pause(struct net_device *dev, int cos);
+void mv_pp3_dev_rx_resume(struct net_device *dev, int cos);
+
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+int mv_pp3_ctrl_nic_skb_recycle(int en);
+bool mv_pp3_is_nic_skb_recycle(void);
+#endif
+
+#define MV_PP3_TXDONE_TIMER_USEC_PERIOD (10000)
+#define MV_PP3_BUF_REQUEST_SIZE	(8)
+
+#if 0
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+
+/* Pool mask, the low 6 bits of CB used to record BPID */
+#define MV_PP3_SKB_RECYCLE_POOL_MASK                        (0x3F)
+/* GP pool from 8 to 35 */
+#define MV_PP3_SKB_RECYCLE_POOL_START                       (8)
+#define MV_PP3_SKB_RECYCLE_POOL_END                         (35)
+/* SKB recycle magic, indicate the skb can be recycled, here it is the address of skb */
+#define MV_PP3_SKB_RECYCLE_MAGIC(skb)                       (((unsigned int)skb) & (~MV_PP3_SKB_RECYCLE_POOL_MASK))
+/* Cb to store magic and bpid, the last 4 bytes of cb is to use */
+#define MV_PP3_SKB_RECYCLE_CB(skb)                          (*((unsigned int *)(&(skb->cb[sizeof(skb->cb) - 4]))))
+
+/*---------------------------------------------------------------------------*/
+/*				Inline functions                             */
+/*---------------------------------------------------------------------------*/
+/* mv_pp3_skb_recycle_magic_bpid_set, set magic and rx pool id */
+static inline void mv_pp3_skb_recycle_magic_bpid_set(struct sk_buff *skb, int bpid)
+{
+	MV_PP3_SKB_RECYCLE_CB(skb) = MV_PP3_SKB_RECYCLE_MAGIC(skb) | bpid;
+}
+
+/* mv_pp3_skb_recycle_bpid_get, get rx pool id */
+static inline int mv_pp3_skb_recycle_bpid_get(struct sk_buff *skb)
+{
+	int bpid;
+	unsigned int magic_bpid = MV_PP3_SKB_RECYCLE_CB(skb);
+
+	/* Check skb recycle magic */
+	if (MV_PP3_SKB_RECYCLE_MAGIC(skb) != (magic_bpid & ~MV_PP3_SKB_RECYCLE_POOL_MASK))
+		return -1;
+
+	bpid = magic_bpid & MV_PP3_SKB_RECYCLE_POOL_MASK;
+	/* Check bpid range for A390 */
+	if ((bpid < MV_PP3_SKB_RECYCLE_POOL_START) || (bpid > MV_PP3_SKB_RECYCLE_POOL_END))
+		return -1;
+
+	return bpid;
+}
+
+static inline int mv_pp3_stack_put(struct pp3_cpu *cpu_ctrl, struct sk_buff *skb)
+{
+	if (mv_stack_is_full(cpu_ctrl->stack)) {
+		STAT_ERR(cpu_ctrl->stack_full++);
+		return -1;
+	}
+	mv_stack_push(cpu_ctrl->stack, (unsigned int)skb);
+	STAT_DBG(cpu_ctrl->stack_put++);
+
+	return 0;
+}
+
+static inline struct sk_buff *mv_pp3_stack_get(struct pp3_cpu *cpu_ctrl)
+{
+	struct sk_buff *skb = NULL;
+
+	if (mv_stack_index(cpu_ctrl->stack) > 0) {
+		STAT_DBG(cpu_ctrl->stack_get++);
+		skb = (struct sk_buff *)mv_stack_pop(cpu_ctrl->stack);
+	} else
+		STAT_ERR(cpu_ctrl->stack_empty++);
+
+	return skb;
+}
+
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+#endif /* if 0 */
+
+/*  Function prepare CFH QC field for TX L3 checksum calculation offload */
+static inline u32 mv_pp3_cfh_tx_l3_csum_offload(bool enable, int l3_offs, int l3_proto, int ip_hdr_len, int *valid)
+{
+	u32 command;
+	*valid = 1;
+
+	command = MV_CFH_L3_OFFS_SET(l3_offs);
+	command |= MV_CFH_IPHDR_LEN_SET(ip_hdr_len);
+
+	if (!enable) {
+		command |= MV_CFH_IP_CSUM_DISABLE;
+		*valid = 0;
+
+	} else if (l3_proto != htons(ETH_P_IP)) {
+		/* enable L3 IP6 CS, IP4 supported by default*/
+		command |= MV_CFH_L3_INFO_TX_SET(L3_TX_IP6);
+		command |= MV_CFH_IP_CSUM_DISABLE;
+		*valid = 0;
+	}
+
+	return command;
+}
+
+/*  Function prepare CFH QC field for TX L4 checksum calculation offload */
+static inline u32 mv_pp3_cfh_tx_l4_csum_offload(bool enable, int l4_proto, int *valid)
+{
+	u32 command = 0;
+	*valid = 1;
+
+	if (!enable) {
+		command |= MV_CFH_L4_CSUM_SET(L4_CSUM_NOT);
+		*valid = 0;
+
+	} else if (l4_proto == IPPROTO_TCP)
+		/*L4_TX_TCP by defult*/
+		command |= MV_CFH_L4_CSUM_SET(L4_CSUM);
+
+	else if (l4_proto == IPPROTO_UDP)
+		command |= (MV_CFH_L4_INFO_TX_SET(L4_TX_UDP) | MV_CFH_L4_CSUM_SET(L4_CSUM));
+
+	else {
+		command |= MV_CFH_L4_CSUM_SET(L4_CSUM_NOT);
+		*valid = 0;
+	}
+
+	return command;
+}
+/* Function verify CHECKSUM validity and update statistics counters */
+static inline bool mv_pp3_rx_csum(struct pp3_vport *cpu_vp, struct mv_cfh_common *cfh, struct sk_buff *skb)
+{
+	struct net_device *dev = (struct net_device *)cpu_vp->root;
+
+	if (dev->features & NETIF_F_RXCSUM) {
+		enum mv_pp3_cfh_l3_info_rx l3_info = MV_CFH_L3_INFO_RX_GET(cfh->l3_l4_info);
+
+		if ((l3_info == L3_RX_IP4) || (l3_info == L3_RX_IP6)) {
+			enum mv_pp3_cfh_l4_info_rx l4_info = MV_CFH_L4_INFO_RX_GET(cfh->l3_l4_info);
+
+			if ((l4_info == L4_RX_TCP) || (l4_info == L4_RX_UDP)) {
+				STAT_DBG(cpu_vp->port.cpu.stats.rx_csum_hw++);
+				return true;
+
+			} else if ((l4_info == L4_RX_TCP_CS_ERR) || (l4_info == L4_RX_UDP_CS_ERR)) {
+				/* l4 error found */
+				STAT_ERR(cpu_vp->port.cpu.stats.rx_csum_l4_err++;)
+			}
+
+		} else if (l3_info == L3_RX_IP4_ERR) {
+			/* l3 error found */
+			STAT_ERR(cpu_vp->port.cpu.stats.rx_csum_l3_err++;)
+		}
+	}
+	STAT_DBG(cpu_vp->port.cpu.stats.rx_csum_sw++);
+	return false;
+}
+
+#endif /* __mv_netdev_h__ */
+
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev_structs.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev_structs.h
new file mode 100644
index 0000000..7eb271b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_netdev_structs.h
@@ -0,0 +1,126 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __mv_netdev_structs_h__
+#define __mv_netdev_structs_h__
+
+#include <linux/interrupt.h>
+#include <net/gnss/mv_nss_defs.h>
+
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+
+struct pp3_dev_rss {
+	int			rss_profile;
+	int			def_cpu;
+	enum mv_hash_type	l2_hash;
+	enum mv_hash_type	l3_hash;
+	enum mv_hash_type	l4_hash;
+	int			hash_weights[CONFIG_NR_CPUS];
+};
+
+struct pp3_dev_qos {
+	int			qos_profile;
+	enum mv_qos_mode	qos_mode;
+	int			rx_prio_to_vq[MV_PP3_PRIO_NUM];
+	int			rx_dscp_to_vq[MV_DSCP_NUM];
+	int			tx_prio_to_vq[MV_PP3_PRIO_NUM];
+	int			tx_dscp_to_vq[MV_DSCP_NUM];
+};
+/*---------------------------------------------------------------------------*/
+
+/* Masks used for pp3_dev_priv flags */
+#define MV_PP3_F_DBG_RX_BIT		0
+#define MV_PP3_F_DBG_TX_BIT		1
+#define MV_PP3_F_DBG_ISR_BIT		2
+#define MV_PP3_F_DBG_POLL_BIT		3
+#define MV_PP3_F_INIT_BIT		4
+#define MV_PP3_F_FP_BIT			5
+#define MV_PP3_F_DBG_SG_BIT		6
+#define MV_PP3_F_SHARED_POOLS_BIT	7
+#define MV_PP3_F_IF_UP_BIT		8
+#define MV_PP3_F_IF_LINK_UP_BIT		9
+#define MV_PP3_F_MAC_CONNECT_BIT	10
+
+#define MV_PP3_F_DBG_RX			(1 << MV_PP3_F_DBG_RX_BIT)
+#define MV_PP3_F_DBG_TX			(1 << MV_PP3_F_DBG_TX_BIT)
+#define MV_PP3_F_DBG_ISR		(1 << MV_PP3_F_DBG_ISR_BIT)
+#define MV_PP3_F_DBG_POLL		(1 << MV_PP3_F_DBG_POLL_BIT)
+#define MV_PP3_F_INIT			(1 << MV_PP3_F_INIT_BIT)
+#define MV_PP3_F_FP			(1 << MV_PP3_F_FP_BIT)
+#define MV_PP3_F_DBG_SG			(1 << MV_PP3_F_DBG_SG_BIT)
+#define MV_PP3_F_IF_UP			(1 << MV_PP3_F_IF_UP_BIT)
+#define MV_PP3_F_IF_LINK_UP		(1 << MV_PP3_F_IF_LINK_UP_BIT)
+#define MV_PP3_F_MAC_CONNECT		(1 << MV_PP3_F_MAC_CONNECT_BIT)
+
+#define MV_PP3_PRIV(dev)		((struct pp3_dev_priv *)(netdev_priv(dev)))
+#define MV_PP3_VPORT_DEV(vport)		((struct net_device *)(vport->root))
+#define MV_PP3_VPORT_DEV_PRIV(vport)	(MV_PP3_PRIV(MV_PP3_VPORT_DEV(vport)))
+
+#define DEV_PRIV_STATS(dev_priv, cpu)	per_cpu_ptr((dev_priv)->dev_stats, (cpu))
+/* counters below used to update net_device statistics and should not zeroed */
+struct pp3_netdev_stats {
+	unsigned int rx_pkt_dev;
+	unsigned int tx_pkt_dev;
+	unsigned int rx_bytes_dev;
+	unsigned int tx_bytes_dev;
+	unsigned int rx_drop_dev;
+	unsigned int tx_drop_dev;
+	unsigned int rx_err_dev;
+};
+
+struct pp3_ptp_desc; /* private PTP descriptor */
+
+/* PP3 driver private information attached to network device */
+struct pp3_dev_priv {
+	int			id;           /* ID taken from FDT or equal to external virtual port id */
+	struct mv_mac_data	mac_data;     /* EMAC data get from FDT file */
+	struct pp3_vport	*cpu_vp[CONFIG_NR_CPUS]; /* CPU virtual ports (per CPU) */
+	struct pp3_vport	*vport;       /* EMAC/External virtual port (single) */
+	struct pp3_cpu_shared   *cpu_shared;  /* Pointer to shared CPUs structure (per port)*/
+	struct net_device	*dev;         /* pointer to network device */
+	struct list_head	mac_list;     /* Shadow list of MAC addresses */
+	struct pp3_ptp_desc	*ptp_desc; /* private PTP descriptor */
+	int			mac_list_size;/* number of MAC addreses in list */
+	unsigned long		flags;        /* PP3 driver flags used for net_device */
+	int			rxqs_per_cpu; /* Number of RXQs per interface per CPU */
+	int			txqs_per_cpu; /* Number of TXQs per interface per CPU */
+	int			rxq_capacity; /* RXQ maximum capacity [pkts] - allocation size */
+	int			txq_capacity; /* TXQ maximum capacity [pkts] - allocation size */
+	struct cpumask		rx_cpus;      /* CPUs which can RX on this network interface */
+	int			rx_pkt_coal;  /* RX coalescing [pkts] for this device */
+	int			rx_time_coal; /* RX time coalescing [usec] for this device */
+	int			rx_time_prof; /* RX time coalescing profile this device connected to */
+	int			tx_done_pkt_coal; /* TX Done coalescing [pkts] for this device */
+	int			tx_done_time_coal; /* TX Done coalescing [usec] for this device */
+	struct pp3_netdev_stats __percpu *dev_stats;
+};
+/*---------------------------------------------------------------------------*/
+#endif /* __mv_netdev_structs_h__ */
+
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook.c
new file mode 100644
index 0000000..443d53a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook.c
@@ -0,0 +1,599 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+*******************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <linux/module.h>
+#include <linux/inetdevice.h>
+#include <linux/interrupt.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <linux/list.h>
+#include <linux/of_irq.h>
+#include <linux/of_mdio.h>
+
+#include "mv_netdev_structs.h"
+
+#define DBG_PTP_TS(FMT, VV...)	pr_info(FMT, ##VV)
+
+#define PTP_PORT_EVENT	319 /* for PTP RX and TX */
+#define PTP_PORT_SIGNAL	320 /* for PTP TX only */
+/* PTP message-IDs having special TX handling */
+#define PTP_SYNC	0x00
+#define PTP_DELAY_REQ	0x01
+#define PTP_PEER_DELAY_REQ	0x02
+#define PTP_DELAY_RESP	0x09
+#define PTP_ANNOUNCE	0x0b
+
+#define PTP_HEADER_OFFS	(44)
+#define PTP_HEADER_MSG_ID_OFFS	(0)
+#define PTP_HEADER_RESERVE_1BYTES_OFFS	(5)
+#define PTP_HEADER_CORRECTION_FIELD_OFFS	(8) /*size 6+2bytes */
+#define PTP_HEADER_RESERVE_4BYTES_OFFS	(16)
+#define PTP_CORRECTION_PRIVATE_ID	0xa5
+
+/* PTP check upon MAX-lenght statistically is most effective.
+ * The skb->data_len is already known ZERO, so skb->len is enought
+ * MAX=Announce_64bytes + MV_MH_SIZE + IPv4_42 + IPv6_20 + VLAN_2 =
+ *  64 + 44 + 20 + 2 = 64 + 66
+ */
+#define MAX_PTP_UDP_LEN	80
+#define MAX_PTP_PKT_LEN	(MAX_PTP_UDP_LEN + 66)
+
+#define PTP_TS_CS_CORRECTION_SIZE	2
+
+/* FEATURES */
+#define PTP_FILLER_CONTROL
+#define PTP_IGNORE_TIMESTAMPING_FLAG_FOR_DEBUG
+#define PTP_TS_TRAFFIC_CORRECTION
+
+/**** DEBUG and HW-testing */
+/*#define PTP_ALL_RX_TS_DBG_CAPTURE*/
+#if defined(PTP_ALL_RX_TS_DBG_CAPTURE) || defined(PTP_DELAY_TRACE)
+#include "mv_ptp_hook_dbg.h"
+#else
+/* Empty fillers for no-debug case */
+#define PTP_RX_TS_DBG_CAPTURE(IDX, LEN, TS)
+#define PTP_RX_TS_DBG_PRINT(C, RC)
+#define PTP_RX_TS_DBG_CFG(val1, val2, val3)	0
+#define PTP_TX_TS_DBG(IN_QUEUE)
+#define PTP_RX_TS_DBG(pDATA, OFFS, RX32B)
+#define PTP_DELAY_TRACE_CFG_DBG(V1, V2, V3, RC)
+#endif
+/**/
+
+struct pp3_ptp_stats {
+	u32 tx;
+	u32 tx_capture_in_queue;
+	u32 rx;
+};
+
+struct pp3_ptp_desc {
+	int	emac_num; /* shortcut for ->vport->port.emac.emac_num */
+	struct pp3_ptp_stats *stats;
+};
+
+static inline struct pp3_dev_priv *mv_pp3_emac_dev_priv_get(int emac_num);
+
+/**** Net-dev hook Utilities (used as static/inline) ******************
+ *  mv_pp3_is_pkt_ptp_rx_proc()   - filter PTP & processing
+ *  mv_pp3_is_pkt_ptp_tx()        - filter PTP
+ *  mv_pp3_send_filler_pkt_cfh()  - processing step 1
+ *  mv_pp3_ptp_pkt_proc_tx()      - processing step 1
+ *
+ *  mv_pp3_pkt_ptp_stats()        - statistic (private PTP)
+ *  mv_ptp_hook_enable()          - enable and statistic print
+ *  mv_ptp_hook_extra_op()        - extra operations for debug
+***********************************************************************/
+
+static struct pp3_ptp_desc	pp3_ptp_desc[MV_PP3_EMAC_NUM];
+static struct pp3_ptp_stats	pp3_ptp_stats[MV_PP3_EMAC_NUM];
+
+static inline void mv_pp3_pkt_ptp_stats(int port, int reset)
+{
+	struct pp3_ptp_stats *p = &pp3_ptp_stats[port];
+	if (reset) {
+		memset(p, 0, sizeof(struct pp3_ptp_stats));
+	} else {
+		/* STATS print-form optimization:
+		 * MasterOnly should always have capture_in_queue=0
+		 * SlaveOnly  should always have tx == capture_in_queue
+		 * BoundaryClock=Master+Slave and so tx != capture_in_queue
+		 */
+		if ((p->tx == p->tx_capture_in_queue) || !p->tx_capture_in_queue)
+			pr_info("ptp port %d stats: tx=%u ; rx=%u\n",
+				port, p->tx, p->rx);
+		else
+			pr_info("ptp port %d stats: tx=%u (%u:Qcapture) ; rx=%u\n",
+				port, p->tx, p->tx_capture_in_queue, p->rx);
+	}
+}
+
+#ifdef PTP_FILLER_CONTROL
+static u32 pp3_ptp_filler_enable; /* DISABLE by default*/
+#endif
+
+
+void mv_ptp_hook_extra_op(u32 val1, u32 val2, u32 val3)
+{
+	int i, rc = -1, clear_stats = 0;
+#ifdef PTP_FILLER_CONTROL
+	if (val1 == 0xf/*Filler*/) {
+		pp3_ptp_filler_enable = val2;
+		if (val3) {
+			/* silent settting requested. Don't print but exit */
+			return;
+		}
+		rc = 0;
+	}
+	pr_info("echo deb f .. > [F]iller enable = %d (1:without, 2/3:with TS, 0xFn:ADDRs save)\n",
+		pp3_ptp_filler_enable);
+#endif
+	PTP_DELAY_TRACE_CFG_DBG(val1, val2, val3, &rc);
+
+	if (val1 == 0xc/*Clear statistic*/) {
+		clear_stats = 1;
+		rc = 1;
+	}
+	pr_info("echo deb c > [C]lear statistic %d\n", clear_stats);
+
+	rc |= PTP_RX_TS_DBG_CFG(val1, val2, val3);
+
+	if (rc) {
+		for (i = 0; i < MV_PP3_EMAC_NUM; i++)
+			mv_pp3_pkt_ptp_stats(i, clear_stats);
+#ifdef PTP_TS_TRAFFIC_CORRECTION
+		pr_info(" PTP_TS_TRAFFIC_CORRECTION is enabled\n");
+#endif
+		PTP_RX_TS_DBG_PRINT(clear_stats, rc);
+	}
+}
+
+void mv_ptp_hook_enable(int port, bool enable)
+{
+	struct pp3_dev_priv *dev_priv;
+
+	if (port >= MV_PP3_EMAC_NUM)
+		return;
+
+	dev_priv = mv_pp3_emac_dev_priv_get(port);
+	if (!dev_priv)
+		return;
+	/* New Request handling depends upon current state */
+	if (!dev_priv->ptp_desc) {
+		/* Currently disabled */
+		if (enable) {
+			mv_pp3_pkt_ptp_stats(port, 1); /* new session, reset only */
+			dev_priv->ptp_desc = &pp3_ptp_desc[port]; /* hook enabling */
+			dev_priv->ptp_desc->emac_num = port;
+			dev_priv->ptp_desc->stats = &pp3_ptp_stats[port];
+		}
+	} else {
+		/* Currently enabled */
+		mv_pp3_pkt_ptp_stats(port, 0); /* print out accumulated */
+		if (!enable)
+			dev_priv->ptp_desc = NULL; /* hook disabling */
+	}
+}
+
+
+/***************************************************************************
+ **  Real-Time used utilities
+ ***************************************************************************
+ */
+static inline int ptp_get_emac_num(struct pp3_dev_priv *dev_priv)
+{
+	return dev_priv->ptp_desc->emac_num;
+}
+
+static inline u32 ptp_MV_CFH_HWQ_SET(struct pp3_vq  *tx_vq, bool high_queue)
+{
+	u32 tag1 = 0;
+	/** Currently not supported
+	if (high_queue)
+		tag1 = MV_CFH_HWQ_SET( tx_vq -> .. ->to_emac_hwq );
+	**/
+	return tag1;
+}
+
+static inline void ptp_raise_tx_q_priority(struct pp3_dev_priv *dev_priv,
+	struct pp3_vport *cpu_vp, struct pp3_vq  **p_tx_vq, struct pp3_swq **p_tx_swq)
+{
+	/** Currently not supported
+	*p_tx_vq = cpu_vp->tx_vqs[dev_priv->vport->tx_vqs_num - 1];
+	*p_tx_swq = (*p_tx_vq)->swq;
+	**/
+}
+
+
+#ifdef PTP_TS_TRAFFIC_CORRECTION
+/* Under traffic long packets have transmission latency ~12us (on 1Gb link)
+ * causing for PTP delay and TimeStamp-deviation 0..12us
+ * Handle the case in a statistical algorithm and correct TS.
+ * Use the fact that EVERY Ingress has TS-32bits in CFH
+ * and pass the info to upper application.
+ * The information is placed into "correction field".
+ * This requires special PTP application to handle this non-standard.
+ * Since the Standard correction-field is used for TransparentClock devices,
+ * we need to place traffic-info only if received correction==0 and mark 0xA5
+ * in 1byte-reserve to distinct standard/non-standard
+ */
+struct ptp_correction_field { /* correctionField not standard refill */
+	u8 tx_factor;
+	u8 rx_handled_burst_sz; /* Pkts handled before PTP in same napi-budget */
+	u16 rx_prev_sz;
+	u32 rx_prev_ts;
+};
+
+struct ptp_taffic_stats {
+	int last_sz;
+	u32 last_ts;
+};
+static struct ptp_taffic_stats ptp_taffic_rx_stats[MV_PP3_EMAC_NUM];
+
+static inline void mv_pp3_rx_traffic_stats(int emac_num, int pkt_len, u32 ts)
+{
+	ptp_taffic_rx_stats[emac_num].last_ts = ts;
+	ptp_taffic_rx_stats[emac_num].last_sz = pkt_len;
+}
+
+static inline void mv_pp3_rx_traffic_handle(int emac_num, int pkt_len,
+	u8 *ptp_data, int rx_pkt_done)
+{
+	struct ptp_correction_field *cf;
+	struct ptp_taffic_stats *s;
+	u16 *p16 = (u16 *)(ptp_data + PTP_HEADER_CORRECTION_FIELD_OFFS + 4);
+	if (*p16)
+		return; /* Field is not empty. Do not touch */
+
+	ptp_data[PTP_HEADER_RESERVE_1BYTES_OFFS] = PTP_CORRECTION_PRIVATE_ID;
+
+	cf = (void *)(ptp_data + PTP_HEADER_CORRECTION_FIELD_OFFS);
+	s = &ptp_taffic_rx_stats[emac_num];
+	cf->rx_handled_burst_sz = (u8)rx_pkt_done;
+	cf->rx_prev_sz = (u16)s->last_sz;
+	cf->rx_prev_ts = s->last_ts;
+}
+#else
+#define mv_pp3_rx_traffic_stats(IDX, LEN, TS)
+#define mv_pp3_rx_traffic_handle(IDX, LEN, DATA, RX_DONE)
+#endif/*PTP_TS_TRAFFIC_CORRECTION*/
+
+static inline int mv_pp3_send_filler_pkt_cfh(struct pp3_dev_priv *dev_priv, u8 *pkt_data,
+				int cpu, struct pp3_vq  **p_tx_vq, struct pp3_swq **p_tx_swq)
+{
+	/* Use filler with MAX possible len "built into" the CFH = 64bytes
+	 * but with MaxMax FIFO = 16k-2
+	 * It could have "any contents" but let's use UDP/PTP_319 DELAY_REQUEST
+	 * cut into len 64 bytes.
+	 * The MAC addresses should be any invalid Non Broadcust/Multicast; for debug
+	 * could save valid MAC and IPv4 addresses from given PTP packet
+	 * For debug only we could save-and-use real MACs and IPs from the packet
+	 */
+	#define DBG_FILLER_REPLACEABLE_SIZE	((12 + 2)/*l2sz*/ + 20/*IPv4sz*/)
+	static u8 pkt_l2[62] = { 0x00, 0x00,  /* marvell header */
+	/*02*/ 0x3c, 0xff, 0xff, 0xff, 0xff, 0xff, 0x3c, 0xff, 0xff, 0xff, 0xff, 0xff, /*MAC dst/src*/
+	/*14*/ 0x08, 0x00, 0x45, 0x00,	0x00, 0x30/*IPlen*/,
+	/*20*/ 0xb6, 0x3e, 0x40, 0x00, 0x40, 0x11/*UDP*/, 0x2f, 0xc6,
+	/*28*/ 0xc0, 0xc0, 0xc0, 0xc0, 0xc0, 0xc0,	0xc0, 0xc0, /* IPv4 addr src/dst: 192.192.192.192 */
+	/*36  =  (MV_MH_SIZE + 34:DBG_FILLER_REPLACEABLE_SIZE) */
+	/*36*/ 0x01, 0x3f, 0x01, 0x3f, 0x00, 0x1c, 0xbf, 0x3b, /* UDP Port=319/319, Lenght(2), CS(2) */
+	/*     0x_F -- PTP but Non-Standard MsgId */
+	/*44*/ 0x0f, 0x02, 0x00, 0x12, 0x04, 0x00, /* TimeStamp may be placed below this ...*/
+	/*50*/ 0xa0, 0xa1, 0xa2, 0xa3, 0xa4, 0xa5, 0xa6, 0xa7, 0xa8, 0xa9, 0xff, 0xff
+	/*62*/
+	};
+	static u16 ptp_fp_len = 0x4000 - 2; /* 16k-2 */
+
+	/* cpu = smp_processor_id() */
+	/* p_tx_vq/p_tx_swq updated if raising priority */
+	/* tx_swq = tx_vq->swq */
+	struct pp3_swq *tx_swq = *p_tx_swq;
+	struct pp3_vport *cpu_vp = dev_priv->cpu_vp[cpu];
+
+	struct mv_cfh_common *cfh;
+	unsigned char *cfh_pdata;
+	int cfh_len_dg, pkt_len, rc = 0;
+
+#ifdef PTP_FILLER_CONTROL
+	if (!pp3_ptp_filler_enable)
+		goto exit;
+#endif
+
+	cfh_len_dg = 96 / MV_PP3_CFH_DG_SIZE;
+
+	/* get cfh */
+	cfh = (struct mv_cfh_common *)mv_pp3_hmac_txq_next_cfh(tx_swq->frame_num,
+								tx_swq->swq, cfh_len_dg);
+	if (!cfh) {
+		STAT_ERR(tx_swq->stats.pkts_errors++);
+		rc = -1;
+		goto exit;
+	}
+	cfh->plen_order = MV_CFH_PKT_LEN_SET(ptp_fp_len) | MV_CFH_REORDER_SET(REORD_NEW) |
+		MV_CFH_LAST_BIT_SET;
+
+	cfh->ctrl = MV_CFH_LEN_SET(cfh_len_dg * MV_PP3_CFH_DG_SIZE) |
+		MV_CFH_MODE_SET(HMAC_CFH) | MV_CFH_PP_MODE_SET(PP_TX_PACKET);
+
+	cfh->vm_bp = 0; /*Pool=0 but not MV_CFH_BPID_SET(1) */
+	cfh->marker_l = 0;
+	cfh->phys_l = 0;
+	cfh->l3_l4_info = 0;
+
+	cfh->tag1 = ptp_MV_CFH_HWQ_SET(*p_tx_vq, false) |
+			MV_CFH_ADD_CRC_BIT_SET | MV_CFH_L2_PAD_BIT_SET;
+
+#ifdef PTP_FILLER_CONTROL
+	if (pp3_ptp_filler_enable & 0xf0) {
+		/* Construct special DEBUG filler-buffer "pkt_l2" (IPv4 only)
+		 * for HW-TS checking and measurement
+		 */
+		u8 tmp[4], *pf;
+
+		pf = pkt_l2 + MV_MH_SIZE;
+		/* Save MAC/IP addresses of original PTP into filler-buffer "pkt_l2" */
+		memcpy(pf, pkt_data + MV_MH_SIZE, DBG_FILLER_REPLACEABLE_SIZE);
+
+		if (pp3_ptp_filler_enable & 0x20) {
+			/* Set MAC-dst Broadcast */
+			/*pf = pkt_l2 + MV_MH_SIZE; already done*/
+			memset(pf, 0xff, 6);
+		}
+		if (pp3_ptp_filler_enable & 0x40) {
+			/* Swap IPv4 src/dst */
+			pf = pkt_l2 + MV_MH_SIZE + 26;
+			memcpy(tmp, pf, 4);
+			memcpy(pf, pf + 4, 4);
+			memcpy(pf + 4, tmp, 4);
+		}
+		if (pp3_ptp_filler_enable & 0x80) {
+			/* Set real 62 lenght instead filler's huge size */
+			ptp_fp_len = sizeof(pkt_l2);
+		}
+		pp3_ptp_filler_enable &= ~0xf0;
+	}
+
+	if (pp3_ptp_filler_enable > 1) {
+		/* filler with TS and CS/CUE avoids latency ~5uSec */
+		/*  TSE, QS, TS_off, CS_off, CUE, PACT, PF, WC, DE, ETS */
+		/*   1,  0,    50,    60,    1(!), 4/6,  0,  0,  0,   0 */
+		cfh->tag1 |= MV_CFH_PTP_TSE_SET;
+		cfh->tag2 = MV_CFH_PTP_TS_OFF_SET(50 - MV_MH_SIZE); /*TS_off*/
+		/* CUE: UDP-CS-Enable and CS_off (2bytes used) if needed *
+		cfh->tag2 |= MV_CFH_PTP_CUE_SET(1) | MV_CFH_PTP_CS_OFF_SET(60 - MV_MH_SIZE);
+		*/
+		if (pp3_ptp_filler_enable > 2)
+			cfh->tag2 |= MV_CFH_PTP_PACT_SET(6); /*PACT=AddTime2packet+Capture*/
+		else
+			cfh->tag2 |= MV_CFH_PTP_PACT_SET(4); /*PACT=AddTime2packet*/
+	} else {
+		cfh->tag2 = 0;
+	}
+#else
+	cfh->tag2 = 0;
+#endif
+
+	/* copy packet to CFH */
+	pkt_len = sizeof(pkt_l2) - 2;  /* not including MV_MH_SIZE */
+	cfh_pdata = (unsigned char *)cfh + MV_PP3_CFH_HDR_SIZE;
+	memcpy(cfh_pdata, pkt_l2, sizeof(pkt_l2));
+
+	/* transmit CFH */
+	wmb();
+	mv_pp3_hmac_txq_send(tx_swq->frame_num, tx_swq->swq, cfh_len_dg);
+
+	DEV_PRIV_STATS(dev_priv, cpu)->tx_pkt_dev++;
+	DEV_PRIV_STATS(dev_priv, cpu)->tx_bytes_dev += pkt_len;
+
+	STAT_DBG(tx_swq->stats.pkts++);
+	STAT_DBG(cpu_vp->port.cpu.stats.tx_bytes += pkt_len);
+exit:
+	ptp_raise_tx_q_priority(dev_priv, cpu_vp, p_tx_vq, p_tx_swq);
+	return rc;
+}
+
+static inline void mv_pp3_is_pkt_ptp_rx_proc(struct pp3_dev_priv *dev_priv,
+	struct mv_cfh_common *cfh,  int pkt_len, u8 *pkt_data, int rx_pkt_done)
+{
+	int eth_tag_len, dst_port_offs, ptp_offs, ptp_hdr_offs, emac_num;
+	u16 ether_type, l4_port;
+	enum mv_pp3_cfh_l3_info_rx l3_info;
+	enum mv_pp3_cfh_l4_info_rx l4_info;
+	u32 ts;
+
+	if (!dev_priv->ptp_desc)
+		return;
+
+	emac_num = ptp_get_emac_num(dev_priv);
+
+	if (pkt_len > MAX_PTP_PKT_LEN)
+		goto exit;
+
+	/* Check VLAN - needed for correct offset */
+	eth_tag_len = (MV_CFH_VLAN_INFO_GET(cfh->l3_l4_info)) ? 2 : 0;
+
+	/* Check in most-valuable ordering: port -> udpProto -> etherType */
+	dst_port_offs = eth_tag_len + MV_MH_SIZE +
+		+ MV_CFH_L3_OFFS_GET(cfh->l3_l4_info)
+		+ MV_CFH_IPHDR_LEN_GET(cfh->l3_l4_info) * sizeof(u32)
+		+ 2; /* +2 for RX only */
+	l4_port = ntohs(*(u16 *)(pkt_data + dst_port_offs));
+	if ((l4_port != PTP_PORT_EVENT) && (l4_port != PTP_PORT_SIGNAL))
+		goto exit;
+
+	l4_info = MV_CFH_L4_INFO_RX_GET(cfh->l3_l4_info);
+	if (l4_info != L4_RX_UDP)
+		goto exit;
+
+	l3_info = MV_CFH_L3_INFO_RX_GET(cfh->l3_l4_info);
+	if ((l3_info != L3_RX_IP4) && (l3_info != L3_RX_IP6))
+		goto exit;
+
+	ether_type = ntohs(*(u16 *)(pkt_data + 14 + eth_tag_len));
+	if (ether_type == ETH_P_1588)
+		goto exit; /*ETH_P_1588=0x88F7 is not supported by upper PTP layers*/
+
+	/* Handling PTP packet: fetch TS32bits from cfh and place into PTP header */
+	ts = cfh->tag2;
+
+	ptp_hdr_offs = PTP_HEADER_OFFS + eth_tag_len;
+	if (l3_info != L3_RX_IP4)
+		ptp_hdr_offs += 20; /* IPV6 header +20 bytes */
+
+	ptp_offs = ptp_hdr_offs + PTP_HEADER_RESERVE_4BYTES_OFFS;
+	memcpy(pkt_data + ptp_offs, &ts, sizeof(ts));
+
+	/*DBG_PTP_TS("ptp-rx: ts=%08x=%d.%09d\n", ts, ts >> 30, ts & 0x3fffffff);*/
+	STAT_INFO(dev_priv->ptp_desc->stats->rx++);
+	PTP_RX_TS_DBG(pkt_data, ptp_offs, ts);
+
+	mv_pp3_rx_traffic_handle(emac_num, pkt_len, pkt_data + ptp_hdr_offs, rx_pkt_done);
+
+	return;
+exit:
+	mv_pp3_rx_traffic_stats(emac_num, pkt_len, cfh->tag2);
+	PTP_RX_TS_DBG_CAPTURE(emac_num, pkt_len, cfh->tag2);
+}
+
+static inline int mv_pp3_is_pkt_ptp_tx(struct pp3_dev_priv *dev_priv, struct sk_buff *skb, int *tx_ts_queue)
+{
+	u16 protocol, udp_port;
+	int eth_tag_len;
+	const int l2_hdr_len = 14;
+	int ip_hdr_len; /* 20 or 40 for ipv4 or ipv6 */
+	int skb_ip_len_lsb_offs;
+	int skb_dst_port_offs/* UDP/L4: on offs=2 out of udpHdrLen=8 */;
+	int skb_udp_len_lsb_offs;
+	int skb_ptp_header_offs; /* Offset from skb-data beginning */
+	int skb_ts_offs; /* OUT result: TimeStamp offset */
+	const int ptp_ts_offs = 34; /* Offset from PTP-data beginning */
+	u8 msg_type;
+
+#ifndef PTP_IGNORE_TIMESTAMPING_FLAG_FOR_DEBUG
+	if (!skb->sk)
+		return 0;
+	/* User should set for PTP/TX socket the sockopt
+	 *  (SOL_SOCKET, SO_TIMESTAMPING, SOCK_TIMESTAMPING_TX_HARDWARE)
+	 */
+	if (!(skb->sk->sk_flags & (1 << SOCK_TIMESTAMPING_TX_HARDWARE)))
+		return 0;
+#endif
+	if (!dev_priv->ptp_desc)
+		return 0;
+
+	if (skb->len > MAX_PTP_PKT_LEN)
+		return 0;
+
+	/* Check VLAN to obtain correct offset */
+	if (skb->protocol == htons(ETH_P_8021Q)) {
+		eth_tag_len = 2;
+		protocol = vlan_eth_hdr(skb)->h_vlan_encapsulated_proto;
+	} else {
+		eth_tag_len = 0;
+		protocol = skb->protocol;
+	}
+	/* Check IP v4 vs v6 */
+	switch (protocol) {
+	case htons(ETH_P_IP):
+		ip_hdr_len = ip_hdr(skb)->ihl * sizeof(u32);
+		skb_dst_port_offs = MV_MH_SIZE + eth_tag_len + l2_hdr_len + ip_hdr_len + 2;
+		udp_port = *(u16 *)(skb->data + skb_dst_port_offs);
+		if ((udp_port != htons(PTP_PORT_EVENT)) && (udp_port != htons(PTP_PORT_SIGNAL)))
+			return 0;
+		if (ip_hdr(skb)->protocol != IPPROTO_UDP)
+			return 0;
+		break;
+
+	case htons(ETH_P_IPV6):
+		ip_hdr_len = 20 + 20;
+		skb_dst_port_offs = MV_MH_SIZE + eth_tag_len + l2_hdr_len + ip_hdr_len + 2;
+		udp_port = *(u16 *)(skb->data + skb_dst_port_offs);
+		if ((udp_port != htons(PTP_PORT_EVENT)) && (udp_port != htons(PTP_PORT_SIGNAL)))
+			return 0;
+		break;
+
+	default:
+		/* PTP_ETHER=0x887F is not supported */
+		return 0;
+	}
+	skb_ptp_header_offs = skb_dst_port_offs + 6;
+	skb_ts_offs = skb_ptp_header_offs + ptp_ts_offs;
+
+	/* Capture TS into Queue for TX-Slave event messages only:
+	 *   DELAY_REQ=1 and PEER_DELAY_REQ=2
+	 */
+	msg_type = skb->data[skb_ptp_header_offs] & 0x0f;
+
+	if (udp_port == htons(PTP_PORT_EVENT)) {
+		/* Capture TS into Queue for TX-Slave event messages only:
+		 *   DELAY_REQ and PEER_DELAY_REQ */
+		*tx_ts_queue = ((msg_type == PTP_DELAY_REQ) ||
+			(msg_type == PTP_PEER_DELAY_REQ));
+	} else if (msg_type == PTP_ANNOUNCE) {
+		*tx_ts_queue = 0;
+	} else {
+		return 0;
+	}
+	/* PTP TX with FW TimeStamp update impacts the CheckSum.
+	 * The FW does not fixes the CS but adds 2 bytes of correction-data
+	 * to bring back the CS to be correct.
+	 * This requires an additional 2 byte storage after TS-field.
+	 * The SKB has enough storage, but the skb, UDP and IPvX lenght
+	 * should be extended with these 2=PTP_TS_CS_CORRECTION_SIZE.
+	 */
+	skb_udp_len_lsb_offs = skb_dst_port_offs + 2 + 1;
+	skb_ip_len_lsb_offs = MV_MH_SIZE + eth_tag_len + l2_hdr_len +
+		(2 + 1)/*IPv4 TotalLen LSB*/;
+	if (protocol == htons(ETH_P_IPV6))
+		skb_ip_len_lsb_offs += 2;  /*IPv6 PayloadLen vs IPv4 TotalLen*/
+	skb->data[skb_udp_len_lsb_offs] += PTP_TS_CS_CORRECTION_SIZE;
+	skb->data[skb_ip_len_lsb_offs] += PTP_TS_CS_CORRECTION_SIZE;
+	skb->len += PTP_TS_CS_CORRECTION_SIZE;
+
+	return skb_ts_offs;
+}
+
+static inline void mv_pp3_ptp_pkt_proc_tx(struct pp3_dev_priv *dev_priv,
+				struct mv_cfh_common *cfh, int skb_len, int skb_ts_offs, int tx_ts_queue)
+{
+	int pact, cfh_ts_offs, cfh_cs_offs;
+
+	/* Convert skb offset to cfh offset (aka "TS off" field)
+	 * Set PACT: 6={AddTime(to packet) + Capture(to egress queue)}
+	 *   or only 4=AddTime according to the cfh-offset
+	 */
+	cfh_ts_offs = skb_ts_offs - MV_MH_SIZE;
+	cfh_cs_offs = skb_len - sizeof(short) - MV_MH_SIZE;
+	pact = (tx_ts_queue) ? 6 : 4;
+
+	/*DBG_PTP_TS("ptp-tx: ts in_queue=%d, offs=%d\n", tx_ts_queue, cfh_ts_offs);*/
+	STAT_INFO(dev_priv->ptp_desc->stats->tx++);
+	if (tx_ts_queue)
+		STAT_INFO(dev_priv->ptp_desc->stats->tx_capture_in_queue++);
+
+	/* Add PTP related to TX CFH */
+	/* TSE, QS, TS_off, CS_off, CUE, PACT, PF, WC, DE, ETS, SEC*/
+	/*  1,   0,   76,     86,    1,   4,    0,  0,  0,  0,   0 */
+	cfh->tag1 |= MV_CFH_PTP_TSE_SET; /*TSE*/
+	/* MV_CFH_PTP_QS_SET(0) QueueSelect=0 */
+	/* Reset Word3 with tag2 by "absolute" TS_OFF_SET */
+	cfh->tag2 = MV_CFH_PTP_TS_OFF_SET(cfh_ts_offs); /*TS_off (not including MV_MH_SIZE!)*/
+	cfh->tag2 |= MV_CFH_PTP_CS_OFF_SET(cfh_cs_offs); /*CS_off*/;
+	cfh->tag2 |= MV_CFH_PTP_CUE_SET(1); /*CUE*/
+	cfh->tag2 |= MV_CFH_PTP_PACT_SET(pact); /*PACT*/
+
+	PTP_TX_TS_DBG(tx_ts_queue);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook_dbg.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook_dbg.h
new file mode 100644
index 0000000..54efc5f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_hook_dbg.h
@@ -0,0 +1,339 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+*******************************************************************************/
+
+/* This is DEBUG file for PTP HW verification but never in real system
+ * Used as INCLUDE into the "mv_ptp_hook.c" file!
+ *
+ * Refer mv_ptp_hook_extra_op() for debug configuration & control
+ *
+ * PTP_DELAY_TRACE
+ * PTP_ALL_RX_TS_DBG_CAPTURE
+ * PTP_PACKET_DUMP
+ */
+
+#ifndef PTP_DELAY_TRACE
+#define PTP_TX_TS_DBG(IN_QUEUE)
+#define PTP_RX_TS_DBG(pDATA, OFFS, RX32B)
+#define PTP_DELAY_TRACE_CFG_DBG(V1, V2, V3, RC)
+#endif
+
+#ifndef PTP_ALL_RX_TS_DBG_CAPTURE
+#define PTP_RX_TS_DBG_CAPTURE(IDX, LEN, TS)
+#define PTP_RX_TS_DBG_PRINT(C, RC)
+#define PTP_RX_TS_DBG_CFG(val1, val2, val3)	0
+#endif
+
+
+/*******************************************************************************
+ * Delay Req/Resp roundtrip measurement;
+ * trace: TX-TimeStamp, RX-packet-TS, RX-TS
+ */
+#ifdef PTP_DELAY_TRACE
+static bool pp3_ptp_dbg_promisc;
+static int pp3_ptp_dbg_tai_reset;
+static u32 pp3_ptp_dbg_enable_cntr;
+static struct mv_pp3_tai_tod ts_tx;
+/*static u64 kclock_tx;*/
+
+static inline void PTP_DELAY_TRACE_CFG_DBG(u32 val1, u32 val2, u32 val3, int *rc)
+{
+	if (val1 == 0xd/*d=Delay measurement*/) {
+		pp3_ptp_dbg_enable_cntr = val2 * 2; /* Req and Resp */
+		pp3_ptp_dbg_promisc = val3 & 1;
+		pp3_ptp_dbg_tai_reset = val3 >> 1;
+		/* DELAY_REQ rate=16/sec, SYNC rate=64/sec */
+		if (pp3_ptp_dbg_promisc)
+			pp3_ptp_dbg_enable_cntr += val2 * 4;
+		*rc = 0;
+	}
+	pr_info("echo deb d NN [resetCntr|sync] > [D]elay Req/Resp 0x%x 0x%x\n",
+		pp3_ptp_dbg_enable_cntr, pp3_ptp_dbg_promisc | (pp3_ptp_dbg_tai_reset << 1));
+}
+
+static inline void PTP_TX_TS_DBG(int in_queue)
+{
+	if (!pp3_ptp_dbg_enable_cntr || !in_queue)
+		return;
+	/*kclock_tx = local_clock();*/
+	if (pp3_ptp_dbg_tai_reset) {
+		pp3_ptp_dbg_tai_reset--;
+		memset(&ts_tx, 0, sizeof(ts_tx));
+		mv_pp3_tai_tod_op(MV_TAI_SET_UPDATE, &ts_tx, 0);
+	} else {
+		mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, &ts_tx, 0);
+	}
+	pp3_ptp_dbg_enable_cntr--;
+}
+
+static inline void PTP_RX_TS_DBG(u8 *pkt_data, int ptp_ts_offs, u32 rx32b)
+{
+	u8 msg_type = pkt_data[ptp_ts_offs - 16] & 0x0f;
+	static struct mv_pp3_tai_tod ts_rx;
+	bool is_delay_resp;
+
+	if (!pp3_ptp_dbg_enable_cntr)
+		return;
+	is_delay_resp = (msg_type == PTP_DELAY_RESP);
+	if (!is_delay_resp && !pp3_ptp_dbg_promisc)
+		return;
+	/* u32 d = (u32)(local_clock() - kclock_tx);  * get before TAI clock */
+	mv_pp3_tai_tod_op(MV_TAI_GET_CAPTURE, &ts_rx, 0);
+	if (!is_delay_resp) {
+		pr_info("%x_%s *****.********* (%u.%09u) %u.%09u\n",
+			msg_type, (msg_type == PTP_SYNC) ? "SYNC" : "misc",
+			/*FromGOP*/ rx32b >> 30, rx32b & 0x3fffffff,
+			ts_rx.sec_lsb_32b & 0xffff, ts_rx.nsec);
+	} else {
+		pr_info(" DELAY %5u.%09u (%u.%09u) %u.%09u\n",
+			ts_tx.sec_lsb_32b & 0xffff, ts_tx.nsec,
+			/*FromGOP*/ rx32b >> 30, rx32b & 0x3fffffff,
+			ts_rx.sec_lsb_32b & 0xffff, ts_rx.nsec);
+	}
+	pp3_ptp_dbg_enable_cntr--;
+}
+#endif /*PTP_DELAY_TRACE*/
+
+
+/*******************************************************************************
+ * All Ingress packets have 32bits timestamp in CFH->tag2
+ * Captire all packets from all ports into buffer to check timestamp consistency
+ */
+#ifdef PTP_ALL_RX_TS_DBG_CAPTURE
+#warning PTP_ALL_RX_TS_DBG_CAPTURE enabled
+
+#define SNIFF_TS_INCONSISTENCY_ON_RANGE
+
+#ifdef SNIFF_TS_INCONSISTENCY_ON_RANGE
+#define RX_TS_DBG_SIZE	128
+
+struct rx_ts_dbg_s {
+	u32 prev_ts;
+	u32 ts;
+	u32 diff;
+};
+static struct rx_ts_dbg_s rx_ts_dbg[RX_TS_DBG_SIZE];
+static u32 sniff_ts_inconsistency_port_no = 1; /* on port 1 */
+static int post_prt_cntr;
+static int sniff_min = 12276; /* This is for 100% 1Gb packets 1518 */
+static int sniff_max = 12360;
+
+#else /*SNIFF_TS_INCONSISTENCY_ON_RANGE*/
+
+#define RX_TS_DBG_SIZE	1024
+
+struct rx_ts_dbg_s {
+	u16 port;
+	u16 len;
+	u32 ts;
+};
+static struct rx_ts_dbg_s rx_ts_dbg[RX_TS_DBG_SIZE];
+static u32 sniff_ts_inconsistency_port_no;
+
+#endif /*SNIFF_TS_INCONSISTENCY_ON_RANGE*/
+
+static u32 rx_ts_dbg_idx;
+
+
+
+static inline u32 convert2nnsec(u32 sec, u32 nsec)
+{
+	/*     avoid warning    { 0, 1000000000, 2000000000, 3000000000 */
+	const u32 sec2nsec[4] = { 0, 0x3b9aca00, 0x77359400, 0xb2d05e00 };
+	u32 nnsec = sec2nsec[sec] + nsec;
+	return nnsec;
+}
+
+static int PTP_RX_TS_DBG_CFG(u32 val1, u32 val2, u32 val3)
+{
+	int rc = 0;
+	if (val1 == 0x5) {
+		sniff_ts_inconsistency_port_no = val2;
+		rc = 1;
+	}
+	pr_info("echo deb 5 <1/3/0>  :%d=Sniff timestamp inconsistency on port 1/3\n",
+		sniff_ts_inconsistency_port_no);
+#ifdef SNIFF_TS_INCONSISTENCY_ON_RANGE
+	if ((val1 == 0x5a) && val2 && val3) {
+		sniff_min = val2;
+		sniff_max = val3;
+		rc = 1;
+	}
+	pr_info("echo deb 5a <min_nsec> <max_nsec> :Sniff on given range\n");
+#endif
+	return rc;
+}
+
+static inline int sniff_ts_inconsistency_f(int emac_idx, u32 ts)
+{
+#ifdef SNIFF_TS_INCONSISTENCY_ON_RANGE
+	static u32 prev_ts, prev_nnsec;
+	u32 sec, nsec, nnsec, diff;
+	if (!sniff_ts_inconsistency_port_no || (emac_idx != sniff_ts_inconsistency_port_no))
+		return 0;
+	sec = ts >> 30;
+	nsec = ts & 0x3fffffff;
+	nnsec =  convert2nnsec(sec, nsec);
+	diff = nnsec - prev_nnsec;
+	if (post_prt_cntr) {
+		post_prt_cntr--;
+		if (rx_ts_dbg_idx < RX_TS_DBG_SIZE) {
+			rx_ts_dbg[rx_ts_dbg_idx].prev_ts = ts;
+			rx_ts_dbg_idx++;
+		}
+		goto exit;
+	}
+	if ((diff >= sniff_min) && (diff <= sniff_max))
+		goto exit;
+	if ((sec == 0) && ((prev_ts >> 30) == 3))
+		goto exit;
+	/* Do not print but save for print by sysfs command */
+	if (rx_ts_dbg_idx < RX_TS_DBG_SIZE) {
+		rx_ts_dbg[rx_ts_dbg_idx].prev_ts = prev_ts;
+		rx_ts_dbg[rx_ts_dbg_idx].ts = ts;
+		rx_ts_dbg[rx_ts_dbg_idx].diff = diff;
+		rx_ts_dbg_idx++;
+	}
+	post_prt_cntr = 2;
+exit:
+	prev_ts = ts;
+	prev_nnsec = nnsec;
+#else
+	static u32 prev_ts;
+	if (!sniff_ts_inconsistency_port_no || (emac_idx != sniff_ts_inconsistency_port_no))
+		return 0;
+	if (prev_ts < ts)
+		goto exit; /* all is ok */
+	if (((prev_ts >> 30) == 3) && ((ts >> 30) == 0))
+		goto exit; /*wrap 3.xxx to 0.xxx is ok */
+
+	pr_err("PREV: %08x=%u.%09u, CURR: %08x=%u.%09u\n",
+		prev_ts, prev_ts>>30, prev_ts & 0x3fffffff,
+		     ts,      ts>>30,      ts & 0x3fffffff);
+exit:
+	prev_ts = ts;
+#endif /*SNIFF_TS_INCONSISTENCY_ON_RANGE*/
+	return 1;
+}
+
+static inline void PTP_RX_TS_DBG_CAPTURE(int emac_idx, int pkt_len, u32 ts)
+{
+	if (sniff_ts_inconsistency_f(emac_idx, ts))
+		return;
+#ifndef SNIFF_TS_INCONSISTENCY_ON_RANGE
+	if (rx_ts_dbg_idx < RX_TS_DBG_SIZE) {
+		rx_ts_dbg[rx_ts_dbg_idx].port = emac_idx;
+		rx_ts_dbg[rx_ts_dbg_idx].len = pkt_len;
+		rx_ts_dbg[rx_ts_dbg_idx].ts = ts;
+		rx_ts_dbg_idx++;
+	}
+#endif
+}
+
+static void PTP_RX_TS_DBG_PRINT(int clear_stats_only, int rc_code)
+{
+	u32 i, prev, sec, nsec, nnsec, prev_nnsec;
+	struct rx_ts_dbg_s *p;
+
+	if (rc_code >= 0x10)
+		return;
+
+	rx_ts_dbg_idx = RX_TS_DBG_SIZE; /* disable capturing */
+
+	if (clear_stats_only)
+		goto clear_exit;
+
+	p = &rx_ts_dbg[0];
+#ifdef SNIFF_TS_INCONSISTENCY_ON_RANGE
+	prev = prev;
+	sec = sec;
+	nsec = nsec;
+	nnsec = nnsec;
+	prev_nnsec = prev_nnsec;
+	i = 0;
+	for (i = 0; i < RX_TS_DBG_SIZE; i++) {
+		if (p->prev_ts == 0) {
+			pr_err("=== RX TS CAPTURE END on %d ===\n", i);
+			goto clear_exit;
+		}
+		pr_err("%08x=%u.%09u - %08x=%u.%09u = %6u\n",
+			p->prev_ts, p->prev_ts >> 30, p->prev_ts & 0x3fffffff,
+			p->ts, p->ts >> 30, p->ts & 0x3fffffff,
+			p->diff);
+		p++;
+	}
+#else /*SNIFF_TS_INCONSISTENCY_ON_RANGE*/
+	i = 0;
+	if (rx_ts_dbg[i].len) {
+		sec = rx_ts_dbg[i].ts >> 30;
+		nsec = rx_ts_dbg[i].ts & 0x3fffffff;
+		pr_err("%d: len=%-4d, ts=%08x=%u.%09u\n",
+			rx_ts_dbg[i].port, rx_ts_dbg[i].len,
+			rx_ts_dbg[i].ts, sec, nsec);
+	}
+	prev = 0;
+	i = 1;
+	while (i < RX_TS_DBG_SIZE) {
+		if (rx_ts_dbg[i].len == 0) {
+			pr_err("=== RX TS CAPTURE END on %d ===\n", i);
+			goto clear_exit;
+		}
+		sec = rx_ts_dbg[prev].ts >> 30;
+		nsec = rx_ts_dbg[prev].ts & 0x3fffffff;
+		prev_nnsec = convert2nnsec(sec, nsec);
+
+		sec = rx_ts_dbg[i].ts >> 30;
+		nsec = rx_ts_dbg[i].ts & 0x3fffffff;
+		nnsec =  convert2nnsec(sec, nsec);
+
+		pr_err("%d: len=%-4d, ts=%08x=%u.%09u (%6u)\n",
+			rx_ts_dbg[i].port, rx_ts_dbg[i].len,
+			rx_ts_dbg[i].ts, sec, nsec,
+			nnsec - prev_nnsec);
+		i++;
+		prev++;
+	}
+#endif /*SNIFF_TS_INCONSISTENCY_ON_RANGE*/
+clear_exit:
+	memset(rx_ts_dbg, 0, sizeof(rx_ts_dbg));
+	rx_ts_dbg_idx = 0;
+}
+#endif/*PTP_ALL_RX_TS_DBG_CAPTURE*/
+
+
+/*******************************************************************************
+ *  General purpose packet dump utility
+ */
+#ifdef PTP_PACKET_DUMP
+static void pp3_pack_dump(char *desc, char *data, int offs_begin, int pack_len)
+{
+	char buf[100];
+	int pos, i, k;
+	if (!desc)
+		desc = " ";
+	pr_info("--- packet dump:%s: offs=%d, pack-len=%d ---\n",
+		desc, offs_begin, pack_len);
+	i = offs_begin;
+	do {
+		/* Prepare and print 1 line */
+		for (pos = 0, k = 0;  k < 16; k++) {
+			if (k == 8)
+				pos += sprintf(buf + pos, " ");
+			pos += sprintf(buf + pos, " %02X", data[i]);
+			if (++i == pack_len)
+				break;
+		}
+		pr_info("%s\n", buf);
+		/* continue on another line */
+	} while (i < pack_len);
+}
+#endif/*PTP_PACKET_DUMP*/
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_service.h b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_service.h
new file mode 100644
index 0000000..17a824f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_service.h
@@ -0,0 +1,36 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+#ifndef __mv_ptp_h__
+#define __mv_ptp_h__
+
+#ifdef __KERNEL__
+/* includes */
+#include "gop/mv_ptp_if.h"
+#else
+/* This "mv_*_regs.h is also included in User-space UIO */
+#endif
+
+void mv_ptp_hook_enable(int port, bool enable);
+void mv_ptp_hook_extra_op(u32 val1, u32 val2, u32 val3);
+
+#ifdef __KERNEL__
+/* Probre/Init should be called with/after mv_pp3_ptp_enable() */
+int mv_pp3_ptp_tai_tod_uio_init(struct platform_device *shared_pdev);
+#endif
+
+#endif /* __mv_ptp_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_uio.c b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_uio.c
new file mode 100644
index 0000000..979d0b1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/net_dev/mv_ptp_uio.c
@@ -0,0 +1,195 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+/******************************************************************************
+**
+**      UIO deriver and device adding
+**
+** Gives direct access to TAI/PTP registers in user-space over UIO-mapping
+** Complicated actions are executed over ".set = write_store_cmd":
+**     write to /sys/module/mv_pp3/parameters/ts_tai_tod_uio
+**
+** If CONFIG_MV_PP3_PTP_SERVICE is not enabled, does nothing but
+** provides stub function mv_pp3_ptp_tai_tod_uio_init()
+*******************************************************************************
+*/
+#ifndef CONFIG_MV_PP3_PTP_SERVICE
+int mv_pp3_ptp_tai_tod_uio_init(struct platform_device *shared_pdev)
+{ return 0; }
+#else /* CONFIG_MV_PP3_PTP_SERVICE */
+
+/* includes */
+#include <linux/kernel.h>
+#include <linux/uio_driver.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/of.h>
+
+#include "gop/a390_mg_if.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_regs.h"
+#include "gop/mv_tai_regs.h"
+#include "net_dev/mv_ptp_service.h"
+
+
+#define TS_NAME	"ts_tai_tod"
+#define TS_NAME_UIO	"ts_tai_tod_uio"
+
+struct ts_ptp_uio {
+	struct uio_info uio_info;
+	/* Auxiliary parameters */
+	u32 dedicated_mg_region;
+	u32 dedicated_mg_region_offs;
+};
+
+static struct ts_ptp_uio *ts_ptp_uio;
+
+static int read_show_cmd(char *buf, const struct kernel_param *kp)
+{
+	struct ts_ptp_uio *p = (void *)(*(u32 *)(kp->arg));
+	if (p) {
+		sprintf(buf, "region=%d region_offs=%x size=%lx",
+			p->dedicated_mg_region, p->dedicated_mg_region_offs,
+			p->uio_info.mem[0].size);
+		pr_debug("%s device is used with parameters: %s\n", kp->name, buf);
+	}
+	return strlen(buf);
+}
+
+static int write_store_cmd(const char *buf, const struct kernel_param *kp)
+{
+	struct mv_pp3_tai_tod *ts;
+	int rc;
+	if (buf[0]) {
+		pr_err("%s: write/store called with ASCII: <%s>\n", TS_NAME_UIO, buf);
+		return 0;
+	}
+	ts = (struct mv_pp3_tai_tod *)buf;
+	if (ts->operation == MV_TAI_GET_CAPTURE) {
+		/* For DEBUG only */
+		/* mv_pp3_tai_tod_op(ts->operation, ts, 0); - already in "ts" */
+		mv_pp3_tai_tod_dump_util(ts);
+		return 0;
+	}
+	/* Real operation called over "parameters/ts_tai_tod_uio" write
+	 * as an alternative to the UIO direct access in user space
+	 */
+	rc = mv_pp3_tai_tod_op(ts->operation, ts, 0);
+	return rc;
+}
+
+static const struct kernel_param_ops param_ops = {
+	.get = read_show_cmd,
+	.set = write_store_cmd,
+};
+module_param_cb(ts_tai_tod_uio, &param_ops, &ts_ptp_uio, 0644);
+
+
+static int ts_ptp_uio_probe(struct platform_device *pdev)
+{
+	int ret;
+	u32 gop_pa;
+	u32 gop_va;
+	u32 gop_size;
+
+	ts_ptp_uio = kzalloc(sizeof(struct ts_ptp_uio), GFP_KERNEL);
+	if (!ts_ptp_uio) {
+		pr_err("%s: out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	ret = mv_gop_addrs_size_get(&gop_va, &gop_pa, &gop_size);
+	if (ret) {
+		pr_err("%s: mv_gop_base_addr_get() failed\n", __func__);
+		ret = 0; /* say OK to continue sys-up without this driver */
+		goto err;
+	}
+
+	platform_set_drvdata(pdev, ts_ptp_uio);
+	ts_ptp_uio->uio_info.name = TS_NAME;
+	ts_ptp_uio->uio_info.version = "v1";
+#ifdef MV_PP3_DEDICATED_MG_REGION
+	/* Address-convert for TAI/PTP registers
+	 *   TAI: 0x03180A00..0x03180B00
+	 *   PTP: 0x03180800..0x03180874 ... port3:0x03183800..0x03183874
+	 *   => TAI/PTP Register(offset) 0318pXXX
+	 * With indirect MG address completion the final Mapping is:
+	 *    0318pXXX -> REGION7(111b << 19) -> 0038pXXX
+	 * TAI-access un User-space is like:
+	 *    *(u32*)(gop_va + 0x00380000 + RegisterOFFS)
+	 *
+	 * Without dedicated region the UIO has no mmap and could be used
+	 * by application only over read_show_cmd, write_store_cmd
+	 */
+	ts_ptp_uio->uio_info.mem[0].name = TS_NAME;
+	ts_ptp_uio->uio_info.mem[0].addr = gop_pa;
+	ts_ptp_uio->uio_info.mem[0].internal_addr = (void *)gop_va;
+	ts_ptp_uio->uio_info.mem[0].size = gop_size;
+	ts_ptp_uio->dedicated_mg_region = MV_PP3_DEDICATED_MG_REGION;
+	ts_ptp_uio->dedicated_mg_region_offs = MV_PP3_DEDICATED_MG_REGION << 19;
+	ts_ptp_uio->uio_info.mem[0].memtype = UIO_MEM_PHYS;
+#endif
+	ts_ptp_uio->uio_info.priv = ts_ptp_uio;
+
+	if (uio_register_device(&pdev->dev, &ts_ptp_uio->uio_info)) {
+		pr_err("%s: register device fails!\n", __func__);
+		goto err;
+	}
+	return 0;
+err:
+	kfree(ts_ptp_uio);
+	ts_ptp_uio = NULL;
+	return ret;
+}
+
+static struct platform_driver ts_tai_tod_driver = {
+	.driver = {
+		.name = TS_NAME,
+		.owner = THIS_MODULE
+	},
+};
+
+int mv_pp3_ptp_tai_tod_uio_init(struct platform_device *shared_pdev)
+{
+	/* This probe-init is extention of mv_pp3_shared_probe()
+	 * but called in very late stage (!) as part of PTP init.
+	 * It is using the shared_pdev imported from net_dev
+	 */
+	int rc;
+
+	/* Could be called more than once but only 1 created */
+	if (ts_ptp_uio)
+		return 0;
+
+	if (!shared_pdev)
+		return 0;
+	rc = ts_ptp_uio_probe(shared_pdev);
+	if (!rc)
+		rc = platform_driver_register(&ts_tai_tod_driver);
+
+	if (rc)
+		pr_err("%s: Can't register %s driver. rc=%d\n", __func__, TS_NAME, rc);
+	return rc;
+}
+
+MODULE_AUTHOR("Yan Markman");
+MODULE_DESCRIPTION("UIO driver for Marvell TAI-ToD");
+MODULE_LICENSE("GPL");
+#endif /* CONFIG_MV_PP3_PTP_SERVICE */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/a390_gic_odmi_if.h b/drivers/net/ethernet/marvell/pp3/platform/a390_gic_odmi_if.h
new file mode 100644
index 0000000..215c813
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/a390_gic_odmi_if.h
@@ -0,0 +1,55 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __a390_gic_odmi_if_h__
+#define __a390_gic_odmi_if_h__
+
+#include "common/mv_hw_if.h"
+
+#define MV_A390_GIC_INT_GROUPS_NUM	(8)	/* number of interrupt groups per frame in ODMI */
+#define MV_A390_GIC_INT_SINGLE_GR_NUM	(6)	/* number of single interrupt groups per frame in ODMI */
+
+#define MV_A390_GIC_REGS_OFFS				(0x19000)
+
+#define MV_A390_GIC_INTERRUPT_REG(f)			(0x40 + (0x2000)*(f) + MV_A390_GIC_REGS_OFFS)
+
+#define MV_A390_GIC_ODMI_EPR0_REG(f, g)			(0x100 + 0x2000*(f) + 0x10*(g) + MV_A390_GIC_REGS_OFFS)
+
+#define MV_A390_GIC_RXQ_INT_SET(val, q)			(val |= (1 << ((q) * 2)))
+#define MV_A390_GIC_RXQ_INT_GET(val, q)			(((val) >> ((q) * 2)) & 1)
+
+/*-------------------------------------------------------------------------*/
+
+
+/* read GIC ODMI Event Pending Register in GICP unit */
+static inline u32 a390_gic_odmi_epr_read(int frame, int event_group)
+{
+	void __iomem *base = mv_pp3_nss_regs_vaddr_get();
+
+	return mv_pp3_hw_reg_read(base + MV_A390_GIC_ODMI_EPR0_REG(frame, event_group));
+}
+
+/* write GIC ODMI Event Pending Register in GICP unit */
+static inline void a390_gic_odmi_epr_write(int frame, int event_group, int data)
+{
+	void __iomem *base = mv_pp3_nss_regs_vaddr_get();
+
+	return mv_pp3_hw_reg_write(base + MV_A390_GIC_ODMI_EPR0_REG(frame, event_group), data);
+}
+
+#endif /* __a390_gic_odmi_if_h__*/
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_a2m.h b/drivers/net/ethernet/marvell/pp3/platform/mv_a2m.h
new file mode 100644
index 0000000..d56c151
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_a2m.h
@@ -0,0 +1,63 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_a2m_h__
+#define __mv_a2m_h__
+
+
+#define MV_PP3_A2M_MAX_MASTER		2
+#define MV_PP3_A2M_MAX_DECODE_WIN	8
+
+#define MV_PP3_A2M_WIN_CTRL_REG(win)	(0x00 + 8 * (win))
+
+/* Fields of MV_NSS_A2M_WIN_CTRL_REG regsiter */
+#define PP3_A2M_WIN_ENABLE_BIT		0
+#define PP3_A2M_WIN_ENABLE_MASK		(1 << PP3_A2M_WIN_ENABLE_BIT)
+
+#define PP3_A2M_WIN_USR_ATTR_BIT	1
+#define PP3_A2M_WIN_USR_ATTR_MASK	(1 << PP3_A2M_WIN_USR_ATTR_BIT)
+
+#define PP3_A2M_WIN_TARGET_OFFS		4
+#define PP3_A2M_WIN_TARGET_MASK		(0xf << PP3_A2M_WIN_TARGET_OFFS)
+
+/* The target associated with this window*/
+#define PP3_A2M_WIN_TARGET_OFFS		4
+#define PP3_A2M_WIN_TARGET_MASK		(0xf << PP3_A2M_WIN_TARGET_OFFS)
+
+/* The target attributes associated with window */
+#define PP3_A2M_WIN_ATTR_OFFS		8
+#define PP3_A2M_WIN_ATTR_MASK		(0xff << PP3_A2M_WIN_ATTR_OFFS)
+
+#define PP3_A2M_WIN_SIZE_OFFS		16
+#define PP3_A2M_WIN_SIZE_MASK		(0xFFFF << PP3_A2M_WIN_SIZE_OFFS)
+/*-------------------------------------------------------------------------*/
+
+#define MV_PP3_A2M_WIN_BASE_REG(win)	(0x04 + 8 * (win))
+
+/* The Base address associated with window */
+#define PP3_A2M_WIN_BASE_OFFS		16
+#define PP3_A2M_WIN_BASE_MASK		(0xFFFF << PP3_A2M_WIN_BASE_OFFS)
+/*-------------------------------------------------------------------------*/
+
+#define PP3_AMB_CTRL0_REG(n)		(0xC0 + (n) * 0x20)
+#define PP3_AMB_CTRL1_REG(n)		(0xC4 + (n) * 0x20)
+#define PP3_AMB_MASK0_REG(n)		(0xD0 + (n) * 0x20)
+#define PP3_AMB_MASK1_REG(n)		(0xD4 + (n) * 0x20)
+/*-------------------------------------------------------------------------*/
+
+#endif /* __mv_a2m_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.c b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.c
new file mode 100644
index 0000000..290b8da
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.c
@@ -0,0 +1,1036 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "mv_pp3.h"
+
+#include <net/gnss/mv_nss_defs.h>
+#include <linux/mbus.h>
+#include <linux/phy.h>
+#include <linux/of_net.h>
+#include <linux/msi.h>
+#ifdef CONFIG_HIGH_RES_TIMERS
+#include <linux/hrtimer.h>
+#include <linux/ktime.h>
+#endif
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_if.h"
+#include "gop/mv_smi.h"
+#include "hmac/mv_hmac.h"
+#include "emac/mv_emac.h"
+#include "cmac/mv_cmac.h"
+#include "fw/mv_fw.h"
+#include "fw/mv_pp3_fw_msg_structs.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "msg/mv_pp3_msg_chan.h"
+#include "bm/mv_bm.h"
+#include "qm/mv_qm.h"
+#include "tm/mv_tm.h"
+#include "tm/wrappers/mv_tm_drop.h"
+#include "vport/mv_pp3_vport.h"
+#include "vport/mv_pp3_cpu.h"
+#include "msg/mv_pp3_msg_drv.h"
+#include "net_dev/mv_netdev.h"
+#include "net_dev/mv_dev_sysfs.h"
+#include "common/mv_sw_if.h"
+#include "a390_gic_odmi_if.h"
+
+#define MV_PP3_SHARED_NAME        "mv_pp3_shared"
+
+struct mv_pp3	*pp3_device;
+
+/* Manage drop profiles for HWQ level */
+struct pp3_dp_ctrl {
+	u32 id;
+	u16 td;
+	u16 red;
+	int ref_count;
+};
+
+bool coherency_hard_mode;
+
+static u8   mv_pp3_dp_q_curve_id;
+static struct pp3_dp_ctrl mv_pp3_dp_q_ctrl[MV_TM_NUM_QUEUE_DROP_PROF];
+
+/* Reconfigure Drop profile */
+static int mv_pp3_dp_q_set(int dp_id, u16 td, u16 red)
+{
+	int i, rc;
+	struct mv_tm_drop_profile drop_profile;
+
+	drop_profile.cbtd_threshold = (u32)(td * 1024 / 16);
+
+	/* Colored Tail Drop Enable: 0 - WRED, 1 - CATD */
+	drop_profile.color_td_en = 0;
+
+	/* Set the same values for all colors */
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		drop_profile.min_threshold[i] = (u32)(red * 1024 / 16);
+		drop_profile.max_threshold[i] = (u32)(td * 1024 / 16);
+		drop_profile.curve_id[i] = mv_pp3_dp_q_curve_id;
+		drop_profile.curve_scale[i] = 0;
+	}
+	rc = mv_tm_drop_profile_set(TM_Q_LEVEL, dp_id, -1, &drop_profile);
+	if (rc) {
+		pr_err("Can't set drop profile #%d. rc=%d\n", dp_id, rc);
+		return rc;
+	}
+
+	pr_info("Drop profile #%d is created: td=%d, red=%d\n",
+		dp_id, td, red);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Create default curve */
+static int mv_pp3_dp_q_curve_create(void)
+{
+	int i, rc;
+
+	/* Once time initialization. We will use the same curve for all drop profiles */
+	memset(mv_pp3_dp_q_ctrl, 0, sizeof(mv_pp3_dp_q_ctrl));
+	for (i = 0; i < MV_TM_NUM_QUEUE_DROP_PROF; i++)
+		mv_pp3_dp_q_ctrl[i].id = i;
+
+	/* for Q_LEVEL: cos=-1, maximum drop probability is 50% */
+	rc = mv_tm_create_wred_curve(TM_Q_LEVEL, -1, 50, &mv_pp3_dp_q_curve_id);
+	if (rc) {
+		pr_err("Can't create WRED curve: err = %d\n", rc);
+		return -1;
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_dp_q_find(u16 td, u16 red)
+{
+	int i, rc;
+	struct pp3_dp_ctrl *dp_ctrl = NULL;
+
+	/* Look for existing drop profile with "td" and "red" values */
+	for (i = 1; i < MV_TM_NUM_QUEUE_DROP_PROF; i++) {
+		dp_ctrl = &mv_pp3_dp_q_ctrl[i];
+
+		if ((dp_ctrl->ref_count > 0) && (dp_ctrl->td == td) && (dp_ctrl->red == red)) {
+			dp_ctrl->ref_count++;
+			return i;
+		}
+	}
+	/* Look for unused drop profile */
+	for (i = 1; i < MV_TM_NUM_QUEUE_DROP_PROF; i++) {
+		dp_ctrl = &mv_pp3_dp_q_ctrl[i];
+		if (dp_ctrl->ref_count == 0) {
+			rc = mv_pp3_dp_q_set(i, td, red);
+			if (rc)
+				return rc;
+
+			dp_ctrl->td = td;
+			dp_ctrl->red = red;
+			dp_ctrl->ref_count++;
+			return i;
+		}
+	}
+	pr_err("No free drop profile for td=%u, red=%u\n", td, red);
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Free DP - decrement reference count */
+void mv_pp3_dp_q_free(int dp_id)
+{
+	struct pp3_dp_ctrl *dp_ctrl = NULL;
+
+	/* dp_id == 0 is default drop profile for ALL HWQs with no profile */
+	if (dp_id != 0) {
+		dp_ctrl = &mv_pp3_dp_q_ctrl[dp_id];
+		if (dp_ctrl && dp_ctrl->ref_count > 0)
+			dp_ctrl->ref_count--;
+	}
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_nss_drain(struct mv_pp3 *priv)
+{
+	int cpu;
+
+	/* stop all open network interfaces */
+	/*mv_pp3_netdev_close_all();*/
+
+	pr_info("%s: CMAC state wait ==> %d\n", __func__, mv_cmac_idle_state_check());
+	mv_pp3_ppc_idle_wait_all();
+
+	for_each_possible_cpu(cpu)
+		mv_pp3_cpu_close(priv, cpu);
+
+
+	tm_close();
+	mv_pp3_drv_messenger_close();
+	mv_pp3_messenger_close();
+
+	mv_pp3_fw_memory_free(priv);
+
+	priv->initialized = false;
+
+	/* re-init configurator clients */
+	mv_pp3_configurator_close();
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Create sysfs commands tree under directory: "/sys/devices/platform/pp3" */
+static int pp3_sysfs_init(struct mv_pp3 *priv)
+{
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp3");
+	if (!pd) {
+		priv->sysfs_pdev = platform_device_register_simple("pp3", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp3");
+	}
+
+	if (!pd) {
+		pr_err("%s: cannot find pp3 device\n", __func__);
+		return -1;
+	}
+	mv_pp3_gop_sysfs_init(&pd->kobj);
+	mv_pp3_emac_sysfs_init(&pd->kobj);
+	mv_pp3_hmac_sysfs_init(&pd->kobj);
+	mv_pp3_fw_sysfs_init(&pd->kobj);
+	mv_pp3_bm_sysfs_init(&pd->kobj);
+	mv_pp3_qm_sysfs_init(&pd->kobj);
+	mv_pp3_tm_sysfs_init(&pd->kobj);
+	mv_pp3_chan_sysfs_init(&pd->kobj);
+	mv_pp3_dev_sysfs_init(&pd->kobj);
+	mv_pp3_init_sysfs_init(&pd->kobj);
+	mv_pp3_debug_sysfs_init(&pd->kobj);
+	mv_pp3_cmac_sysfs_init(&pd->kobj);
+	mv_pp3_vport_sysfs_init(&pd->kobj);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+static void pp3_sysfs_exit(struct mv_pp3 *priv)
+{
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp3");
+	if (!pd) {
+		pr_err("%s: cannot find pp3 device\n", __func__);
+		return;
+	}
+	mv_pp3_vport_sysfs_exit(&pd->kobj);
+	mv_pp3_debug_sysfs_exit(&pd->kobj);
+	mv_pp3_init_sysfs_exit(&pd->kobj);
+	mv_pp3_dev_sysfs_exit(&pd->kobj);
+	mv_pp3_emac_sysfs_exit(&pd->kobj);
+	mv_pp3_gop_sysfs_exit(&pd->kobj);
+	mv_pp3_hmac_sysfs_exit(&pd->kobj);
+	mv_pp3_cmac_sysfs_exit(&pd->kobj);
+	mv_pp3_fw_sysfs_exit(&pd->kobj);
+	mv_pp3_bm_sysfs_exit(&pd->kobj);
+	mv_pp3_qm_sysfs_exit(&pd->kobj);
+	mv_pp3_tm_sysfs_exit(&pd->kobj);
+	mv_pp3_chan_sysfs_exit(&pd->kobj);
+
+	platform_device_unregister(priv->sysfs_pdev);
+}
+
+/*---------------------------------------------------------------------------*/
+#ifdef CONFIG_HIGH_RES_TIMERS
+/* high resolution timer callback function */
+static enum hrtimer_restart mv_pp3_hr_timer_callback(struct hrtimer *timer)
+{
+	struct mv_pp3_timer *pp3_timer = container_of(timer, struct mv_pp3_timer, hr_timer);
+
+	if (pp3_timer->wq) {
+		struct work_struct work = pp3_timer->timer_work->work;
+		/* TODO debug error */
+		if (!queue_work(pp3_timer->wq, &work))
+			pr_err("%s: Internal error, work already in queue\n", __func__);
+	} else
+		tasklet_schedule(&pp3_timer->tasklet);
+
+	return HRTIMER_NORESTART;
+}
+#endif /* CONFIG_HIGH_RES_TIMERS */
+/*---------------------------------------------------------------------------*/
+
+/* normal timer callback function */
+static void mv_pp3_normal_timer_callback(unsigned long data)
+{
+
+	struct mv_pp3_timer *pp3_timer = (struct mv_pp3_timer *)data;
+	STAT_INFO(pp3_timer->stats.timer_sched++);
+
+	if (pp3_timer->wq) {
+		if (!queue_work(pp3_timer->wq, &pp3_timer->timer_work->work))
+			pr_err("%s: Internal error, work already in queue\n", __func__);
+	} else
+		tasklet_schedule(&pp3_timer->tasklet);
+	return;
+}
+
+/* work queue callback function */
+/*---------------------------------------------------------------------------*/
+static void mv_pp3_workqueue_callback(struct work_struct *curr_work)
+{
+	struct pp3_timer_work *timer_work = container_of(curr_work, struct pp3_timer_work, work);
+	timer_work->cb_func(timer_work->cookie);
+}
+
+/*---------------------------------------------------------------------------*/
+/* pp3 timer initialization
+	func   - callback function, must call to mv_pp3_timer_complete
+	usec   - timer time interval
+	cookie - cookie for user usage
+*/
+int mv_pp3_timer_init(struct mv_pp3_timer *pp3_timer, unsigned int cpu, unsigned int usec,
+			enum mv_pp3_timer_internal_type type,
+			void (*func)(unsigned long), unsigned long cookie)
+{
+	if (!pp3_timer) {
+		pr_err("%s: timer pointer is NULL\n", __func__);
+		return -EINVAL;
+	}
+
+	if (test_bit(MV_PP3_TIMER_INIT_BIT, &pp3_timer->flags)) {
+		pr_err("%s: error - timer already initialized\n", __func__);
+		return -1;
+	}
+
+	memset(pp3_timer, 0, sizeof(struct mv_pp3_timer));
+
+#ifdef CONFIG_HIGH_RES_TIMERS
+	/* Init high resolution timer */
+	hrtimer_init(&pp3_timer->hr_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
+	pp3_timer->hr_timer.function = mv_pp3_hr_timer_callback;
+#endif /* CONFIG_HIGH_RES_TIMERS */
+
+	/* Init normal timer */
+	init_timer(&pp3_timer->normal_timer);
+	pp3_timer->normal_timer.function = mv_pp3_normal_timer_callback;
+	pp3_timer->normal_timer.data = (unsigned long)pp3_timer;
+	clear_bit(MV_PP3_TIMER_SCHED_BIT, &(pp3_timer->flags));
+	set_bit(MV_PP3_TIMER_INIT_BIT, &(pp3_timer->flags));
+
+	/* Tasklet init */
+	if (type == MV_PP3_TASKLET) {
+		tasklet_init(&pp3_timer->tasklet, func, cookie);
+		pp3_timer->wq = NULL;
+
+	} else {
+		pp3_timer->wq = create_singlethread_workqueue("pp3_timer_wq");
+		if (!pp3_timer->wq) {
+			pr_err("%s - Out of memeory\n", __func__);
+			return -1;
+		}
+
+		pp3_timer->timer_work = kmalloc(sizeof(struct pp3_timer_work), GFP_KERNEL);
+		INIT_WORK(&pp3_timer->timer_work->work, mv_pp3_workqueue_callback);
+		pp3_timer->timer_work->cookie = cookie;
+		pp3_timer->timer_work->cb_func = func;
+	}
+
+	/* set timer usec and type */
+	mv_pp3_timer_usec_set(pp3_timer, usec);
+	pp3_timer->cpu = cpu;
+	pr_info("PP3 timer (%s based) initialized on CPU #%d successfully\n",
+		(type == MV_PP3_WORKQUEUE) ? "work queue" : "tasklet", cpu);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+/* kill timer */
+int mv_pp3_timer_kill(struct mv_pp3_timer *pp3_timer)
+{
+	if (!pp3_timer) {
+		pr_err("%s: timer pointer is NULL\n", __func__);
+		return -EINVAL;
+	}
+	if (pp3_timer->wq) {
+		flush_workqueue(pp3_timer->wq);
+		destroy_workqueue(pp3_timer->wq);
+		kfree(pp3_timer->timer_work);
+	} else
+		tasklet_kill(&pp3_timer->tasklet);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_timer_usec_set(struct mv_pp3_timer *pp3_timer, unsigned long usec)
+{
+	/* 1 jiffy is minimal time or normal timer */
+	if (usec < jiffies_to_usecs(1)) {
+#ifndef CONFIG_HIGH_RES_TIMERS
+		pr_err("%s: Error - invalid time period, must be >= %d usec\n", __func__, jiffies_to_usecs(1));
+		return -1;
+#endif
+		pp3_timer->type =  MV_PP3_HRES_TIMER;
+	} else
+		pp3_timer->type =  MV_PP3_NORMAL_TIMER;
+
+	pp3_timer->usec = usec;
+
+	return 0;
+}
+
+#if 0
+/*---------------------------------------------------------------------------*/
+/* return timer type that currently in use */
+enum mv_pp3_timer_type mv_pp3_timer_type_get(struct mv_pp3_timer *pp3_timer)
+{
+	return pp3_timer->type;
+}
+#endif
+
+/*---------------------------------------------------------------------------*/
+/* Create and remap window to access GoP registers */
+static int mv_pp3_gop_window_remap(struct platform_device *pdev, struct mv_io_addr *gop_addr)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct device_node *gop_node;
+	u32 target_id, win_attr;
+	u32 remap_addr, gop_size, gop_pbase;
+
+	/*
+	 * The mvebu-mbus DT binding currently doesn't allow
+	 * describing static windows with the remap capability, so we
+	 * simply use the mvebu-mbus API to dynamically create the
+	 * required window. This should be changed once mvebu-mbus is
+	 * extended to cover such a case.
+	 */
+	gop_node = of_parse_phandle(np, "gop_access", 0);
+	if (gop_node) {
+		if (of_property_read_u32(gop_node, "gop-base", &gop_pbase)) {
+			pr_err("could not get gop base\n");
+			return -1;
+		}
+		if (of_property_read_u32(gop_node, "gop-size", &gop_size)) {
+			pr_err("could not get gop size\n");
+			return -1;
+		}
+		if (of_property_read_u32(gop_node, "mg-target-id", &target_id)) {
+			pr_err("could not get target_id\n");
+			return -1;
+		}
+		if (of_property_read_u32(gop_node, "mg-attr", &win_attr)) {
+			pr_err("could not get win_attr\n");
+			return -1;
+		}
+		if (of_property_read_u32(gop_node, "mg-remap-base", &remap_addr)) {
+			pr_err("could not get remap_addr\n");
+			return -1;
+		}
+		if (mvebu_mbus_add_window_remap_by_id(target_id, win_attr,
+				(phys_addr_t)gop_pbase, (size_t)gop_size, (phys_addr_t)remap_addr)) {
+			pr_err("can't remap gop window\n");
+			return -1;
+		}
+		gop_addr->paddr = (phys_addr_t)gop_pbase;
+		gop_addr->size = (size_t)gop_size;
+	} else {
+		pr_err("can't find gop_access node\n");
+		return -1;
+	}
+	return 0;
+}
+
+static int mv_pp3_a2m_win_init(struct mv_pp3 *priv)
+{
+	int i, master;
+	const struct mbus_dram_target_info *dram;
+
+	/* First disable all A2M address decode windows */
+	for (master = 0; master < MV_PP3_A2M_MAX_MASTER; master++) {
+		for (i = 0; i < MV_PP3_A2M_MAX_DECODE_WIN; i++)
+			mv_pp3_hw_reg_write(priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_CTRL_REG(i), 0);
+	}
+
+	dram = mv_mbus_dram_info();
+	if (!dram) {
+		pr_err("%s: No DRAM information\n", __func__);
+		return -ENODEV;
+	}
+	pr_info("A2M decoding windows initialization: DRAM info found - num_cs=%d\n", dram->num_cs);
+	for (i = 0; i < dram->num_cs; i++) {
+		const struct mbus_dram_window *cs = dram->cs + i;
+		u32 baseReg, base = cs->base;
+		u32 ctrlReg, size = cs->size;
+		u8 attr = cs->mbus_attr;
+		u8 target = dram->mbus_dram_target_id;
+
+		/* check if address is aligned to the size */
+		if (MV_IS_NOT_ALIGN(base, size)) {
+			pr_err("%s: Wrong DRAM info cs=%d. Addr=0x%08x is not aligned to size=0x%x\n",
+			   __func__, i, base, size);
+			return -EINVAL;
+		}
+
+		if (!MV_IS_POWER_OF_2(size)) {
+			pr_err("%s: Wrong DRAM info cs=%d. Size=0x%x is not a power of 2\n",
+				__func__, i, size);
+			return -EINVAL;
+		}
+
+		baseReg = (base & PP3_A2M_WIN_BASE_MASK);
+
+		/* set size */
+		ctrlReg = ((((size / (64 * 1024)) - 1) << PP3_A2M_WIN_SIZE_OFFS) & PP3_A2M_WIN_SIZE_MASK);
+
+		/* set attributes */
+		ctrlReg |= ((attr << PP3_A2M_WIN_ATTR_OFFS) & PP3_A2M_WIN_ATTR_MASK);
+
+		/* set target ID */
+		ctrlReg |= ((target << PP3_A2M_WIN_TARGET_OFFS) & PP3_A2M_WIN_TARGET_MASK);
+
+		/* set user attribute enable bit */
+		ctrlReg |= PP3_A2M_WIN_USR_ATTR_MASK;
+
+		/* set user attribute enable bit */
+		ctrlReg |= PP3_A2M_WIN_ENABLE_MASK;
+		pr_info("%s: DRAM CS #%d, base=0x%x, size=0x%x, target=0x%x, attr=0x%x\n", __func__,
+			i, base, size, target, attr);
+
+		for (master = 0; master < MV_PP3_A2M_MAX_MASTER; master++) {
+			mv_pp3_hw_reg_write(priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_CTRL_REG(i), ctrlReg);
+			mv_pp3_hw_reg_write(priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_BASE_REG(i), baseReg);
+			pr_info("%s: DRAM CS #%d, Master=%d, baseReg: %p=0x%x, ctrlReg: %p=0x%x\n", __func__,
+				i, master, priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_BASE_REG(i), baseReg,
+					priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_CTRL_REG(i), ctrlReg);
+		}
+	}
+
+	for (master = 0; master < MV_PP3_A2M_MAX_MASTER; master++) {
+		u32 ctrlReg;
+		/* open window to ODMI registers */
+		ctrlReg = ((1 << PP3_A2M_WIN_TARGET_OFFS) & PP3_A2M_WIN_TARGET_MASK);
+		/* set user attribute enable bit */
+		ctrlReg |= PP3_A2M_WIN_ENABLE_MASK;
+
+		/* Init 64K window for internal registers */
+		mv_pp3_hw_reg_write(priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_CTRL_REG(i), ctrlReg);
+		mv_pp3_hw_reg_write(priv->a2m_regs[master].vaddr + MV_PP3_A2M_WIN_BASE_REG(i),
+					priv->int_regs_paddr + MV_A390_GIC_REGS_OFFS);
+
+		/* init AMB registers */
+		mv_pp3_hw_reg_write(priv->amb_regs.vaddr + PP3_AMB_CTRL0_REG(master),
+					priv->int_regs_paddr + MV_A390_GIC_REGS_OFFS);
+		mv_pp3_hw_reg_write(priv->amb_regs.vaddr + PP3_AMB_CTRL1_REG(master), 0);
+		mv_pp3_hw_reg_write(priv->amb_regs.vaddr + PP3_AMB_MASK0_REG(master), 0x7fff);
+		mv_pp3_hw_reg_write(priv->amb_regs.vaddr + PP3_AMB_MASK1_REG(master), 0);
+	}
+	return 0;
+}
+
+/* Print information from struct mv_pp3 */
+void mv_pp3_device_show(struct mv_pp3 *priv)
+{
+	int master;
+
+	pr_info("Core Tclock rate        : %d MHz\n", priv->tclk_hz / (1000 * 1000));
+	pr_info("Number of ports         : %d\n", priv->ports_num);
+	pr_info("IRQ base                : %d\n", priv->irq_base);
+	pr_info("NSS registers base      : PHYS = %pa, VIRT = %p, size = %d KBytes\n",
+		&priv->nss_regs.paddr, priv->nss_regs.vaddr, priv->nss_regs.size / 1024);
+	pr_info("GoP registers base      : PHYS = %pa, VIRT = %p, size = %d KBytes\n",
+		&priv->gop_regs.paddr, priv->gop_regs.vaddr, priv->gop_regs.size / 1024);
+	pr_info("AMB registers base      : PHYS = %pa, VIRT = %p, size = %d KBytes\n",
+		&priv->amb_regs.paddr, priv->amb_regs.vaddr, priv->amb_regs.size / 1024);
+	for (master = 0; master < MV_PP3_A2M_MAX_MASTER; master++) {
+		pr_info("A2M_%d registers base    : PHYS = %pa, VIRT = %p, size = %d KBytes\n",
+			master, &priv->a2m_regs[master].paddr,
+			priv->a2m_regs[master].vaddr, priv->a2m_regs[master].size / 1024);
+	}
+	pr_info("Short pool buffer size  : %d\n", priv->short_pool_buf_size);
+}
+
+/*---------------------------------------------------------------------------*/
+/* HW initialization of pools 0-3 (QM internal pools)			     */
+/*---------------------------------------------------------------------------*/
+static int mv_pp3_bm_qm_init(void)
+{
+	int ppc_num, hw_txq, hwq_num, ret_val = 0;
+	struct pp3_pool *pools[2];
+
+	/* config rd/wr dram attributes  */
+	bm_attr_all_pools_def_set();
+
+	pools[0] = mv_pp3_pool_get(BM_QM_GPM_POOL_0);
+	pools[1] = mv_pp3_pool_get(BM_QM_GPM_POOL_1);
+
+	mv_pp3_pools_qm_gpm_sw_init(pools[0], pools[1]);
+	ret_val = mv_pp3_pools_qm_hw_init(pools[0], pools[1]);
+	if (ret_val < 0)
+		goto err;
+
+	pools[0] = mv_pp3_pool_get(BM_QM_DRAM_POOL_0);
+	pools[1] = mv_pp3_pool_get(BM_QM_DRAM_POOL_1);
+	if (pools[0] || pools[1]) {
+		mv_pp3_pools_qm_dram_sw_init(pools[0], pools[1]);
+		ret_val = mv_pp3_pools_qm_hw_init(pools[0], pools[1]);
+		if (ret_val < 0)
+			goto err;
+	}
+
+	bm_enable();
+
+	qm_clear_hw_config();
+	ppc_num = mv_pp3_fw_ppc_num_get();
+	qm_default_set(ppc_num);
+	qm_dma_gpm_pools_def_enable();
+
+	mv_pp3_cfg_dp_hw_txq_get(&hw_txq, &hwq_num);
+
+	/* set hmac->ppc queues for secret machine */
+	qm_xoff_hmac_qs_set(hw_txq, hwq_num);
+
+	/* set hmac threshold profile,
+	   attached hmac->ppc queues to profile */
+
+	qm_hmac_profile_set(hw_txq, hwq_num);
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_shared_start(struct mv_pp3 *priv)
+{
+	int cpu, frame, profile, rc;
+	struct mv_pp3_version fw_ver, *drv_ver;
+	char *version_name;
+	int ver_name_size;
+
+	if (priv->initialized)
+		return 0;
+
+	/* smi init */
+	mv_gop_smi_init();
+
+	/* load fw */
+	if (mv_pp3_fw_load()) {
+		pr_err("Firmware load failed\n");
+		return -1;
+	}
+
+	/* default frame configuration */
+	for (frame = 0; frame < MV_PP3_HFRM_NUM; frame++) {
+		mv_pp3_hmac_frame_cfg(frame, 0);
+
+		for (profile = 0; profile < MV_PP3_HFRM_TIME_COAL_PROF_NUM; profile++)
+			mv_pp3_hmac_frame_time_coal_set(frame, profile, CONFIG_MV_PP3_RX_COAL_USEC);
+	}
+
+#ifdef CONFIG_MV_PP3_TM_SUPPORT
+	tm_cfg1();
+#endif /* CONFIG_MV_PP3_TM_SUPPORT */
+
+	/* Create default DP curve */
+	mv_pp3_dp_q_curve_create();
+
+	/* init configurator clients */
+	mv_pp3_configurator_init(priv);
+
+	mv_pp3_bm_qm_init();
+
+	/* default CMAC and EIP-197 configuration */
+	mv_pp3_cmac_config();
+
+	/* run ppn */
+	mv_pp3_ppc_run_all();
+
+	/* init cpu's structures */
+	for_each_possible_cpu(cpu) {
+		mv_pp3_cpu_sw_init(pp3_cpus[cpu]);
+		mv_pp3_cpu_hw_init(pp3_cpus[cpu]);
+	}
+
+	mv_pp3_messenger_init(priv);
+	mv_pp3_drv_messenger_init(MV_PP3_CHAN_SIZE, false);
+
+	/* get FW version */
+	rc = pp3_fw_version_get(&fw_ver);
+	if (rc) {
+		pr_err("FW version is unknown. rc = %d\n", rc);
+		return -1;
+	}
+
+	ver_name_size = sizeof(fw_ver.name);
+	version_name = kzalloc(ver_name_size + 1, GFP_KERNEL);
+	if (!version_name)
+		return -ENOMEM;
+
+	drv_ver = mv_pp3_get_driver_version();
+	memcpy(version_name, drv_ver->name, ver_name_size);
+	pr_info("\n");
+	pr_info("Driver version: %s:%d.%d.%d.%d",
+			version_name, drv_ver->major_x, drv_ver->minor_y, drv_ver->local_z, drv_ver->debug_d);
+
+	memcpy(version_name, fw_ver.name, ver_name_size);
+	pr_info("FW version:     %s:%d.%d.%d.%d\n",
+			version_name, fw_ver.major_x, fw_ver.minor_y, fw_ver.local_z, fw_ver.debug_d);
+
+	kfree(version_name);
+
+	/* Send request for memory buffer size needed by FW */
+	if (mv_pp3_fw_memory_alloc(pp3_device) < 0)
+		return -1;
+
+	/* initialized CPUs virtual ports */
+	for_each_possible_cpu(cpu)
+		if (pp3_fw_cpu_vport_set(MV_PP3_CPU_VPORT_ID(cpu)) < 0)
+			return -1;
+
+	priv->initialized = true;
+
+	return 0;
+}
+
+static void mv_pp3_set_msi_msg(struct msi_desc *desc, struct msi_msg *msg)
+{
+	pr_info("PP3 MSI CB LO:%x HI:%x DATA:%x\n", msg->address_lo, msg->address_hi, msg->data);
+}
+
+static int mv_pp3_shared_probe(struct platform_device *pdev)
+{
+	int master, pool, cpu, i, ret;
+	struct device_node *np = pdev->dev.of_node;
+	struct device_node *child;
+	struct msi_desc *msi_desc;
+	struct resource *a2m[MV_PP3_A2M_MAX_MASTER], *amb, *nss_regs;
+	struct net_device *dev;
+	char name[20];
+
+	coherency_hard_mode = coherency_available();
+
+	pp3_device = kzalloc(sizeof(struct mv_pp3), GFP_KERNEL);
+	if (!pp3_device) {
+		pr_err("%s: out of memory\n", __func__);
+		return -ENOMEM;
+	}
+
+	pp3_device->pdev = pdev;
+	of_property_read_u32(np, "clock-frequency", &pp3_device->tclk_hz);
+	pp3_device->ports_num = MV_PP3_EMAC_NUM;
+
+	ret = platform_msi_domain_alloc_irqs(&pdev->dev, 32,
+					     mv_pp3_set_msi_msg);
+	if (ret) {
+		pr_err("pp3: paltform domain alloc error:%s\n", np->full_name);
+		return ret;
+	}
+
+	msi_desc = first_msi_entry(&pdev->dev);
+	if (!msi_desc) {
+		pr_err("no msi desc for pdev name:%s\n", np->full_name);
+		/*platform_msi_domain_free_irqs(&pdev->dev);*/
+		return -ENODEV;
+	}
+
+	pp3_device->irq_base = msi_desc->irq;
+
+	pr_info("PP3 PROBE RX_ISR_BASE:%u full name:%s\n", pp3_device->irq_base, np->full_name);
+
+	/*
+	 * The mvebu-mbus DT binding currently doesn't allow
+	 * describing static windows with the remap capability, so we
+	 * simply use the mvebu-mbus API to dynamically create the
+	 * required window. This should be changed once mvebu-mbus is
+	 * extended to cover such a case.
+	 */
+	if (mv_pp3_gop_window_remap(pdev, &pp3_device->gop_regs) == -1)
+		return -ENODEV;
+
+	pp3_device->gop_regs.vaddr = devm_ioremap(&pdev->dev, pp3_device->gop_regs.paddr,
+								pp3_device->gop_regs.size);
+	if (!pp3_device->gop_regs.vaddr) {
+		pr_err("Can not map MG registers, aborting\n");
+		return -EBUSY;
+	}
+
+	for (master = 0; master < MV_PP3_A2M_MAX_MASTER; master++) {
+		a2m[master] = platform_get_resource(pdev, IORESOURCE_MEM, master);
+		if (!a2m[master]) {
+			pr_err("Can not find A2M_%d registers base address, aborting\n", master);
+			return -ENODEV;
+		}
+		pp3_device->a2m_regs[master].paddr = a2m[master]->start;
+		pp3_device->a2m_regs[master].size = resource_size(a2m[master]);
+		pp3_device->a2m_regs[master].vaddr = devm_ioremap(&pdev->dev, a2m[master]->start,
+									resource_size(a2m[master]));
+		if (!pp3_device->a2m_regs[master].vaddr) {
+			pr_err("Can not map A2M_%d registers, aborting\n", master);
+			return -EBUSY;
+		}
+	}
+	/* store physical base address of CPU cluster */
+	pp3_device->int_regs_paddr = pp3_device->a2m_regs[0].paddr & 0xFF000000;
+
+	/* map AMB registers space */
+	amb = platform_get_resource(pdev, IORESOURCE_MEM, 2);
+	if (!amb) {
+		pr_err("Can not find AMB registers base address, aborting\n");
+		return -ENODEV;
+	}
+	pp3_device->amb_regs.paddr = amb->start;
+	pp3_device->amb_regs.size = resource_size(amb);
+	pp3_device->amb_regs.vaddr = devm_ioremap(&pdev->dev, amb->start, resource_size(amb));
+	if (!pp3_device->amb_regs.vaddr) {
+		pr_err("Cannot map PP3 AMB registers, aborting\n");
+		return -EBUSY;
+	}
+
+	/* map NSS registers space */
+	nss_regs = platform_get_resource(pdev, IORESOURCE_MEM, 3);
+	if (!nss_regs) {
+		pr_err("Can not find NSS registers base address, aborting\n");
+		return -ENODEV;
+	}
+	pp3_device->nss_regs.paddr = nss_regs->start;
+	pp3_device->nss_regs.size = resource_size(nss_regs);
+	pp3_device->nss_regs.vaddr = devm_ioremap(&pdev->dev, nss_regs->start, resource_size(nss_regs));
+	if (!pp3_device->nss_regs.vaddr) {
+		pr_err("Can not map NSS registers, aborting\n");
+		return -EBUSY;
+	}
+	pp3_device->short_pool_buf_size = CONFIG_MV_PP3_BM_SHORT_BUF_SIZE;
+	mv_pp3_device_show(pp3_device);
+
+	if (mv_pp3_a2m_win_init(pp3_device)) {
+		pr_err("Cannot initialize PP3 A2M windows, aborting\n");
+		return -EBUSY;
+	}
+
+	/* Basic initialization for all sub-modules and allocate all shared resources */
+	mv_gop_init(&pp3_device->gop_regs, MV_PP3_GOP_MAC_NUM, INDIRECT_MG_ACCESS);
+
+	/* TAI clock init (must be after gop) */
+	mv_pp3_ptp_tclk_hz_set(pp3_device->tclk_hz);
+	mv_pp3_tai_clock_init(pdev);
+
+	mv_pp3_emac_global_init(MV_PP3_EMAC_NUM);
+	for (i = 0; i < MV_PP3_EMAC_NUM; i++) {
+		/* EMACs are enabled by HW default. Disable them first. */
+		mv_pp3_emac_unit_base(i, pp3_device->nss_regs.vaddr + MV_PP3_EMAC_BASE(i));
+		mv_pp3_emac_rx_enable(i, 0);
+	}
+
+	qm_init(pp3_device->nss_regs.vaddr);
+	tm_global_init(pp3_device->nss_regs.vaddr, "A390");
+	mv_pp3_hmac_init(pp3_device);
+	mv_pp3_cmac_init(pp3_device->nss_regs.vaddr);
+	mv_pp3_bm_init(pp3_device->nss_regs.vaddr);
+
+	/* set number of active PPCS */
+	mv_pp3_fw_ppc_num_set(CONFIG_MV_PP3_PPC_NUM);
+
+	/* init FW and allocate DRAM memory for each active PPC */
+	mv_pp3_fw_init(pp3_device);
+
+	if (mv_pp3_vports_global_init(pp3_device, MV_PP3_COMMON_VPORTS_NUM))
+		return -ENODEV;
+
+	if (mv_pp3_cpus_global_init(pp3_device, nr_cpu_ids))
+		return -ENODEV;
+
+	if (mv_pp3_pools_global_init(pp3_device, BM_POOLS_NUM))
+		return -ENODEV;
+
+	/* QM pools allocation */
+	pr_info("  o QM GPM pools memory allocation\n");
+	for (pool = BM_QM_GPM_POOL_0; pool <= BM_QM_GPM_POOL_1; pool++) {
+		struct pp3_pool *ppool;
+
+		pr_cont("\t  o GPM pool %d: capacity = %d elements - ", pool, BM_QM_GPM_POOL_CAPACITY);
+		ppool = mv_pp3_pool_alloc(BM_QM_GPM_POOL_CAPACITY);
+		if (!ppool)
+			return -ENOMEM;
+
+		pr_cont("%d bytes of coherent memory allocated\n", ppool->capacity * sizeof(unsigned int));
+		mv_pp3_pool_set_id(ppool, pool);
+	}
+
+	/* allocate CPU private and pools */
+	for_each_possible_cpu(cpu) {
+		pr_info("  o CPU %d memory allocation\n", cpu);
+		if (mv_pp3_cpu_alloc(cpu) == NULL)
+			return -ENOMEM;
+	}
+
+	mv_pp3_netdev_global_init(pp3_device);
+
+	/* Create netdevice interfaces if needed */
+
+	for_each_child_of_node(np, child) {
+		if (!of_device_is_available(child))
+			continue;
+
+		if (!strcmp(child->name, "nic")) {
+			of_property_read_u32(child, "id", &i);
+			sprintf(name, "nic%d", i);
+			dev = mv_pp3_netdev_init(name, CONFIG_MV_PP3_RXQ_NUM, CONFIG_MV_PP3_TXQ_NUM);
+			if (!dev)
+				return -ENODEV;
+
+			mv_pp3_netdev_set_emac_params(dev, child);
+			mv_pp3_netdev_show(dev);
+		}
+	}
+	if (pp3_sysfs_init(pp3_device) < 0)
+		pr_err("NSS init - sysfs initialization failed\n");
+
+	return 0;
+}
+/* Init mac data according to node mac data */
+int mv_pp3_ftd_mac_data_get(struct device_node *np, struct mv_mac_data *mac_data)
+{
+	struct device_node *emac_node;
+	struct device_node *phy_node;
+	int phy_mode, err;
+	const char *force_link;
+	u32 speed;
+
+	/* TODO add emac id to printouts */
+	emac_node = of_parse_phandle(np, "emac-data", 0);
+	if (!emac_node) {
+		pr_info("%s: No EMAC data\n", __func__);
+		return 0;
+	}
+
+	phy_mode = of_get_phy_mode(emac_node);
+
+	switch (phy_mode) {
+	case PHY_INTERFACE_MODE_SGMII:
+		speed = 0;
+		/* check phy speed */
+		of_property_read_u32(emac_node, "phy-speed", &speed);
+		switch (speed) {
+		case 1000:
+			mac_data->port_mode = MV_PORT_SGMII;
+			break;
+		case 2500:
+			mac_data->port_mode = MV_PORT_SGMII2_5;
+			break;
+		default:
+			mac_data->port_mode = MV_PORT_SGMII;
+			break;
+		}
+		break;
+	case PHY_INTERFACE_MODE_RXAUI:
+		mac_data->port_mode = MV_PORT_RXAUI;
+		break;
+	case PHY_INTERFACE_MODE_QSGMII:
+		mac_data->port_mode = MV_PORT_QSGMII;
+		break;
+	case PHY_INTERFACE_MODE_RGMII:
+		mac_data->port_mode = MV_PORT_RGMII;
+		break;
+	default:
+		pr_err("%s: incorrect phy-mode\n", __func__);
+		return -1;
+	}
+
+	phy_node = of_parse_phandle(emac_node, "phy", 0);
+	if (phy_node) {
+		if (of_property_read_u32(phy_node, "reg", &mac_data->phy_addr))
+			pr_err("%s: NO PHY address\n", __func__);
+	}
+
+	mac_data->link_irq = irq_of_parse_and_map(emac_node, 0);
+	pr_info("PP3 LINK IRQ: %d for %s\n", mac_data->link_irq, emac_node->full_name);
+	mac_data->force_link = false;
+	err = of_property_read_string(emac_node, "force-link", &force_link);
+	if (err >= 0) {
+		if (!strcasecmp(force_link, "yes"))
+			mac_data->force_link = true;
+	}
+	return 0;
+}
+
+int mv_pp3_fdt_mac_address_get(struct device_node *np, unsigned char *mac_addr)
+{
+	struct device_node *emac_node;
+	const char *node_mac_addr = NULL;
+
+	emac_node = of_parse_phandle(np, "emac-data", 0);
+	if (!emac_node) {
+		/* TODO add emac id to printouts */
+		pr_info("%s: No EMAC data\n", __func__);
+		return 0;
+	}
+
+	node_mac_addr = of_get_mac_address(emac_node);
+	if (node_mac_addr != NULL)
+		memcpy(mac_addr, node_mac_addr, MV_MAC_ADDR_SIZE);
+
+	return 0;
+}
+
+static int mv_pp3_shared_remove(struct platform_device *pdev)
+{
+	/* free all shared resources */
+	pr_err("%s:: called", __func__);
+	return 0;
+}
+
+static const struct of_device_id mv_pp3_shared_match[] = {
+	{ .compatible = "marvell,armada-390-pp3" },
+	{}
+};
+MODULE_DEVICE_TABLE(of, mv_pp3_shared_match);
+
+static struct platform_driver mv_pp3_shared_driver = {
+	.probe		= mv_pp3_shared_probe,
+	.remove		= mv_pp3_shared_remove,
+	.driver = {
+		.name	= MV_PP3_SHARED_NAME,
+		.owner	= THIS_MODULE,
+		.of_match_table = mv_pp3_shared_match,
+	},
+};
+
+static int __init mv_pp3_init_module(void)
+{
+	int rc = 0;
+
+	rc = platform_driver_register(&mv_pp3_shared_driver);
+	if (rc) {
+		pr_err("%s: Can't register %s driver. rc=%d\n",
+			__func__, mv_pp3_shared_driver.driver.name, rc);
+		return rc;
+	}
+	return rc;
+}
+module_init(mv_pp3_init_module);
+/*---------------------------------------------------------------------------*/
+
+static void __exit mv_pp3_cleanup_module(void)
+{
+	platform_driver_unregister(&mv_pp3_shared_driver);
+}
+module_exit(mv_pp3_cleanup_module);
+/*-------------------------------------------------*/
+
+MODULE_DESCRIPTION("Marvell PPv3 Network Driver - www.marvell.com");
+MODULE_AUTHOR("Dmitri Epshtein <dima@marvell.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.h b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.h
new file mode 100644
index 0000000..18c54b0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3.h
@@ -0,0 +1,218 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_h__
+#define __mv_pp3_h__
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+#include <linux/workqueue.h>
+
+#ifdef CONFIG_MV_GNSS_SUPPORT
+#include <net/gnss/mv_nss_defs.h>
+#else
+#include <net/mvebu/mv_nss.h>
+#endif
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "mv_a2m.h"
+#include "mv_pp3_defs.h"
+#include "mv_pp3_cfh.h"
+
+
+struct mv_pp3 {
+	struct platform_device	*pdev;
+	struct  platform_device	*sysfs_pdev;
+	struct mv_io_addr	a2m_regs[MV_PP3_A2M_MAX_MASTER];
+	struct mv_io_addr	amb_regs;
+	struct mv_io_addr	nss_regs;
+	struct mv_io_addr	gop_regs;
+	phys_addr_t		int_regs_paddr;
+	u32			tclk_hz;
+	int			short_pool_buf_size;
+	unsigned int		ports_num;
+	unsigned int		irq_base;
+	bool			initialized;
+};
+
+extern struct mv_pp3 *pp3_device;
+
+enum mv_pp3_timer_type {
+	MV_PP3_HRES_TIMER,
+	MV_PP3_NORMAL_TIMER
+};
+
+enum mv_pp3_timer_internal_type {
+	MV_PP3_TASKLET,
+	MV_PP3_WORKQUEUE
+};
+
+struct pp3_timer_stats {
+	unsigned int timer_add;
+	unsigned int timer_sched;
+	unsigned int user_cnt1; /* generic counter, used as time usec_elapsed */
+	unsigned int user_cnt2;	/* generic counter, count timer iterations */
+
+};
+
+struct pp3_timer_work {
+	struct work_struct work;
+	unsigned long cookie;
+	void (*cb_func)(unsigned long param);
+};
+
+#define MV_PP3_TIMER_INIT_BIT		0
+#define MV_PP3_TIMER_SCHED_BIT		1
+
+struct mv_pp3_timer {
+	unsigned int		usec;          /* timer period int micro seconds */
+	unsigned int		cpu;	       /* cpu to run timer on */
+	enum mv_pp3_timer_type	type;
+	struct tasklet_struct	tasklet;
+	struct workqueue_struct *wq;
+	struct pp3_timer_work	*timer_work;
+#ifdef CONFIG_HIGH_RES_TIMERS
+	struct hrtimer		hr_timer;      /* high resolutin timer */
+#endif
+	struct timer_list	normal_timer;  /* normal timer */
+	unsigned long		flags;
+	struct pp3_timer_stats  stats;
+};
+/*---------------------------------------------------------------------------*/
+static inline void mv_pp3_timer_complete(struct mv_pp3_timer *pp3_timer)
+{
+	clear_bit(MV_PP3_TIMER_SCHED_BIT, &(pp3_timer->flags));
+}
+
+/*---------------------------------------------------------------------------*/
+static inline bool mv_pp3_timer_is_initialized(struct mv_pp3_timer *pp3_timer)
+{
+	return test_bit(MV_PP3_TIMER_INIT_BIT, &(pp3_timer->flags)) ? true : false;
+}
+/*---------------------------------------------------------------------------*/
+static inline bool mv_pp3_timer_is_running(struct mv_pp3_timer *pp3_timer)
+{
+	return test_bit(MV_PP3_TIMER_SCHED_BIT, &(pp3_timer->flags)) ? true : false;
+}
+/*---------------------------------------------------------------------------*/
+/* add time period to timer on the current CPU */
+static inline void mv_pp3_timer_add(struct mv_pp3_timer *pp3_timer)
+{
+	if (test_and_set_bit(MV_PP3_TIMER_SCHED_BIT, &(pp3_timer->flags)))
+		return;
+
+	STAT_INFO(pp3_timer->stats.timer_add++);
+
+#ifdef CONFIG_HIGH_RES_TIMERS
+	if (pp3_timer->type == MV_PP3_HRES_TIMER) {
+		ktime_t interval = ktime_set(0, pp3_timer->usec * 1000); /* 0 seconds, delay_in_ns nanoseconds */
+		hrtimer_start(&pp3_timer->hr_timer, interval, HRTIMER_MODE_REL_PINNED);
+		return;
+	}
+#endif /* CONFIG_HIGH_RES_TIMERS */
+	if (pp3_timer->usec) {
+		pp3_timer->normal_timer.expires = jiffies + usecs_to_jiffies(pp3_timer->usec);
+		add_timer_on(&pp3_timer->normal_timer, pp3_timer->cpu);
+	}
+}
+
+
+/* Timer initialization */
+int mv_pp3_timer_init(struct mv_pp3_timer *pp3_timer, unsigned int cpu, unsigned int usec,
+			enum mv_pp3_timer_internal_type type, void (*func)(unsigned long), unsigned long cookie);
+/* Timer kill */
+int mv_pp3_timer_kill(struct mv_pp3_timer *pp3_timer);
+
+ /* Add time period to timer on the current CPU */
+void mv_pp3_timer_add(struct mv_pp3_timer *pp3_timer);
+
+/* Set timer time period, input in micro seconds */
+int mv_pp3_timer_usec_set(struct mv_pp3_timer *pp3_timer, unsigned long usec);
+
+#if 0
+/* Get current timer type, high resolution or normal */
+enum mv_pp3_timer_type mv_pp3_timer_type_get(struct mv_pp3_timer *pp3_timer);
+
+#endif
+/* Return value of TCLOCK (core) in Hz */
+static inline u32 mv_pp3_silicon_tclk_get(void)
+{
+	return pp3_device->tclk_hz;
+}
+
+/* Return virtual address for NSS access */
+static inline void *mv_pp3_nss_regs_vaddr_get(void)
+{
+	return pp3_device->nss_regs.vaddr;
+}
+
+/* Return physical address for internal registers access */
+static inline phys_addr_t mv_pp3_internal_regs_paddr_get(struct mv_pp3 *priv)
+{
+	return priv->int_regs_paddr;
+}
+
+static inline struct platform_device *mv_pp3_platform_dev_get(struct mv_pp3 *priv)
+{
+	return priv->pdev;
+}
+
+static inline struct device *mv_pp3_dev_get(struct mv_pp3 *priv)
+{
+	struct platform_device *pdev = mv_pp3_platform_dev_get(priv);
+
+	return &pdev->dev;
+}
+
+static inline int mv_pp3_ports_num_get(struct mv_pp3 *priv)
+{
+	return priv->ports_num;
+}
+
+static inline bool mv_pp3_shared_initialized(struct mv_pp3 *priv)
+{
+	return priv->initialized;
+}
+
+static inline int mv_pp3_irq_base_get(struct mv_pp3 *priv)
+{
+	return priv->irq_base;
+}
+
+/* Function prorotypes */
+int mv_pp3_fdt_mac_address_get(struct device_node *np, unsigned char *mac_addr);
+int mv_pp3_ftd_mac_data_get(struct device_node *np, struct mv_mac_data *mac_data);
+struct mv_pp3_version *mv_pp3_get_driver_version(void);
+int mv_pp3_shared_start(struct mv_pp3 *priv);
+int mv_pp3_init_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_init_sysfs_exit(struct kobject *pp3_kobj);
+int mv_pp3_debug_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_debug_sysfs_exit(struct kobject *pp3_kobj);
+int mv_pp3_nss_drain(struct mv_pp3 *priv);
+int mv_pp3_dp_q_find(u16 td, u16 red);
+void mv_pp3_dp_q_free(int dp_id);
+
+
+#endif /* __mv_pp3_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_cfh.h b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_cfh.h
new file mode 100644
index 0000000..e54f6ff
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_cfh.h
@@ -0,0 +1,329 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_cfh_h__
+#define __mv_pp3_cfh_h__
+
+#define MV_PP3_CFH_COMMON_WORDS			(8)	/* CFH common size in words */
+#define MV_PP3_CFH_HDR_SIZE			(32)	/* CFH header size in bytes */
+#define MV_PP3_CFH_ALIGN_HDR_SIZE		(64)	/* CFH header size aligned to 64 bytes to prevent dummy CFHs */
+#define MV_PP3_CFH_MDATA_SIZE			(32)	/* CFH meta data size in bytes */
+#define MV_PP3_CFH_PKT_SIZE			(MV_PP3_CFH_HDR_SIZE + MV_PP3_CFH_MDATA_SIZE)
+#define MV_PP3_CFH_PAYLOAD_MAX_SIZE		(MV_PP3_CFH_MAX_SIZE - MV_PP3_CFH_PKT_SIZE)
+#define MV_PP3_CFH_MAX_SIZE			(128)	/* CFH max size in bytes */
+#define MV_PP3_CFH_DG_SIZE			(16)	/* Datagram size in bytes */
+#define MV_PP3_CFH_PKT_DG_SIZE			(MV_PP3_CFH_PKT_SIZE/MV_PP3_CFH_DG_SIZE)
+#define MV_PP3_CFH_DG_MAX_NUM			(MV_PP3_CFH_MAX_SIZE / MV_PP3_CFH_DG_SIZE)
+
+struct mv_cfh_common {
+	u32 plen_order;
+	u32 ctrl;
+	u32 tag1;
+	u32 tag2;
+	u32 phys_l;
+	u32 vm_bp;
+	u32 marker_l;
+	u32 l3_l4_info;
+};
+
+enum mv_pp3_cfh_mode {
+	HMAC_CFH = 0,
+	EMAC_CFH,
+	CMAC_CFH,
+	RADIO_CFH
+};
+
+enum mv_pp3_cfh_pp_mode_tx {
+	PP_TX_PACKET = 0,
+	PP_TX_PACKET_NSS,
+	PP_TX_RESERVED,
+	PP_TX_MESSAGE
+};
+
+enum mv_pp3_cfh_pp_mode_rx {
+	PP_RX_PACKET = 0,
+	PP_RX_REASEM_PACKET,	/* Reassembly packet */
+	PP_RX_INV_PACKET,	/* Invalid packet */
+	PP_RX_MESSAGE
+};
+
+
+enum mv_pp3_cfh_l4_info_rx {
+	L4_RX_UNKNOWN = 0,
+	L4_RX_TCP,
+	L4_RX_TCP_CS_ERR,
+	L4_RX_UDP,
+	L4_RX_UDP_LITE,
+	L4_RX_UDP_CS_ERR,
+	L4_RX_IGMP,
+	L4_RX_OTHER
+};
+
+enum mv_pp3_cfh_l4_info_tx {
+	L4_TX_TCP = 0,
+	L4_TX_UDP
+};
+
+enum mv_pp3_cfh_vlan_info {
+	VLAN_UNTAGGED = 0,
+	VLAN_SINGLE,
+	VLAN_DOUBLE,
+	VLAN_RESERVED
+};
+
+enum mv_pp3_cfh_l2_info {
+	L2_UCAST = 0,
+	L2_MCAST,
+	L2_IP_MCAST,
+	L2_BCAST
+};
+
+enum mv_pp3_cfh_l3_info_rx {
+	L3_RX_UNKNOWN = 0,
+	L3_RX_IP4,
+	L3_RX_IP4_FRAG,
+	L3_RX_IP4_OPT,
+	L3_RX_IP4_ERR,
+	L3_RX_IP6,
+	L3_RX_IP6_EXT,
+	L3_RX_ARP
+};
+
+enum mv_pp3_cfh_l3_info_tx {
+	L3_TX_IP4 = 0,
+	L3_TX_IP6
+};
+enum mv_pp3_cfh_reorder {
+	REORD_BYPASS = 0,
+	REORD_NEW,
+	REOED_FIN,
+	REORD_RENEW
+};
+
+enum mv_pp3_l4_csum {
+	L4_CSUM = 0,
+	L4_CSUM_FRAG,
+	L4_CSUM_NOT
+};
+
+/*------------------------------------------------------*/
+/*	CFH - common fileds for packet and message	*/
+/*------------------------------------------------------*/
+
+/* word 0 */
+#define MV_CFH_PKT_LEN_OFFS		(0)
+#define MV_CFH_PKT_LEN_MASK		(0xFFFF)
+#define MV_CFH_PKT_LEN_SET(v)		(((v) & MV_CFH_PKT_LEN_MASK) << MV_CFH_PKT_LEN_OFFS)
+#define MV_CFH_PKT_LEN_GET(v)		(((v) >> MV_CFH_PKT_LEN_OFFS) & MV_CFH_PKT_LEN_MASK)
+
+
+#define MV_CFH_REORDER_OFFS		(28)
+#define MV_CFH_REORDER_MASK		(0x3)
+#define MV_CFH_REORDER_SET(v)		(((v) & MV_CFH_REORDER_MASK) << MV_CFH_REORDER_OFFS)
+#define MV_CFH_REORDER_GET(v)		(((v) >> MV_CFH_REORDER_OFFS) & MV_CFH_REORDER_MASK)
+
+#define MV_CFH_DEQ_MODE_BIT_OFFS	(30)	/* 0-packet 1-message */
+
+#define MV_CFH_DEQ_MODE_BIT_SET		(0x1 << MV_CFH_DEQ_MODE_BIT_OFFS)
+#define MV_CFH_DEQ_MODE_BIT_GET(v)	(((v) >> MV_CFH_DEQ_MODE_BIT_OFFS) & 0x1)
+
+#define MV_CFH_LAST_BIT_OFFS		(31)
+#define MV_CFH_LAST_BIT_SET		(0x1 << MV_CFH_LAST_BIT_OFFS)
+
+/* word 1 */
+
+#define MV_CFH_WR_OFFS			(0)	/* packet recived - Payload byte offset in buffer */
+#define MV_CFH_WR_MASK			(0xF)
+#define MV_CFH_WR_GET(v)		(((v) >> MV_CFH_WR_OFFS) & MV_CFH_WR_MASK)
+#define MV_CFH_WR_RES			(32)   /* 32 bytes resolution for normal (non reassembly) packets */
+#define MV_CFH_WR_REASEM_RES		(2)    /* 2 bytes resolution for reassembly packets */
+
+#define MV_CFH_RD_OFFS			(0)	/* packet transmit - Payload byte offset in buffer */
+#define MV_CFH_RD_MASK			(0x3FF)
+#define MV_CFH_RD_SET(v)		(((v) & MV_CFH_RD_MASK) << MV_CFH_RD_OFFS)
+
+#define MV_CFH_QC_BIT_OFFS		(13)
+#define MV_CFH_QC_BIT_SET		(0x1 << MV_CFH_QC_BIT_OFFS)
+#define MV_CFH_QC_BIT_GET(v)		(((v) >> MV_CFH_QC_OFFS) & 0x1)
+
+#define MV_CFH_SWQ_OFFS			(4)
+#define MV_CFH_SWQ_MASK			(0xFF)
+#define MV_CFH_SWQ_GET(v)		(((v) >> MV_CFH_SWQ_OFFS) & MV_CFH_SWQ_MASK)
+
+
+
+#define MV_CFH_LEN_OFFS			(16)
+#define MV_CFH_LEN_MASK			(0xFF)
+#define MV_CFH_LEN_SET(v)		(((v) & MV_CFH_LEN_MASK) << MV_CFH_LEN_OFFS)
+#define MV_CFH_LEN_GET(v)		(((v) >> MV_CFH_LEN_OFFS) & MV_CFH_LEN_MASK)
+
+#define MV_CFH_MODE_OFFS		(24)
+#define MV_CFH_MODE_MASK		(0x3)
+#define MV_CFH_MODE_SET(v)		(((v) & MV_CFH_MODE_MASK) << MV_CFH_MODE_OFFS)
+
+
+#define MV_CFH_MDATA_BIT_OFFS		(26)
+#define MV_CFH_MDATA_BIT_SET		(0x1 << MV_CFH_MDATA_BIT_OFFS)
+#define MV_CFH_MDATA_BIT_GET(v)		(((v) >> MV_CFH_MDATA_BIT_OFFS) & 0x1)
+
+#define MV_CFH_PP_MODE_OFFS		(30)
+#define MV_CFH_PP_MODE_MASK		(0x3)
+#define MV_CFH_PP_MODE_SET(v)		(((v) & MV_CFH_PP_MODE_MASK) << MV_CFH_PP_MODE_OFFS)
+#define MV_CFH_PP_MODE_GET(v)		(((v) >> MV_CFH_PP_MODE_OFFS) & MV_CFH_PP_MODE_MASK)
+
+/* CFH word 2 */
+#define MV_CFH_INIT_CS_OFSS		(0)
+#define MV_CFH_INIT_CS_MASK		(0xFFFF)
+
+#define MV_CFH_HWQ_OFFS			(16)	/* packet transmit - QM Q */
+#define MV_CFH_HWQ_MASK			(0xFFF)
+#define MV_CFH_HWQ_SET(v)		(((v) & MV_CFH_HWQ_MASK) << MV_CFH_HWQ_OFFS)
+
+#define MV_CFH_ADD_CRC_BIT_OFFS		(28)
+#define MV_CFH_ADD_CRC_BIT_SET		(1 << MV_CFH_ADD_CRC_BIT_OFFS)
+
+#define MV_CFH_L2_PAD_BIT_OFFS		(31)
+#define MV_CFH_L2_PAD_BIT_SET		(1 << MV_CFH_L2_PAD_BIT_OFFS)
+
+#define MV_CFH_CHAN_ID_OFFS		(16)	/* message transmit - set channel id */
+#define MV_CFH_CHAN_ID_MASK		(0xFF)
+#define MV_CFH_CHAN_ID_SET(v)		(((v) & MV_CFH_CHAN_ID_MASK) << MV_CFH_CHAN_ID_OFFS)
+
+#define MV_CFH_PTP_QS_OFFS		(26)
+#define MV_CFH_PTP_QS_MASK		(1)
+#define MV_CFH_PTP_QS_SET(v)		(((v) & MV_CFH_PTP_QS_MASK) << MV_CFH_PTP_QS_OFFS)
+#define MV_CFH_PTP_QS_GET(v)		(((v) >> MV_CFH_PTP_QS_OFFS) & 0x1)
+
+#define MV_CFH_PTP_TSE_OFFS		(27)
+#define MV_CFH_PTP_TSE_SET		(1 << MV_CFH_PTP_TSE_OFFS)
+#define MV_CFH_PTP_TSE_GET(v)		(((v) >> MV_CFH_PTP_TSE_OFFS) & 0x1)
+
+/* CFH word 3 */
+#define MV_CFH_PTP_TS_OFF_OFFS		(0)
+#define MV_CFH_PTP_TS_OFF_MASK		(0xFF)
+#define MV_CFH_PTP_TS_OFF_SET(v)	(((v) & MV_CFH_PTP_TS_OFF_MASK) << MV_CFH_PTP_TS_OFF_OFFS)
+#define MV_CFH_PTP_TS_OFF_GET(v)	(((v) >> MV_CFH_PTP_TS_OFF_OFFS) & MV_CFH_PTP_TS_OFF_MASK)
+
+#define MV_CFH_PTP_CS_OFF_OFFS		(8)
+#define MV_CFH_PTP_CS_OFF_MASK		(0xFF)
+#define MV_CFH_PTP_CS_OFF_SET(v)	(((v) & MV_CFH_PTP_CS_OFF_MASK) << MV_CFH_PTP_CS_OFF_OFFS)
+#define MV_CFH_PTP_CS_OFF_GET(v)	(((v) >> MV_CFH_PTP_CS_OFF_OFFS) & MV_CFH_PTP_CS_OFF_MASK)
+
+#define MV_CFH_PTP_CUE_OFFS		(16)
+#define MV_CFH_PTP_CUE_MASK		(1)
+#define MV_CFH_PTP_CUE_SET(v)		(((v) & MV_CFH_PTP_CUE_MASK) << MV_CFH_PTP_CUE_OFFS)
+#define MV_CFH_PTP_CUE_GET(v)		(((v) >> MV_CFH_PTP_CUE_OFFS) & MV_CFH_PTP_CUE_MASK)
+
+#define MV_CFH_PTP_PACT_OFFS		(17)	/* PTP action */
+#define MV_CFH_PTP_PACT_MASK		(0xF)
+#define MV_CFH_PTP_PACT_SET(v)		(((v) & MV_CFH_PTP_PACT_MASK) << MV_CFH_PTP_PACT_OFFS)
+#define MV_CFH_PTP_PACT_GET(v)		(((v) >> MV_CFH_PTP_PACT_OFFS) & MV_CFH_PTP_PACT_MASK)
+
+#define MV_CFH_PTP_WC_OFFS		(24)
+#define MV_CFH_PTP_WC_MASK		(1)
+#define MV_CFH_PTP_WC_SET(v)		(((v) & MV_CFH_PTP_WC_MASK) << MV_CFH_PTP_WC_OFFS)
+#define MV_CFH_PTP_WC_GET(v)		(((v) >> MV_CFH_PTP_WC_OFFS) & MV_CFH_PTP_WC_MASK)
+
+#define MV_CFH_PTP_SEC_OFFS		(30)
+#define MV_CFH_PTP_SEC_MASK		(3)
+#define MV_CFH_PTP_SEC_SET(v)		(((v) & MV_CFH_PTP_SEC_MASK) << MV_CFH_PTP_SEC_OFFS)
+#define MV_CFH_PTP_SEC_GET(v)		(((v) >> MV_CFH_PTP_SEC_OFFS) & MV_CFH_PTP_SEC_MASK)
+
+/* word 4 */
+#define MV_CFH_PHYS_L_OFFS		(0)
+#define MV_CFH_PHYS_L_MASK		(0xFFFFFFFF)
+
+/* word 5 */
+#define MV_CFH_PHYS_H_OFFS		(0x0)
+#define MV_CFH_PHYS_H_MASK		(0xFF)
+#define MV_CFH_PHYS_H_SET(v)		(((v) & MV_CFH_PHYS_H_MASK) << MV_CFH_PHYS_H_OFFS)
+#define MV_CFH_PHYS_H_GET(v)		(((v) >> MV_CFH_PHYS_H_OFFS) & MV_CFH_PHYS_H_MASK)
+
+#define MV_CFH_VMID_OFFS		(16)
+#define MV_CFH_VMID_MASK		(0xFF)
+#define MV_CFH_VMID_SET(v)		(((v) & MV_CFH_VMID_MASK) << MV_CFH_VMID_OFFS)
+
+#define MV_CFH_BPID_OFFS		(24)
+#define MV_CFH_BPID_MASK		(0xFF)
+#define MV_CFH_BPID_SET(v)		(((v) & MV_CFH_BPID_MASK) << MV_CFH_BPID_OFFS)
+#define MV_CFH_BPID_GET(v)		(((v) >> MV_CFH_BPID_OFFS) & MV_CFH_BPID_MASK)
+
+/* word 6 */
+#define MV_CFH_VIRT_L_OFFS		(0)
+#define MV_CFH_VIRT_L_MASK		(0xFF)
+
+
+/* CFH word 7 - received packet parsing*/
+
+#define MV_CFH_VIRT_H_OFFS		(0x0)
+#define MV_CFH_VIRT_H_MASK		(0xFF)
+#define MV_CFH_VIRT_H_SET(v)		(((v) & MV_CFH_VIRT_H_MASK) << MV_CFH_VIRT_H_OFFS)
+#define MV_CFH_VIRT_H_GET(v)		(((v) >> MV_CFH_VIRT_H_OFFS) & MV_CFH_VIRT_H_MASK)
+
+#define MV_CFH_L3_OFFS			(8)
+#define MV_CFH_L3_OFFS_MASK		(0x7f)
+#define MV_CFH_L3_OFFS_SET(v)		(((v) & MV_CFH_L3_OFFS_MASK) << MV_CFH_L3_OFFS)
+#define MV_CFH_L3_OFFS_GET(v)		(((v) >> MV_CFH_L3_OFFS) & MV_CFH_L3_OFFS_MASK)
+
+#define MV_CFH_MACME_BIT_OFFS		(15) /* packet recived */
+#define MV_CFH_MACME_BIT_GET(v)		(((v) >> MV_CFH_MACME_BIT_OFFS) & 0x1)
+
+#define MV_CFH_IP_CSUM_BIT_OFFS		(15) /* packet transmit cs calc */
+#define MV_CFH_IP_CSUM_DISABLE		(1 << MV_CFH_IP_CSUM_BIT_OFFS)
+
+#define MV_CFH_IPHDR_LEN_OFFS		(16)
+#define MV_CFH_IPHDR_LEN_MASK		(0x1F)
+#define MV_CFH_IPHDR_LEN_SET(v)		(((v) & MV_CFH_IPHDR_LEN_MASK) << MV_CFH_IPHDR_LEN_OFFS)
+#define MV_CFH_IPHDR_LEN_GET(v)		(((v) >> MV_CFH_IPHDR_LEN_OFFS) & MV_CFH_IPHDR_LEN_MASK)
+
+#define MV_CFH_L4_INFO_RX_OFFS		(21)
+#define MV_CFH_L4_INFO_RX_MASK		(0x7)
+#define MV_CFH_L4_INFO_RX_GET(v)	(((v) >> MV_CFH_L4_INFO_RX_OFFS) & MV_CFH_L4_INFO_RX_MASK)
+
+#define MV_CFH_VLAN_INFO_OFFS		(24)
+#define MV_CFH_VLAN_INFO_MASK		(0x3)
+#define MV_CFH_VLAN_INFO_GET(v)		(((v) >> MV_CFH_VLAN_INFO_OFFS) & MV_CFH_VLAN_INFO_MASK)
+
+#define MV_CFH_L4_CSUM_OFFS		(26) /* packet transmit cs calc */
+#define MV_CFH_L4_CSUM_MASK		(0x3)
+#define MV_CFH_L4_CSUM_SET(v)		(((v) & MV_CFH_L4_CSUM_MASK) << MV_CFH_L4_CSUM_OFFS)
+
+#define MV_CFH_MGMT_BIT_OFFS		(26)
+#define MV_CFH_MGMT_BIT_GET(v)		(((v) >> MV_CFH_MGMT_BIT_OFFS) & 0x1)
+
+#define MV_CFH_L2_INFO_OFFS		(27)
+#define MV_CFH_L2_INFO_MASK		(0x3)
+#define MV_CFH_L2_INFO_GET(v)		(((v) >> MV_CFH_L2_INFO_OFFS) & MV_CFH_L2_INFO_MASK)
+
+#define MV_CFH_L3_INFO_RX_OFFS		(29)
+#define MV_CFH_L3_INFO_RX_MASK		(0x7)
+#define MV_CFH_L3_INFO_RX_GET(v)	(((v) >> MV_CFH_L3_INFO_RX_OFFS) & MV_CFH_L3_INFO_RX_MASK)
+
+#define MV_CFH_L4_INFO_TX_OFFS		(28)
+#define MV_CFH_L4_INFO_TX_MASK		(0x3)
+#define MV_CFH_L4_INFO_TX_SET(v)	(((v) & MV_CFH_L4_INFO_TX_MASK) << MV_CFH_L4_INFO_TX_OFFS)
+
+#define MV_CFH_L3_INFO_TX_OFFS		(30)
+#define MV_CFH_L3_INFO_TX_MASK		(0x3)
+#define MV_CFH_L3_INFO_TX_SET(v)	(((v) & MV_CFH_L3_INFO_TX_MASK) << MV_CFH_L3_INFO_TX_OFFS)
+
+#endif /* __mv_pp3_cfh_h__ */
+
+
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.c b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.c
new file mode 100644
index 0000000..5bb6cfe
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.c
@@ -0,0 +1,870 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "mv_pp3.h"
+#include "mv_pp3_config.h"
+#include "bm/mv_bm.h"
+#include "hmac/mv_hmac.h"
+#include "emac/mv_emac.h"
+#include <net/gnss/mv_nss_defs.h>
+#include "tm_defs.h"
+#include "mv_tm_scheme.h"
+#include "a390_gic_odmi_if.h"
+
+/* store resource allocation per interface */
+struct mv_pp3_net_if_cfg {
+	bool   first_init_done;
+	u32    num_of_sw_q[MV_PP3_CPU_NUM];		/* reserved for this interface on one cpu */
+	struct mv_pp3_tm_node *anode[MV_PP3_HFRM_Q_NUM];/* A node reserved for sw queue */
+	struct mv_pp3_tm_node *tx_bnode;
+	struct mv_pp3_tm_node *rx_anode;
+	int if_frame;					/* HMAC frame reserved for this inteface */
+	int if_first_sw_q;				/* HMAC first queue reserved for interace */
+};
+
+struct mv_pp3_cpu_cfg {
+	u32 sw_free_rxq[MV_PP3_HFRM_NUM];	/* free HMAC RX SW queue number per frame */
+	u32 sw_free_txq[MV_PP3_HFRM_NUM];	/* free HMAC TX SW queue number per frame */
+	u32 free_irq_group[MV_PP3_HFRM_NUM];	/* free HMAC IRQ group number per frame */
+	u32 buffer_pool_id;			/* free GP pool number */
+	u32 bp_group_id;			/* internal back pressure group */
+	u32 irq_rx_base;			/* ODMI Interrupt Vector base number */
+	int frame_vip_vport[MV_PP3_HFRM_NUM];
+	bool vip_rx_if[MV_PP3_HFRM_NUM][MV_PP3_CPU_NUM];
+	bool vip_tx_if[MV_PP3_HFRM_NUM][MV_PP3_CPU_NUM];
+};
+
+static struct mv_pp3_hwq_cfg    mv_pp3_cfg_clients_info[PP3_CLIENTS_NUM];
+static struct mv_pp3_net_if_cfg mv_pp3_if_rxq_resources[MV_PP3_INTERNAL_CPU_PORT_NUM];
+static struct mv_pp3_net_if_cfg mv_pp3_if_txq_resources[MV_PP3_INTERNAL_CPU_PORT_NUM];
+static struct mv_pp3_cpu_cfg    mv_pp3_cfg_sw_info;
+
+static void mv_pp3_port_subtree_build(struct mv_pp3_tm_node *level_ptr, enum tm_level level, int node_id);
+static void mv_pp3_cfg_subtree_free(struct mv_pp3_tm_node *node);
+#ifdef PP3_DEBUG
+static void mv_pp3_port_subtree_print(struct mv_pp3_tm_node *node);
+#endif
+
+
+
+int mv_pp3_cfg_rx_irq_get(int id, int irq_group)
+{
+	int frame = mv_pp3_if_rxq_resources[id].if_frame;
+
+	return mv_pp3_cfg_sw_info.irq_rx_base + MV_PP3_SW_IRQ_OFF(frame, irq_group);
+}
+
+void mv_pp3_configurator_init(struct mv_pp3 *priv)
+{
+	int i;
+	int qm_ports[PP3_CLIENTS_NUM] = {TM_A0_PORT_PPC0_0, TM_A0_PORT_EMAC0, TM_A0_PORT_EMAC1,
+					 TM_A0_PORT_EMAC2, TM_A0_PORT_EMAC3, TM_A0_PORT_CMAC_IN,
+					 TM_A0_PORT_CMAC_LA, TM_A0_PORT_HMAC};
+
+	memset(mv_pp3_cfg_clients_info, 0, sizeof(mv_pp3_cfg_clients_info));
+	memset(&mv_pp3_cfg_sw_info, 0, sizeof(mv_pp3_cfg_sw_info));
+	memset(mv_pp3_if_rxq_resources, 0, sizeof(mv_pp3_if_rxq_resources));
+	memset(mv_pp3_if_txq_resources, 0, sizeof(mv_pp3_if_txq_resources));
+
+	mv_pp3_cfg_sw_info.irq_rx_base = priv->irq_base;
+	/* first GP pool number */
+	mv_pp3_cfg_sw_info.buffer_pool_id = BM_GP_POOL_MIN;
+	/* first internal BP group */
+	mv_pp3_cfg_sw_info.bp_group_id = 1;
+
+	for (i = 0; i < MV_PP3_HFRM_NUM; i++)
+		mv_pp3_cfg_sw_info.frame_vip_vport[i] = -1;
+
+	/* init configurator clients */
+	for (i = 0; i < PP3_CLIENTS_NUM; i++) {
+		mv_pp3_cfg_clients_info[i].qm_port_id = qm_ports[i];
+		mv_pp3_port_subtree_build(&mv_pp3_cfg_clients_info[i].port_nodes, C_LEVEL, qm_ports[i]);
+		mv_pp3_cfg_hwq_info_set(i, &mv_pp3_cfg_clients_info[i]);
+	}
+
+#ifdef PP3_DEBUG
+	/* print clients info */
+	for (i = 0; i < PP3_CLIENTS_NUM; i++) {
+		struct mv_pp3_tm_node *tmp = &mv_pp3_cfg_clients_info[i].port_nodes;
+		pr_info("\nPort %d:", mv_pp3_cfg_clients_info[i].qm_port_id);
+		pr_info("\t\tnode %d: first = %d, first_free = %d (%d), subnodes number = %d, queues = %d\n",
+		tmp->node_id, tmp->first_ch, tmp->first_free_q, tmp->first_q, tmp->num_of_ch, tmp->num_of_q);
+		mv_pp3_port_subtree_print(&mv_pp3_cfg_clients_info[i].port_nodes);
+	}
+#endif
+}
+
+void mv_pp3_configurator_close(void)
+{
+	int i;
+
+	/* free configurator clients tree */
+	for (i = 0; i < PP3_CLIENTS_NUM; i++) {
+		if (!mv_pp3_cfg_clients_info[i].port_nodes.sub_nodes)
+			continue;
+
+		mv_pp3_cfg_subtree_free(&mv_pp3_cfg_clients_info[i].port_nodes);
+	}
+}
+
+int mv_pp3_cfg_hwq_info_set(enum mv_pp3_cfg_clients cl, struct mv_pp3_hwq_cfg *cfg)
+{
+	struct mv_pp3_tm_node *cnode, *bnode, *anode;
+	int i, j;
+
+	if (cl >= PP3_CLIENTS_NUM)
+		return -1;
+
+	switch (cl) {
+	case PP3_PPC0_DP:
+		/* configure TX tree for better usage */
+		cnode = &cfg->port_nodes;
+		for (i = 0; i < cnode->num_of_ch; i++) {
+			bnode = &cnode->sub_nodes[i];
+			/* set on B level number of first free queue */
+			bnode->first_q = bnode->sub_nodes[0].first_ch;
+			bnode->first_free_q = bnode->first_q;
+			for (j = 0; j < bnode->num_of_ch; j++) {
+				anode = &bnode->sub_nodes[j];
+				/* set on A level number of first free queue */
+				anode->first_q = anode->first_ch;
+				anode->first_free_q = anode->first_q;
+			}
+			if (i == 0) {
+				cnode->first_q = bnode->first_q;
+				cnode->first_free_q = bnode->first_free_q;
+			}
+		}
+	break;
+	case PP3_HMAC_RX:
+		cnode = &cfg->port_nodes;
+		for (i = 0; i < cnode->num_of_ch; i++) {
+			bnode = &cnode->sub_nodes[i];
+			bnode->first_q = bnode->sub_nodes[0].first_ch;
+			bnode->first_free_q = bnode->first_q;
+			for (j = 0; j < bnode->num_of_ch; j++) {
+				anode = &bnode->sub_nodes[j];
+				/* set on A level number of first free queue */
+				anode->first_q = anode->first_ch;
+				anode->first_free_q = anode->first_q;
+			}
+			if (i == 0) {
+				cnode->first_q = bnode->first_q;
+				cnode->first_free_q = bnode->first_free_q;
+			}
+		}
+	break;
+	case PP3_EMAC0:
+	case PP3_EMAC1:
+	case PP3_EMAC2:
+	case PP3_EMAC3:
+		cnode = &cfg->port_nodes;
+		if (cnode->num_of_ch) {
+			bnode = &cnode->sub_nodes[0];
+			cnode->first_q = bnode->sub_nodes[0].first_ch;
+			cnode->first_free_q = cnode->first_q;
+		}
+		break;
+	default:
+		return -1;
+	}
+
+	return 0;
+}
+
+int mv_pp3_cfg_rx_bp_node_get(int hwq_base, int *node_type, int *node_num)
+{
+	if ((node_num == NULL) || (node_type == NULL))
+		return -1;
+
+	/* each SWQ is connected to 1 HW queue */
+	*node_num = hwq_base;
+	*node_type = MV_QM_Q_NODE;
+
+	return 0;
+}
+
+static int pp3_cfg_anode_get(struct mv_pp3_tm_node *cnode, int hwq_base, int *anode_num)
+{
+	struct mv_pp3_tm_node *bnode, *anode;
+	int i, j, k;
+
+	for (i = 0; i < cnode->num_of_ch; i++) {
+		bnode = &cnode->sub_nodes[i];
+		for (j = 0; j < bnode->num_of_ch; j++) {
+			anode = &bnode->sub_nodes[j];
+			for (k = 0; k < anode->num_of_ch; k++)
+				if ((anode->first_ch <= hwq_base) &&
+				   ((anode->first_ch + anode->num_of_ch) > hwq_base)) {
+					*anode_num = anode->node_id;
+					return 0;
+				}
+		}
+	}
+	return -1;
+}
+
+int mv_pp3_cfg_hmac_rx_anode_get(int hwq_base, int *anode_num)
+{
+	if ((anode_num == NULL) || (!mv_pp3_cfg_clients_info[PP3_HMAC_RX].port_nodes.sub_nodes))
+		return -1;
+
+	return pp3_cfg_anode_get(&mv_pp3_cfg_clients_info[PP3_HMAC_RX].port_nodes, hwq_base, anode_num);
+}
+
+int mv_pp3_cfg_hmac_tx_anode_get(int hwq_base, int *anode_num)
+{
+	if ((anode_num == NULL) || (!mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes.sub_nodes))
+		return -1;
+
+	return pp3_cfg_anode_get(&mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes, hwq_base, anode_num);
+}
+
+int mv_pp3_cfg_emac_anode_get(int emac, int hwq_base, int *anode_num)
+{
+	if ((anode_num == NULL) || (!mv_pp3_cfg_clients_info[PP3_EMAC0 + emac].port_nodes.sub_nodes))
+		return -1;
+
+	return pp3_cfg_anode_get(&mv_pp3_cfg_clients_info[PP3_EMAC0 + emac].port_nodes, hwq_base, anode_num);
+}
+
+/* get channel HMAC SW parameters (free frame & queue & interrupt group)
+Inputs:
+	chan_num - channel ID
+Outputs:
+	frame	- HMAC frame number
+	queue	- HMAC queue number
+	group	- HMAC queue interrupt group
+	irq_off	- IRQ offset to connect queue ISR
+*/
+int mv_pp3_cfg_chan_sw_params_get(int chan_num, int *frame, int *queue, int *group, int *irq_off)
+{
+	if ((frame == NULL) || (queue == NULL) || (group == NULL) || (irq_off == NULL))
+		return -1;
+
+	if (((mv_pp3_cfg_sw_info.sw_free_rxq[MV_PP3_HMAC_MSG_FRAME] + 1) > MV_PP3_HFRM_Q_NUM) ||
+		(mv_pp3_cfg_sw_info.free_irq_group[MV_PP3_HMAC_MSG_FRAME] >= MV_A390_GIC_INT_GROUPS_NUM))
+		return -1;
+
+	*frame = MV_PP3_HMAC_MSG_FRAME;
+	*queue = mv_pp3_cfg_sw_info.sw_free_rxq[MV_PP3_HMAC_MSG_FRAME]++;
+	mv_pp3_cfg_sw_info.sw_free_txq[MV_PP3_HMAC_MSG_FRAME]++;
+
+	*group = mv_pp3_cfg_sw_info.free_irq_group[MV_PP3_HMAC_MSG_FRAME]++;
+	*irq_off = mv_pp3_cfg_sw_info.irq_rx_base + *frame * MV_A390_GIC_INT_GROUPS_NUM + *group;
+
+	return 0;
+}
+
+/* get channel QM HW q number, messenger BM pool ID
+Inputs:
+	chan_num - channel ID
+Outputs:
+	hwq_rx	- RX QM queue number
+	hwq_tx	- TX QM queue number
+*/
+int mv_pp3_cfg_chan_hw_params_get(int chan_num, unsigned short *hwq_rx, unsigned char *hwq_tx)
+{
+	struct mv_pp3_tm_node *cnode, *bnode, *anode;
+	bool found = false;
+	int i, j;
+
+	if ((hwq_rx == NULL) || (hwq_tx == NULL))
+		return -1;
+
+	/* on Rx: 4 queues connected to last A node are used for messenger */
+	cnode = &mv_pp3_cfg_clients_info[PP3_HMAC_RX].port_nodes;
+	bnode = &cnode->sub_nodes[cnode->num_of_ch - 1];		/* last B node */
+	for (i = 1; (i <= 4) && !found; i++) {
+		anode = &bnode->sub_nodes[bnode->num_of_ch - i];
+		if (((anode->first_free_q - anode->first_q) + 1) <= anode->num_of_q) {
+			found = true;
+			*hwq_rx = anode->first_free_q++;
+			anode->busy = true;
+		}
+	}
+	if (!found)
+		return -1;
+
+	/* on TX: queues start from MV_PP3_HMAC_TO_PPC_QUEUE_BASE are used for messenger */
+	/* mark coresponded B node as busy */
+	found = false;
+	cnode = &mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes;
+	for (i = 0; (i < cnode->num_of_ch) && (!found); i++) {
+		bnode = &cnode->sub_nodes[i];
+		if ((bnode->first_q + bnode->num_of_q) >= MV_PP3_HMAC_TO_PPC_QUEUE_BASE) {
+			for (j = 0; j < bnode->num_of_ch; j++) {
+				anode = &bnode->sub_nodes[j];
+				if ((anode->first_q >= MV_PP3_HMAC_TO_PPC_QUEUE_BASE) &&
+				   (((anode->first_free_q - anode->first_q) + 1) <= anode->num_of_q)) {
+					*hwq_tx = anode->first_free_q++;
+					found = true;
+					anode->busy = true;
+				}
+			}
+		}
+	}
+	if (!found)
+		return -1;
+
+	return 0;
+}
+
+/* get free internal back pressure group id */
+int mv_pp3_cfg_dp_gen_bp_group(int *group_id)
+{
+	if (group_id == NULL)
+		return -1;
+
+	if (mv_pp3_cfg_sw_info.bp_group_id >= MV_PP3_QM_BP_RULES_NUM)
+		return -1;
+
+	*group_id = mv_pp3_cfg_sw_info.bp_group_id++;
+	return 0;
+}
+
+/* get free buffers pool */
+int mv_pp3_cfg_dp_gen_pool_id(int *pool_id)
+{
+	if (pool_id == NULL)
+		return -1;
+
+	if (mv_pp3_cfg_sw_info.buffer_pool_id >= BM_GP_POOL_MAX)
+		return -1;
+
+	*pool_id = mv_pp3_cfg_sw_info.buffer_pool_id++;
+	return 0;
+}
+
+
+/* get frame and queue number in order to manage bm pools per cpu
+Inputs:
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	queue	- HMAC queue number
+	size	- max number of CFH messages in HMAC queue
+	group	- queue interrupt group
+	irq_off	- IRQ offset to connect queue ISR
+*/
+int mv_pp3_cfg_dp_bmq_params_get(int cpu, int *frame, int *queue, int *group)
+{
+
+	if (((mv_pp3_cfg_sw_info.sw_free_rxq[MV_PP3_HMAC_MSG_FRAME] + 1) > MV_PP3_HFRM_Q_NUM) ||
+	   ((mv_pp3_cfg_sw_info.free_irq_group[MV_PP3_HMAC_MSG_FRAME] + 1) > MV_A390_GIC_INT_GROUPS_NUM))
+		return -1;
+
+	if (frame)
+		*frame = MV_PP3_HMAC_MSG_FRAME;
+	if (queue) {
+		*queue = mv_pp3_cfg_sw_info.sw_free_rxq[MV_PP3_HMAC_MSG_FRAME]++;
+		mv_pp3_cfg_sw_info.sw_free_txq[MV_PP3_HMAC_MSG_FRAME]++;
+	}
+	if (group)
+		*group = mv_pp3_cfg_sw_info.free_irq_group[MV_PP3_HMAC_MSG_FRAME]++;
+
+	return 0;
+}
+
+static int mv_pp3_cfg_hw_rxq_single_hwq_get(int if_num, int *hw_rxq)
+{
+	struct mv_pp3_tm_node *node;
+
+	node = mv_pp3_if_rxq_resources[if_num].rx_anode;
+	if (node->num_of_q > (node->first_free_q - node->first_q)) {
+		*hw_rxq = node->first_free_q;
+		node->first_free_q++;
+		return 0;
+	}
+
+	return -1;
+}
+
+/* get data path TX queue parameters
+
+Connect one SW queue to the one A node.
+If SW queues duplicated per cpu, the same SW queues connected to the same A node.
+
+Inputs:
+	if_num	- emac number
+	cpu	- CPU number
+Outputs:
+	hw_txq	- QM TX queue number
+*/
+static int mv_pp3_cfg_hw_txq_params_get(int id, int cpu, int *hw_txq)
+{
+	struct mv_pp3_tm_node *bnode, *anode;
+	u32 curr_q_num;
+	int i;
+	int if_num = id - cpu;
+
+	bnode = mv_pp3_if_txq_resources[if_num].tx_bnode;
+
+	if (mv_pp3_if_txq_resources[if_num].first_init_done == false) {
+		/* take first free anode */
+		for (i = 0; i < bnode->num_of_ch; i++) {
+			anode = &bnode->sub_nodes[i];
+			if (anode->busy)
+				continue;
+
+			anode->busy = true;
+			*hw_txq = anode->first_free_q++;
+			mv_pp3_if_txq_resources[if_num].anode[0] = anode;
+			mv_pp3_if_txq_resources[if_num].num_of_sw_q[cpu] = 1;
+			mv_pp3_if_txq_resources[if_num].first_init_done = true;
+			return 0;
+		}
+	}
+
+	/* number of SW queues already reserved on interface / cpu */
+	curr_q_num = mv_pp3_if_txq_resources[if_num].num_of_sw_q[cpu];
+	if (curr_q_num > 0) {
+		if (mv_pp3_if_txq_resources[if_num].anode[curr_q_num]) {
+			anode = mv_pp3_if_txq_resources[if_num].anode[curr_q_num];
+			*hw_txq = anode->first_free_q++;
+		} else {
+			/* next SW queue on cpu takes next free A node */
+			for (i = 0; i < bnode->num_of_ch; i++) {
+				anode = &bnode->sub_nodes[i];
+				if (anode->busy)
+					continue;
+
+				anode->busy = true;
+				*hw_txq = anode->first_free_q++;
+				mv_pp3_if_txq_resources[if_num].anode[curr_q_num] = anode;
+				break;
+			}
+		}
+		mv_pp3_if_txq_resources[if_num].num_of_sw_q[cpu]++;
+	} else {
+		/* first SW queue on cpu, but not on interface takes A node allocated before */
+		anode = mv_pp3_if_txq_resources[if_num].anode[curr_q_num];
+		*hw_txq = anode->first_free_q++;
+		mv_pp3_if_txq_resources[if_num].num_of_sw_q[cpu]++;
+	}
+
+	return 0;
+}
+
+/* get data path RX queue parameters for NIC mode
+Inputs:
+	emac	- emac number
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	sw_rxq	- HMAC RX queue number
+	hw_rxq	- QM RX queue number
+	hwq_num - number of RX hw queue per one sw queue
+*/
+int mv_pp3_cfg_dp_rxq_params_get(int if_num, int *frame, int *sw_rxq, int *hw_rxq, int *hwq_num)
+{
+	if ((frame == NULL) || (sw_rxq == NULL) || (hw_rxq == NULL) || (hwq_num == NULL)) {
+		pr_err("%s: Invalid input parameters\n", __func__);
+		return -1;
+	}
+
+	if (!mv_pp3_if_rxq_resources[if_num].rx_anode) {
+		pr_info("%s: failed for cpu_vp = %d, cpu %d\n", __func__, if_num, if_num % MV_PP3_CPU_NUM);
+		return -1;
+	}
+
+	*frame = mv_pp3_if_rxq_resources[if_num].if_frame;
+	*sw_rxq = mv_pp3_if_rxq_resources[if_num].if_first_sw_q++;
+
+	*hwq_num = 1;
+	mv_pp3_cfg_hw_rxq_single_hwq_get(if_num, hw_rxq);
+
+	return 0;
+}
+
+/* get data path TX queue parameters for NIC mode
+Inputs:
+	emac	- emac number
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	sw_txq	- HMAC TX queue number
+	hw_txq	- QM TX queue number
+*/
+
+int mv_pp3_cfg_dp_txq_params_get(int vp, int cpu, int *frame, int *sw_txq, int *hw_txq)
+{
+	if ((frame == NULL) || (sw_txq == NULL) || (hw_txq == NULL))
+		return -1;
+
+	*frame = mv_pp3_if_txq_resources[vp].if_frame;
+	*sw_txq = mv_pp3_if_txq_resources[vp].if_first_sw_q++;
+
+	mv_pp3_cfg_hw_txq_params_get(vp, cpu, hw_txq);
+	return 0;
+}
+
+/* get total data path TX queues base and number
+
+Outputs:
+	hw_txq	- first QM (HMAC to PPC) TX queue number
+	hwq_num	- number of (HMAC to PPC) TX queues
+*/
+int mv_pp3_cfg_dp_hw_txq_get(int *hw_txq, int *hwq_num)
+{
+	if ((hw_txq == NULL) || (hwq_num == NULL))
+		return -1;
+
+	*hw_txq = MV_PP3_HMAC_TO_PPC_QUEUE_BASE;
+	*hwq_num = mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes.num_of_q - MV_PP3_HMAC_TO_PPC_QUEUE_BASE;
+
+	return 0;
+}
+
+/* get data path queue HW parameters
+Inputs:
+	emac	- emac number
+Outputs:
+	qmq	- QM first queue number used by EMAC
+*/
+int mv_pp3_cfg_dp_emac_params_get(int emac, int *qmq)
+{
+	if ((qmq == NULL) || (emac >= MV_PP3_EMAC_NUM))
+		return -1;
+
+	*qmq = mv_pp3_cfg_clients_info[PP3_EMAC0 + emac].port_nodes.first_free_q;
+	mv_pp3_cfg_clients_info[PP3_EMAC0 + emac].port_nodes.first_free_q++;
+	return 0;
+}
+
+/* get EMAC deq port num and enq queue num
+Inputs:
+	emac	- EMAC number
+Outputs:
+	qmp	- EMAC deq port num
+	qmq	- EMAC enq queue num
+*/
+
+int mv_pp3_cfg_emac_qm_params_get(int emac, int *qmp, int *qmq)
+{
+	if (emac >= MV_PP3_EMAC_NUM)
+		return -1;
+
+	/* EMAC->PPC QM queue */
+	if (qmq)
+		*qmq = mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes.first_q + 1 + emac * 4;
+	if (qmp)
+		*qmp = mv_pp3_cfg_clients_info[PP3_EMAC0 + emac].qm_port_id;
+
+	return 0;
+}
+
+/* get data path IRQ number for RX process
+Inputs:
+	frame	  - frame number
+Outputs:
+	group     - frame group number
+*/
+int mv_pp3_cfg_dp_gen_irq_group(int id, int cpu, int *group)
+{
+	if (group == NULL)
+		return -1;
+
+	if (mv_pp3_cfg_sw_info.free_irq_group[mv_pp3_if_rxq_resources[id].if_frame] >= MV_A390_GIC_INT_GROUPS_NUM) {
+		pr_err("No free irq group for frame %d\n", mv_pp3_if_rxq_resources[id].if_frame);
+		return -1;
+	}
+
+	/* skip two first multiple groups */
+	*group = mv_pp3_cfg_sw_info.free_irq_group[mv_pp3_if_rxq_resources[id].if_frame];
+	mv_pp3_cfg_sw_info.free_irq_group[mv_pp3_if_rxq_resources[id].if_frame]++;
+	return 0;
+}
+
+int mv_pp3_cfg_hmac_pnode_get(enum mv_pp3_cfg_clients client)
+{
+	return mv_pp3_cfg_clients_info[client].qm_port_id;
+}
+
+void mv_pp3_port_subtree_build(struct mv_pp3_tm_node *level_ptr, enum tm_level level, int node_id)
+{
+	struct mv_pp3_tm_node *tmp_ptr;
+	int i;
+
+	mv_tm_scheme_sub_nodes_get(level, node_id, &level_ptr->first_ch, &level_ptr->num_of_ch);
+	level_ptr->level = level;
+	/*pr_info("%s: node %d (%p): level %d, first = %d, number = %d\n", __func__,
+		node_id, level_ptr, level, level_ptr->first_ch, level_ptr->num_of_ch);*/
+	if (level == A_LEVEL) {
+		level_ptr->num_of_q = level_ptr->num_of_ch;
+		level_ptr->first_free_q = level_ptr->first_ch;
+		return;
+	}
+
+	level_ptr->sub_nodes = kzalloc(level_ptr->num_of_ch * sizeof(struct mv_pp3_tm_node), GFP_KERNEL);
+
+	for (i = 0; i < level_ptr->num_of_ch; i++) {
+		tmp_ptr = &level_ptr->sub_nodes[i];
+		tmp_ptr->node_id = level_ptr->first_ch + i;
+		mv_pp3_port_subtree_build(tmp_ptr, level - 1, tmp_ptr->node_id);
+		level_ptr->num_of_q += tmp_ptr->num_of_q;
+	}
+
+	return;
+}
+
+#ifdef PP3_DEBUG
+static void mv_pp3_port_subtree_print(struct mv_pp3_tm_node *node)
+{
+	struct mv_pp3_tm_node *tmp;
+	int i;
+
+	if (node->level == A_LEVEL)
+		return;
+
+	for (i = 0; i < node->num_of_ch; i++) {
+		tmp = &node->sub_nodes[i];
+		pr_info("\t\tnode %d: first = %d, first_free = %d (%d), subnodes number = %d, queues = %d\n",
+		tmp->node_id, tmp->first_ch, tmp->first_free_q, tmp->first_q, tmp->num_of_ch, tmp->num_of_q);
+		mv_pp3_port_subtree_print(tmp);
+	}
+
+	return;
+}
+#endif /* PP3_DEBUG */
+
+static void mv_pp3_cfg_sort(u32 *queues, int *arr)
+{
+	int tmp, i, j;
+
+	for (i = 0; i < MV_PP3_HFRM_NUM; i++)
+		arr[i] = i;
+
+	for (i = 0; i < (MV_PP3_HFRM_NUM - 1); i++) {
+		for (j = 0; j < MV_PP3_HFRM_NUM - 1 - i; j++) {
+			if (queues[arr[j]] > queues[arr[j+1]]) {
+				tmp = arr[j+1];
+				arr[j+1] = arr[j];
+				arr[j] = tmp;
+			}
+		}
+	}
+}
+
+/* reserve data path RX queues for future allocation by specified interface
+ * reserve A node with queues number >= virtual queues number
+Inputs:
+	id	- unique request ID (interface number)
+	cpu	- cpu number
+	q_num	- number of queues allocated per request (interface)
+Outputs:
+	hw_rxq	- first QM queue number
+*/
+int mv_pp3_cfg_dp_reserve_rxq(int id, int if_num, int cpu, int q_num)
+{
+	struct mv_pp3_tm_node *cnode, *bnode, *anode;
+	int i, j, anode_q_num;
+	int frame = 0;
+	int ind_arr[MV_PP3_HFRM_NUM];
+	bool found;
+
+	if (id >= MV_PP3_INTERNAL_CPU_PORT_MAX) {
+		pr_info("%s: cannot reserved RX resources for interface %d\n", __func__, id);
+		return -1;
+	}
+	if (mv_pp3_if_rxq_resources[id].rx_anode) {
+		pr_info("%s: already reserved RX resources for interface %d\n", __func__, id);
+		return -1;
+	}
+
+	/* look for free SW queues belong to one frame */
+	found = false;
+	for (i = 0; (i < MV_PP3_HFRM_NUM) && !found; i++) {
+		if (mv_pp3_cfg_sw_info.frame_vip_vport[i] == if_num) {
+			found = true;
+			frame = i;
+		}
+	}
+	if (!found) {
+		/* sort all frames per free RXQs number */
+		mv_pp3_cfg_sort(mv_pp3_cfg_sw_info.sw_free_rxq, ind_arr);
+		/* look for free SW queues belong to one frame */
+		for (i = 0; (i < MV_PP3_HFRM_NUM) && !found; i++) {
+			if ((mv_pp3_cfg_sw_info.sw_free_rxq[ind_arr[i]] + q_num) > MV_PP3_HFRM_Q_NUM)
+				continue;
+
+			/* each emac interface placed in different frame */
+			if ((if_num < MV_PP3_EMAC_VP_NUM) && (mv_pp3_cfg_sw_info.vip_rx_if[ind_arr[i]][cpu]))
+				continue;
+
+			if (mv_pp3_cfg_sw_info.free_irq_group[ind_arr[i]] >= MV_A390_GIC_INT_GROUPS_NUM)
+				continue;
+
+			frame = ind_arr[i];
+			found = true;
+		}
+	}
+
+	if (!found) {
+		pr_info("%s: cannot reserved SW RX resources for interface %d\n", __func__, id);
+		return -1;
+	}
+
+	mv_pp3_if_rxq_resources[id].if_frame = frame;
+	mv_pp3_if_rxq_resources[id].if_first_sw_q = mv_pp3_cfg_sw_info.sw_free_rxq[frame];
+	mv_pp3_cfg_sw_info.sw_free_rxq[frame] += q_num;
+	mv_pp3_cfg_sw_info.frame_vip_vport[frame] = if_num;
+	if (if_num < MV_PP3_EMAC_VP_NUM)
+		mv_pp3_cfg_sw_info.vip_rx_if[frame][cpu] = true;
+
+	found = false;
+	/* look for free A node with queues number >= q_num */
+	anode_q_num = 0xFFFF;
+	cnode = &mv_pp3_cfg_clients_info[PP3_HMAC_RX].port_nodes;
+	for (i = 0; i < cnode->num_of_ch; i++) {
+		bnode = &cnode->sub_nodes[i];
+		for (j = 0; j < bnode->num_of_ch; j++) {
+			anode = &bnode->sub_nodes[j];
+			if (!anode->busy) {
+				/* check how many queues it has */
+				if ((anode->num_of_q >= q_num) && (anode_q_num > anode->num_of_q)) {
+						mv_pp3_if_rxq_resources[id].rx_anode = anode;
+						anode_q_num = anode->num_of_q;
+						found = true;
+					}
+			}
+		}
+	}
+	/* mark A node as busy */
+	cnode = &mv_pp3_cfg_clients_info[PP3_HMAC_RX].port_nodes;
+	for (i = 0; (i < cnode->num_of_ch) && found; i++) {
+		bnode = &cnode->sub_nodes[i];
+		for (j = 0; j < bnode->num_of_ch; j++) {
+			anode = &bnode->sub_nodes[j];
+			if (mv_pp3_if_rxq_resources[id].rx_anode->node_id == anode->node_id) {
+				anode->busy = true;
+				return 0;
+			}
+		}
+	}
+	return -1;
+}
+
+/* reserve data path TX queues for future allocation by specified interface
+ * reserve B node with A nodes number >= virtual queues number
+ * one interface (with all internal cpu vp) must belong to one B node
+Inputs:
+	id	- unique request ID (interface number)
+	cpu	- cpu number
+	q_num	- number of queues allocated per request (interface)
+Outputs:
+	hw_rxq	- first QM queue number
+*/
+int mv_pp3_cfg_dp_reserve_txq(int id, int if_num, int cpu, int q_num)
+{
+	struct mv_pp3_tm_node *cnode, *bnode, *anode;
+	int i, j;
+	int frame = 0;
+	int ind_arr[MV_PP3_HFRM_NUM];
+	bool found;
+
+	if (id >= MV_PP3_INTERNAL_CPU_PORT_MAX) {
+		pr_info("%s: cannot reserved TX resources for emac %d\n", __func__, id);
+		return -1;
+	}
+
+	/* look for free SW queues belong to one frame */
+	found = false;
+	for (i = 0; (i < MV_PP3_HFRM_NUM) && !found; i++) {
+		if (mv_pp3_cfg_sw_info.frame_vip_vport[i] == if_num) {
+			found = true;
+			frame = i;
+		}
+	}
+	if (!found) {
+		/* sort all frames per free RXQs number */
+		mv_pp3_cfg_sort(mv_pp3_cfg_sw_info.sw_free_txq, ind_arr);
+
+		for (i = 0; (i < MV_PP3_HFRM_NUM) && !found; i++) {
+			if ((mv_pp3_cfg_sw_info.sw_free_txq[ind_arr[i]] + q_num) > MV_PP3_HFRM_Q_NUM)
+				continue;
+
+			/* each emac interface placed in different frame */
+			if ((if_num < MV_PP3_EMAC_VP_NUM) && (mv_pp3_cfg_sw_info.vip_tx_if[ind_arr[i]][cpu]))
+				continue;
+
+			if (mv_pp3_cfg_sw_info.free_irq_group[ind_arr[i]] >= MV_A390_GIC_INT_GROUPS_NUM)
+				continue;
+
+			frame = ind_arr[i];
+			found = true;
+		}
+	}
+	if (!found) {
+		pr_info("%s: cannot reserved SW TX resources for interface %d\n", __func__, id);
+		return -1;
+	}
+
+	mv_pp3_if_txq_resources[id].if_frame = frame;
+	mv_pp3_if_txq_resources[id].if_first_sw_q = mv_pp3_cfg_sw_info.sw_free_txq[frame];
+	mv_pp3_cfg_sw_info.sw_free_txq[frame] += q_num;
+	mv_pp3_cfg_sw_info.frame_vip_vport[frame] = if_num;
+	if (if_num < MV_PP3_EMAC_VP_NUM)
+		mv_pp3_cfg_sw_info.vip_tx_if[frame][cpu] = true;
+
+	/* one B node per interface */
+	if (mv_pp3_if_txq_resources[id].tx_bnode)
+		return 0;
+
+	if (mv_pp3_if_txq_resources[id - cpu].tx_bnode) {
+		/* use the same B node for next interface */
+		bnode = mv_pp3_if_txq_resources[id - cpu].tx_bnode;
+		mv_pp3_if_txq_resources[id].tx_bnode = bnode;
+		return 0;
+	}
+
+	found = false;
+	/* look for first B node with free A nodes number >= q_num */
+	cnode = &mv_pp3_cfg_clients_info[PP3_PPC0_DP].port_nodes;
+	for (i = 0; (i < cnode->num_of_ch); i++) {
+		bnode = &cnode->sub_nodes[i];
+		if (bnode->first_q >= MV_PP3_HMAC_TO_PPC_QUEUE_BASE + 4) {
+			for (j = 0; j < bnode->num_of_ch; j++) {
+				anode = &bnode->sub_nodes[j];
+				if ((!anode->busy) && (anode->num_of_q >= q_num)) {
+					mv_pp3_if_txq_resources[id].tx_bnode = bnode;
+					bnode->busy = true;
+					return 0;
+				}
+			}
+		}
+	}
+
+	return -1;
+}
+
+static void mv_pp3_cfg_subtree_free(struct mv_pp3_tm_node *node)
+{
+	struct mv_pp3_tm_node *anode, *bnode;
+	int i;
+
+	for (i = 0; i < node->num_of_ch; i++) {
+		bnode = &node->sub_nodes[i];
+		anode = &bnode->sub_nodes[0];
+		kfree(anode);
+	}
+	bnode = &node->sub_nodes[0];
+	kfree(bnode);
+
+	return;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.h b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.h
new file mode 100644
index 0000000..f548ba8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_config.h
@@ -0,0 +1,233 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_config_h__
+#define __mv_pp3_config_h__
+
+#include "common/mv_sw_if.h"
+#include "mv_pp3.h"
+
+#define MV_PP3_MSG_BUFF_SIZE	4096
+
+#define MV_PP3_HMAC_TO_PPC_QUEUE_BASE	(44)
+#define MV_PP3_HMAC_MSG_FRAME		(3)
+
+#define MV_PP3_SW_IRQ_OFF(_frame_, _group_)		(((_frame_) * MV_A390_GIC_INT_GROUPS_NUM) + (_group_))
+#define MV_PP3_SW_IRQ_2_HFRAME(_irq_)			((_irq_) / MV_A390_GIC_INT_GROUPS_NUM)
+#define MV_PP3_SW_IRQ_2_GROUP(_irq_)			((_irq_) % MV_A390_GIC_INT_GROUPS_NUM)
+
+/* Maximum packet size for TX checksum offload - 10 KBytes */
+#define MV_PP3_TX_CSUM_MAX_SIZE		(10 * 1024)
+
+/* HW RX queue allocation mode: */
+/* - 1 SW -> 4 HW queues        */
+/* - 1 SW -> 1 HW queue         */
+enum mv_hwq_alloc_mode {
+
+	MV_1SWQ_4HWQ,
+	MV_1SWQ_1HWQ
+};
+
+/* list of system clients */
+enum mv_pp3_cfg_clients {
+
+	PP3_PPC0_DP,
+	PP3_EMAC0,
+	PP3_EMAC1,
+	PP3_EMAC2,
+	PP3_EMAC3,
+	PP3_CMAC_IN,
+	PP3_CMAC_LA,
+	PP3_HMAC_RX,
+
+	PP3_CLIENTS_NUM
+};
+
+struct mv_pp3_tm_node {
+	int level;
+	bool busy;
+	int node_id;
+	int first_ch;
+	int num_of_ch;
+	int first_q;
+	int num_of_q;
+	int first_free_q;
+	struct mv_pp3_tm_node *sub_nodes;
+};
+
+/* Hold QM/TM queues allocation */
+struct mv_pp3_hwq_cfg {
+	int qm_port_id;
+	struct mv_pp3_tm_node port_nodes;
+};
+
+void mv_pp3_configurator_init(struct mv_pp3 *priv);
+int mv_pp3_cfg_dp_reserve_rxq(int id, int if_num, int cpu, int q_num);
+int mv_pp3_cfg_dp_reserve_txq(int id, int if_num, int cpu, int q_num);
+void mv_pp3_configurator_close(void);
+void mv_pp3_cfg_rx_irq_base_init(int irq_base);
+int mv_pp3_cfg_hwq_info_set(enum mv_pp3_cfg_clients cl, struct mv_pp3_hwq_cfg *cfg);
+int mv_pp3_cfg_hmac_rx_anode_get(int hwq_base, int *anode_num);
+int mv_pp3_cfg_hmac_tx_anode_get(int hwq_base, int *anode_num);
+int mv_pp3_cfg_emac_anode_get(int emac, int hwq_base, int *anode_num);
+int mv_pp3_cfg_hmac_pnode_get(enum mv_pp3_cfg_clients client);
+int mv_pp3_cfg_rx_bp_node_get(int hwq_base, int *node_type, int *node_num);
+void mv_pp3_rx_hwq_alloc_mode_change(enum mv_hwq_alloc_mode mode);
+
+/* get ingress virtual queues mapping array
+Outputs:
+	ingress_vq_map	- Array of virtual ingress queues priority
+	size		- Array size
+*/
+enum mv_priority_type *mv_pp3_nic_cfg_ingress_vq_map_get(int *size);
+
+/* get messenger bm queue parameters (frame, queue, size)
+Outputs:
+	frame	- HMAC frame number
+	queue	- HMAC queue number
+	size	- max number of CFH messages in HMAC queue
+	group	- queue interrupt group
+	irq_off	- IRQ offset to connect queue ISR
+*/
+int mv_pp3_cfg_msg_bmq_params_get(int *frame, int *queue, int *size, int *group, int *irq_off);
+
+/* get channel HMAC SW parameters (free frame & queue & interrupt group)
+Inputs:
+	chan_num - channel ID
+Outputs:
+	frame	- HMAC frame number
+	queue	- HMAC queue number
+	size	- max number of CFH messages in HMAC queue
+	group	- queue interrupt group
+	irq_off	- IRQ offset to connect queue ISR
+*/
+int mv_pp3_cfg_chan_sw_params_get(int chan_num, int *frame, int *queue, int *group, int *irq_off);
+
+/* get channel QM HW q number, messenger BM pool ID
+Inputs:
+	chan_num - channel ID
+Outputs:
+	hwq_rx	- RX QM queue number
+	hwq_tx	- TX QM queue number
+	pool_id	- BM pool ID
+	b_hr	- buffer header
+*/
+int mv_pp3_cfg_chan_hw_params_get(int chan_num, unsigned short *hwq_rx, unsigned char *hwq_tx);
+
+/* get data path frames bitmap per cpu */
+int mv_pp3_cfg_dp_cpu_frames(int cpu, int *frame);
+
+/* get free buffers pool */
+int mv_pp3_cfg_dp_gen_pool_id(int *pool_id);
+
+/* get free internal back pressure group */
+int mv_pp3_cfg_dp_gen_bp_group(int *group_id);
+
+/* get frame and queue number in order to manage bm pools per cpu
+Inputs:
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	queue	- HMAC queue number
+	size	- max number of CFH messages in HMAC queue
+	group	- queue interrupt group
+	irq_off	- IRQ offset to connect queue ISR
+*/
+int mv_pp3_cfg_dp_bmq_params_get(int cpu, int *frame, int *queue, int *group);
+
+/* get data path RX queue parameters for NIC mode
+Inputs:
+	emac	- emac number
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	sw_rxq	- HMAC RX queue number
+	hw_rxq	- QM RX queue number
+	hwq_num - number of RX hw queue per one sw queue
+*/
+
+int mv_pp3_cfg_dp_rxq_params_get(int cpu, int *frame, int *queue, int *hwq_base, int *hwq_num);
+
+
+/* get free IRQ group number for RX proces
+Inputs:
+	frame   - HMAC frame number
+Outputs:
+	group     - group number
+*/
+
+int mv_pp3_cfg_dp_gen_irq_group(int frame, int cpu, int *group);
+/* get IRQ number for RX proces
+Inputs:
+	frame   - HMAC frame number
+	irq_group     - group number
+Outputs:
+	Irq number
+*/
+int mv_pp3_cfg_rx_irq_get(int frame, int irq_group);
+
+/* get cpu assigned to <frame, group> for RX process
+
+Inputs:
+	frame   - HMAC frame number
+	group   - HMAC group number
+Outputs:
+	cpu     - cpu ID
+*/
+int mv_pp3_cfg_group2cpu_get(int frame, int group);
+
+/* get data path TX queue parameters for NIC mode
+Inputs:
+	cpu	- CPU number
+Outputs:
+	frame	- HMAC frame number
+	queue	- free HMAC RX queue number
+	hwq	-  HMAC->PPC QM f queue number
+	emacs	- QM first queue number used by EMAC
+*/
+int mv_pp3_cfg_dp_txq_params_get(int vp, int cpu, int *frame, int *queue, int *hwq);
+
+/* get data path queue HW parameters
+Inputs:
+	vp	- vport number
+Outputs:
+	qmq	- QM first queue number used by EMAC
+	qmq_num - number of hw queue for PPC->EMAC traffic
+*/
+int mv_pp3_cfg_dp_emac_params_get(int emac, int *qmq);
+
+/* get EMAC deq port num and enq queue num
+Inputs:
+	emac	- EMAC number
+Outputs:
+	qmp	- EMAC deq port num
+	qmq	- EMAC enq queue num
+*/
+int mv_pp3_cfg_emac_qm_params_get(int emac, int *qmp, int *qmq);
+
+
+/* get total data path TX queues
+
+Outputs:
+	hw_txq	- first QM (HMAC to PPC) TX queue number
+	hwq_num	- number of (HMAC to PPC) TX queues
+*/
+
+int mv_pp3_cfg_dp_hw_txq_get(int *hw_txq, int *hwq_num);
+
+#endif /* __mv_pp3_config_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_debug_sysfs.c b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_debug_sysfs.c
new file mode 100644
index 0000000..a3bd1a4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_debug_sysfs.c
@@ -0,0 +1,270 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "net_complex/mv_net_complex_a39x.h"
+#include "mv_pp3.h"
+
+
+#define PP3_DEBUG_ARRAY_SIZE	512
+
+static ssize_t pp3_debug_help(char *b)
+{
+	int o = 0;
+	int p = PAGE_SIZE;
+
+	o += sprintf(b+o, "\n");
+
+	o += scnprintf(b+o, p-o, "cat                  reset_nss      - Reset NSS sub system\n");
+	o += scnprintf(b+o, p-o, "echo [o] [v] [c]   > write_nss_reg  - Write value [v] to [c] NSS registers from offset [o]\n");
+	o += scnprintf(b+o, p-o, "echo [o] [c]       > read_nss_reg   - Read [c] NSS registers from offset [o]\n");
+	o += scnprintf(b+o, p-o, "echo [o] [s:e] [v] > modify_nss_reg - Write value [v] to NSS register offset [o] start from bit [s] to bit [e]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [v] [c]   > write_u32      - Write value [v] to [c] virtual address [a]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [c]       > read_u32       - Read [c] values from virtual address [a]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [s:e] [v] > modify_u32     - Write value [v] to virtual address [a] start from bit [s] to bit [e]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [v] [c]   > write_u32_le   - Write LE value [v] to [c] virtual addresses start from [a]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [c]       > read_u32_le    - Read [c] LE values start from virtual address [a]\n");
+	o += scnprintf(b+o, p-o, "echo [a] [s:e] [v] > modify_u32_le  - Write LE value [v] to virtual address [a] start from bit [s] to bit [e]\n");
+	o += scnprintf(b+o, p-o, "parameters:\n");
+	o += scnprintf(b+o, p-o, "      [c] number of registers for read/write; must be < 0x80\n");
+	o += scnprintf(b+o, p-o, "      All inputs in hex.");
+	o += scnprintf(b+o, p-o, "\n");
+
+	return o;
+}
+
+static ssize_t pp3_debug_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) {
+		off = pp3_debug_help(buf);
+	} else if (!strcmp(name, "reset_nss")) {
+		pr_err("%s operation not supported yet\n", attr->attr.name);
+		/*if (mv_pp3_nss_drain(NULL))
+			off = -EINVAL;
+		else
+			mv_nss_sw_reset();*/
+	} else {
+		off = -EINVAL;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t pp3_hex_debug_modify(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	unsigned long   flags;
+	u32 p, u, start_bit, end_bit, val;
+	u32 ret, mask;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	ret = sscanf(buf, "%x %d:%d %x", &p, &start_bit, &end_bit, &u);
+	if (ret < 4)
+		return -EINVAL;
+
+	if ((end_bit < start_bit) || ((end_bit - start_bit + 1) > 32))
+		return -EINVAL;
+
+	if ((end_bit - start_bit + 1) == 32)
+		mask = 0xFFFFFFFF;
+	else
+		mask = (1 << (end_bit - start_bit + 1)) - 1;
+
+	local_irq_save(flags);
+	if (!strcmp(name, "modify_nss_reg")) {
+
+		val = mv_pp3_hw_reg_read(p + mv_pp3_nss_regs_vaddr_get());
+		MV_U32_SET_FIELD(val, (mask << start_bit), ((u & mask) << start_bit));
+		mv_pp3_hw_reg_write(p + mv_pp3_nss_regs_vaddr_get(), val);
+
+	} else if (!strcmp(name, "modify_u32_le")) {
+
+		val = mv_pp3_hw_reg_read((void __iomem *)p);
+		MV_U32_SET_FIELD(val, (mask << start_bit), ((u & mask) << start_bit));
+		mv_pp3_hw_reg_write((void __iomem *)p, val);
+
+	} else if (!strcmp(name, "modify_u32")) {
+
+		val = *(u32 *)p;
+		MV_U32_SET_FIELD(val, (mask << start_bit), ((u & mask) << start_bit));
+		*(u32 *)p = val;
+	}
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static ssize_t pp3_hex_debug_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    a, b, c;
+	unsigned long   flags;
+	u32             *arr;
+	int i, ret;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = a = b = c = 0;
+	ret = sscanf(buf, "%x %x %x", &a, &b, &c);
+
+	local_irq_save(flags);
+
+	arr = kzalloc(sizeof(unsigned int) * PP3_DEBUG_ARRAY_SIZE, GFP_KERNEL);
+
+	if (!strcmp(name, "write_nss_reg")) {
+		if (c > PP3_DEBUG_ARRAY_SIZE) {
+			pr_info("can't write more than %d values", PP3_DEBUG_ARRAY_SIZE);
+			err = 1;
+			goto end;
+		}
+		for (i = 0; i < c; i++)
+			arr[i] = b;
+		mv_pp3_hw_write(a + mv_pp3_nss_regs_vaddr_get(), c, arr);
+	} else if (!strcmp(name, "read_nss_reg")) {
+		if (b > PP3_DEBUG_ARRAY_SIZE) {
+			pr_info("can't read more than %d values", PP3_DEBUG_ARRAY_SIZE);
+			err = 1;
+			goto end;
+		}
+		mv_pp3_hw_read(a + mv_pp3_nss_regs_vaddr_get(), b, arr);
+		for (i = 0; i < b; i++)
+			pr_info("0x%x = 0x%08x\n", a+i*4, arr[i]);
+	} else if (!strcmp(name, "write_u32_le")) {
+		if (c > PP3_DEBUG_ARRAY_SIZE) {
+			pr_info("can't write more than %d values", PP3_DEBUG_ARRAY_SIZE);
+			err = 1;
+			goto end;
+		}
+		for (i = 0; i < c; i++)
+			arr[i] = b;
+		mv_pp3_hw_write((void __iomem *)a, c, arr);
+	} else if (!strcmp(name, "read_u32_le")) {
+		if (b > PP3_DEBUG_ARRAY_SIZE) {
+			pr_info("can't read more than %d values", PP3_DEBUG_ARRAY_SIZE);
+			err = 1;
+			goto end;
+		}
+		mv_pp3_hw_read((void __iomem *)a, b, arr);
+		for (i = 0; i < b; i++)
+			pr_info("0x%x = 0x%08x\n", a + i*4, arr[i]);
+
+	} else if (!strcmp(name, "read_u32")) {
+		for (i = 0; i < b; i++)
+			pr_info("0x%x = 0x%08x\n", a + i*4, *(u32 *)(a + 4*i));
+
+	} else if (!strcmp(name, "write_u32")) {
+		for (i = 0; i < c; i++)
+			*(u32 *)(a + 4*i) = b;
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+end:
+	kfree(arr);
+
+	local_irq_restore(flags);
+
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(write_nss_reg,	S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(read_nss_reg,	S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(read_u32_le,		S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(write_u32_le,	S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(read_u32,		S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(write_u32,		S_IWUSR, NULL, pp3_hex_debug_store);
+static DEVICE_ATTR(modify_nss_reg,	S_IWUSR, NULL, pp3_hex_debug_modify);
+static DEVICE_ATTR(modify_u32,		S_IWUSR, NULL, pp3_hex_debug_modify);
+static DEVICE_ATTR(modify_u32_le,	S_IWUSR, NULL, pp3_hex_debug_modify);
+static DEVICE_ATTR(help,		S_IRUSR, pp3_debug_show, NULL);
+static DEVICE_ATTR(reset_nss,		S_IRUSR, pp3_debug_show, NULL);
+
+static struct attribute *pp3_debug_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_reset_nss.attr,
+	&dev_attr_write_nss_reg.attr,
+	&dev_attr_read_nss_reg.attr,
+	&dev_attr_write_u32_le.attr,
+	&dev_attr_read_u32_le.attr,
+	&dev_attr_write_u32.attr,
+	&dev_attr_read_u32.attr,
+	&dev_attr_modify_nss_reg.attr,
+	&dev_attr_modify_u32_le.attr,
+	&dev_attr_modify_u32.attr,
+	NULL
+};
+
+static struct attribute_group pp3_debug_group = {
+	.attrs = pp3_debug_attrs,
+};
+
+static struct kobject *dev_kobj;
+
+int mv_pp3_debug_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	dev_kobj = kobject_create_and_add("debug", pp3_kobj);
+	if (!dev_kobj) {
+		pr_err("%s: cannot create dev kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_update_group(dev_kobj, &pp3_debug_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", pp3_debug_group.name, err);
+		return err;
+	}
+
+	return err;
+}
+
+
+int mv_pp3_debug_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &pp3_debug_group);
+
+	return 0;
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_defs.h b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_defs.h
new file mode 100644
index 0000000..44caed3
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_defs.h
@@ -0,0 +1,119 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+
+#ifndef __mv_pp3_defs_h__
+#define __mv_pp3_defs_h__
+
+/*---------------------------------------------------------------------------*/
+/*			global HW configuration				     */
+/*---------------------------------------------------------------------------*/
+#define MV_PP3_CPU_NUM			(2)   /* Must be equal or larger than CONFIG_NR_CPUS */
+#define MV_PP3_EMAC_NUM			(4)   /* Number of EMACs in board */
+#define MV_PP3_GOP_MAC_NUM		(4)   /* Max number of MACs in project GOP */
+
+#define MV_PP3_EMAC_VP_NUM		MV_PP3_EMAC_NUM
+#define MV_PP3_CPU_VP_NUM		((MV_PP3_EMAC_VP_NUM + 1) * MV_PP3_CPU_NUM)
+
+#define MV_PP3_HFRM_TIME_COAL_PROF_NUM	(2)   /* Number of HMAC frame coalescing */
+#define MV_PP3_HFRM_NUM			(4)   /* Number of HMAC frame in packets processor */
+#define MV_PP3_HFRM_Q_NUM		(16)  /* Number of queues couples in each HMAC frame */
+
+#define MV_PP3_PPC_MAX_NUM		(2)	/* max number of PPCs in system */
+
+#define MV_PP3_QM_BP_RULES_NUM		(64)	/* Number of QM internal back pressure groups */
+
+#define MV_PP3_EMAC_BASE(_emac_)	(0x000CA000 + (0x1000 * (_emac_)))
+
+/*---------------------------------------------------------------------------*/
+/*			global SW configuration				     */
+/*---------------------------------------------------------------------------*/
+#define MV_PP3_INTERNAL_CPU_PORT_MIN    (0)
+#define MV_PP3_INTERNAL_CPU_PORT_NUM	(32)
+#define MV_PP3_INTERNAL_CPU_PORT_MAX	(MV_PP3_INTERNAL_CPU_PORT_MIN + MV_PP3_INTERNAL_CPU_PORT_NUM - 1)
+
+/* translate cpu number to cpu virtual port id */
+#define MV_PP3_CPU_VPORT_ID(_cpu_id_)	(MV_NSS_CPU_PORT_MIN + (_cpu_id_))
+/* translate cpu virtual port it to CPU number */
+#define MV_PP3_CPU_VPORT_TO_CPU(cpu_vp)	((cpu_vp) - MV_NSS_CPU_PORT_MIN)
+
+
+#define MV_PP3_DEV_NUM			(MV_NSS_EXT_PORT_NUM + MV_PP3_EMAC_NUM) /* max number of network devices */
+
+#define MV_PP3_BM_POOL_HROOM_RES	(32)
+
+#define MV_PP3_HMAC_BM_Q_SIZE		(1024) /* size of rxq/txq that used for BM pools access */
+#define MV_PP3_CHAN_SIZE		(512)  /* new channel size */
+
+#define MV_PP3_DEBUG_BUFFER		1024
+#define MV_PP3_RSS_MAX_HASH		(0xFFFFFFFF)
+
+#define MV_PP3_VQ_NUM			16
+#define MV_PP3_PRIO_NUM			16
+#define MV_PP3_SCHED_PRIO_NUM		8
+
+#define MV_PP3_QM_128B_UNITS		128
+#define MV_PP3_QM_16B_UNITS		16
+
+#define MV_PP3_QM_UNITS			MV_PP3_QM_128B_UNITS
+
+#define MV_PP3_TXDONE_HRTIMER_PERIOD	(1000)	/* default value for digh resolution timer in usec */
+
+/* Default Drop thresholds per HWQ: */
+/* TD  = 20 packets 2K bytes each = 40 KBytes */
+/* RED = 10 packets 2K bytes each = 20 KBytes */
+#define MV_PP3_INGRESS_TD_DEF           (2 * 20) /* 40 KBytes */
+#define MV_PP3_INGRESS_RED_DEF          (2 * 10) /* 20 KBytes */
+
+/*---------------------------------------------------------------------------*/
+/*			global SW thresholds configuration		     */
+/*---------------------------------------------------------------------------*/
+/* thresholds in KB */
+#define MV_PP3_10G_LOW_THR		200
+#define MV_PP3_10G_PAUSE_THR		250
+#define MV_PP3_10G_HIGH_THR		300
+
+#define MV_PP3_2_5G_LOW_THR		90
+#define MV_PP3_2_5G_PAUSE_THR		100
+#define MV_PP3_2_5G_HIGH_THR		120
+
+#define MV_PP3_1G_LOW_THR		30
+#define MV_PP3_1G_PAUSE_THR		35
+#define MV_PP3_1G_HIGH_THR		40
+
+#define MV_PP3_HMAC_LOW_THR		1
+#define MV_PP3_HMAC_HIGH_THR		3
+#define MV_PP3_HMAC_PAUSE_THR		(MV_PP3_HMAC_HIGH_THR * 2) /*not in use*/
+
+/* QM internal back pressure thresholds in KB */
+#define MV_PP3_QM_BPI_XON		1
+#define MV_PP3_QM_BPI_XOFF		2
+
+/* Number of buffers in the pool calculated as */
+/* number of CPUs * (number of RXQs per CPU * number of packets in each RXQ  + EXTRA */
+#define MV_PP3_RX_BUFS_EXTRA		2000
+
+/* PP3 queue type */
+enum mv_pp3_queue_type {
+	MV_PP3_EMAC_TO_PPC = 0,	/* relevant for emac_vport */
+	MV_PP3_PPC_TO_EMAC,	/* relevant for emac_vport */
+	MV_PP3_HMAC_TO_PPC,	/* relevant for cpu_vport */
+	MV_PP3_PPC_TO_HMAC,	/* relevant for cpu_vport */
+};
+
+#endif /* __mv_pp3_defs_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_fw_opcodes.h b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_fw_opcodes.h
new file mode 100644
index 0000000..5fe8469
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_fw_opcodes.h
@@ -0,0 +1,64 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_fw_opcodes_h__
+#define __mv_pp3_fw_opcodes_h__
+
+/* Message opcodes for Software <-> Firmware communication */
+enum mv_pp3_fw_msg_opcode {
+
+	MV_IDLE_MSG = 0,
+	MV_FW_MSG_CHAN_SET,
+	MV_FW_VERSION_GET,
+	MV_FW_MEM_REQ_GET,
+	MV_FW_MEM_REQ_SET,
+	MV_FW_EMAC_VPORT_SET,
+	MV_FW_EMAC_VPORT_GET,
+	MV_FW_CPU_VPORT_SET,
+	MV_FW_CPU_VPORT_GET,
+	MV_FW_INTERNAL_CPU_PORT_SET,
+	MV_FW_INTERNAL_CPU_PORT_GET,
+	MV_FW_BM_POOL_SET,
+	MV_FW_BM_POOL_GET,
+	MV_FW_VQ_MAP_SET,
+	MV_FW_VQ_MAP_GET,
+	MV_FW_VQ_POLICER_SET,
+	MV_FW_VQ_POLICER_GET,
+	MV_FW_COS_TO_VQ_SET,
+	MV_FW_COS_TO_VQ_GET,
+	MV_FW_VPORT_STATE_SET,
+	MV_FW_VPORT_MAC_SET,
+	MV_FW_VPORT_MAC_LIST_SET,
+	MV_FW_VPORT_MAC_LIST_GET,
+	MV_FW_VPORT_L2_OPTION_SET,
+	MV_FW_VPORT_MTU_SET,
+	MV_FW_HWQ_STATS_GET,
+	MV_FW_SWQ_STATS_GET,
+	MV_FW_VPORT_STATS_GET,
+	MV_FW_BM_POOL_STATS_GET,
+	MV_FW_MSG_CHAN_STATS_GET,
+	MV_FW_RESET_STATISTICS,
+	MV_FW_LINK_CHANGE_NOTE,
+	MV_FW_INTERNAL_CPU_PORT_RX_PKT_MODE_SET,
+	MV_FW_VPORT_DEF_DEST_SET,
+	MV_FW_CPU_VPORT_MAP,
+
+	MV_FW_EXT_MSG_OPCODE_BASE = 0x80,
+};
+
+#endif /* __mv_pp3_fw_opcodes_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_init_sysfs.c b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_init_sysfs.c
new file mode 100644
index 0000000..6eb8575
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_init_sysfs.c
@@ -0,0 +1,126 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "fw/mv_fw.h"
+#include "mv_pp3.h"
+
+
+static ssize_t pp3_init_help(char *b)
+{
+	int o = 0;
+	int p = PAGE_SIZE;
+
+	o += sprintf(b+o, "\n");
+
+	o += scnprintf(b+o, p-o, "cat          help      - show this help\n");
+	o += scnprintf(b+o, p-o, "echo 1     > sys_init  - init FW and HW, run PPNs\n");
+	o += scnprintf(b+o, p-o, "\n");
+
+	return o;
+}
+
+static ssize_t pp3_init_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = pp3_init_help(buf);
+
+	return off;
+}
+
+static ssize_t pp3_init_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err, fields;
+	unsigned int    start;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = start = 0;
+
+	if (!strcmp(name, "sys_init")) {
+		fields = sscanf(buf, "%d", &start);
+		if (fields == 1) {
+			if (start)
+				err = mv_pp3_shared_start(pp3_device);
+		} else
+			err = 1;
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__,
+		       attr->attr.name);
+	}
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,		S_IRUSR, pp3_init_show, NULL);
+static DEVICE_ATTR(sys_init,		S_IWUSR, NULL, pp3_init_store);
+
+static struct attribute *pp3_init_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_sys_init.attr,
+	NULL
+};
+
+static struct attribute_group pp3_init_group = {
+	.attrs = pp3_init_attrs,
+};
+
+static struct kobject *dev_kobj;
+
+int mv_pp3_init_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+
+	dev_kobj = kobject_create_and_add("init", pp3_kobj);
+	if (!dev_kobj) {
+		pr_err("%s: cannot create dev kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_update_group(dev_kobj, &pp3_init_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", pp3_init_group.name, err);
+		return err;
+	}
+
+	return err;
+}
+
+
+int mv_pp3_init_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &pp3_init_group);
+
+	return 0;
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_version.c b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_version.c
new file mode 100644
index 0000000..3405a8c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/platform/mv_pp3_version.c
@@ -0,0 +1,37 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+
+/* includes */
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include "fw/mv_pp3_fw_msg_structs.h"
+
+static struct mv_pp3_version mv_pp3_driver_version = {
+	.name = "NSS",
+	.major_x = 1,
+	.minor_y = 1,
+	.local_z = 5,
+	.debug_d = 0
+};
+
+struct mv_pp3_version *mv_pp3_get_driver_version(void)
+{
+	return &mv_pp3_driver_version;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
new file mode 100644
index 0000000..343add4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
@@ -0,0 +1,1622 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+/* includes */
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "qm/mv_qm.h"
+#include "qm/mv_qm_regs.h"
+#include "tm/wrappers/mv_tm_scheme.h"
+
+static int ppc_port_fifo_base;
+static int mac_port_fifo_base;
+static int qm_regs_debug_flags;
+
+
+void qm_dbg_flags(u32 flag, u32 en)
+{
+	u32 bit_flag;
+
+	bit_flag = (fls(flag) - 1);
+
+	if (en)
+		qm_regs_debug_flags |= (1 << bit_flag);
+	else
+		qm_regs_debug_flags &= ~(1 << bit_flag);
+
+	return;
+}
+
+static void qm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+
+	mv_pp3_hw_read((void __iomem *)base_address + offset, wordsNumber, dataPtr);
+
+	if (qm_regs_debug_flags & QM_F_DBG_RD) {
+		int i;
+
+		for (i = 0; i < wordsNumber; i++)
+			pr_info("QM READ : 0x%08x = 0x%08x\n", base_address+offset + (4 * i), dataPtr[i]);
+	}
+}
+
+static void qm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+
+	mv_pp3_hw_write((void __iomem *)base_address + offset, wordsNumber, dataPtr);
+
+	if (qm_regs_debug_flags & QM_F_DBG_WR) {
+		int i;
+
+		for (i = 0; i < wordsNumber; i++)
+			pr_info("QM WRITE: 0x%08x = 0x%08x\n", base_address+offset + (4 * i), dataPtr[i]);
+	}
+}
+
+static void mv_pp3_qm_reg_print(char *reg_name, u32 reg, u32 val)
+{
+	pr_info("  %-32s: 0x%04x = 0x%08x\n", reg_name, reg, val);
+}
+
+/* send XOFF to macs when BM-almost-empty is asserted */
+static void qm_xoff_to_macs_enable(void)
+{
+	u32 val = 1;
+
+	qm_register_write(qm.ql.base + 0x0000600, 0, 1, &val);
+}
+
+/* set hmac ingress queues for secret machine stop/start */
+void qm_xoff_hmac_qs_set(int first_q, int q_num)
+{
+	u32 val = first_q | ((first_q + q_num) << 16);
+	qm_register_write(qm.ql.xoff_hmac_qs, 0, 1, &val);
+}
+
+/* set emac ingress queue for secret machine stop/start */
+void qm_xoff_emac_qnum_set(int emac, int queue)
+{
+	qm_register_write(qm.ql.xoff_mac_qnum, emac * 4, 1, &queue);
+}
+
+
+/* Enable/disable tail pointer insertion in the CFH, per EMAC source */
+void qm_tail_ptr_mode(int emac, bool enable)
+{
+	u32 reg_val;
+
+	qm_register_read(qm.dma.tail_pointer_en, 0, 1, &reg_val);
+
+	if (enable)
+		reg_val |= 1 << emac;
+	else
+		reg_val &= ~(1 << emac);
+
+	qm_register_write(qm.dma.tail_pointer_en, 0, 1, &reg_val);
+}
+
+/* Data FIFO port 15 parameters - depth and base offset */
+void qm_data_fifo_drop_port_cfg(void)
+{
+	u32 val = 0X1020000;
+	int reg_base_address =      qm.dqf.Data_FIFO_params_p;
+	int reg_size   =   qm_reg_size.dqf.Data_FIFO_params_p;
+	int reg_offset = qm_reg_offset.dqf.Data_FIFO_params_p * 15;
+
+	qm_register_write(reg_base_address, reg_offset, reg_size, &val);
+}
+
+/* init regisers base, offset and size */
+void qm_init(void __iomem *base)
+{
+	qm_reg_address_alias_init((u32)base);
+	qm_reg_size_alias_init();
+	qm_reg_offset_alias_init();
+}
+
+
+void qm_pfe_base_address_pool_set(struct mv_a40 *qece_base_address, struct mv_a40 *pyld_base_address)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+
+	struct pfe_qece_dram_base_address_hi         reg_qece_dram_base_address_hi;
+	struct pfe_qece_dram_base_address_lo         reg_qece_dram_base_address_lo;
+	struct pfe_pyld_dram_base_address_hi         reg_pyld_dram_base_address_hi;
+	struct pfe_pyld_dram_base_address_lo         reg_pyld_dram_base_address_lo;
+
+	if (qece_base_address) {
+		reg_base_address =      qm.pfe.qece_dram_base_address_hi;
+		reg_size   =   qm_reg_size.pfe.qece_dram_base_address_hi;
+		reg_offset = qm_reg_offset.pfe.qece_dram_base_address_hi * 0;
+
+		qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+		reg_qece_dram_base_address_hi.qece_dram_base_address_hi	= qece_base_address->dma_msb;
+		qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+
+		reg_base_address =      qm.pfe.qece_dram_base_address_lo;
+		reg_size   =   qm_reg_size.pfe.qece_dram_base_address_lo;
+		reg_offset = qm_reg_offset.pfe.qece_dram_base_address_lo * 0;
+
+		qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+
+		reg_qece_dram_base_address_lo.qece_dram_base_address_low = qece_base_address->dma_lsb;
+		qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+	}
+
+	if (pyld_base_address) {
+		reg_base_address =      qm.pfe.pyld_dram_base_address_hi;
+		reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_hi;
+		reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_hi * 0;
+
+		qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+
+		reg_pyld_dram_base_address_hi.pyld_dram_base_address_hi	 = pyld_base_address->dma_msb;
+		qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+
+		reg_base_address =      qm.pfe.pyld_dram_base_address_lo;
+		reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_lo;
+		reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_lo * 0;
+
+		qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+
+		reg_pyld_dram_base_address_lo.pyld_dram_base_address_low = pyld_base_address->dma_lsb;
+		qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+	}
+}
+
+/* Configure DMA with GPM pool thresholds, Enable QM */
+static void qm_dma_gpm_pools_enable(u32 qece_thr_hi, u32 qece_thr_lo, u32 pl_thr_hi, u32 pl_thr_lo)
+{
+	struct dma_gpm_thresholds reg_gpm_thresholds;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	reg_base_address =      qm.dma.gpm_thresholds;
+	reg_size   =   qm_reg_size.dma.gpm_thresholds;
+	reg_offset = qm_reg_offset.dma.gpm_thresholds * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_gpm_thresholds);
+
+	reg_gpm_thresholds.gpm_qe_pool_low_bp  = qece_thr_lo;	/* qe_thr & 0x00FFFFFFFF; */
+	reg_gpm_thresholds.gpm_qe_pool_high_bp = qece_thr_hi;	/* qe_thr >> 32; */
+	reg_gpm_thresholds.gpm_pl_pool_low_bp  =   pl_thr_lo;	/* pl_thr & 0x00FFFFFFFF; */
+	reg_gpm_thresholds.gpm_pl_pool_high_bp =   pl_thr_hi;	/* pl_thr >> 32; */
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_gpm_thresholds);
+}
+
+void qm_dma_gpm_pools_def_enable(void)
+{
+	/* set gpm qece and pl pools (0 and 1) thresholds */
+	qm_dma_gpm_pools_enable(QM_POOL_THR_HIGH, QM_POOL_THR_LOW,
+					QM_POOL_THR_HIGH, QM_POOL_THR_LOW);
+}
+
+/* Configure DMA with DRAM pool thresholds */
+static void qm_dma_dram_pools_enable(u32 qece_thr_hi, u32 qece_thr_lo, u32 pl_thr_hi, u32 pl_thr_lo)
+{
+	struct dma_dram_thresholds reg_dram_thresholds;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	reg_base_address =      qm.dma.dram_thresholds;
+	reg_size   =   qm_reg_size.dma.dram_thresholds;
+	reg_offset = qm_reg_offset.dma.dram_thresholds * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_thresholds);
+	reg_dram_thresholds.dram_qe_pool_low_bp  = qece_thr_lo;	/* qe_thr & 0x00FFFFFFFF; */
+	reg_dram_thresholds.dram_qe_pool_high_bp = qece_thr_hi;	/* qe_thr >> 32; */
+	reg_dram_thresholds.dram_pl_pool_low_bp  =   pl_thr_lo;	/* pl_thr & 0x00FFFFFFFF; */
+	reg_dram_thresholds.dram_pl_pool_high_bp =   pl_thr_hi;	/* pl_thr >> 32; */
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_thresholds);
+}
+
+
+void qm_dma_dram_pools_def_enable(void)
+{
+	/* set gpm qece and pl pools (2 and 3) thresholds */
+	qm_dma_dram_pools_enable(QM_POOL_THR_HIGH, QM_POOL_THR_LOW,
+					QM_POOL_THR_HIGH, QM_POOL_THR_LOW);
+}
+
+/*
+qm_dqf_port_data_fifo_params_set:
+	description:
+		set port FIFO base and offset
+	parameters:
+		port  - QM port number
+		base  - base offset in bytes
+		depth - FIFO depth in bytes
+*/
+
+static int qm_dqf_port_data_fifo_params_set(int port, int base, int depth)
+{
+	struct dqf_Data_FIFO_params_p reg_data_fifo_params;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if (port <= 3) {
+		/* rows of 144B */
+		reg_data_fifo_params.data_fifo_depth_p  =
+			depth / QM_DQF_PPC_ROW_SIZE;
+		reg_data_fifo_params.data_fifo_base_p =
+			base / QM_DQF_PPC_ROW_SIZE;
+	} else {
+		/* rows of 16B */
+		reg_data_fifo_params.data_fifo_depth_p  =
+			depth/QM_DQF_MAC_ROW_SIZE;
+		reg_data_fifo_params.data_fifo_base_p   =
+			base / QM_DQF_MAC_ROW_SIZE;
+	}
+
+
+	reg_base_address =      qm.dqf.Data_FIFO_params_p;
+	reg_size   =   qm_reg_size.dqf.Data_FIFO_params_p;
+	reg_offset = qm_reg_offset.dqf.Data_FIFO_params_p * port;
+
+	qm_register_write(qm.dqf.Data_FIFO_params_p,
+			  qm_reg_offset.dqf.Data_FIFO_params_p * port,
+			  qm_reg_size.dqf.Data_FIFO_params_p,
+			  (u32 *)&reg_data_fifo_params);
+
+	return MV_OK;
+}
+
+/*
+qm_dqf_all_ports_credit_thr_set:
+	description:
+		set Credit Threshold per port
+	parameters:
+		port   - QM port number
+		credit - Credit Threshold in bytes
+*/
+static int qm_dqf_port_credit_thr_set(int port, int credit)
+{
+	struct dqf_Credit_Threshold_p          reg_credit_threshold_p;
+
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	memset(&reg_credit_threshold_p, 0, sizeof(struct dqf_Credit_Threshold_p));
+
+	reg_credit_threshold_p.Credit_Threshold_p   = credit / 16;
+
+	qm_register_write(qm.dqf.Credit_Threshold_p,
+			  qm_reg_offset.dqf.Credit_Threshold_p * port,
+			  qm_reg_size.dqf.Credit_Threshold_p, (u32 *)&reg_credit_threshold_p);
+	return MV_OK;
+}
+
+/**
+*  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+*  relevant only for PPC port.
+*  Return values:
+*		0 - success
+*/
+static int qm_dqf_port_ppc_map_set(int port, u32 ppc_bitmap)
+{
+	struct dqf_PPC_port_map_p reg_PPC_port_map_p;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	memset(&reg_PPC_port_map_p, 0, sizeof(struct dqf_PPC_port_map_p));
+
+	reg_base_address =      qm.dqf.PPC_port_map_p;
+	reg_size   =   qm_reg_size.dqf.PPC_port_map_p;
+	reg_offset = qm_reg_offset.dqf.PPC_port_map_p * port;
+
+	reg_PPC_port_map_p.ppc_port_map_p = ppc_bitmap;
+
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_PPC_port_map_p);
+
+	return MV_OK;
+}
+
+static int qm_ql_q_profile_set(int queue, enum mv_qm_thr_profiles profile)
+{
+	u32 reg_offset, queue_offset, reg_qptr_entry;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	reg_offset = qm_reg_offset.ql.qptr * (queue/8);
+	qm_register_read(qm.ql.qptr, reg_offset, qm_reg_size.ql.qptr, &reg_qptr_entry);
+
+	/* each queue is 3 bits, 8 queues in u32 */
+	queue_offset = (queue % 8) * 3;
+	/* clear old value */
+	reg_qptr_entry &= ~(0x7 << queue_offset);
+
+	if (profile != QM_THR_PROFILE_INVALID)
+		reg_qptr_entry |= ((profile + 1) << queue_offset);
+
+	qm_register_write(qm.ql.qptr, reg_offset, qm_reg_size.ql.qptr, &reg_qptr_entry);
+
+	return MV_OK;
+}
+
+/*
+ description:
+	return queue thersholds profile number
+	inputs:
+		qeueue  - queue number
+*/
+static int qm_ql_q_profile_get(int queue, enum mv_qm_thr_profiles *profile)
+{
+	u32 reg_offset, queue_offset, reg_qptr_entry;
+
+	if (!profile) {
+		pr_err("input pointer is NULL");
+		return -EINVAL;
+	}
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	reg_offset = qm_reg_offset.ql.qptr * (queue/8);
+
+	qm_register_read(qm.ql.qptr, reg_offset, qm_reg_size.ql.qptr, &reg_qptr_entry);
+
+	/* each queue is 3 bits, 8 queues in u32 */
+	queue_offset = (queue % 8) * 3;
+
+	reg_qptr_entry &= 0x7 << queue_offset;
+
+	*profile = reg_qptr_entry >> queue_offset;
+
+	return MV_OK;
+}
+
+int qm_emac_profile_set(int emac, enum mv_port_mode port_mode, int queue)
+{
+	int ret_val;
+
+	if ((port_mode == MV_PORT_XAUI) || (port_mode == MV_PORT_RXAUI))
+		/* 10 Giga port thresholds */
+		qm_ql_profile_cfg(emac, MV_PP3_10G_LOW_THR, MV_PP3_10G_PAUSE_THR, MV_PP3_10G_HIGH_THR);
+
+	else  if (port_mode == MV_PORT_SGMII2_5)
+		/* 2.5 Giga port thresholds */
+		qm_ql_profile_cfg(emac, MV_PP3_2_5G_LOW_THR, MV_PP3_2_5G_PAUSE_THR, MV_PP3_2_5G_HIGH_THR);
+	else
+		/* 1 Giga port thresholds */
+		qm_ql_profile_cfg(emac, MV_PP3_1G_LOW_THR, MV_PP3_1G_PAUSE_THR, MV_PP3_1G_HIGH_THR);
+
+	/* connect queue to profile */
+	ret_val = qm_ql_q_profile_set(queue, emac);
+
+	if (ret_val < 0) {
+		pr_err("%s: mapping queue %d to emac %d profile failed\n",
+				__func__, queue, emac);
+		return ret_val;
+	}
+
+	return MV_OK;
+}
+
+
+int qm_hmac_profile_set(int first_q, int q_num)
+{
+	int ret_val, queue, last_q;
+
+	qm_ql_profile_cfg(QM_THR_PROFILE_HMAC, MV_PP3_HMAC_LOW_THR,
+			  MV_PP3_HMAC_PAUSE_THR, MV_PP3_HMAC_HIGH_THR);
+
+	last_q = q_num + first_q;
+
+	for (queue = first_q; queue < last_q; queue++) {
+		ret_val = qm_ql_q_profile_set(queue, QM_THR_PROFILE_HMAC);
+
+		if (ret_val < 0) {
+			pr_err("%s: mapping queue %d to hmac profile (%d) failed\n",
+					__func__, queue, QM_THR_PROFILE_HMAC);
+			return ret_val;
+		}
+	}
+
+	return MV_OK;
+}
+
+/* mapping queue to port for drop recommendation */
+static int qm_ql_queue_port_set(int queue, int port)
+{
+	u32 reg_offset, queue_offset, reg_val;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	reg_offset = qm_reg_offset.ql.qmap_port * (queue/4);
+	qm_register_read(qm.ql.qmap_port, reg_offset, qm_reg_size.ql.qmap_port, &reg_val);
+
+	/* each queue is 6 bits + 2 reserved */
+	queue_offset = (queue % 4) * 8;
+
+	/* clear old value */
+	reg_val &= ~(0xF << queue_offset);
+
+	reg_val |= (port << queue_offset);
+
+	qm_register_write(qm.ql.qmap_port, reg_offset, qm_reg_size.ql.qmap_port, &reg_val);
+
+	return MV_OK;
+}
+
+/* mapping queue to internal back pressure group */
+int qm_ql_queue_bpi_group_set(int queue, int group)
+{
+	u32 reg_offset, queue_offset, reg_val;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	if (group >= MV_PP3_QM_BP_RULES_NUM) {
+		pr_err("Invalid group number %d\n", group);
+		return -EINVAL;
+	}
+
+	reg_offset = qm_reg_offset.ql.qmap_group * (queue/4);
+	qm_register_read(qm.ql.qmap_group, reg_offset, qm_reg_size.ql.qmap_group, &reg_val);
+
+	/* each queue is 6 bits + 2 reserved */
+	queue_offset = (queue % 4) * 8;
+
+	/* clear old value */
+	reg_val &= ~(0x3F << queue_offset);
+
+	reg_val |= (group << queue_offset);
+
+	qm_register_write(qm.ql.qmap_group, reg_offset, qm_reg_size.ql.qmap_group, &reg_val);
+
+	return MV_OK;
+}
+/* get queue internal back pressure group */
+static int qm_ql_queue_bpi_group_get(int queue, int *group)
+{
+	u32 reg_offset, queue_offset, reg_val;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	reg_offset = qm_reg_offset.ql.qmap_group * (queue/4);
+	qm_register_read(qm.ql.qmap_group, reg_offset, qm_reg_size.ql.qmap_group, &reg_val);
+
+	/* each queue is 6 bits + 2 reserved */
+	queue_offset = (queue % 4) * 8;
+
+	/* clear old value */
+	reg_val &= 0x3F << queue_offset;
+
+	*group = reg_val >> queue_offset;
+
+	return MV_OK;
+}
+
+
+const char *mv_qm_node_str(enum mv_qm_node_type level)
+{
+	const char *str;
+
+	switch (level) {
+	case MV_QM_Q_NODE:
+		str = "Q-NODE";
+		break;
+	case MV_QM_A_NODE:
+		str = "A-NODE";
+		break;
+	case MV_QM_B_NODE:
+		str = "B-NODE";
+		break;
+	case MV_QM_C_NODE:
+		str = "C-NODE";
+		break;
+	case MV_QM_PORT_NODE:
+		str = "P-NODE";
+		break;
+	default:
+		str = "Unknown";
+	}
+	return str;
+}
+
+/* config internal back pressure group */
+int qm_ql_group_bpi_set(int group, int xon_thr, int xoff_thr, enum mv_qm_node_type level, int node_id)
+{
+	struct ql_rule_bpi_entry reg_rule_bpi_entry;
+
+	memset(&reg_rule_bpi_entry, 0, sizeof(struct ql_rule_bpi_entry));
+
+	if ((level != MV_QM_A_NODE) && (level != MV_QM_B_NODE) && (level != MV_QM_C_NODE)) {
+		pr_err("%s: invalid node type %s (%d)\n", __func__, mv_qm_node_str(level), level);
+		return -EINVAL;
+	}
+
+	/* TODO inputs validation */
+
+	reg_rule_bpi_entry.xon_thr = (xon_thr * 1024) / MV_PP3_QM_UNITS;
+	reg_rule_bpi_entry.xoff_thr = (xoff_thr * 1024) / MV_PP3_QM_UNITS;
+
+	reg_rule_bpi_entry.target_lvl = level;
+	reg_rule_bpi_entry.target_node = node_id;
+
+	qm_register_write(qm.ql.rule_bpi, qm_reg_offset.ql.rule_bpi * group,
+				qm_reg_size.ql.rule_bpi, (u32 *)&reg_rule_bpi_entry);
+
+	return MV_OK;
+}
+
+int qm_ql_group_bpi_get(int group, int *xon_thr, int *xoff_thr, enum mv_qm_node_type *level, int *node_id)
+{
+	struct ql_rule_bpi_entry reg_rule_bpi_entry;
+
+	if (group >= MV_PP3_QM_BP_RULES_NUM) {
+		pr_err("Invalid group number %d\n", group);
+		return -EINVAL;
+	}
+
+	qm_register_read(qm.ql.rule_bpi, qm_reg_offset.ql.rule_bpi * group,
+			qm_reg_size.ql.rule_bpi, (u32 *)&reg_rule_bpi_entry);
+	if (xon_thr)
+		*xon_thr = (reg_rule_bpi_entry.xon_thr * MV_PP3_QM_UNITS / 1024);
+	if (xoff_thr)
+		*xoff_thr = (reg_rule_bpi_entry.xoff_thr * MV_PP3_QM_UNITS / 1024);
+	if (level)
+		*level = reg_rule_bpi_entry.target_lvl & 0x3;
+	if (node_id)
+		*node_id = reg_rule_bpi_entry.target_node & 0x7F;
+
+	return 0;
+}
+
+static int qm_ql_rule_bpi_disable(int group)
+{
+	/* disable group back pressure - set high xon_thr and xoff_thr */
+	return qm_ql_group_bpi_set(group, 0x1FFF, 0x1FFF, MV_QM_A_NODE, 0);
+}
+
+void qm_ql_group_bpi_show_all(void)
+{
+	int group;
+	struct ql_rule_bpi_entry reg_rule_bpi_entry;
+
+	for (group = 0; group < QM_BPI_GROUPS; group++) {
+		qm_register_read(qm.ql.rule_bpi, qm_reg_offset.ql.rule_bpi * group,
+				qm_reg_size.ql.rule_bpi, (u32 *)&reg_rule_bpi_entry);
+
+		/* print only enabled groups */
+		if (reg_rule_bpi_entry.xon_thr < reg_rule_bpi_entry.xoff_thr)
+			qm_ql_group_bpi_show(group);
+	}
+}
+
+void qm_ql_group_bpi_show(int group)
+{
+	struct ql_rule_bpi_entry reg_rule_bpi_entry;
+	const char *node_name;
+	int queue, q_group, count = 0;
+
+	qm_register_read(qm.ql.rule_bpi, qm_reg_offset.ql.rule_bpi * group,
+				qm_reg_size.ql.rule_bpi, (u32 *)&reg_rule_bpi_entry);
+
+	node_name = mv_qm_node_str(reg_rule_bpi_entry.target_lvl & 0x3);
+
+	pr_info("\n-------------- QM QL BPI group %d -----------", group);
+	pr_info("Xon  threshold [KB]  :  %d\n", (reg_rule_bpi_entry.xon_thr * MV_PP3_QM_UNITS) / 1024);
+	pr_info("Xoff threshold [KB]  :  %d\n", (reg_rule_bpi_entry.xoff_thr * MV_PP3_QM_UNITS) / 1024);
+	pr_info("Node                 :  %s %d\n", node_name, reg_rule_bpi_entry.target_node & 0x7F);
+
+	pr_info("Connected queues list:");
+	for (queue = 0; queue < QM_QUEUES_NUM; queue++) {
+		qm_ql_queue_bpi_group_get(queue, &q_group);
+
+		if (q_group == group) {
+			pr_cont(" %3d", queue);
+			count++;
+
+			if ((count % 25) == 0)
+				pr_info("\n                      ");
+		}
+	}
+
+	pr_info("\n");
+}
+
+/* set thresholds profile
+	parameters:
+		profie - profile number
+		low, pause, high - thresholds in KB
+		source - traffic source to stop
+*/
+void qm_ql_profile_cfg(enum mv_qm_thr_profiles profile, u32 low, u32 pause, u32 high)
+{
+	struct ql_low_threshold		reg_low_threshold;
+	struct ql_pause_threshold	reg_pause_threshold;
+	struct ql_high_threshold	reg_high_threshold;
+	struct ql_traffic_source	reg_traffic_source;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	memset(&reg_low_threshold, 0, sizeof(struct ql_low_threshold));
+	memset(&reg_pause_threshold, 0, sizeof(struct ql_pause_threshold));
+	memset(&reg_high_threshold, 0, sizeof(struct ql_high_threshold));
+	memset(&reg_traffic_source, 0, sizeof(struct ql_traffic_source));
+
+	reg_base_address =      qm.ql.low_threshold;
+	reg_size   =   qm_reg_size.ql.low_threshold;
+	reg_offset = qm_reg_offset.ql.low_threshold * profile;
+	reg_low_threshold.low_threshold   = (low * 1024) / MV_PP3_QM_UNITS;
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_low_threshold);
+
+	reg_base_address =      qm.ql.pause_threshold;
+	reg_size   =   qm_reg_size.ql.pause_threshold;
+	reg_offset = qm_reg_offset.ql.pause_threshold * profile;
+	reg_pause_threshold.pause_threshold = (pause * 1024) / MV_PP3_QM_UNITS;
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pause_threshold);
+
+	reg_base_address =      qm.ql.high_threshold;
+	reg_size   =   qm_reg_size.ql.high_threshold;
+	reg_offset = qm_reg_offset.ql.high_threshold * profile;
+	reg_high_threshold.high_threshold = (high * 1024) / MV_PP3_QM_UNITS;
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_high_threshold);
+
+	reg_base_address =      qm.ql.traffic_source;
+	reg_size   =   qm_reg_size.ql.traffic_source;
+	reg_offset = qm_reg_offset.ql.traffic_source * profile;
+	reg_traffic_source.traffic_source = profile;
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_traffic_source);
+}
+
+int qm_queue_flush_start(int queue)
+{
+	struct pfe_queue_flush reg_queue_flush;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	reg_base_address =      qm.pfe.queue_flush;
+	reg_size   =   qm_reg_size.pfe.queue_flush;
+	reg_offset = qm_reg_offset.pfe.queue_flush * (queue/32);
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_queue_flush);
+	reg_queue_flush.queue_flush_bit_per_q |=  (0x00000001 << ((reg_queue_flush.queue_flush_bit_per_q)%32));
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_queue_flush);
+
+	return MV_OK;
+}
+
+static int qm_port_max_credit_request_set(int port, int credit)
+{
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	qm_register_write(qm.pfe.max_credit_for_new_dram_req, port * 4, 1, &credit);
+
+	return MV_OK;
+}
+
+static int qm_port_drop_mode_set(u32 port, bool enable)
+{
+	struct pfe_port_flush reg_port_flush;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	reg_base_address =      qm.pfe.port_flush;
+	reg_size   =   qm_reg_size.pfe.port_flush;
+	reg_offset = qm_reg_offset.pfe.port_flush * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_port_flush);
+
+	if (enable)
+		reg_port_flush.port_flush |=  (0x00000001 << port);
+	else
+		reg_port_flush.port_flush &= ~(0x00000001 << port);
+
+	qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_port_flush);
+
+	return MV_OK;
+}
+
+int ql_queue_length_get(int queue, u32 *length, u32 *status)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	struct ql_qlen     reg_qlen;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return -EINVAL;
+	}
+
+	reg_base_address =      qm.ql.qlen;
+	reg_size   =   qm_reg_size.ql.qlen;
+	reg_offset = qm_reg_offset.ql.qlen * queue;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qlen);
+
+	*length = reg_qlen.reg_ql_entry.ql;
+	*status = reg_qlen.reg_ql_entry.qstatus;
+
+	return MV_OK;
+}
+
+void qm_idle_status_get(u32 *status)
+{
+	struct dma_idle_status reg_idle_status;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	reg_base_address =      qm.dma.idle_status;
+	reg_size   =   qm_reg_size.dma.idle_status;
+	reg_offset = qm_reg_offset.dma.idle_status * 0;
+
+	pr_info("\n-------------- Read DMA idle status -----------");
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_idle_status);
+
+	*status = *(u32 *)&reg_idle_status;
+
+	pr_info("\n");
+
+	pr_info("\t idle_status.gpm_pl_cache_is_empty  = %d\n",
+				((reg_idle_status.gpm_pl_cache_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.gpm_pl_cache_is_full  = %d\n",
+				((reg_idle_status.gpm_pl_cache_is_full == 0) ? 0 : 1));
+	pr_info("\t idle_status.gpm_qe_cache_is_empty  = %d\n",
+				((reg_idle_status.gpm_qe_cache_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.gpm_qe_cache_is_full  = %d\n",
+				((reg_idle_status.gpm_qe_cache_is_full == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_pl_cache_is_empty  = %d\n",
+				((reg_idle_status.dram_pl_cache_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_pl_cache_is_full  = %d\n",
+				((reg_idle_status.dram_pl_cache_is_full == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_qe_cache_is_empty  = %d\n",
+				((reg_idle_status.dram_qe_cache_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_qe_cache_is_full  = %d\n",
+				((reg_idle_status.dram_qe_cache_is_full == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_fifo_is_empty  = %d\n",
+				((reg_idle_status.dram_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.mac_axi_enq_channel_is_empty  = %d\n",
+				((reg_idle_status.mac_axi_enq_channel_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.NSS_axi_enq_channel_is_empty  = %d\n",
+				((reg_idle_status.NSS_axi_enq_channel_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.gpm_ppe_read_fifo_is_empty  = %d\n",
+				((reg_idle_status.gpm_ppe_read_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.ppe_gpm_pl_write_fifo_is_empty  = %d\n",
+				((reg_idle_status.ppe_gpm_pl_write_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.ppe_gpm_qe_write_fifo_is_empty  = %d\n",
+				((reg_idle_status.ppe_gpm_qe_write_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.ppe_ru_read_fifo_is_empty  = %d\n",
+				((reg_idle_status.ppe_ru_read_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.ppe_ru_write_fifo_is_empty  = %d\n",
+				((reg_idle_status.ppe_ru_write_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.ru_ppe_read_fifo_is_empty  = %d\n",
+				((reg_idle_status.ru_ppe_read_fifo_is_empty == 0) ? 0 : 1));
+	pr_info("\t idle_status.dram_fifo_fsm_state_is_idle  = %d\n",
+				((reg_idle_status.dram_fifo_fsm_state_is_idle == 0) ? 0 : 1));
+	pr_info("\t idle_status.qeram_init_fsm_state_is_idle  = %d\n",
+				((reg_idle_status.qeram_init_fsm_state_is_idle == 0) ? 0 : 1));
+}
+
+/* QM Debug functions */
+void qm_errors_dump(void)
+{
+	u32 reg_base_address, reg_size, reg_offset, reg_data;
+
+	pr_info("\n-------------- QL errors dump (0x%x) -----------\n", qm.ql.base);
+
+	reg_base_address =      qm.ql.ECC_error_cause;
+	reg_size   =   qm_reg_size.ql.ECC_error_cause;
+	reg_offset = qm_reg_offset.ql.ECC_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("ECC ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.ql.Internal_error_cause;
+	reg_size   =   qm_reg_size.ql.Internal_error_cause;
+	reg_offset = qm_reg_offset.ql.Internal_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("INTERNAL ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- PFE errors dump (0x%x) -----------\n", qm.pfe.base);
+
+	reg_base_address =      qm.pfe.ecc_error_cause;
+	reg_size   =   qm_reg_size.pfe.ecc_error_cause;
+	reg_offset = qm_reg_offset.pfe.ecc_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("ECC ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.internal_error_cause;
+	reg_size   =   qm_reg_size.pfe.internal_error_cause;
+	reg_offset = qm_reg_offset.pfe.internal_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("INTERNAL ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- DMA errors dump (0x%x) -----------\n", qm.dma.base);
+
+	reg_base_address =      qm.dma.ecc_error_cause;
+	reg_size   =   qm_reg_size.dma.ecc_error_cause;
+	reg_offset = qm_reg_offset.dma.ecc_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("ECC ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.internal_error_cause;
+	reg_size   =   qm_reg_size.dma.internal_error_cause;
+	reg_offset = qm_reg_offset.dma.internal_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("INTERNAL ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- DQF errors dump (0x%x) -----------\n", qm.dqf.base);
+
+	reg_base_address =      qm.dqf.dqf_itnr_cause;
+	reg_size   =   qm_reg_size.dqf.dqf_itnr_cause;
+	reg_offset = qm_reg_offset.dqf.dqf_itnr_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("DQF INTERRUPT CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.dqf_ser_summary_intr_cause;
+	reg_size   =   qm_reg_size.dqf.dqf_ser_summary_intr_cause;
+	reg_offset = qm_reg_offset.dqf.dqf_ser_summary_intr_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("INTERNAL SER SUMMARY CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.write_to_full_error_intr_cause;
+	reg_size   =   qm_reg_size.dqf.write_to_full_error_intr_cause;
+	reg_offset = qm_reg_offset.dqf.write_to_full_error_intr_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("WRITE TO FULL ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.read_from_empty_error_intr_cause;
+	reg_size   =   qm_reg_size.dqf.read_from_empty_error_intr_cause;
+	reg_offset = qm_reg_offset.dqf.read_from_empty_error_intr_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("READ FROM EMPTY ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.wrong_axi_rd_error_intr_cause;
+	reg_size   =   qm_reg_size.dqf.wrong_axi_rd_error_intr_cause;
+	reg_offset = qm_reg_offset.dqf.wrong_axi_rd_error_intr_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("WRONG AXI RD ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- REORDER errors dump (0x%x) -----------\n", qm.reorder.base);
+
+	reg_base_address =      qm.reorder.ru_ser_error_cause;
+	reg_size   =   qm_reg_size.reorder.ru_ser_error_cause;
+	reg_offset = qm_reg_offset.reorder.ru_ser_error_cause * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("RU SER ERROR CAUSE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+}
+
+void qm_global_dump(void)
+{
+	u32 reg_data;
+	u32 reg_base_address, reg_size, reg_offset;
+	u32 t;
+
+	pr_info("\n-------------- QL global registers dump (0x%x)-----------\n", qm.ql.base);
+
+	for (t = 0; t < QM_THR_PROFILE_INVALID; t++) {
+
+		pr_info("\n-------------- Profile %d ---------------\n", t);
+		reg_base_address =      qm.ql.low_threshold;
+		reg_size   =   qm_reg_size.ql.low_threshold;
+		reg_offset = qm_reg_offset.ql.low_threshold * t;
+		qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_data);
+		mv_pp3_qm_reg_print("LOW THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+		reg_base_address =      qm.ql.pause_threshold;
+		reg_size   =   qm_reg_size.ql.pause_threshold;
+		reg_offset = qm_reg_offset.ql.pause_threshold * t;
+		qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+		mv_pp3_qm_reg_print("PAUSE THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+		reg_base_address =      qm.ql.high_threshold;
+		reg_size   =   qm_reg_size.ql.high_threshold;
+		reg_offset = qm_reg_offset.ql.high_threshold * t;
+		qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+		mv_pp3_qm_reg_print("HIGH THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+		reg_base_address =      qm.ql.traffic_source;
+		reg_size   =   qm_reg_size.ql.traffic_source;
+		reg_offset = qm_reg_offset.ql.traffic_source * t;
+		qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+		mv_pp3_qm_reg_print("TRAFFIC SOURCE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+	}
+
+	pr_info("\n-------------- PFE global registers dump (0x%x)-----------\n", qm.pfe.base);
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_hi * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("QE_CE DRAM BASE HIGH", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_hi * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("PAYLOAD DRAM BASE HIGH", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_lo * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("QE_CE DRAM BASE LOW", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_lo * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("PAYLOAD DRAM BASE LOW", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.QM_VMID;
+	reg_size   =   qm_reg_size.pfe.QM_VMID;
+	reg_offset = qm_reg_offset.pfe.QM_VMID * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("QM VMID", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.port_flush;
+	reg_size   =   qm_reg_size.pfe.port_flush;
+	reg_offset = qm_reg_offset.pfe.port_flush * 0;
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("PORT FLUSH", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR SWF MODE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR RDMA MODE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR HWF MODE QECE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR HWF MODE PYLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- DMA global registers dump (0x%x) -----------\n", qm.dma.base);
+
+	reg_base_address =      qm.dma.gpm_thresholds;
+	reg_size   =   qm_reg_size.dma.gpm_thresholds;
+	reg_offset = qm_reg_offset.dma.gpm_thresholds * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("GPM THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.dram_thresholds;
+	reg_size   =   qm_reg_size.dma.dram_thresholds;
+	reg_offset = qm_reg_offset.dma.dram_thresholds * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("DRAM THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_swf_mode * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI WRITE ATTR SWF MODE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR RDMA MODE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR HWF MODE QECE", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("AXI READ ATTR HWF MODE PYLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.DRAM_VMID;
+	reg_size   =   qm_reg_size.dma.DRAM_VMID;
+	reg_offset = qm_reg_offset.dma.DRAM_VMID * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("DRAM VMID", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dma.idle_status;
+	reg_size   =   qm_reg_size.dma.idle_status;
+	reg_offset = qm_reg_offset.dma.idle_status * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("IDLE STATUS", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- REORDER global registers dump (0x%x) -----------\n", qm.reorder.base);
+
+	reg_base_address =      qm.reorder.ru_pool;
+	reg_size   =   qm_reg_size.reorder.ru_pool;
+	reg_offset = qm_reg_offset.reorder.ru_pool * 0;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("RU POOL 0", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.reorder.ru_pool;
+	reg_size   =   qm_reg_size.reorder.ru_pool;
+	reg_offset = qm_reg_offset.reorder.ru_pool * 1;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("RU POOL 1", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	for (t = 0; t <= QM_CLASS_MAX; t++) {
+		char r_name[20];
+		reg_base_address =      qm.reorder.ru_class_head;
+		reg_size   =   qm_reg_size.reorder.ru_class_head;
+		reg_offset = qm_reg_offset.reorder.ru_class_head * t;
+
+		qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+		sprintf(r_name, "RU CLASS HEAD %d", t);
+		mv_pp3_qm_reg_print(r_name, (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+	}
+}
+
+void qm_queue_dump(int queue)
+{
+	u32 reg_data;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if (queue >= QM_QUEUES_NUM) {
+		pr_err("Invalid queue number %d\n", queue);
+		return;
+	}
+
+	pr_info("\n-------------- QM queue dump for queue %d -----------\n", queue);
+	pr_info("\n-------------- QL queue registers -----------\n");
+
+	reg_base_address =      qm.ql.qptr;
+	reg_size   =   qm_reg_size.ql.qptr;
+	reg_offset = qm_reg_offset.ql.qptr * queue/8;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	reg_data = (reg_data  >> (queue % 8) & 7);
+	mv_pp3_qm_reg_print("QUEUE PTR", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.ql.qlen;
+	reg_size   =   qm_reg_size.ql.qlen;
+	reg_offset = qm_reg_offset.ql.qlen * queue;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_data);
+	mv_pp3_qm_reg_print("QUEUE LENGTH AND STATUS", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- PFE queue dump -----------\n");
+
+	reg_base_address =      qm.pfe.queue_flush;
+	reg_size   =   qm_reg_size.pfe.queue_flush;
+	reg_offset = qm_reg_offset.pfe.queue_flush * (queue/32); /* each queue is represented by one bit*/
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	reg_data = (reg_data  >> (queue % 32) & 1);
+	mv_pp3_qm_reg_print("QUEUE FLUSH", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	pr_info("\n-------------- DMA queue dump -----------\n");
+
+	reg_base_address =      qm.dma.Q_memory_allocation;
+	reg_size   =   qm_reg_size.dma.Q_memory_allocation;
+	reg_offset = qm_reg_offset.dma.Q_memory_allocation * (queue/32); /* each queue is represented by one bit*/
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	reg_data = (reg_data  >> (queue % 32) & 1);
+	mv_pp3_qm_reg_print("QUEUE MEM ALLOCATION", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+}
+
+static const char *qm_ql_bp_status_str(enum mv_qm_ql_bp_status status)
+{
+	const char *str;
+
+	switch (status) {
+	case QM_BP_XON:
+		str = "XON";
+		break;
+	case QM_BP_PAUSE:
+		str = "PAUSE";
+		break;
+	case QM_BP_XOFF:
+		str = "XOFF";
+		break;
+	default:
+		str = "Unknown";
+	}
+	return str;
+}
+
+struct qm_queue_len_info {
+	int queue;
+	struct ql_qlen       reg_qlen;
+	struct ql_bp_qlen    reg_ql_bp_qlen;
+	struct ql_drop_qlen  reg_ql_drop_qlen;
+};
+
+void qm_nempty_queue_len_dump(void)
+{
+	int queue, nempty = 0;
+	bool dump;
+	char bp_str[10];
+	struct qm_queue_len_info *qlen_array, *qlen_info;
+
+	qlen_array = kzalloc(QM_QUEUES_NUM * sizeof(struct qm_queue_len_info), GFP_KERNEL);
+	if (qlen_array == NULL) {
+		pr_err("%s: Can't allocate %d bytes. first=%d\n", __func__,
+			QM_QUEUES_NUM * sizeof(struct qm_queue_len_info), 0);
+		return;
+	}
+	/* First of all read queues registers from QM without print */
+	for (queue = 0; queue < QM_QUEUES_NUM; queue++) {
+		qlen_info = &qlen_array[nempty];
+
+		qm_register_read(qm.ql.qlen, qm_reg_offset.ql.qlen * queue,
+				qm_reg_size.ql.qlen, (u32 *)&qlen_info->reg_qlen);
+
+		qm_register_read(qm.ql.bp_qlen, qm_reg_offset.ql.bp_qlen * queue,
+				qm_reg_size.ql.bp_qlen, (u32 *)&qlen_info->reg_ql_bp_qlen);
+
+		qm_register_read(qm.ql.drop_qlen, qm_reg_offset.ql.drop_qlen * queue,
+				qm_reg_size.ql.drop_qlen, (u32 *)&qlen_info->reg_ql_drop_qlen);
+
+		dump =  qlen_info->reg_qlen.reg_ql_entry.ql ||
+			qlen_info->reg_ql_bp_qlen.reg_ql_bp_qlen_entry.ql ||
+			qlen_info->reg_ql_drop_qlen.reg_ql_drop_qlen_entry.ql;
+
+		if (dump) {
+			qlen_info->queue = queue;
+			nempty++;
+		}
+	}
+	pr_info("\n");
+	pr_info("Queue | length[16B] | bp_len[128B] (mode)   | drop_len[128B]\n");
+
+	for (queue = 0; queue < nempty; queue++) {
+		qlen_info = &qlen_array[queue];
+
+		sprintf(bp_str, "(%s)",
+			qm_ql_bp_status_str(qlen_info->reg_ql_bp_qlen.reg_ql_bp_qlen_entry.qstatus & 0x3));
+		pr_info("%3d   | 0x%08X  | 0x%08X %-9s  | 0x%08X\n",
+			qlen_info->queue, qlen_info->reg_qlen.reg_ql_entry.ql,
+			qlen_info->reg_ql_bp_qlen.reg_ql_bp_qlen_entry.ql, bp_str,
+			qlen_info->reg_ql_drop_qlen.reg_ql_drop_qlen_entry.ql);
+	}
+	kfree(qlen_array);
+}
+
+void qm_dqf_port_dump(int port)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	u32 reg_data;
+
+	if (port >= QM_PORTS_NUM) {
+		pr_err("Invalid port number %d\n", port);
+		return;
+	}
+
+	pr_info("\n-------------- DQF port dump for port %d -----------\n", port);
+
+	reg_base_address =      qm.dqf.Data_FIFO_params_p;
+	reg_size   =   qm_reg_size.dqf.Data_FIFO_params_p;
+	reg_offset = qm_reg_offset.dqf.Data_FIFO_params_p * port;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("DATA FIFO PARAMS", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.Credit_Threshold_p;
+	reg_size   =   qm_reg_size.dqf.Credit_Threshold_p;
+	reg_offset = qm_reg_offset.dqf.Credit_Threshold_p * port;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("CREDIT THRESHOLD", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.PPC_port_map_p;
+	reg_size   =   qm_reg_size.dqf.PPC_port_map_p;
+	reg_offset = qm_reg_offset.dqf.PPC_port_map_p * port;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("PPC_PORT_MAP", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+
+	reg_base_address =      qm.dqf.data_fifo_pointers_p;
+	reg_size   =   qm_reg_size.dqf.data_fifo_pointers_p;
+	reg_offset = qm_reg_offset.dqf.data_fifo_pointers_p * port;
+
+	qm_register_read(reg_base_address, reg_offset, reg_size, &reg_data);
+	mv_pp3_qm_reg_print("DATA FIFO PTRS", (reg_base_address + reg_offset) & 0xFFFF, reg_data);
+}
+
+static const char *qm_ql_profile_source_str(enum mv_qm_thr_profiles profile)
+{
+	const char *source_str;
+
+	switch (profile) {
+	case QM_THR_PROFILE_EMAC_0:
+		source_str = "EMAC0";
+		break;
+	case QM_THR_PROFILE_EMAC_1:
+		source_str = "EMAC1";
+		break;
+	case QM_THR_PROFILE_EMAC_2:
+		source_str = "EMAC2";
+		break;
+	case QM_THR_PROFILE_EMAC_3:
+		source_str = "EMAC3";
+		break;
+	case QM_THR_PROFILE_HMAC:
+		source_str = "HMAC";
+		break;
+	default:
+		source_str = "Unknown";
+	}
+	return source_str;
+}
+
+void qm_ql_profile_show(enum mv_qm_thr_profiles profile)
+{
+	enum mv_qm_thr_profiles q_profile;
+	struct ql_low_threshold		reg_low_threshold;
+	struct ql_pause_threshold	reg_pause_threshold;
+	struct ql_high_threshold	reg_high_threshold;
+	u32 reg_offset, reg_data;
+	int queue, count = 0;
+
+	reg_offset = qm_reg_offset.ql.low_threshold * profile;
+	qm_register_read(qm.ql.low_threshold, reg_offset, 1, (u32 *)&reg_low_threshold);
+
+	reg_offset = qm_reg_offset.ql.pause_threshold * profile;
+	qm_register_read(qm.ql.pause_threshold, reg_offset, 1, (u32 *)&reg_pause_threshold);
+
+	reg_offset = qm_reg_offset.ql.high_threshold * profile;
+	qm_register_read(qm.ql.high_threshold, reg_offset, 1, (u32 *)&reg_high_threshold);
+
+	reg_offset = qm_reg_offset.ql.traffic_source * profile;
+	qm_register_read(qm.ql.traffic_source, reg_offset, 1, &reg_data);
+
+	pr_info("\n-------------- QM QL profile %d -----------", profile);
+	pr_info("Low threshold [KB]      : %d\n", (reg_low_threshold.low_threshold * MV_PP3_QM_UNITS) / 1024);
+	pr_info("Pause threshold [KB]    : %d\n", (reg_pause_threshold.pause_threshold * MV_PP3_QM_UNITS) / 1024);
+	pr_info("High threshold [KB]     : %d\n", (reg_high_threshold.high_threshold * MV_PP3_QM_UNITS) / 1024);
+	pr_info("Traffic source          : %s (%d)\n", qm_ql_profile_source_str(reg_data), reg_data);
+
+	pr_info("Connected queues list   :\n");
+	for (queue = 0; queue < QM_QUEUES_NUM; queue++) {
+		qm_ql_q_profile_get(queue, &q_profile);
+
+		if (q_profile == (profile + 1)) {
+			pr_cont(" %3d", queue);
+			count++;
+
+			if ((count % 8) == 0)
+				pr_info("\n");
+		}
+	}
+
+	pr_info("\n");
+}
+
+/* global HW work around */
+static void qm_hw_internal_regs_set(void)
+{	u32 val;
+
+	/* DQF port 14 data fifo prameters registers use for global WA */
+	val = 0x200000;
+	qm_register_write(qm.dqf.base + 0x38, 0, 1, &val);
+
+	/* DQF port 15 data fifo prameters registers use for global WA */
+	val = 0x4030000;
+	qm_register_write(qm.dqf.base + 0x3C, 0, 1, &val);
+}
+
+
+/*
+ clear HW configuration
+	- disable all queues threshold profile
+	- disable all backpressure profiles
+	- disable drop prots
+	- dsconnect PPCs from all ports
+	- zeroed ports fifo parameters (depth = 0 and base = 0)
+	- clear ports credit threshold
+*/
+void qm_clear_hw_config(void)
+{
+	int i;
+	/*
+	 disable for all queues
+		1. threshold profiles
+		2. assign internal back pressure to group 0 - not in use
+	*/
+	for (i = 0; i < QM_QUEUES_NUM;  i++) {
+		qm_ql_q_profile_set(i, QM_THR_PROFILE_INVALID);
+		qm_ql_queue_bpi_group_set(i, QM_BP_INVALID_GROUP);
+	}
+
+	/* disable back pressure groups */
+	for (i = 0; i < QM_BPI_GROUPS; i++)
+		qm_ql_rule_bpi_disable(i);
+
+	/* clear mac ingress hw queue number to stop */
+	/* TODO - define MAC number */
+	for (i = 0; i < 7; i++) {
+		qm_xoff_emac_qnum_set(i, 0);
+		qm_tail_ptr_mode(i, false);
+	}
+
+	qm_xoff_hmac_qs_set(0, 0);
+
+	for (i = 0; i < QM_PORTS_NUM; i++) {
+		/* disable drop mode for all prots */
+		qm_port_drop_mode_set(i, false);
+
+		/* disconnect PPCs from ports */
+		qm_dqf_port_ppc_map_set(i, 0);
+
+		/* clear port dequeue fifo parameters */
+		qm_dqf_port_data_fifo_params_set(i, 0, 0);
+
+		/* clear port dequeue fifo credit threshold */
+		qm_dqf_port_credit_thr_set(i, 0);
+
+		/* clear port max credit request */
+		qm_port_max_credit_request_set(i, 0);
+	}
+
+	/* clear data fifo base */
+	mac_port_fifo_base = 0;
+	ppc_port_fifo_base = 0;
+}
+
+/*
+qm_port_default_set:
+	description: config port parameters
+		- drop ports
+		- dequeue fifo base and depth
+		- dequeue fifo credit threshold
+		- how many credits needed to start reading DRAM chunk
+*/
+
+static int qm_port_default_set(int port, enum mv_tm_source_type type)
+{
+	switch (type) {
+
+	case SOURCE_DROP:
+		/* DQF do not aware to ports 13-15.
+		   ports 13-15 registers used as NSS general debug registers */
+		qm_port_drop_mode_set(port, true);
+		break;
+	case SOURCE_PPC_DP:
+		qm_dqf_port_data_fifo_params_set(port, ppc_port_fifo_base, QM_PPC_DP_FIFO_DEPTH);
+		ppc_port_fifo_base += QM_PPC_DP_FIFO_DEPTH;
+		break;
+	case SOURCE_PPC_MNT:
+		qm_dqf_port_data_fifo_params_set(port, ppc_port_fifo_base, QM_PPC_MNT_FIFO_DEPTH);
+		ppc_port_fifo_base += QM_PPC_MNT_FIFO_DEPTH;
+		break;
+	case SOURCE_EMAC:
+		qm_dqf_port_data_fifo_params_set(port, mac_port_fifo_base, QM_EMAC_FIFO_DEPTH(port));
+		mac_port_fifo_base += QM_EMAC_FIFO_DEPTH(port);
+		qm_dqf_port_credit_thr_set(port, QM_EMAC_CREDIT_THR);
+		qm_port_max_credit_request_set(port, QM_EMAC_REQ_MAX_CREDIT(port));
+		break;
+	case SOURCE_CMAC:
+		qm_dqf_port_data_fifo_params_set(port, mac_port_fifo_base, QM_CMAC_FIFO_DEPTH(port));
+		mac_port_fifo_base += QM_CMAC_FIFO_DEPTH(port);
+		qm_dqf_port_credit_thr_set(port, QM_CMAC_CREDIT_THR(port));
+		qm_port_max_credit_request_set(port, QM_CMAC_REQ_MAX_CREDIT(port));
+		break;
+	case SOURCE_HMAC:
+		qm_dqf_port_data_fifo_params_set(port, mac_port_fifo_base, QM_HMAC_FIFO_DEPTH);
+		mac_port_fifo_base += QM_HMAC_FIFO_DEPTH;
+		qm_dqf_port_credit_thr_set(port, QM_HMAC_CREDIT_THR);
+		break;
+	default:
+		pr_err("%s: invalid port number %d\n", __func__, port);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int qm_ru_port_to_class_set(int port, int class, int sid_pool)
+{
+	u32 port2class_entry;
+
+	if (port > QM_INPUT_PORT_MAX) {
+		pr_err("%s: Invalid port number %d\n",  __func__, port);
+		return -EINVAL;
+	}
+
+	if (class > QM_CLASS_MAX) {
+		pr_err("%s: Invalid class number %d\n", __func__, class);
+		return -EINVAL;
+	}
+
+	if (sid_pool > QM_SID_POOL_MAX) {
+		pr_err("%s: Invalid pool number %d\n",  __func__, sid_pool);
+		return -EINVAL;
+	}
+
+	port2class_entry = class | (sid_pool << 6);
+	qm_register_write(qm.reorder.ru_port2class, port * 4, 4, &port2class_entry);
+	return 0;
+}
+
+/*
+ qm_ru_port_to_class_default_set
+	description: default port to class table configuration
+ -------------------------------------
+ |SOURCE | source port | class range |
+ -------------------------------------
+ | EMAC  |   0 - 5     |   0 - 5     |
+ -------------------------------------
+ | CMAC  |   6 - 7     |   6 - 7     |
+ -------------------------------------
+ | HMAC  |   8 - 71    |   8 - 15    |  Warp around every 8
+ -------------------------------------
+ | FW    |   72 - 119  |   16 - 63   |
+ -------------------------------------
+*/
+
+static int qm_ru_port_to_class_default_set(void)
+{
+	int port, class;
+
+	/* EMACs - one class per EMAC*/
+	class = 0;
+	for (port = 0; port < 6; port++) {
+		if (qm_ru_port_to_class_set(port, class, 0) < 0)
+			goto err;
+		class++;
+	}
+
+	/* OCMAC one class per direction */
+	class = 6;
+	for (port = 6; port < 8; port++) {
+		if (qm_ru_port_to_class_set(port, class, 0) < 0)
+			goto err;
+		class++;
+	}
+
+	class = 8;
+	for (port = 8; port < 72; port++) {
+		if (qm_ru_port_to_class_set(port, class + (port % 8), 0) < 0)
+			goto err;
+	}
+
+	class = 16;
+	for (port = 72; port < 120; port++) {
+		if (qm_ru_port_to_class_set(port, class, 0) < 0)
+			goto err;
+		class++;
+	}
+
+	return 0;
+err:
+	pr_err("%s: failed to config reorder unit\n", __func__);
+	return -1;
+}
+
+/*
+qm_default_set:
+	description: set defaults
+	parameters
+		ppc_num - number of active PPCs
+*/
+int qm_default_set(int ppc_num)
+{
+	int i, ports, port_id;
+	enum mv_tm_source_type type;
+
+	/* hw WA */
+	qm_hw_internal_regs_set();
+
+	/* secret machine enable*/
+	qm_xoff_to_macs_enable();
+
+	/* Enable tail pointer insertion in CMAC CFH*/
+	qm_tail_ptr_mode(QM_TAIL_PTR_CMAC_BIT, true);
+
+	/* mapping queue to port for QM drop recommendation */
+	for (i = 0; i < QM_QUEUES_NUM;  i++)
+		if (mv_tm_scheme_queue_path_get(i, NULL, NULL, NULL, &port_id) == 0)
+			qm_ql_queue_port_set(i, port_id);
+		else
+			pr_warn("%s: cannot get port id of q#%d from TM api\n", __func__, i);
+
+
+	/* config ports */
+	ports = mv_tm_scheme_ports_num();
+
+	for (i = 0; i < ports; i++) {
+		/* tm api return SOURCE_LAST for unused ports */
+		type = mv_tm_scheme_port_to_source(i, NULL);
+		if (type != SOURCE_LAST)
+			if (qm_port_default_set(i, type) < 0)
+				return -1;
+	}
+
+	/* Set all active PPCs to process packets from scheduler port 0 and 1 */
+	port_id = mv_tm_scheme_source_to_port(SOURCE_PPC_DP, 0);
+	qm_dqf_port_ppc_map_set(port_id, (1 << ppc_num) - 1);
+
+	port_id = mv_tm_scheme_source_to_port(SOURCE_PPC_DP, 1);
+	qm_dqf_port_ppc_map_set(port_id, (1 << ppc_num) - 1);
+
+	if (qm_ru_port_to_class_default_set() < 0)
+		return -1;
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
new file mode 100644
index 0000000..4bb2cd6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
@@ -0,0 +1,363 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef	__mv_qm_h__
+#define	__mv_qm_h__
+
+#include "platform/mv_pp3.h"
+#include "mv_qm_regs.h"
+
+enum mv_qm_node_type {
+	MV_QM_Q_NODE,
+	MV_QM_A_NODE,
+	MV_QM_B_NODE,
+	MV_QM_C_NODE,
+	MV_QM_PORT_NODE,
+	mv_QM_NODE_INVALID
+};
+
+enum mv_qm_thr_profiles {
+	QM_THR_PROFILE_EMAC_0 = 0,
+	QM_THR_PROFILE_EMAC_1,
+	QM_THR_PROFILE_EMAC_2,
+	QM_THR_PROFILE_EMAC_3,
+	QM_THR_PROFILE_UNUSED_1,
+	QM_THR_PROFILE_UNUSED_2,
+	QM_THR_PROFILE_HMAC,
+	QM_THR_PROFILE_INVALID,
+};
+
+enum mv_qm_ql_bp_status {
+	QM_BP_XON = 0,
+	QM_BP_PAUSE,
+	QM_BP_XOFF,
+	QM_BP_INVALID,
+};
+
+/* QM debug flags */
+#define QM_F_DBG_RD_BIT			0
+#define QM_F_DBG_WR_BIT			1
+
+#define QM_F_DBG_RD			(1 << QM_F_DBG_RD_BIT)
+#define QM_F_DBG_WR			(1 << QM_F_DBG_WR_BIT)
+
+#define QM_QUEUES_NUM			512
+#define QM_BPI_GROUPS			64
+#define QM_PORTS_NUM			16
+#define QM_BP_INVALID_GROUP		0 /* assign all queues to group 0 in default init */
+
+/* fifo depth - set port dequeue fifo size */
+#define QM_PPC_DP_FIFO_DEPTH		(0x2 * QM_DQF_PPC_ROW_SIZE)
+#define QM_PPC_MNT_FIFO_DEPTH		(0x1 * QM_DQF_PPC_ROW_SIZE)
+#define QM_EMAC_10G_FIFO_DEPTH		(0x29A * QM_DQF_MAC_ROW_SIZE)
+#define QM_EMAC_1G_FIFO_DEPTH		(0x359 * QM_DQF_MAC_ROW_SIZE)
+#define QM_CMAC_IN_FIFO_DEPTH		(0x29A * QM_DQF_MAC_ROW_SIZE)
+#define QM_CMAC_LA_FIFO_DEPTH		(0x80 * QM_DQF_MAC_ROW_SIZE)
+#define QM_HMAC_FIFO_DEPTH		(0x40 * QM_DQF_MAC_ROW_SIZE)
+
+#define QM_EMAC_FIFO_DEPTH(_port_)	((_port_ == 4) ? QM_EMAC_10G_FIFO_DEPTH : QM_EMAC_1G_FIFO_DEPTH)
+#define QM_CMAC_FIFO_DEPTH(_port_)	((_port_ == 10) ? QM_CMAC_IN_FIFO_DEPTH : QM_CMAC_LA_FIFO_DEPTH)
+
+/* credit threshold - relevant for MAC ports only, set when DQF sends indication to the MAC */
+#define QM_EMAC_CREDIT_THR		(0x282 * QM_DQF_MAC_ROW_SIZE)
+#define QM_CMAC_IN_CREDIT_THR		(0x268 * QM_DQF_MAC_ROW_SIZE)
+#define QM_CMAC_LA_CREDIT_THR		(0x68 * QM_DQF_MAC_ROW_SIZE)
+#define QM_HMAC_CREDIT_THR		(0x28 * QM_DQF_MAC_ROW_SIZE)
+#define QM_CMAC_CREDIT_THR(_port_)	\
+			((_port_ == 10) ? QM_CMAC_IN_CREDIT_THR : QM_CMAC_LA_CREDIT_THR)
+
+/* max credit - How many credits needed to start reading DRAM chunk */
+#define QM_EMAC_10G_REQ_MAX_CREDIT	(0x7d0)  /* 2000 */
+#define QM_EMAC_1G_REQ_MAX_CREDIT	(0x2648) /* 9800 */
+#define QM_CMAC_IN_REQ_MAX_CREDIT	(0x7d0)  /* 2000 */
+
+#define QM_EMAC_REQ_MAX_CREDIT(_port_)	\
+			((_port_ == 4) ? QM_EMAC_10G_REQ_MAX_CREDIT : QM_EMAC_1G_REQ_MAX_CREDIT)
+#define QM_CMAC_REQ_MAX_CREDIT(_port_)	\
+			((_port_ == 10) ? QM_CMAC_IN_REQ_MAX_CREDIT : 0)
+
+/* Default pools thresholds */
+#define QM_POOL_THR_LOW				0x0000000C
+#define QM_POOL_THR_HIGH			0x00000018
+
+
+/* read/write attributes defenitions */
+#define QM_SWF_AWQOS_DEF			0x00000001
+#define QM_RDMA_AWQOS_DEF			0x00000001
+#define QM_HWF_QE_CE_AWQOS_DEF			0x00000001
+#define QM_HWF_SFH_PL_AWQOS_DEF			0x00000001
+
+#define QM_SWF_AWCACHE_DEF			0x0000000B
+#define QM_RDMA_AWCACHE_DEF			0x0000000B
+#define QM_HWF_QE_CE_AWCACHE_DEF		0x00000003
+#define QM_HWF_SFH_PL_AWCACHE_DEF		0x00000003
+
+#define QM_SWF_AWDOMAIN_DEF			0x00000002
+#define QM_RDMA_AWDOMAIN_DEF			0x00000002
+#define QM_HWF_QE_CE_AWDOMAIN_DEF	        0
+#define QM_HWF_SFH_PL_AWDOMAIN_DEF	        0
+
+#define QM_SWF_ARQOS_DEF			0x00000001
+#define QM_RDMA_ARQOS_DEF			0x00000001
+#define QM_HWF_QE_CE_ARQOS_DEF			0x00000001
+#define QM_HWF_SFH_PL_ARQOS_DEF			0x00000001
+
+#define QM_SWF_ARCACHE_DEF			0x0000000B
+#define QM_RDMA_ARCACHE_DEF			0x0000000B
+#define QM_HWF_QE_CE_ARCACHE_DEF		0x00000003
+#define QM_HWF_SFH_PL_ARCACHE_DEF		0x00000003
+
+#define QM_SWF_ARDOMAIN_DEF			0x00000002
+#define QM_RDMA_ARDOMAIN_DEF			0x00000002
+#define QM_HWF_QE_CE_ARDOMAIN_DEF		0
+#define QM_HWF_SFH_PL_ARDOMAIN_DEF		0
+
+/* all SIDs are allocated by pool 0 */
+#define QM_POOL0_SID_NUM	QM_SID_MAX
+#define QM_POOL1_SID_NUM	0x0
+
+/* reorder unit defenitions */
+#define QM_SID_MAX				0x00001000
+#define QM_VMID_MAX				0x0000003F
+#define QM_CLASS_MAX				0x0000003F
+#define QM_SID_POOL_MAX				0x00000001
+#define QM_INPUT_PORT_MAX			0x0000011F
+#define QM_ATTR_DOMAIN_MAX			0x00000003
+#define QM_ATTR_CACHE_MAX			0x0000000F
+#define QM_ATTR_QOS_MAX				0x00000003
+
+/* Init registers alias structures */
+void qm_init(void __iomem *base);
+
+/* Enable/Disable QM registers read and write dumps */
+void qm_dbg_flags(u32 flag, u32 en);
+
+/* Enable/disable tail pointer insertion in the CFH, per EMAC source */
+void qm_tail_ptr_mode(int emac, bool enable);
+
+/**
+ *  Set base address in Dram for pool
+ *
+ */
+void qm_pfe_base_address_pool_set(struct mv_a40 *pl_base_address, /* Payload DRAM base address */
+				  struct mv_a40 *qece_base_address); /* QE/CE DRAM base address */
+
+/**
+ *  Enables QM,
+ *  Configure DMA with GPM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+void qm_dma_gpm_pools_def_enable(void);
+
+/**
+ *  Configure DMA with DRAM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+void qm_dma_dram_pools_def_enable(void);
+
+/**
+ *  Set default for QM units for mandatory parameters
+ *  Inputs:
+ *      ppc_num - number of active PPCs
+ *  Return values:
+ *		0 - success
+ */
+int qm_default_set(int ppc_num);
+
+/*
+ clear HW configuration
+	- disable all queues threshold profile
+	- disable all internal back pressure groups
+	- disable drop prots
+	- dsconnect PPCs from all ports
+	- zeroed ports fifo parameters (depth = 0 and base = 0)
+	- clear ports credit threshold
+*/
+
+void qm_clear_hw_config(void);
+
+/**
+ *  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+ *  relevant only for PPC port with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_ppc_map_def_set(void);
+
+/**
+ *  Configures QL thresholds
+ *  parameters:
+ *    profie           - profile number
+ *    low, pause, high - thresholds in KB
+ *  Return values:
+ *		0 - success
+ */
+
+void qm_ql_profile_cfg(enum mv_qm_thr_profiles profile, u32 low, u32 pause, u32 high);
+
+int qm_ql_group_bpi_set(int group, int xon_thr, int xoff_thr,
+				enum mv_qm_node_type level, int node_id);
+int qm_ql_group_bpi_get(int group, int *xon_thr, int *xoff_thr,
+				enum mv_qm_node_type *level, int *node_id);
+
+void qm_ql_group_bpi_show(int group);
+void qm_ql_group_bpi_show_all(void);
+
+int qm_ql_queue_bpi_group_set(int queue, int group);
+
+/**
+ *  Configre PFE to start Flushing Queue. This process takes a while.
+ *  Indication for its completion is when Queue is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_queue_flush_start(int queue); /* queue number from 0 to 511 */
+
+/**
+ *  Configre PFE to start Flushing Port. This process takes a while.
+ *  Indication for its completion is when Port is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_port_flush_start(int port);
+
+/**
+ *  Gives queue length and status
+ *  Return values:
+ *		0 - success
+ */
+int qm_queue_len_get(int queue, u32 *length, u32 *status);
+
+/**
+ *  Get Idle status from DMA
+*/
+void qm_idle_status_get(u32 *status);
+
+/**
+ * Configure REORDER with class command when permission is granted.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_class_cmd_set(u32 host, u32 host_class, u32 host_sid, u32 cmd);
+/*
+ *  Check error bits.
+ *  If set to 1, and print the error that occurred.
+ *  Bit 0 is always an OR of all the other errors.
+ *  So bit 0 with value 0 indicates there are no errors.
+ *  Return values:
+ *		0 - success
+*/
+void qm_errors_dump(void);
+
+/*
+ *  Print all global registers
+*/
+void qm_global_dump(void);
+
+/*
+ *  Print registers per queues 0 to 511
+*/
+void qm_queue_dump(int queue);
+
+
+/*
+ * Print for the queues that are not empty the following.
+ * Run on all queues from 0 to 511.
+ * For each queue print hw length indications if qlen, qlen_bp or  qlen_drop are not 0.
+*/
+void qm_nempty_queue_len_dump(void);
+
+/*
+ * Print dqf port parameters:
+ *  Return values:
+ *		0 - success
+*/
+void qm_dqf_port_dump(int port);
+
+
+/* Set emac ingress queue for secret machine
+ * inputs
+ *      emac - emac number
+ *      queue - queue number to stop
+*/
+
+void qm_xoff_emac_qnum_set(int emac, int queue);
+
+/* Set hmac ingress queues range for secret machine
+ * inputs
+ *      first_q - first queue to stop
+ *      q_num   - number of queues to stop
+*/
+
+void qm_xoff_hmac_qs_set(int first_q, int q_num);
+
+/* Set emac threshold profile to default values
+ * inputs
+ *      emac - emac number
+ *      queue - attached queue to profile
+*/
+int qm_emac_profile_set(int emac, enum mv_port_mode port_mode, int queue);
+
+/* Set hmac threshold profile to default values
+ * inputs
+ *      parameters define queues range to attached to hmac profile
+ *      first_q - hmac->ppc first queue
+ *      q_num   - hmac->ppc queues number
+*/
+
+int qm_hmac_profile_set(int first_q, int q_num);
+
+/*
+ * Config internal back pressure group
+ * Parameters:
+ *  group - group number
+ *  xon_thr, xoff_thr - low / high thresholds in KB
+ *  level - node type (A/B/C)
+ *  node_id - node number
+*/
+
+int qm_ql_group_bpi_set(int group, int xon_thr, int xoff_thr,
+				enum mv_qm_node_type level, int node_id);
+
+/*
+ *  Mapping qm queue to internal back pressure group
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_queue_bpi_group_set(int queue, int group);
+
+/*
+ * QM sysfs functions
+ */
+int mv_pp3_qm_sysfs_init(struct kobject *neta_kobj);
+int mv_pp3_qm_sysfs_exit(struct kobject *emac_kobj);
+void qm_ql_profile_show(enum mv_qm_thr_profiles profile);
+const char *mv_qm_node_str(enum mv_qm_node_type level);
+
+#endif /* __mv_qm_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
new file mode 100644
index 0000000..3f199cb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
@@ -0,0 +1,412 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+/* includes */
+#include "common/mv_sw_if.h"
+#include "qm/mv_qm_regs.h"
+
+struct qm_alias qm;
+struct qm_alias qm_reg_size;
+struct qm_alias qm_reg_offset;
+
+void qm_reg_address_alias_init(u32 siliconBase)
+{
+	qm.ql.base      = siliconBase +      QL_UNIT_OFFSET;	/*0x00400000*/
+	qm.pfe.base     = siliconBase +     PFE_UNIT_OFFSET;	/*0x00410000*/
+	qm.dqf.base     = siliconBase +     DQF_UNIT_OFFSET;	/*0x00420000*/
+	qm.dma.base     = siliconBase +     DMA_UNIT_OFFSET;	/*0x00430000*/
+	qm.reorder.base = siliconBase + REORDER_UNIT_OFFSET;	/*0x00500000*/
+
+	/* QL registers addresses */
+	qm.ql.qptr                 = qm.ql.base + 0x00000000;
+	qm.ql.qmap_port            = qm.ql.base + 0x00008000;
+	qm.ql.qmap_group           = qm.ql.base + 0x00009000;
+	qm.ql.rule_bpi             = qm.ql.base + 0x0000A000;
+	qm.ql.low_threshold        = qm.ql.base + 0x00000400;
+	qm.ql.pause_threshold      = qm.ql.base + 0x00000404;
+	qm.ql.high_threshold       = qm.ql.base + 0x00000408;
+	qm.ql.traffic_source       = qm.ql.base + 0x0000040C;
+	qm.ql.ECC_error_cause      = qm.ql.base + 0x00000500;
+	qm.ql.ECC_error_mask       = qm.ql.base + 0x00000504;
+	qm.ql.Internal_error_cause = qm.ql.base + 0x00000508;
+	qm.ql.internal_error_mask  = qm.ql.base + 0x0000050C;
+	qm.ql.nss_general_purpose  = qm.ql.base + 0x00001000;
+	qm.ql.qlen                 = qm.ql.base + 0x00002000;
+	qm.ql.bp_qlen              = qm.ql.base + 0x00004000;
+	qm.ql.drop_qlen            = qm.ql.base + 0x00006000;
+	qm.ql.xoff_when_bm_empty_en = qm.ql.base + 0x0000600;
+	qm.ql.xoff_mac_qnum        = qm.ql.base + 0x0000604;
+	qm.ql.xoff_hmac_qs         = qm.ql.base + 0x0000620;
+
+
+	/* PFE registers addresses */
+	qm.pfe.qece_dram_base_address_hi         = qm.pfe.base + 0x00000000;
+	qm.pfe.pyld_dram_base_address_hi         = qm.pfe.base + 0x00000004;
+	qm.pfe.qece_dram_base_address_lo         = qm.pfe.base + 0x00000008;
+	qm.pfe.pyld_dram_base_address_lo         = qm.pfe.base + 0x0000000C;
+	qm.pfe.QM_VMID                           = qm.pfe.base + 0x00000010;
+	qm.pfe.port_flush                        = qm.pfe.base + 0x0000001C;
+	qm.pfe.AXI_read_attributes_for_swf_mode  = qm.pfe.base + 0x00000030;
+	qm.pfe.AXI_read_attributes_for_rdma_mode = qm.pfe.base + 0x00000034;
+	qm.pfe.AXI_read_attributes_for_hwf_qece  = qm.pfe.base + 0x00000038;
+	qm.pfe.AXI_read_attributes_for_hwf_pyld  = qm.pfe.base + 0x0000003C;
+	qm.pfe.max_credit_for_new_dram_req       = qm.pfe.base + 0x00000050;
+	qm.pfe.ecc_error_cause                   = qm.pfe.base + 0x00000100;
+	qm.pfe.ecc_error_mask                    = qm.pfe.base + 0x00000104;
+	qm.pfe.internal_error_cause              = qm.pfe.base + 0x00000108;
+	qm.pfe.internal_error_mask               = qm.pfe.base + 0x0000010C;
+	qm.pfe.idle_status                       = qm.pfe.base + 0x00000110;
+	qm.pfe.queue_flush                       = qm.pfe.base + 0x00000400;
+	qm.pfe.queue_qece                        = qm.pfe.base + 0x00008000;
+
+	/* DQF registers addresses */
+	qm.dqf.Data_FIFO_params_p               = qm.dqf.base + 0x00000000;
+	qm.dqf.Credit_Threshold_p               = qm.dqf.base + 0x00000040;
+	qm.dqf.PPC_port_map_p                   = qm.dqf.base + 0x00000080;
+	qm.dqf.data_fifo_pointers_p             = qm.dqf.base + 0x000000C0;
+	qm.dqf.dqf_itnr_cause                   = qm.dqf.base + 0x00000100;
+	qm.dqf.dqf_itnr_mask                    = qm.dqf.base + 0x00000104;
+	qm.dqf.misc_error_intr_cause            = qm.dqf.base + 0x00000108;
+	qm.dqf.misc_error_intr_mask             = qm.dqf.base + 0x00000104;
+	qm.dqf.dqf_ser_summary_intr_cause       = qm.dqf.base + 0x00000110;
+	qm.dqf.dqf_ser_summary_intr_mask        = qm.dqf.base + 0x00000114;
+	qm.dqf.write_to_full_error_intr_cause   = qm.dqf.base + 0x00000118;
+	qm.dqf.write_to_full_error_intr_mask    = qm.dqf.base + 0x0000011C;
+	qm.dqf.read_from_empty_error_intr_cause = qm.dqf.base + 0x00000120;
+	qm.dqf.read_from_empty_error_intr_mask  = qm.dqf.base + 0x00000124;
+	qm.dqf.wrong_axi_rd_error_intr_cause    = qm.dqf.base + 0x00000128;
+	qm.dqf.wrong_axi_rd_error_intr_mask     = qm.dqf.base + 0x0000012C;
+	qm.dqf.mg2mem_req_addr_ctrl             = qm.dqf.base + 0x00000130;
+	qm.dqf.mem2mg_resp_status               = qm.dqf.base + 0x00000134;
+	qm.dqf.mem2mg_resp_data_hh              = qm.dqf.base + 0x00000138;
+	qm.dqf.mem2mg_resp_data_hl              = qm.dqf.base + 0x0000013C;
+	qm.dqf.mem2mg_resp_data_lh              = qm.dqf.base + 0x00000140;
+	qm.dqf.mem2mg_resp_data_ll              = qm.dqf.base + 0x00000144;
+	qm.dqf.dqf_macs_l3_res                  = qm.dqf.base + 0x00001000;
+	qm.dqf.dqf_macs_l4_res                  = qm.dqf.base + 0x00001400;
+	qm.dqf.dqf_macs_l3_ptr                  = qm.dqf.base + 0x00001800;
+	qm.dqf.dqf_macs_l4_ptr                  = qm.dqf.base + 0x00001C00;
+	qm.dqf.dqf_macs_desc                    = qm.dqf.base + 0x00002000;
+
+	/* DMA registers addresses */
+	qm.dma.Q_memory_allocation                = qm.dma.base + 0x00000000;
+	qm.dma.gpm_thresholds                     = qm.dma.base + 0x00000050;
+	qm.dma.dram_thresholds                    = qm.dma.base + 0x00000054;
+	qm.dma.AXI_write_attributes_for_swf_mode  = qm.dma.base + 0x00000060;
+	qm.dma.AXI_write_attributes_for_rdma_mode = qm.dma.base + 0x00000064;
+	qm.dma.AXI_write_attributes_for_hwf_qece  = qm.dma.base + 0x00000068;
+	qm.dma.AXI_write_attributes_for_hwf_pyld  = qm.dma.base + 0x0000006C;
+	qm.dma.DRAM_VMID                          = qm.dma.base + 0x00000070;
+	qm.dma.tail_pointer_en			  = qm.dma.base + 0x0000007C;
+	qm.dma.idle_status                        = qm.dma.base + 0x00000080;
+	qm.dma.ecc_error_cause                    = qm.dma.base + 0x00000100;
+	qm.dma.ecc_error_mask                     = qm.dma.base + 0x00000104;
+	qm.dma.internal_error_cause               = qm.dma.base + 0x00000108;
+	qm.dma.internal_error_mask                = qm.dma.base + 0x0000010C;
+	qm.dma.ceram_mac                          = qm.dma.base + 0x00000800;
+	qm.dma.ceram_ppe                          = qm.dma.base + 0x00001000;
+	qm.dma.qeram                              = qm.dma.base + 0x00001800;
+	qm.dma.dram_fifo                          = qm.dma.base + 0x00002000;
+
+	/* REORDER registers addresses */
+	qm.reorder.ru_qe              = qm.reorder.base + 0x00000000;
+	qm.reorder.ru_class           = qm.reorder.base + 0x00020000;
+	qm.reorder.ru_tasks           = qm.reorder.base + 0x00028000;
+	qm.reorder.ru_ptr2next        = qm.reorder.base + 0x00030000;
+	qm.reorder.ru_sid_fifo        = qm.reorder.base + 0x00038000;
+	qm.reorder.ru_port2class      = qm.reorder.base + 0x00040000;
+	qm.reorder.ru_pool            = qm.reorder.base + 0x00090000;
+	qm.reorder.ru_class_head      = qm.reorder.base + 0x00090100;
+	qm.reorder.ru_ser_error_cause = qm.reorder.base + 0x00090500;
+	qm.reorder.ru_ser_error_mask  = qm.reorder.base + 0x00090504;
+	qm.reorder.ru_host_cmd        = qm.reorder.base + 0x00090580;
+	qm.reorder.ru_task_permission = qm.reorder.base + 0x00090584;
+}
+
+void qm_reg_size_alias_init(void)
+{
+	u32 word_size_in_bits, byte_size_in_bits = 8;
+
+	word_size_in_bits = 32/byte_size_in_bits;	/* word_size_in_bits = 4 */
+
+	/* QL registers sizes */
+	qm_reg_size.ql.qptr                 = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.qmap_port            = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.qmap_group           = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.rule_bpi             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.low_threshold        = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.pause_threshold      = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.high_threshold       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.traffic_source       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.ECC_error_cause      = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.ECC_error_mask       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.Internal_error_cause = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.internal_error_mask  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.nss_general_purpose  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.qlen                 = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.bp_qlen               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.drop_qlen             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.xoff_hmac_qs         = 32/byte_size_in_bits/word_size_in_bits;
+	/* PFE registers sizes */
+	qm_reg_size.pfe.qece_dram_base_address_hi         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.pyld_dram_base_address_hi         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.qece_dram_base_address_lo         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.pyld_dram_base_address_lo         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.QM_VMID                           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.port_flush                        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_swf_mode  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.ecc_error_cause                   =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.ecc_error_mask                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.internal_error_cause              =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.internal_error_mask               =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.idle_status                       =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.queue_flush                       =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.queue_qece                        = 128/byte_size_in_bits/word_size_in_bits;
+
+	/* DQF registers sizes */
+	qm_reg_size.dqf.Data_FIFO_params_p               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.Credit_Threshold_p               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.PPC_port_map_p                   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.data_fifo_pointers_p             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_itnr_cause                   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_itnr_mask                    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.misc_error_intr_cause            = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.misc_error_intr_mask             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_ser_summary_intr_cause       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_ser_summary_intr_mask        = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.write_to_full_error_intr_cause   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.write_to_full_error_intr_mask    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.read_from_empty_error_intr_cause = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.read_from_empty_error_intr_mask  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.wrong_axi_rd_error_intr_cause    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.wrong_axi_rd_error_intr_mask     = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mg2mem_req_addr_ctrl             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_status               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_hh              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_hl              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_lh              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_ll              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l3_res                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l4_res                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l3_ptr                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l4_ptr                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_desc                    = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* DMA registers addresses */
+	qm_reg_size.dma.Q_memory_allocation                =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.gpm_thresholds                     =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.dram_thresholds                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_swf_mode  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_rdma_mode =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_hwf_qece  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.DRAM_VMID                          =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.idle_status                        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ecc_error_cause                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ecc_error_mask                     =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.internal_error_cause               =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.internal_error_mask                =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ceram_mac                          =  96/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ceram_ppe                          = 160/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.qeram                              =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.dram_fifo                          = 160/byte_size_in_bits/word_size_in_bits;
+
+	/* SCHED registers addresses */
+	qm_reg_size.sched.ErrStus			               = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* DROP registers addresses */
+	qm_reg_size.drop.DrpErrStus                            = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpFirstExc                           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpErrCnt                             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpExcCnt                             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpExcMask                            = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpId                                 = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpForceErr                           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.WREDDropProbMode                      = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.WREDMaxProbModePerColor               = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DPSource                              = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.RespLocalDPSel                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.Drp_Decision_to_Query_debug           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.Drp_Decision_hierarchy_to_Query_debug = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.TMtoTMPktGenQuantum                   = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.TMtoTMDPCoSSel                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.AgingUpdEnable                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.PortInstAndAvgQueueLength             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpEccConfig                          = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpEccMemParams                       = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* REORDER registers addresses */
+	qm_reg_size.reorder.ru_qe              = 256/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_class           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_tasks           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ptr2next        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_sid_fifo        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_port2class      =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_pool            =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_class_head      =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ser_error_cause =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ser_error_mask  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_host_cmd        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_task_permission =  32/byte_size_in_bits/word_size_in_bits;
+}
+
+void qm_reg_offset_alias_init(void)
+{
+
+	/*memset(qm_reg_offset,0,sizeof(*qm_reg_offset));*/
+	/* QL registers sizes */
+	qm_reg_offset.ql.qptr                 =  4;
+	qm_reg_offset.ql.qmap_port            =  4;
+	qm_reg_offset.ql.qmap_group           =  4;
+	qm_reg_offset.ql.rule_bpi             =  8;
+	qm_reg_offset.ql.low_threshold        = 16;
+	qm_reg_offset.ql.pause_threshold      = 16;
+	qm_reg_offset.ql.high_threshold       = 16;
+	qm_reg_offset.ql.traffic_source       = 16;
+	qm_reg_offset.ql.ECC_error_cause      =  4;
+	qm_reg_offset.ql.ECC_error_mask       =  4;
+	qm_reg_offset.ql.Internal_error_cause =  4;
+	qm_reg_offset.ql.internal_error_mask  =  4;
+	qm_reg_offset.ql.nss_general_purpose  =  4;
+	qm_reg_offset.ql.qlen                 =  4;
+	qm_reg_offset.ql.bp_qlen              =  4;
+	qm_reg_offset.ql.drop_qlen            =  4;
+
+	/* PFE registers sizes */
+	qm_reg_offset.pfe.qece_dram_base_address_hi         =   4;
+	qm_reg_offset.pfe.pyld_dram_base_address_hi         =   4;
+	qm_reg_offset.pfe.qece_dram_base_address_lo         =   4;
+	qm_reg_offset.pfe.pyld_dram_base_address_lo         =   4;
+	qm_reg_offset.pfe.QM_VMID                           =   4;
+	qm_reg_offset.pfe.port_flush                        =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode  =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece  =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld  =   4;
+	qm_reg_offset.pfe.ecc_error_cause                   =   4;
+	qm_reg_offset.pfe.ecc_error_mask                    =   4;
+	qm_reg_offset.pfe.internal_error_cause              =   4;
+	qm_reg_offset.pfe.internal_error_mask               =   4;
+	qm_reg_offset.pfe.idle_status                       =   4;
+	qm_reg_offset.pfe.queue_flush                       =   4;
+	qm_reg_offset.pfe.queue_qece                        =  16;
+
+	/* DQF registers sizes */
+	qm_reg_offset.dqf.Data_FIFO_params_p               = 4;
+	qm_reg_offset.dqf.Credit_Threshold_p	           = 4;
+	qm_reg_offset.dqf.PPC_port_map_p                   = 4;
+	qm_reg_offset.dqf.data_fifo_pointers_p             = 4;
+	qm_reg_offset.dqf.dqf_itnr_cause                   = 4;
+	qm_reg_offset.dqf.dqf_itnr_mask                    = 4;
+	qm_reg_offset.dqf.misc_error_intr_cause            = 4;
+	qm_reg_offset.dqf.misc_error_intr_mask             = 4;
+	qm_reg_offset.dqf.dqf_ser_summary_intr_cause       = 4;
+	qm_reg_offset.dqf.dqf_ser_summary_intr_mask        = 4;
+	qm_reg_offset.dqf.write_to_full_error_intr_cause   = 4;
+	qm_reg_offset.dqf.write_to_full_error_intr_mask    = 4;
+	qm_reg_offset.dqf.read_from_empty_error_intr_cause = 4;
+	qm_reg_offset.dqf.read_from_empty_error_intr_mask  = 4;
+	qm_reg_offset.dqf.wrong_axi_rd_error_intr_cause    = 4;
+	qm_reg_offset.dqf.wrong_axi_rd_error_intr_mask     = 4;
+	qm_reg_offset.dqf.mg2mem_req_addr_ctrl             = 4;
+	qm_reg_offset.dqf.mem2mg_resp_status               = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_hh              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_hl              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_lh              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_ll              = 4;
+	qm_reg_offset.dqf.dqf_macs_l3_res                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l4_res                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l3_ptr                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l4_ptr                  = 4;
+	qm_reg_offset.dqf.dqf_macs_desc                    = 4;
+
+	/* DMA registers addresses */
+	qm_reg_offset.dma.Q_memory_allocation                =  4;
+	qm_reg_offset.dma.gpm_thresholds                     =  4;
+	qm_reg_offset.dma.dram_thresholds                    =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_swf_mode  =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece  =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld  =  4;
+	qm_reg_offset.dma.DRAM_VMID                          =  4;
+	qm_reg_offset.dma.idle_status                        =  4;
+	qm_reg_offset.dma.ecc_error_cause                    =  4;
+	qm_reg_offset.dma.ecc_error_mask                     =  4;
+	qm_reg_offset.dma.internal_error_cause               =  4;
+	qm_reg_offset.dma.internal_error_mask                =  4;
+	qm_reg_offset.dma.ceram_mac                          = 16;
+	qm_reg_offset.dma.ceram_ppe                          = 32;
+	qm_reg_offset.dma.qeram                              =  4;
+/*#warning MY_WARNING: Register qm_reg_offset.dma.dram_fifo is not defined in CIDER properly.*/
+	qm_reg_offset.dma.dram_fifo                          = 32;
+
+	/* SCHED registers addresses */
+	qm_reg_offset.sched.ErrStus                = 8;
+
+	/* DROP registers addresses */
+	qm_reg_offset.drop.DrpErrStus                            = 8;
+	qm_reg_offset.drop.DrpFirstExc                           = 8;
+	qm_reg_offset.drop.DrpErrCnt                             = 8;
+	qm_reg_offset.drop.DrpExcCnt                             = 8;
+	qm_reg_offset.drop.DrpExcMask                            = 8;
+	qm_reg_offset.drop.DrpId                                 = 8;
+	qm_reg_offset.drop.DrpForceErr                           = 8;
+	qm_reg_offset.drop.WREDDropProbMode                      = 8;
+	qm_reg_offset.drop.WREDMaxProbModePerColor               = 8;
+	qm_reg_offset.drop.DPSource                              = 8;
+	qm_reg_offset.drop.RespLocalDPSel                        = 8;
+	qm_reg_offset.drop.Drp_Decision_to_Query_debug           = 8;
+
+	qm_reg_offset.drop.Drp_Decision_hierarchy_to_Query_debug = 8;
+	qm_reg_offset.drop.TMtoTMPktGenQuantum                   = 8;
+	qm_reg_offset.drop.TMtoTMDPCoSSel                        = 8;
+	qm_reg_offset.drop.AgingUpdEnable                        = 8;
+	qm_reg_offset.drop.PortInstAndAvgQueueLength             = 8;
+	qm_reg_offset.drop.DrpEccConfig                          = 8;
+	qm_reg_offset.drop.DrpEccMemParams                       = 8;
+
+	/* REORDER registers addresses */
+	qm_reg_offset.reorder.ru_qe              = 32;
+	qm_reg_offset.reorder.ru_class           =  4;
+	qm_reg_offset.reorder.ru_tasks           =  4;
+	qm_reg_offset.reorder.ru_ptr2next        =  4;
+	qm_reg_offset.reorder.ru_sid_fifo        =  4;
+	qm_reg_offset.reorder.ru_port2class      =  4;
+	qm_reg_offset.reorder.ru_pool            =  4;
+	qm_reg_offset.reorder.ru_class_head      =  4;
+	qm_reg_offset.reorder.ru_ser_error_cause =  4;
+	qm_reg_offset.reorder.ru_ser_error_mask  =  4;
+	qm_reg_offset.reorder.ru_host_cmd        =  8;
+	qm_reg_offset.reorder.ru_task_permission =  8;
+}
+
+
+#ifdef MY_HIDE
+#endif /* MY_HIDE */
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h
new file mode 100644
index 0000000..06738f8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h
@@ -0,0 +1,958 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef	__mv_qm_regs_h__
+#define	__mv_qm_regs_h__
+
+#include "qm/mv_qm.h"
+
+#define      QL_UNIT_OFFSET 0x00400000
+#define     PFE_UNIT_OFFSET 0x00410000
+#define     DQF_UNIT_OFFSET 0x00420000
+#define     DMA_UNIT_OFFSET 0x00430000
+#define REORDER_UNIT_OFFSET 0x00500000
+#define     GPM_UNIT_OFFSET 0x00600000
+
+
+/* --------------------------------------- */
+/*     registers global defenitions        */
+/* --------------------------------------- */
+
+/* DQF row size in bytes*/
+#define QM_DQF_PPC_ROW_SIZE		144
+#define QM_DQF_MAC_ROW_SIZE		16
+
+/* DMA degenitions */
+#define QM_TAIL_PTR_CMAC_BIT		0x6
+
+/* DMA */
+struct dma_q_memory_allocation {
+	int q_memory:32;					/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_gpm_thresholds {
+	int gpm_pl_pool_low_bp:6;			/* byte[ 0- 3] ,bit[ 0- 5] */
+	int _reserved_1:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int gpm_pl_pool_high_bp:6;			/* byte[ 0- 3] ,bit[ 8-13] */
+	int _reserved_2:2;					/* byte[ 0- 3] ,bit[14-15] */
+	int gpm_qe_pool_low_bp:6;			/* byte[ 0- 3] ,bit[16-21] */
+	int _reserved_3:2;					/* byte[ 0- 3] ,bit[22-23] */
+	int gpm_qe_pool_high_bp:6;			/* byte[ 0- 3] ,bit[24-29] */
+	int _reserved_4:2;					/* byte[ 0- 3] ,bit[30-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_dram_thresholds {
+	int dram_pl_pool_low_bp:6;			/* byte[ 0- 3] ,bit[ 0- 5] */
+	int _reserved_1:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int dram_pl_pool_high_bp:6;			/* byte[ 0- 3] ,bit[ 8-13] */
+	int _reserved_2:2;					/* byte[ 0- 3] ,bit[14-15] */
+	int dram_qe_pool_low_bp:6;			/* byte[ 0- 3] ,bit[16-21] */
+	int _reserved_3:2;					/* byte[ 0- 3] ,bit[22-23] */
+	int dram_qe_pool_high_bp:6;			/* byte[ 0- 3] ,bit[24-29] */
+	int _reserved_4:2;					/* byte[ 0- 3] ,bit[30-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_swf_mode {
+	int swf_awdomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int swf_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int swf_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_rdma_mode {
+	int rdma_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int rdma_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int rdma_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_hwf_qece {
+	int qece_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int qece_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int qece_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_hwf_pyld {
+	int pyld_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int pyld_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int pyld_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_DRAM_VMID {
+	int dram_vmid:8;					/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_idle_status {
+	int gpm_pl_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int gpm_pl_cache_is_full:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int gpm_qe_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_qe_cache_is_full:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int dram_pl_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dram_pl_cache_is_full:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_qe_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dram_qe_cache_is_full:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int dram_fifo_is_empty:1;				/* byte[ 0- 3] ,bit[ 8- 8] */
+	int mac_axi_enq_channel_is_empty:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int NSS_axi_enq_channel_is_empty:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int gpm_ppe_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int ppe_gpm_pl_write_fifo_is_empty:1;	/* byte[ 0- 3] ,bit[12-12] */
+	int ppe_gpm_qe_write_fifo_is_empty:1;	/* byte[ 0- 3] ,bit[13-13] */
+	int ppe_ru_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int ppe_ru_write_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int ru_ppe_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int dram_fifo_fsm_state_is_idle:1;		/* byte[ 0- 3] ,bit[17-17] */
+	int qeram_init_fsm_state_is_idle:1;		/* byte[ 0- 3] ,bit[18-18] */
+	int _reserved:13;						/* byte[ 0- 3] ,bit[19-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ecc_error_cause {
+	int qm_dma_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ceram_mac_ecc_error:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ceram_ppe_ecc_error:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_pl_ecc_error:1;					/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_qe_ecc_error:1;					/* byte[ 0- 3] ,bit[ 4- 4] */
+	int qeram_ecc_error:1;					/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_fifo_ecc_error:1;				/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved:25;						/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ecc_error_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ceram_mac_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ceram_ppe_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_pl_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_qe_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int qeram_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_fifo_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved_2:25;						/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_internal_error_cause {
+	int qm_dma_internal_error_interrupt:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int mac_enq_with_wrong_source_id_error:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_enq_with_wrong_source_id_error:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int _reserved:27;								/* byte[ 0- 3] ,bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+/* HW structures*/
+/* QL */
+struct ql_low_threshold {
+	int low_threshold:16;					/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_pause_threshold {
+	int pause_threshold:16;					/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_high_threshold {
+	int high_threshold:16;					/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_traffic_source {
+	int traffic_source:3;					/* byte[ 0- 3] ,bit[ 0- 2] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_ecc_error_cause {
+	int qm_ql_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qptr_ecc_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qlen_ecc_error:1;					/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_ecc_error_mask {
+	int _reserved_0:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qptr_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qlen_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved_1:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_internal_error_cause {
+	int qm_ql_internal_error_interrupt:1;	/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int _reserved:30;						/* byte[ 0- 3] ,bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_internal_error_mask {
+	int _reserved_0:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int _reserved:30;						/* byte[ 0- 3] ,bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_nss_general_purpose {
+	int nss_general_purpose:32;				/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qptr_entry {
+	int qptr0:3;							/* byte[ 0- 3] ,bit[ 0- 2] */
+	int qptr1:3;							/* byte[ 0- 3] ,bit[ 3- 5] */
+	int qptr2:3;							/* byte[ 0- 3] ,bit[ 6- 8] */
+	int qptr3:3;							/* byte[ 0- 3] ,bit[ 9-11] */
+	int qptr4:3;							/* byte[ 0- 3] ,bit[12-14] */
+	int qptr5:3;							/* byte[ 0- 3] ,bit[15-17] */
+	int qptr6:3;							/* byte[ 0- 3] ,bit[18-20] */
+	int qptr7:3;							/* byte[ 0- 3] ,bit[21-23] */
+	int _reserved:8;						/* byte[ 0- 3] ,bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qptr {
+	struct ql_qptr_entry reg_qptr_entry;
+} __ATTRIBUTE_PACKED__;
+
+struct ql_rule_bpi_entry {
+	int  xon_thr:16;						/* byte[ 0- 1] ,bit[ 0- 15] */
+	int xoff_thr:16;						/* byte[ 2- 3] ,bit[ 16- 31] */
+	int target_lvl:2;						/* byte[ 4- 4] ,bit[ 32- 33] */
+	int target_node:7;						/* byte[ 4- 5] ,bit[ 34- 40] */
+	int _reserved:23;
+} __ATTRIBUTE_PACKED__;
+
+struct ql_rule_bpi {
+	struct ql_rule_bpi_entry reg_rule_bpi_entry;
+} __ATTRIBUTE_PACKED__;
+
+
+
+
+struct ql_ql_entry {
+	int ql:24;							/* byte[ 0- 3] ,bit[ 0-23] */
+	int qstatus:2;							/* byte[ 0- 3] ,bit[24-25] */
+	int _reserved:6;						/* byte[ 0- 3] ,bit[26-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qlen {
+	struct ql_ql_entry reg_ql_entry;
+} __ATTRIBUTE_PACKED__;
+
+struct ql_bp_qlen_entry {
+	int ql:16;							/* byte[ 0- 1] ,bit[ 0-15] */
+	int qstatus:2;							/* byte[ 2] ,bit[16-17] */
+	int _reserved:14;						/* byte[ 2-3] ,bit[18-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_bp_qlen {
+	struct ql_bp_qlen_entry reg_ql_bp_qlen_entry;
+} __ATTRIBUTE_PACKED__;
+
+struct ql_drop_qlen_entry {
+	int ql:16;							/* byte[ 0- 1] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 2-3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_drop_qlen {
+	struct ql_drop_qlen_entry reg_ql_drop_qlen_entry;
+} __ATTRIBUTE_PACKED__;
+
+/* PFE */
+struct pfe_qece_dram_base_address_hi {
+	int qece_dram_base_address_hi:8;		/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_pyld_dram_base_address_hi {
+	int pyld_dram_base_address_hi:8;		/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_qece_dram_base_address_lo {
+	int qece_dram_base_address_low:32;		/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_pyld_dram_base_address_lo {
+	int pyld_dram_base_address_low:32;		/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_QM_VMID {
+	int VMID:8;								/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct pfe_port_ppe {
+	int port_ppe:16;						*//* byte[ 0- 3] ,bit[ 0-15] *//*
+	int _reserved:16;						*//* byte[ 0- 3] ,bit[16-31] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+struct pfe_port_flush {
+	int port_flush:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_swf_mode {
+	int swf_ardomain:2;						/* byte[ 0- 3] ,bit[ 0- 1] */
+	int swf_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int swf_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_rdma_mode {
+	int rdma_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int rdma_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int rdma_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_hwf_qece {
+	int qece_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int qece_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int qece_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_hwf_pyld {
+	int pyld_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int pyld_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int pyld_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_ecc_error_cause {
+	int qm_pfe_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qflush_ecc_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qece_ecc_error:1;					/* byte[ 0- 3] ,bit[ 2- 2] */
+	int macsdata_ecc_error:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved:28;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_ecc_error_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qflush_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qece_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int macsdata_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_2:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_internal_error_cause {
+	int qm_pfe_internal_error_interrupt:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int last_port_not_last_queue_error:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_cl_error:1;								/* byte[ 0- 3] ,bit[ 4- 4] */
+	int deq_mode_error:1;							/* byte[ 0- 3] ,bit[ 5- 5] */
+	int no_descriptor_mode_for_dram_q_error:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int pckt_len_grtr_cfh_len_plus_descr_error:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved:24;								/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_internal_error_mask {
+	int _reserved_1:1;                                  /* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error_mask:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error_mask:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int last_port_not_last_queue_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_cl_error_mask:1;							/* byte[ 0- 3] ,bit[ 4- 4] */
+	int deq_mode_error_mask:1;							/* byte[ 0- 3] ,bit[ 5- 5] */
+	int no_descriptor_mode_for_dram_q_error_mask:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int pckt_len_grtr_cfh_len_plus_descr_error_mask:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_2:24;                                 /* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_idle_status {
+	int axi_outstanding_fifo_empty:1;		/* byte[ 0- 3] ,bit[ 0-31] */
+	int dram_to_macs_fifo_empty:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int bm_release_fifo_empty:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_queue_flush {
+	int queue_flush_bit_per_q:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_queue_qece {
+/*	uint128_t qece:128;						 byte[ 0-15] ,bit[ 0-127] */
+	int qece_1:32;							/* byte[ 0-15] ,bit[ 0-31] */
+	int qece_2:32;							/* byte[ 0-15] ,bit[32-63] */
+	int qece_3:32;							/* byte[ 0-15] ,bit[64-95] */
+	int qece_4:32;							/* byte[ 0-15] ,bit[96-127] */
+/*	int _reserved:32;						 byte[ 0- 3] ,bit[ 0-31]  DUMMY*/
+} __ATTRIBUTE_PACKED__;
+
+
+
+/* REORDER */
+struct reorder_ru_pool {
+	int sid_limit:32;					/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_class_head {
+	int ru_class_head:12;				/* byte[ 0- 3] ,bit[ 0-11] */
+	int _reserved:20;					/* byte[ 0- 3] ,bit[12-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_ser_error_cause {
+	int ru_ser_error_interrupt:1;		/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ru_qe_ser_error:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ru_class_ser_error:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ru_tasks_ser_error:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ru_ptr2next_ser_error:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ru_sid_fifo_ser_error:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ru_port2class_ser_error:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ru_rf_error:1;					/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_ser_error_mask {
+	int ru_ser_error_mask:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ru_qe_ser_error_mask:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ru_class_ser_error_mask:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ru_tasks_ser_error_mask:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ru_ptr2next_ser_error_mask:1;	/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ru_sid_fifo_ser_error_mask:1;	/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ru_port2class_ser_error_mask:1;	/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ru_rf_error_mask:1;				/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_host_cmd {
+	int ru_host_sid:12;					/* byte[ 0- 3] ,bit[ 0-11] */
+	int _reserved_1:4;					/* byte[ 0- 3] ,bit[12-15] */
+	int ru_host_class:7;				/* byte[ 0- 3] ,bit[16-22] */
+	int _reserved_2:1;					/* byte[ 0- 3] ,bit[23-23] */
+	int ru_host_task:3;					/* byte[ 0- 3] ,bit[24-26] */
+	int _reserved_3:4;					/* byte[ 0- 3] ,bit[27-30] */
+	int ru_host_exec:1;					/* byte[ 0- 3] ,bit[31-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_task_permission {
+	int _reserved_1:31;					/* byte[ 0- 3] ,bit[ 0-30] */
+	int ru_host_permitted:1;			/* byte[ 0- 3] ,bit[31-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_port2class {
+	int ru_class:6;						/* byte[ 0- 3] ,bit[ 0- 5] */
+	int ru_pool:1;						/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved_1:25;					/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+
+/* GPM */
+struct gpm_gpm_pl {
+/*	int gpm_pl:512;						 byte[ 0-63] ,bit[  0-511] */
+	int gpm_pl_00:32;					/* byte[ 0-63] ,bit[  0- 31] */
+	int gpm_pl_01:32;					/* byte[ 0-63] ,bit[ 32- 63] */
+	int gpm_pl_02:32;					/* byte[ 0-63] ,bit[ 64- 95] */
+	int gpm_pl_03:32;					/* byte[ 0-63] ,bit[ 96-127] */
+	int gpm_pl_04:32;					/* byte[ 0-63] ,bit[128-159] */
+	int gpm_pl_05:32;					/* byte[ 0-63] ,bit[160-191] */
+	int gpm_pl_06:32;					/* byte[ 0-63] ,bit[192-223] */
+	int gpm_pl_07:32;					/* byte[ 0-63] ,bit[224-255] */
+	int gpm_pl_08:32;					/* byte[ 0-63] ,bit[256-287] */
+	int gpm_pl_09:32;					/* byte[ 0-63] ,bit[288-319] */
+	int gpm_pl_10:32;					/* byte[ 0-63] ,bit[320-351] */
+	int gpm_pl_11:32;					/* byte[ 0-63] ,bit[352-383] */
+	int gpm_pl_12:32;					/* byte[ 0-63] ,bit[384-415] */
+	int gpm_pl_13:32;					/* byte[ 0-63] ,bit[416-447] */
+	int gpm_pl_14:32;					/* byte[ 0-63] ,bit[448-479] */
+	int gpm_pl_15:32;					/* byte[ 0-63] ,bit[480-511] */
+} __ATTRIBUTE_PACKED__;
+
+struct gpm_gpm_qe {
+/*	int gpm_qe:128;						 byte[ 0- 7] ,bit[  0-128] */
+	int gpm_qe_00:32;					/* byte[ 0- 7] ,bit[  0- 31] */
+	int gpm_qe_01:32;					/* byte[ 0- 7] ,bit[ 32- 63] */
+	int gpm_qe_02:32;					/* byte[ 0- 7] ,bit[ 64- 95] */
+	int gpm_qe_03:32;					/* byte[ 0- 7] ,bit[ 96-127] */
+} __ATTRIBUTE_PACKED__;
+
+
+
+/* DQF */
+struct dqf_Data_FIFO_params_p {
+	int data_fifo_base_p:12;			/* byte[ 0- 3] ,bit[ 0- 11] */
+	int _reserved_1:4;					/* byte[ 0- 3] ,bit[12-15] */
+	int data_fifo_depth_p:12;			/* byte[ 0- 3] ,bit[16-27] */
+	int _reserved_2:4;					/* byte[ 0- 3] ,bit[28-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_Credit_Threshold_p {
+	int Credit_Threshold_p:12;			/* byte[ 0- 3] ,bit[ 0- 11] */
+	int _reserved_1:20;					/* byte[ 0- 3] ,bit[12-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_PPC_port_map_p {
+	int ppc_port_map_p:3;				/* byte[ 0- 3] ,bit[ 0- 2] */
+	int _reserved_1:29;					/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_data_fifo_pointers_p {
+	int data_fifo_wr_ptr_p:13;			/* byte[ 0- 3] ,bit[ 0-12] */
+	int _reserved_1:3;					/* byte[ 0- 3] ,bit[13-15] */
+	int data_fifo_rd_ptr_p:13;			/* byte[ 0- 3] ,bit[16-28] */
+	int _reserved_2:3;					/* byte[ 0- 3] ,bit[29-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mg2mem_req_addr_ctrl {
+	int mg2mem_req_addr:12;				/* byte[ 0- 3] ,bit[ 0- 11] */
+	int mg2mem_req_mem_sel:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int _reserved_1:19;					/* byte[ 0- 3] ,bit[13-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_intr_cause {
+	int dqf_intr_sum:1;					/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_ser_sum:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_err_sum:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_err_sum:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_err_sum:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dqf_cs_calc_err:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dqf_cs_inp_ctrl_err:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dqf_rf_error:1;					/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_1:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_ser_sum_mask:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_sum_mask:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_sum_mask:1;	/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_sum_mask:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dqf_cs_calc_err_mask:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dqf_cs_inp_ctrl_err_mask:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dqf_rf_error_mask:1;				/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_2:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_misc_error_intr_cause {
+	int misc_intr_sum:1;					/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_cs_calc_err:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dqf_cs_inp_ctrl_err:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int dqf_rf_error:1;						/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_1:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_misc_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_cs_calc_err_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dqf_cs_inp_ctrl_err_mask:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int dqf_rf_error_mask:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_2:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_ser_summary_intr_cause {
+	int ser_summary_intr_sum:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ppe_data_ser_error_0:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ppe_data_ser_error_1:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ppe_data_ser_error_2:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_data_ser_error_3:1;				/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ppe_data_ser_error_4:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ppe_data_ser_error_5:1;				/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ppe_data_ser_error_6:1;				/* byte[ 0- 3] ,bit[ 7- 7] */
+	int ppe_data_ser_error_7:1;				/* byte[ 0- 3] ,bit[ 8- 8] */
+	int ppe_data_ser_error_8:1;				/* byte[ 0- 3] ,bit[ 9- 9] */
+	int macs_csptr_ser_error_0:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int macs_csptr_ser_error_1:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int macs_csres_ser_error_0:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int macs_csres_ser_error_1:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int macs_data_ser_error:1;				/* byte[ 0- 3] ,bit[14-14] */
+	int macs_desc_ser_error:1;				/* byte[ 0- 3] ,bit[15-15] */
+	int macs_d2cs_ser_error:1;				/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_ser_summary_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ppe_data_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ppe_data_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ppe_data_ser_error_2_mask:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_data_ser_error_3_mask:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ppe_data_ser_error_4_mask:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ppe_data_ser_error_5_mask:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ppe_data_ser_error_6_mask:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int ppe_data_ser_error_7_mask:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int ppe_data_ser_error_8_mask:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int macs_csptr_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int macs_csptr_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int macs_csres_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int macs_csres_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int macs_data_ser_error_mask:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int macs_desc_ser_error_mask:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int macs_d2cs_ser_error_mask:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_write_to_full_error_intr_cause {
+	int write_to_full_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int write_to_full_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int write_to_full_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int write_to_full_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int write_to_full_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int write_to_full_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int write_to_full_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int write_to_full_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int write_to_full_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int write_to_full_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int write_to_full_error_p10:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int write_to_full_error_p11:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int write_to_full_error_p12:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int write_to_full_error_p13:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int write_to_full_error_p14:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int write_to_full_error_p15:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_write_to_full_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int write_to_full_error_mask_p0:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_mask_p1:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int write_to_full_error_mask_p2:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int write_to_full_error_mask_p3:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int write_to_full_error_mask_p4:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int write_to_full_error_mask_p5:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int write_to_full_error_mask_p6:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int write_to_full_error_mask_p7:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int write_to_full_error_mask_p8:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int write_to_full_error_mask_p9:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int write_to_full_error_mask_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int write_to_full_error_mask_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int write_to_full_error_mask_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int write_to_full_error_mask_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int write_to_full_error_mask_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int write_to_full_error_mask_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_read_from_empty_error_intr_cause {
+	int read_from_empty_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int read_from_empty_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int read_from_empty_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int read_from_empty_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int read_from_empty_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int read_from_empty_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int read_from_empty_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int read_from_empty_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int read_from_empty_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int read_from_empty_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int read_from_empty_error_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int read_from_empty_error_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int read_from_empty_error_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int read_from_empty_error_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int read_from_empty_error_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int read_from_empty_error_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_read_from_empty_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int read_from_empty_error_mask_p0:1;	/* byte[ 0- 3] ,bit[ 1- 1] */
+	int read_from_empty_error_mask_p1:1;	/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_mask_p2:1;	/* byte[ 0- 3] ,bit[ 3- 3] */
+	int read_from_empty_error_mask_p3:1;	/* byte[ 0- 3] ,bit[ 4- 4] */
+	int read_from_empty_error_mask_p4:1;	/* byte[ 0- 3] ,bit[ 5- 5] */
+	int read_from_empty_error_mask_p5:1;	/* byte[ 0- 3] ,bit[ 6- 6] */
+	int read_from_empty_error_mask_p6:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int read_from_empty_error_mask_p7:1;	/* byte[ 0- 3] ,bit[ 8- 8] */
+	int read_from_empty_error_mask_p8:1;	/* byte[ 0- 3] ,bit[ 9- 9] */
+	int read_from_empty_error_mask_p9:1;	/* byte[ 0- 3] ,bit[10-10] */
+	int read_from_empty_error_mask_p10:1;	/* byte[ 0- 3] ,bit[11-11] */
+	int read_from_empty_error_mask_p11:1;	/* byte[ 0- 3] ,bit[12-12] */
+	int read_from_empty_error_mask_p12:1;	/* byte[ 0- 3] ,bit[13-13] */
+	int read_from_empty_error_mask_p13:1;	/* byte[ 0- 3] ,bit[14-14] */
+	int read_from_empty_error_mask_p14:1;	/* byte[ 0- 3] ,bit[15-15] */
+	int read_from_empty_error_mask_p15:1;	/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_wrong_axi_rd_error_intr_cause {
+	int wrong_axi_rd_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int wrong_axi_rd_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int wrong_axi_rd_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int wrong_axi_rd_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int wrong_axi_rd_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int wrong_axi_rd_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int wrong_axi_rd_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int wrong_axi_rd_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int wrong_axi_rd_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int wrong_axi_rd_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int wrong_axi_rd_error_p10:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int wrong_axi_rd_error_p11:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int wrong_axi_rd_error_p12:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int wrong_axi_rd_error_p13:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int wrong_axi_rd_error_p14:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int wrong_axi_rd_error_p15:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_wrong_axi_rd_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int wrong_axi_rd_error_mask_p0:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int wrong_axi_rd_error_mask_p1:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int wrong_axi_rd_error_mask_p2:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_mask_p3:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int wrong_axi_rd_error_mask_p4:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int wrong_axi_rd_error_mask_p5:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int wrong_axi_rd_error_mask_p6:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int wrong_axi_rd_error_mask_p7:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int wrong_axi_rd_error_mask_p8:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int wrong_axi_rd_error_mask_p9:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int wrong_axi_rd_error_mask_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int wrong_axi_rd_error_mask_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int wrong_axi_rd_error_mask_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int wrong_axi_rd_error_mask_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int wrong_axi_rd_error_mask_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int wrong_axi_rd_error_mask_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_status {
+	int mem2mg_resp_ready:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int mem2mg_resp_sop:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int mem2mg_resp_eop:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved_1:29;					/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_hh {
+	int mem2mg_resp_data_hh:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_hl {
+	int mem2mg_resp_data_hl:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_lh {
+	int mem2mg_resp_data_lh:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_ll {
+	int mem2mg_resp_data_ll:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct l3_result {
+	int l3_res:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l3_res {
+	struct l3_result reg_l3_result;
+} __ATTRIBUTE_PACKED__;
+
+struct l4_result {
+	int l3_res:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l4_res {
+	struct l4_result reg_l4_result;
+} __ATTRIBUTE_PACKED__;
+
+struct l3_pointer {
+	int l3_ptr:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l3_ptr {
+	struct l3_pointer reg_l3_pointer;
+} __ATTRIBUTE_PACKED__;
+
+struct l4_pointer {
+	int l4_ptr:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l4_ptr {
+	struct l4_pointer reg_l4_pointer;
+} __ATTRIBUTE_PACKED__;
+
+struct desc {
+	int macs_desc_1:32;					/* byte[ 0- 7] ,bit[ 0-31] */
+	int macs_desc_2:2;					/* byte[ 0- 7] ,bit[32-33] */
+	int _reserved_1:30;					/* byte[ 0- 7] ,bit[34-63] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_desc {
+	struct desc reg_desc;
+} __ATTRIBUTE_PACKED__;
+
+
+
+/* QM General */
+
+
+struct qm_alias {
+
+	struct {
+		int base;
+		int qptr;
+		int qmap_port;
+		int qmap_group;
+		int rule_bpi;
+		int low_threshold;
+		int pause_threshold;
+		int high_threshold;
+		int traffic_source;
+		int ECC_error_cause;
+		int ECC_error_mask;
+		int Internal_error_cause;
+		int internal_error_mask;
+		int nss_general_purpose;
+		int qlen;
+		int bp_qlen;
+		int drop_qlen;
+		int xoff_when_bm_empty_en;
+		int xoff_mac_qnum;
+		int xoff_hmac_qs;
+	} ql;
+
+	struct {
+		int base;
+		int qece_dram_base_address_hi;
+		int pyld_dram_base_address_hi;
+		int qece_dram_base_address_lo;
+		int pyld_dram_base_address_lo;
+		int QM_VMID;
+		int port_flush;
+		int AXI_read_attributes_for_swf_mode;
+		int AXI_read_attributes_for_rdma_mode;
+		int AXI_read_attributes_for_hwf_qece;
+		int AXI_read_attributes_for_hwf_pyld;
+		int max_credit_for_new_dram_req;
+		int ecc_error_cause;
+		int ecc_error_mask;
+		int internal_error_cause;
+		int internal_error_mask;
+		int idle_status;
+		int queue_flush;
+		int queue_qece;
+	} pfe;
+
+	struct {
+		int base;
+		int Data_FIFO_params_p;
+		int Credit_Threshold_p;
+		int PPC_port_map_p;
+		int data_fifo_pointers_p;
+		int dqf_itnr_cause;
+		int dqf_itnr_mask;
+		int misc_error_intr_cause;
+		int misc_error_intr_mask;
+		int dqf_ser_summary_intr_cause;
+		int dqf_ser_summary_intr_mask;
+		int write_to_full_error_intr_cause;
+		int write_to_full_error_intr_mask;
+		int read_from_empty_error_intr_cause;
+		int read_from_empty_error_intr_mask;
+		int wrong_axi_rd_error_intr_cause;
+		int wrong_axi_rd_error_intr_mask;
+		int mg2mem_req_addr_ctrl;
+		int mem2mg_resp_status;
+		int mem2mg_resp_data_hh;
+		int mem2mg_resp_data_hl;
+		int mem2mg_resp_data_lh;
+		int mem2mg_resp_data_ll;
+		int dqf_macs_l3_res;
+		int dqf_macs_l4_res;
+		int dqf_macs_l3_ptr;
+		int dqf_macs_l4_ptr;
+		int dqf_macs_desc;
+	} dqf;
+
+	struct {
+		int base;
+		int Q_memory_allocation;
+		int gpm_thresholds;
+		int dram_thresholds;
+		int AXI_write_attributes_for_swf_mode;
+		int AXI_write_attributes_for_rdma_mode;
+		int AXI_write_attributes_for_hwf_qece;
+		int AXI_write_attributes_for_hwf_pyld;
+		int DRAM_VMID;
+		int tail_pointer_en;
+		int idle_status;
+		int ecc_error_cause;
+		int ecc_error_mask;
+		int internal_error_cause;
+		int internal_error_mask;
+		int ceram_mac;
+		int ceram_ppe;
+		int qeram;
+		int dram_fifo;
+	} dma;
+
+	struct {
+		int base;
+		int ErrStus;
+	} sched;
+
+	struct {
+		int base;
+		int DrpErrStus;
+		int DrpFirstExc;
+		int DrpErrCnt;
+		int DrpExcCnt;
+		int DrpExcMask;
+		int DrpId;
+		int DrpForceErr;
+		int WREDDropProbMode;
+		int WREDMaxProbModePerColor;
+		int DPSource;
+		int RespLocalDPSel;
+		int Drp_Decision_to_Query_debug;
+		int Drp_Decision_hierarchy_to_Query_debug;
+		int TMtoTMPktGenQuantum;
+		int TMtoTMDPCoSSel;
+		int AgingUpdEnable;
+		int PortInstAndAvgQueueLength;
+		int DrpEccConfig;
+		int DrpEccMemParams;
+	} drop;
+
+	struct {
+		int base;
+		int ru_qe;
+		int ru_class;
+		int ru_tasks;
+		int ru_ptr2next;
+		int ru_sid_fifo;
+		int ru_port2class;
+		int ru_pool;
+		int ru_class_head;
+		int ru_ser_error_cause;
+		int ru_ser_error_mask;
+		int ru_host_cmd;
+		int ru_task_permission;
+	} reorder;
+
+};	/* QM; */
+
+extern struct qm_alias qm;
+extern struct qm_alias qm_reg_size;
+extern struct qm_alias qm_reg_offset;
+
+void qm_reg_address_alias_init(u32 silicon_base);
+void  qm_reg_size_alias_init(void);
+void qm_reg_offset_alias_init(void);
+
+#endif   /* __mv_qm_regs_h__ */
+
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm_sysfs.c b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_sysfs.c
new file mode 100644
index 0000000..14f95d0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_sysfs.c
@@ -0,0 +1,208 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include "common/mv_sw_if.h"
+#include "qm/mv_qm.h"
+#include "qm/mv_qm_regs.h"
+
+
+#define PR_ERR_CODE(_rc)	\
+{							\
+	pr_err("%s: operation failed. probably wrong input (rc=%d)\n", __func__, _rc);	\
+}
+
+#define PR_INFO_CALLED		\
+{							\
+	pr_info("%s is called\n", attr->attr.name);	\
+}
+
+static ssize_t mv_qm_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cat                                  errors_regs    - Print error registers\n");
+	o += scnprintf(b+o, s-o, "cat                                  global_regs    - Print global registers\n");
+	o += scnprintf(b+o, s-o, "cat                                  nempty_queues  - Print length of non-empty queues\n");
+	o += scnprintf(b+o, s-o, "cat                                  bpi_groups     - Print all valids (xon < xoff) internal back pressure groups\n");
+	o += scnprintf(b+o, s-o, "echo [q]                           > queue_regs     - Print Q registers\n");
+	o += scnprintf(b+o, s-o, "echo [p]                           > dqf_port_regs  - Print dequeue fifo registers\n");
+	o += scnprintf(b+o, s-o, "echo [pr]                          > profile_show   - Print profile configuration parameters\n");
+	o += scnprintf(b+o, s-o, "echo [pr] [low] [pause] [high]     > profile_set    - Set profile parameters\n");
+	o += scnprintf(b+o, s-o, "echo [gr]                          > bpi_show       - Print internal back pressure group\n");
+	o += scnprintf(b+o, s-o, "echo [gr] [low] [high] [node] [id] > bpi_set        - Set internal back pressure group parameters\n");
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "parameters: [p]     port\n");
+	o += scnprintf(b+o, s-o, "            [pr]    profile 0:emac0, 1:emac1, 2:emac2: 3:emac3 6:hamc\n");
+	o += scnprintf(b+o, s-o, "            [q]     queue\n");
+	o += scnprintf(b+o, s-o, "            [low]   low threshold in KB\n");
+	o += scnprintf(b+o, s-o, "            [pause] pause threshold in KB\n");
+	o += scnprintf(b+o, s-o, "            [high]  high threshold in KB\n");
+	o += scnprintf(b+o, s-o, "            [gr]    internal back pressure group\n");
+	o += scnprintf(b+o, s-o, "            [node]  1: A node, 2: B node, 3: C node\n");
+	o += scnprintf(b+o, s-o, "            [id]    node id\n");
+
+
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_qm_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) {
+		off = mv_qm_help(buf);
+	} else if (!strcmp(name, "errors_dump")) {
+		qm_errors_dump();
+	} else if (!strcmp(name, "global_dump")) {
+		qm_global_dump();
+	} else if (!strcmp(name, "nempty_queues")) {
+		qm_nempty_queue_len_dump();
+	} else if (!strcmp(name, "bpi_groups")) {
+		qm_ql_group_bpi_show_all();
+	} else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t mv_qm_config(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int a, b, c, d, e, err;
+
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read input parameters */
+	err = a = b = c = d = e = 0;
+
+	if (sscanf(buf, "%d %d %d %d %d", &a, &b, &c, &d, &e) <= 0) {
+		err = 1;
+		goto exit;
+	}
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "queue_dump")) {
+		qm_queue_dump(a);
+	} else if (!strcmp(name, "dqf_port_regs")) {
+		qm_dqf_port_dump(a);
+	} else if (!strcmp(name, "profile_show")) {
+		qm_ql_profile_show(a);
+	} else if (!strcmp(name, "profile_set")) {
+		qm_ql_profile_cfg(a, b, c, d);
+	} else if (!strcmp(name, "bpi_show")) {
+		qm_ql_group_bpi_show(a);
+	} else if (!strcmp(name, "bpi_set")) {
+		qm_ql_group_bpi_set(a, b, c, d, e);
+	} else if (!strcmp(name, "debug")) {
+		qm_dbg_flags(QM_F_DBG_RD, a & 0x1);
+		qm_dbg_flags(QM_F_DBG_WR, a & 0x2);
+	} else {
+		err = 1;
+		pr_err("%s: wrong name of QM function <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+exit:
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,                      S_IRUSR, mv_qm_show, NULL);
+static DEVICE_ATTR(errors_dump,               S_IRUSR, mv_qm_show, NULL);
+static DEVICE_ATTR(global_dump,               S_IRUSR, mv_qm_show, NULL);
+static DEVICE_ATTR(nempty_queues,             S_IRUSR, mv_qm_show, NULL);
+static DEVICE_ATTR(bpi_groups,                S_IRUSR, mv_qm_show, NULL);
+static DEVICE_ATTR(queue_dump,                S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(dqf_port_regs,             S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(profile_show,              S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(profile_set,               S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(bpi_show,                  S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(bpi_set,                   S_IWUSR, NULL, mv_qm_config);
+static DEVICE_ATTR(debug,                   S_IWUSR, NULL, mv_qm_config);
+
+static struct attribute *mv_qm_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_errors_dump.attr,
+	&dev_attr_global_dump.attr,
+	&dev_attr_queue_dump.attr,
+	&dev_attr_nempty_queues.attr,
+	&dev_attr_bpi_groups.attr,
+	&dev_attr_dqf_port_regs.attr,
+	&dev_attr_profile_show.attr,
+	&dev_attr_profile_set.attr,
+	&dev_attr_bpi_show.attr,
+	&dev_attr_bpi_set.attr,
+	&dev_attr_debug.attr,
+
+	NULL
+};
+
+static struct attribute_group mv_qm_group = {
+	.attrs = mv_qm_attrs,
+};
+
+int mv_pp3_qm_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+	struct kobject *qm_kobj;
+
+	qm_kobj = kobject_create_and_add("qm", pp3_kobj);
+	if (!qm_kobj) {
+		printk(KERN_ERR"%s: cannot create qm kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(qm_kobj, &mv_qm_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for qm%d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_qm_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &mv_qm_group);
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.c
new file mode 100644
index 0000000..cadb0f1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.c
@@ -0,0 +1,804 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_internal_types.h"
+#include "rm_alloc.h"
+#include "rm_chunk.h"
+#include "rm_free.h"
+#include "tm/core/tm_defs.h"
+
+
+/**
+ */
+int rm_find_free_queue(rmctl_t hndl, uint32_t a_node_ind)
+{
+	struct rm_node *queue = 0;
+	uint32_t free_node;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (a_node_ind >= ctl->rm_total_a_nodes)
+		return -EFAULT;
+
+	if (ctl->rm_a_node_array[a_node_ind].cnt == 0)
+		return -ENOBUFS;
+
+	free_node = ctl->rm_a_node_array[a_node_ind].first_child;
+
+	/* Pop free queue */
+	queue = &(ctl->rm_queue_array[free_node]);
+	queue->used = RM_TRUE;
+	ctl->rm_queue_cnt--;
+	ctl->rm_a_node_array[a_node_ind].first_child = queue->next_free_ind;
+	ctl->rm_a_node_array[a_node_ind].cnt--;
+
+	/* The last one */
+	if ((free_node == ctl->rm_a_node_array[a_node_ind].last_child) &&
+		(ctl->rm_a_node_array[a_node_ind].first_child == (uint16_t)TM_INVAL))
+		ctl->rm_a_node_array[a_node_ind].last_child = (uint16_t)TM_INVAL;
+
+	return free_node;
+}
+
+
+/**
+ */
+int rm_find_free_a_node(rmctl_t hndl, uint32_t b_node_ind, uint32_t num_of_children)
+{
+	enum rm_level low_lvl = RM_Q_LVL;
+	struct rm_node *node = 0;
+	struct rm_node *child = 0;
+	uint32_t free_node;
+	uint32_t ind;
+	int rc;
+	int i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (b_node_ind >= ctl->rm_total_b_nodes)
+		return -EFAULT;
+
+	free_node = ctl->rm_b_node_array[b_node_ind].first_child;
+	if (free_node == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	rc = rm_get_chunk(hndl, low_lvl, num_of_children, &ind);
+	if (rc)
+		return rc;
+
+	node = &(ctl->rm_a_node_array[free_node]);
+	node->first_child = ind;
+	node->last_child = ind + num_of_children - 1;
+
+	for (i = ind; i < node->last_child; i++) {
+		child = &(ctl->rm_queue_array[i]);
+		child->parent_ind = free_node;
+		child->next_free_ind = i + 1;
+	}
+	/* for last child in range */
+	child = &(ctl->rm_queue_array[i]);
+	child->parent_ind = free_node;
+	child->next_free_ind = (uint16_t)TM_INVAL;
+
+	/* Pop free node */
+	node->used = RM_TRUE;
+	node->cnt = num_of_children;
+	ctl->rm_a_node_cnt--;
+	ctl->rm_b_node_array[b_node_ind].first_child = node->next_free_ind;
+	ctl->rm_b_node_array[b_node_ind].cnt--;
+
+	/* The last one */
+	if ((free_node == ctl->rm_b_node_array[b_node_ind].last_child) &&
+		(ctl->rm_b_node_array[b_node_ind].first_child == (uint16_t)TM_INVAL))
+		ctl->rm_b_node_array[b_node_ind].last_child = (uint16_t)TM_INVAL;
+
+	return free_node;
+}
+
+
+/**
+ */
+int rm_find_free_b_node(rmctl_t hndl, uint32_t c_node_ind, uint32_t num_of_children)
+{
+	enum rm_level low_lvl = RM_A_LVL;
+	struct rm_node *node = 0;
+	struct rm_node *child = 0;
+	uint32_t free_node;
+	uint32_t ind;
+	int rc;
+	int i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (c_node_ind >= ctl->rm_total_c_nodes)
+		return -EFAULT;
+
+	free_node = ctl->rm_c_node_array[c_node_ind].first_child;
+	if (free_node == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	rc = rm_get_chunk(hndl, low_lvl, num_of_children, &ind);
+	if (rc)
+		return rc;
+
+	node = &(ctl->rm_b_node_array[free_node]);
+	node->first_child = ind;
+	node->last_child = ind + num_of_children - 1;
+
+	for (i = ind; i < node->last_child; i++) {
+		child = &(ctl->rm_a_node_array[i]);
+		child->parent_ind = free_node;
+		child->next_free_ind = i + 1;
+	}
+	/* for last child in range */
+	child = &(ctl->rm_a_node_array[i]);
+	child->parent_ind = free_node;
+	child->next_free_ind = (uint16_t) TM_INVAL;
+
+	/* Pop free node */
+	node->used = RM_TRUE;
+	node->cnt = num_of_children;
+	ctl->rm_b_node_cnt--;
+	ctl->rm_c_node_array[c_node_ind].first_child = node->next_free_ind;
+	ctl->rm_c_node_array[c_node_ind].cnt--;
+
+	/* The last one */
+	if ((free_node == ctl->rm_c_node_array[c_node_ind].last_child) &&
+		(ctl->rm_c_node_array[c_node_ind].first_child == (uint16_t)TM_INVAL))
+		ctl->rm_c_node_array[c_node_ind].last_child = (uint16_t)TM_INVAL;
+
+	return free_node;
+}
+
+
+/**
+ */
+int rm_find_free_c_node(rmctl_t hndl, uint8_t port_ind, uint32_t num_of_children)
+{
+	enum rm_level low_lvl = RM_B_LVL;
+	struct rm_node *node = 0; /*NULL;*/
+	struct rm_node *child = 0;/*NULL;*/
+	uint32_t free_node;
+	uint32_t ind;
+	int rc;
+	int i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (port_ind >= ctl->rm_total_ports)
+		return -EFAULT;
+
+	free_node = ctl->rm_port_array[port_ind].first_child;
+	if (free_node == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	rc = rm_get_chunk(hndl, low_lvl, num_of_children, &ind);
+	if (rc)
+		return rc;
+
+	node = &(ctl->rm_c_node_array[free_node]);
+	node->first_child = ind;
+	node->last_child = ind + num_of_children - 1;
+
+	for (i = ind; i < node->last_child; i++) {
+		child = &(ctl->rm_b_node_array[i]);
+		child->parent_ind = free_node;
+		child->next_free_ind = i + 1;
+	}
+	/* for last child in range */
+	child = &(ctl->rm_b_node_array[i]);
+	child->parent_ind = free_node;
+	child->next_free_ind = (uint16_t) TM_INVAL;
+
+	/* Pop free node */
+	node->used = RM_TRUE;
+	node->cnt = num_of_children;
+	ctl->rm_c_node_cnt--;
+	ctl->rm_port_array[port_ind].first_child = node->next_free_ind;
+	ctl->rm_port_array[port_ind].cnt--;
+
+	/* The last one */
+	if ((free_node == ctl->rm_port_array[port_ind].last_child) &&
+		(ctl->rm_port_array[port_ind].first_child == (uint16_t)TM_INVAL)) /* OR: cnt == 0 */
+		ctl->rm_port_array[port_ind].last_child = (uint16_t)TM_INVAL;
+
+	return free_node;
+}
+
+
+/**
+ */
+int rm_init_port(rmctl_t hndl, uint8_t port_id, uint32_t num_of_children)
+{
+	enum rm_level low_lvl = RM_C_LVL;
+	struct rm_node *node = 0;/*NULL;*/
+	struct rm_node *child = 0;/*NULL;*/
+	uint32_t ind;
+	int rc;
+	int i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (port_id >= ctl->rm_total_ports)
+		return -EFAULT;
+
+	/* No free ports */
+	if (ctl->rm_port_cnt == 0)
+		return -ENOMEM;
+
+	rc = rm_get_chunk(hndl, low_lvl, num_of_children, &ind);
+	if (rc)
+		return rc;
+
+	node = &(ctl->rm_port_array[port_id]);
+	node->parent_ind = 0;
+	node->next_free_ind = 0;
+
+
+	node->first_child = ind;
+	node->last_child = ind + num_of_children - 1;
+
+	for (i = ind; i < node->last_child; i++) {
+		child = &(ctl->rm_c_node_array[i]);
+		child->parent_ind = port_id;
+		child->next_free_ind = i + 1;
+	}
+	/* for last child in range */
+	child = &(ctl->rm_c_node_array[i]);
+	child->parent_ind = port_id;
+	child->next_free_ind = (uint16_t) TM_INVAL;
+
+	node->used = RM_TRUE;
+	node->cnt = num_of_children;
+	ctl->rm_port_cnt--;
+
+	return 0;
+}
+
+
+/** For reshuffling purposes.
+ */
+int rm_expand_range(rmctl_t hndl, enum tm_level level, uint32_t index, uint32_t parent_index)
+{
+	struct rm_node *node = 0;/*NULL;*/
+	struct rm_node *parent = 0;/*NULL;*/
+	int rc;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	switch (level) {
+	case A_LEVEL:
+		if (index >= ctl->rm_total_a_nodes)
+			return -EFAULT;
+
+		if (parent_index >= ctl->rm_total_b_nodes)
+			return -EFAULT;
+
+		rc = rm_expand_chunk(hndl, RM_A_LVL, index);
+		if (rc)
+			return rc;
+
+		parent = &(ctl->rm_b_node_array[parent_index]);
+		node = &(ctl->rm_a_node_array[index]);
+
+		/* Assumption: no free nodes to the parent,
+		because of the reshuffling is performed on full parent only */
+
+		/* Init parent */
+		parent->first_child = index;
+		parent->last_child = index;
+		parent->cnt++;
+
+		/* Init node */
+		node->used = RM_FALSE;
+		node->parent_ind = parent_index;
+		node->next_free_ind = (uint16_t) TM_INVAL;
+		break;
+	case B_LEVEL:
+		if (index >= ctl->rm_total_b_nodes)
+			return -EFAULT;
+
+		if (parent_index >= ctl->rm_total_c_nodes)
+			return -EFAULT;
+
+		rc = rm_expand_chunk(hndl, RM_B_LVL, index);
+		if (rc)
+			return rc;
+
+		parent = &(ctl->rm_c_node_array[parent_index]);
+		node = &(ctl->rm_b_node_array[index]);
+
+		/* Assumption: no free nodes to the parent,
+		because of the reshuffling is performed on full parent only */
+
+		/* Init parent */
+		parent->first_child = index;
+		parent->last_child = index;
+		parent->cnt++;
+
+		/* Init node */
+		node->used = RM_FALSE;
+		node->parent_ind = parent_index;
+		node->next_free_ind = (uint16_t) TM_INVAL;
+		break;
+	default:
+		return -ERANGE;
+	}
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_find_free_wred_queue_curve(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_WRED_Q_CURVE];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_queue_curves[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_WRED_Q_CURVE] =
+		ctl->rm_wred_queue_curves[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_WRED_Q_CURVE]) &&
+		(ctl->rm_first_free_entry[RM_WRED_Q_CURVE] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_WRED_Q_CURVE] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_wred_a_node_curve(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_WRED_A_CURVE];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_a_node_curves[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_WRED_A_CURVE] =
+		ctl->rm_wred_a_node_curves[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_WRED_A_CURVE]) &&
+		(ctl->rm_first_free_entry[RM_WRED_A_CURVE] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_WRED_A_CURVE] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_wred_b_node_curve(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_WRED_B_CURVE];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_b_node_curves[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_WRED_B_CURVE] =
+		ctl->rm_wred_b_node_curves[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_WRED_B_CURVE]) &&
+		(ctl->rm_first_free_entry[RM_WRED_B_CURVE] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_WRED_B_CURVE] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_wred_c_node_curve(rmctl_t hndl, uint8_t cos)
+{
+	uint16_t free_entry;
+	enum rm_prf_level ptr_lvl = RM_WRED_C_CURVE_COS_0;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_C_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_C_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_C_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_C_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_C_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_C_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_C_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_C_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT;
+	}
+
+	free_entry = ctl->rm_first_free_entry[ptr_lvl];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_c_node_curves[cos][free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[ptr_lvl] =
+		ctl->rm_wred_c_node_curves[cos][free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[ptr_lvl]) &&
+		(ctl->rm_first_free_entry[ptr_lvl] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[ptr_lvl] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_wred_port_curve(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	free_entry = ctl->rm_first_free_entry[RM_WRED_P_CURVE];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_port_curves[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_WRED_P_CURVE] =
+		ctl->rm_wred_port_curves[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_WRED_P_CURVE]) &&
+		(ctl->rm_first_free_entry[RM_WRED_P_CURVE] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_WRED_P_CURVE] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_wred_port_curve_cos(rmctl_t hndl, uint8_t cos)
+{
+	uint16_t free_entry;
+	enum rm_prf_level ptr_lvl = RM_WRED_P_CURVE_COS_0;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_P_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_P_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_P_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_P_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_P_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_P_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_P_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_P_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT;
+	}
+
+	free_entry = ctl->rm_first_free_entry[ptr_lvl];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_wred_port_curves_cos[cos][free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[ptr_lvl] =
+		ctl->rm_wred_port_curves_cos[cos][free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[ptr_lvl]) &&
+		(ctl->rm_first_free_entry[ptr_lvl] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[ptr_lvl] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_queue_drop_profile(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_Q_DROP_PRF];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_queue_drop_profiles[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_Q_DROP_PRF] =
+		ctl->rm_queue_drop_profiles[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_Q_DROP_PRF]) &&
+		(ctl->rm_first_free_entry[RM_Q_DROP_PRF] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_Q_DROP_PRF] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_a_node_drop_profile(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_A_DROP_PRF];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_a_node_drop_profiles[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_A_DROP_PRF] =
+		ctl->rm_a_node_drop_profiles[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_A_DROP_PRF]) &&
+		(ctl->rm_first_free_entry[RM_A_DROP_PRF] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_A_DROP_PRF] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_b_node_drop_profile(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_B_DROP_PRF];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_b_node_drop_profiles[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_B_DROP_PRF] =
+		ctl->rm_b_node_drop_profiles[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_B_DROP_PRF]) &&
+		(ctl->rm_first_free_entry[RM_B_DROP_PRF] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_B_DROP_PRF] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_c_node_drop_profile(rmctl_t hndl, uint8_t cos)
+{
+	uint16_t free_entry;
+	enum rm_prf_level ptr_lvl = RM_C_DROP_PRF_COS_0;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_C_DROP_PRF_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_C_DROP_PRF_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_C_DROP_PRF_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_C_DROP_PRF_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_C_DROP_PRF_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_C_DROP_PRF_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_C_DROP_PRF_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_C_DROP_PRF_COS_7;
+		break;
+	default:
+		return -EFAULT;
+	}
+
+	free_entry = ctl->rm_first_free_entry[ptr_lvl];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_c_node_drop_profiles[cos][free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[ptr_lvl] =
+		ctl->rm_c_node_drop_profiles[cos][free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[ptr_lvl]) &&
+		(ctl->rm_first_free_entry[ptr_lvl] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[ptr_lvl] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/**
+ */
+int rm_find_free_port_drop_profile(rmctl_t hndl)
+{
+	uint16_t free_entry;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	free_entry = ctl->rm_first_free_entry[RM_P_DROP_PRF];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_port_drop_profiles[free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[RM_P_DROP_PRF] =
+		ctl->rm_port_drop_profiles[free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[RM_P_DROP_PRF]) &&
+		(ctl->rm_first_free_entry[RM_P_DROP_PRF] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[RM_P_DROP_PRF] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
+
+
+/* for BC2  only */
+int rm_find_free_port_drop_profile_cos(rmctl_t hndl, uint8_t cos)
+{
+	uint16_t free_entry;
+	enum rm_prf_level ptr_lvl = RM_P_DROP_PRF_COS_0;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_P_DROP_PRF_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_P_DROP_PRF_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_P_DROP_PRF_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_P_DROP_PRF_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_P_DROP_PRF_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_P_DROP_PRF_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_P_DROP_PRF_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_P_DROP_PRF_COS_7;
+		break;
+	default:
+		return -EFAULT;
+	}
+
+	free_entry = ctl->rm_first_free_entry[ptr_lvl];
+	if (free_entry == (uint16_t)TM_INVAL)
+		return -ENOBUFS;
+
+	/* Pop free entry */
+	ctl->rm_port_drop_profiles_cos[cos][free_entry].used = RM_TRUE;
+	ctl->rm_first_free_entry[ptr_lvl] =
+		ctl->rm_port_drop_profiles_cos[cos][free_entry].next_free_ind;
+
+	/* The last one */
+	if ((free_entry == ctl->rm_last_free_entry[ptr_lvl]) &&
+		(ctl->rm_first_free_entry[ptr_lvl] == (uint16_t)TM_INVAL))
+		ctl->rm_last_free_entry[ptr_lvl] = (uint16_t)TM_INVAL;
+
+	return free_entry;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.h
new file mode 100644
index 0000000..0f2a40c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_alloc.h
@@ -0,0 +1,288 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef	RM_ALLOC_H
+#define	RM_ALLOC_H
+
+#include "rm_interface.h"
+#include "tm/core/tm_defs.h"
+
+
+/** Find free Queue.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		a_node_ind	     A-node index.
+ *
+ *   @return an integer positive index of found free queue.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if a_node_ind is out of range.
+ *   @retval -ENOBUFS when no free queues.
+ */
+int rm_find_free_queue(rmctl_t hndl, uint32_t a_node_ind);
+
+
+/** Find free A-node.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		b_node_ind	     B-node index.
+ *   @param[in]		num_of_children	 Children nodes number.
+ *
+ *   @return an integer positive index of found free node.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if b_node_ind is out of range.
+ *   @retval -ENOBUFS when no free A-nodes.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_find_free_a_node(rmctl_t hndl, uint32_t b_node_ind, uint32_t num_of_children);
+
+
+/** Find free B-node.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		c_node_ind	     C-node index.
+ *   @param[in]		num_of_children	 Children nodes number.
+ *
+ *   @return an integer positive index of found free node.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if c_node_ind is out of range.
+ *   @retval -ENOBUFS when no free B-nodes.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_find_free_b_node(rmctl_t hndl, uint32_t c_node_ind, uint32_t num_of_children);
+
+
+/** Find free C-node.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		port_ind	     Port index.
+ *   @param[in]		num_of_children	 Children nodes number.
+ *
+ *   @return an integer positive index of found free node.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if port_ind is out of range.
+ *   @retval -ENOBUFS when no free C-nodes.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_find_free_c_node(rmctl_t hndl, uint8_t port_ind, uint32_t num_of_children);
+
+
+/** Init Port in RM.
+ *
+ *   @param[in]		hndl			Resource Manager handle.
+ *   @param[in]		port_id	        Port index.
+ *   @param[in]		num_of_children	Children nodes number.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if port_id is out of range.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_init_port(rmctl_t hndl, uint8_t port_id, uint32_t num_of_children);
+
+
+/** Expand range of the parent by adding the node to it's range.
+ *
+ *   @param[in]		hndl			Resource Manager handle.
+ *   @param[in]		level	                Level of the node.
+ *   @param[in]		node	                Index of the node.
+ *   @param[in]		parent	                Index of the parent.
+ *
+ *   @node: node index should be adjacent to the index of the last child node
+ *   in range of this parent.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if one of indises is out of range.
+ *   @retval -ENOMEM when out of memory space or node index is not found.
+ */
+int rm_expand_range(rmctl_t hndl, enum tm_level level, uint32_t node, uint32_t parent);
+
+
+/** Find free WRED Queue Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_queue_curve(rmctl_t hndl);
+
+
+/** Find free WRED A-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_a_node_curve(rmctl_t hndl);
+
+
+/** Find free WRED B-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_b_node_curve(rmctl_t hndl);
+
+
+/** Find free WRED C-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if cos is out of range.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_c_node_curve(rmctl_t hndl, uint8_t cos);
+
+
+/** Find free WRED Port Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_port_curve(rmctl_t hndl);
+
+
+/* BC2 only */
+/** Find free WRED Port Curve entry per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if cos is out of range.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_wred_port_curve_cos(rmctl_t hndl, uint8_t cos);
+
+
+/** Find free Queue Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_queue_drop_profile(rmctl_t hndl);
+
+
+/** Find free A-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_a_node_drop_profile(rmctl_t hndl);
+
+
+/** Find free B-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_b_node_drop_profile(rmctl_t hndl);
+
+
+/** Find free C-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if cos is out of range.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_c_node_drop_profile(rmctl_t hndl, uint8_t cos);
+
+
+/** Find free Port Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_port_drop_profile(rmctl_t hndl);
+
+
+/* BC2 only */
+/** Find free Port Drop Profile entry per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *
+ *   @return an integer positive index of found free entry.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if cos is out of range.
+ *   @retval -ENOBUFS when no free entry.
+ */
+int rm_find_free_port_drop_profile_cos(rmctl_t hndl, uint8_t cos);
+
+
+#endif   /* RM_ALLOC_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.c
new file mode 100644
index 0000000..43866b5
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.c
@@ -0,0 +1,175 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_internal_types.h"
+#include "rm_chunk.h"
+#include "tm/core/tm_os_interface.h"
+
+
+/* Chunk list is always in decending order - the biggest is first */
+/* Chunk list always have member - if no free nodes so it has one chunk with 0 size */
+
+
+void clear_chunk_list(chunk_ptr list)
+{
+	chunk_ptr tmp;
+	while (list) {
+		tmp = list->next_free;
+		tm_free(list);
+		list = tmp;
+	}
+}
+
+
+static void prv_swap_chunk_content(chunk_ptr a, chunk_ptr b)
+{
+	uint32_t tmp;
+	tmp = a->index; a->index = b->index ; b->index = tmp;
+	tmp = a->size; a->size = b->size ; b->size = tmp;
+}
+
+
+static void prv_reorder_decreased(chunk_ptr ptr)
+{
+	while ((ptr->next_free) && (ptr->next_free->size > ptr->size)) {
+		prv_swap_chunk_content(ptr, ptr->next_free);
+		ptr = ptr->next_free;
+	}
+	/* remove extra zero sizes chunks */
+	if (ptr->size == 0) {
+		/* this is first zero size chunk - all chunks after must be also zero-sized and should be removed */
+		clear_chunk_list(ptr->next_free);
+		/* terminate  list */
+		ptr->next_free = 0;
+	}
+}
+
+
+static void prv_reorder_increased(chunk_ptr list, chunk_ptr ptr)
+{
+	while (list != ptr) {
+		if (list->size < ptr->size)
+			prv_swap_chunk_content(list, ptr);
+		list = list->next_free;
+	}
+}
+
+
+chunk_ptr rm_new_chunk(uint32_t start_index, uint32_t length, struct rm_chunk *chunk_list)
+{
+	struct rm_chunk *pchunk = (struct rm_chunk *)tm_malloc(sizeof(struct rm_chunk));
+	pchunk->index = start_index;
+	pchunk->size = length;
+	pchunk->next_free = chunk_list;
+	prv_reorder_decreased(pchunk);
+	return pchunk;
+}
+
+
+int rm_release_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t size, uint32_t index)
+{
+	chunk_ptr ptr;
+	uint32_t end_index = index + size;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	/* find if the chunk can be merged with already existing free chunk */
+	for (ptr = ctl->rm_free_nodes[lvl]; ptr ; ptr = ptr->next_free) {
+		if (ptr->index+ptr->size == index) /* chunk is merged after existing free space */
+			break;
+		if (ptr->index == end_index) { /* chunk is merged before existing free space */
+			ptr->index = index;
+			break;
+		}
+	}
+	if (ptr) {
+		ptr->size += size;
+		/* if next chunk starts immediately after this - let merge them */
+		if ((ptr->next_free) && (ptr->next_free->index == ptr->index+ptr->size)) {
+			ptr->size += ptr->next_free->size;
+			ptr->next_free->size = 0;
+			prv_reorder_decreased(ptr->next_free);
+		}
+		/* chunk merged, chunk size increased, need reorder */
+		prv_reorder_increased(ctl->rm_free_nodes[lvl], ptr);
+	} else {
+		/* new free chunk added, reordering inside chunk creation function */
+		ctl->rm_free_nodes[lvl] = rm_new_chunk(index, size, ctl->rm_free_nodes[lvl]);
+	}
+	return 0;
+}
+
+
+int rm_get_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t size, uint32_t *index)
+{
+	chunk_ptr	ptr;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	ptr = ctl->rm_free_nodes[lvl];
+	if (ptr->size < size)
+		return -ENOMEM; /* no enought continuous nodes pool */
+	/* if we want to utilize smallest possible chunk  -  launch string below */
+	while ((ptr->next_free) && (ptr->next_free->size > size))
+		ptr = ptr->next_free;
+	/* here ptr is the last chunk with size >= required size */
+	/* otherwize we will get resources from biggest chunk; */
+	/* let get pool from chunk and return it's index */
+	ptr->size -= size;
+	/* we can extract pool from start of chunk */
+	*index = ptr->index;
+	ptr->index += size;
+	/* or extract it fom the end */
+	/* *index=ptr->index+ptr->size; */
+	prv_reorder_decreased(ptr);
+	return 0;
+}
+
+
+int rm_expand_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t index)
+{
+	chunk_ptr	ptr;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	ptr = ctl->rm_free_nodes[lvl];
+	while ((ptr) && (ptr->index != index))
+		ptr = ptr->next_free;
+	if (ptr && ptr->size) { /* found */
+		ptr->index += 1;
+		ptr->size -= 1;
+		prv_reorder_decreased(ptr);
+		return 0;
+	} else
+		return -ENOMEM;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.h
new file mode 100644
index 0000000..715ab98
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_chunk.h
@@ -0,0 +1,100 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_CHUNK_H
+#define RM_CHUNK_H
+
+#include "rm_interface.h"
+
+
+/** Find index of matching chunk and update internal DB.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]		lvl		          Hierarchy level.
+ *   @param[in]		size		      Length of needed range.
+ *   @param[out]	index		      Index of node.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOMEM if no free space in needed size.
+ */
+int rm_get_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t size, uint32_t *index);
+
+
+/** Add chunk of the nodes that became free and update internal DB.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]		lvl		          Hierarchy level.
+ *   @param[in]		size		      Length of needed range.
+ *   @param[in]		index		      Index of node.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_release_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t size, uint32_t index);
+
+
+/** Find free chunk that includes index and get from it node to expand used nodes range.
+ *
+ *   @param[in]		hndl				Resource Manager handle.
+ *   @param[in]		lvl					Hierarchy level.
+ *   @param[in]		index				Index of node.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOMEM if index not found.
+ */
+int rm_expand_chunk(rmctl_t hndl, enum rm_level lvl, uint32_t index);
+
+
+/** Create new chunk and add it to free chunk list ( list elements are stay in decending order of chunk size)
+ *
+ *   @param[in]	    index		  Index of starting node.
+ *   @param[in]	    length		  length of chunk
+ *   @param[in]	    chunk_list	  Pointer to chunk list to add to
+ *
+ *   @return  new pointer to updated chunk list
+ */
+chunk_ptr rm_new_chunk(uint32_t start_index, uint32_t length, struct rm_chunk *chunk_list);
+
+
+/** Deallocate chunk list and releases allocated memory
+ *
+ *   @param[in]	    chunk_list	  Pointer to chunk list to free *
+ */
+void clear_chunk_list(chunk_ptr list);
+
+
+#endif   /* RM_CHUNK_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.c
new file mode 100644
index 0000000..d9c76e8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.c
@@ -0,0 +1,423 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm/core/tm_core_types.h"
+#include "rm_internal_types.h"
+#include "rm_ctl.h"
+#include "rm_chunk.h"
+#include "tm/core/tm_os_interface.h"
+#include "tm/core/tm_hw_configuration_interface.h"
+
+
+/**
+ */
+int rm_open(uint8_t total_ports,
+			uint16_t total_c_nodes,
+			uint16_t total_b_nodes,
+			uint16_t total_a_nodes,
+			uint32_t total_queues,
+			rmctl_t *hndl)
+{
+	struct rmctl *ctl = NULL;
+	int i;
+	int j;
+
+	int rc = 0;
+
+	/* check that it is new handle to create*/
+	if (!hndl) {
+		rc = -EINVAL;
+		goto out;
+	}
+	*hndl = NULL;
+
+	/* Create rmctl instance */
+	ctl = tm_malloc(sizeof(*ctl));
+	if (!ctl) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl, 0, sizeof(*ctl));
+
+	/* Fill in ctl structure */
+	ctl->magic = RM_MAGIC;
+
+
+	/* Allocate arrays */
+	ctl->rm_queue_array = tm_malloc(total_queues * sizeof(struct rm_node));
+	if (!ctl->rm_queue_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->rm_queue_array, 0, total_queues * sizeof(struct rm_node));
+
+	ctl->rm_a_node_array = tm_malloc(total_a_nodes * sizeof(struct rm_node));
+	if (!ctl->rm_a_node_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->rm_a_node_array, 0, total_a_nodes * sizeof(struct rm_node));
+
+	ctl->rm_b_node_array = tm_malloc(total_b_nodes * sizeof(struct rm_node));
+	if (!ctl->rm_b_node_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->rm_b_node_array, 0, total_b_nodes * sizeof(struct rm_node));
+
+	ctl->rm_c_node_array = tm_malloc(total_c_nodes * sizeof(struct rm_node));
+	if (!ctl->rm_c_node_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->rm_c_node_array, 0, total_c_nodes * sizeof(struct rm_node));
+
+	ctl->rm_port_array = tm_malloc(total_ports * sizeof(struct rm_node));
+	if (!ctl->rm_port_array) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->rm_port_array, 0, total_ports * sizeof(struct rm_node));
+
+	ctl->rm_wred_queue_curves =
+		tm_malloc(TM_NUM_WRED_QUEUE_CURVES * sizeof(struct rm_entry));
+	if (!ctl->rm_wred_queue_curves) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->rm_wred_a_node_curves =
+		tm_malloc(TM_NUM_WRED_A_NODE_CURVES * sizeof(struct rm_entry));
+	if (!ctl->rm_wred_a_node_curves) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->rm_wred_b_node_curves =
+		tm_malloc(TM_NUM_WRED_B_NODE_CURVES * sizeof(struct rm_entry));
+	if (!ctl->rm_wred_b_node_curves) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+
+	for (i = 0; i < RM_COS; i++) {
+		ctl->rm_wred_c_node_curves[i] =
+			tm_malloc(TM_NUM_WRED_C_NODE_CURVES * sizeof(struct rm_entry));
+		if (!ctl->rm_wred_c_node_curves[i]) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+
+	ctl->rm_wred_port_curves =
+		tm_malloc(TM_NUM_WRED_PORT_CURVES * sizeof(struct rm_entry));
+	if (!ctl->rm_wred_port_curves) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < RM_COS; i++) {
+		ctl->rm_wred_port_curves_cos[i] =
+			tm_malloc(TM_NUM_WRED_PORT_CURVES * sizeof(struct rm_entry));
+		if (!ctl->rm_wred_port_curves_cos[i]) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	ctl->rm_queue_drop_profiles =
+		tm_malloc(TM_NUM_QUEUE_DROP_PROF * sizeof(struct rm_entry));
+	if (!ctl->rm_queue_drop_profiles) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->rm_a_node_drop_profiles =
+		tm_malloc(TM_NUM_A_NODE_DROP_PROF * sizeof(struct rm_entry));
+	if (!ctl->rm_a_node_drop_profiles) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->rm_b_node_drop_profiles =
+		tm_malloc(TM_NUM_B_NODE_DROP_PROF * sizeof(struct rm_entry));
+	if (!ctl->rm_b_node_drop_profiles) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+
+	/* not used in HX/AX  */
+	for (i = 0; i < RM_COS; i++) {
+		ctl->rm_c_node_drop_profiles[i] =
+			tm_malloc(TM_NUM_C_NODE_DROP_PROF * sizeof(struct rm_entry));
+		if (!ctl->rm_c_node_drop_profiles[i]) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	ctl->rm_port_drop_profiles = tm_malloc(TM_NUM_PORT_DROP_PROF * sizeof(struct rm_entry));
+	if (!ctl->rm_port_drop_profiles) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	/* not used in HX/AX*/
+	for (i = 0; i < RM_COS; i++) {
+		ctl->rm_port_drop_profiles_cos[i] = tm_malloc(TM_NUM_PORT_DROP_PROF * sizeof(struct rm_entry));
+		if (!ctl->rm_port_drop_profiles_cos[i]) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	for (i = 0; i < TM_NUM_WRED_QUEUE_CURVES; i++) {
+		ctl->rm_wred_queue_curves[i].used = RM_FALSE;
+		ctl->rm_wred_queue_curves[i].next_free_ind = i+1;
+	}
+	ctl->rm_wred_queue_curves[TM_NUM_WRED_QUEUE_CURVES-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (i = 0; i < TM_NUM_WRED_A_NODE_CURVES; i++) {
+		ctl->rm_wred_a_node_curves[i].used = RM_FALSE;
+		ctl->rm_wred_a_node_curves[i].next_free_ind = i+1;
+	}
+	ctl->rm_wred_a_node_curves[TM_NUM_WRED_A_NODE_CURVES-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (i = 0; i < TM_NUM_WRED_B_NODE_CURVES; i++) {
+		ctl->rm_wred_b_node_curves[i].used = RM_FALSE;
+		ctl->rm_wred_b_node_curves[i].next_free_ind = i+1;
+	}
+	ctl->rm_wred_b_node_curves[TM_NUM_WRED_B_NODE_CURVES-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_WRED_C_NODE_CURVES; i++) {
+			ctl->rm_wred_c_node_curves[j][i].used = RM_FALSE;
+			ctl->rm_wred_c_node_curves[j][i].next_free_ind = i+1;
+		}
+		ctl->rm_wred_c_node_curves[j][TM_NUM_WRED_C_NODE_CURVES-1].next_free_ind =
+			(uint16_t)TM_INVAL;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+		ctl->rm_wred_port_curves[i].used = RM_FALSE;
+		ctl->rm_wred_port_curves[i].next_free_ind = i+1;
+	}
+	ctl->rm_wred_port_curves[TM_NUM_WRED_PORT_CURVES-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	/* nor used in HX/AX*/
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+			ctl->rm_wred_port_curves_cos[j][i].used = RM_FALSE;
+			ctl->rm_wred_port_curves_cos[j][i].next_free_ind = i+1;
+		}
+		ctl->rm_wred_port_curves_cos[j][TM_NUM_WRED_PORT_CURVES-1].next_free_ind =
+			(uint16_t)TM_INVAL;
+	}
+
+
+	for (i = 0; i < TM_NUM_QUEUE_DROP_PROF; i++) {
+		ctl->rm_queue_drop_profiles[i].used = RM_FALSE;
+		ctl->rm_queue_drop_profiles[i].next_free_ind = i+1;
+	}
+	ctl->rm_queue_drop_profiles[TM_NUM_QUEUE_DROP_PROF-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (i = 0; i < TM_NUM_A_NODE_DROP_PROF; i++) {
+		ctl->rm_a_node_drop_profiles[i].used = RM_FALSE;
+		ctl->rm_a_node_drop_profiles[i].next_free_ind = i+1;
+	}
+	ctl->rm_a_node_drop_profiles[TM_NUM_A_NODE_DROP_PROF-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (i = 0; i < TM_NUM_B_NODE_DROP_PROF; i++) {
+		ctl->rm_b_node_drop_profiles[i].used = RM_FALSE;
+		ctl->rm_b_node_drop_profiles[i].next_free_ind = i+1;
+	}
+	ctl->rm_b_node_drop_profiles[TM_NUM_B_NODE_DROP_PROF-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_C_NODE_DROP_PROF; i++) {
+			ctl->rm_c_node_drop_profiles[j][i].used = RM_FALSE;
+			ctl->rm_c_node_drop_profiles[j][i].next_free_ind = i+1;
+		}
+		ctl->rm_c_node_drop_profiles[j][TM_NUM_C_NODE_DROP_PROF-1].next_free_ind =
+			(uint16_t)TM_INVAL;
+	}
+
+	for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+		ctl->rm_port_drop_profiles[i].used = RM_FALSE;
+		ctl->rm_port_drop_profiles[i].next_free_ind = i+1;
+	}
+	ctl->rm_port_drop_profiles[TM_NUM_PORT_DROP_PROF-1].next_free_ind =
+		(uint16_t)TM_INVAL;
+
+	/* not for Hx/AX*/
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+			ctl->rm_port_drop_profiles_cos[j][i].used = RM_FALSE;
+			ctl->rm_port_drop_profiles_cos[j][i].next_free_ind = i+1;
+		}
+		ctl->rm_port_drop_profiles_cos[j][TM_NUM_PORT_DROP_PROF-1].next_free_ind =
+			(uint16_t)TM_INVAL;
+	}
+
+	/* Initiate counters */
+	ctl->rm_queue_cnt = total_queues;
+	ctl->rm_a_node_cnt = total_a_nodes;
+	ctl->rm_b_node_cnt = total_b_nodes;
+	ctl->rm_c_node_cnt = total_c_nodes;
+	ctl->rm_port_cnt = total_ports;
+
+	/* Copy total numbers of nodes per level */
+	ctl->rm_total_queues = total_queues;
+	ctl->rm_total_a_nodes = total_a_nodes;
+	ctl->rm_total_b_nodes = total_b_nodes;
+	ctl->rm_total_c_nodes = total_c_nodes;
+	ctl->rm_total_ports = total_ports;
+
+
+	/* Initiate free entries arrays */
+	for (i = 0; i < RM_MAX_PROFILES; i++)
+		ctl->rm_first_free_entry[i] = 0;
+
+	ctl->rm_last_free_entry[RM_WRED_Q_CURVE] = TM_NUM_WRED_QUEUE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_A_CURVE] = TM_NUM_WRED_A_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_B_CURVE] = TM_NUM_WRED_B_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_0] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_1] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_2] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_3] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_4] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_5] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_6] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_C_CURVE_COS_7] = TM_NUM_WRED_C_NODE_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE] = TM_NUM_WRED_PORT_CURVES;
+
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_0] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_1] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_2] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_3] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_4] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_5] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_6] = TM_NUM_WRED_PORT_CURVES;
+	ctl->rm_last_free_entry[RM_WRED_P_CURVE_COS_7] = TM_NUM_WRED_PORT_CURVES;
+
+	ctl->rm_last_free_entry[RM_Q_DROP_PRF] = TM_NUM_QUEUE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_A_DROP_PRF] = TM_NUM_A_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_B_DROP_PRF] = TM_NUM_B_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_0] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_1] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_2] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_3] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_4] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_5] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_6] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_C_DROP_PRF_COS_7] = TM_NUM_C_NODE_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF] = TM_NUM_PORT_DROP_PROF;
+
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_0] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_1] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_2] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_3] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_4] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_5] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_6] = TM_NUM_PORT_DROP_PROF;
+	ctl->rm_last_free_entry[RM_P_DROP_PRF_COS_7] = TM_NUM_PORT_DROP_PROF;
+
+	ctl->rm_free_nodes[RM_Q_LVL] = rm_new_chunk(0, total_queues, NULL);
+	ctl->rm_free_nodes[RM_A_LVL] = rm_new_chunk(0, total_a_nodes, NULL);
+	ctl->rm_free_nodes[RM_B_LVL] = rm_new_chunk(0, total_b_nodes, NULL);
+	ctl->rm_free_nodes[RM_C_LVL] = rm_new_chunk(0, total_c_nodes, NULL);
+
+	*hndl = ctl;
+
+out:
+	if ((rc) && (ctl))
+		rm_close((rmctl_t)ctl);
+
+	return rc;
+}
+
+
+/**
+ */
+int rm_close(rmctl_t hndl)
+{
+	int i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	ctl->magic = 0;
+
+	/* Free dynamically allocated arrays */
+	tm_free(ctl->rm_queue_array);
+	tm_free(ctl->rm_a_node_array);
+	tm_free(ctl->rm_b_node_array);
+	tm_free(ctl->rm_c_node_array);
+	tm_free(ctl->rm_port_array);
+
+	tm_free(ctl->rm_wred_queue_curves);
+	tm_free(ctl->rm_wred_a_node_curves);
+	tm_free(ctl->rm_wred_b_node_curves);
+	for (i = 0; i < RM_COS; i++)
+		tm_free(ctl->rm_wred_c_node_curves[i]);
+	tm_free(ctl->rm_wred_port_curves);
+	tm_free(ctl->rm_queue_drop_profiles);
+	tm_free(ctl->rm_a_node_drop_profiles);
+	tm_free(ctl->rm_b_node_drop_profiles);
+	for (i = 0; i < RM_COS; i++)
+		tm_free(ctl->rm_wred_port_curves_cos[i]);
+
+	for (i = 0; i < RM_COS; i++)
+		tm_free(ctl->rm_c_node_drop_profiles[i]);
+
+	tm_free(ctl->rm_port_drop_profiles);
+	for (i = 0; i < RM_COS; i++)
+		tm_free(ctl->rm_port_drop_profiles_cos[i]);
+
+
+	/* Free list of chunks */
+	clear_chunk_list(ctl->rm_free_nodes[RM_Q_LVL]);
+	clear_chunk_list(ctl->rm_free_nodes[RM_A_LVL]);
+	clear_chunk_list(ctl->rm_free_nodes[RM_B_LVL]);
+	clear_chunk_list(ctl->rm_free_nodes[RM_C_LVL]);
+
+	/* free rm handle */
+	tm_free(ctl);
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.h
new file mode 100644
index 0000000..98cf853
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_ctl.h
@@ -0,0 +1,68 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_CTL_H
+#define RM_CTL_H
+
+#include "rm_interface.h"
+
+/** Create RM handle.
+ *
+ *   @param[in]     hlog			         generic log handle.
+ *   @param[in]		total_ports		         Total num Ports.
+ *   @param[in]		total_c_nodes		     Total num C-nodes.
+ *   @param[in]		total_b_nodes		     Total num B-nodes.
+ *   @param[in]		total_a_nodes		     Total num A-nodes.
+ *   @param[in]		total_queues		     Total num Queues.
+ *   @param[out]    hndl					RM handle pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -ENOMEM when out of memory space.
+ */
+int rm_open(uint8_t total_ports,
+			uint16_t total_c_nodes,
+			uint16_t total_b_nodes,
+			uint16_t total_a_nodes,
+			uint32_t total_queues,
+			rmctl_t *hndl);
+
+
+/** Close RM handle.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle
+ */
+int rm_close(rmctl_t hndl);
+
+
+#endif   /* RM_CTL_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.c
new file mode 100644
index 0000000..ed39cea
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.c
@@ -0,0 +1,753 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_internal_types.h"
+#include "rm_free.h"
+#include "rm_chunk.h"
+#include "tm/core/tm_core_types.h"
+#include "tm/core/tm_hw_configuration_interface.h"
+
+/**
+ */
+int rm_free_queue(rmctl_t hndl, uint32_t queue_ind)
+{
+	struct rm_node *node = NULL;
+	uint32_t parent_ind;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (queue_ind >= (ctl->rm_total_queues))
+		return -EFAULT;
+
+	node = &(ctl->rm_queue_array[queue_ind]);
+	if (node->used != RM_TRUE)
+		return -ENOMSG;
+
+	parent_ind = node->parent_ind;
+
+	/* Insert as free node */
+	node->used = RM_FALSE;
+	ctl->rm_queue_cnt++;
+	node->next_free_ind = ctl->rm_a_node_array[parent_ind].first_child;
+	ctl->rm_a_node_array[parent_ind].first_child = queue_ind;
+	ctl->rm_a_node_array[parent_ind].cnt++;
+
+	/* Was empty */
+	if (ctl->rm_a_node_array[parent_ind].last_child == (uint16_t)TM_INVAL)
+		ctl->rm_a_node_array[parent_ind].last_child = queue_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_a_node(rmctl_t hndl, uint32_t a_node_ind, uint32_t range)
+{
+	struct rm_node *node = NULL;
+	uint32_t parent_ind;
+	uint32_t cur_ind;
+	uint32_t min_ind;
+	int rc = 0;
+	uint32_t i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (a_node_ind >= ctl->rm_total_a_nodes)
+		return -EFAULT;
+
+	node = &(ctl->rm_a_node_array[a_node_ind]);
+	if (node->used != RM_TRUE)
+		return -ENOMSG;
+
+	if (node->cnt < range) /* any child still in use */
+		return -EBUSY;
+
+	parent_ind = node->parent_ind;
+
+	/* Insert as free node */
+	node->used = RM_FALSE;
+	ctl->rm_a_node_cnt++;
+	node->next_free_ind = ctl->rm_b_node_array[parent_ind].first_child;
+	ctl->rm_b_node_array[parent_ind].first_child = a_node_ind;
+	ctl->rm_b_node_array[parent_ind].cnt++;
+
+	/* find the lowest index in range */
+	cur_ind = node->first_child;
+	min_ind = cur_ind;
+	for (i = 1; i < range; i++) {
+		cur_ind = ctl->rm_queue_array[cur_ind].next_free_ind;
+		if (min_ind > cur_ind)
+			min_ind = cur_ind;
+	}
+	rc = rm_release_chunk(hndl, RM_Q_LVL, node->cnt, min_ind);
+	if (rc)
+		return rc;
+
+	/* Was empty */
+	if (ctl->rm_b_node_array[parent_ind].last_child == (uint16_t)TM_INVAL)
+		ctl->rm_b_node_array[parent_ind].last_child = a_node_ind;
+
+	return rc;
+}
+
+
+/**
+ */
+int rm_free_b_node(rmctl_t hndl, uint32_t b_node_ind, uint32_t range)
+{
+	struct rm_node *node = NULL;
+	uint32_t parent_ind;
+	uint32_t cur_ind;
+	uint32_t min_ind;
+	int rc = 0;
+	uint32_t i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (b_node_ind >= ctl->rm_total_b_nodes)
+		return -EFAULT;
+
+	node = &(ctl->rm_b_node_array[b_node_ind]);
+	if (node->used != RM_TRUE)
+		return -ENOMSG;
+
+	if (node->cnt < range) /* any child still in use */
+		return -EBUSY;
+
+	parent_ind = node->parent_ind;
+
+	/* Insert as free node */
+	node->used = RM_FALSE;
+	ctl->rm_b_node_cnt++;
+	node->next_free_ind = ctl->rm_c_node_array[parent_ind].first_child;
+	ctl->rm_c_node_array[parent_ind].first_child = b_node_ind;
+	ctl->rm_c_node_array[parent_ind].cnt++;
+
+	/* find the lowest index in range */
+	cur_ind = node->first_child;
+	min_ind = cur_ind;
+	for (i = 1; i < range; i++) {
+		cur_ind = ctl->rm_a_node_array[cur_ind].next_free_ind;
+		if (min_ind > cur_ind)
+			min_ind = cur_ind;
+	}
+	rc = rm_release_chunk(hndl, RM_A_LVL, node->cnt, min_ind);
+	if (rc)
+		return rc;
+
+	/* Was empty */
+	if (ctl->rm_c_node_array[parent_ind].last_child == (uint16_t)TM_INVAL)
+		ctl->rm_c_node_array[parent_ind].last_child = b_node_ind;
+
+	return rc;
+}
+
+
+/**
+ */
+int rm_free_c_node(rmctl_t hndl, uint32_t c_node_ind, uint32_t range)
+{
+	struct rm_node *node = NULL;
+	uint32_t parent_ind;
+	uint32_t cur_ind;
+	uint32_t min_ind;
+	int rc = 0;
+	uint32_t i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (c_node_ind >= ctl->rm_total_c_nodes)
+		return -EFAULT;
+
+	node = &(ctl->rm_c_node_array[c_node_ind]);
+	if (node->used != RM_TRUE)
+		return -ENOMSG;
+
+	if (node->cnt < range)   /* any child still in use */
+		return -EBUSY;
+
+	parent_ind = node->parent_ind;
+
+	/* Insert as free node */
+	node->used = RM_FALSE;
+	ctl->rm_c_node_cnt++;
+	node->next_free_ind = ctl->rm_port_array[parent_ind].first_child;
+	ctl->rm_port_array[parent_ind].first_child = c_node_ind;
+	ctl->rm_port_array[parent_ind].cnt++;
+
+	/* find the lowest index in range */
+	cur_ind = node->first_child;
+	min_ind = cur_ind;
+	for (i = 1; i < range; i++) {
+		cur_ind = ctl->rm_b_node_array[cur_ind].next_free_ind;
+		if (min_ind > cur_ind)
+			min_ind = cur_ind;
+	}
+	rc = rm_release_chunk(hndl, RM_B_LVL, node->cnt, min_ind);
+	if (rc)
+		return rc;
+
+	/* Was empty */
+	if (ctl->rm_port_array[parent_ind].last_child == (uint16_t)TM_INVAL)
+		ctl->rm_port_array[parent_ind].last_child = c_node_ind;
+
+	return rc;
+}
+
+
+/**
+ */
+int rm_free_port(rmctl_t hndl, uint8_t port_ind, uint32_t range)
+{
+	struct rm_node *node = NULL;
+	uint32_t cur_ind;
+	uint32_t min_ind;
+	int rc = 0;
+	uint32_t i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (port_ind >= ctl->rm_total_ports)
+		return -EFAULT;
+
+	node = &(ctl->rm_port_array[port_ind]);
+	if (node->used != RM_TRUE)
+		return -ENOMSG;
+
+	if (node->cnt < range) /* any child still in use */
+		return -EBUSY;
+
+	/* Insert as free port */
+	node->used = RM_FALSE;
+	ctl->rm_port_cnt++;
+
+	/* find the lowest index in range */
+	cur_ind = node->first_child;
+	min_ind = cur_ind;
+	for (i = 1; i < range; i++) {
+		cur_ind = ctl->rm_c_node_array[cur_ind].next_free_ind;
+		if (min_ind > cur_ind)
+			min_ind = cur_ind;
+	}
+	/* Manage c-nodes chunks */
+	rc = rm_release_chunk(hndl, RM_C_LVL, node->cnt, min_ind);
+	if (rc)
+		return rc;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_queue_curve(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_WRED_QUEUE_CURVES)
+		return -EFAULT;
+
+	if (ctl->rm_wred_queue_curves[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_queue_curves[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_WRED_Q_CURVE] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_WRED_Q_CURVE] = entry_ind;
+	else
+		ctl->rm_wred_queue_curves[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_WRED_Q_CURVE];
+
+	ctl->rm_first_free_entry[RM_WRED_Q_CURVE] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_a_node_curve(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_WRED_A_NODE_CURVES)
+		return -EFAULT;
+
+	if (ctl->rm_wred_a_node_curves[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_a_node_curves[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_WRED_A_CURVE] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_WRED_A_CURVE] = entry_ind;
+	else
+		ctl->rm_wred_a_node_curves[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_WRED_A_CURVE];
+
+	ctl->rm_first_free_entry[RM_WRED_A_CURVE] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_b_node_curve(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_WRED_B_NODE_CURVES)
+		return -EFAULT;
+
+	if (ctl->rm_wred_b_node_curves[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_b_node_curves[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_WRED_B_CURVE] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_WRED_B_CURVE] = entry_ind;
+	else
+		ctl->rm_wred_b_node_curves[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_WRED_B_CURVE];
+
+	ctl->rm_first_free_entry[RM_WRED_B_CURVE] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_c_node_curve(rmctl_t hndl, uint8_t cos, uint16_t entry_ind)
+{
+	enum rm_prf_level ptr_lvl;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_WRED_C_NODE_CURVES)
+		return -EFAULT;
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_C_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_C_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_C_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_C_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_C_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_C_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_C_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_C_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT; /* cos >= TM_WRED_COS */
+	}
+
+	if (ctl->rm_wred_c_node_curves[cos][entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_c_node_curves[cos][entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[ptr_lvl] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[ptr_lvl] = entry_ind;
+	else
+		ctl->rm_wred_c_node_curves[cos][entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[ptr_lvl];
+
+	ctl->rm_first_free_entry[ptr_lvl] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_port_curve(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_WRED_PORT_CURVES)
+		return -EFAULT;
+
+	if (ctl->rm_wred_port_curves[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_port_curves[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_WRED_P_CURVE] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_WRED_P_CURVE] = entry_ind;
+	else
+		ctl->rm_wred_port_curves[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_WRED_P_CURVE];
+
+	ctl->rm_first_free_entry[RM_WRED_P_CURVE] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_wred_port_curve_cos(rmctl_t hndl, uint8_t cos, uint16_t entry_ind)
+{
+	enum rm_prf_level ptr_lvl;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (!ctl)
+		return -EINVAL;
+	if (ctl->magic != RM_MAGIC)
+		return -EBADF;
+
+	if (entry_ind >= TM_NUM_WRED_PORT_CURVES)
+		return -EFAULT;
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_P_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_P_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_P_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_P_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_P_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_P_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_P_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_P_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT; /* cos >= TM_WRED_COS */
+	}
+
+	if (ctl->rm_wred_port_curves_cos[cos][entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_wred_port_curves_cos[cos][entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[ptr_lvl] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[ptr_lvl] = entry_ind;
+	else
+		ctl->rm_wred_port_curves_cos[cos][entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[ptr_lvl];
+
+	ctl->rm_first_free_entry[ptr_lvl] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_queue_drop_profile(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_QUEUE_DROP_PROF)
+		return -EFAULT;
+
+	if (ctl->rm_queue_drop_profiles[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_queue_drop_profiles[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_Q_DROP_PRF] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_Q_DROP_PRF] = entry_ind;
+	else
+		ctl->rm_queue_drop_profiles[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_Q_DROP_PRF];
+
+	ctl->rm_first_free_entry[RM_Q_DROP_PRF] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_a_node_drop_profile(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_A_NODE_DROP_PROF)
+		return -EFAULT;
+
+	if (ctl->rm_a_node_drop_profiles[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_a_node_drop_profiles[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_A_DROP_PRF] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_A_DROP_PRF] = entry_ind;
+	else
+		ctl->rm_a_node_drop_profiles[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_A_DROP_PRF];
+
+	ctl->rm_first_free_entry[RM_A_DROP_PRF] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_b_node_drop_profile(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_B_NODE_DROP_PROF)
+		return -EFAULT;
+
+	if (ctl->rm_b_node_drop_profiles[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_b_node_drop_profiles[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_B_DROP_PRF] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_B_DROP_PRF] = entry_ind;
+	else
+		ctl->rm_b_node_drop_profiles[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_B_DROP_PRF];
+
+	ctl->rm_first_free_entry[RM_B_DROP_PRF] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_c_node_drop_profile(rmctl_t hndl, uint8_t cos, uint16_t entry_ind)
+{
+	enum rm_prf_level ptr_lvl;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_C_NODE_DROP_PROF)
+		return -EFAULT;
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_C_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_C_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_C_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_C_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_C_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_C_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_C_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_C_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT; /* cos >= TM_WRED_COS */
+	}
+
+	if (ctl->rm_c_node_drop_profiles[cos][entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_c_node_drop_profiles[cos][entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[ptr_lvl] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[ptr_lvl] = entry_ind;
+	else
+		ctl->rm_c_node_drop_profiles[cos][entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[ptr_lvl];
+
+	ctl->rm_first_free_entry[ptr_lvl] = entry_ind;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_free_port_drop_profile(rmctl_t hndl, uint16_t entry_ind)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_PORT_DROP_PROF)
+		return -EFAULT;
+
+	if (ctl->rm_port_drop_profiles[entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_port_drop_profiles[entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[RM_WRED_P_CURVE] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[RM_WRED_P_CURVE] = entry_ind;
+	else
+		ctl->rm_port_drop_profiles[entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[RM_WRED_P_CURVE];
+
+	ctl->rm_first_free_entry[RM_WRED_P_CURVE] = entry_ind;
+
+	return 0;
+}
+
+
+/* not used for HX/AX*/
+/**
+ */
+int rm_free_port_drop_profile_cos(rmctl_t hndl, uint8_t cos, uint16_t entry_ind)
+{
+	enum rm_prf_level ptr_lvl;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (!ctl)
+		return -EINVAL;
+	if (ctl->magic != RM_MAGIC)
+		return -EBADF;
+
+	if (entry_ind >= TM_NUM_PORT_DROP_PROF)
+		return -EFAULT;
+
+	switch (cos) {
+	case 0:
+		ptr_lvl = RM_WRED_P_CURVE_COS_0;
+		break;
+	case 1:
+		ptr_lvl = RM_WRED_P_CURVE_COS_1;
+		break;
+	case 2:
+		ptr_lvl = RM_WRED_P_CURVE_COS_2;
+		break;
+	case 3:
+		ptr_lvl = RM_WRED_P_CURVE_COS_3;
+		break;
+	case 4:
+		ptr_lvl = RM_WRED_P_CURVE_COS_4;
+		break;
+	case 5:
+		ptr_lvl = RM_WRED_P_CURVE_COS_5;
+		break;
+	case 6:
+		ptr_lvl = RM_WRED_P_CURVE_COS_6;
+		break;
+	case 7:
+		ptr_lvl = RM_WRED_P_CURVE_COS_7;
+		break;
+	default:
+		return -EFAULT; /* cos >= TM_WRED_COS */
+	}
+
+	if (ctl->rm_port_drop_profiles_cos[cos][entry_ind].used != RM_TRUE)
+		return -ENOMSG;
+
+	/* Insert as free entry */
+	ctl->rm_port_drop_profiles_cos[cos][entry_ind].used = RM_FALSE;
+
+	/* Was empty */
+	if (ctl->rm_last_free_entry[ptr_lvl] == (uint16_t)TM_INVAL)
+		ctl->rm_last_free_entry[ptr_lvl] = entry_ind;
+	else
+		ctl->rm_port_drop_profiles_cos[cos][entry_ind].next_free_ind =
+			ctl->rm_first_free_entry[ptr_lvl];
+
+	ctl->rm_first_free_entry[ptr_lvl] = entry_ind;
+
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.h
new file mode 100644
index 0000000..7452dde
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_free.h
@@ -0,0 +1,304 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_FREE_H
+#define RM_FREE_H
+
+#include "rm_interface.h"
+
+/** Free Queue.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		queue_ind	Queue index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if queue_ind is out of range.
+ *   @retval -ENOMSG if queue_ind is already free.
+ */
+int rm_free_queue(rmctl_t hndl, uint32_t queue_ind);
+
+
+/** Free A-node.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		a_node_ind	A-node index.
+ *   @param[in]		range	    Number of children Queues in range.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if a_node_ind is out of range.
+ *   @retval -ENOMSG if a_node_ind is already free.
+ *   @retval EBUSY if any of children is still in use.
+ */
+int rm_free_a_node(rmctl_t hndl, uint32_t a_node_ind, uint32_t range);
+
+
+/** Free B-node.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		b_node_ind	B-node index.
+ *   @param[in]		range	    Number of children A-nodes in range.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if b_node_ind is out of range.
+ *   @retval -ENOMSG if b_node_ind is already free.
+ *   @retval EBUSY if any of children is still in use.
+ */
+int rm_free_b_node(rmctl_t hndl, uint32_t b_node_ind, uint32_t range);
+
+
+/** Free C-node.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		c_node_ind	C-node index.
+ *   @param[in]		range	    Number of children B-nodes in range.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if c_node_ind is out of range.
+ *   @retval -ENOMSG if c_node_ind is already free.
+ *   @retval EBUSY if any of children is still in use.
+ */
+int rm_free_c_node(rmctl_t hndl, uint32_t c_node_ind, uint32_t range);
+
+
+/** Free Port.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		port_ind	Port index.
+ *   @param[in]		range	    Number of children C-nodes in range.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if port_ind is out of range.
+ *   @retval -ENOMSG if port_ind is already free.
+ *	 @retval -ENOMEM when out of memory space.
+ *   @retval EBUSY if any of children is still in use.
+ */
+int rm_free_port(rmctl_t hndl, uint8_t port_ind, uint32_t range);
+
+
+/** Free WRED Queue Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_queue_curve(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free WRED A-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_a_node_curve(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free WRED B-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_b_node_curve(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free WRED C-node Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos			CoS of RED Curve.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_c_node_curve(rmctl_t hndl, uint8_t cos, uint16_t entry_ind);
+
+
+/** Free WRED Port Curve entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_port_curve(rmctl_t hndl, uint16_t entry_ind);
+
+/* not used for HX/AX*/
+/** Free WRED Port Curve entry per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_wred_port_curve_cos(rmctl_t hndl, uint8_t cos, uint16_t entry_ind);
+
+
+
+/** Free Queue Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_queue_drop_profile(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free A-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_a_node_drop_profile(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free B-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_b_node_drop_profile(rmctl_t hndl, uint16_t entry_ind);
+
+
+/** Free C-node Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos			CoS of RED Curve.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_c_node_drop_profile(rmctl_t hndl, uint8_t cos, uint16_t entry_ind);
+
+
+/** Free Port Drop Profile entry.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_port_drop_profile(rmctl_t hndl, uint16_t entry_ind);
+
+
+/* not used for HX/AX */
+/** Free Port Drop Profile entry per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos		    CoS of RED Curve.
+ *   @param[in]		entry_ind	Entry index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ *   @retval -ENOMSG if entry_ind is already free.
+ */
+int rm_free_port_drop_profile_cos(rmctl_t hndl, uint8_t cos, uint16_t entry_ind);
+
+
+#endif   /* RM_FREE_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_interface.h
new file mode 100644
index 0000000..d50b2d1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_interface.h
@@ -0,0 +1,70 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_INTERFACE_H
+#define RM_INTERFACE_H
+
+#include "common/mv_sw_if.h"
+
+
+/** An rm instance handle type.
+ */
+#define rmctl_t void *
+
+#define RM_FALSE 0
+#define RM_TRUE  1
+
+
+/**
+ */
+enum rm_level {
+	RM_C_LVL = 0,
+	RM_B_LVL,
+	RM_A_LVL,
+	RM_Q_LVL
+};
+
+
+/** RM list element data structure.
+ */
+struct rm_list_elem {
+	uint32_t  index;
+	uint8_t   level;
+	struct rm_list_elem *next;
+};
+
+
+/** RM list data structure.
+ */
+struct rm_list {
+	struct rm_list_elem *next_ptr;
+	struct rm_list_elem *first;
+};
+
+
+#endif   /* RM_INTERFACE_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_internal_types.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_internal_types.h
new file mode 100644
index 0000000..57a7179
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_internal_types.h
@@ -0,0 +1,184 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_INTERNAL_TYPES_H
+#define RM_INTERNAL_TYPES_H
+
+#include "tm/core/tm_core_types.h"
+
+/*nesessary fo RM_HANDLE macro*/
+/** Magic number used to determine struct rmctl_t validity.
+ */
+#define RM_MAGIC 0x1EDA5D
+
+
+/* following macro declares and checks validity of rmctl */
+#define DECLARE_RM_HANDLE(handle, value)	struct rmctl *handle = (struct rmctl *)value;
+
+#define CHECK_RM_HANDLE(handle)	\
+{ \
+	if (!handle) \
+		return -EINVAL; \
+	if (handle->magic != RM_MAGIC) \
+		return -EBADF; \
+}
+
+#define RM_COS   8
+
+#define chunk_ptr   struct rm_chunk*
+
+/**
+ */
+enum rm_prf_level {
+	RM_WRED_Q_CURVE = 0,
+	RM_WRED_A_CURVE,
+	RM_WRED_B_CURVE,
+	RM_WRED_C_CURVE_COS_0,
+	RM_WRED_C_CURVE_COS_1,
+	RM_WRED_C_CURVE_COS_2,
+	RM_WRED_C_CURVE_COS_3,
+	RM_WRED_C_CURVE_COS_4,
+	RM_WRED_C_CURVE_COS_5,
+	RM_WRED_C_CURVE_COS_6,
+	RM_WRED_C_CURVE_COS_7,
+	RM_WRED_P_CURVE,
+	RM_WRED_P_CURVE_COS_0,
+	RM_WRED_P_CURVE_COS_1,
+	RM_WRED_P_CURVE_COS_2,
+	RM_WRED_P_CURVE_COS_3,
+	RM_WRED_P_CURVE_COS_4,
+	RM_WRED_P_CURVE_COS_5,
+	RM_WRED_P_CURVE_COS_6,
+	RM_WRED_P_CURVE_COS_7,
+	/*----*/
+	RM_Q_DROP_PRF,
+	RM_A_DROP_PRF,
+	RM_B_DROP_PRF,
+	RM_C_DROP_PRF_COS_0,
+	RM_C_DROP_PRF_COS_1,
+	RM_C_DROP_PRF_COS_2,
+	RM_C_DROP_PRF_COS_3,
+	RM_C_DROP_PRF_COS_4,
+	RM_C_DROP_PRF_COS_5,
+	RM_C_DROP_PRF_COS_6,
+	RM_C_DROP_PRF_COS_7,
+	RM_P_DROP_PRF,
+	RM_P_DROP_PRF_COS_0,
+	RM_P_DROP_PRF_COS_1,
+	RM_P_DROP_PRF_COS_2,
+	RM_P_DROP_PRF_COS_3,
+	RM_P_DROP_PRF_COS_4,
+	RM_P_DROP_PRF_COS_5,
+	RM_P_DROP_PRF_COS_6,
+	RM_P_DROP_PRF_COS_7,
+	RM_MAX_PROFILES
+};
+
+
+
+
+/** RM node data structure.
+ */
+struct rm_node {
+	uint8_t   used:1;
+	uint16_t  parent_ind:14;
+	uint16_t  next_free_ind;
+	/* Children */
+	uint32_t cnt;
+	uint16_t  first_child;   /* Head */
+	uint16_t  last_child;    /* Tail */
+} __ATTRIBUTE_PACKED__;
+
+
+/** RM entry data structure.
+ */
+struct rm_entry {
+	uint8_t   used:1;
+	uint32_t  next_free_ind;
+} __ATTRIBUTE_PACKED__;
+
+
+/** RM chunk data structure.
+ */
+struct rm_chunk {
+	uint32_t  index;
+	uint32_t  size;
+	struct rm_chunk *next_free;
+};
+
+
+/** Resource Manger handle struct.
+ */
+struct rmctl {
+	uint32_t magic;
+	/* RM node arrays */
+	struct rm_node *rm_queue_array;
+	struct rm_node *rm_a_node_array;
+	struct rm_node *rm_b_node_array;
+	struct rm_node *rm_c_node_array;
+	struct rm_node *rm_port_array;
+
+	/* Statistics - total num of free nodes per level */
+	uint8_t  rm_port_cnt;
+	uint16_t rm_c_node_cnt;
+	uint16_t rm_b_node_cnt;
+	uint16_t rm_a_node_cnt;
+	uint32_t rm_queue_cnt;
+
+	/* RM entry arrays */
+	struct rm_entry *rm_wred_queue_curves;
+	struct rm_entry *rm_wred_a_node_curves;
+	struct rm_entry *rm_wred_b_node_curves;
+	struct rm_entry *rm_wred_c_node_curves[RM_COS];
+	struct rm_entry *rm_wred_port_curves;
+	struct rm_entry *rm_wred_port_curves_cos[RM_COS];
+/*----*/
+	struct rm_entry *rm_queue_drop_profiles;
+	struct rm_entry *rm_a_node_drop_profiles;
+	struct rm_entry *rm_b_node_drop_profiles;
+	struct rm_entry *rm_c_node_drop_profiles[RM_COS];
+	struct rm_entry *rm_port_drop_profiles;
+	struct rm_entry *rm_port_drop_profiles_cos[RM_COS];
+/*----*/
+
+	uint32_t rm_first_free_entry[RM_MAX_PROFILES]; /* Heads */
+	uint32_t rm_last_free_entry[RM_MAX_PROFILES];  /* Tails */
+
+	/* Total number of nodes within each level */
+	uint8_t  rm_total_ports;   /**< total ports number */
+	uint16_t rm_total_c_nodes; /**< total c_nodes number */
+	uint16_t rm_total_b_nodes; /**< total b_nodes number */
+	uint16_t rm_total_a_nodes; /**< total a_nodes number */
+	uint32_t rm_total_queues;  /**< total queues number */
+
+	/* Internal DB */
+	chunk_ptr rm_free_nodes[4]; /* from RM_Q_LVL to RM_C_LVL, RM_P_LVL not used inside RM */
+};
+
+
+#endif   /* RM_INTERNAL_TYPES_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.c
new file mode 100644
index 0000000..4ca4bb0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.c
@@ -0,0 +1,179 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_list.h"
+#include "tm/core/tm_os_interface.h"
+
+/* needed for RM_HANDLE  but not nesessary for the code ???*/
+#include "rm_internal_types.h"
+
+
+/**
+ */
+int rm_list_create(rmctl_t hndl, struct rm_list **list_ptr)
+{
+	struct rm_list *list = NULL;
+
+	list = (struct rm_list *)tm_malloc(sizeof(struct rm_list));
+	if (list == NULL)
+		return -ENOMEM;
+
+	list->next_ptr = NULL;
+	list->first = NULL;
+
+	*list_ptr = list;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_list_add_index(rmctl_t hndl, struct rm_list *list, uint32_t index,
+	uint8_t level)
+{
+	struct rm_list_elem *elem = NULL;
+
+	if (!list)
+		return -EFAULT;
+
+	elem = tm_malloc(sizeof(struct rm_list_elem));
+	if (elem == NULL)
+		return -ENOMEM;
+
+	elem->index = index;
+	elem->level = level;
+	elem->next = list->first;
+
+	list->next_ptr = elem;
+	list->first = elem;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_list_next_index(rmctl_t hndl, struct rm_list *list, uint32_t *index,
+	uint8_t *level)
+{
+	if (!list)
+		return -EFAULT;
+
+	if (list->next_ptr == NULL) {
+		*index = 0xFFFFFFFF;
+		*level = 0xFF;
+		/* reset next pointer to start if the end of the list have
+			* been reached */
+		list->next_ptr = list->first;
+		return 0;
+	}
+
+	*index = list->next_ptr->index;
+	*level = list->next_ptr->level;
+	list->next_ptr = list->next_ptr->next;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_list_reset_to_start(rmctl_t hndl, struct rm_list *list, uint32_t *index, uint8_t *level)
+{
+	if (!list)
+		return -EFAULT;
+
+	list->next_ptr = list->first;
+
+	if (list->first) {
+		*index = list->first->index;
+		*level = list->first->level;
+		list->next_ptr = list->first->next;
+	} else {
+		*index = 0xFFFFFFFF;
+		*level = 0xFF;
+	}
+	return 0;
+}
+
+
+/**
+ */
+int rm_list_del_index(rmctl_t hndl, struct rm_list *list, uint32_t index,
+	uint8_t level)
+{
+	struct rm_list_elem *elem = NULL;
+	struct rm_list_elem *prev = NULL;
+
+	if (!list)
+		return -EFAULT;
+
+	/* find element */
+	list->next_ptr = list->first;
+	while (list->next_ptr) {
+		if ((list->next_ptr->index == index)
+			&& (list->next_ptr->level == level)) {
+			elem = list->next_ptr;
+			if (prev == NULL) /* first in the list */
+				list->first = elem->next;
+			else /* not a first */
+				prev->next = elem->next;
+			tm_free(elem);
+			list->next_ptr = list->first; /* reset to start */
+			return 0;
+		}
+		prev = list->next_ptr;
+		list->next_ptr = list->next_ptr->next;
+	}
+
+	if (!elem)
+		return -EBADMSG;
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_list_delete(rmctl_t hndl, struct rm_list *list)
+{
+	struct rm_list_elem *elem = NULL;
+
+	if (!list)
+		return -EFAULT;
+
+	while (list->first) {
+		elem = list->first;
+		list->first = elem->next;
+		tm_free(elem);
+	}
+	tm_free(list);
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.h
new file mode 100644
index 0000000..a9fade1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_list.h
@@ -0,0 +1,139 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_LIST_H
+#define RM_LIST_H
+
+#include "rm_interface.h"
+
+
+/** Create list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[out]	list		      Pointer to list.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -ENOMEM if no free space.
+ */
+int rm_list_create(rmctl_t hndl, struct rm_list **list);
+
+
+/** Add index to list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]	    list		      Pointer to list.
+ *   @param[in]	    index		      Index of element to be added.
+ *   @param[in]	    level		      Level of element to be added.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if list is an invalid pointer.
+ *   @retval -ENOMEM if no free space.
+ */
+int rm_list_add_index(rmctl_t hndl, struct rm_list *list,
+						uint32_t index,
+						uint8_t level);
+
+
+/** Next index in the list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]	    list		      Pointer to list.
+ *   @param[out]	index		      Next index in list.
+ *   @param[out]	level		      Level of next index in list.
+ *
+ *   @note   At each call the next index in list will be returned. If
+ *   other list function called in process (add or delete), next index will start from
+ *   the head of list. When end of the list index will get value NULL.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if list is an invalid pointer.
+ */
+int rm_list_next_index(rmctl_t hndl, struct rm_list *list,
+						uint32_t *index,
+						uint8_t *level);
+
+
+/** Reset the pointer of next index in the list to start of the list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]	    list		      Pointer to list.
+ *   @param[out]	index		      First index in list.
+ *   @param[out]	level		      Level of first index in list.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if list is an invalid pointer.
+ */
+int rm_list_reset_to_start(rmctl_t hndl, struct rm_list *list, uint32_t *index, uint8_t *level);
+
+
+/** Delete index from the list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]	    list		      Pointer to list.
+ *   @param[in]	    index		      Index in list to be deleted.
+ *   @param[in]	    level		      Level in list to be deleted.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if list is an invalid pointer.
+ *   @retval -EBADMSG if index is not in list.
+ */
+int rm_list_del_index(rmctl_t hndl, struct rm_list *list,
+						uint32_t index,
+						uint8_t level);
+
+
+/** Forced delete of the list.
+ *
+ *   @param[in]		hndl			  Resource Manager handle.
+ *   @param[in]	    list		      Pointer to list.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if list is an invalid pointer.
+ */
+int rm_list_delete(rmctl_t hndl, struct rm_list *list);
+
+
+#endif   /* RM_LIST_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.c
new file mode 100644
index 0000000..66274b0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.c
@@ -0,0 +1,335 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_internal_types.h"
+#include "rm_reorder.h"
+#include "tm/core/tm_defs.h"
+
+/**
+ */
+int rm_nodes_move(rmctl_t hndl,
+		enum rm_level level,
+		uint32_t from_node_ind,
+		uint32_t to_node_ind,
+		uint32_t number_of_children,
+		uint32_t first_child_to_move)
+{
+	struct rm_node *node = NULL;
+	struct rm_node *from_node = NULL;
+	struct rm_node *to_node = NULL;
+	uint32_t prev = 0;
+	uint32_t i;
+	uint32_t j;
+	uint32_t last_child_to_move = first_child_to_move + number_of_children - 1;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	switch (level) {
+	case RM_Q_LVL:
+	if ((from_node_ind >= ctl->rm_total_a_nodes) ||
+	(to_node_ind >= ctl->rm_total_a_nodes))
+		return -EFAULT;
+
+	from_node = &(ctl->rm_a_node_array[from_node_ind]);
+	to_node = &(ctl->rm_a_node_array[to_node_ind]);
+
+	for (i = first_child_to_move; i <= last_child_to_move; i++) {
+		node = &(ctl->rm_queue_array[i]);
+		node->parent_ind = to_node_ind;
+		if (node->used == RM_FALSE) {
+			/* pop the node form the list of free nodes under the "from_node" */
+			for (j = from_node->first_child; j != TM_INVAL;
+				j = ctl->rm_queue_array[j].next_free_ind) {
+				if (j == i) {
+					if (j == from_node->first_child) /* head */
+						from_node->first_child = ctl->rm_queue_array[j].next_free_ind;
+					else
+						ctl->rm_queue_array[prev].next_free_ind =
+						ctl->rm_queue_array[j].next_free_ind;
+					from_node->cnt--;
+					if (from_node->cnt == 0)
+						from_node->last_child = (uint16_t) TM_INVAL;
+					if (from_node->last_child == j)
+						from_node->last_child = prev;
+					break; /* for */
+				}
+				prev = j;
+			}
+			if (j == TM_INVAL)
+				return -ENOBUFS;
+
+			/* move the node to the list of free nodes under the "to_node" */
+			ctl->rm_queue_array[j].next_free_ind = to_node->first_child;
+			to_node->first_child = j;
+			if (to_node->cnt == 0) /* empty */
+			to_node->last_child = j;
+			to_node->cnt++;
+		}
+	/* no action required when the node in use */
+	}
+	break; /* switch */
+	case RM_A_LVL:
+	if ((from_node_ind >= ctl->rm_total_b_nodes) ||
+	(to_node_ind >= ctl->rm_total_b_nodes))
+		return -EFAULT;
+
+	from_node = &(ctl->rm_b_node_array[from_node_ind]);
+	to_node = &(ctl->rm_b_node_array[to_node_ind]);
+
+	for (i = first_child_to_move; i <= last_child_to_move; i++) {
+		node = &(ctl->rm_a_node_array[i]);
+		node->parent_ind = to_node_ind;
+		if (node->used == RM_FALSE) {
+			/* pop the node form the list of free nodes under the "from_node" */
+			for (j = from_node->first_child; j != TM_INVAL;
+				j = ctl->rm_a_node_array[j].next_free_ind) {
+				if (j == i) {
+					if (j == from_node->first_child) /* head */
+						from_node->first_child = ctl->rm_a_node_array[j].next_free_ind;
+					else
+						ctl->rm_a_node_array[prev].next_free_ind =
+						ctl->rm_a_node_array[j].next_free_ind;
+					from_node->cnt--;
+					if (from_node->cnt == 0)
+						from_node->last_child = (uint16_t) TM_INVAL;
+					if (from_node->last_child == j)
+						from_node->last_child = prev;
+					break; /* for */
+				}
+				prev = j;
+			}
+			if (j == TM_INVAL)
+				return -ENOBUFS;
+
+			/* move the node to the list of free nodes under the "to_node" */
+			ctl->rm_a_node_array[j].next_free_ind = to_node->first_child;
+			to_node->first_child = j;
+			if (to_node->cnt == 0) /* empty */
+			to_node->last_child = j;
+			to_node->cnt++;
+		}
+		/* no action required when the node in use */
+	}
+	break; /* switch */
+	case RM_B_LVL:
+	if ((from_node_ind >= ctl->rm_total_c_nodes) ||
+	(to_node_ind >= ctl->rm_total_c_nodes))
+		return -EFAULT;
+
+	from_node = &(ctl->rm_c_node_array[from_node_ind]);
+	to_node = &(ctl->rm_c_node_array[to_node_ind]);
+
+	for (i = first_child_to_move; i <= last_child_to_move; i++) {
+		node = &(ctl->rm_b_node_array[i]);
+		node->parent_ind = to_node_ind;
+		if (node->used == RM_FALSE) {
+			/* pop the node form the list of free nodes under the "from_node" */
+			for (j = from_node->first_child; j != TM_INVAL;
+				j = ctl->rm_b_node_array[j].next_free_ind) {
+				if (j == i) {
+					if (j == from_node->first_child) /* head */
+						from_node->first_child = ctl->rm_b_node_array[j].next_free_ind;
+					else
+						ctl->rm_b_node_array[prev].next_free_ind =
+						ctl->rm_b_node_array[j].next_free_ind;
+					from_node->cnt--;
+					if (from_node->cnt == 0)
+						from_node->last_child = (uint16_t) TM_INVAL;
+					if (from_node->last_child == j)
+						from_node->last_child = prev;
+					break; /* for */
+				}
+				prev = j;
+			}
+			if (j == TM_INVAL)
+				return -ENOBUFS;
+
+			/* move the node to the list of free nodes under the "to_node" */
+			ctl->rm_b_node_array[j].next_free_ind = to_node->first_child;
+			to_node->first_child = j;
+			if (to_node->cnt == 0) /* empty */
+				to_node->last_child = j;
+			to_node->cnt++;
+		}
+		/* no action required when the node in use */
+	}
+	break; /* switch */
+	case RM_C_LVL:
+	if ((from_node_ind >= ctl->rm_total_ports) ||
+	(to_node_ind >= ctl->rm_total_ports))
+		return -EFAULT;
+
+	from_node = &(ctl->rm_port_array[from_node_ind]);
+	to_node = &(ctl->rm_port_array[to_node_ind]);
+
+	for (i = first_child_to_move; i <= last_child_to_move; i++) {
+		node = &(ctl->rm_c_node_array[i]);
+		node->parent_ind = to_node_ind;
+		if (node->used == RM_FALSE) {
+			/* pop the node form the list of free nodes under the "from_node" */
+			for (j = from_node->first_child; j != TM_INVAL;
+				j = ctl->rm_c_node_array[j].next_free_ind) {
+				if (j == i) {
+					if (j == from_node->first_child) /* head */
+						from_node->first_child = ctl->rm_c_node_array[j].next_free_ind;
+					else
+						ctl->rm_c_node_array[prev].next_free_ind =
+						ctl->rm_c_node_array[j].next_free_ind;
+					from_node->cnt--;
+					if (from_node->cnt == 0)
+						from_node->last_child = (uint16_t) TM_INVAL;
+					if (from_node->last_child == j)
+						from_node->last_child = prev;
+					break; /* for */
+				}
+				prev = j;
+			}
+			if (j == TM_INVAL)
+				return -ENOBUFS;
+
+			/* move the node to the list of free nodes under the "to_node" */
+			ctl->rm_c_node_array[j].next_free_ind = to_node->first_child;
+			to_node->first_child = j;
+			if (to_node->cnt == 0) /* empty */
+			to_node->last_child = j;
+			to_node->cnt++;
+		}
+	/* no action required when the node in use */
+	}
+	break; /* switch */
+	default:
+		return -ERANGE;
+	}
+	return 0;
+}
+
+
+/**
+ */
+int rm_nodes_switch(rmctl_t hndl,
+			enum rm_level level,
+			uint32_t node_a_ind,
+			uint32_t node_b_ind,
+			uint32_t first_a_child,
+			uint32_t last_a_child,
+			uint32_t first_b_child,
+			uint32_t last_b_child)
+{
+	struct rm_node *node_a = NULL;
+	struct rm_node *node_b = NULL;
+	uint32_t first_child;
+	uint32_t last_child;
+	uint32_t cnt;
+	uint32_t i;
+
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	switch (level) {
+	case RM_Q_LVL:
+		if ((node_a_ind >= ctl->rm_total_a_nodes) ||
+		(node_b_ind >= ctl->rm_total_a_nodes))
+			return -EFAULT;
+
+		node_a = &(ctl->rm_a_node_array[node_a_ind]);
+		node_b = &(ctl->rm_a_node_array[node_b_ind]);
+
+		for (i = first_a_child; i <= last_a_child; i++)
+			ctl->rm_queue_array[i].parent_ind = node_b_ind;
+
+		for (i = first_b_child; i <= last_b_child; i++)
+			ctl->rm_queue_array[i].parent_ind = node_a_ind;
+
+		break;
+	case RM_A_LVL:
+		if ((node_a_ind >= ctl->rm_total_b_nodes) ||
+		(node_b_ind >= ctl->rm_total_b_nodes))
+			return -EFAULT;
+
+		node_a = &(ctl->rm_b_node_array[node_a_ind]);
+		node_b = &(ctl->rm_b_node_array[node_b_ind]);
+
+		for (i = first_a_child; i <= last_a_child; i++)
+			ctl->rm_a_node_array[i].parent_ind = node_b_ind;
+
+		for (i = first_b_child; i <= last_b_child; i++)
+			ctl->rm_a_node_array[i].parent_ind = node_a_ind;
+
+		break;
+	case RM_B_LVL:
+		if ((node_a_ind >= ctl->rm_total_c_nodes) ||
+		(node_b_ind >= ctl->rm_total_c_nodes))
+			return -EFAULT;
+
+		node_a = &(ctl->rm_c_node_array[node_a_ind]);
+		node_b = &(ctl->rm_c_node_array[node_b_ind]);
+
+		for (i = first_a_child; i <= last_a_child; i++)
+			ctl->rm_b_node_array[i].parent_ind = node_b_ind;
+
+		for (i = first_b_child; i <= last_b_child; i++)
+			ctl->rm_b_node_array[i].parent_ind = node_a_ind;
+
+		break;
+	case RM_C_LVL:
+		if ((node_a_ind >= ctl->rm_total_ports) ||
+		(node_b_ind >= ctl->rm_total_ports))
+			return -EFAULT;
+
+		node_a = &(ctl->rm_port_array[node_a_ind]);
+		node_b = &(ctl->rm_port_array[node_b_ind]);
+
+		for (i = first_a_child; i <= last_a_child; i++)
+			ctl->rm_c_node_array[i].parent_ind = node_b_ind;
+
+		for (i = first_b_child; i <= last_b_child; i++)
+			ctl->rm_c_node_array[i].parent_ind = node_a_ind;
+
+		break;
+	default:
+		return -ERANGE;
+	}
+
+	first_child = node_a->first_child;
+	last_child = node_a->last_child;
+	cnt = node_a->cnt;
+
+	node_a->first_child = node_b->first_child;
+	node_a->last_child = node_b->last_child;
+	node_a->cnt = node_b->cnt;
+
+	node_b->first_child = first_child;
+	node_b->last_child = last_child;
+	node_b->cnt = cnt;
+
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.h
new file mode 100644
index 0000000..c3d5bfc
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_reorder.h
@@ -0,0 +1,85 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_REORDER_H
+#define RM_REORDER_H
+
+
+#include "rm_interface.h"
+
+/** Move nodes from one parent to other.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		level                Level of the nodes to be moved.
+ *   @param[in]		from_node_ind        Parent index from which the nodes are moved.
+ *   @param[in]		to_node_ind          Parent index to which the nodes are moved.
+ *   @param[in]		number_of_children   Number of the nodes.
+ *   @param[in]		first_child_to_move  Index of the first node to be moved.
+ *
+ *   @return an integer positive index of found free queue.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if from/to_node_ind is out of range.
+ *   @retval -ENOBUFS when node is not found in free nodes list.
+ */
+int rm_nodes_move(rmctl_t hndl,
+		  enum rm_level level,
+		  uint32_t from_node_ind,
+		  uint32_t to_node_ind,
+		  uint32_t number_of_children,
+		  uint32_t first_child_to_move);
+
+
+/** Switch children between two nodes.
+ *
+ *   @param[in]		hndl		     Resource Manager handle.
+ *   @param[in]		level                Level of the nodes to be moved.
+ *   @param[in]		node_a_ind           First node index.
+ *   @param[in]		node_b_ind           Second node index.
+ *   @param[in]		first_a_child        First child in range to first node.
+ *   @param[in]		last_a_child         Last child in range to first node.
+ *   @param[in]		first_b_child        First child in range to second node.
+ *   @param[in]		last_b_child         Last child in range to second node.
+ *
+ *   @return an integer positive index of found free node.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if node_a/b_ind is out of range.
+ */
+int rm_nodes_switch(rmctl_t hndl,
+			enum rm_level level,
+			uint32_t node_a_ind,
+			uint32_t node_b_ind,
+			uint32_t first_a_child,
+			uint32_t last_a_child,
+			uint32_t first_b_child,
+			uint32_t last_b_child);
+
+
+#endif   /* RM_REORDER_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.c b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.c
new file mode 100644
index 0000000..7453678
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.c
@@ -0,0 +1,316 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "rm_internal_types.h"
+#include "rm_status.h"
+#include "tm/core/tm_core_types.h"
+#include "tm/core/tm_hw_configuration_interface.h"
+
+
+/**
+ */
+int rm_node_status(rmctl_t hndl,
+					enum tm_level lvl,
+					uint32_t node_ind,
+					uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	switch (lvl) {
+	case P_LEVEL:
+		if (node_ind >= ctl->rm_total_ports)
+			return  -EFAULT;
+		*status = ctl->rm_port_array[node_ind].used;
+		break;
+	case C_LEVEL:
+		if (node_ind >= ctl->rm_total_c_nodes)
+			return  -EFAULT;
+		*status = ctl->rm_c_node_array[node_ind].used;
+		break;
+	case B_LEVEL:
+		if (node_ind >= ctl->rm_total_b_nodes)
+			return  -EFAULT;
+		*status = ctl->rm_b_node_array[node_ind].used;
+		break;
+	case A_LEVEL:
+		if (node_ind >= ctl->rm_total_a_nodes)
+			return  -EFAULT;
+		*status = ctl->rm_a_node_array[node_ind].used;
+		break;
+	case Q_LEVEL:
+		if (node_ind >= ctl->rm_total_queues)
+			return  -EFAULT;
+		*status = ctl->rm_queue_array[node_ind].used;
+		break;
+	default:
+		return -ERANGE;
+	}
+
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_queue_curve_status(rmctl_t hndl,
+								uint8_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_WRED_QUEUE_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_queue_curves[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_a_node_curve_status(rmctl_t hndl,
+								uint8_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_WRED_A_NODE_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_a_node_curves[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_b_node_curve_status(rmctl_t hndl,
+								uint8_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_WRED_B_NODE_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_b_node_curves[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_c_node_curve_status(rmctl_t hndl,
+								uint8_t cos,
+								uint8_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (cos >= TM_WRED_COS)
+		return -EFAULT;
+
+	if (entry_ind >= TM_NUM_WRED_C_NODE_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_c_node_curves[cos][entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_port_curve_status(rmctl_t hndl,
+								uint8_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_WRED_PORT_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_port_curves[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_wred_port_curve_status_cos(rmctl_t hndl,
+									uint8_t cos,
+									uint8_t entry_ind,
+									uint8_t *status)
+{
+	struct rmctl *ctl = hndl;
+
+	if (!ctl)
+		return -EINVAL;
+	if (ctl->magic != RM_MAGIC)
+		return -EBADF;
+
+	if (cos >= TM_WRED_COS)
+		return -EFAULT;
+
+	if (entry_ind >= TM_NUM_WRED_PORT_CURVES)
+		return -EFAULT;
+
+	*status = ctl->rm_wred_port_curves_cos[cos][entry_ind].used;
+	return 0;
+}
+
+
+
+/**
+ */
+int rm_queue_drop_profile_status(rmctl_t hndl,
+								uint16_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_QUEUE_DROP_PROF)
+		return -EFAULT;
+
+	*status = ctl->rm_queue_drop_profiles[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_a_node_drop_profile_status(rmctl_t hndl,
+									uint16_t entry_ind,
+									uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_A_NODE_DROP_PROF)
+		return -EFAULT;
+
+	*status = ctl->rm_a_node_drop_profiles[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_b_node_drop_profile_status(rmctl_t hndl,
+									uint16_t entry_ind,
+									uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (entry_ind >= TM_NUM_B_NODE_DROP_PROF)
+		return -EFAULT;
+
+	*status = ctl->rm_b_node_drop_profiles[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_c_node_drop_profile_status(rmctl_t hndl,
+									uint8_t cos,
+									uint16_t entry_ind,
+									uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+
+	if (cos >= TM_WRED_COS)
+		return -EFAULT;
+
+	if (entry_ind >= TM_NUM_C_NODE_DROP_PROF)
+		return -EFAULT;
+
+	*status = ctl->rm_c_node_drop_profiles[cos][entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_port_drop_profile_status(rmctl_t hndl,
+								uint16_t entry_ind,
+								uint8_t *status)
+{
+	DECLARE_RM_HANDLE(ctl, hndl)
+	CHECK_RM_HANDLE(ctl)
+
+	if (entry_ind >= TM_NUM_PORT_DROP_PROF)
+		return -EFAULT;
+
+	*status = ctl->rm_port_drop_profiles[entry_ind].used;
+	return 0;
+}
+
+
+/**
+ */
+int rm_port_drop_profile_status_cos(rmctl_t hndl,
+									uint8_t cos,
+									uint16_t entry_ind,
+									uint8_t *status)
+{
+	struct rmctl *ctl = hndl;
+
+	if (!ctl)
+		return -EINVAL;
+	if (ctl->magic != RM_MAGIC)
+		return -EBADF;
+
+	if (entry_ind >= TM_NUM_PORT_DROP_PROF)
+		return -EFAULT;
+
+	if (cos >= TM_WRED_COS)
+		return -EFAULT;
+
+	*status = ctl->rm_port_drop_profiles_cos[cos][entry_ind].used;
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.h b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.h
new file mode 100644
index 0000000..9ac0e29
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/resource_management/rm_status.h
@@ -0,0 +1,258 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef RM_STATUS_H
+#define RM_STATUS_H
+
+#include "rm_interface.h"
+#include "tm/core/tm_defs.h"
+
+/** Get Node status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		lvl			Level of node.
+ *   @param[in]		node_ind	Node index.
+ *   @param[out]	status		Node status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if node_ind is out of range.
+ *   @retval -ERANGE if lvl is out of range.
+*/
+int rm_node_status(rmctl_t hndl, enum tm_level lvl, uint32_t node_ind,
+					uint8_t *status);
+
+
+/** Get WRED Queue Curve status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_wred_queue_curve_status(rmctl_t hndl, uint8_t entry_ind,
+								uint8_t *status);
+
+
+/** Get WRED A-node Curve status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_wred_a_node_curve_status(rmctl_t hndl, uint8_t entry_ind,
+								uint8_t *status);
+
+
+/** Get WRED B-node Curve status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_wred_b_node_curve_status(rmctl_t hndl, uint8_t entry_ind,
+								uint8_t *status);
+
+
+/** Get WRED C-node Curve status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos	        CoS of RED Curve.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ */
+int rm_wred_c_node_curve_status(rmctl_t hndl, uint8_t cos, uint8_t entry_ind,
+								uint8_t *status);
+
+
+/** Get WRED Port Curve status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_wred_port_curve_status(rmctl_t hndl,
+							uint8_t entry_ind,
+							uint8_t *status);
+
+
+/* not used for HX/AX */
+/** Get WRED Port Curve status per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos	        CoS of RED Curve.
+ *   @param[in]		entry_ind	Curve index.
+ *   @param[out]	status		Curve status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ */
+int rm_wred_port_curve_status_cos(rmctl_t hndl,
+								uint8_t cos,
+								uint8_t entry_ind,
+								uint8_t *status);
+
+
+/** Get Queue Drop Profile status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_queue_drop_profile_status(rmctl_t hndl, uint16_t entry_ind,
+								uint8_t *status);
+
+
+/** Get A-node Drop Profile status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_a_node_drop_profile_status(rmctl_t hndl, uint16_t entry_ind,
+								uint8_t *status);
+
+
+/** Get B-node Drop Profile status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_b_node_drop_profile_status(rmctl_t hndl, uint16_t entry_ind,
+								uint8_t *status);
+
+
+/** Get C-node Drop Profile status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos	        CoS of RED Curve.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_c_node_drop_profile_status(rmctl_t hndl, uint8_t cos, uint16_t entry_ind,
+								uint8_t *status);
+
+
+/** Get Port Drop Profile status.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind is out of range.
+ */
+int rm_port_drop_profile_status(rmctl_t hndl,
+								uint16_t entry_ind,
+								uint8_t *status);
+
+
+
+/* not used for Hx/AX*/
+/** Get Port Drop Profile status per Cos.
+ *
+ *   @param[in]		hndl		Resource Manager handle.
+ *   @param[in]		cos	        CoS of RED Curve.
+ *   @param[in]		entry_ind	Profile index.
+ *   @param[out]	status		Profile status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ *   @retval -EFAULT if entry_ind or cos is out of range.
+ */
+int rm_port_drop_profile_status_cos(rmctl_t hndl,
+									uint8_t cos,
+									uint16_t entry_ind,
+									uint8_t *status);
+
+
+#endif   /* RM_STATUS_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.c b/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.c
new file mode 100644
index 0000000..52a356b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.c
@@ -0,0 +1,4905 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/delay.h>
+#include "set_hw_registers.h"
+#include "tm_alias.h"
+#include "tm_rw_registers_interface.h"
+#include "tm_hw_configuration_interface.h"
+#include "rm_internal_types.h"
+#include "rm_status.h"
+
+
+/*#define SHIFT_TABLE */
+#define STRUCTS
+
+#define READ_ONLY   0
+
+#if defined(STRUCTS)
+	#include "tm_payloads.h"
+#elif defined(SHIFT_TABLE)
+	#include "tm_registers_description.h"
+#else
+
+#endif
+
+#include "tm_registers_processing.h"
+#include "tm_errcodes.h"
+
+
+#define COMPLETE_HW_WRITE								\
+	do {												\
+		if (0 == rc)									\
+			rc = flush_hw_connection(TM_ENV(ctl));		\
+		if (rc)											\
+			rc = reset_hw_connection(TM_ENV(ctl), rc);	\
+	} while (0);
+
+#define TM_WRITE_REGISTER(address, register_name)                   \
+	do {                                                            \
+		if (sizeof(struct register_name) != 8)                      \
+			pr_err("WR size is %d\n", sizeof(struct register_name));\
+		rc = tm_register_write(TM_ENV(ctl), (void *)&(address),     \
+			TM_REGISTER_VAR_ADDR(register_name));                   \
+	} while (0);
+
+#define TM_READ_REGISTER(address, register_name)                    \
+	do {                                                            \
+		if (sizeof(struct register_name) != 8)                      \
+			pr_err("WR size is %d\n", sizeof(struct register_name));\
+		rc = tm_register_read(TM_ENV(ctl), (void *)&(address),      \
+			TM_REGISTER_VAR_ADDR(register_name));                   \
+	} while (0);
+
+#define TM_WRITE_TABLE_REGISTER(address, index, register_name)      \
+	do {                                                            \
+		if (sizeof(struct register_name) != 8)                      \
+			pr_err("WR size is %d\n", sizeof(struct register_name));\
+		rc = tm_table_entry_write(TM_ENV(ctl), (void *)&(address),  \
+			index, TM_REGISTER_VAR_ADDR(register_name));            \
+	} while (0);
+
+#define TM_READ_TABLE_REGISTER(address, index, register_name)       \
+	do {                                                            \
+		if (sizeof(struct register_name) != 8)                      \
+			pr_err("WR size is %d\n", sizeof(struct register_name));\
+		rc = tm_table_entry_read(TM_ENV(ctl), (void *)&(address),   \
+		index, TM_REGISTER_VAR_ADDR(register_name));                \
+	} while (0);
+
+
+int set_hw_fixed_port_periodic_scheme(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortPerConf)
+	TM_REGISTER_VAR(TM_Sched_PortPerRateShpPrms)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_PortPerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_PortPerConf, PerInterval, TM_FIXED_2_5_G_PORT_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_PortPerConf, PerEn, TM_FIXED_PERIODIC_SCHEME_PER_EN);
+	TM_WRITE_REGISTER(TM.Sched.PortPerConf, TM_Sched_PortPerConf);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, L, TM_FIXED_PERIODIC_SCHEME_L);
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, K, TM_FIXED_PERIODIC_SCHEME_K);
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, N, TM_FIXED_PERIODIC_SCHEME_N);
+	TM_WRITE_REGISTER(TM.Sched.PortPerRateShpPrms, TM_Sched_PortPerRateShpPrms);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_fixed_c_level_periodic_scheme(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_ClvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_ClvlPerRateShpPrms)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_ClvlPerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_ClvlPerConf, PerInterval, TM_FIXED_2_5_G_C_LEVEL_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_ClvlPerConf, PerEn, TM_FIXED_PERIODIC_SCHEME_PER_EN);
+	TM_WRITE_REGISTER(TM.Sched.ClvlPerConf, TM_Sched_ClvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, L, TM_FIXED_PERIODIC_SCHEME_L);
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, K, TM_FIXED_PERIODIC_SCHEME_K);
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, N, TM_FIXED_PERIODIC_SCHEME_N);
+	TM_WRITE_REGISTER(TM.Sched.ClvlPerRateShpPrms, TM_Sched_ClvlPerRateShpPrms);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_fixed_b_level_periodic_scheme(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_BlvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_BlvlPerRateShpPrms)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_BlvlPerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_BlvlPerConf, PerInterval, TM_FIXED_2_5_G_B_LEVEL_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_BlvlPerConf, PerEn, TM_FIXED_PERIODIC_SCHEME_PER_EN);
+	TM_WRITE_REGISTER(TM.Sched.BlvlPerConf, TM_Sched_BlvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, L, TM_FIXED_PERIODIC_SCHEME_L);
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, K, TM_FIXED_PERIODIC_SCHEME_K);
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, N, TM_FIXED_PERIODIC_SCHEME_N);
+	TM_WRITE_REGISTER(TM.Sched.BlvlPerRateShpPrms, TM_Sched_BlvlPerRateShpPrms);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_fixed_a_level_periodic_scheme(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_AlvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_AlvlPerRateShpPrms)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_AlvlPerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_AlvlPerConf, PerInterval, TM_FIXED_2_5_G_A_LEVEL_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_AlvlPerConf, PerEn, TM_FIXED_PERIODIC_SCHEME_PER_EN);
+	TM_WRITE_REGISTER(TM.Sched.AlvlPerConf, TM_Sched_AlvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, L, TM_FIXED_PERIODIC_SCHEME_L);
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, K, TM_FIXED_PERIODIC_SCHEME_K);
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, N, TM_FIXED_PERIODIC_SCHEME_N);
+	TM_WRITE_REGISTER(TM.Sched.AlvlPerRateShpPrms, TM_Sched_AlvlPerRateShpPrms);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_fixed_queue_periodic_scheme(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_QueuePerConf)
+	TM_REGISTER_VAR(TM_Sched_QueuePerRateShpPrms)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_QueuePerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_QueuePerConf, PerInterval, TM_FIXED_2_5_G_QUEUE_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_QueuePerConf, PerEn, TM_FIXED_PERIODIC_SCHEME_PER_EN);
+	TM_WRITE_REGISTER(TM.Sched.QueuePerConf, TM_Sched_QueuePerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, L, TM_FIXED_PERIODIC_SCHEME_L);
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, K, TM_FIXED_PERIODIC_SCHEME_K);
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, N, TM_FIXED_PERIODIC_SCHEME_N);
+	TM_WRITE_REGISTER(TM.Sched.QueuePerRateShpPrms, TM_Sched_QueuePerRateShpPrms);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_fixed_port_shaping_status(tm_handle hndl, uint8_t shaping_status)
+{
+	int rc = -ERANGE;
+
+	TM_REGISTER_VAR(TM_Sched_PortPerConf)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	TM_REGISTER_SET(TM_Sched_PortPerConf, DecEn, TM_FIXED_PERIODIC_SCHEME_DEC_EN);
+	TM_REGISTER_SET(TM_Sched_PortPerConf, PerInterval, TM_FIXED_2_5_G_PORT_PERIODIC_SCHEME_PER_INTERVAL);
+	TM_REGISTER_SET(TM_Sched_PortPerConf, PerEn, shaping_status);
+
+	TM_WRITE_REGISTER(TM.Sched.PortPerConf, TM_Sched_PortPerConf);
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+#ifdef MV_QMTM_NSS_A0
+/**
+ */
+int set_hw_dwrr_limit(tm_handle hndl)
+{
+	int rc = 0;
+	TM_REGISTER_VAR(TM_Sched_PortDWRRBytesPerBurstsLimit)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_PortDWRRBytesPerBurstsLimit, limit, ctl->dwrr_bytes_burst_limit);
+	TM_WRITE_REGISTER(TM.Sched.PortDWRRBytesPerBurstsLimit, TM_Sched_PortDWRRBytesPerBurstsLimit);
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_gen_conf(tm_handle hndl)
+{
+	int rc = 0;
+	TM_REGISTER_VAR(TM_Sched_PortExtBPEn)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_PortExtBPEn, En, ctl->port_ext_bp_en);
+	TM_WRITE_REGISTER(TM.Sched.PortExtBPEn, TM_Sched_PortExtBPEn);
+	COMPLETE_HW_WRITE
+	return rc;
+}
+#endif
+
+/**
+ */
+int set_hw_max_dp_mode(tm_handle hndl)
+{
+	int rc = 0;
+	int i;
+	uint8_t port = 0;
+	uint8_t c_lvl = 0;
+	uint8_t b_lvl = 0;
+	uint8_t a_lvl = 0;
+	uint8_t queue = 0;
+
+	TM_REGISTER_VAR(TM_Drop_WREDMaxProbModePerColor)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < 3; i++) {
+		port  = port  | (ctl->dp_unit.local[P_LEVEL].max_p_mode[i] << (i*2));
+		c_lvl = c_lvl | (ctl->dp_unit.local[C_LEVEL].max_p_mode[i] << (i*2));
+		b_lvl = b_lvl | (ctl->dp_unit.local[B_LEVEL].max_p_mode[i] << (i*2));
+		a_lvl = a_lvl | (ctl->dp_unit.local[A_LEVEL].max_p_mode[i] << (i*2));
+		queue = queue | (ctl->dp_unit.local[Q_LEVEL].max_p_mode[i] << (i*2));
+	}
+
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Port, port)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Clvl, c_lvl)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Blvl, b_lvl)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Alvl, a_lvl)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Queue, queue)
+
+	TM_WRITE_REGISTER(TM.Drop.WREDMaxProbModePerColor, TM_Drop_WREDMaxProbModePerColor)
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int __set_hw_queues_wred_curve(tm_handle hndl, uint8_t *prob_array, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	int i;
+	int j;
+	int ind;
+	TM_REGISTER_VAR(TM_Drop_QueueREDCurve_Color)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		TM_REGISTER_SET(TM_Drop_QueueREDCurve_Color, Prob, prob_array[i])
+		ind = curve_ind*32 + i;
+		for (j = 0; j < 3; j++) {
+			/* the same curve for each color */
+			rc = tm_table_entry_write(TM_ENV(ctl), (void *)&(TM.Drop.QueueREDCurve.Color[j]), ind, TM_REGISTER_VAR_ADDR(TM_Drop_QueueREDCurve_Color));
+			if (rc)
+				goto out;
+		}
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_queues_wred_curve(tm_handle hndl, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	uint8_t *prob_array;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (curve_ind < TM_NUM_WRED_QUEUE_CURVES) {
+		prob_array = (uint8_t *)(ctl->tm_wred_q_lvl_curves[curve_ind].prob);
+		return __set_hw_queues_wred_curve(hndl, prob_array, curve_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_queues_default_wred_curve(tm_handle hndl, uint8_t *prob_array)
+{
+	return __set_hw_queues_wred_curve(hndl, prob_array, 0);
+}
+
+/*****************************/
+
+
+int __set_hw_a_nodes_wred_curve(tm_handle hndl, uint8_t *prob_array, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	int i;
+	int j;
+	int ind;
+	TM_REGISTER_VAR(TM_Drop_AlvlREDCurve_Color)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+	{
+		TM_REGISTER_SET(TM_Drop_AlvlREDCurve_Color, Prob, prob_array[i])
+		ind = curve_ind*32 + i;
+		for (j = 0; j < 3; j++)
+		{
+			rc = tm_table_entry_write(TM_ENV(ctl), (void *)&(TM.Drop.AlvlREDCurve.Color[j]), ind, TM_REGISTER_VAR_ADDR(TM_Drop_AlvlREDCurve_Color));
+			if (rc)
+				goto out;
+		}
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_a_nodes_wred_curve(tm_handle hndl, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	uint8_t *prob_array;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (curve_ind < TM_NUM_WRED_A_NODE_CURVES)
+	{
+		prob_array = (uint8_t *)(ctl->tm_wred_a_lvl_curves[curve_ind].prob);
+		return __set_hw_a_nodes_wred_curve(hndl,prob_array,curve_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_a_nodes_default_wred_curve(tm_handle hndl, uint8_t *prob_array)
+{
+	return __set_hw_a_nodes_wred_curve(hndl, prob_array, 0);
+}
+
+/*****************************/
+
+
+int __set_hw_b_nodes_wred_curve(tm_handle hndl, uint8_t *prob_array, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	int i;
+	TM_REGISTER_VAR(TM_Drop_BlvlREDCurve_Table)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		TM_REGISTER_SET(TM_Drop_BlvlREDCurve_Table, Prob, prob_array[i]);
+		rc = tm_table_entry_write(TM_ENV(ctl), (void *)&TM.Drop.BlvlREDCurve[curve_ind].Table, i, TM_REGISTER_VAR_ADDR(TM_Drop_BlvlREDCurve_Table));
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_b_nodes_wred_curve(tm_handle hndl, uint8_t curve_ind)
+{
+	int rc = -ERANGE;
+	uint8_t *prob_array;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (curve_ind < TM_NUM_WRED_B_NODE_CURVES)
+	{
+		prob_array = (uint8_t *)(ctl->tm_wred_b_lvl_curves[curve_ind].prob);
+		return __set_hw_b_nodes_wred_curve(hndl, prob_array,curve_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_b_nodes_default_wred_curve(tm_handle hndl, uint8_t *prob_array)
+{
+	return __set_hw_b_nodes_wred_curve(hndl, prob_array, 0);
+}
+
+
+/**
+ */
+int __set_hw_c_nodes_wred_curve(tm_handle hndl, uint8_t *prob_array, uint8_t cos, uint8_t curve_ind)
+{
+	int rc = -EFAULT;
+	int i;
+	int ind;
+	TM_REGISTER_VAR(TM_Drop_ClvlREDCurve_CoS)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		TM_REGISTER_SET(TM_Drop_ClvlREDCurve_CoS, Prob, prob_array[i]);
+		ind = curve_ind*32 + i;
+		rc = tm_table_entry_write(TM_ENV(ctl), (void *)&(TM.Drop.ClvlREDCurve.CoS[cos]), ind, TM_REGISTER_VAR_ADDR(TM_Drop_ClvlREDCurve_CoS));
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_c_nodes_wred_curve(tm_handle hndl, uint8_t cos, uint8_t curve_ind)
+{
+	uint8_t *prob_array;
+	int rc = -EFAULT;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (curve_ind < TM_NUM_WRED_C_NODE_CURVES)
+	{
+		prob_array = (uint8_t *)(ctl->tm_wred_c_lvl_curves[cos][curve_ind].prob);
+		return __set_hw_c_nodes_wred_curve(hndl, prob_array, cos, curve_ind);
+	}
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+int set_hw_c_nodes_default_wred_curve(tm_handle hndl, uint8_t cos, uint8_t *prob_array)
+{
+	return __set_hw_c_nodes_wred_curve(hndl, prob_array, cos, 0);
+}
+
+/**
+ */
+int __set_hw_ports_wred_curve(tm_handle hndl, uint8_t *prob_array)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Drop_PortREDCurve)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		TM_REGISTER_SET(TM_Drop_PortREDCurve, Prob, prob_array[i]);
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortREDCurve, i, TM_Drop_PortREDCurve)
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_wred_curve(tm_handle hndl, uint8_t curve_ind)
+{
+	int rc = -EFAULT;
+	uint8_t *prob_array;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (curve_ind < TM_NUM_WRED_PORT_CURVES)
+	{
+		prob_array = (uint8_t *)(ctl->tm_wred_ports_curves[curve_ind].prob);
+		return __set_hw_ports_wred_curve(hndl,prob_array);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_default_wred_curve(tm_handle hndl, uint8_t *prob_array)
+{
+	return	__set_hw_ports_wred_curve(hndl,prob_array);
+}
+
+
+int __set_hw_ports_wred_curve_cos(tm_handle hndl, uint8_t *prob_array, uint8_t cos)
+{
+	int rc = 0;
+	int i;
+	TM_REGISTER_VAR(TM_Drop_PortREDCurve)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		TM_REGISTER_SET(TM_Drop_PortREDCurve, Prob, prob_array[i]);
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortREDCurve_CoS[cos], i, TM_Drop_PortREDCurve)
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_wred_curve_cos(tm_handle hndl, uint8_t cos, uint8_t curve_ind)
+{
+	int rc = -EFAULT;
+	uint8_t *prob_array;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (curve_ind < TM_NUM_WRED_PORT_CURVES)
+	{
+		prob_array = (uint8_t *)(ctl->tm_wred_ports_curves_cos[cos][curve_ind].prob);
+		return __set_hw_ports_wred_curve_cos( hndl, prob_array, cos);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_default_wred_curve_cos(tm_handle hndl, uint8_t cos, uint8_t *prob_array)
+{
+	return __set_hw_ports_wred_curve_cos( hndl, prob_array, cos);
+}
+
+
+/**
+ */
+int __set_hw_queue_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDDPRatio)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDParams, CurveIndexColor2, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDParams, prof_ind, TM_Drop_QueueDropPrfWREDParams);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDScaleRatio, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDScaleRatio, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDScaleRatio, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDScaleRatio, prof_ind, TM_Drop_QueueDropPrfWREDScaleRatio);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDMinThresh, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDMinThresh, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDMinThresh, MinTHColor2, profile->min_threshold[2].thresh);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDMinThresh, prof_ind, TM_Drop_QueueDropPrfWREDMinThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfTailDrpThresh, TailDropThreshRes, profile->td_thresh_res);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfTailDrpThresh, TailDropThresh, profile->td_threshold);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfTailDrpThresh, prof_ind, TM_Drop_QueueDropPrfTailDrpThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDDPRatio, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDDPRatio, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_QueueDropPrfWREDDPRatio, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDDPRatio, prof_ind, TM_Drop_QueueDropPrfWREDDPRatio);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_queue_drop_profile(tm_handle hndl, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_QUEUE_DROP_PROF)
+	{
+		profile = &(ctl->tm_q_lvl_drop_profiles[prof_ind]);
+		return __set_hw_queue_drop_profile(hndl, profile, prof_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_queue_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile)
+{
+	return __set_hw_queue_drop_profile(hndl, profile, 0);
+}
+
+/**
+ */
+int __set_hw_a_nodes_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDDPRatio)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDParams, CurveIndexColor2, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDParams, prof_ind, TM_Drop_AlvlDropPrfWREDParams);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDScaleRatio, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDScaleRatio, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDScaleRatio, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDScaleRatio, prof_ind, TM_Drop_AlvlDropPrfWREDScaleRatio);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDMinThresh, MinTHColor2, profile->min_threshold[2].thresh);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDMinThresh, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDMinThresh, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDMinThresh, prof_ind, TM_Drop_AlvlDropPrfWREDMinThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfTailDrpThresh, TailDropThreshRes, profile->td_thresh_res);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfTailDrpThresh, TailDropThresh, profile->td_threshold);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfTailDrpThresh, prof_ind, TM_Drop_AlvlDropPrfTailDrpThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDDPRatio, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDDPRatio, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_AlvlDropPrfWREDDPRatio, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDDPRatio, prof_ind, TM_Drop_AlvlDropPrfWREDDPRatio);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_a_nodes_drop_profile(tm_handle hndl, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_A_NODE_DROP_PROF)
+	{
+		profile = &(ctl->tm_a_lvl_drop_profiles[prof_ind]);
+		return __set_hw_a_nodes_drop_profile(hndl,profile,prof_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+int set_hw_a_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile)
+{
+	return __set_hw_a_nodes_drop_profile(hndl, profile, 0);
+}
+
+
+/**
+ */
+int __set_hw_b_nodes_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDDPRatio)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDParams, CurveIndexColor2, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDParams, prof_ind, TM_Drop_BlvlDropPrfWREDParams);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDScaleRatio, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDScaleRatio, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDScaleRatio, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDScaleRatio, prof_ind, TM_Drop_BlvlDropPrfWREDScaleRatio);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDMinThresh, MinTHColor2, profile->min_threshold[2].thresh);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDMinThresh, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDMinThresh, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDMinThresh, prof_ind, TM_Drop_BlvlDropPrfWREDMinThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfTailDrpThresh, TailDropThreshRes, profile->td_thresh_res);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfTailDrpThresh, TailDropThresh, profile->td_threshold);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfTailDrpThresh, prof_ind, TM_Drop_BlvlDropPrfTailDrpThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDDPRatio, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDDPRatio, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_BlvlDropPrfWREDDPRatio, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDDPRatio, prof_ind, TM_Drop_BlvlDropPrfWREDDPRatio);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_b_nodes_drop_profile(tm_handle hndl, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_B_NODE_DROP_PROF)
+	{
+		profile = &(ctl->tm_b_lvl_drop_profiles[prof_ind]);
+		return __set_hw_b_nodes_drop_profile(hndl, profile, prof_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_b_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile)
+{
+	return __set_hw_b_nodes_drop_profile(hndl, profile, 0);
+}
+
+
+/**
+ */
+int __set_hw_c_nodes_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint8_t cos, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDParams_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDScaleRatio_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDMinThresh_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfTailDrpThresh_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDDPRatio_CoS)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDParams_CoS, CurveIndexColor2, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDParams.CoS[cos], prof_ind, TM_Drop_ClvlDropPrfWREDParams_CoS);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDScaleRatio_CoS, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDScaleRatio_CoS, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDScaleRatio_CoS, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[cos], prof_ind,
+		TM_Drop_ClvlDropPrfWREDScaleRatio_CoS);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDMinThresh_CoS, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDMinThresh_CoS, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDMinThresh_CoS, MinTHColor2, profile->min_threshold[2].thresh);
+
+	TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDMinThresh.CoS[cos], prof_ind, TM_Drop_ClvlDropPrfWREDMinThresh_CoS);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfTailDrpThresh_CoS, TailDropThreshRes, profile->td_thresh_res);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfTailDrpThresh_CoS, TailDropThresh, profile->td_threshold);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfTailDrpThresh.CoS[cos], prof_ind, TM_Drop_ClvlDropPrfTailDrpThresh_CoS);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDDPRatio_CoS, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDDPRatio_CoS, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_ClvlDropPrfWREDDPRatio_CoS, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDDPRatio.CoS[cos], prof_ind,
+		TM_Drop_ClvlDropPrfWREDDPRatio_CoS);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_c_nodes_drop_profile(tm_handle hndl, uint8_t cos, uint32_t prof_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_C_NODE_DROP_PROF)
+	{
+		profile = &(ctl->tm_c_lvl_drop_profiles[cos][prof_ind]);
+		return __set_hw_c_nodes_drop_profile(hndl, profile, cos, prof_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_c_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint8_t cos)
+{
+	return __set_hw_c_nodes_drop_profile(hndl, profile, cos, 0);
+}
+
+
+/**
+ */
+int __set_hw_ports_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint32_t prof_ind, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDDPRatio)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	profile = &(ctl->tm_p_lvl_drop_profiles[prof_ind]);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor2, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDParams, port_ind, TM_Drop_PortDropPrfWREDParams);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDScaleRatio, port_ind, TM_Drop_PortDropPrfWREDScaleRatio);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor2, profile->min_threshold[2].thresh);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDMinThresh, port_ind, TM_Drop_PortDropPrfWREDMinThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfTailDrpThresh, TailDropThreshRes, profile->td_thresh_res);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfTailDrpThresh, TailDropThresh, profile->td_threshold);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfTailDrpThresh, port_ind, TM_Drop_PortDropPrfTailDrpThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDDPRatio, port_ind, TM_Drop_PortDropPrfWREDDPRatio);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_drop_profile(tm_handle hndl, uint32_t prof_ind, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_PORT_DROP_PROF)
+	{
+		profile = &(ctl->tm_p_lvl_drop_profiles[prof_ind]);
+		return __set_hw_ports_drop_profile(hndl, profile, prof_ind,port_ind);
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint8_t port_ind)
+{
+	return __set_hw_ports_drop_profile(hndl, profile, 0, port_ind);
+}
+
+
+/**
+ */
+int __set_hw_ports_drop_profile_cos(tm_handle hndl, struct tm_drop_profile *profile, uint8_t cos, uint32_t port_ind)
+{
+	int rc = 0;
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDDPRatio)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, AQLExp, profile->aql_exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ColorTDEn, profile->color_td_en);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor2, profile->scale_exp[2].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor1, profile->scale_exp[1].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, ScaleExpColor0, profile->scale_exp[0].exp);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor0, profile->curve_id[0].index);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor1, profile->curve_id[1].index);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDParams, CurveIndexColor0, profile->curve_id[2].index);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDParams_CoSRes[cos], port_ind, TM_Drop_PortDropPrfWREDParams);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor0, profile->scale_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor1, profile->scale_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDScaleRatio, ScaleRatioColor2, profile->scale_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[cos], port_ind,
+		TM_Drop_PortDropPrfWREDScaleRatio);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor0, profile->min_threshold[0].thresh);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor1, profile->min_threshold[1].thresh);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDMinThresh, MinTHColor2, profile->min_threshold[2].thresh);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDMinThresh_CoSRes[cos], port_ind,
+		TM_Drop_PortDropPrfWREDMinThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfTailDrpThresh, TailDropThresh, profile->td_threshold);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfTailDrpThresh, TailDropThreshRes, profile->td_thresh_res);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfTailDrpThresh_CoSRes[cos], port_ind,
+		TM_Drop_PortDropPrfTailDrpThresh);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio0, profile->dp_ratio[0].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio1, profile->dp_ratio[1].ratio);
+	TM_REGISTER_SET(TM_Drop_PortDropPrfWREDDPRatio, DPRatio2, profile->dp_ratio[2].ratio);
+	TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDDPRatio_CoSRes[cos], port_ind, TM_Drop_PortDropPrfWREDDPRatio);
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_drop_profile_cos(tm_handle hndl, uint8_t cos, uint32_t prof_ind, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (prof_ind < TM_NUM_PORT_DROP_PROF)
+	{
+		profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][prof_ind]);
+		return __set_hw_ports_drop_profile_cos(hndl, profile, cos, port_ind);
+
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_ports_default_drop_profile_cos(tm_handle hndl, struct tm_drop_profile *profile,
+	uint8_t cos, uint8_t port_ind)
+{
+	return __set_hw_ports_drop_profile_cos(hndl, profile, cos, port_ind);
+}
+
+
+/****************************************************************************************************
+* common macros for shaping functions
+*
+****************************************************************************************************/
+#define SET_NODE_SHAPING_MAC(level, condition, resolution)	\
+	do {\
+		int rc = -EFAULT;\
+	\
+		TM_REGISTER_VAR(TM_Sched_##level##TokenBucketTokenEnDiv)\
+		TM_REGISTER_VAR(TM_Sched_##level##TokenBucketBurstSize)\
+		DECLARE_TM_CTL_PTR(ctl, hndl)\
+		CHECK_TM_CTL_PTR(ctl)\
+	\
+		if (condition) {\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketTokenEnDiv, MaxTokenRes, resolution);\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketTokenEnDiv, MaxToken,\
+							ebw/TM_FIXED_10_M_SHAPING_TOKEN);\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketTokenEnDiv, MinTokenRes, resolution);\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketTokenEnDiv, MinToken,\
+							cbw/TM_FIXED_10_M_SHAPING_TOKEN);\
+			TM_WRITE_TABLE_REGISTER(TM.Sched.level##TokenBucketTokenEnDiv, index,\
+					TM_Sched_##level##TokenBucketTokenEnDiv);\
+			if (rc)\
+				goto out;\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketBurstSize, MaxBurstSz, cbs);\
+			TM_REGISTER_SET(TM_Sched_##level##TokenBucketBurstSize, MinBurstSz, ebs);\
+			TM_WRITE_TABLE_REGISTER(TM.Sched.level##TokenBucketBurstSize, index,\
+					TM_Sched_##level##TokenBucketBurstSize);\
+			if (rc)\
+				goto out;\
+		} \
+out:\
+		COMPLETE_HW_WRITE\
+		return rc;\
+	} while (0)
+
+#define SET_BURSTS(min_cbs, min_ebs) \
+	do {\
+		cbs = min_cbs;\
+		ebs = min_ebs;\
+		if (pcbs) {\
+			if (*pcbs >= cbs)\
+				cbs = *pcbs;\
+			else {\
+				*pcbs = cbs;\
+				rc = 1;\
+			} \
+		} \
+		if (pebs) {\
+			if (*pebs >= ebs)\
+				ebs = *pebs;\
+			else {\
+				*pebs = ebs;\
+				rc = 1;\
+			} \
+		} \
+	} while (0)
+
+#define GET_NODE_SHAPING_MAC(level, condition)	\
+	do {\
+		int rc = -EFAULT;\
+		uint32_t value;\
+		TM_REGISTER_VAR(TM_Sched_##level##TokenBucketTokenEnDiv)\
+		TM_REGISTER_VAR(TM_Sched_##level##TokenBucketBurstSize)\
+	\
+		DECLARE_TM_CTL_PTR(ctl, hndl)\
+		CHECK_TM_CTL_PTR(ctl)\
+	\
+		if (condition) {\
+			TM_READ_TABLE_REGISTER(TM.Sched.level##TokenBucketTokenEnDiv, index,\
+					TM_Sched_##level##TokenBucketTokenEnDiv);\
+			if (rc)\
+				return rc;\
+			TM_REGISTER_GET(TM_Sched_##level##TokenBucketTokenEnDiv, MaxToken, value, (uint32_t));\
+			if (pebw)\
+				*pebw = value * TM_FIXED_10_M_SHAPING_TOKEN;\
+			TM_REGISTER_GET(TM_Sched_##level##TokenBucketTokenEnDiv, MinToken, value, (uint32_t));\
+			if (pcbw)\
+				*pcbw = value * TM_FIXED_10_M_SHAPING_TOKEN;\
+			TM_READ_TABLE_REGISTER(TM.Sched.level##TokenBucketBurstSize, index,\
+					TM_Sched_##level##TokenBucketBurstSize);\
+			if (rc)\
+				return rc;\
+			if (pebs)\
+				TM_REGISTER_GET(TM_Sched_##level##TokenBucketBurstSize, MaxBurstSz, *pebs, (uint32_t));\
+			if (pcbs)\
+				TM_REGISTER_GET(TM_Sched_##level##TokenBucketBurstSize, MinBurstSz, *pcbs, (uint32_t));\
+		} \
+		return rc;\
+	} while (0)
+
+int __set_hw_queue_shaping(tm_handle hndl, uint32_t index, uint32_t cbw, uint32_t ebw, uint32_t cbs, uint32_t ebs)
+{
+	SET_NODE_SHAPING_MAC(Queue, index < get_tm_queues_count(), TM_FIXED_10_M_QUEUE_SHAPING_TOKEN_RES);
+}
+
+int set_hw_queue_shaping_ex(tm_handle hndl, uint32_t node_ind,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	int cbs, ebs;
+	int rc = 0;
+/*
+	cbs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_QUEUE_SHAPING_TOKEN_RES) /1024;
+	ebs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_QUEUE_SHAPING_TOKEN_RES) /1024;
+*/
+	SET_BURSTS(TM_FIXED_2_5_G_QUEUE_SHAPING_BURST_SIZE, TM_FIXED_2_5_G_QUEUE_SHAPING_BURST_SIZE);
+
+	if (rc == 0)
+		return __set_hw_queue_shaping(hndl, node_ind, cbw, ebw, cbs, ebs);
+	else
+		return TM_CONF_MIN_TOKEN_TOO_LARGE;
+}
+int set_hw_queue_shaping_def(tm_handle hndl, uint32_t node_ind)
+{
+	return set_hw_queue_shaping_ex(hndl, node_ind, 10000, 10000, NULL, NULL);
+}
+
+int __set_hw_a_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t cbs, uint32_t ebs)
+{
+	SET_NODE_SHAPING_MAC(Alvl, index < get_tm_a_nodes_count(), TM_FIXED_10_M_A_LEVEL_SHAPING_TOKEN_RES);
+}
+
+int set_hw_a_node_shaping_ex(tm_handle hndl, uint32_t node_ind,
+							uint32_t cbw, uint32_t ebw, uint32_t  *pcbs, uint32_t *pebs)
+{
+	int cbs, ebs;
+	int rc = 0;
+/*
+	cbs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_A_LEVEL_SHAPING_TOKEN_RES) /1024;
+	ebs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_A_LEVEL_SHAPING_TOKEN_RES) /1024;
+*/
+	SET_BURSTS(TM_FIXED_2_5_G_A_LEVEL_SHAPING_BURST_SIZE, TM_FIXED_2_5_G_A_LEVEL_SHAPING_BURST_SIZE);
+
+	if (rc == 0)
+		return __set_hw_a_node_shaping(hndl, node_ind, cbw, ebw, cbs, ebs);
+	else
+		return TM_CONF_MIN_TOKEN_TOO_LARGE;
+}
+
+int set_hw_a_node_shaping_def(tm_handle hndl, uint32_t node_ind)
+{
+	return set_hw_a_node_shaping_ex(hndl, node_ind, 10000, 10000, 0, 0);
+}
+
+int __set_hw_b_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t cbs, uint32_t ebs)
+{
+	SET_NODE_SHAPING_MAC(Blvl, index < get_tm_b_nodes_count(), TM_FIXED_10_M_B_LEVEL_SHAPING_TOKEN_RES);
+}
+
+int set_hw_b_node_shaping_ex(tm_handle hndl, uint32_t node_ind,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	int cbs, ebs;
+	int rc = 0;
+/*
+	cbs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_B_LEVEL_SHAPING_TOKEN_RES) /1024;
+	ebs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_B_LEVEL_SHAPING_TOKEN_RES) /1024;
+*/
+	SET_BURSTS(TM_FIXED_2_5_G_B_LEVEL_SHAPING_BURST_SIZE, TM_FIXED_2_5_G_B_LEVEL_SHAPING_BURST_SIZE);
+
+	if (rc == 0)
+		return __set_hw_b_node_shaping(hndl, node_ind, cbw, ebw, cbs, ebs);
+	else
+		return TM_CONF_MIN_TOKEN_TOO_LARGE;
+}
+
+int set_hw_b_node_shaping_def(tm_handle hndl, uint32_t node_ind)
+{
+	return set_hw_b_node_shaping_ex(hndl, node_ind, 10000, 10000, NULL, NULL);
+}
+
+
+int __set_hw_c_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t cbs, uint32_t ebs)
+{
+	SET_NODE_SHAPING_MAC(Clvl, index < get_tm_c_nodes_count(), TM_FIXED_10_M_C_LEVEL_SHAPING_TOKEN_RES);
+}
+
+int set_hw_c_node_shaping_ex(tm_handle hndl, uint32_t node_ind,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	int cbs, ebs;
+	int rc = 0;
+/*
+	cbs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_C_LEVEL_SHAPING_TOKEN_RES) /1024;
+	ebs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) * (1 << TM_FIXED_10_M_C_LEVEL_SHAPING_TOKEN_RES) /1024;
+*/
+	SET_BURSTS(TM_FIXED_2_5_G_C_LEVEL_SHAPING_BURST_SIZE, TM_FIXED_2_5_G_C_LEVEL_SHAPING_BURST_SIZE);
+
+	if (rc == 0)
+		return __set_hw_c_node_shaping(hndl, node_ind, cbw, ebw, cbs, ebs);
+	else
+		return TM_CONF_MIN_TOKEN_TOO_LARGE;
+}
+
+int set_hw_c_node_shaping_def(tm_handle hndl, uint32_t node_ind)
+{
+	return set_hw_c_node_shaping_ex(hndl, node_ind, 10000, 10000, NULL, NULL);
+}
+
+
+int get_hw_queue_shaping(tm_handle hndl, uint32_t index,
+						uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	GET_NODE_SHAPING_MAC(Queue, index < get_tm_queues_count());
+}
+int get_hw_a_node_shaping(tm_handle hndl, uint32_t index,
+						uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	GET_NODE_SHAPING_MAC(Alvl, index < get_tm_a_nodes_count());
+}
+int get_hw_b_node_shaping(tm_handle hndl, uint32_t index, uint32_t *pcbw,
+						uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	GET_NODE_SHAPING_MAC(Blvl, index < get_tm_b_nodes_count());
+}
+int get_hw_c_node_shaping(tm_handle hndl, uint32_t index,
+						uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	GET_NODE_SHAPING_MAC(Clvl, index < get_tm_c_nodes_count());
+}
+
+/**
+ */
+int set_hw_drop_aqm_mode(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_WREDDropProbMode)
+	TM_REGISTER_VAR(TM_Drop_DPSource)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Port, 1);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Clvl, 1);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Blvl, 1);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Alvl, 1);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Queue, 1);
+
+	if ((ctl->dp_unit.local[Q_LEVEL].color_num == TM_1_COLORS) ||
+		(ctl->dp_unit.local[Q_LEVEL].color_num == TM_2_COLORS))
+	{
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Queue, 0);
+	}
+
+	if ((ctl->dp_unit.local[A_LEVEL].color_num == TM_1_COLORS) ||
+		(ctl->dp_unit.local[A_LEVEL].color_num == TM_2_COLORS))
+	{
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Alvl, 0);
+	}
+	if ((ctl->dp_unit.local[B_LEVEL].color_num == TM_1_COLORS) ||
+		(ctl->dp_unit.local[B_LEVEL].color_num == TM_2_COLORS))
+	{
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Blvl, 0);
+	}
+	if ((ctl->dp_unit.local[C_LEVEL].color_num == TM_1_COLORS) ||
+		(ctl->dp_unit.local[C_LEVEL].color_num == TM_2_COLORS))
+	{
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Clvl, 0);
+	}
+
+	if ((ctl->dp_unit.local[P_LEVEL].color_num == TM_1_COLORS) ||
+		(ctl->dp_unit.local[P_LEVEL].color_num == TM_2_COLORS))
+	{
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Port, 0);
+	}
+	TM_WRITE_REGISTER(TM.Drop.WREDDropProbMode, TM_Drop_WREDDropProbMode)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_DPSource, PortSrc, ctl->dp_unit.local[P_LEVEL].dp_src[0] +
+		ctl->dp_unit.local[P_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[P_LEVEL].dp_src[2]*4);
+	TM_REGISTER_SET(TM_Drop_DPSource, ClvlSrc, ctl->dp_unit.local[C_LEVEL].dp_src[0]);
+	TM_REGISTER_SET(TM_Drop_DPSource, BlvlSrc, ctl->dp_unit.local[B_LEVEL].dp_src[0]);
+	TM_REGISTER_SET(TM_Drop_DPSource, AlvlSrc, ctl->dp_unit.local[A_LEVEL].dp_src[0]);
+	TM_REGISTER_SET(TM_Drop_DPSource, QueueSrc, ctl->dp_unit.local[Q_LEVEL].dp_src[0]);
+	TM_WRITE_REGISTER(TM.Drop.DPSource, TM_Drop_DPSource)
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_drop_color_num(tm_handle hndl)
+{
+	int rc = -EFAULT;
+	TM_REGISTER_VAR(TM_Drop_WREDDropProbMode)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Port, 0);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Clvl, 0);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Blvl, 0);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Alvl, 0);
+	TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Queue, 0);
+
+	if (ctl->dp_unit.local[Q_LEVEL].color_num > 2)
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Queue, 1);
+	if (ctl->dp_unit.local[A_LEVEL].color_num > 2)
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Alvl, 1);
+	if (ctl->dp_unit.local[B_LEVEL].color_num > 2)
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Blvl, 1);
+	if (ctl->dp_unit.local[C_LEVEL].color_num > 2)
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Clvl, 1);
+	if (ctl->dp_unit.local[P_LEVEL].color_num > 2)
+		TM_REGISTER_SET(TM_Drop_WREDDropProbMode, Port, 1);
+	TM_WRITE_REGISTER(TM.Drop.WREDDropProbMode, TM_Drop_WREDDropProbMode)
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_map(tm_handle hndl, enum tm_level lvl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ClvltoPortAndBlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_BLvltoClvlAndAlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+	TM_REGISTER_VAR(TM_Sched_QueueAMap)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (lvl)
+	{
+	case P_LEVEL:
+		TM_REGISTER_SET(TM_Sched_PortRangeMap, Lo, ctl->tm_port_array[index].first_child_c_node);
+		TM_REGISTER_SET(TM_Sched_PortRangeMap, Hi, ctl->tm_port_array[index].last_child_c_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortRangeMap, index, TM_Sched_PortRangeMap);
+		break;
+	case C_LEVEL:
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, ctl->tm_c_node_array[index].parent_port);
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlLo,
+			ctl->tm_c_node_array[index].first_child_b_node);
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlHi,
+			ctl->tm_c_node_array[index].last_child_b_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvltoPortAndBlvlRangeMap, index, TM_Sched_ClvltoPortAndBlvlRangeMap);
+		break;
+	case B_LEVEL:
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, Clvl, ctl->tm_b_node_array[index].parent_c_node);
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlLo,
+			ctl->tm_b_node_array[index].first_child_a_node);
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlHi,
+			ctl->tm_b_node_array[index].last_child_a_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BLvltoClvlAndAlvlRangeMap, index, TM_Sched_BLvltoClvlAndAlvlRangeMap);
+		break;
+	case A_LEVEL:
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, Blvl, ctl->tm_a_node_array[index].parent_b_node);
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo,
+			ctl->tm_a_node_array[index].first_child_queue;);
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi,
+			ctl->tm_a_node_array[index].last_child_queue);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, index,
+			TM_Sched_ALvltoBlvlAndQueueRangeMap);
+		break;
+	case Q_LEVEL:
+		TM_REGISTER_SET(TM_Sched_QueueAMap, Alvl, ctl->tm_queue_array[index].parent_a_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueAMap, index, TM_Sched_QueueAMap);
+		break;
+	}
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_queue(tm_handle hndl, uint32_t queue_ind)
+{
+	int rc = -EFAULT;
+
+	int entry;
+	int base_ind;
+	struct tm_queue *queue = NULL;
+
+	TM_REGISTER_VAR(TM_Sched_QueueAMap)
+	TM_REGISTER_VAR(TM_Sched_QueueQuantum)
+	TM_REGISTER_VAR(TM_Drop_QueueDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (queue_ind < ((struct rmctl *)(ctl->rm))->rm_total_queues)
+	{
+		queue = &(ctl->tm_queue_array[queue_ind]);
+		TM_REGISTER_SET(TM_Sched_QueueAMap, Alvl, queue->parent_a_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueAMap, queue_ind, TM_Sched_QueueAMap);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_QueueEligPrioFuncPtr, Ptr, queue->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, queue_ind, TM_Sched_QueueEligPrioFuncPtr);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_QueueQuantum, Quantum, queue->dwrr_quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueQuantum, queue_ind, TM_Sched_QueueQuantum);
+		if (rc)
+			goto out;
+
+		/* Set drop profile pointer entry with data exisitng in SW image
+		 * to avoid read-modify-write from HW */
+		/* Entry in the table */
+		entry = queue_ind/TM_Q_DRP_PROF_PER_ENTRY;
+		base_ind = entry*TM_Q_DRP_PROF_PER_ENTRY;
+
+		TM_REGISTER_SET(TM_Drop_QueueDropProfPtr, ProfPtr0, ctl->tm_q_lvl_drop_prof_ptr[base_ind+0]);
+		TM_REGISTER_SET(TM_Drop_QueueDropProfPtr, ProfPtr1, ctl->tm_q_lvl_drop_prof_ptr[base_ind+1]);
+		TM_REGISTER_SET(TM_Drop_QueueDropProfPtr, ProfPtr2, ctl->tm_q_lvl_drop_prof_ptr[base_ind+2]);
+		TM_REGISTER_SET(TM_Drop_QueueDropProfPtr, ProfPtr3, ctl->tm_q_lvl_drop_prof_ptr[base_ind+3]);
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropProfPtr, entry, TM_Drop_QueueDropProfPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_queue(tm_handle hndl, uint32_t index, struct tm_queue *queue)
+{
+	int rc = -EFAULT;
+
+	int entry;
+	int ind;
+
+	TM_REGISTER_VAR(TM_Sched_QueueAMap)
+	TM_REGISTER_VAR(TM_Sched_QueueQuantum)
+	TM_REGISTER_VAR(TM_Drop_QueueDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *)(ctl->rm))->rm_total_queues) {
+		TM_READ_TABLE_REGISTER(TM.Sched.QueueAMap, index, TM_Sched_QueueAMap);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_QueueAMap, Alvl, queue->parent_a_node, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, index, TM_Sched_QueueEligPrioFuncPtr);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFuncPtr, Ptr, queue->elig_prio_func_ptr, (uint8_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.QueueQuantum, index, TM_Sched_QueueQuantum);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_QueueQuantum, Quantum, queue->dwrr_quantum, (uint16_t));
+
+		/* Entry in the table */
+		entry = index/TM_Q_DRP_PROF_PER_ENTRY;
+		ind = index - entry*TM_Q_DRP_PROF_PER_ENTRY;
+
+		TM_READ_TABLE_REGISTER(TM.Drop.QueueDropProfPtr, entry, TM_Drop_QueueDropProfPtr);
+		if (rc)
+			return rc;
+		switch (ind) {
+		case 0:
+			TM_REGISTER_GET(TM_Drop_QueueDropProfPtr, ProfPtr0, queue->wred_profile_ref, (uint8_t));
+			break;
+		case 1:
+			TM_REGISTER_GET(TM_Drop_QueueDropProfPtr, ProfPtr1, queue->wred_profile_ref, (uint8_t));
+			break;
+		case 2:
+			TM_REGISTER_GET(TM_Drop_QueueDropProfPtr, ProfPtr2, queue->wred_profile_ref, (uint8_t));
+			break;
+		case 3:
+			TM_REGISTER_GET(TM_Drop_QueueDropProfPtr, ProfPtr3, queue->wred_profile_ref, (uint8_t));
+			break;
+		}
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_a_node(tm_handle hndl, uint32_t node_ind)
+{
+	int rc = -EFAULT;
+
+	int entry;
+	int base_ind;
+	struct tm_a_node *node = NULL;
+
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+	TM_REGISTER_VAR(TM_Sched_AlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_AlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (node_ind < ((struct rmctl *)(ctl->rm))->rm_total_a_nodes)
+	{
+		node = &(ctl->tm_a_node_array[node_ind]);
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, Blvl, node->parent_b_node);
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi, node->last_child_queue);
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo, node->first_child_queue);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, node_ind,
+									TM_Sched_ALvltoBlvlAndQueueRangeMap);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFuncPtr, node_ind, TM_Sched_AlvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlQuantum, Quantum, node->dwrr_quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlQuantum, node_ind, TM_Sched_AlvlQuantum);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlDWRRPrioEn, En, node->dwrr_priority);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlDWRRPrioEn, node_ind, TM_Sched_AlvlDWRRPrioEn);
+		if (rc)
+			goto out;
+
+		/* Set drop profile pointer entry with data exisitng in SW image
+		 * to avoid read-modify-write from HW */
+		/* Entry in the table */
+		entry = node_ind/TM_A_DRP_PROF_PER_ENTRY;
+		base_ind = entry*TM_A_DRP_PROF_PER_ENTRY;
+
+		TM_REGISTER_SET(TM_Drop_AlvlDropProfPtr, ProfPtr0, ctl->tm_a_lvl_drop_prof_ptr[base_ind+0]);
+		TM_REGISTER_SET(TM_Drop_AlvlDropProfPtr, ProfPtr1, ctl->tm_a_lvl_drop_prof_ptr[base_ind+1]);
+		TM_REGISTER_SET(TM_Drop_AlvlDropProfPtr, ProfPtr2, ctl->tm_a_lvl_drop_prof_ptr[base_ind+2]);
+		TM_REGISTER_SET(TM_Drop_AlvlDropProfPtr, ProfPtr3, ctl->tm_a_lvl_drop_prof_ptr[base_ind+3]);
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropProfPtr, entry, TM_Drop_AlvlDropProfPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_a_node(tm_handle hndl, uint32_t index, struct tm_a_node *node)
+{
+	int rc = -EFAULT;
+
+	int entry;
+	int ind;
+
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+	TM_REGISTER_VAR(TM_Sched_AlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_AlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *)(ctl->rm))->rm_total_a_nodes) {
+		TM_READ_TABLE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, index, TM_Sched_ALvltoBlvlAndQueueRangeMap);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_ALvltoBlvlAndQueueRangeMap, Blvl, node->parent_b_node, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi, node->last_child_queue, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo, node->first_child_queue, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.AlvlEligPrioFuncPtr, index, TM_Sched_AlvlEligPrioFuncPtr);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_AlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr, (uint8_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.AlvlQuantum, index, TM_Sched_AlvlQuantum);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_AlvlQuantum, Quantum, node->dwrr_quantum, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.AlvlDWRRPrioEn, index, TM_Sched_AlvlDWRRPrioEn);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_AlvlDWRRPrioEn, En, node->dwrr_priority, (uint8_t));
+
+		/* Entry in the table */
+		entry = index/TM_A_DRP_PROF_PER_ENTRY;
+		ind = index - entry*TM_A_DRP_PROF_PER_ENTRY;
+
+		TM_READ_TABLE_REGISTER(TM.Drop.AlvlDropProfPtr, entry, TM_Drop_AlvlDropProfPtr);
+		if (rc)
+			return rc;
+		switch (ind) {
+		case 0:
+			TM_REGISTER_GET(TM_Drop_AlvlDropProfPtr, ProfPtr0, node->wred_profile_ref, (uint8_t));
+			break;
+		case 1:
+			TM_REGISTER_GET(TM_Drop_AlvlDropProfPtr, ProfPtr1, node->wred_profile_ref, (uint8_t));
+			break;
+		case 2:
+			TM_REGISTER_GET(TM_Drop_AlvlDropProfPtr, ProfPtr2, node->wred_profile_ref, (uint8_t));
+			break;
+		case 3:
+			TM_REGISTER_GET(TM_Drop_AlvlDropProfPtr, ProfPtr3, node->wred_profile_ref, (uint8_t));
+			break;
+		}
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_b_node(tm_handle hndl, uint32_t node_ind)
+{
+	int rc = -EFAULT;
+	int entry;
+	int base_ind;
+	struct tm_b_node *node = NULL;
+
+	TM_REGISTER_VAR(TM_Sched_BLvltoClvlAndAlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_BlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_BlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (node_ind < ((struct rmctl *)(ctl->rm))->rm_total_b_nodes)
+	{
+		node = &(ctl->tm_b_node_array[node_ind]);
+
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, Clvl, node->parent_c_node);
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlHi, node->last_child_a_node);
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlLo, node->first_child_a_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BLvltoClvlAndAlvlRangeMap, node_ind,
+			TM_Sched_BLvltoClvlAndAlvlRangeMap);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFuncPtr, node_ind, TM_Sched_BlvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlQuantum, Quantum, node->dwrr_quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlQuantum, node_ind, TM_Sched_BlvlQuantum);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlDWRRPrioEn, En, node->dwrr_priority);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlDWRRPrioEn, node_ind, TM_Sched_BlvlDWRRPrioEn);
+		if (rc)
+			goto out;
+
+		/* Set drop profile pointer entry with data exisitng in SW image
+		 * to avoid read-modify-write from HW */
+		/* Entry in the table */
+		entry = node_ind/TM_B_DRP_PROF_PER_ENTRY;
+		base_ind = entry*TM_B_DRP_PROF_PER_ENTRY;
+
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr0, ctl->tm_b_lvl_drop_prof_ptr[base_ind+0]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr1, ctl->tm_b_lvl_drop_prof_ptr[base_ind+1]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr2, ctl->tm_b_lvl_drop_prof_ptr[base_ind+2]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr3, ctl->tm_b_lvl_drop_prof_ptr[base_ind+3]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr4, ctl->tm_b_lvl_drop_prof_ptr[base_ind+4]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr5, ctl->tm_b_lvl_drop_prof_ptr[base_ind+5]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr6, ctl->tm_b_lvl_drop_prof_ptr[base_ind+6]);
+		TM_REGISTER_SET(TM_Drop_BlvlDropProfPtr, ProfPtr7, ctl->tm_b_lvl_drop_prof_ptr[base_ind+7]);
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropProfPtr, entry, TM_Drop_BlvlDropProfPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_b_node(tm_handle hndl, uint32_t index, struct tm_b_node *node)
+{
+	int rc = -EFAULT;
+
+	int entry;
+	int ind;
+
+	TM_REGISTER_VAR(TM_Sched_BLvltoClvlAndAlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_BlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_BlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *)(ctl->rm))->rm_total_b_nodes) {
+		TM_READ_TABLE_REGISTER(TM.Sched.BLvltoClvlAndAlvlRangeMap, index, TM_Sched_BLvltoClvlAndAlvlRangeMap);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_BLvltoClvlAndAlvlRangeMap, Clvl, node->parent_c_node, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlHi, node->last_child_a_node, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlLo, node->first_child_a_node, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.BlvlEligPrioFuncPtr, index, TM_Sched_BlvlEligPrioFuncPtr);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_BlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr, (uint8_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.BlvlQuantum, index, TM_Sched_BlvlQuantum);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_BlvlQuantum, Quantum, node->dwrr_quantum, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.BlvlDWRRPrioEn, index, TM_Sched_BlvlDWRRPrioEn);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_BlvlDWRRPrioEn, En, node->dwrr_priority, (uint8_t));
+
+		/* Entry in the table */
+		entry = index/TM_B_DRP_PROF_PER_ENTRY;
+		ind = index - entry*TM_B_DRP_PROF_PER_ENTRY;
+
+		TM_READ_TABLE_REGISTER(TM.Drop.BlvlDropProfPtr, entry, TM_Drop_BlvlDropProfPtr);
+		if (rc)
+			return rc;
+		switch (ind) {
+		case 0:
+			TM_REGISTER_GET(TM_Drop_BlvlDropProfPtr, ProfPtr0, node->wred_profile_ref, (uint8_t));
+			break;
+		case 1:
+			TM_REGISTER_GET(TM_Drop_BlvlDropProfPtr, ProfPtr1, node->wred_profile_ref, (uint8_t));
+			break;
+		case 2:
+			TM_REGISTER_GET(TM_Drop_BlvlDropProfPtr, ProfPtr2, node->wred_profile_ref, (uint8_t));
+			break;
+		case 3:
+			TM_REGISTER_GET(TM_Drop_BlvlDropProfPtr, ProfPtr3, node->wred_profile_ref, (uint8_t));
+			break;
+		}
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_c_node(tm_handle hndl, uint32_t node_ind)
+{
+	int rc = -EFAULT;
+	int i;
+	int entry;
+	int base_ind;
+	struct tm_c_node *node = NULL;
+
+	TM_REGISTER_VAR(TM_Sched_ClvltoPortAndBlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ClvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_ClvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropProfPtr_CoS)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (node_ind < ((struct rmctl *)(ctl->rm))->rm_total_c_nodes)
+	{
+		node = &(ctl->tm_c_node_array[node_ind]);
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, node->parent_port);
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlHi, node->last_child_b_node);
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlLo, node->first_child_b_node);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvltoPortAndBlvlRangeMap, node_ind,
+			TM_Sched_ClvltoPortAndBlvlRangeMap);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFuncPtr, node_ind, TM_Sched_ClvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlQuantum, Quantum, node->dwrr_quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlQuantum, node_ind, TM_Sched_ClvlQuantum);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlDWRRPrioEn, En, node->dwrr_priority);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlDWRRPrioEn, node_ind, TM_Sched_ClvlDWRRPrioEn);
+		if (rc)
+			goto out;
+
+		/* Set drop profile pointer entry with data exisitng in SW image
+		 * to avoid read-modify-write from HW */
+		/* Entry in the table */
+		entry = node_ind/TM_C_DRP_PROF_PER_ENTRY;
+		base_ind = entry*TM_C_DRP_PROF_PER_ENTRY;
+
+		for (i = 0; i < TM_WRED_COS; i++) {
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr0,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+0]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr1,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+1]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr2,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+2]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr3,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+3]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr4,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+4]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr5,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+5]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr6,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+6]);
+			TM_REGISTER_SET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr7,
+				ctl->tm_c_lvl_drop_prof_ptr[i][base_ind+7]);
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropProfPtr_CoS[i], entry, TM_Drop_ClvlDropProfPtr_CoS);
+			if (rc)
+				goto out;
+		}
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_c_node(tm_handle hndl, uint32_t index, struct tm_c_node *node)
+{
+	int rc = -EFAULT;
+	int i;
+	int entry;
+	int ind;
+
+	TM_REGISTER_VAR(TM_Sched_ClvltoPortAndBlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ClvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_ClvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropProfPtr_CoS)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *)(ctl->rm))->rm_total_c_nodes) {
+		TM_READ_TABLE_REGISTER(TM.Sched.ClvltoPortAndBlvlRangeMap, index, TM_Sched_ClvltoPortAndBlvlRangeMap);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, node->parent_port, (uint8_t));
+		TM_REGISTER_GET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlHi, node->last_child_b_node, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlLo, node->first_child_b_node, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.ClvlEligPrioFuncPtr, index, TM_Sched_ClvlEligPrioFuncPtr);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_ClvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr, (uint8_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.ClvlQuantum, index, TM_Sched_ClvlQuantum);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_ClvlQuantum, Quantum, node->dwrr_quantum, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.ClvlDWRRPrioEn, index, TM_Sched_ClvlDWRRPrioEn);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_ClvlDWRRPrioEn, En, node->dwrr_priority, (uint8_t));
+
+		/* Entry in the table */
+		entry = index/TM_C_DRP_PROF_PER_ENTRY;
+		ind = index - entry*TM_C_DRP_PROF_PER_ENTRY;
+
+		for (i = 0; i < TM_WRED_COS; i++) {
+			TM_READ_TABLE_REGISTER(TM.Drop.ClvlDropProfPtr_CoS[i], entry, TM_Drop_ClvlDropProfPtr_CoS);
+			if (rc)
+				return rc;
+			switch (ind) {
+			case 0:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr0,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 1:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr1,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 2:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr2,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 3:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr3,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 4:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr4,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 5:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr5,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 6:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr6,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			case 7:
+				TM_REGISTER_GET(TM_Drop_ClvlDropProfPtr_CoS, ProfPtr7,
+					node->wred_profile_ref[i], (uint8_t));
+				break;
+			}
+		}
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_queue_elig_prio_func_ptr(tm_handle hndl, uint32_t ind)
+{
+	int rc = -EFAULT;
+
+	struct tm_queue *node;
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (ind < ((struct rmctl *) (ctl->rm))->rm_total_queues) {
+		node = &(ctl->tm_queue_array[ind]);
+		TM_REGISTER_SET(TM_Sched_QueueEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, ind, TM_Sched_QueueEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_a_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind)
+{
+	int rc = -EFAULT;
+
+	struct tm_a_node *node;
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (ind < ((struct rmctl *) (ctl->rm))->rm_total_a_nodes) {
+		node = &(ctl->tm_a_node_array[ind]);
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFuncPtr, ind, TM_Sched_AlvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_b_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind)
+{
+	int rc = -EFAULT;
+
+	struct tm_b_node *node;
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (ind < ((struct rmctl *) (ctl->rm))->rm_total_b_nodes) {
+		node = &(ctl->tm_b_node_array[ind]);
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFuncPtr, ind, TM_Sched_BlvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_c_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind)
+{
+	int rc = -EFAULT;
+
+	struct tm_c_node *node;
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (ind < ((struct rmctl *) (ctl->rm))->rm_total_c_nodes) {
+		node = &(ctl->tm_c_node_array[ind]);
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFuncPtr, Ptr, node->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFuncPtr, ind, TM_Sched_ClvlEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_port_elig_prio_func_ptr(tm_handle hndl, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+
+	struct tm_port *port;
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		port = &(ctl->tm_port_array[port_ind]);
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFuncPtr, Ptr, port->elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFuncPtr, port_ind, TM_Sched_PortEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+
+#define GET_ELIG_PRIO_HW_MAC(level, max_nodes)	\
+	do {\
+		int rc = -EFAULT;\
+		TM_REGISTER_VAR(TM_Sched_##level##EligPrioFuncPtr)\
+\
+		DECLARE_TM_CTL_PTR(ctl, hndl)\
+		CHECK_TM_CTL_PTR(ctl)\
+\
+		if (ind < max_nodes) {\
+			TM_READ_TABLE_REGISTER(TM.Sched.level##EligPrioFuncPtr, ind,\
+									TM_Sched_##level##EligPrioFuncPtr);\
+			if (rc)\
+				goto out;\
+			if (pfunc)\
+				TM_REGISTER_GET(TM_Sched_##level##EligPrioFuncPtr, Ptr, *pfunc, (uint8_t));\
+		} \
+out:\
+		COMPLETE_HW_WRITE\
+		return rc;\
+	} while (0)
+
+int get_hw_queue_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc)
+{
+	GET_ELIG_PRIO_HW_MAC(Queue, ((struct rmctl *) (ctl->rm))->rm_total_queues);
+}
+int get_hw_a_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc)
+{
+	GET_ELIG_PRIO_HW_MAC(Alvl, ((struct rmctl *) (ctl->rm))->rm_total_a_nodes);
+}
+int get_hw_b_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc)
+{
+	GET_ELIG_PRIO_HW_MAC(Blvl, ((struct rmctl *) (ctl->rm))->rm_total_b_nodes);
+}
+int get_hw_c_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc)
+{
+	GET_ELIG_PRIO_HW_MAC(Clvl, ((struct rmctl *) (ctl->rm))->rm_total_c_nodes);
+}
+int get_hw_port_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc)
+{
+	GET_ELIG_PRIO_HW_MAC(Port, ((struct rmctl *) (ctl->rm))->rm_total_ports);
+}
+
+
+/**
+ */
+
+int __set_hw_port_shaping(tm_handle hndl, uint8_t port_ind,
+						uint32_t cbw, uint32_t ebw, uint32_t cbs, uint32_t ebs)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortTokenBucketTokenEnDiv)
+	TM_REGISTER_VAR(TM_Sched_PortTokenBucketBurstSize)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, Periods, TM_FIXED_2_5_G_PORT_SHAPING_PERIODS);
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, MinToken, cbw/TM_FIXED_10_M_SHAPING_TOKEN);
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, MaxToken, ebw/TM_FIXED_10_M_SHAPING_TOKEN);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortTokenBucketTokenEnDiv, port_ind,
+			TM_Sched_PortTokenBucketTokenEnDiv);
+		if (rc)
+			goto out;
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketBurstSize, MaxBurstSz, cbs);
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketBurstSize, MinBurstSz, ebs);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortTokenBucketBurstSize, port_ind,
+			TM_Sched_PortTokenBucketBurstSize);
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+/**
+ */
+int set_hw_port_shaping_ex(tm_handle hndl, uint8_t port_ind,
+						uint32_t cbw, uint32_t ebw ,  uint32_t *pcbs, uint32_t *pebs)
+{
+	int cbs, ebs;
+	int rc = 0;
+/*
+	cbs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) / 1024;
+	ebs= 2 * ( (min_bw/TM_FIXED_10_M_SHAPING_TOKEN) / 1024;
+*/
+	SET_BURSTS(TM_FIXED_2_5_G_PORT_SHAPING_BURST_SIZE, TM_FIXED_2_5_G_PORT_SHAPING_BURST_SIZE);
+
+	if (rc == 0)
+		return __set_hw_port_shaping(hndl, port_ind, cbw, ebw, cbs, ebs);
+	else
+		return TM_CONF_MIN_TOKEN_TOO_LARGE;
+
+}
+
+int set_hw_port_shaping_def(tm_handle hndl, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	struct tm_port *port = NULL;
+
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if ((port_ind < get_tm_port_count()) && (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports)) {
+		port = &(ctl->tm_port_array[port_ind]);
+		switch (port->port_speed) {
+		case TM_1G_PORT:
+			return set_hw_port_shaping_ex(hndl, port_ind, 1000, 0, NULL, NULL);
+			break;
+		case TM_2HG_PORT:
+			return set_hw_port_shaping_ex(hndl, port_ind, 2500, 0, NULL, NULL);
+			break;
+		case TM_10G_PORT:
+			return set_hw_port_shaping_ex(hndl, port_ind, 10000, 0, NULL, NULL);
+			break;
+			/* TBD */
+		case TM_40G_PORT:
+		case TM_50G_PORT:
+		case TM_100G_PORT:
+		default:
+			break;
+		}
+	}
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int get_hw_port_shaping(tm_handle hndl, uint32_t index,
+						uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs)
+{
+	GET_NODE_SHAPING_MAC(Port, index < ((struct rmctl *) (ctl->rm))->rm_total_ports);
+}
+
+/**
+ */
+int set_hw_port_scheduling(tm_handle hndl, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	struct tm_port *port = NULL;
+#ifdef MV_QMTM_NSS_A0
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosLo)
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosHi)
+#endif
+	TM_REGISTER_VAR(TM_Sched_PortDWRRPrioEn)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		port = &(ctl->tm_port_array[port_ind]);
+
+#ifdef MV_QMTM_NSS_A0
+		/* DWRR for Port */
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum0, port->dwrr_quantum[0].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum1, port->dwrr_quantum[1].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum2, port->dwrr_quantum[2].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum3, port->dwrr_quantum[3].quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortQuantumsPriosLo, port_ind, TM_Sched_PortQuantumsPriosLo);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum4, port->dwrr_quantum[4].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum5, port->dwrr_quantum[5].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum6, port->dwrr_quantum[6].quantum);
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum7, port->dwrr_quantum[7].quantum);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortQuantumsPriosHi, port_ind, TM_Sched_PortQuantumsPriosHi);
+		if (rc)
+			goto out;
+#endif
+		/* DWRR for C-nodes in Port's range */
+		TM_REGISTER_SET(TM_Sched_PortDWRRPrioEn, En, port->dwrr_priority);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDWRRPrioEn, port_ind, TM_Sched_PortDWRRPrioEn);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_port_drop(tm_handle hndl, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	struct tm_port *port = NULL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		port = &(ctl->tm_port_array[port_ind]);
+		rc = set_hw_ports_drop_profile(hndl, port->wred_profile_ref, port_ind);
+	}
+	return rc;
+}
+
+
+int set_hw_port_drop_cos(tm_handle hndl, uint8_t port_ind, uint8_t cos)
+{
+	int rc = 0;
+	struct tm_port *port ;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		port = &(ctl->tm_port_array[port_ind]);
+		rc = set_hw_ports_drop_profile_cos(hndl, cos, port->wred_profile_ref_cos[cos], port_ind);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_port(tm_handle hndl, uint8_t port_ind)
+{
+	int rc = -EFAULT;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (port_ind < ((struct rmctl *) (ctl->rm))->rm_total_ports)
+	{
+		rc = set_hw_map(hndl, P_LEVEL, port_ind);
+		if (rc < 0)
+			goto out;
+
+		rc = set_hw_port_shaping_def(hndl, port_ind);
+		if (rc < 0)
+			goto out;
+#ifdef MV_QMTM_NSS_A0
+		rc = set_hw_port_scheduling(hndl, port_ind);
+		if (rc < 0)
+			goto out;
+#endif
+
+		rc = set_hw_port_drop(hndl, port_ind);
+		if (rc < 0)
+			goto out;
+
+		rc = set_hw_port_elig_prio_func_ptr(hndl, port_ind);
+	}
+out:
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_port(tm_handle hndl, uint8_t index, struct tm_port *port)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortRangeMap)
+#ifdef MV_QMTM_NSS_A0
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosLo)
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosHi)
+#endif
+	TM_REGISTER_VAR(TM_Sched_PortDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFuncPtr)
+	/* No Drop Profile Ptr for Port */
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *)(ctl->rm))->rm_total_ports) {
+		TM_READ_TABLE_REGISTER(TM.Sched.PortRangeMap, index, TM_Sched_PortRangeMap);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_PortRangeMap, Hi, port->last_child_c_node, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortRangeMap, Lo, port->first_child_c_node, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.PortEligPrioFuncPtr, index, TM_Sched_PortEligPrioFuncPtr);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_PortEligPrioFuncPtr, Ptr, port->elig_prio_func_ptr, (uint8_t));
+
+#ifdef MV_QMTM_NSS_A0
+		/* DWRR for Port */
+		TM_READ_TABLE_REGISTER(TM.Sched.PortQuantumsPriosLo, index, TM_Sched_PortQuantumsPriosLo);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosLo, Quantum0, port->dwrr_quantum[0].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosLo, Quantum1, port->dwrr_quantum[1].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosLo, Quantum2, port->dwrr_quantum[2].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosLo, Quantum3, port->dwrr_quantum[3].quantum, (uint16_t));
+
+		TM_READ_TABLE_REGISTER(TM.Sched.PortQuantumsPriosHi, index, TM_Sched_PortQuantumsPriosHi);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosHi, Quantum4, port->dwrr_quantum[4].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosHi, Quantum5, port->dwrr_quantum[5].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosHi, Quantum6, port->dwrr_quantum[6].quantum, (uint16_t));
+		TM_REGISTER_GET(TM_Sched_PortQuantumsPriosHi, Quantum7, port->dwrr_quantum[7].quantum, (uint16_t));
+#endif
+
+		TM_READ_TABLE_REGISTER(TM.Sched.PortDWRRPrioEn, index, TM_Sched_PortDWRRPrioEn);
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Sched_PortDWRRPrioEn, En, port->dwrr_priority, (uint8_t));
+
+		/* No Drop Profile Ptr for Port */
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_tree_deq_status(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_TreeDeqEn)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_TreeDeqEn, En, ctl->tree_deq_status);
+	TM_WRITE_REGISTER(TM.Sched.TreeDeqEn, TM_Sched_TreeDeqEn)
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+#ifdef MV_QMTM_NSS_A0
+/**
+ */
+int set_hw_tree_dwrr_priority(tm_handle hndl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_TreeDWRRPrioEn)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_TreeDWRRPrioEn, PrioEn, ctl->tree_dwrr_priority);
+	TM_WRITE_REGISTER(TM.Sched.TreeDWRRPrioEn, TM_Sched_TreeDWRRPrioEn)
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+#endif
+
+
+/**
+ */
+int set_hw_deq_status(tm_handle hndl, enum tm_level lvl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (lvl)
+	{
+	case P_LEVEL:
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFuncPtr, Ptr, ctl->tm_port_array[index].elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFuncPtr, index, TM_Sched_PortEligPrioFuncPtr);
+		break;
+	case C_LEVEL:
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFuncPtr, Ptr, ctl->tm_c_node_array[index].elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFuncPtr, index, TM_Sched_ClvlEligPrioFuncPtr);
+		break;
+	case B_LEVEL:
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFuncPtr, Ptr, ctl->tm_b_node_array[index].elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFuncPtr, index, TM_Sched_BlvlEligPrioFuncPtr);
+		break;
+	case A_LEVEL:
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFuncPtr, Ptr, ctl->tm_a_node_array[index].elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFuncPtr, index, TM_Sched_AlvlEligPrioFuncPtr);
+		break;
+	case Q_LEVEL:
+		TM_REGISTER_SET(TM_Sched_QueueEligPrioFuncPtr, Ptr, ctl->tm_queue_array[index].elig_prio_func_ptr);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, index, TM_Sched_QueueEligPrioFuncPtr);
+		break;
+	}
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_disable_ports(tm_handle hndl, uint32_t total_ports)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* Disable Ports */
+	for (i = 0; i < (int)total_ports; i++)
+	{
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFuncPtr, Ptr, 63); /* DeQ disable function ID */
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFuncPtr, i, TM_Sched_PortEligPrioFuncPtr);
+		if (rc)
+			goto out;
+	}
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+
+
+/**
+*  Configure user Q level Eligible Priority Function
+*/
+int set_hw_q_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	struct tm_elig_prio_func_queue *params;
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFunc)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	params = &(ctl->tm_elig_prio_q_lvl_tbl[func_offset]);
+	/* assign register fields */
+	TM_REGISTER_SET(TM_Sched_QueueEligPrioFunc , FuncOut0 , params->tbl_entry.func_out[0])
+	TM_REGISTER_SET(TM_Sched_QueueEligPrioFunc , FuncOut1 , params->tbl_entry.func_out[1])
+	TM_REGISTER_SET(TM_Sched_QueueEligPrioFunc , FuncOut2 , params->tbl_entry.func_out[2])
+	TM_REGISTER_SET(TM_Sched_QueueEligPrioFunc , FuncOut3 , params->tbl_entry.func_out[3])
+	/* write register */
+	TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFunc, func_offset, TM_Sched_QueueEligPrioFunc)
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+/**
+ *  Configure user Node level Eligible Priority Function
+ */
+int set_hw_a_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFunc)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < 8; i++)	{
+		/* assign register fields */
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFunc , FuncOut0 ,
+			ctl->tm_elig_prio_a_lvl_tbl[func_offset].tbl_entry[i].func_out[0])
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFunc , FuncOut1 ,
+			ctl->tm_elig_prio_a_lvl_tbl[func_offset].tbl_entry[i].func_out[1])
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFunc , FuncOut2 ,
+			ctl->tm_elig_prio_a_lvl_tbl[func_offset].tbl_entry[i].func_out[2])
+		TM_REGISTER_SET(TM_Sched_AlvlEligPrioFunc , FuncOut3 ,
+			ctl->tm_elig_prio_a_lvl_tbl[func_offset].tbl_entry[i].func_out[3])
+		/* write register */
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFunc, func_offset + i*64 , TM_Sched_AlvlEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_b_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFunc)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < 8; i++)	{
+		/* assign register fields */
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFunc , FuncOut0 ,
+			ctl->tm_elig_prio_b_lvl_tbl[func_offset].tbl_entry[i].func_out[0])
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFunc , FuncOut1 ,
+			ctl->tm_elig_prio_b_lvl_tbl[func_offset].tbl_entry[i].func_out[1])
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFunc , FuncOut2 ,
+			ctl->tm_elig_prio_b_lvl_tbl[func_offset].tbl_entry[i].func_out[2])
+		TM_REGISTER_SET(TM_Sched_BlvlEligPrioFunc , FuncOut3 ,
+			ctl->tm_elig_prio_b_lvl_tbl[func_offset].tbl_entry[i].func_out[3])
+		/* write register */
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFunc, func_offset + i*64 , TM_Sched_BlvlEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_c_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFunc)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < 8; i++)	{
+		/* assign register fields */
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFunc , FuncOut0 ,
+			ctl->tm_elig_prio_c_lvl_tbl[func_offset].tbl_entry[i].func_out[0]);
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFunc , FuncOut1 ,
+			ctl->tm_elig_prio_c_lvl_tbl[func_offset].tbl_entry[i].func_out[1]);
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFunc , FuncOut2 ,
+			ctl->tm_elig_prio_c_lvl_tbl[func_offset].tbl_entry[i].func_out[2]);
+		TM_REGISTER_SET(TM_Sched_ClvlEligPrioFunc , FuncOut3 ,
+			ctl->tm_elig_prio_c_lvl_tbl[func_offset].tbl_entry[i].func_out[3]);
+		/* write register */
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFunc, func_offset + i*64 , TM_Sched_ClvlEligPrioFunc);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE;
+	return rc;
+}
+
+int set_hw_p_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFunc)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (i = 0; i < 8; i++)	{/* Entry ID */
+		/* assign register fields */
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFunc , FuncOut0 ,
+			ctl->tm_elig_prio_p_lvl_tbl[func_offset].tbl_entry[i].func_out[0])
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFunc , FuncOut1 ,
+			ctl->tm_elig_prio_p_lvl_tbl[func_offset].tbl_entry[i].func_out[1])
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFunc , FuncOut2 ,
+			ctl->tm_elig_prio_p_lvl_tbl[func_offset].tbl_entry[i].func_out[2])
+		TM_REGISTER_SET(TM_Sched_PortEligPrioFunc , FuncOut3 ,
+			ctl->tm_elig_prio_p_lvl_tbl[func_offset].tbl_entry[i].func_out[3])
+		/* write register */
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFunc , func_offset + i*64 , TM_Sched_PortEligPrioFunc);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_elig_prio_func_tbl_q_level(tm_handle hndl)
+{
+	int j;
+	int rc;
+
+	for (j = 0; j < TM_ELIG_FUNC_TABLE_SIZE; j++) {
+		rc = set_hw_q_elig_prio_func_entry(hndl, j);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_elig_prio_func_tbl_a_level(tm_handle hndl)
+{
+	int rc =  -EFAULT;
+	int j;
+	for (j = 0; j < TM_ELIG_FUNC_TABLE_SIZE; j++) {
+		rc = set_hw_a_lvl_elig_prio_func_entry(hndl, j);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_elig_prio_func_tbl_b_level(tm_handle hndl)
+{
+	int rc =  -EFAULT;
+	int j;
+	for (j = 0; j < TM_ELIG_FUNC_TABLE_SIZE; j++) {
+		rc = set_hw_b_lvl_elig_prio_func_entry(hndl, j);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+
+/**
+ */
+int set_hw_elig_prio_func_tbl_c_level(tm_handle hndl)
+{
+	int rc =  -EFAULT;
+	int j;
+	for (j = 0; j < TM_ELIG_FUNC_TABLE_SIZE; j++) {
+		rc = set_hw_c_lvl_elig_prio_func_entry(hndl, j);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+
+/**
+ */
+int set_hw_elig_prio_func_tbl_p_level(tm_handle hndl)
+{
+	int rc =  -EFAULT;
+	int j;
+	for (j = 0; j < TM_ELIG_FUNC_TABLE_SIZE; j++) {
+		rc = set_hw_p_lvl_elig_prio_func_entry(hndl, j);
+		if (rc)
+			break;
+	}
+	return rc;
+}
+
+/**
+ */
+int set_hw_port_deficit_clear(tm_handle hndl, uint8_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioHi)
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioLo)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_ports) {
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit0, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit1, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit2, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit3, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDefPrioHi, index, TM_Sched_PortDefPrioHi);
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit0, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit1, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit2, 0x1);
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit3, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDefPrioLo, index, TM_Sched_PortDefPrioLo);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_c_node_deficit_clear(tm_handle hndl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_CLvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_c_nodes) {
+		TM_REGISTER_SET(TM_Sched_CLvlDef, Deficit, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.CLvlDef, index, TM_Sched_CLvlDef);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_b_node_deficit_clear(tm_handle hndl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_BlvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_b_nodes) {
+		TM_REGISTER_SET(TM_Sched_BlvlDef, Deficit, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlDef, index, TM_Sched_BlvlDef);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_a_node_deficit_clear(tm_handle hndl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_AlvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_a_nodes) {
+		TM_REGISTER_SET(TM_Sched_AlvlDef, Deficit, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlDef, index, TM_Sched_AlvlDef);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_queue_deficit_clear(tm_handle hndl, uint32_t index)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_QueueDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_queues) {
+		TM_REGISTER_SET(TM_Sched_QueueDef, Deficit, 0x1);
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueDef, index, TM_Sched_QueueDef);
+		if (rc)
+			goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_dp_local_resp(tm_handle hndl, uint8_t port_dp, enum tm_level local_lvl)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_RespLocalDPSel)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	(void)port_dp;
+
+	TM_REGISTER_SET(TM_Drop_RespLocalDPSel, DPSel, local_lvl);
+	TM_WRITE_REGISTER(TM.Drop.RespLocalDPSel, TM_Drop_RespLocalDPSel)
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_port_sms_attr_pbase(tm_handle hndl, uint8_t index)
+{
+	int rc = -EFAULT;
+	(void) hndl;
+	(void)index;
+	/*
+	check if it exists in SN
+	struct TM_RCB_SMSPortAttrPBase p_attr;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	p_attr.PBase = ctl->tm_port_sms_attr_pbase[index].pbase;
+	p_attr.PShift = ctl->tm_port_sms_attr_pbase[index].pshift;
+	*//* debug fields *//*
+	p_attr.AddTiRxHead = 0;
+	p_attr.RxChanFieldEn = 0;
+
+	p_attr.RxTimeFieldEn = 0;
+	rc = tm_table_entry_write(TM_ENV(ctl), (void *)&TM.RCB.SMSPortAttrPBase, index, &p_attr);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+*/
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_port_sms_attr_qmap_pars(tm_handle hndl, uint8_t index)
+{
+	int rc = -EFAULT;
+	(void) hndl;
+	(void) index;
+	/*
+	check if it exists in SN
+	struct TM_RCB_SMSPortAttrQmapPars q_map ;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	q_map.ParseMode = ctl->tm_port_sms_attr_qmap_pars[index].mode;
+	q_map.BaseQ = ctl->tm_port_sms_attr_qmap_pars[index].base_q;
+	q_map.DfltColor = ctl->tm_port_sms_attr_qmap_pars[index].dcolor;
+	*//* debug fields *//*
+	q_map.EType = 0x8100;
+	q_map.QmapStrip = 0;
+	q_map.Offs = 0;
+	rc = tm_table_entry_write(TM_ENV(ctl), (void *)&TM.RCB.SMSPortAttrQmapPars, index, &q_map);
+	if (rc)
+		goto out;
+
+out:
+	COMPLETE_HW_WRITE
+*/
+	return rc;
+}
+
+
+
+
+int set_hw_dp_source(tm_handle hndl)
+{
+	int rc;
+	TM_REGISTER_VAR(TM_Drop_DPSource)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Drop_DPSource, PortSrc, ctl->dp_unit.local[P_LEVEL].dp_src[0] +
+	ctl->dp_unit.local[P_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[P_LEVEL].dp_src[2]*4)
+	TM_REGISTER_SET(TM_Drop_DPSource, ClvlSrc, ctl->dp_unit.local[C_LEVEL].dp_src[0] +
+	ctl->dp_unit.local[C_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[C_LEVEL].dp_src[2]*4)
+	TM_REGISTER_SET(TM_Drop_DPSource, BlvlSrc, ctl->dp_unit.local[B_LEVEL].dp_src[0] +
+	ctl->dp_unit.local[B_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[B_LEVEL].dp_src[2]*4)
+	TM_REGISTER_SET(TM_Drop_DPSource, AlvlSrc, ctl->dp_unit.local[A_LEVEL].dp_src[0] +
+	ctl->dp_unit.local[A_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[A_LEVEL].dp_src[2]*4)
+	TM_REGISTER_SET(TM_Drop_DPSource, QueueSrc, ctl->dp_unit.local[Q_LEVEL].dp_src[0] +
+	ctl->dp_unit.local[Q_LEVEL].dp_src[1]*2 + ctl->dp_unit.local[Q_LEVEL].dp_src[2]*4)
+	TM_WRITE_REGISTER(TM.Drop.DPSource, TM_Drop_DPSource)
+	if (rc)
+		goto out;
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int set_hw_queue_cos(tm_handle hndl, uint32_t index)
+{
+	int rc = -EFAULT;
+	uint32_t entry = index/4;
+	uint32_t base = entry*4;
+
+	TM_REGISTER_VAR(TM_Drop_QueueCoSConf)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (index < ((struct rmctl *) (ctl->rm))->rm_total_queues) {
+		TM_REGISTER_SET(TM_Drop_QueueCoSConf, QueueCos0, ctl->tm_q_cos[base]);
+		TM_REGISTER_SET(TM_Drop_QueueCoSConf, QueueCos1, ctl->tm_q_cos[base + 1]);
+		TM_REGISTER_SET(TM_Drop_QueueCoSConf, QueueCos2, ctl->tm_q_cos[base + 2]);
+		TM_REGISTER_SET(TM_Drop_QueueCoSConf, QueueCos3, ctl->tm_q_cos[base + 3]);
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueCoSConf, entry, TM_Drop_QueueCoSConf);
+	}
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+/**
+ */
+int set_hw_register_db_default(tm_handle hndl)
+{
+	int rc = -EFAULT;
+	uint32_t i, j;
+	uint32_t cos;
+	uint32_t max_entries;
+
+	/* Drop */
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDDPRatio)
+
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_AlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Drop_AlvlREDCurve_Color)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDDPRatio)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropProfPtr)
+	TM_REGISTER_VAR(TM_Drop_BlvlREDCurve_Table)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfTailDrpThresh_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDDPRatio_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDMinThresh_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDParams_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropPrfWREDScaleRatio_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropProfPtr_CoS)
+	TM_REGISTER_VAR(TM_Drop_ClvlREDCurve_CoS)
+	TM_REGISTER_VAR(TM_Drop_ExcMask)
+	TM_REGISTER_VAR(TM_Drop_DPSource)
+	TM_REGISTER_VAR(TM_Drop_Drp_Decision_hierarchy_to_Query_debug)/*NEW*/
+	TM_REGISTER_VAR(TM_Drop_Drp_Decision_to_Query_debug)/*NEW*/
+	TM_REGISTER_VAR(TM_Drop_EccConfig)/*NEW*/
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfTailDrpThresh_CoSRes)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDDPRatio)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDDPRatio_CoSRes)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDMinThresh_CoSRes)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDParams_CoSRes)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_PortDropPrfWREDScaleRatio_CoSRes)
+	TM_REGISTER_VAR(TM_Drop_PortREDCurve)
+	TM_REGISTER_VAR(TM_Drop_PortREDCurve_CoS)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfTailDrpThresh)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDDPRatio)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDMinThresh)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDParams)
+	TM_REGISTER_VAR(TM_Drop_QueueDropPrfWREDScaleRatio)
+	TM_REGISTER_VAR(TM_Drop_QueueCoSConf)
+	TM_REGISTER_VAR(TM_Drop_QueueDropProfPtr)
+	TM_REGISTER_VAR(TM_Drop_QueueREDCurve_Color)
+	TM_REGISTER_VAR(TM_Drop_RespLocalDPSel)
+	TM_REGISTER_VAR(TM_Drop_WREDDropProbMode)
+	TM_REGISTER_VAR(TM_Drop_WREDMaxProbModePerColor)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Drop_AlvlDropProb)
+	TM_REGISTER_VAR(TM_Drop_AlvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_BlvlDropProb)
+	TM_REGISTER_VAR(TM_Drop_BlvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_ClvlDropProb)
+	TM_REGISTER_VAR(TM_Drop_ClvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_EccMemParams)/*NEW*/
+	TM_REGISTER_VAR(TM_Drop_ErrCnt)
+	TM_REGISTER_VAR(TM_Drop_ErrStus)
+	TM_REGISTER_VAR(TM_Drop_ExcCnt)
+	TM_REGISTER_VAR(TM_Drop_FirstExc)
+	TM_REGISTER_VAR(TM_Drop_ForceErr)
+	TM_REGISTER_VAR(TM_Drop_Id)
+	TM_REGISTER_VAR(TM_Drop_PortDropProb)
+	TM_REGISTER_VAR(TM_Drop_PortDropProbPerCoS_CoS)
+	TM_REGISTER_VAR(TM_Drop_PortInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_PortInstAndAvgQueueLengthPerCoS_CoS)
+	TM_REGISTER_VAR(TM_Drop_QueueAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_QueueDropProb)
+#endif
+
+	/* Sched */
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+	TM_REGISTER_VAR(TM_Sched_AlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_AlvlDef)
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_AlvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_AlvlPerRateShpPrms)
+	TM_REGISTER_VAR(TM_Sched_AlvlPerRateShpPrmsInt)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_AlvlTokenBucketBurstSize)
+	TM_REGISTER_VAR(TM_Sched_AlvlTokenBucketTokenEnDiv)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_ALevelShaperBucketNeg)
+	TM_REGISTER_VAR(TM_Sched_AlvlBankEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL0ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL0ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL1ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL1ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL2ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlL2ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlMyQ)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlMyQEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlNodeState)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlPerStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlRRDWRRStatus01)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlRRDWRRStatus23)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlRRDWRRStatus45)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlRRDWRRStatus67)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_AlvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_AlvlWFS)/*NEW*/
+#endif
+	TM_REGISTER_VAR(TM_Sched_BLvltoClvlAndAlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_BlvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_BlvlDef)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_BlvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_BlvlPerRateShpPrms)
+	TM_REGISTER_VAR(TM_Sched_BlvlPerRateShpPrmsInt)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_BlvlTokenBucketBurstSize)
+	TM_REGISTER_VAR(TM_Sched_BlvlTokenBucketTokenEnDiv)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_BLevelShaperBucketNeg)
+	TM_REGISTER_VAR(TM_Sched_BlvlBankEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlL0ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlL0ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlL1ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlL1ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlMyQ)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlMyQEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlNodeState)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlPerStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlRRDWRRStatus01)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlRRDWRRStatus23)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlRRDWRRStatus45)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlRRDWRRStatus67)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_BlvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_BlvlWFS)/*NEW*/
+#endif
+	TM_REGISTER_VAR(TM_Sched_CLvlDef)
+	TM_REGISTER_VAR(TM_Sched_ClvlDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_ClvlPerConf)
+	TM_REGISTER_VAR(TM_Sched_ClvlPerRateShpPrms)
+	TM_REGISTER_VAR(TM_Sched_ClvlPerRateShpPrmsInt)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlQuantum)
+	TM_REGISTER_VAR(TM_Sched_ClvlTokenBucketBurstSize)
+	TM_REGISTER_VAR(TM_Sched_ClvlTokenBucketTokenEnDiv)
+	TM_REGISTER_VAR(TM_Sched_ClvltoPortAndBlvlRangeMap)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_CLevelShaperBucketNeg)
+	TM_REGISTER_VAR(TM_Sched_ClvlBPFromSTF)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlBankEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlL0ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlL0ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlMyQ)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlMyQEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlNodeState)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlPerStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlRRDWRRStatus01)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlRRDWRRStatus23)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlRRDWRRStatus45)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlRRDWRRStatus67)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ClvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_ClvlWFS)/*NEW*/
+#endif
+	TM_REGISTER_VAR(TM_Sched_PortDWRRBytesPerBurstsLimit)
+	TM_REGISTER_VAR(TM_Sched_PortDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioHi)
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioLo)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_PortExtBPEn)
+	TM_REGISTER_VAR(TM_Sched_PortPerConf)
+	TM_REGISTER_VAR(TM_Sched_PortPerRateShpPrms)
+	TM_REGISTER_VAR(TM_Sched_PortPerRateShpPrmsInt)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosHi)
+	TM_REGISTER_VAR(TM_Sched_PortQuantumsPriosLo)
+	TM_REGISTER_VAR(TM_Sched_PortRangeMap)
+	TM_REGISTER_VAR(TM_Sched_PortTokenBucketBurstSize)
+	TM_REGISTER_VAR(TM_Sched_PortTokenBucketTokenEnDiv)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_PortShaperBucketNeg)
+	TM_REGISTER_VAR(TM_Sched_PortBPFromQMgr)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortBPFromSTF)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortBankEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortMyQ)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortNodeState)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortPerStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortRRDWRRStatus01)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortRRDWRRStatus23)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortRRDWRRStatus45)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortRRDWRRStatus67)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortWFS)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_PortShpBucketLvls)
+#endif
+	TM_REGISTER_VAR(TM_Sched_QueueAMap)
+	TM_REGISTER_VAR(TM_Sched_QueueDef)
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+	TM_REGISTER_VAR(TM_Sched_QueuePerConf)
+	TM_REGISTER_VAR(TM_Sched_QueuePerRateShpPrms)
+	TM_REGISTER_VAR(TM_Sched_QueuePerRateShpPrmsInt)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueQuantum)
+	TM_REGISTER_VAR(TM_Sched_QueueTokenBucketBurstSize)
+	TM_REGISTER_VAR(TM_Sched_QueueTokenBucketTokenEnDiv)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_QueueBank0EccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueBank1EccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueBank2EccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueBank3EccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL0ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL0ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL1ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL1ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL2ClusterStateHi)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueL2ClusterStateLo)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueNodeState)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueuePerStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueWFS)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_QueueShaperBucketNeg)
+	TM_REGISTER_VAR(TM_Sched_QueueShpBucketLvls)
+#endif
+	TM_REGISTER_VAR(TM_Sched_EccConfig)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ExcMask)
+	TM_REGISTER_VAR(TM_Sched_ScrubDisable)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ScrubSlotAlloc)
+	TM_REGISTER_VAR(TM_Sched_TreeDWRRPrioEn)
+	TM_REGISTER_VAR(TM_Sched_TreeDeqEn)
+#if READ_ONLY
+	TM_REGISTER_VAR(TM_Sched_EccMemParams)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_ErrCnt)
+	TM_REGISTER_VAR(TM_Sched_ErrStus)
+	TM_REGISTER_VAR(TM_Sched_ExcCnt)
+	TM_REGISTER_VAR(TM_Sched_FirstExc)
+	TM_REGISTER_VAR(TM_Sched_ForceErr)
+	TM_REGISTER_VAR(TM_Sched_GeneralEccErrStatus)/*NEW*/
+	TM_REGISTER_VAR(TM_Sched_Id)
+	TM_REGISTER_VAR(TM_Sched_TreeRRDWRRStatus)/*NEW*/
+#endif
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* Drop */
+	/* A level */
+	for (i = 0; i < TM_NUM_A_NODE_DROP_PROF; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfTailDrpThresh, i, TM_Drop_AlvlDropPrfTailDrpThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDDPRatio, i, TM_Drop_AlvlDropPrfWREDDPRatio)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDMinThresh, i, TM_Drop_AlvlDropPrfWREDMinThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDParams, i, TM_Drop_AlvlDropPrfWREDParams)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropPrfWREDScaleRatio, i, TM_Drop_AlvlDropPrfWREDScaleRatio)
+		if (rc)
+			goto out;
+	}
+
+	max_entries = get_tm_a_nodes_count()/TM_A_DRP_PROF_PER_ENTRY;
+	for (i = 0; i < max_entries; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlDropProfPtr, i, TM_Drop_AlvlDropProfPtr)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_A_NODE_CURVES; i++)
+		/* TBD  __set_hw_queues_wred_curve(tm_handle hndl, uint8_t *prob_array, uint8_t curve_ind) */
+		for (j = 0; j < 3; j++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.AlvlREDCurve.Color[j], i, TM_Drop_AlvlREDCurve_Color)
+			if (rc)
+				goto out;
+		}
+
+	/* B level */
+	for (i = 0; i < TM_NUM_B_NODE_DROP_PROF; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfTailDrpThresh, i, TM_Drop_BlvlDropPrfTailDrpThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDDPRatio, i, TM_Drop_BlvlDropPrfWREDDPRatio)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDMinThresh, i, TM_Drop_BlvlDropPrfWREDMinThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDParams, i, TM_Drop_BlvlDropPrfWREDParams)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropPrfWREDScaleRatio, i, TM_Drop_BlvlDropPrfWREDScaleRatio)
+		if (rc)
+			goto out;
+	}
+
+	max_entries = get_tm_b_nodes_count()/TM_B_DRP_PROF_PER_ENTRY;
+	for (i = 0; i < max_entries; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlDropProfPtr, i, TM_Drop_BlvlDropProfPtr)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_B_NODE_CURVES; i++)
+		for (j = 0; j < 4; j++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.BlvlREDCurve[j].Table, i, TM_Drop_BlvlREDCurve_Table)
+			if (rc)
+				goto out;
+		}
+
+	/* C level */
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		for (i = 0; i < TM_NUM_C_NODE_DROP_PROF; i++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfTailDrpThresh.CoS[cos], i,
+				TM_Drop_ClvlDropPrfTailDrpThresh_CoS)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDDPRatio.CoS[cos], i,
+				TM_Drop_ClvlDropPrfWREDDPRatio_CoS)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDMinThresh.CoS[cos], i,
+				TM_Drop_ClvlDropPrfWREDMinThresh_CoS)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDParams.CoS[cos], i,
+				TM_Drop_ClvlDropPrfWREDParams_CoS)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[cos], i,
+				TM_Drop_ClvlDropPrfWREDScaleRatio_CoS)
+			if (rc)
+				goto out;
+		}
+
+		max_entries = get_tm_c_nodes_count()/TM_C_DRP_PROF_PER_ENTRY;
+		for (i = 0; i < max_entries; i++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlDropProfPtr_CoS[cos], i, TM_Drop_ClvlDropProfPtr_CoS)
+			if (rc)
+				goto out;
+		}
+
+		for (i = 0; i < TM_NUM_WRED_C_NODE_CURVES; i++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.ClvlREDCurve.CoS[cos], i, TM_Drop_ClvlREDCurve_CoS)
+			if (rc)
+				goto out;
+		}
+	}
+
+	/* Port level */
+	/* Global */
+	for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfTailDrpThresh, i, TM_Drop_PortDropPrfTailDrpThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDDPRatio, i, TM_Drop_PortDropPrfWREDDPRatio)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDMinThresh, i, TM_Drop_PortDropPrfWREDMinThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDParams, i, TM_Drop_PortDropPrfWREDParams)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDScaleRatio, i, TM_Drop_PortDropPrfWREDScaleRatio)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.PortREDCurve, i, TM_Drop_PortREDCurve)
+		if (rc)
+			goto out;
+	}
+
+	/* CoS */
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfTailDrpThresh_CoSRes[cos], i,
+				TM_Drop_PortDropPrfTailDrpThresh_CoSRes)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDDPRatio_CoSRes[cos], i,
+				TM_Drop_PortDropPrfWREDDPRatio_CoSRes)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDMinThresh_CoSRes[cos], i,
+				TM_Drop_PortDropPrfWREDMinThresh_CoSRes)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDParams_CoSRes[cos], i,
+				TM_Drop_PortDropPrfWREDParams_CoSRes)
+			if (rc)
+				goto out;
+
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[cos], i,
+				TM_Drop_PortDropPrfWREDScaleRatio_CoSRes)
+			if (rc)
+				goto out;
+		}
+
+		for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.PortREDCurve_CoS[cos], i, TM_Drop_PortREDCurve_CoS)
+			if (rc)
+				goto out;
+		}
+	}
+
+	/* Queue level */
+	max_entries = get_tm_queues_count()/4;
+	for (i = 0; i < max_entries; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueCoSConf, i, TM_Drop_QueueCoSConf)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_QUEUE_DROP_PROF; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfTailDrpThresh, i, TM_Drop_QueueDropPrfTailDrpThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDDPRatio, i, TM_Drop_QueueDropPrfWREDDPRatio)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDMinThresh, i, TM_Drop_QueueDropPrfWREDMinThresh)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDParams, i, TM_Drop_QueueDropPrfWREDParams)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropPrfWREDScaleRatio, i, TM_Drop_QueueDropPrfWREDScaleRatio)
+		if (rc)
+			goto out;
+	}
+
+	max_entries = get_tm_queues_count()/TM_Q_DRP_PROF_PER_ENTRY;
+	for (i = 0; i < max_entries; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Drop.QueueDropProfPtr, i, TM_Drop_QueueDropProfPtr)
+		if (rc)
+			goto out;
+	}
+	for (i = 0; i < TM_NUM_WRED_QUEUE_CURVES; i++)
+		for (j = 0; j < 3; j++) {
+			TM_WRITE_TABLE_REGISTER(TM.Drop.QueueREDCurve.Color[j], i, TM_Drop_QueueREDCurve_Color)
+			if (rc)
+				goto out;
+		}
+
+	/* General */
+	TM_WRITE_REGISTER(TM.Drop.DPSource, TM_Drop_DPSource)
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Drop.RespLocalDPSel, TM_Drop_RespLocalDPSel)
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Drop.WREDDropProbMode, TM_Drop_WREDDropProbMode)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Port, 0x2A)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Clvl, 0x2A)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Blvl, 0x2A)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Port, 0x2A)
+	TM_REGISTER_SET(TM_Drop_WREDMaxProbModePerColor, Alvl, 0x2A)
+	TM_WRITE_REGISTER(TM.Drop.WREDMaxProbModePerColor, TM_Drop_WREDMaxProbModePerColor)
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Drop.Drp_Decision_hierarchy_to_Query_debug,
+		TM_Drop_Drp_Decision_hierarchy_to_Query_debug)/*NEW*/
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Drop.Drp_Decision_to_Query_debug, TM_Drop_Drp_Decision_to_Query_debug)/*NEW*/
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Drop.EccConfig, TM_Drop_EccConfig)/*NEW*/
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Drop_ExcMask, ForcedErr, 0x1)
+	TM_REGISTER_SET(TM_Drop_ExcMask, CorrECCErr, 0x1)
+	TM_REGISTER_SET(TM_Drop_ExcMask, UncECCErr, 0x1)
+	TM_REGISTER_SET(TM_Drop_ExcMask, QuesryRespSyncFifoFull, 0x1)
+	TM_REGISTER_SET(TM_Drop_ExcMask, QueryReqFifoOverflow, 0x1)
+	TM_REGISTER_SET(TM_Drop_ExcMask, AgingFifoOverflow, 0x1)
+	TM_WRITE_REGISTER(TM.Drop.ExcMask, TM_Drop_ExcMask)
+	if (rc)
+		goto out;
+
+
+	/* Sched */
+	/* A level */
+	max_entries = get_tm_a_nodes_count();
+	for (i = 0; i < max_entries; i++) {
+		TM_REGISTER_SET(TM_Sched_AlvlDef, Deficit, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlDef, i, TM_Sched_AlvlDef)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlDWRRPrioEn, i, TM_Sched_AlvlDWRRPrioEn)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFuncPtr, i, TM_Sched_AlvlEligPrioFuncPtr)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlQuantum, Quantum, 0x40)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlQuantum, i, TM_Sched_AlvlQuantum)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlTokenBucketBurstSize, MinBurstSz, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_AlvlTokenBucketBurstSize, MaxBurstSz, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlTokenBucketBurstSize, i, TM_Sched_AlvlTokenBucketBurstSize)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_AlvlTokenBucketTokenEnDiv, MinToken, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_AlvlTokenBucketTokenEnDiv, MaxToken, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlTokenBucketBurstSize, i, TM_Sched_AlvlTokenBucketTokenEnDiv)
+		if (rc)
+			goto out;
+
+		/* TBD */
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo, i*4)
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi, i*4 + 3)
+		TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, Blvl, i/4)
+		TM_WRITE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, TM_Sched_ALvltoBlvlAndQueueRangeMap)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < 512; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.AlvlEligPrioFunc, i, TM_Sched_AlvlEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+
+	TM_REGISTER_SET(TM_Sched_AlvlPerConf, PerInterval, 0xe39)
+	TM_WRITE_REGISTER(TM.Sched.AlvlPerConf, TM_Sched_AlvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, N, 0x2)
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, K, 0x66F)
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrms, L, 0x16E)
+	TM_WRITE_REGISTER(TM.Sched.AlvlPerRateShpPrms, TM_Sched_AlvlPerRateShpPrms)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrmsInt, B, 0x1)
+	TM_REGISTER_SET(TM_Sched_AlvlPerRateShpPrmsInt, I, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.AlvlPerRateShpPrmsInt, TM_Sched_AlvlPerRateShpPrmsInt)/*NEW*/
+	if (rc)
+		goto out;
+
+
+	/* B level */
+	max_entries = get_tm_b_nodes_count();
+	for (i = 0; i < max_entries; i++) {
+		TM_REGISTER_SET(TM_Sched_BlvlDef, Deficit, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlDef, i, TM_Sched_BlvlDef)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlDWRRPrioEn, i, TM_Sched_BlvlDWRRPrioEn)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFuncPtr, i, TM_Sched_BlvlEligPrioFuncPtr)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlQuantum, Quantum, 0x40)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlQuantum, i, TM_Sched_BlvlQuantum)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlTokenBucketBurstSize, MinBurstSz, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_BlvlTokenBucketBurstSize, MaxBurstSz, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlTokenBucketBurstSize, i, TM_Sched_BlvlTokenBucketBurstSize)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_BlvlTokenBucketTokenEnDiv, MinToken, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_BlvlTokenBucketTokenEnDiv, MaxToken, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlTokenBucketTokenEnDiv, i, TM_Sched_BlvlTokenBucketTokenEnDiv)
+		if (rc)
+			goto out;
+
+		/* TBD */
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlLo, i*4)
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlHi, i*4 + 3)
+		TM_REGISTER_SET(TM_Sched_BLvltoClvlAndAlvlRangeMap, Clvl, i/2)
+		TM_WRITE_REGISTER(TM.Sched.BLvltoClvlAndAlvlRangeMap, TM_Sched_BLvltoClvlAndAlvlRangeMap)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < 512; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.BlvlEligPrioFunc, i, TM_Sched_BlvlEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+
+	TM_REGISTER_SET(TM_Sched_BlvlPerConf, PerInterval, 0xe39)
+	TM_WRITE_REGISTER(TM.Sched.BlvlPerConf, TM_Sched_BlvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, N, 0x2)
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, K, 0x66F)
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrms, L, 0x16E)
+	TM_WRITE_REGISTER(TM.Sched.BlvlPerRateShpPrms, TM_Sched_BlvlPerRateShpPrms)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrmsInt, B, 0x1)
+	TM_REGISTER_SET(TM_Sched_BlvlPerRateShpPrmsInt, I, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.BlvlPerRateShpPrmsInt, TM_Sched_BlvlPerRateShpPrmsInt)/*NEW*/
+	if (rc)
+		goto out;
+
+
+	/* C level */
+	max_entries = get_tm_c_nodes_count();
+	for (i = 0; i < max_entries; i++) {
+		TM_REGISTER_SET(TM_Sched_CLvlDef, Deficit, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.CLvlDef, i, TM_Sched_CLvlDef)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlDWRRPrioEn, i, TM_Sched_ClvlDWRRPrioEn)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFuncPtr, i, TM_Sched_ClvlEligPrioFuncPtr)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlQuantum, Quantum, 0x40)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlQuantum, i, TM_Sched_ClvlQuantum)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlTokenBucketBurstSize, MinBurstSz, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_ClvlTokenBucketBurstSize, MaxBurstSz, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlTokenBucketBurstSize, i, TM_Sched_ClvlTokenBucketBurstSize)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_ClvlTokenBucketTokenEnDiv, MinToken, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_ClvlTokenBucketTokenEnDiv, MaxToken, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlTokenBucketTokenEnDiv, i, TM_Sched_ClvlTokenBucketTokenEnDiv)
+		if (rc)
+			goto out;
+
+		/* TBD */
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlLo, i*2)
+		TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlHi, i*2 + 1)
+		if (i < 4)
+			TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, 0)
+		else
+			if (i > 13)
+				TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, i)
+			else
+				TM_REGISTER_SET(TM_Sched_ClvltoPortAndBlvlRangeMap, Port, i+3)
+		TM_WRITE_REGISTER(TM.Sched.ClvltoPortAndBlvlRangeMap, TM_Sched_ClvltoPortAndBlvlRangeMap)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < 512; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.ClvlEligPrioFunc, i, TM_Sched_ClvlEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+
+	TM_REGISTER_SET(TM_Sched_ClvlPerConf, PerInterval, 0x71c)
+	TM_WRITE_REGISTER(TM.Sched.ClvlPerConf, TM_Sched_ClvlPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, N, 0x2)
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, K, 0x66F)
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrms, L, 0x16E)
+	TM_WRITE_REGISTER(TM.Sched.ClvlPerRateShpPrms, TM_Sched_ClvlPerRateShpPrms)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrmsInt, B, 0x1)
+	TM_REGISTER_SET(TM_Sched_ClvlPerRateShpPrmsInt, I, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.ClvlPerRateShpPrmsInt, TM_Sched_ClvlPerRateShpPrmsInt)/*NEW*/
+	if (rc)
+		goto out;
+
+
+	/* Port level */
+	max_entries = get_tm_port_count();
+	for (i = 0; i < max_entries; i++) {
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit0, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit1, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit2, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioHi, Deficit3, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDefPrioHi, i, TM_Sched_PortDefPrioHi)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit0, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit1, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit2, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortDefPrioLo, Deficit3, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDefPrioLo, i, TM_Sched_PortDefPrioLo)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortDWRRPrioEn, i, TM_Sched_PortDWRRPrioEn)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFuncPtr, i, TM_Sched_PortEligPrioFuncPtr)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum0, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum1, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum2, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosLo, Quantum3, 0x10)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortQuantumsPriosLo, i, TM_Sched_PortQuantumsPriosLo)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum4, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum5, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum6, 0x10)
+		TM_REGISTER_SET(TM_Sched_PortQuantumsPriosHi, Quantum7, 0x10)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortQuantumsPriosHi, i, TM_Sched_PortQuantumsPriosHi)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketBurstSize, MinBurstSz, 0x1FFFF)
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketBurstSize, MaxBurstSz, 0x1FFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortTokenBucketBurstSize, i, TM_Sched_PortTokenBucketBurstSize)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, Periods, 0x1)
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, MinToken, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_PortTokenBucketTokenEnDiv, MaxToken, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortTokenBucketTokenEnDiv, i, TM_Sched_PortTokenBucketTokenEnDiv)
+		if (rc)
+			goto out;
+
+		/* TBD */
+		TM_REGISTER_SET(TM_Sched_PortRangeMap, Lo, i*2)
+		TM_REGISTER_SET(TM_Sched_PortRangeMap, Hi, i*2 + 1)
+		if (i == 0) {
+			TM_REGISTER_SET(TM_Sched_PortRangeMap, Lo, 0)
+			TM_REGISTER_SET(TM_Sched_PortRangeMap, Hi, 3)
+		} else {
+			if (i < 11) {
+				TM_REGISTER_SET(TM_Sched_PortRangeMap, Lo, i+3)
+				TM_REGISTER_SET(TM_Sched_PortRangeMap, Hi, i+3)
+			} else if (i > 13) {
+					TM_REGISTER_SET(TM_Sched_PortRangeMap, Lo, i)
+					TM_REGISTER_SET(TM_Sched_PortRangeMap, Hi, i)
+				}
+		}
+		TM_WRITE_REGISTER(TM.Sched.PortRangeMap, TM_Sched_PortRangeMap)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < 512; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.PortEligPrioFunc, i, TM_Sched_PortEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+
+	TM_REGISTER_SET(TM_Sched_PortDWRRBytesPerBurstsLimit, limit, 0x20)
+	TM_WRITE_REGISTER(TM.Sched.PortDWRRBytesPerBurstsLimit, TM_Sched_PortDWRRBytesPerBurstsLimit)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_PortPerConf, PerInterval, 0x50)
+	TM_WRITE_REGISTER(TM.Sched.PortPerConf, TM_Sched_PortPerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_PortExtBPEn, En, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.PortExtBPEn, TM_Sched_PortExtBPEn);
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, N, 0x2)
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, K, 0x66F)
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrms, L, 0x16E)
+	TM_WRITE_REGISTER(TM.Sched.PortPerRateShpPrms, TM_Sched_PortPerRateShpPrms)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrmsInt, B, 0x1)
+	TM_REGISTER_SET(TM_Sched_PortPerRateShpPrmsInt, I, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.PortPerRateShpPrmsInt, TM_Sched_PortPerRateShpPrmsInt)/*NEW*/
+	if (rc)
+		goto out;
+
+	/* Queue level */
+	max_entries = get_tm_queues_count();
+	for (i = 0; i < max_entries; i++) {
+		TM_REGISTER_SET(TM_Sched_QueueDef, Deficit, 0x1)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueDef, i, TM_Sched_QueueDef)
+		if (rc)
+			goto out;
+
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, i, TM_Sched_QueueEligPrioFuncPtr)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_QueueQuantum, Quantum, 0x40)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueQuantum, i, TM_Sched_QueueQuantum)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_QueueTokenBucketBurstSize, MinBurstSz, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_QueueTokenBucketBurstSize, MaxBurstSz, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueTokenBucketBurstSize, i, TM_Sched_QueueTokenBucketBurstSize)
+		if (rc)
+			goto out;
+
+		TM_REGISTER_SET(TM_Sched_QueueTokenBucketTokenEnDiv, MinToken, 0xFFF)
+		TM_REGISTER_SET(TM_Sched_QueueTokenBucketTokenEnDiv, MaxToken, 0xFFF)
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueTokenBucketTokenEnDiv, i, TM_Sched_QueueTokenBucketTokenEnDiv)
+		if (rc)
+			goto out;
+
+		/* TBD */
+		TM_REGISTER_SET(TM_Sched_QueueAMap, Alvl, i/4)
+		TM_WRITE_REGISTER(TM.Sched.QueueAMap, TM_Sched_QueueAMap)
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_ELIG_FUNC_TABLE_SIZE; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFunc, i, TM_Sched_QueueEligPrioFunc)
+		if (rc)
+			goto out;
+	}
+
+	TM_REGISTER_SET(TM_Sched_QueuePerConf, PerInterval, 0xe39)
+	TM_WRITE_REGISTER(TM.Sched.QueuePerConf, TM_Sched_QueuePerConf)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, N, 0x2)
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, K, 0x66F)
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrms, L, 0x16E)
+	TM_WRITE_REGISTER(TM.Sched.QueuePerRateShpPrms, TM_Sched_QueuePerRateShpPrms)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrmsInt, B, 0x1)
+	TM_REGISTER_SET(TM_Sched_QueuePerRateShpPrmsInt, I, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.QueuePerRateShpPrmsInt, TM_Sched_QueuePerRateShpPrmsInt)/*NEW*/
+	if (rc)
+		goto out;
+
+
+	/* General */
+	TM_WRITE_REGISTER(TM.Sched.ScrubDisable, TM_Sched_ScrubDisable)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_ScrubSlotAlloc, QueueSlots, 0x20)
+	TM_REGISTER_SET(TM_Sched_ScrubSlotAlloc, AlvlSlots, 0x10)
+	TM_REGISTER_SET(TM_Sched_ScrubSlotAlloc, BlvlSlots, 0x8)
+	TM_REGISTER_SET(TM_Sched_ScrubSlotAlloc, ClvlSlots, 0x4)
+	TM_REGISTER_SET(TM_Sched_ScrubSlotAlloc, PortSlots, 0x4)
+	TM_WRITE_REGISTER(TM.Sched.ScrubSlotAlloc, TM_Sched_ScrubSlotAlloc)
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Sched.TreeDWRRPrioEn, TM_Sched_TreeDWRRPrioEn)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_TreeDeqEn, En, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.TreeDeqEn, TM_Sched_TreeDeqEn)
+	if (rc)
+		goto out;
+
+	TM_WRITE_REGISTER(TM.Sched.EccConfig, TM_Sched_EccConfig)
+	if (rc)
+		goto out;
+
+	TM_REGISTER_SET(TM_Sched_ExcMask, ForcedErr, 0x1)
+	TM_REGISTER_SET(TM_Sched_ExcMask, CorrECCErr, 0x1)
+	TM_REGISTER_SET(TM_Sched_ExcMask, UncECCErr, 0x1)
+	TM_REGISTER_SET(TM_Sched_ExcMask, BPBSat, 0x0)
+	TM_REGISTER_SET(TM_Sched_ExcMask, TBNegSat, 0x1)
+	TM_REGISTER_SET(TM_Sched_ExcMask, FIFOOvrflowErr, 0x1)
+	TM_WRITE_REGISTER(TM.Sched.ExcMask, TM_Sched_ExcMask)
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+/**
+ */
+int get_hw_port_status(tm_handle hndl,
+					uint8_t index,
+					struct tm_port_status *tm_status)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_PortShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioHi)
+	TM_REGISTER_VAR(TM_Sched_PortDefPrioLo)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_TABLE_REGISTER(TM.Sched.PortShpBucketLvls, index, TM_Sched_PortShpBucketLvls);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_PortShpBucketLvls, MinLvl, tm_status->min_bucket_level, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortShpBucketLvls, MaxLvl, tm_status->max_bucket_level, (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.PortDefPrioHi, index, TM_Sched_PortDefPrioHi);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_PortDefPrioHi, Deficit0, tm_status->deficit[0], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioHi, Deficit1, tm_status->deficit[1], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioHi, Deficit2, tm_status->deficit[2], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioHi, Deficit3, tm_status->deficit[3], (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.PortDefPrioLo, index, TM_Sched_PortDefPrioLo);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_PortDefPrioLo, Deficit0, tm_status->deficit[4], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioLo, Deficit1, tm_status->deficit[5], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioLo, Deficit2, tm_status->deficit[6], (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortDefPrioLo, Deficit3, tm_status->deficit[7], (uint32_t));
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_c_node_status(tm_handle hndl,
+					uint32_t index,
+					struct tm_node_status *tm_status)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_ClvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_CLvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_TABLE_REGISTER(TM.Sched.ClvlShpBucketLvls, index, TM_Sched_ClvlShpBucketLvls);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_ClvlShpBucketLvls, MinLvl, tm_status->min_bucket_level, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_ClvlShpBucketLvls, MaxLvl, tm_status->max_bucket_level, (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.CLvlDef, index, TM_Sched_CLvlDef);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_CLvlDef, Deficit, tm_status->deficit, (uint32_t));
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_b_node_status(tm_handle hndl,
+					uint32_t index,
+					struct tm_node_status *tm_status)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_BlvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_BlvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_TABLE_REGISTER(TM.Sched.BlvlShpBucketLvls, index, TM_Sched_BlvlShpBucketLvls);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_BlvlShpBucketLvls, MinLvl, tm_status->min_bucket_level, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_BlvlShpBucketLvls, MaxLvl, tm_status->max_bucket_level, (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.BlvlDef, index, TM_Sched_BlvlDef);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_BlvlDef, Deficit, tm_status->deficit, (uint32_t));
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_a_node_status(tm_handle hndl,
+					uint32_t index,
+					struct tm_node_status *tm_status)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_AlvlShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_AlvlDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_TABLE_REGISTER(TM.Sched.AlvlShpBucketLvls, index, TM_Sched_AlvlShpBucketLvls);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_AlvlShpBucketLvls, MinLvl, tm_status->min_bucket_level, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_AlvlShpBucketLvls, MaxLvl, tm_status->max_bucket_level, (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.AlvlDef, index, TM_Sched_AlvlDef);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_AlvlDef, Deficit, tm_status->deficit, (uint32_t));
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_queue_status(tm_handle hndl,
+					uint32_t index,
+					struct tm_node_status *tm_status)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_QueueShpBucketLvls)
+	TM_REGISTER_VAR(TM_Sched_QueueDef)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_TABLE_REGISTER(TM.Sched.QueueShpBucketLvls, index, TM_Sched_QueueShpBucketLvls);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_QueueShpBucketLvls, MinLvl, tm_status->min_bucket_level, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_QueueShpBucketLvls, MaxLvl, tm_status->max_bucket_level, (uint32_t));
+
+	TM_READ_TABLE_REGISTER(TM.Sched.QueueDef, index, TM_Sched_QueueDef);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_QueueDef, Deficit, tm_status->deficit, (uint32_t));
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_queue_length(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t *av_q_length)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_QueueAvgQueueLength)		/* average */
+	TM_REGISTER_VAR(TM_Drop_AlvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_BlvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_ClvlInstAndAvgQueueLength)
+	TM_REGISTER_VAR(TM_Drop_PortInstAndAvgQueueLength)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (level) {
+	case Q_LEVEL:
+		TM_READ_TABLE_REGISTER(TM.Drop.QueueAvgQueueLength, index, TM_Drop_QueueAvgQueueLength)
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Drop_QueueAvgQueueLength, AQL, *av_q_length, (uint32_t)); /* casting to uint32_t */
+		break;
+	case A_LEVEL:
+		TM_READ_TABLE_REGISTER(TM.Drop.AlvlInstAndAvgQueueLength, index, TM_Drop_AlvlInstAndAvgQueueLength)
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Drop_AlvlInstAndAvgQueueLength, AQL, *av_q_length, (uint32_t));
+		break;
+	case B_LEVEL:
+		TM_READ_TABLE_REGISTER(TM.Drop.BlvlInstAndAvgQueueLength, index, TM_Drop_BlvlInstAndAvgQueueLength)
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Drop_BlvlInstAndAvgQueueLength, AQL, *av_q_length, (uint32_t));
+		break;
+	case C_LEVEL:
+		TM_READ_TABLE_REGISTER(TM.Drop.ClvlInstAndAvgQueueLength, index, TM_Drop_ClvlInstAndAvgQueueLength)
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Drop_ClvlInstAndAvgQueueLength, AQL, *av_q_length, (uint32_t));
+		break;
+	case P_LEVEL:
+		TM_READ_TABLE_REGISTER(TM.Drop.PortInstAndAvgQueueLength, index, TM_Drop_PortInstAndAvgQueueLength)
+		if (rc)
+			return rc;
+		TM_REGISTER_GET(TM_Drop_PortInstAndAvgQueueLength, AQL, *av_q_length, (uint32_t));
+		break;
+	}
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_sched_errors(tm_handle hndl, struct tm_error_info *info)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_ErrCnt)
+	TM_REGISTER_VAR(TM_Sched_ExcCnt)
+
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_REGISTER(TM.Sched.ErrCnt, TM_Sched_ErrCnt);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_ErrCnt, Cnt, info->error_counter, (uint16_t)); /* casting to uint16_t */
+
+	TM_READ_REGISTER(TM.Sched.ExcCnt, TM_Sched_ExcCnt);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Sched_ExcCnt, Cnt, info->exception_counter, (uint16_t)); /* casting to uint16_t */
+
+	return rc;
+}
+
+
+/**
+ */
+int get_hw_drop_errors(tm_handle hndl, struct tm_error_info *info)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Drop_ErrCnt)
+	TM_REGISTER_VAR(TM_Drop_ExcCnt)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_READ_REGISTER(TM.Drop.ErrCnt, TM_Drop_ErrCnt);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Drop_ErrCnt, Cnt, info->error_counter, (uint16_t)); /* casting to uint16_t */
+
+	TM_READ_REGISTER(TM.Drop.ExcCnt, TM_Drop_ExcCnt);
+	if (rc)
+		return rc;
+	TM_REGISTER_GET(TM_Drop_ExcCnt, Cnt, info->exception_counter, (uint16_t)); /* casting to uint16_t */
+	return rc;
+}
+
+
+#define READ_ELIG_PRIO_FUN_TABLE_MAC(level)	\
+do {\
+	for (i = 0; i < 8; i++) {\
+		TM_READ_TABLE_REGISTER(TM.Sched.level##EligPrioFunc,\
+								func_offset + (i * 64),\
+								TM_Sched_##level##EligPrioFunc);\
+		if (rc)\
+			goto out;\
+		TM_REGISTER_GET(TM_Sched_##level##EligPrioFunc, FuncOut0, table[i*4], (uint16_t));\
+		TM_REGISTER_GET(TM_Sched_##level##EligPrioFunc, FuncOut1, table[i*4+1], (uint16_t));\
+		TM_REGISTER_GET(TM_Sched_##level##EligPrioFunc, FuncOut2, table[i*4+2], (uint16_t));\
+		TM_REGISTER_GET(TM_Sched_##level##EligPrioFunc, FuncOut3, table[i*4+3], (uint16_t));\
+	} \
+} while (0)
+
+/**
+ * Dump Eligible Priority Function
+ */
+int get_hw_elig_prio_func(tm_handle hndl, enum tm_level level, uint16_t func_offset, uint16_t *table)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFunc)
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFunc)
+
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = -EFAULT;
+		TM_READ_TABLE_REGISTER(TM.Sched.QueueEligPrioFunc, func_offset, TM_Sched_QueueEligPrioFunc)
+		if (rc)
+			goto out;
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut0, table[0], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut1, table[1], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut2, table[2], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut3, table[3], (uint16_t));
+		goto out;
+		break;
+	case A_LEVEL:
+		READ_ELIG_PRIO_FUN_TABLE_MAC(Alvl);
+		break;
+	case B_LEVEL:
+		READ_ELIG_PRIO_FUN_TABLE_MAC(Blvl);
+		break;
+	case C_LEVEL:
+		READ_ELIG_PRIO_FUN_TABLE_MAC(Clvl);
+		break;
+	case P_LEVEL:
+		READ_ELIG_PRIO_FUN_TABLE_MAC(Port);
+		break;
+	default:
+		goto out;
+	}
+out:
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+
+int show_hw_elig_prio_func(tm_handle hndl, enum tm_level level, uint16_t func_offset)
+{
+	int rc = -EFAULT;
+	int i, j;
+	int entry_index;
+	int prop_prio;
+	uint8_t mask = 0x07;
+	uint16_t elig_func_table[32];
+
+	rc = get_hw_elig_prio_func(hndl, level, func_offset, elig_func_table);
+	if (rc)
+		return rc;
+	pr_info("Function: %d\n", func_offset);
+	if (level == Q_LEVEL) {
+		pr_info("%02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x\n",
+			0, elig_func_table[0],
+			1, elig_func_table[1],
+			2, elig_func_table[2],
+			3, elig_func_table[3]);
+		/* in - MinTBNeg, MaxTBNeg, PropPrio */
+		/* out - Elig, SchdPrio, PropPrio, MinTBUsed, MaxTBUsed */
+		pr_info("  Detailed table:\n");
+		pr_info("    Input       OutPut            Value\n");
+		pr_info("    -----    -----------------    -----\n");
+		pr_info("    M   M    E   S   P   M   M\n");
+		pr_info("    i   a    l   c   r   i   a\n");
+		pr_info("    n   x    i   h   o   n   x\n");
+		pr_info("    T   T    g   d   p   T   T\n");
+		pr_info("    B   B        P   P   B   B\n");
+		pr_info("    N   N        r   r   U   U\n");
+		pr_info("    e   e        i   i   s   s\n");
+		pr_info("    g   g        o   o   e   e\n");
+		pr_info("    -   -    -   -   -   -   -\n");
+		for (j = 0; j < 4; j++) {
+			entry_index =  j;
+			pr_info("%02d: %d   %d    %d   %d   %d   %d   %d    0x%03x\n",
+				entry_index,
+				entry_index / 2,
+				entry_index % 2,
+				(elig_func_table[j] >> 8) & 0x01,		/*elig*/
+				(elig_func_table[j] >> 2) & mask,		/*sched_prio*/
+				(elig_func_table[j] >> 5) & mask,		/*prop_prio*/
+				(elig_func_table[j] >> 1) & 0x01,		/*min_tb*/
+				elig_func_table[j] & 0x01,			/*max_tb*/
+				elig_func_table[j]
+				);
+		}
+	} else {
+		for (i = 0; i < 8; i++) {
+			pr_info("%02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x\n",
+				(i*4) + 0, elig_func_table[i*4 + 0],
+				(i*4) + 1, elig_func_table[i*4 + 1],
+				(i*4) + 2, elig_func_table[i*4 + 2],
+				(i*4) + 3, elig_func_table[i*4 + 3]);
+		}
+
+		/* in - MinTBNeg, MaxTBNeg, PropPrio */
+		/* out - Elig, SchdPrio, PropPrio, MinTBUsed, MaxTBUsed */
+		pr_info("  Detailed table:\n");
+		pr_info("      Input            OutPut         Value\n");
+		pr_info("    ---------     -----------------   -----\n");
+		pr_info("    M   M   P     E   S   P   M   M\n");
+		pr_info("    i   a   r     l   c   r   i   a\n");
+		pr_info("    n   x   o     i   h   o   n   x\n");
+		pr_info("    T   T   p     g   d   p   T   T\n");
+		pr_info("    B   B   P         P   P   B   B\n");
+		pr_info("    N   N   r         r   r   U   U\n");
+		pr_info("    e   e   i         i   i   s   s\n");
+		pr_info("    g   g   o         o   o   e   e\n");
+		pr_info("    -   -   -     -   -   -   -   -\n");
+
+		for (i = 0; i < 8; i++) {
+			for (j = 0; j < 4; j++) {
+				entry_index = i*4 + j;
+				prop_prio = entry_index & 7;
+				pr_info("%02d: %d   %d   %d     %d   %d   %d   %d   %d   0x%03x\n",
+						entry_index,
+						entry_index / 16,
+						(entry_index / 8) % 2,
+						prop_prio,
+						(elig_func_table[entry_index] >> 8) & 0x01,		/*elig*/
+						(elig_func_table[entry_index] >> 2) & mask,		/*sched_prio*/
+						(elig_func_table[entry_index] >> 5) & mask,		/*prop_prio*/
+						(elig_func_table[entry_index] >> 1) & 0x01,		/*min_tb*/
+						elig_func_table[entry_index] & 0x01,			/*max_tb*/
+						elig_func_table[entry_index]
+						);
+			}
+		}
+	}
+	pr_info("---------------------------------------\n");
+
+
+#if 0
+	TM_REGISTER_VAR(TM_Sched_AlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_BlvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_ClvlEligPrioFunc)
+	TM_REGISTER_VAR(TM_Sched_PortEligPrioFunc)
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFunc)
+
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = -EFAULT;
+		TM_READ_TABLE_REGISTER(TM.Sched.QueueEligPrioFunc, func_offset, TM_Sched_QueueEligPrioFunc)
+		if (rc)
+			goto out;
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut0, elig_func_val[0], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut1, elig_func_val[1], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut2, elig_func_val[2], (uint16_t));
+		TM_REGISTER_GET(TM_Sched_QueueEligPrioFunc, FuncOut3, elig_func_val[3], (uint16_t));
+		pr_info("Function: %d\n", func_offset);
+		pr_info("%02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x\n",
+			0, elig_func_val[0],
+			1, elig_func_val[1],
+			2, elig_func_val[2],
+			3, elig_func_val[3]);
+		/* in - MinTBNeg, MaxTBNeg, PropPrio */
+		/* out - Elig, SchdPrio, PropPrio, MinTBUsed, MaxTBUsed */
+		pr_info("  Detailed table:\n");
+		pr_info("    Input       OutPut            Value\n");
+		pr_info("    -----    -----------------    -----\n");
+		pr_info("    M   M    E   S   P   M   M\n");
+		pr_info("    i   a    l   c   r   i   a\n");
+		pr_info("    n   x    i   h   o   n   x\n");
+		pr_info("    T   T    g   d   p   T   T\n");
+		pr_info("    B   B        P   P   B   B\n");
+		pr_info("    N   N        r   r   U   U\n");
+		pr_info("    e   e        i   i   s   s\n");
+		pr_info("    g   g        o   o   e   e\n");
+		pr_info("    -   -    -   -   -   -   -\n");
+		for (j = 0; j < 4; j++) {
+			entry_index =  j;
+			pr_info("%02d: %d   %d    %d   %d   %d   %d   %d    0x%03x\n",
+				entry_index,
+				entry_index / 2,
+				entry_index % 2,
+				(elig_func_val[j] >> 8) & 0x01,		/*elig*/
+				(elig_func_val[j] >> 2) & mask,		/*sched_prio*/
+				(elig_func_val[j] >> 5) & mask,		/*prop_prio*/
+				(elig_func_val[j] >> 1) & 0x01,		/*min_tb*/
+				elig_func_val[j] & 0x01,			/*max_tb*/
+				elig_func_val[j]
+				);
+		}
+		pr_info("---------------------------------------\n");
+		goto out;
+		break;
+	case A_LEVEL:
+		for (i = 0; i < 8; i++) {
+			rc = tm_table_entry_read(TM_ENV(ctl), (void *)&(TM.Sched.AlvlEligPrioFunc),
+				func_offset + (i * 64), TM_REGISTER_VAR_ADDR(TM_Sched_AlvlEligPrioFunc));
+			if (rc)
+				goto out;
+
+			TM_REGISTER_GET(TM_Sched_AlvlEligPrioFunc, FuncOut0,
+				params->tbl_entry[i].func_out0, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_AlvlEligPrioFunc, FuncOut1,
+				params->tbl_entry[i].func_out1, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_AlvlEligPrioFunc, FuncOut2,
+				params->tbl_entry[i].func_out2, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_AlvlEligPrioFunc, FuncOut3,
+				params->tbl_entry[i].func_out3, (uint16_t));
+		}
+		break;
+	case B_LEVEL:
+		for (i = 0; i < 8; i++) {
+			rc = tm_table_entry_read(TM_ENV(ctl), (void *)&(TM.Sched.BlvlEligPrioFunc),
+				func_offset + (i * 64), TM_REGISTER_VAR_ADDR(TM_Sched_BlvlEligPrioFunc));
+
+			TM_REGISTER_GET(TM_Sched_BlvlEligPrioFunc, FuncOut0,
+				params->tbl_entry[i].func_out0, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_BlvlEligPrioFunc, FuncOut1,
+				params->tbl_entry[i].func_out1, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_BlvlEligPrioFunc, FuncOut2,
+				params->tbl_entry[i].func_out2, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_BlvlEligPrioFunc, FuncOut3,
+				params->tbl_entry[i].func_out3, (uint16_t));
+		}
+		break;
+	case C_LEVEL:
+		for (i = 0; i < 8; i++) {
+			rc = tm_table_entry_read(TM_ENV(ctl), (void *)&(TM.Sched.ClvlEligPrioFunc),
+				func_offset + (i * 64), TM_REGISTER_VAR_ADDR(TM_Sched_ClvlEligPrioFunc));
+
+			TM_REGISTER_GET(TM_Sched_ClvlEligPrioFunc, FuncOut0,
+				params->tbl_entry[i].func_out0, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_ClvlEligPrioFunc, FuncOut1,
+				params->tbl_entry[i].func_out1, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_ClvlEligPrioFunc, FuncOut2,
+				params->tbl_entry[i].func_out2, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_ClvlEligPrioFunc, FuncOut3,
+				params->tbl_entry[i].func_out3, (uint16_t));
+		}
+		break;
+	case P_LEVEL:
+		for (i = 0; i < 8; i++) {
+			rc = tm_table_entry_read(TM_ENV(ctl), (void *)&(TM.Sched.PortEligPrioFunc),
+				func_offset + (i * 64), TM_REGISTER_VAR_ADDR(TM_Sched_PortEligPrioFunc));
+
+			TM_REGISTER_GET(TM_Sched_PortEligPrioFunc, FuncOut0,
+				params->tbl_entry[i].func_out0, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_PortEligPrioFunc, FuncOut1,
+				params->tbl_entry[i].func_out1, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_PortEligPrioFunc, FuncOut2,
+				params->tbl_entry[i].func_out2, (uint16_t));
+			TM_REGISTER_GET(TM_Sched_PortEligPrioFunc, FuncOut3,
+				params->tbl_entry[i].func_out3, (uint16_t));
+		}
+		break;
+	default:
+		goto out;
+	}
+
+	pr_info("Function: %d\n", func_offset);
+
+	for (i = 0; i < 8; i++) {
+		elig_func_val[0] = params->tbl_entry[i].func_out0;
+		elig_func_val[1] = params->tbl_entry[i].func_out1;
+		elig_func_val[2] = params->tbl_entry[i].func_out2;
+		elig_func_val[3] = params->tbl_entry[i].func_out3;
+
+		pr_info("%02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x  %02d: 0x%03x\n",
+			(i*4), elig_func_val[0],
+			(i*4) + 1, elig_func_val[1],
+			(i*4) + 2, elig_func_val[2],
+			(i*4) + 3, elig_func_val[3]);
+	}
+
+	/* in - MinTBNeg, MaxTBNeg, PropPrio */
+	/* out - Elig, SchdPrio, PropPrio, MinTBUsed, MaxTBUsed */
+	pr_info("  Detailed table:\n");
+	pr_info("      Input            OutPut         Value\n");
+	pr_info("    ---------     -----------------   -----\n");
+	pr_info("    M   M   P     E   S   P   M   M\n");
+	pr_info("    i   a   r     l   c   r   i   a\n");
+	pr_info("    n   x   o     i   h   o   n   x\n");
+	pr_info("    T   T   p     g   d   p   T   T\n");
+	pr_info("    B   B   P         P   P   B   B\n");
+	pr_info("    N   N   r         r   r   U   U\n");
+	pr_info("    e   e   i         i   i   s   s\n");
+	pr_info("    g   g   o         o   o   e   e\n");
+	pr_info("    -   -   -     -   -   -   -   -\n");
+
+	for (i = 0; i < 8; i++) {
+		elig_func_val[0] = params->tbl_entry[i].func_out0;
+		elig_func_val[1] = params->tbl_entry[i].func_out1;
+		elig_func_val[2] = params->tbl_entry[i].func_out2;
+		elig_func_val[3] = params->tbl_entry[i].func_out3;
+
+		for (j = 0; j < 4; j++) {
+			entry_index = i*4 + j;
+			prop_prio = entry_index & 7;
+			pr_info("%02d: %d   %d   %d     %d   %d   %d   %d   %d   0x%03x\n",
+					entry_index,
+					entry_index / 16,
+					(entry_index / 8) % 2,
+					prop_prio,
+					(elig_func_val[j] >> 8) & 0x01,		/*elig*/
+					(elig_func_val[j] >> 2) & mask,		/*sched_prio*/
+					(elig_func_val[j] >> 5) & mask,		/*prop_prio*/
+					(elig_func_val[j] >> 1) & 0x01,		/*min_tb*/
+					elig_func_val[j] & 0x01,			/*max_tb*/
+					elig_func_val[j]
+					);
+		}
+	}
+	pr_info("-------------------------------------------\n");
+
+out:
+	COMPLETE_HW_WRITE
+#endif
+	return rc;
+}
+
+
+int tm_dump_port_hw(tm_handle hndl, uint32_t portIndex)
+{
+	uint32_t                   portFirstChild;
+	uint32_t                   portLastChild;
+	uint32_t                   cFirstChild;
+	uint32_t                   cLastChild;
+	uint32_t                   bFirstChild;
+	uint32_t                   bLastChild;
+	uint32_t                   aFirstChild;
+	uint32_t                   aLastChild;
+	uint32_t                   ic;
+	uint32_t                   ib;
+	uint32_t                   ia/*, iq*/;
+	uint8_t status;
+	int rc = 0;
+
+	TM_REGISTER_VAR(TM_Sched_PortRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ClvltoPortAndBlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_BLvltoClvlAndAlvlRangeMap)
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (portIndex >= rm->rm_total_ports)
+		return -ERANGE;
+
+	TM_READ_TABLE_REGISTER(TM.Sched.PortRangeMap, portIndex, TM_Sched_PortRangeMap);
+
+	TM_REGISTER_GET(TM_Sched_PortRangeMap, Lo, portFirstChild, (uint32_t));
+	TM_REGISTER_GET(TM_Sched_PortRangeMap, Hi, portLastChild, (uint32_t));
+
+	rc = rm_node_status(rm, P_LEVEL, portIndex, &status);
+	if ((rc) || (status != RM_TRUE))
+		return -ERANGE;
+
+	pr_info("P%d: (c%d-c%d)\n", portIndex, portFirstChild, portLastChild);
+
+	for (ic = portFirstChild; ic <= portLastChild; ic++) {
+
+		rc = rm_node_status(rm, C_LEVEL, ic, &status);
+		if (rc)
+			return -ERANGE;
+
+		if (status != RM_TRUE)
+			continue;
+
+		TM_READ_TABLE_REGISTER(TM.Sched.ClvltoPortAndBlvlRangeMap, ic, TM_Sched_ClvltoPortAndBlvlRangeMap);
+
+		if (portIndex != TM_REGISTER_VAR_NAME(TM_Sched_ClvltoPortAndBlvlRangeMap).Port)
+			continue;
+
+		TM_REGISTER_GET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlLo, cFirstChild, (uint32_t));
+		TM_REGISTER_GET(TM_Sched_ClvltoPortAndBlvlRangeMap, BlvlHi, cLastChild, (uint32_t));
+
+		pr_info(" C%d: (b%d-b%d)\n", ic, cFirstChild, cLastChild);
+
+		for (ib = cFirstChild; ib <= cLastChild; ib++) {
+			rc = rm_node_status(rm, B_LEVEL, ib, &status);
+			if (rc)
+				return -ERANGE;
+
+			if (status != RM_TRUE)
+				continue;
+
+			TM_READ_TABLE_REGISTER(TM.Sched.BLvltoClvlAndAlvlRangeMap, ib,
+					TM_Sched_BLvltoClvlAndAlvlRangeMap);
+
+			if (ic != TM_REGISTER_VAR_NAME(TM_Sched_BLvltoClvlAndAlvlRangeMap).Clvl)
+				continue;
+
+			TM_REGISTER_GET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlLo, bFirstChild, (uint32_t));
+			TM_REGISTER_GET(TM_Sched_BLvltoClvlAndAlvlRangeMap, AlvlHi, bLastChild, (uint32_t));
+
+			pr_info("  B%d: (a%d-a%d)\n", ib, bFirstChild, bLastChild);
+
+			for (ia = bFirstChild ; ia <= bLastChild ; ia++) {
+				rc = rm_node_status(rm, A_LEVEL, ia, &status);
+				if (rc)
+					return -ERANGE;
+
+				if (status != RM_TRUE)
+					continue;
+
+				TM_READ_TABLE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, ia,
+						TM_Sched_ALvltoBlvlAndQueueRangeMap);
+
+				if (ib != TM_REGISTER_VAR_NAME(TM_Sched_ALvltoBlvlAndQueueRangeMap).Blvl)
+					continue;
+
+				TM_REGISTER_GET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo, aFirstChild, (uint32_t));
+				TM_REGISTER_GET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi, aLastChild, (uint32_t));
+
+				pr_info("    A%d: (q%d-q%d)\n", ia, aFirstChild, aLastChild);
+
+				/*
+				pr_info("	Q: ");
+
+				for (iq = aFirstChild ; iq <= aLastChild ; iq++)
+					pr_info("%d ", iq);
+				pr_info("\n");
+				*/
+			}
+		}
+	}
+
+	return rc;
+}
+
+
+int set_hw_elig_per_queue_range(tm_handle hndl, uint32_t startInd, uint32_t endInd, uint8_t elig)
+{
+	int rc = -EFAULT;
+	int i;
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_QueueEligPrioFuncPtr, Ptr, elig);
+	for (i = startInd; i <= endInd; i++) {
+		TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, i, TM_Sched_QueueEligPrioFuncPtr);
+		if (rc)
+			return rc;
+	}
+	return rc;
+}
+
+int check_hw_drop_path(tm_handle hndl, uint32_t timeout, uint8_t full_path)
+{
+	int rc = -EFAULT;
+	int i = 0;
+	int k = 0;
+	int num_of_queues;
+	uint32_t len = 0;
+	uint32_t a_ind, b_ind, c_ind, port;
+	uint8_t debug_flag = TM_DISABLE;
+
+	TM_REGISTER_VAR(TM_Sched_QueueEligPrioFuncPtr)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if ((full_path != TM_DISABLE) && (full_path != TM_ENABLE))
+		return -ERANGE;
+
+	num_of_queues = get_tm_queues_count();
+
+	/* DeQ disable to all Qs */
+	rc = set_hw_elig_per_queue_range(ctl, 0, (num_of_queues - 1), TM_ELIG_DEQ_DISABLE);
+	if (rc) {
+		pr_info("set_hw_elig_per_queue_range to DeQ disable failed: %d\n", rc);
+		return rc;
+	}
+
+	/* Disable debug printing if it switched on */
+	if (tm_debug_on == TM_ENABLE) {
+		debug_flag = TM_ENABLE;
+		tm_debug_on = TM_DISABLE;
+	}
+
+	while (k < timeout) {
+		/* Check which Q is not empty */
+		for (i = 0; i < num_of_queues; i++) {
+			rc = get_hw_queue_length(ctl, Q_LEVEL, i, &len);
+			if (rc) {
+				pr_info("get_hw_queue_length failed: %d\n", rc);
+				return rc;
+			}
+			if (len != 0) {
+				pr_info("Q%d: LEN=%d\n", i, len*16);
+				/* DeQ enable on non empty Q */
+				TM_REGISTER_SET(TM_Sched_QueueEligPrioFuncPtr, Ptr, TM_ELIG_Q_DEFAULT);
+				TM_WRITE_TABLE_REGISTER(TM.Sched.QueueEligPrioFuncPtr, i,
+					TM_Sched_QueueEligPrioFuncPtr);
+				if (rc) {
+					pr_info("DeQ enable to Q=%d failed: %d\n", i, rc);
+					return rc;
+				}
+				while (len) {/* wait till Q will empty */
+					rc = get_hw_queue_length(ctl, Q_LEVEL, i, &len);
+					if (rc) {
+						pr_info("get_hw_queue_length failed: %d\n", rc);
+						return rc;
+					}
+				}
+
+				if (full_path) {
+					a_ind = ctl->tm_queue_array[i].parent_a_node;
+					b_ind = ctl->tm_a_node_array[a_ind].parent_b_node;
+					c_ind = ctl->tm_b_node_array[b_ind].parent_c_node;
+					port = ctl->tm_c_node_array[c_ind].parent_port;
+					pr_info("Full Path: A = %d, B = %d, C = %d, P = %d\n",
+						a_ind, b_ind, c_ind, port);
+				}
+
+				break; /* for (i = 0; i < 512; i++) */
+			} /* if (len != 0) */
+		}
+		msleep(10);
+		k += 20; /* adding ~10 for reading length of Qs*/
+	}
+
+
+	/* Restore debug printing state */
+	if (debug_flag == TM_ENABLE)
+		tm_debug_on = TM_ENABLE;
+
+	/* restore queues eligible function */
+	for (i = 0; i < num_of_queues; i++) {
+		rc = set_hw_queue_elig_prio_func_ptr(ctl, i);
+		if (rc) {
+			pr_info("set_hw_queue_elig_prio_func_ptr failed: %d\n", rc);
+			return rc;
+		}
+	}
+
+	return rc;
+}
+
+
+int set_hw_queue_map_directly(tm_handle hndl, uint32_t queue_index, uint32_t parent)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_QueueAMap)
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_QueueAMap, Alvl, parent);
+	TM_WRITE_TABLE_REGISTER(TM.Sched.QueueAMap, queue_index, TM_Sched_QueueAMap);
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int set_hw_a_node_map_directly(tm_handle hndl,
+					uint32_t a_node_index,
+					uint32_t parent,
+					uint32_t first_child,
+					uint32_t last_child)
+{
+	int rc = -EFAULT;
+
+	TM_REGISTER_VAR(TM_Sched_ALvltoBlvlAndQueueRangeMap)
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, Blvl, parent);
+	TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueLo, first_child)
+	TM_REGISTER_SET(TM_Sched_ALvltoBlvlAndQueueRangeMap, QueueHi, last_child);
+	TM_WRITE_TABLE_REGISTER(TM.Sched.ALvltoBlvlAndQueueRangeMap, a_node_index, TM_Sched_ALvltoBlvlAndQueueRangeMap);
+	COMPLETE_HW_WRITE
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.h b/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.h
new file mode 100644
index 0000000..eda59fb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/set_hw_registers.h
@@ -0,0 +1,267 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef SET_HW_REGISTERS_H
+#define SET_HW_REGISTERS_H
+
+#include "tm_core_types.h"
+
+int set_hw_fixed_port_periodic_scheme(tm_handle hndl);
+int set_hw_fixed_c_level_periodic_scheme(tm_handle hndl);
+int set_hw_fixed_b_level_periodic_scheme(tm_handle hndl);
+int set_hw_fixed_a_level_periodic_scheme(tm_handle hndl);
+int set_hw_fixed_queue_periodic_scheme(tm_handle hndl);
+
+int set_hw_fixed_port_shaping_status(tm_handle hndl, uint8_t shaping_status);
+
+int set_hw_fixed_shaping_status(tm_handle hndl, enum tm_level level);
+
+int set_hw_dwrr_limit(tm_handle hndl);
+
+int set_hw_gen_conf(tm_handle hndl);
+
+int set_hw_max_dp_mode(tm_handle hndl);
+
+int set_hw_queues_wred_curve(tm_handle hndl, uint8_t curve_ind);
+int set_hw_queues_default_wred_curve(tm_handle hndl, uint8_t *prob_array);
+
+int set_hw_a_nodes_wred_curve(tm_handle hndl, uint8_t curve_ind);
+int set_hw_a_nodes_default_wred_curve(tm_handle hndl, uint8_t *prob_array);
+
+int set_hw_b_nodes_wred_curve(tm_handle hndl, uint8_t curve_ind);
+int set_hw_b_nodes_default_wred_curve(tm_handle hndl, uint8_t *prob_array);
+
+int set_hw_c_nodes_wred_curve(tm_handle hndl, uint8_t cos, uint8_t curve_ind);
+int set_hw_c_nodes_default_wred_curve(tm_handle hndl, uint8_t cos, uint8_t *prob_array);
+
+int set_hw_ports_wred_curve(tm_handle hndl, uint8_t curve_ind);
+int set_hw_ports_default_wred_curve(tm_handle hndl, uint8_t *prob_array);
+
+int set_hw_ports_wred_curve_cos(tm_handle hndl, uint8_t cos, uint8_t curve_ind);
+int set_hw_ports_default_wred_curve_cos(tm_handle hndl, uint8_t cos, uint8_t *prob_array);
+
+int set_hw_queue_drop_profile(tm_handle hndl, uint32_t prof_ind);
+int set_hw_queue_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile);
+
+int set_hw_a_nodes_drop_profile(tm_handle hndl, uint32_t prof_ind);
+int set_hw_a_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile);
+
+int set_hw_b_nodes_drop_profile(tm_handle hndl, uint32_t prof_ind);
+int set_hw_b_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile);
+
+int set_hw_c_nodes_drop_profile(tm_handle hndl, uint8_t cos, uint32_t prof_ind);
+int set_hw_c_nodes_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint8_t cos);
+
+int set_hw_ports_drop_profile(tm_handle hndl, uint32_t prof_ind, uint8_t port_ind);
+int set_hw_ports_default_drop_profile(tm_handle hndl, struct tm_drop_profile *profile, uint8_t port_ind);
+
+int set_hw_ports_drop_profile_cos(tm_handle hndl, uint8_t cos, uint32_t prof_ind, uint8_t port_ind);
+int set_hw_ports_default_drop_profile_cos(tm_handle hndl,  struct tm_drop_profile *profile,
+	uint8_t cos, uint8_t port_ind);
+
+int set_hw_shaping_profile(tm_handle hndl,
+								  enum tm_level level,
+								  uint32_t node_ind,
+								  uint32_t prof_ind);
+
+int set_hw_drop_aqm_mode(tm_handle hndl);
+
+int set_hw_drop_color_num(tm_handle hndl);
+
+int set_hw_tm2tm_aqm_mode(tm_handle hndl);
+
+int set_hw_periodic_scheme(tm_handle hndl);
+
+int set_hw_map(tm_handle hndl, enum tm_level lvl, uint32_t index);
+
+int set_hw_queue(tm_handle hndl, uint32_t index);
+int get_hw_queue(tm_handle hndl, uint32_t index, struct tm_queue *queue);
+
+int set_hw_a_node(tm_handle hndl, uint32_t index);
+int get_hw_a_node(tm_handle hndl, uint32_t index, struct tm_a_node *node);
+
+int set_hw_b_node(tm_handle hndl, uint32_t index);
+int get_hw_b_node(tm_handle hndl, uint32_t index, struct tm_b_node *node);
+
+int set_hw_c_node(tm_handle hndl, uint32_t index);
+int get_hw_c_node(tm_handle hndl, uint32_t index, struct tm_c_node *node);
+
+int set_hw_queue_elig_prio_func_ptr(tm_handle hndl, uint32_t ind);
+int set_hw_a_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind);
+int set_hw_b_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind);
+int set_hw_c_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind);
+int set_hw_port_elig_prio_func_ptr(tm_handle hndl, uint8_t port_ind);
+
+/* in following functions  NULL value of pcbs/pebs   will cause to set cbs/ebs system default value */
+int set_hw_queue_shaping_ex(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs);
+int set_hw_queue_shaping_def(tm_handle hndl, uint32_t index);
+int get_hw_queue_shaping(tm_handle hndl, uint32_t index,
+							uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs);
+
+int set_hw_a_node_shaping_ex(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs);
+int set_hw_a_node_shaping_def(tm_handle hndl, uint32_t index);
+int get_hw_a_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs);
+
+int set_hw_b_node_shaping_ex(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs);
+int set_hw_b_node_shaping_def(tm_handle hndl, uint32_t index);
+int get_hw_b_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs);
+
+int set_hw_c_node_shaping_ex(tm_handle hndl, uint32_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs);
+int set_hw_c_node_shaping_def(tm_handle hndl, uint32_t index);
+int get_hw_c_node_shaping(tm_handle hndl, uint32_t index,
+							uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs);
+
+int set_hw_port_shaping_ex(tm_handle hndl, uint8_t index,
+							uint32_t cbw, uint32_t ebw, uint32_t *pcbs, uint32_t *pebs);
+int set_hw_port_shaping_def(tm_handle hndl, uint8_t index);
+int get_hw_port_shaping(tm_handle hndl, uint32_t index,
+						uint32_t *pcbw, uint32_t *pebw, uint32_t *pcbs, uint32_t *pebs);
+
+int set_hw_port_scheduling(tm_handle hndl, uint8_t port_ind);
+
+int set_hw_port_drop(tm_handle hndl, uint8_t port_ind);
+int set_hw_port_drop_cos(tm_handle hndl, uint8_t port_ind, uint8_t cos);
+
+int set_hw_port(tm_handle hndl, uint8_t index);
+int get_hw_port(tm_handle hndl, uint8_t index, struct tm_port *port);
+
+int set_hw_tree_deq_status(tm_handle hndl);
+
+#ifdef MV_QMTM_NSS_A0
+int set_hw_tree_dwrr_priority(tm_handle hndl);
+#endif
+
+int set_hw_deq_status(tm_handle hndl, enum tm_level lvl, uint32_t index);
+
+int set_hw_disable_ports(tm_handle hndl, uint32_t total_ports);
+
+
+
+int set_hw_q_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset);
+int set_hw_a_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset);
+int set_hw_b_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset);
+int set_hw_c_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset);
+int set_hw_p_lvl_elig_prio_func_entry(tm_handle hndl, uint16_t func_offset);
+
+int set_hw_elig_prio_func_tbl_q_level(tm_handle hndl);
+int set_hw_elig_prio_func_tbl_a_level(tm_handle hndl);
+int set_hw_elig_prio_func_tbl_b_level(tm_handle hndl);
+int set_hw_elig_prio_func_tbl_c_level(tm_handle hndl);
+int set_hw_elig_prio_func_tbl_p_level(tm_handle hndl);
+
+
+
+int set_hw_port_deficit_clear(tm_handle hndl, uint8_t index);
+
+int set_hw_c_node_deficit_clear(tm_handle hndl, uint32_t index);
+
+int set_hw_b_node_deficit_clear(tm_handle hndl, uint32_t index);
+
+int set_hw_a_node_deficit_clear(tm_handle hndl, uint32_t index);
+
+int set_hw_queue_deficit_clear(tm_handle hndl, uint32_t index);
+
+int set_hw_dp_remote_resp(tm_handle hndl, enum tm2tm_channel remote_lvl);
+
+int set_hw_dp_local_resp(tm_handle hndl, uint8_t port_dp, enum tm_level local_lvl);
+
+int set_hw_port_sms_attr_pbase(tm_handle hndl, uint8_t index);
+
+int set_hw_port_sms_attr_qmap_pars(tm_handle hndl, uint8_t index);
+
+int set_hw_dp_source(tm_handle hndl);
+
+int set_hw_queue_cos(tm_handle hndl, uint32_t index);
+
+int set_hw_register_db_default(tm_handle hndl);
+
+
+int get_hw_queue_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc);
+int get_hw_a_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc);
+int get_hw_b_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc);
+int get_hw_c_node_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc);
+int get_hw_port_elig_prio_func_ptr(tm_handle hndl, uint32_t ind, uint8_t *pfunc);
+
+int get_hw_elig_prio_func(tm_handle hndl, enum tm_level level, uint16_t func_offset, uint16_t *table);
+
+
+int get_hw_port_status(tm_handle hndl,
+					 uint8_t index,
+					 struct tm_port_status *tm_status);
+
+int get_hw_c_node_status(tm_handle hndl,
+					   uint32_t index,
+					   struct tm_node_status *tm_status);
+
+int get_hw_b_node_status(tm_handle hndl,
+					   uint32_t index,
+					   struct tm_node_status *tm_status);
+
+int get_hw_a_node_status(tm_handle hndl,
+					   uint32_t index,
+					   struct tm_node_status *tm_status);
+
+int get_hw_queue_status(tm_handle hndl,
+					   uint32_t index,
+					   struct tm_node_status *tm_status);
+
+int get_hw_queue_length(tm_handle hndl,
+					  enum tm_level level,
+					  uint32_t index,
+					  uint32_t *av_q_length);
+
+int get_hw_sched_errors(tm_handle hndl, struct tm_error_info *info);
+
+int get_hw_drop_errors(tm_handle hndl, struct tm_error_info *info);
+
+int tm_dump_port_hw(tm_handle hndl, uint32_t portIndex);
+
+int set_hw_elig_per_queue_range(tm_handle hndl, uint32_t startInd, uint32_t endInd, uint8_t elig);
+
+int check_hw_drop_path(tm_handle hndl, uint32_t timeout, uint8_t full_path);
+
+int show_hw_elig_prio_func(tm_handle hndl, enum tm_level level, uint16_t func_offset);
+
+
+
+int set_hw_queue_map_directly(tm_handle hndl, uint32_t queue_index, uint32_t parent);
+
+int set_hw_a_node_map_directly(tm_handle hndl,
+				 uint32_t a_node_index,
+				 uint32_t parent,
+				 uint32_t first_child,
+				 uint32_t last_child);
+
+
+#endif   /* SET_HW_REGISTERS_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_core_types.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_core_types.h
new file mode 100644
index 0000000..832ee0f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_core_types.h
@@ -0,0 +1,532 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef	TM_CORE_TYPES_H
+#define	TM_CORE_TYPES_H
+
+
+#include "tm_defs.h"
+
+/** Periodic Scheme configuration
+ */
+#define TM_FIXED_PERIODIC_SCHEME_DEC_EN			TM_DISABLE
+#define TM_FIXED_PERIODIC_SCHEME_PER_EN			1
+#define TM_FIXED_PERIODIC_SCHEME_L				55
+#define TM_FIXED_PERIODIC_SCHEME_K				1
+#define TM_FIXED_PERIODIC_SCHEME_N				23
+#define TM_FIXED_10_M_SHAPING_TOKEN				10
+
+/** Port level shaping
+ */
+#define TM_FIXED_2_5_G_PORT_PERIODIC_SCHEME_PER_INTERVAL	48
+#define TM_FIXED_2_5_G_PORT_SHAPING_PERIODS					1
+#define TM_FIXED_2_5_G_PORT_SHAPING_BURST_SIZE				10
+
+
+/** C level shaping
+ */
+#define TM_FIXED_2_5_G_C_LEVEL_PERIODIC_SCHEME_PER_INTERVAL		768
+#define TM_FIXED_10_M_C_LEVEL_SHAPING_TOKEN_RES					4
+#define TM_FIXED_2_5_G_C_LEVEL_SHAPING_BURST_SIZE				16
+
+/** B level shaping
+ */
+#define TM_FIXED_2_5_G_B_LEVEL_PERIODIC_SCHEME_PER_INTERVAL		1536
+#define TM_FIXED_10_M_B_LEVEL_SHAPING_TOKEN_RES					5
+#define TM_FIXED_2_5_G_B_LEVEL_SHAPING_BURST_SIZE				16
+
+/** A level shaping
+ */
+#define TM_FIXED_2_5_G_A_LEVEL_PERIODIC_SCHEME_PER_INTERVAL		1536
+#define TM_FIXED_10_M_A_LEVEL_SHAPING_TOKEN_RES					5
+#define TM_FIXED_2_5_G_A_LEVEL_SHAPING_BURST_SIZE				16
+
+/** Queue level shaping
+ */
+#define TM_FIXED_2_5_G_QUEUE_PERIODIC_SCHEME_PER_INTERVAL		3072
+#define TM_FIXED_10_M_QUEUE_SHAPING_TOKEN_RES					6
+#define TM_FIXED_2_5_G_QUEUE_SHAPING_BURST_SIZE					16
+
+
+/** Internal Constants definitions
+ */
+#define TM_NUM_QUEUE_DROP_PROF        16 /* was 2048*/
+#define TM_NUM_A_NODE_DROP_PROF       8  /* was 256*/
+#define TM_NUM_B_NODE_DROP_PROF       8  /* was 64*/
+#define TM_NUM_C_NODE_DROP_PROF       2  /* was 64*/ /* Per CoS */
+#define TM_NUM_PORT_DROP_PROF         16 /* TBD: get_tm_port_count() */
+#define TM_NUM_WRED_QUEUE_CURVES      8  /* Per Color */
+#define TM_NUM_WRED_A_NODE_CURVES     8  /* Per Color */
+#define TM_NUM_WRED_B_NODE_CURVES     4
+#define TM_NUM_WRED_C_NODE_CURVES     2  /* was 4*/ /* Per CoS */
+#define TM_NUM_WRED_PORT_CURVES       4
+#define TM_NUM_DIVIDERS               8
+
+
+/** Registers values
+ */
+#define TM_128M 0x7FFFFFF
+#define TM_4M   0x3FFFFF
+
+#define TM_1K	1024
+
+
+/** Delay Size Multiplier (used to calculate TD Threshold)
+ */
+#define TM_DELAY_SIZE_MULT   1
+
+
+/* Physical port capacity (speed in Kbits) */
+#define TM_1G_SPEED   1000000  /* 1050000000UL */   /* 1G + 5% */
+#define TM_2HG_SPEED  2000000  /* 2625000000UL */   /* 2.5G + 5% */
+#define TM_10G_SPEED  10000000 /* 10500000000ULL */ /* 10G + 5% */
+#define TM_40G_SPEED  40000000 /* 42000000000ULL */ /* 40G + 5% */
+#define TM_50G_SPEED  50000000
+#define TM_100G_SPEED 100000000
+
+
+/** WRED CoS number */
+#define TM_WRED_COS              8
+
+/** WRED curve points number */
+#define TM_WRED_CURVE_POINTS     32
+
+/** Drop Profile Pointer Table values */
+#define TM_Q_DRP_PROF_PER_ENTRY  4
+#define TM_A_DRP_PROF_PER_ENTRY  4
+#define TM_B_DRP_PROF_PER_ENTRY  8
+#define TM_C_DRP_PROF_PER_ENTRY  8
+
+
+/** Max number of Scrubbing slots */
+#define TM_SCRUB_SLOTS 64
+
+/** Max Probability Mode */
+enum tm_max_prob_mode {
+	TM_MAX_PROB_100 = 0,   /* 100%  */
+	TM_MAX_PROB_50,        /*  50%  */
+	TM_MAX_PROB_25,        /*  25%  */
+	TM_MAX_PROB_12H       /* 12.5% */
+};
+
+
+/*********************************/
+/* Internal Databases Structures */
+/*********************************/
+#define TM_ELIG_FUNC_TABLE_SIZE		64
+
+#define	TM_NODE_DISABLED_FUN		62
+
+#define VALIDATE_ELIG_FUNCTION(elig_fun) \
+do { \
+	if ((elig_fun >= TM_ELIG_FUNC_TABLE_SIZE) || (elig_fun == TM_NODE_DISABLED_FUN))	{\
+		/* maximum function id 0..63 */\
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;\
+		goto out;\
+	} \
+} while (0)
+
+
+/** Global arrays structures definitions */
+
+
+/** WRED curve
+ */
+struct tm_wred_curve {
+	uint8_t prob[32];
+};
+
+struct curve_ind {
+	uint8_t index:3; /* 3 bits for Q/A-level, 2 bits - B/C/P levels */
+};
+
+struct min_thresh {
+	uint16_t thresh:10;
+};
+
+struct dwrr_quantum {
+	uint16_t quantum:9;
+};
+
+struct scale_exp {
+	uint8_t exp:5;
+};
+
+struct scale_ratio {
+	uint16_t ratio:10;
+};
+
+
+struct dp_ratio {
+	uint8_t ratio:6;
+};
+
+
+/** Range of children nodes in symetric distribution
+ */
+struct ranges {
+	uint32_t norm_range[3];
+	uint32_t last_range[3];
+};
+
+/** Drop profile
+ */
+struct tm_drop_profile {
+	uint32_t out_bw;                /**< CATD/WRED Out BW in Kbits/sec */
+	uint32_t cbtd_bw;               /**< CBTD BW in Kbits/sec */
+	uint8_t aql_exp:4;              /**< Forget factor exponent */
+	uint8_t color_td_en:1;          /**< Colored Tail Drop Enable */
+
+	struct scale_exp scale_exp[3];     /**< Used for scaling of AQL range */
+	struct scale_ratio scale_ratio[3]; /**< Used for scaling of DP range */
+	struct curve_ind curve_id[3];      /**< RED curve index per color[0..2] */
+	struct dp_ratio dp_ratio[3];       /**< Used for scaling of DP */
+
+	struct min_thresh min_threshold[3];/**< RED curve Min threshold per color [0..2] */
+	uint8_t td_thresh_res:1;     /**< Tail Drop Threshold resolution - 16B or 16KB */
+	uint32_t td_threshold:19;    /**< Hard Limit on queue length */
+	struct rm_list *use_list;    /**< List of ports that use this profile, for Port lvl only */
+	uint32_t use_counter;
+
+	/* For read issues */
+	uint32_t min_th_sw[3];        /**< Min Threshold ratio from RTT in % per color */
+	uint32_t max_th_sw[3];        /**< Max Threshold ratio from RTT in % per color */
+} __ATTRIBUTE_PACKED__;
+
+
+/** Queue data structure
+ */
+struct tm_queue {
+	uint8_t installed:1;
+	uint16_t dwrr_quantum:14;
+	uint16_t parent_a_node:14;
+	uint8_t wred_profile_ref;
+	uint8_t elig_prio_func_ptr;
+} __ATTRIBUTE_PACKED__;
+
+
+/** A-node data structure
+ */
+struct tm_a_node {
+	uint16_t dwrr_quantum:14;
+	uint8_t dwrr_priority;
+	uint16_t parent_b_node:12;
+	uint16_t first_child_queue;
+	uint16_t last_child_queue;
+	uint8_t wred_profile_ref;
+	uint8_t elig_prio_func_ptr;
+} __ATTRIBUTE_PACKED__;
+
+
+/** B-node data structure
+ */
+struct tm_b_node {
+	uint16_t dwrr_quantum:14;
+	uint8_t dwrr_priority;
+	uint16_t parent_c_node:9;
+	uint16_t first_child_a_node:14;
+	uint16_t last_child_a_node:14;
+	uint8_t wred_profile_ref;
+	uint8_t elig_prio_func_ptr;
+} __ATTRIBUTE_PACKED__;
+
+
+/** C-node data structure
+ */
+struct tm_c_node {
+	uint8_t wred_cos;   /* bit map */
+	uint16_t dwrr_quantum:14;
+	uint8_t dwrr_priority;
+	uint8_t parent_port;
+	uint16_t first_child_b_node:12;
+	uint16_t last_child_b_node:12;
+	uint8_t wred_profile_ref[TM_WRED_COS];
+	uint8_t elig_prio_func_ptr;
+} __ATTRIBUTE_PACKED__;
+
+
+/** Port data structure
+ */
+struct tm_port {
+#ifdef MV_QMTM_NSS_A0
+	struct dwrr_quantum dwrr_quantum[8];
+#endif
+	uint8_t dwrr_priority;
+	uint8_t port_speed:3;
+
+#ifdef MV_QMTM_NOT_NSS
+	/* Shaping config */
+	uint16_t cir_token:11;
+	uint16_t eir_token:11;
+	uint32_t cir_burst_size:17;
+	uint32_t eir_burst_size:17;
+	uint16_t periods:13;
+	uint8_t min_token_res:1;
+	uint8_t max_token_res:1;
+#endif
+	uint8_t sym_mode:1;         /* assymetric/symetric tree */
+	uint16_t first_child_c_node:9;
+	uint16_t last_child_c_node:9;
+	struct ranges children_range;   /* for symetric distribution only */
+
+#ifdef MV_QMTM_NOT_NSS
+	uint8_t rcb_high_range_limit;
+	uint8_t rcb_low_range_limit;
+#endif
+
+	/* WRED profile */
+	uint8_t wred_profile_ref; /* Global port Drop profile */
+	uint8_t wred_cos;   /* bit map */
+	uint8_t wred_profile_ref_cos[TM_WRED_COS];
+#ifdef MV_QMTM_NOT_NSS
+	/*save the values as configured for read api*/
+	uint32_t cbs_sw;                  /**< CBS in kbytes */
+	uint32_t ebs_sw;                  /**< EBS in kbytes */
+#endif
+	uint8_t elig_prio_func_ptr;
+} __ATTRIBUTE_PACKED__;
+
+
+/* Eligible Priority Functions structures */
+
+struct tm_elig_prio_func_node_entry {
+	uint16_t func_out[4];
+};
+
+/* Eligible Priority Functions Definitions */
+
+struct tm_elig_prio_func_node {
+	struct tm_elig_prio_func_node_entry tbl_entry[8];
+};
+
+struct tm_elig_prio_func_queue {
+	struct tm_elig_prio_func_node_entry tbl_entry;
+};
+
+
+#ifdef MV_QMTM_NOT_NSS
+/** TM2TM Channel */
+struct tm2tm_port_channel {
+	uint8_t configured:1;
+	uint8_t egr_elems:6;        /* x4, max 64, reset 0x30, 0=all 64 */
+	uint8_t _reserved_1:1;
+	uint8_t src_lvl:3;          /* A/B/C/Port */
+	uint8_t mode:1;             /* WRED/BP */
+	/* relevant for BP mode only */
+	uint8_t bp_map:1;           /* Queue/C */
+	uint16_t bp_offset;
+	uint8_t bp_xon:6;           /* BP Xon */
+	uint8_t _reserved_2:2;
+	uint8_t bp_xoff:6;          /* BP Xoff */
+} __ATTRIBUTE_PACKED__;
+
+struct tm2tm_node_channel {
+	uint8_t configured:1;
+	uint16_t egr_elems;         /* x16, max 64K, reset 0x0, 0=all 64K */
+	uint8_t src_lvl:3;          /* Queue/A/B/C */
+	uint8_t mode:1;             /* WRED/BP */
+	/* relevant for BP mode only */
+	uint8_t bp_map:1;           /* Queue/C */
+	uint16_t bp_offset;
+	uint8_t bp_xon:6;           /* BP Xon */
+	uint8_t _reserved_1:2;
+	uint8_t bp_xoff:6;          /* BP Xoff */
+} __ATTRIBUTE_PACKED__;
+#endif
+/** TM2TM Egress AQM mode settings */
+struct tm_aqm_local_params {
+	uint8_t configured:1;
+	uint8_t color_num; /* 1 or 2 or 3 */
+	enum tm_dp_source dp_src[3]; /* QL/AQL per color [0..2] */
+	uint8_t resolution; /* 4 or 6 bits */
+	enum tm_max_prob_mode max_p_mode[4]; /* Max Probability Mode - 100/50/25/12.5% */
+} __ATTRIBUTE_PACKED__;
+
+
+/** TM2TM Ingress AQM mode settings - Channels */
+struct tm_aqm_remote_params {
+	uint8_t configured:1;
+	uint8_t color_num; /* 0 or 1 or 2 */
+} __ATTRIBUTE_PACKED__;
+
+/** TM2TM Drop Unit structure */
+struct dp_unit {
+	struct tm_aqm_local_params local[P_LEVEL+1]; /* per Port/C/B/A/Queue level */
+	struct tm_aqm_remote_params remote[TM2TM_PORT_CH+1]; /* per Port/Node level */
+};
+
+
+/** TM Scheduler Port SMS pBase Attribute structure */
+struct port_sms_attr_pbase {
+	uint8_t pbase;
+	uint8_t pshift;
+};
+
+/** TM Scheduler Port SMS Qmap parsing Attribute structure */
+struct port_sms_attr_qmap_parsing {
+	uint8_t mode;
+	uint16_t base_q;
+	uint8_t dcolor;
+};
+
+
+
+/* typedef void *tm_handle; */
+#define tm_handle void *
+
+
+struct tm_ctl {
+	uint32_t magic;
+	tm_handle rm;   /**< rm hndl */
+
+	/* Nodes arrays */
+	struct tm_queue *tm_queue_array;
+	struct tm_a_node *tm_a_node_array;
+	struct tm_b_node *tm_b_node_array;
+	struct tm_c_node *tm_c_node_array;
+	struct tm_port *tm_port_array;
+
+	/* Global arrays */
+	struct tm_drop_profile *tm_q_lvl_drop_profiles;
+	struct tm_drop_profile *tm_a_lvl_drop_profiles;
+	struct tm_drop_profile *tm_b_lvl_drop_profiles;
+	struct tm_drop_profile *tm_c_lvl_drop_profiles[TM_WRED_COS];
+	struct tm_drop_profile *tm_p_lvl_drop_profiles;
+	struct tm_drop_profile *tm_p_lvl_drop_profiles_cos[TM_WRED_COS];
+
+	struct tm_wred_curve *tm_wred_q_lvl_curves;
+	struct tm_wred_curve *tm_wred_a_lvl_curves;
+	struct tm_wred_curve *tm_wred_b_lvl_curves;
+	struct tm_wred_curve *tm_wred_c_lvl_curves[TM_WRED_COS];
+	struct tm_wred_curve *tm_wred_ports_curves;
+	struct tm_wred_curve *tm_wred_ports_curves_cos[TM_WRED_COS];
+
+	/* Eligible Priority Function Table arrays */
+	struct tm_elig_prio_func_node tm_elig_prio_a_lvl_tbl[TM_ELIG_FUNC_TABLE_SIZE];
+	struct tm_elig_prio_func_node tm_elig_prio_b_lvl_tbl[TM_ELIG_FUNC_TABLE_SIZE];
+	struct tm_elig_prio_func_node tm_elig_prio_c_lvl_tbl[TM_ELIG_FUNC_TABLE_SIZE];
+	struct tm_elig_prio_func_node tm_elig_prio_p_lvl_tbl[TM_ELIG_FUNC_TABLE_SIZE];
+
+	struct tm_elig_prio_func_queue tm_elig_prio_q_lvl_tbl[TM_ELIG_FUNC_TABLE_SIZE];
+
+	uint16_t *tm_q_lvl_drop_prof_ptr;   /* mirror for Q Drop prof. ptr table
+										* to avoid read-modify-write during
+										* single pointer update */
+	uint16_t *tm_a_lvl_drop_prof_ptr;   /* mirror for A Drop prof. ptr table
+										* to avoid read-modify-write during
+										* single pointer update */
+	uint8_t *tm_b_lvl_drop_prof_ptr;    /* mirror for B Drop prof. ptr table
+										* to avoid read-modify-write during
+										* single pointer update */
+	uint8_t *tm_c_lvl_drop_prof_ptr[TM_WRED_COS];
+										/* mirror for C Drop prof. ptr table
+										* to avoid read-modify-write during
+										* single pointer update */
+
+	/* Abstraction for Port Drop profiles */
+	uint8_t *tm_p_lvl_drop_prof_ptr;
+	uint8_t *tm_p_lvl_drop_prof_ptr_cos[TM_WRED_COS]; /* CoS mode */
+
+	uint16_t *tm_q_cos;   /* mirror for Q Cos table
+						* to avoid read-modify-write during
+						* single Queue update */
+
+#ifdef MV_QMTM_NOT_NSS
+	/* Scheduling parameters */
+	uint32_t freq;                 /**< LAD frequency */
+#endif
+	/* global update states */
+	uint8_t periodic_scheme_state; /**< periodic scheme updated/not updated */
+	/* RCB sections */
+	uint8_t rcb_section_used[4];   /**< 4 sections, max range 0..0xFF each */
+
+#ifdef MV_QMTM_NOT_NSS
+	/* per level data including port level */
+	struct level_config level_data[P_LEVEL+1];
+#endif
+	/* Tree data */
+	uint8_t tree_deq_status;       /**< tree DeQ status */
+#ifdef MV_QMTM_NSS_A0
+	uint8_t tree_dwrr_priority;    /**< tree DWRR priority bitmap for port scheduling */
+#endif
+
+	/* TM2TM */
+	struct dp_unit dp_unit;
+#ifdef MV_QMTM_NOT_NSS
+	struct tm2tm_port_channel port_ch;
+	struct tm2tm_node_channel node_ch;
+#endif
+	/* Reshuffling changes */
+	struct tm_tree_change list;
+
+	/* Other registers */
+#ifdef MV_QMTM_NSS_A0
+	uint8_t port_ext_bp_en;
+	uint8_t dwrr_bytes_burst_limit;
+#endif
+	uint32_t mtu;                  /**<  Maximal Transmission Unit */
+	uint16_t min_quantum;          /**<  nodes minimum quantum [256B], must be  equal to TM_MSU */
+	uint16_t min_pkg_size;         /**<  minimum package size */
+#ifdef MV_QMTM_NSS_A0
+	uint8_t port_ch_emit;          /**<  port chunks emitted per scheduler selection */
+#endif
+#ifdef MV_QMTM_NOT_NSS
+	uint8_t aging_status;          /**< aging status */
+#endif
+	/* TM-SMS mapping */
+	struct port_sms_attr_pbase        *tm_port_sms_attr_pbase;
+	struct port_sms_attr_qmap_parsing *tm_port_sms_attr_qmap_pars;
+
+	/* environment*/
+	tm_handle hEnv;
+};
+
+
+
+/** Internal TM control structure
+ */
+
+#define TM_MAGIC 0x24051974
+/* following macro declares and checks validity of tmctl*/
+#define DECLARE_TM_CTL_PTR(name, value)	struct tm_ctl *name = (struct tm_ctl *)value;
+
+#define CHECK_TM_CTL_PTR(ptr)	\
+{ \
+	if (!ptr) \
+		return -EINVAL; \
+	if (ptr->magic != TM_MAGIC) \
+		return -EBADF; \
+}
+/*
+#define TM_CTL(name, handle) DECLARE_TM_CTL_PTR(name, handle); CHECK_TM_CTL_PTR(name);
+*/
+
+#define TM_ENV(var)	((var)->hEnv)
+
+
+#endif   /* TM_CORE_TYPES_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.c
new file mode 100644
index 0000000..3fa3c54
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.c
@@ -0,0 +1,605 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_ctl.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_hw_configuration_interface.h"
+#include "tm_os_interface.h"
+#include "tm_locking_interface.h"
+#include "rm_internal_types.h"
+#include "rm_ctl.h"
+#include "rm_free.h"
+#include "rm_status.h"
+#include "rm_list.h"
+#include "tm_rw_registers_interface.h"
+#include "tm_nodes_ctl.h"
+#include "tm_drop.h"
+#include "tm_nodes_utils.h"
+#include "tm_elig_prio_func.h"
+#include "tm_errcodes.h"
+#include "set_hw_registers.h"
+#include "tm_get_gen_param_interface.h"
+#include "tm_core_types.h"
+
+
+int tm_lib_init_hw(tm_handle hndl)
+{
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* Get general parameters : LAD frequency,  dwrr params  - they are readed from H/W resources */
+	rc = tm_get_gen_params(ctl);
+	if (rc)
+		goto out;
+
+	/* configure default drop registers */
+	rc = _tm_config_default_drop_hw((tm_handle)ctl);
+	if (rc)
+		goto out;
+
+	rc = tm_config_elig_prio_func_table((tm_handle)ctl, 1); /* with H/W update*/
+	if (rc)
+		goto out;
+
+	/* TBD */
+	/*rc = set_hw_disable_ports((tm_handle) ctl, get_tm_port_count());*/
+out:
+	return rc;
+}
+
+
+/**
+ */
+int tm_lib_open(const char *cProductName, tm_handle hEnv, tm_handle *htm)
+{
+	rmctl_t rm = NULL;
+	struct tm_ctl *ctl = NULL;
+	uint32_t total_queues;
+	uint16_t total_a_nodes;
+	uint16_t total_b_nodes;
+	uint16_t total_c_nodes;
+	uint8_t total_ports;
+	int rc = 0;
+	unsigned int i;
+	unsigned int j;
+
+
+	if ((*htm) != NULL)
+	{
+		rc = -EINVAL;
+		goto out;
+	}
+
+	*htm = NULL;
+
+	if (init_tm_hardware_configuration(cProductName))
+	{
+		rc = TM_CONF_INVALID_PROD_NAME;
+		return rc;
+	}
+
+	/* Total number of nodes per level */
+	total_ports = get_tm_port_count();
+	total_c_nodes = get_tm_c_nodes_count();
+	total_b_nodes = get_tm_b_nodes_count();
+	total_a_nodes = get_tm_a_nodes_count();
+	total_queues = get_tm_queues_count();
+
+	/* Allocate handle */
+	ctl = tm_malloc(sizeof(*ctl) * 1);
+	if (!ctl)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl, 0, sizeof(*ctl));
+
+	ctl->magic = TM_MAGIC;
+	ctl->hEnv=hEnv;
+
+	rc = rm_open(total_ports, total_c_nodes, total_b_nodes, total_a_nodes, total_queues, &rm);
+	if (rc)
+		goto out;
+
+	ctl->rm = rm;
+
+	if (rc)
+		goto out;
+
+	/* allocate global arrays */
+	ctl->tm_port_array = tm_malloc(sizeof(struct tm_port) * total_ports);
+	if (ctl->tm_port_array == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_c_node_array = tm_malloc(sizeof(struct tm_c_node) * total_c_nodes);
+	if (ctl->tm_c_node_array == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_b_node_array = tm_malloc(sizeof(struct tm_b_node) * total_b_nodes);
+	if (ctl->tm_b_node_array == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_a_node_array = tm_malloc(sizeof(struct tm_a_node) * total_a_nodes);
+	if (ctl->tm_a_node_array == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_queue_array = tm_malloc(sizeof(struct tm_queue) * total_queues);
+	if (ctl->tm_queue_array == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_q_lvl_drop_profiles = tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_QUEUE_DROP_PROF);
+	if (ctl->tm_q_lvl_drop_profiles == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_a_lvl_drop_profiles = tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_A_NODE_DROP_PROF);
+	if (ctl->tm_a_lvl_drop_profiles == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_b_lvl_drop_profiles = tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_B_NODE_DROP_PROF);
+	if (ctl->tm_b_lvl_drop_profiles == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++)
+	{
+		ctl->tm_c_lvl_drop_profiles[i] = tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_C_NODE_DROP_PROF);
+		if (ctl->tm_c_lvl_drop_profiles[i] == NULL)
+		{
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	ctl->tm_p_lvl_drop_profiles =
+		tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_PORT_DROP_PROF);
+	if (ctl->tm_p_lvl_drop_profiles == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		ctl->tm_p_lvl_drop_profiles_cos[i] =
+			tm_malloc(sizeof(struct tm_drop_profile) * TM_NUM_PORT_DROP_PROF);
+		if (ctl->tm_p_lvl_drop_profiles_cos[i] == NULL) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+
+	ctl->tm_wred_q_lvl_curves = tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_QUEUE_CURVES);
+	if (ctl->tm_wred_q_lvl_curves == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_wred_a_lvl_curves = tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_A_NODE_CURVES);
+	if (ctl->tm_wred_a_lvl_curves == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_wred_b_lvl_curves = tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_B_NODE_CURVES);
+	if (ctl->tm_wred_b_lvl_curves == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++)
+	{
+		ctl->tm_wred_c_lvl_curves[i] = tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_C_NODE_CURVES);
+		if (ctl->tm_wred_c_lvl_curves[i] == NULL)
+		{
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	ctl->tm_wred_ports_curves =
+		tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_PORT_CURVES);
+	if (ctl->tm_wred_ports_curves == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+/* BC2 */
+	for (i = 0; i < TM_WRED_COS; i++) {
+		ctl->tm_wred_ports_curves_cos[i] =
+			tm_malloc(sizeof(struct tm_wred_curve) * TM_NUM_WRED_PORT_CURVES);
+		if (ctl->tm_wred_ports_curves_cos[i] == NULL) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+
+	ctl->tm_q_lvl_drop_prof_ptr = tm_malloc(sizeof(uint16_t) * total_queues);
+	if (ctl->tm_q_lvl_drop_prof_ptr == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_a_lvl_drop_prof_ptr = tm_malloc(sizeof(uint16_t) * total_a_nodes);
+	if (ctl->tm_a_lvl_drop_prof_ptr == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	ctl->tm_b_lvl_drop_prof_ptr = tm_malloc(sizeof(uint8_t) * total_b_nodes);
+	if (ctl->tm_b_lvl_drop_prof_ptr == NULL)
+	{
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++)
+	{
+		ctl->tm_c_lvl_drop_prof_ptr[i] = tm_malloc(sizeof(uint8_t) * total_c_nodes);
+		if (ctl->tm_c_lvl_drop_prof_ptr[i] == NULL)
+		{
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+
+	ctl->tm_p_lvl_drop_prof_ptr = tm_malloc(sizeof(uint8_t) * total_ports);
+	if (ctl->tm_p_lvl_drop_prof_ptr == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		ctl->tm_p_lvl_drop_prof_ptr_cos[i] =
+			tm_malloc(sizeof(uint8_t) * total_ports);
+		if (ctl->tm_p_lvl_drop_prof_ptr_cos[i] == NULL) {
+			rc = -ENOMEM;
+			goto out;
+		}
+	}
+
+	ctl->tm_q_cos = tm_malloc(sizeof(uint16_t) * total_queues);
+	if (ctl->tm_q_cos == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->tm_q_cos, 0, sizeof(uint16_t) * total_queues);
+
+	ctl->tm_port_sms_attr_pbase = tm_malloc(sizeof(struct port_sms_attr_pbase) * total_ports);
+	if (ctl->tm_port_sms_attr_pbase == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->tm_port_sms_attr_pbase, 0, sizeof(struct port_sms_attr_pbase) * total_ports);
+
+	ctl->tm_port_sms_attr_qmap_pars = tm_malloc(sizeof(struct port_sms_attr_qmap_parsing) * total_ports);
+	if (ctl->tm_port_sms_attr_qmap_pars == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	tm_memset(ctl->tm_port_sms_attr_qmap_pars, 0, sizeof(struct port_sms_attr_qmap_parsing) * total_ports);
+
+	/* set to default all the arrays fields */
+
+	for (i = 0; i < total_ports; i++)
+		ctl->tm_port_sms_attr_pbase[i].pbase = 0x4;
+
+	for (i = 0; i < total_ports; i++) {
+		rc = set_sw_port_default(ctl->tm_port_array, (uint8_t)i, rm);
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < total_c_nodes; i++) {
+		rc = set_sw_c_node_default(ctl->tm_c_node_array, i, rm);
+		if (rc)
+			goto out;
+		ctl->tm_c_node_array[i].parent_port = total_ports - 1;
+	}
+
+	for (i = 0; i < total_b_nodes; i++) {
+		rc = set_sw_b_node_default(ctl->tm_b_node_array, i, rm);
+		if (rc)
+			goto out;
+		ctl->tm_b_node_array[i].parent_c_node = total_c_nodes - 1;
+	}
+
+	for (i = 0; i < total_a_nodes; i++) {
+		rc = set_sw_a_node_default(ctl->tm_a_node_array, i, rm);
+		if (rc)
+			goto out;
+		ctl->tm_a_node_array[i].parent_b_node = total_b_nodes - 1;
+	}
+
+	for (i = 0; i < total_queues; i++) {
+		rc = set_sw_queue_default(ctl->tm_queue_array, i, rm);
+		if (rc)
+			goto out;
+		ctl->tm_queue_array[i].parent_a_node = total_a_nodes - 1;
+	}
+
+	for (i = 0; i < TM_NUM_QUEUE_DROP_PROF; i++) {
+		rc = set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles, i);
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_A_NODE_DROP_PROF; i++) {
+		rc = set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles, i);
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_B_NODE_DROP_PROF; i++) {
+		rc = set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles, i);
+		if (rc)
+			goto out;
+	}
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_C_NODE_DROP_PROF; i++)
+		{
+			rc = set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[j], i);
+			if (rc)
+				goto out;
+		}
+	}
+
+	for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+		rc = set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, i);
+		if (rc)
+			goto out;
+	}
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+			rc = set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[j], i);
+			if (rc)
+				goto out;
+		}
+	}
+
+	for (i = 0; i < TM_NUM_WRED_QUEUE_CURVES; i++) {
+		rc = set_sw_wred_curve_default(ctl->tm_wred_q_lvl_curves, (uint16_t)i);
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_A_NODE_CURVES; i++) {
+		rc = set_sw_wred_curve_default(ctl->tm_wred_a_lvl_curves, (uint16_t)i);
+		if (rc)
+			goto out;
+	}
+
+	for (i = 0; i < TM_NUM_WRED_B_NODE_CURVES; i++) {
+		rc = set_sw_wred_curve_default(ctl->tm_wred_b_lvl_curves, (uint16_t)i);
+		if (rc)
+			goto out;
+	}
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_WRED_C_NODE_CURVES; i++) {
+			rc = set_sw_wred_curve_default(ctl->tm_wred_c_lvl_curves[j], (uint16_t)i);
+			if (rc)
+				goto out;
+		}
+	}
+
+	for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+		rc = set_sw_wred_curve_default(ctl->tm_wred_ports_curves, (uint16_t)i);
+		if (rc)
+			goto out;
+	}
+
+	for (j = 0; j < TM_WRED_COS; j++) {
+		for (i = 0; i < TM_NUM_WRED_PORT_CURVES; i++) {
+			rc = set_sw_wred_curve_default(ctl->tm_wred_ports_curves_cos[j], (uint16_t)i);
+			if (rc)
+				goto out;
+		}
+	}
+
+	for (i = 0; i < total_queues; i++)
+		ctl->tm_q_lvl_drop_prof_ptr[i] = 0;
+
+	for (i = 0; i < total_a_nodes; i++)
+		ctl->tm_a_lvl_drop_prof_ptr[i] = 0;
+
+	for (i = 0; i < total_b_nodes; i++)
+		ctl->tm_b_lvl_drop_prof_ptr[i] = 0;
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		for (j = 0; j < total_c_nodes; j++)
+			ctl->tm_c_lvl_drop_prof_ptr[i][j] = 0;
+		for (j = 0; j < total_ports; j++)
+			ctl->tm_p_lvl_drop_prof_ptr_cos[i][j] = 0;
+	}
+
+	for (i = 0; i < total_ports; i++)
+		ctl->tm_p_lvl_drop_prof_ptr[i] = 0;
+
+	/* Reshuffling changes list */
+	ctl->list.next = NULL;
+
+	/* Shaping Profile #0 is reserved in the library and represents no
+	 * shaping. If the user application doesn't want to apply shaping
+	 * for a node the TM_INF_PROFILE must be used for
+	 * shaping profile referece */
+
+	/* Drop Profiles #0 are reserved in the library and represent no drop.
+	 * If the user application doesn't want to apply drop for a node
+	 * the TM_NO_DROP_PROFILE must be used for drop profile referece */
+	/* WRED Curves #0 are reserved in the library and represent traditional
+	 * curve with 50% maximal drop probability. */
+	/* Create default drop profiles & curves for each level */
+	rc = _tm_config_default_drop_sw((tm_handle)ctl);
+	if (rc)
+		goto out;
+
+	/* scheduling configuration */
+	rc = set_sw_sched_conf_default((tm_handle)ctl);
+	if (rc)
+		goto out;
+
+	/* other scheduler registers */
+	rc = set_sw_gen_conf_default((tm_handle)ctl);
+	if (rc)
+		goto out;
+
+	rc = tm_config_elig_prio_func_table((tm_handle)ctl, 0); /* without H/W update*/
+	if (rc)
+		goto out;
+
+	/* set the handle */
+	*htm = (tm_handle)ctl;
+
+out:
+	if ((rc) && (ctl))
+		tm_lib_close((tm_handle)ctl);
+	return rc;
+}
+
+
+/**
+ */
+int tm_lib_close(tm_handle hndl)
+{
+	unsigned int i,j;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, (tm_handle)hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* Free use lists of Drop profiles */
+	/* Relevant for Port level only */
+	for (i = 0; i < TM_NUM_PORT_DROP_PROF; i++) {
+		if (ctl->tm_p_lvl_drop_profiles[i].use_list != NULL) {
+			rc = rm_list_delete(rm,
+								ctl->tm_p_lvl_drop_profiles[i].use_list);
+			if (rc)
+				return rc;
+		}
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++)
+		for (j = 0; j < TM_NUM_PORT_DROP_PROF; j++) {
+			if (ctl->tm_p_lvl_drop_profiles_cos[i][j].use_list != NULL) {
+				rc = rm_list_delete(rm,
+									ctl->tm_p_lvl_drop_profiles_cos[i][j].use_list);
+				if (rc)
+					return rc;
+			}
+		}
+	rm_close(rm);
+
+	/* Clean reshuffling list */
+	tm_clean_list(hndl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	tm_free(ctl->tm_queue_array);
+	tm_free(ctl->tm_a_node_array);
+	tm_free(ctl->tm_b_node_array);
+	tm_free(ctl->tm_c_node_array);
+	tm_free(ctl->tm_port_array);
+	tm_free(ctl->tm_q_lvl_drop_prof_ptr);
+	tm_free(ctl->tm_a_lvl_drop_prof_ptr);
+	tm_free(ctl->tm_b_lvl_drop_prof_ptr);
+	for (i = 0; i < TM_WRED_COS; i++) {
+		tm_free(ctl->tm_c_lvl_drop_prof_ptr[i]);
+		tm_free(ctl->tm_p_lvl_drop_prof_ptr_cos[i]);
+	}
+	tm_free(ctl->tm_p_lvl_drop_prof_ptr);
+	tm_free(ctl->tm_q_cos);
+	tm_nodes_unlock(TM_ENV(ctl));
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	tm_free(ctl->tm_q_lvl_drop_profiles);
+	tm_free(ctl->tm_a_lvl_drop_profiles);
+	tm_free(ctl->tm_b_lvl_drop_profiles);
+	for (i = 0; i < TM_WRED_COS; i++) {
+		tm_free(ctl->tm_c_lvl_drop_profiles[i]);
+		tm_free(ctl->tm_p_lvl_drop_profiles_cos[i]);
+	}
+	tm_free(ctl->tm_p_lvl_drop_profiles);
+	tm_free(ctl->tm_wred_q_lvl_curves);
+	tm_free(ctl->tm_wred_a_lvl_curves);
+	tm_free(ctl->tm_wred_b_lvl_curves);
+	for (i = 0; i < TM_WRED_COS; i++) {
+		tm_free(ctl->tm_wred_c_lvl_curves[i]);
+		tm_free(ctl->tm_wred_ports_curves_cos[i]);
+	}
+	tm_free(ctl->tm_wred_ports_curves);
+	tm_free(ctl->tm_port_sms_attr_pbase);
+	tm_free(ctl->tm_port_sms_attr_qmap_pars);
+	tm_glob_unlock(TM_ENV(ctl));
+
+
+	/* release TM lib handle */
+	tm_free(ctl);
+
+	return 0;
+}
+
+int tm_lib_init_hw_def(tm_handle hndl)
+{
+	return set_hw_register_db_default(hndl);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.h
new file mode 100644
index 0000000..bf82f17
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_ctl.h
@@ -0,0 +1,94 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef   	TM_CTL_H
+#define   	TM_CTL_H
+
+#include "tm_core_types.h"	 /* in order to define tm_handle */
+
+
+/** Initialize TM configuration library.
+ *
+ *   @param[in]		cProductName	Product Name.
+ *   @param[in]		hEnv			TM handle storage.
+ *   @param[out]	htm				Pointer to TM lib handle.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if any of handles is NULL.
+ *   @retval -EBADF if any of handles is invalid.
+ *   @retval -ENOMEM when out of memory space.
+ *
+ *   @retval TM_CONF_INVALID_PROD_NAME.
+ */
+int tm_lib_open(const char * cProductName, tm_handle hEnv, tm_handle *htm);
+
+
+/**
+ * @brief   Initiate TM related H/W resources.
+ *
+ * @param[in]    hndl    TM lib handle
+ *
+ * @return an integer return code.
+ * @retval zero on success.
+ * @retval -EINVAL if any of handles is NULL.
+ * @retval -EBADF if any of handles is invalid.
+ *
+ * @retval TM_HW_GEN_CONFIG_FAILED.
+ */
+int tm_lib_init_hw(tm_handle hndl);
+
+
+/** Close TM configuration library.
+ *
+ *   @param[in]		hndl		TM lib handle
+ *
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is an invalid handle.
+ */
+int tm_lib_close(tm_handle hndl);
+
+
+/**
+ * @brief   Initiate TM H/W resources to default.
+ *
+ * @param[in]    hndl    TM lib handle
+ *
+ * @return an integer return code.
+ * @retval zero on success.
+ * @retval -EINVAL if any of handles is NULL.
+ * @retval -EBADF if any of handles is invalid.
+ *
+ * @retval TM_HW_GEN_CONFIG_FAILED.
+ */
+int tm_lib_init_hw_def(tm_handle hndl);
+
+
+#endif   /* TM_CTL_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_defs.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_defs.h
new file mode 100644
index 0000000..ba8d596
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_defs.h
@@ -0,0 +1,461 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef	TM_DEFS_H
+#define	TM_DEFS_H
+
+#include "common/mv_sw_if.h"
+
+
+/** BW resolution in Kbits */
+#define TM_KBITS   1000
+
+/** Maximal MTU */
+#define TM_MAX_MTU	MV_MTU_MAX	/* 0x4000 */
+
+/*---------------- Constants definitions-------------*/
+
+/** Number of Linecards */
+#define TM_LC_NUM       10
+
+/** Round Trip Time */
+#define TM_RTT          200    /* milliseconds */
+
+/** Node Quantum Unit in units of 256 bytes */
+#define TM_NODE_QUANTUM_UNIT  256
+/** Port Quantum Unit in units of 64 bytes */
+#define TM_PORT_QUANTUM_UNIT  64
+
+/** No Drop  */
+#define TM_NO_DROP_PROFILE  0
+
+/** Infinite Shaping = 0xFFF (12 bits) * TM_FIXED_10_M_SHAPING_MAX_TOKEN */
+#define TM_MAX_SHAPING_BW	0x9FF6
+
+/* TM INVALID constants */
+/** 32 bit Invalid data indicator */
+#define TM_INVAL         0xFFFFFFFF
+/** 64 bit Invalid data indicator */
+#define TM_64BIT_INVAL   0xFFFFFFFFFFFFFFFFULL
+
+
+/* Status constants */
+/** Enable indicator */
+#define TM_ENABLE  1
+/** Disable indicator */
+#define TM_DISABLE 0
+
+
+/** Maximum Bandwidth (in Kbits/sec) */
+#define TM_MAX_BW 100000000 /* 100GBit/sec */
+
+enum {
+	/** Eligible function for dequeue disable (the node is not eligible)
+	*  - the last function in eligible function array - reserved for queues and nodes**/
+	TM_ELIG_DEQ_DISABLE = 63,
+	/** The size of  eligible functions array  **/
+};
+
+#define FIXED_PRIORITY		0
+#define MINTB_SHAPING		1
+#define MINMAXTB_SHAPING	2
+
+#define PRIO_0		0
+#define PRIO_1		1
+#define PRIO_2		2
+#define PRIO_3		3
+#define PRIO_4		4
+#define PRIO_5		5
+#define PRIO_6		6
+#define PRIO_7		7
+#define PRIO_P		8
+
+#define ENCODE_ELIGIBLE_FUN(type, prio)				(type * 10 + prio)
+#define DECODE_ELIGIBLE_FUN(elig_fun, type, prio)	do { type = elig_fun / 10 ; prio = elig_fun % 10; } while (0)
+
+#define IS_VALID_Q_TYPE_PRIO(type, prio)			((type <= MINMAXTB_SHAPING) && (prio <= PRIO_7))
+#define IS_VALID_N_TYPE_PRIO(type, prio)			((type <= MINMAXTB_SHAPING) && (prio <= PRIO_P))
+
+
+
+
+enum elig_func_node {
+	/** Eligible function priority 0 **/
+	TM_ELIG_N_FIXED_P0 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_0),
+	/** Eligible function priority 1 **/
+	TM_ELIG_N_FIXED_P1 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_1),
+	/** Eligible function priority 2 **/
+	TM_ELIG_N_FIXED_P2 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_2),
+	/** Eligible function priority 3 **/
+	TM_ELIG_N_FIXED_P3 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_3),
+	/** Eligible function priority 4 **/
+	TM_ELIG_N_FIXED_P4 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_4),
+	/** Eligible function priority 5 **/
+	TM_ELIG_N_FIXED_P5 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_5),
+	/** Eligible function priority 6 **/
+	TM_ELIG_N_FIXED_P6 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_6),
+	/** Eligible function priority 7 **/
+	TM_ELIG_N_FIXED_P7 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_7),
+	/** Eligible function priority propagated **/
+	TM_ELIG_N_FIXED_PP = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_P),
+
+	/** Eligible function min shaping priority 0 **/
+	TM_ELIG_N_MIN_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_0),
+	/** Eligible function min shaping priority 1 **/
+	TM_ELIG_N_MIN_SHP_P1 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_1),
+	/** Eligible function min shaping priority 2 **/
+	TM_ELIG_N_MIN_SHP_P2 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_2),
+	/** Eligible function min shaping priority 3 **/
+	TM_ELIG_N_MIN_SHP_P3 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_3),
+	/** Eligible function min shaping priority 4 **/
+	TM_ELIG_N_MIN_SHP_P4 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_4),
+	/** Eligible function min shaping priority 5 **/
+	TM_ELIG_N_MIN_SHP_P5 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_5),
+	/** Eligible function min shaping priority 6 **/
+	TM_ELIG_N_MIN_SHP_P6 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_6),
+	/** Eligible function min shaping priority 7 **/
+	TM_ELIG_N_MIN_SHP_P7 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_7),
+	/** Eligible function min shaping priority propagated **/
+	TM_ELIG_N_MIN_SHP_PP = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_P),
+
+	/** Eligible function min shaping priority 0, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P0_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_0),
+	/** Eligible function min shaping priority 1, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P1_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_1),
+	/** Eligible function min shaping priority 2, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P2_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_2),
+	/** Eligible function min shaping priority 3, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P3_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_3),
+	/** Eligible function min shaping priority 4, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P4_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_4),
+	/** Eligible function min shaping priority 5, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P5_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_5),
+	/** Eligible function min shaping priority 6, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P6_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_6),
+	/** Eligible function min shaping priority 7, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_P7_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_7),
+	/** Eligible function min shaping priority propagated, max shaping priority 0 **/
+	TM_ELIG_N_SHP_MIN_SHP_PP_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_P),
+
+	TM_ELIG_N_DEFAULT = TM_ELIG_N_FIXED_P0
+
+
+};
+
+
+/** Eligible functions for queue nodes enumerator */
+enum elig_func_queue {
+	/** Eligible function priority 0 **/
+	TM_ELIG_Q_FIXED_P0 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_0),
+	/** Eligible function priority 1 **/
+	TM_ELIG_Q_FIXED_P1 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_1),
+	/** Eligible function priority 2 **/
+	TM_ELIG_Q_FIXED_P2 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_2),
+	/** Eligible function priority 3 **/
+	TM_ELIG_Q_FIXED_P3 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_3),
+	/** Eligible function priority 4 **/
+	TM_ELIG_Q_FIXED_P4 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_4),
+	/** Eligible function priority 5 **/
+	TM_ELIG_Q_FIXED_P5 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_5),
+	/** Eligible function priority 6 **/
+	TM_ELIG_Q_FIXED_P6 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_6),
+	/** Eligible function priority 7 **/
+	TM_ELIG_Q_FIXED_P7 = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_7),
+
+	/** Eligible function min shaping priority 0 **/
+	TM_ELIG_Q_MIN_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_0),
+	/** Eligible function min shaping priority 1 **/
+	TM_ELIG_Q_MIN_SHP_P1 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_1),
+	/** Eligible function min shaping priority 2 **/
+	TM_ELIG_Q_MIN_SHP_P2 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_2),
+	/** Eligible function min shaping priority 3 **/
+	TM_ELIG_Q_MIN_SHP_P3 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_3),
+	/** Eligible function min shaping priority 4 **/
+	TM_ELIG_Q_MIN_SHP_P4 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_4),
+	/** Eligible function min shaping priority 5 **/
+	TM_ELIG_Q_MIN_SHP_P5 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_5),
+	/** Eligible function min shaping priority 6 **/
+	TM_ELIG_Q_MIN_SHP_P6 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_6),
+	/** Eligible function min shaping priority 7 **/
+	TM_ELIG_Q_MIN_SHP_P7 = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_7),
+
+	/** Eligible function min shaping priority 0, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P0_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_0),
+	/** Eligible function min shaping priority 1, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P1_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_1),
+	/** Eligible function min shaping priority 2, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P2_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_2),
+	/** Eligible function min shaping priority 3, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P3_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_3),
+	/** Eligible function min shaping priority 4, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P4_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_4),
+	/** Eligible function min shaping priority 5, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P5_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_5),
+	/** Eligible function min shaping priority 6, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P6_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_6),
+	/** Eligible function min shaping priority 7, max shaping priority 0 **/
+	TM_ELIG_Q_SHP_MIN_SHP_P7_MAX_SHP_P0 = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_7),
+
+	TM_ELIG_Q_DEFAULT = TM_ELIG_Q_FIXED_P0
+};
+
+/*---------------------- Enumerated Types---------------- */
+
+/** TM levels */
+enum tm_level {
+	Q_LEVEL = 0, /**< Queue Level */
+	A_LEVEL,     /**< A-nodes Level */
+	B_LEVEL,     /**< B-nodes Level */
+	C_LEVEL,     /**< C-nodes Level */
+	P_LEVEL      /**< Ports Level */
+};
+
+/** Port's physical bandwidth */
+enum tm_port_bw {
+	TM_1G_PORT = 0, /**< 1G bit/sec */
+	TM_2HG_PORT,    /**< 2.5G bit/sec*/
+	TM_10G_PORT,    /**< 10G bit/sec */
+	TM_40G_PORT,    /**< 40G bit/sec */
+	TM_50G_PORT,    /**< 50G bit/sec */
+	TM_100G_PORT    /**< 100G bit/sec */
+};
+
+#ifdef MV_QMTM_NOT_NSS
+/** Token bucket usage */
+enum token_bucket {
+	MIN_TOKEN_BUCKET = 0, /**< Use Min token bucket */
+	MAX_TOKEN_BUCKET      /**< Use Max tiken bucket */
+};
+
+/** TM Port Basic Periodic update rate */
+enum tm_port_update_rate {
+	TM_PORT_RATE_1M = 1, /**< 1MHz */
+	TM_MIN_PORT_RATE = TM_PORT_RATE_1M, /**< Port Minimum update rate */
+	TM_PORT_RATE_2M,     /**< 2MHz */
+	TM_PORT_RATE_3M,     /**< 3MHz */
+	TM_PORT_RATE_4M,     /**< 4MHz */
+	TM_PORT_RATE_5M,     /**< 5MHz */
+	TM_MAX_PORT_RATE = TM_PORT_RATE_5M  /**< Port Maximum update rate */
+};
+#endif
+/** Drop WRED/CATD mode */
+enum tm_drop_mode {
+	WRED = 0, /**< WRED */
+	CATD,     /**< Color Aware TD */
+	DISABLED  /**< Both modes are disabled */
+};
+
+/** TM2TM channel */
+enum tm2tm_channel {
+	TM2TM_NODE_CH = 0,
+	TM2TM_PORT_CH
+};
+
+#ifdef MV_QMTM_NOT_NSS
+/** TM2TM Port/Node channel's mode */
+enum tm2tm_mode {
+TM2TM_WRED = 0,
+TM2TM_BP
+};
+#endif
+/** Number of colors */
+enum tm_color_num {
+	TM_1_COLORS = 0,
+	TM_2_COLORS,
+	TM_3_COLORS
+};
+
+/** Drop Probability Source */
+enum tm_dp_source {
+	TM_AQL = 0,
+	TM_QL
+};
+
+/*------------------- Global Paramteres Data structures-----------------*/
+
+/** Drop configuration profile */
+struct tm_drop_profile_params {
+	uint32_t wred_catd_bw;     /**< WRED/Color Aware TD BW in Kbits/sec */
+	uint32_t cbtd_bw;          /**< Color Blind TD BW in Kbits/sec */
+	uint32_t cbtd_rtt_ratio;   /**< Color Blind TD BW ratio from RTT in % */
+	uint8_t aql_exp;           /**< Forget factor exponent */
+
+	enum tm_drop_mode wred_catd_mode;   /**< Color Aware TD/WRED */
+	uint8_t curve_id[3];       /**< RED curve index per color[0..2] */
+	uint8_t dp_ratio[3];       /**< DP ratio per color[0..2] */
+	uint16_t min_th[3];        /**< Min Threshold ratio from RTT in % per color */
+	uint16_t max_th[3];        /**< Max Threshold ratio from RTT in % per color */
+};
+
+/*----------------- Nodes Parameters Data Structures---------------*/
+/* Note: only drop mode 0 is supported in current version.
+ *  Drop profile reference fields are present only for queues and
+ *  ports
+*/
+
+/** Queue Parameters Data Structure */
+struct tm_queue_params {
+	uint16_t quantum;              /**< Queue DWRR Quantum in TM_NODE_QUANTUM_UNIT */
+	uint8_t wred_profile_ref;     /**< Index of Drop profile */
+	uint8_t elig_prio_func_ptr;    /**< Eligible Priority Function pointer */
+};
+
+
+/** A-Node Parameters Data Structure */
+struct tm_a_node_params {
+	uint16_t quantum;              /**< DWRR Quantum in TM_NODE_QUANTUM_UNIT */
+	uint8_t dwrr_priority[8];      /**< DWRR Priority for Queue Scheduling */
+	uint8_t wred_profile_ref;     /**< Index of Drop profile */
+	uint8_t elig_prio_func_ptr;    /**< Eligible Priority Function pointer */
+	uint32_t num_of_children;      /**< Number of children nodes */
+};
+
+
+/** B-Node Parameters Data Structure */
+struct tm_b_node_params {
+	uint16_t quantum;              /**< DWRR Quantum in TM_NODE_QUANTUM_UNIT */
+	uint8_t dwrr_priority[8];      /**< DWRR Priority for A-Node Scheduling */
+	uint8_t wred_profile_ref;      /**< Index of Drop profile */
+	uint8_t elig_prio_func_ptr;    /**< Eligible Priority Function pointer */
+	uint16_t num_of_children;      /**< Number of children nodes */
+};
+
+
+/** C-Node Parameters Data Structure */
+struct tm_c_node_params {
+	uint16_t quantum;              /**< DWRR Quantum in TM_NODE_QUANTUM_UNIT */
+	uint8_t dwrr_priority[8];      /**< DWRR Priority for B-Node Scheduling */
+	uint8_t wred_cos;              /**< C-node CoS bit map for WRED */
+	uint8_t wred_profile_ref[8];   /**< Index of Drop profile per CoS */
+	uint8_t elig_prio_func_ptr;    /**< Eligible Priority Function pointer */
+	uint16_t num_of_children;      /**< Number of children nodes */
+};
+
+
+/** Port Parameters Data Structure */
+struct tm_port_params {
+#ifdef MV_QMTM_NSS_A0
+	uint16_t quantum[8];           /**< DWRR Quantum for each instance in TM_PORT_QUANTUM_UNIT */
+#endif
+	uint8_t dwrr_priority[8];      /**< DWRR Priority for C-Node Scheduling */
+	uint8_t wred_profile_ref;      /**< Index of Drop profile */
+	uint8_t elig_prio_func_ptr;    /**< Eligible Priority Function pointer */
+	uint16_t num_of_children;      /**< Number of children nodes */
+};
+
+struct tm_port_drop_per_cos {
+	uint8_t wred_cos;              /**< Port CoS bit map for WRED */
+	uint8_t wred_profile_ref[8];   /**< Index of Drop profile per CoS */
+};
+
+
+/** Port status data structure */
+struct tm_port_status {
+	uint32_t max_bucket_level;  /**< Maximal Shaper Bucket level */
+	uint32_t min_bucket_level;  /**< Minimal Shaper Bucket level */
+	uint32_t deficit[8];        /**< DWRR Deficit per instance */
+};
+
+
+/** Node status data structure */
+struct tm_node_status {
+	uint32_t max_bucket_level;  /**< Maximal Shaper Bucket level */
+	uint32_t min_bucket_level;  /**< Minimal Shaper Bucket level */
+	uint32_t deficit;           /**< DWRR Deficit */
+};
+
+/** QMR Packet Statistics data structure */
+/*
+struct tm_qmr_pkt_statistics {
+	uint64_t num_pkts_to_unins_queue;   *//**< Pkts from SMS that have arrived
+											* to not installed Queue *//*
+};
+
+
+*//** RCB Packet Statistics data structure *//*
+struct tm_rcb_pkt_statistics {
+	uint64_t num_pkts_to_sms;            *//**< Non-error pkts that are passed to SMS *//*
+	uint64_t num_crc_err_pkts_to_sms;    *//**< Pkts with CRC error *//*
+	uint64_t num_errs_from_sms_to_dram;  *//**< Pkts with error from SMS that has
+										* been written to DRAM *//*
+};
+*/
+
+/** TM Blocks Error Information */
+struct tm_error_info {
+	uint16_t error_counter; /**< TM Block Error counter */
+	uint16_t exception_counter; /**< TM Block Exception Counter */
+};
+
+
+/** TM2TM External Headers */
+struct tm_ext_hdr {
+	uint8_t size;               /**< only fixed values - 3, 7, 11 or 15 */
+	uint8_t	content[32];		/**< header data */
+};
+
+/** TM2TM Control Packet Structure */
+struct tm_ctrl_pkt_str {
+	uint8_t ports;	/**< Ports */
+	uint8_t nodes;	/**< Nodes */
+};
+
+/** TM2TM Delta Range Mapping to Priority */
+struct tm_delta_range {
+	uint8_t upper_range0;	/**< Range 0 */
+	uint8_t upper_range1;	/**< Range 1 */
+	uint8_t upper_range2;	/**< Range 2 */
+};
+
+/** Reshuffling index/range change structure */
+struct tm_tree_change {
+	uint8_t type;   /**< Type of change: index - TM_ENABLE, range - TM_DISABLE */
+	uint32_t index; /**< Index of changed parent node */
+	uint32_t old_index;   /**< Old index/range */
+	uint32_t new_index;   /**< New index/range */
+	struct tm_tree_change *next; /**< Pointer to the next change */
+};
+
+/** Eligible Priority Function Data structures */
+struct tm_elig_prio_func_out {
+	uint8_t max_tb;             /**< Use Max Token Bucket   */
+	uint8_t min_tb;             /**< Use Min Token Bucket   */
+	uint8_t prop_prio;          /**< Propagated priority    */
+	uint8_t sched_prio;         /**< Scheduling priority    */
+	uint8_t elig;               /**< Eligibility            */
+};
+
+/** Eligible Priority Function storage */
+union tm_elig_prio_func {
+	struct tm_elig_prio_func_out queue_elig_prio_func[4];		/**< Eligible Priority Functions for queues   */
+	struct tm_elig_prio_func_out node_elig_prio_func[8][4];		/**< Eligible Priority Functions for intermediate nodes   */
+};
+
+
+#endif   /* TM_DEFS_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.c
new file mode 100644
index 0000000..47aff39
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.c
@@ -0,0 +1,2901 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_drop.h"
+#include "tm_errcodes.h"
+
+#include "rm_internal_types.h"
+#include "rm_alloc.h"
+#include "rm_free.h"
+#include "rm_list.h"
+#include "rm_status.h"
+
+#include "set_hw_registers.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_os_interface.h"
+#include "tm_locking_interface.h"
+#include "tm_hw_configuration_interface.h"
+
+
+static int tm_round_int(uint32_t val, uint32_t divider)
+{
+	return (val * 100 + 50) / (divider * 100);
+}
+
+
+/**
+ */
+int update_curves_at_level(tm_handle hndl,
+						enum tm_level level,
+						uint8_t curve_ind,
+						uint8_t max_prob,
+						uint8_t old_mode)
+{
+	int i;
+	uint8_t j;
+	uint8_t k;
+	uint8_t status;
+	struct tm_wred_curve *curve = NULL;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (level) {
+	case Q_LEVEL:
+		for (j = 0; j < TM_NUM_WRED_QUEUE_CURVES; j++) {
+			rc = rm_wred_queue_curve_status(rm, j, &status);
+			if (rc)
+				return rc;
+
+			if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+				break;
+
+			curve = &(ctl->tm_wred_q_lvl_curves[j]);
+			for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+				curve->prob[i] =
+					(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+
+			/* Download to HW */
+			rc = set_hw_queues_wred_curve(ctl, j);
+			if (rc)
+				return rc;
+		}
+		break;
+	case A_LEVEL:
+		for (j = 0; j < TM_NUM_WRED_A_NODE_CURVES; j++) {
+			rc = rm_wred_a_node_curve_status(rm, j, &status);
+			if (rc)
+				return rc;
+			if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+				break;
+
+			curve = &(ctl->tm_wred_a_lvl_curves[j]);
+			for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+				curve->prob[i] =
+					(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+
+			/* Download to HW */
+			rc = set_hw_a_nodes_wred_curve(ctl, j);
+			if (rc)
+				return rc;
+		}
+		break;
+	case B_LEVEL:
+		for (j = 0; j < TM_NUM_WRED_B_NODE_CURVES; j++) {
+			rc = rm_wred_b_node_curve_status(rm, j, &status);
+			if (rc)
+				return rc;
+			if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+				break;
+
+			curve = &(ctl->tm_wred_b_lvl_curves[j]);
+			for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+				curve->prob[i] =
+					(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+			/* Download to HW */
+			rc = set_hw_b_nodes_wred_curve(ctl, j);
+			if (rc)
+				return rc;
+		}
+		break;
+	case C_LEVEL:
+		for (k = 0; k < TM_WRED_COS; k++) {
+			for (j = 0; j < TM_NUM_WRED_C_NODE_CURVES; j++) {
+				rc = rm_wred_c_node_curve_status(rm, k, j, &status);
+				if (rc)
+					return rc;
+				if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+					break;
+
+				curve = &(ctl->tm_wred_c_lvl_curves[k][j]);
+				for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+					curve->prob[i] =
+						(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+				/* Download to HW */
+				rc = set_hw_c_nodes_wred_curve(ctl, k, j);
+				if (rc)
+					return rc;
+			}
+		}
+		break;
+	case P_LEVEL:
+		for (j = 0; j < TM_NUM_WRED_PORT_CURVES; j++) {
+			rc = rm_wred_port_curve_status(rm, j, &status);
+			if (rc)
+				return rc;
+			if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+				break;
+
+			curve = &(ctl->tm_wred_ports_curves[j]);
+			for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+				curve->prob[i] =
+					(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+			/* Download to HW */
+			rc = set_hw_ports_wred_curve(ctl, j);
+			if (rc)
+				return rc;
+		}
+		for (k = 0; k < TM_WRED_COS; k++) {
+			for (j = 0; j < TM_NUM_WRED_PORT_CURVES; j++) {
+				rc = rm_wred_port_curve_status_cos(rm, k, j, &status);
+				if (rc)
+					return rc;
+				if ((status == TM_DISABLE) || (j == curve_ind)) /* end */
+					break;
+
+				curve = &(ctl->tm_wred_ports_curves_cos[k][j]);
+				for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+					curve->prob[i] =
+						(uint8_t)tm_round_int(curve->prob[i]*old_mode, max_prob);
+				/* Download to HW */
+				rc = set_hw_ports_wred_curve_cos(ctl, k, j);
+				if (rc)
+					return rc;
+			}
+		}
+		break;
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_wred_curve(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint8_t *prob,
+						uint8_t *curve_index)
+{
+
+	struct tm_wred_curve *curve;
+	uint8_t max_prob = 0;
+	uint8_t old_mode = 0;
+	uint8_t res;
+	uint8_t exp;
+
+	int i;
+	int rc;
+	int curve_ind = (int)TM_INVAL;
+	uint8_t flag_mode_change = TM_DISABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EADDRNOTAVAIL;
+		goto out;
+	}
+
+	max_prob = prob[0];
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++) {
+		if (prob[i] > 100) {
+			rc = -EPERM;
+			goto out;
+		}
+		if (prob[i] > max_prob)
+			max_prob = prob[i];
+	}
+
+
+	/* find free curve */
+	switch (level) {
+	case Q_LEVEL:
+		curve_ind = rm_find_free_wred_queue_curve(rm);
+		break;
+	case A_LEVEL:
+		curve_ind = rm_find_free_wred_a_node_curve(rm);
+		break;
+	case B_LEVEL:
+		curve_ind = rm_find_free_wred_b_node_curve(rm);
+		break;
+	case C_LEVEL:
+		if (cos >= TM_WRED_COS) {
+			rc = -EDOM;
+			goto out;
+		}
+		curve_ind = rm_find_free_wred_c_node_curve(rm, cos);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL)
+			curve_ind = rm_find_free_wred_port_curve(rm);
+		else {
+			if (cos >= TM_WRED_COS) {
+				rc = -EDOM;
+				goto out;
+			}
+			curve_ind = rm_find_free_wred_port_curve_cos(rm, cos);
+		}
+		break;
+	default:
+		break;
+	}
+
+	if (curve_ind < 0) {
+		rc = -ENOSPC;
+		goto out;
+	} else
+		*curve_index = (uint8_t)curve_ind;
+
+
+	/* Check that max_p doesn't exceed dp_max mode. If - yes, update
+	 * all existing curves at this level and for this color according to the new mode. */
+	switch (ctl->dp_unit.local[level].max_p_mode[0]) {
+	case TM_MAX_PROB_100: /* 100% */
+		max_prob = 100;
+		break;
+	case TM_MAX_PROB_50: /* 50% */
+		if (max_prob > 50) {
+			max_prob = 100;
+			old_mode = 50;
+			for (i = 0; i < 3; i++)
+				ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_100;
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			max_prob = 50;
+		break;
+	case TM_MAX_PROB_25: /* 25% */
+		if (max_prob > 25) {
+			old_mode = 25;
+			if (max_prob <= 50) {
+				max_prob = 50;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_50;
+			} else {
+				max_prob = 100;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_100;
+			}
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			max_prob = 25;
+		break;
+	case TM_MAX_PROB_12H: /* 12.5% */
+		if (max_prob > 12) {
+			old_mode = 12;
+			if (max_prob <= 25) {
+				max_prob = 25;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_25;
+			} else {
+				if (max_prob <= 50) {
+					max_prob = 50;
+					for (i = 0; i < 3; i++)
+						ctl->dp_unit.local[level].max_p_mode[i] =
+							TM_MAX_PROB_50;
+				} else {
+					max_prob = 100;
+					for (i = 0; i < 3; i++)
+						ctl->dp_unit.local[level].max_p_mode[i] =
+							TM_MAX_PROB_100;
+				}
+			}
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			max_prob = 12;
+		break;
+	}
+
+	if (rc) {
+		rc = TM_HW_WRED_CURVE_FAILED;
+		goto out;
+	}
+
+	if (flag_mode_change == TM_ENABLE) {
+		/* Update all the rest of curves at this level */
+		rc = update_curves_at_level(ctl, level, (uint8_t)curve_ind, max_prob, old_mode);
+		if (rc) {
+			rc = TM_HW_WRED_CURVE_FAILED;
+			goto out;
+		}
+	}
+
+	/* Calculate prob values of current curve */
+	res = ctl->dp_unit.local[level].resolution;
+	exp = (uint8_t)((1 << res) - 1);
+
+	switch (level) {
+	case Q_LEVEL:
+		/* update SW image */
+		curve = &(ctl->tm_wred_q_lvl_curves[*curve_index]);
+		for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+			curve->prob[i] = (uint8_t)tm_round_int(prob[i] * exp, max_prob);
+		/* update HW */
+		rc = set_hw_queues_wred_curve(hndl, *curve_index);
+		break;
+	case A_LEVEL:
+		/* update SW image */
+		curve = &(ctl->tm_wred_a_lvl_curves[*curve_index]);
+		for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+			curve->prob[i] = (uint8_t)tm_round_int(prob[i] * exp, max_prob);
+		/* update HW */
+		rc = set_hw_a_nodes_wred_curve(hndl, *curve_index);
+		break;
+	case B_LEVEL:
+		/* update SW image */
+		curve = &(ctl->tm_wred_b_lvl_curves[*curve_index]);
+		for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+			curve->prob[i] = (uint8_t)tm_round_int(prob[i] * exp, max_prob);
+		/* update HW */
+		rc = set_hw_b_nodes_wred_curve(hndl, *curve_index);
+		break;
+	case C_LEVEL:
+		/* update SW image */
+		curve = &(ctl->tm_wred_c_lvl_curves[cos][*curve_index]);
+		for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+			curve->prob[i] = (uint8_t)tm_round_int(prob[i] * exp, max_prob);
+		/* update HW */
+		rc = set_hw_c_nodes_wred_curve(hndl, cos, *curve_index);
+		break;
+	case P_LEVEL:
+		/* update SW image */
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			curve = &(ctl->tm_wred_ports_curves[*curve_index]);
+		else
+			curve = &(ctl->tm_wred_ports_curves_cos[cos][*curve_index]);
+		for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+			curve->prob[i] = (uint8_t)tm_round_int(prob[i] * exp, max_prob);
+		/* update HW */
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			rc = set_hw_ports_wred_curve(hndl, *curve_index);
+		else
+			rc = set_hw_ports_wred_curve_cos(hndl, cos, *curve_index);
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_WRED_CURVE_FAILED;
+out:
+	if (rc) {
+		switch (level) {
+		case Q_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_queue_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_a_lvl_curves,
+										*curve_index);
+			break;
+		case A_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_a_node_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_a_lvl_curves,
+										*curve_index);
+			break;
+		case B_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_b_node_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_b_lvl_curves,
+										*curve_index);
+			break;
+		case C_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_c_node_curve(rm, cos, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_c_lvl_curves[cos],
+										*curve_index);
+			break;
+		case P_LEVEL:
+			if (curve_ind >= 0) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rm_free_wred_port_curve(rm, *curve_index);
+				else
+					rm_free_wred_port_curve_cos(rm, cos, *curve_index);
+			}
+			if (rc == TM_HW_WRED_CURVE_FAILED) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					set_sw_wred_curve_default(ctl->tm_wred_ports_curves, *curve_index);
+				else
+					set_sw_wred_curve_default(ctl->tm_wred_ports_curves_cos[cos], *curve_index);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_create_wred_traditional_curve(tm_handle hndl,
+									enum tm_level level,
+									uint8_t cos,
+									uint8_t mp,
+									uint8_t *curve_index)
+{
+	uint8_t res;
+	uint8_t exp;
+	int i;
+	int rc;
+	struct tm_wred_curve *curve = NULL;
+	int curve_ind = (int)TM_INVAL;
+	uint8_t mp_scaled = 0;
+	uint8_t max_prob = 0;
+	uint8_t old_mode = 0;
+	uint8_t flag_mode_change = TM_DISABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters */
+	if (level > P_LEVEL) {
+		rc = -EADDRNOTAVAIL;
+		goto out;
+	}
+
+	if ((mp == 0) || (mp > 100)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	/* find free curve */
+	switch (level) {
+	case Q_LEVEL:
+		curve_ind = rm_find_free_wred_queue_curve(rm);
+		break;
+	case A_LEVEL:
+		curve_ind = rm_find_free_wred_a_node_curve(rm);
+		break;
+	case B_LEVEL:
+		curve_ind = rm_find_free_wred_b_node_curve(rm);
+		break;
+	case C_LEVEL:
+		if (cos >= TM_WRED_COS) {
+			rc = -EDOM;
+			goto out;
+		}
+		curve_ind = rm_find_free_wred_c_node_curve(rm, cos);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL)
+			curve_ind = rm_find_free_wred_port_curve(rm);
+		else {
+			if (cos >= TM_WRED_COS) {
+				rc = -EDOM;
+				goto out;
+			}
+			curve_ind = rm_find_free_wred_port_curve_cos(rm, cos);
+		}
+		break;
+	default:
+		break;
+	}
+	if (curve_ind < 0) {
+		rc = -ENOSPC;
+		goto out;
+	} else
+		*curve_index = (uint8_t)curve_ind;
+
+	res = ctl->dp_unit.local[level].resolution;
+	exp = (uint8_t)((1 << res) - 1);
+
+	switch (ctl->dp_unit.local[level].max_p_mode[0]) {
+	case TM_MAX_PROB_100: /* 100% */
+		mp_scaled = (uint8_t)tm_round_int(mp*exp, 100);
+		max_prob = 100;
+		break;
+	case TM_MAX_PROB_50: /* 50% */
+		if (mp > 50) {
+			mp_scaled = (uint8_t)tm_round_int(mp*exp, 100);
+			old_mode = 50;
+			max_prob = 100;
+			for (i = 0; i < 3; i++)
+				ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_100;
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			mp_scaled = (uint8_t)tm_round_int(mp*exp, 50);
+		break;
+	case TM_MAX_PROB_25: /* 25% */
+		if (mp > 25) {
+			old_mode = 25;
+			if (mp <= 50) {
+				mp_scaled = (uint8_t)tm_round_int(mp*exp, 50);
+				max_prob = 50;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_50;
+			} else {
+				mp_scaled = (uint8_t)tm_round_int(mp*exp, 100);
+				max_prob = 100;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_100;
+			}
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			mp_scaled = (uint8_t)tm_round_int(mp*exp, 25);
+		break;
+	case TM_MAX_PROB_12H: /* 12.5% */
+		if (mp > 12) {
+			old_mode = 12;
+			if (mp <= 25) {
+				mp_scaled = (uint8_t)tm_round_int(mp*exp, 25);
+				max_prob = 25;
+				for (i = 0; i < 3; i++)
+					ctl->dp_unit.local[level].max_p_mode[i] = TM_MAX_PROB_25;
+			} else {
+				if (mp <= 50) {
+					mp_scaled = (uint8_t)tm_round_int(mp*exp, 50);
+					max_prob = 50;
+					for (i = 0; i < 3; i++)
+						ctl->dp_unit.local[level].max_p_mode[i] =
+							TM_MAX_PROB_50;
+				} else {
+					mp_scaled = (uint8_t)tm_round_int(mp*exp, 100);
+					max_prob = 100;
+					for (i = 0; i < 3; i++)
+						ctl->dp_unit.local[level].max_p_mode[i] =
+							TM_MAX_PROB_100;
+				}
+			}
+			rc = set_hw_max_dp_mode(ctl);
+
+			/* Update all the rest of curves at this level */
+			flag_mode_change = TM_ENABLE;
+		} else
+			mp_scaled = (uint8_t)tm_round_int(mp*exp, 12);
+		break;
+	}
+	if (rc) {
+		rc = TM_HW_WRED_CURVE_FAILED;
+		goto out;
+	}
+
+
+	if (flag_mode_change == TM_ENABLE) {
+		/* Update all the rest of curves at this level */
+		rc = update_curves_at_level(ctl, level, (uint8_t)curve_ind, max_prob, old_mode);
+		if (rc) {
+			rc = TM_HW_WRED_CURVE_FAILED;
+			goto out;
+		}
+	}
+
+
+	/* update SW image */
+	switch (level) {
+	case Q_LEVEL:
+		curve = &(ctl->tm_wred_q_lvl_curves[*curve_index]);
+		break;
+	case A_LEVEL:
+		curve = &(ctl->tm_wred_a_lvl_curves[*curve_index]);
+		break;
+	case B_LEVEL:
+		curve = &(ctl->tm_wred_b_lvl_curves[*curve_index]);
+		break;
+	case C_LEVEL:
+		curve = &(ctl->tm_wred_c_lvl_curves[cos][*curve_index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			curve = &(ctl->tm_wred_ports_curves[*curve_index]);
+		else
+			curve = &(ctl->tm_wred_ports_curves_cos[cos][*curve_index]);
+		break;
+	default:
+		break;
+	}
+
+	/* Calculate drop probability for each of 32 points */
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+		curve->prob[i] = (uint8_t)tm_round_int((uint8_t)mp_scaled * (i+1), (uint8_t)TM_WRED_CURVE_POINTS);
+
+
+	/* update HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queues_wred_curve(hndl, *curve_index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_wred_curve(hndl, *curve_index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_wred_curve(hndl, *curve_index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_wred_curve(hndl, cos, *curve_index);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			rc = set_hw_ports_wred_curve(hndl, *curve_index);
+		else
+			rc = set_hw_ports_wred_curve_cos(hndl, cos, *curve_index);
+		break;
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_WRED_CURVE_FAILED;
+out:
+	if (rc) {
+		switch (level) {
+		case Q_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_queue_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_q_lvl_curves,
+										*curve_index);
+			break;
+		case A_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_a_node_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_a_lvl_curves,
+										*curve_index);
+			break;
+		case B_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_b_node_curve(rm, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_b_lvl_curves,
+										*curve_index);
+			break;
+		case C_LEVEL:
+			if (curve_ind >= 0)
+				rm_free_wred_c_node_curve(rm, cos, *curve_index);
+			if (rc == TM_HW_WRED_CURVE_FAILED)
+				set_sw_wred_curve_default(ctl->tm_wred_c_lvl_curves[cos],
+										*curve_index);
+			break;
+		case P_LEVEL:
+			if (curve_ind >= 0) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rm_free_wred_port_curve(rm, *curve_index);
+				else
+					rm_free_wred_port_curve_cos(rm, cos, *curve_index);
+			}
+			if (rc == TM_HW_WRED_CURVE_FAILED) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					set_sw_wred_curve_default(ctl->tm_wred_ports_curves, *curve_index);
+				else
+					set_sw_wred_curve_default(ctl->tm_wred_ports_curves_cos[cos], *curve_index);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+int tm_create_wred_flat_curve(tm_handle hndl,
+									 enum tm_level level,
+									 uint8_t cos,
+									 uint8_t cp,
+									 uint8_t *curve_index)
+{
+	uint8_t prob[32];
+	int i;
+	for (i = 0 ; i < 32 ; i++)
+		prob[i] = cp;
+	return tm_create_wred_curve(hndl, level, cos, prob, curve_index);
+}
+
+
+/**
+*/
+int tm_create_drop_profile(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						struct tm_drop_profile_params *profile,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile *node_profile;
+	int i;
+	int rc;
+	uint8_t status;
+	uint32_t td_threshold;
+	uint8_t exp;
+	uint32_t max_th;
+	uint32_t max_thresh_scaled = 0;
+	uint32_t min_th;
+	uint32_t min_thresh_scaled = 0;
+	uint16_t ratio;
+	uint32_t out_bw = profile->wred_catd_bw;
+	uint8_t color_num;
+	struct rm_list *list = NULL;
+	int prof_ind = (int)TM_INVAL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	color_num = ctl->dp_unit.local[level].color_num;
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	if (profile->wred_catd_bw > TM_MAX_BW) {
+		rc = -EACCES;
+		goto out;
+	}
+
+	if (profile->cbtd_bw > TM_MAX_BW) {
+		rc = -EACCES;
+		goto out;
+	}
+
+	if (profile->aql_exp > 0xF) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	if ((profile->wred_catd_mode != WRED) &&
+		(profile->wred_catd_mode != CATD) &&
+		(profile->wred_catd_mode != DISABLED)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	if (profile->wred_catd_bw == 0) {
+		if (profile->wred_catd_mode != DISABLED) {
+			rc = -ENODATA;
+			goto out;
+		}
+	}
+
+	if (profile->wred_catd_mode == WRED) {
+		for (i = 0; i < color_num; i++) {
+			if (profile->max_th[i] < profile->min_th[i]) {
+				rc = -ERANGE;
+				goto out;
+			}
+
+			if (i == 2) {
+				if (profile->dp_ratio[i] > 16) { /* 4 bits */
+					rc = -ERANGE;
+					goto out;
+				}
+			} else {
+				if (profile->dp_ratio[i] > 63) { /* 6 bits */
+					rc = -ERANGE;
+					goto out;
+				}
+			}
+		}
+	}
+
+	for (i = 0; i < color_num; i++) {
+		/* check if the assigned WRED curve exists */
+		switch (level) {
+		case Q_LEVEL:
+			rc = rm_wred_queue_curve_status(rm, profile->curve_id[i],
+											&status);
+			break;
+		case A_LEVEL:
+			rc = rm_wred_a_node_curve_status(rm, profile->curve_id[i],
+											 &status);
+			break;
+		case B_LEVEL:
+			rc = rm_wred_b_node_curve_status(rm, profile->curve_id[i],
+											 &status);
+			break;
+		case C_LEVEL:
+			rc = rm_wred_c_node_curve_status(rm, cos, profile->curve_id[i],
+											 &status);
+			break;
+		case P_LEVEL:
+			if (cos == (uint8_t)TM_INVAL) /* Global Port */
+				rc = rm_wred_port_curve_status(rm, profile->curve_id[i],
+											&status);
+			else
+				rc = rm_wred_port_curve_status_cos(rm, cos, profile->curve_id[i],
+										&status);
+			break;
+		default:
+			break;
+		}
+
+		/* if referenced WRED curve doesn't exist */
+		if ((rc < 0) || (status != RM_TRUE)) {
+			rc = -ENODEV;
+			goto out;
+		}
+	}
+
+	/* find free profile */
+	switch (level) {
+	case Q_LEVEL:
+		prof_ind = rm_find_free_queue_drop_profile(rm);
+		break;
+	case A_LEVEL:
+		prof_ind = rm_find_free_a_node_drop_profile(rm);
+		break;
+	case B_LEVEL:
+		prof_ind = rm_find_free_b_node_drop_profile(rm);
+		break;
+	case C_LEVEL:
+		prof_ind = rm_find_free_c_node_drop_profile(rm, cos);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			prof_ind = rm_find_free_port_drop_profile(rm);
+		else
+			prof_ind = rm_find_free_port_drop_profile_cos(rm, cos);
+		rc = rm_list_create(rm, &list);
+		break;
+	default:
+		break;
+	}
+
+	if ((prof_ind < 0) || rc) {
+		rc = -ENOSPC;
+		goto out;
+	} else
+		*prof_index = prof_ind;
+
+	switch (level) {
+	case Q_LEVEL:
+		node_profile = &(ctl->tm_q_lvl_drop_profiles[*prof_index]);
+		break;
+	case A_LEVEL:
+		node_profile = &(ctl->tm_a_lvl_drop_profiles[*prof_index]);
+		break;
+	case B_LEVEL:
+		node_profile = &(ctl->tm_b_lvl_drop_profiles[*prof_index]);
+		break;
+	case C_LEVEL:
+		node_profile = &(ctl->tm_c_lvl_drop_profiles[cos][*prof_index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			node_profile = &(ctl->tm_p_lvl_drop_profiles[*prof_index]);
+		else
+			node_profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][*prof_index]);
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+		break;
+	}
+
+	/* update SW image */
+	for (i = 0; i < 3; i++) {
+		node_profile->min_th_sw[i] = profile->min_th[i];  /**< Min Threshold ratio from RTT in % per color */
+		node_profile->max_th_sw[i] = profile->max_th[i];  /**< Max Threshold ratio from RTT in % per color */
+	}
+
+	node_profile->use_list = list;
+
+	node_profile->out_bw = out_bw;
+	node_profile->aql_exp = profile->aql_exp;
+	if (profile->wred_catd_mode != DISABLED) {
+		if (profile->wred_catd_mode == WRED) {
+			node_profile->color_td_en = TM_DISABLE;
+			/* calculate min_th, scale_exp and scale_ratio for each color */
+			for (i = 0; i < color_num; i++) {
+				node_profile->curve_id[i].index = profile->curve_id[i];
+				max_th = profile->max_th[i];
+				min_th = profile->min_th[i];
+				/* find highest value for exp when max_thresh_scaled smaller from 1024 */
+				for (exp = 0; exp < 22; exp++) {
+					/* 64 = (8[byte]*16[burst]*100[%]*1000[msec])/(TM_KBITS*TM_RTT) */
+					max_thresh_scaled =
+						((uint8_t)max_th*(uint8_t)out_bw/(uint8_t)64)/(uint8_t)(1 << exp);
+					if (max_thresh_scaled < 1024)
+						break;
+				}
+				min_thresh_scaled = ((min_th*out_bw)/64)/(1<<exp);
+				node_profile->scale_exp[i].exp = exp;
+				/* 1024 * 32 = 0x8000 */
+				ratio =
+					(uint16_t)tm_round_int(0x8000, (max_thresh_scaled-min_thresh_scaled+1));
+				if (ratio > 1023)
+					node_profile->scale_ratio[i].ratio = 1023;
+				else
+					node_profile->scale_ratio[i].ratio = ratio;
+				node_profile->min_threshold[i].thresh = (uint16_t)min_thresh_scaled;
+				node_profile->dp_ratio[i].ratio = profile->dp_ratio[i];
+			}
+			for (i = color_num; i < 3; i++) {
+				/* Disable WRED for not used colors */
+				node_profile->curve_id[i].index = 0;
+				node_profile->scale_exp[i].exp = 22;
+				node_profile->scale_ratio[i].ratio = 0;
+				node_profile->min_threshold[i].thresh = 1023;
+				node_profile->dp_ratio[i].ratio = 0;
+			}
+		} else { /* CATD */
+			node_profile->color_td_en = TM_ENABLE;
+			for (i = 0; i < color_num; i++) {
+				min_th = profile->min_th[i];
+				/* find highest value for exp when min_thresh_scaled smaller from 1024 */
+				for (exp = 0; exp < 22; exp++) {
+					/* 64 = 8[byte]*16[burst]*100[%]*1000[msec]/(TM_RTT*TM_KBITS) */
+					min_thresh_scaled = ((min_th*out_bw)/64)/(1<<exp);
+					if (min_thresh_scaled < 1024)
+						break;
+				}
+				node_profile->min_threshold[i].thresh = (uint16_t)min_thresh_scaled;
+				node_profile->curve_id[i].index = 0;
+				node_profile->scale_exp[i].exp = exp;
+				node_profile->scale_ratio[i].ratio = 0;
+				node_profile->dp_ratio[i].ratio = 0;
+			}
+			for (i = color_num; i < 3; i++) {
+				/* Disable WRED for not used colors */
+				node_profile->curve_id[i].index = 0;
+				node_profile->scale_exp[i].exp = 22;
+				node_profile->scale_ratio[i].ratio = 0;
+				node_profile->min_threshold[i].thresh = 1023;
+				node_profile->dp_ratio[i].ratio = 0;
+			}
+		}
+	} else { /* DISABLED = CBTD only */
+		node_profile->color_td_en = TM_DISABLE;
+		node_profile->aql_exp = 0;
+		for (i = 0; i < 3; i++) {
+			node_profile->curve_id[i].index = 0;
+			node_profile->scale_exp[i].exp = 22;
+			node_profile->scale_ratio[i].ratio = 0;
+			node_profile->min_threshold[i].thresh = 1023;
+			node_profile->dp_ratio[i].ratio = 0;
+		}
+	}
+
+	/* Calculate TD threshold */
+	if (profile->cbtd_bw == TM_MAX_BW) {
+		/* Disable CBTD */
+		node_profile->td_thresh_res = TM_ENABLE;
+		node_profile->td_threshold = get_drop_threshold_definition();
+	} else {
+		/* 64 = 8[byte]*16[burst]*100[%]*1000[usec]/(TM_RTT*TM_KBITS) */
+		td_threshold = (profile->cbtd_bw*profile->cbtd_rtt_ratio)/64;
+		if (td_threshold > get_drop_threshold_definition()) {
+			node_profile->td_thresh_res = TM_ENABLE;
+			node_profile->td_threshold = td_threshold/1024;
+		} else {
+			node_profile->td_thresh_res = TM_DISABLE;
+			node_profile->td_threshold = td_threshold;
+		}
+	}
+	node_profile->cbtd_bw = profile->cbtd_bw;
+
+	/* update HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_drop_profile(hndl, *prof_index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_drop_profile(hndl, cos, *prof_index);
+		break;
+	case P_LEVEL:
+		/* Port Drop profile should be set to hw later in time of port's
+		 * creation */
+		break;
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_DROP_PROFILE_FAILED;
+out:
+	if (rc) {
+		switch (level) {
+		case Q_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_queue_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case A_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_a_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case B_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_b_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case C_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_c_node_drop_profile(rm, cos, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[cos],
+											*prof_index);
+			break;
+		case P_LEVEL:
+			if (list)
+				rm_list_delete(rm, list);
+			if (prof_ind >= 0) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rm_free_port_drop_profile(rm, *prof_index);
+				else
+					rm_free_port_drop_profile_cos(rm, cos, *prof_index);
+			}
+			if (rc == TM_HW_DROP_PROFILE_FAILED) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, *prof_index);
+				else
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[cos], *prof_index);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_update_drop_profile(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t index,
+						struct tm_drop_profile_params *profile)
+{
+	struct tm_drop_profile *dp;
+	int i;
+	int rc;
+	uint8_t fl_change = TM_DISABLE;
+
+	uint8_t status;
+	uint8_t color_num;
+	uint32_t td_threshold;
+	uint8_t exp;
+	uint32_t max_th;
+	uint32_t max_thresh_scaled = 0;
+	uint32_t min_th;
+	uint32_t min_thresh_scaled = 0;
+	uint16_t ratio;
+	uint32_t out_bw = profile->wred_catd_bw;
+
+	uint32_t ind;
+	uint8_t lvl;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	/* Must parameter! */
+	if ((profile->wred_catd_mode != WRED) &&
+		(profile->wred_catd_mode != CATD) &&
+		(profile->wred_catd_mode != DISABLED)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	color_num = ctl->dp_unit.local[level].color_num;
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = rm_queue_drop_profile_status(rm, index, &status);
+		if ((rc < 0) || (status != RM_TRUE))
+			return -EFAULT;
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case A_LEVEL:
+		rc = rm_a_node_drop_profile_status(rm, index, &status);
+		if ((rc < 0) || (status != RM_TRUE))
+			return -EFAULT;
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case B_LEVEL:
+		rc = rm_b_node_drop_profile_status(rm, index, &status);
+		if ((rc < 0) || (status != RM_TRUE))
+			return -EFAULT;
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case C_LEVEL:
+		rc = rm_c_node_drop_profile_status(rm, cos, index, &status);
+		if ((rc < 0) || (status != RM_TRUE))
+			return -EFAULT;
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) { /* Global Port */
+			rc = rm_port_drop_profile_status(rm, index, &status);
+			if ((rc < 0) || (status != RM_TRUE))
+				return -EFAULT;
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		} else {
+			rc = rm_port_drop_profile_status_cos(rm, cos, index, &status);
+			if ((rc < 0) || (status != RM_TRUE))
+				return -EFAULT;
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		}
+		break;
+	default:
+		return -EPERM;
+		break;
+	}
+
+	/* CBTD */
+	if (profile->cbtd_bw != TM_INVAL) {
+		if (profile->cbtd_bw > TM_MAX_BW) {
+			rc = -EACCES;
+			goto out;
+		}
+
+		if (profile->cbtd_bw == TM_MAX_BW) { /* Disable CBTD */
+			dp->td_thresh_res = TM_ENABLE;
+			dp->td_threshold = get_drop_threshold_definition();
+		} else {
+			/* 64 = 8[byte]*16[burst]*100[%]*1000[usec]/(TM_RTT*TM_KBITS) */
+			td_threshold = (profile->cbtd_bw*profile->cbtd_rtt_ratio)/64;
+			if (td_threshold > get_drop_threshold_definition()) {
+				dp->td_thresh_res = TM_ENABLE;
+				dp->td_threshold = td_threshold/1024;
+			} else {
+				dp->td_thresh_res = TM_DISABLE;
+				dp->td_threshold = td_threshold;
+			}
+		}
+		dp->cbtd_bw = profile->cbtd_bw;
+		fl_change = TM_ENABLE;
+	}
+
+	if ((profile->wred_catd_mode == DISABLED) && (dp->out_bw != 0)) {
+		dp->color_td_en = TM_DISABLE;
+		dp->out_bw = 0;
+		dp->aql_exp = 0;
+		for (i = 0; i < 3; i++) {
+			dp->curve_id[i].index = 0;
+			dp->scale_exp[i].exp = 22;
+			dp->scale_ratio[i].ratio = 0;
+			dp->min_threshold[i].thresh = 1023;
+			dp->dp_ratio[i].ratio = 0;
+			dp->min_th_sw[i] = 0;
+			dp->max_th_sw[i] = 0;
+		}
+		fl_change = TM_ENABLE;
+	}
+
+	/* CA/WRED */
+	if (profile->wred_catd_mode != DISABLED) {
+		if (profile->aql_exp != (uint8_t) TM_INVAL) {
+			if (profile->aql_exp > 0xF) {
+				rc = -EFAULT;
+				goto out;
+			}
+
+			dp->aql_exp = profile->aql_exp;
+			fl_change = TM_ENABLE;
+		}
+
+		if (profile->wred_catd_bw > TM_MAX_BW) {
+			rc = -EACCES;
+			goto out;
+		}
+	}
+
+	/* WRED */
+	if (profile->wred_catd_mode == WRED) {
+		for (i = 0; i < color_num; i++) {
+			if (profile->max_th[i] < profile->min_th[i]) {
+				rc = -ERANGE;
+				goto out;
+			}
+
+			if (i == 2) {
+				if (profile->dp_ratio[i] > 16) { /* 4 bits */
+					rc = -ERANGE;
+					goto out;
+				}
+			} else
+				if (profile->dp_ratio[i] > 63) { /* 6 bits */
+					rc = -ERANGE;
+					goto out;
+				}
+
+			switch (level) {
+			case Q_LEVEL:
+				if (profile->curve_id[i] >= TM_NUM_WRED_QUEUE_CURVES) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				/* check if the assigned WRED curve exists */
+				rc = rm_wred_queue_curve_status(rm, profile->curve_id[i],
+											&status);
+				break;
+			case A_LEVEL:
+				if (profile->curve_id[i] >= TM_NUM_WRED_A_NODE_CURVES) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				rc = rm_wred_a_node_curve_status(rm, profile->curve_id[i],
+											 &status);
+				break;
+			case B_LEVEL:
+				if (profile->curve_id[i] >= TM_NUM_WRED_B_NODE_CURVES) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				rc = rm_wred_b_node_curve_status(rm, profile->curve_id[i],
+											 &status);
+				break;
+			case C_LEVEL:
+				if (cos > TM_WRED_COS) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				if (profile->curve_id[i] >= TM_NUM_WRED_C_NODE_CURVES) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				rc = rm_wred_c_node_curve_status(rm, cos, profile->curve_id[i],
+											 &status);
+				break;
+			case P_LEVEL:
+				if (profile->curve_id[i] >= TM_NUM_WRED_PORT_CURVES) {
+					rc = -EADDRNOTAVAIL;
+					goto out;
+				}
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rc = rm_wred_port_curve_status(rm, profile->curve_id[i],
+											&status);
+				else
+					rc = rm_wred_port_curve_status_cos(rm, cos, profile->curve_id[i],
+										&status);
+				break;
+			default:
+				break;
+			}
+			/* if referenced WRED curve doesn't exist */
+			if ((rc < 0) || (status != RM_TRUE)) {
+				rc = -ENODEV;
+				goto out;
+			}
+
+			dp->min_th_sw[i] = profile->min_th[i];
+			dp->max_th_sw[i] = profile->max_th[i];
+		}
+
+		dp->color_td_en = TM_DISABLE; /* WRED mode */
+		dp->out_bw = out_bw;
+
+		/* calculate min_th, scale_exp and scale_ratio for each color */
+		for (i = 0; i < color_num; i++) {
+			dp->curve_id[i].index = profile->curve_id[i];
+			max_th = profile->max_th[i];
+			min_th = profile->min_th[i];
+			/* find highest value for exp when max_thresh_scaled smaller from 1024 */
+			for (exp = 0; exp < 22; exp++) {
+				/* 64 = (8[byte]*16[burst]*100[%]*1000[msec])/(TM_KBITS*TM_RTT) */
+				max_thresh_scaled =
+					((uint8_t)max_th*(uint8_t)out_bw/(uint8_t)64)/(uint8_t)(1 << exp);
+				if (max_thresh_scaled < 1024)
+					break;
+			}
+			min_thresh_scaled = ((min_th*out_bw)/64)/(1<<exp);
+			dp->scale_exp[i].exp = exp;
+			/* 1024 * 32 = 0x8000 */
+			ratio =
+			(uint16_t)tm_round_int(0x8000, (max_thresh_scaled-min_thresh_scaled+1));
+			if (ratio > 1023)
+				dp->scale_ratio[i].ratio = 1023;
+			else
+				dp->scale_ratio[i].ratio = ratio;
+			dp->min_threshold[i].thresh = (uint16_t)min_thresh_scaled;
+			dp->dp_ratio[i].ratio = profile->dp_ratio[i];
+		}
+		for (i = color_num; i < 3; i++) {
+			dp->curve_id[i].index = 0;
+			dp->scale_exp[i].exp = 22;
+			dp->scale_ratio[i].ratio = 0;
+			dp->min_threshold[i].thresh = 1023;
+			dp->dp_ratio[i].ratio = 0;
+		}
+		fl_change = TM_ENABLE;
+	}
+
+	/* CATD */
+	if (profile->wred_catd_mode == CATD) {
+		dp->color_td_en = TM_ENABLE;
+		dp->out_bw = out_bw;
+		for (i = 0; i < color_num; i++) {
+			min_th = profile->min_th[i];
+			/* find highest value for exp when min_thresh_scaled smaller from 1024 */
+			for (exp = 0; exp < 22; exp++) {
+				/* 64 = 8[byte]*16[burst]*100[%]*1000[msec]/(TM_RTT*TM_KBITS) */
+				min_thresh_scaled = ((min_th*out_bw)/64)/(1<<exp);
+				if (min_thresh_scaled < 1024)
+					break;
+			}
+			dp->min_threshold[i].thresh = (uint16_t)min_thresh_scaled;
+			dp->curve_id[i].index = 0;
+			dp->scale_exp[i].exp = exp;
+			dp->scale_ratio[i].ratio = 0;
+			dp->dp_ratio[i].ratio = 0;
+		}
+		for (i = color_num; i < 3; i++) {
+			dp->curve_id[i].index = 0;
+			dp->scale_exp[i].exp = 22;
+			dp->scale_ratio[i].ratio = 0;
+			dp->min_threshold[i].thresh = 1023;
+			dp->dp_ratio[i].ratio = 0;
+		}
+		fl_change = TM_ENABLE;
+	}
+
+	if (fl_change == TM_ENABLE) {
+		/* update HW */
+		switch (level) {
+		case Q_LEVEL:
+			rc = set_hw_queue_drop_profile(hndl, index);
+			break;
+		case A_LEVEL:
+			rc = set_hw_a_nodes_drop_profile(hndl, index);
+			break;
+		case B_LEVEL:
+			rc = set_hw_b_nodes_drop_profile(hndl, index);
+			break;
+		case C_LEVEL:
+			rc = set_hw_c_nodes_drop_profile(hndl, cos, index);
+			break;
+		case P_LEVEL:
+			i = dp->use_counter;
+			if (i == 0) /* list empty */
+				break;
+			for (; i > 0; i--) {
+				if (i == dp->use_counter)
+					rc = rm_list_reset_to_start(rm, dp->use_list, &ind, &lvl);
+				else
+					rc = rm_list_next_index(rm, dp->use_list, &ind, &lvl);
+				if (rc || (lvl != P_LEVEL))
+					goto out;
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rc = set_hw_port_drop(hndl, ind);
+				else
+					rc = set_hw_port_drop_cos(hndl, ind, cos);
+				if (rc)
+					rc = TM_HW_PORT_CONFIG_FAIL;
+			}
+			break;
+		default:
+			break;
+		}
+		if (rc)
+			rc = TM_HW_DROP_PROFILE_FAILED;
+	}
+out:
+	if (rc == TM_HW_DROP_PROFILE_FAILED)
+		switch (level) {
+		case Q_LEVEL:
+			set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles, index);
+			break;
+		case A_LEVEL:
+			set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles, index);
+			break;
+		case B_LEVEL:
+			set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles, index);
+			break;
+		case C_LEVEL:
+			set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[cos], index);
+			break;
+		case P_LEVEL:
+			if (cos == (uint8_t)TM_INVAL) /* Global Port */
+				set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, index);
+			else
+				set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[cos], index);
+			break;
+		default:
+			break;
+		}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_drop_profile_hw_set(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t index)
+{
+	struct tm_drop_profile *dp;
+	int i = 0;
+	int rc;
+
+	uint32_t ind;
+	uint8_t lvl;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case A_LEVEL:
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case B_LEVEL:
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case C_LEVEL:
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t) TM_INVAL)
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		else
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+	}
+
+	/* update HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_drop_profile(ctl, index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_drop_profile(ctl, index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_drop_profile(ctl, index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_drop_profile(ctl, cos, index);
+		break;
+	case P_LEVEL:
+		i = dp->use_counter;
+		if (i == 0) /* list empty */
+			break;
+		for (; i > 0; i--) {
+			if (i == dp->use_counter)
+				rc = rm_list_reset_to_start(rm, dp->use_list, &ind, &lvl);
+			else
+				rc = rm_list_next_index(rm, dp->use_list, &ind, &lvl);
+			if (rc || (lvl != P_LEVEL))
+				rc = TM_HW_DROP_PROFILE_FAILED;
+			if (cos == (uint8_t)TM_INVAL) /* Global Port */
+				rc = set_hw_port_drop(ctl, ind);
+			else
+				rc = set_hw_port_drop_cos(ctl, ind, cos);
+		}
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+	}
+	if (rc)
+		rc = TM_HW_DROP_PROFILE_FAILED;
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_create_drop_profile_1G(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile *node_profile;
+	int i;
+	int rc;
+	uint32_t td_threshold;
+	struct rm_list *list = NULL;
+	int prof_ind = (int)TM_INVAL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	/* find free profile */
+	switch (level) {
+	case Q_LEVEL:
+		prof_ind = rm_find_free_queue_drop_profile(rm);
+		break;
+	case A_LEVEL:
+		prof_ind = rm_find_free_a_node_drop_profile(rm);
+		break;
+	case B_LEVEL:
+		prof_ind = rm_find_free_b_node_drop_profile(rm);
+		break;
+	case C_LEVEL:
+		prof_ind = rm_find_free_c_node_drop_profile(rm, cos);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			prof_ind = rm_find_free_port_drop_profile(rm);
+		else
+			prof_ind = rm_find_free_port_drop_profile_cos(rm, cos);
+		rc = rm_list_create(rm, &list);
+		break;
+	default:
+		break;
+	}
+
+	if ((prof_ind < 0) || rc) {
+		rc = -ENOSPC;
+		goto out;
+	} else
+		*prof_index = prof_ind;
+
+
+	switch (level) {
+	case Q_LEVEL:
+		node_profile = &(ctl->tm_q_lvl_drop_profiles[*prof_index]);
+		break;
+	case A_LEVEL:
+		node_profile = &(ctl->tm_a_lvl_drop_profiles[*prof_index]);
+		break;
+	case B_LEVEL:
+		node_profile = &(ctl->tm_b_lvl_drop_profiles[*prof_index]);
+		break;
+	case C_LEVEL:
+		node_profile = &(ctl->tm_c_lvl_drop_profiles[cos][*prof_index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			node_profile = &(ctl->tm_p_lvl_drop_profiles[*prof_index]);
+		else
+			node_profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][*prof_index]);
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+		break;
+	}
+
+	/* update SW image */
+	for (i = 0; i < 3; i++) {
+		node_profile->min_th_sw[i] = TM_DISABLE;  /**< Min Threshold ratio from RTT in % per color */
+		node_profile->max_th_sw[i] = TM_DISABLE;  /**< Max Threshold ratio from RTT in % per color */
+	}
+	node_profile->use_list = list;
+
+	/* DISABLED = CBTD only */
+	node_profile->out_bw = TM_DISABLE;
+	node_profile->aql_exp = TM_DISABLE;
+	node_profile->color_td_en = TM_DISABLE;
+	node_profile->aql_exp = 0;
+	for (i = 0; i < 3; i++) {
+		node_profile->curve_id[i].index = 0;
+		node_profile->scale_exp[i].exp = 22;
+		node_profile->scale_ratio[i].ratio = 0;
+		node_profile->min_threshold[i].thresh = 1023;
+		node_profile->dp_ratio[i].ratio = 0;
+	 }
+
+	/* TD threshold for 1G */
+	td_threshold = 1638400;
+	if (td_threshold > get_drop_threshold_definition()) {
+		node_profile->td_thresh_res = TM_ENABLE;
+		node_profile->td_threshold = td_threshold/1024;
+	} else {
+		node_profile->td_thresh_res = TM_DISABLE;
+		node_profile->td_threshold = td_threshold;
+	}
+	node_profile->cbtd_bw = 1000000;
+
+	/* update HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_drop_profile(hndl, *prof_index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_drop_profile(hndl, cos, *prof_index);
+		break;
+	case P_LEVEL:
+		/* Port Drop profile should be set to hw later in time of port's
+		 * creation */
+		break;
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_DROP_PROFILE_FAILED;
+out:
+	if (rc) {
+		switch (level) {
+		case Q_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_queue_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case A_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_a_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case B_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_b_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case C_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_c_node_drop_profile(rm, cos, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[cos],
+											*prof_index);
+			break;
+		case P_LEVEL:
+			if (list)
+				rm_list_delete(rm, list);
+			if (prof_ind >= 0) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rm_free_port_drop_profile(rm, *prof_index);
+				else
+					rm_free_port_drop_profile_cos(rm, cos, *prof_index);
+			}
+			if (rc == TM_HW_DROP_PROFILE_FAILED) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, *prof_index);
+				else
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[cos], *prof_index);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_create_drop_profile_2_5G(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile *node_profile;
+	int i;
+	int rc;
+	uint32_t td_threshold;
+	struct rm_list *list = NULL;
+	int prof_ind = (int)TM_INVAL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	/* find free profile */
+	switch (level) {
+	case Q_LEVEL:
+		prof_ind = rm_find_free_queue_drop_profile(rm);
+		break;
+	case A_LEVEL:
+		prof_ind = rm_find_free_a_node_drop_profile(rm);
+		break;
+	case B_LEVEL:
+		prof_ind = rm_find_free_b_node_drop_profile(rm);
+		break;
+	case C_LEVEL:
+		prof_ind = rm_find_free_c_node_drop_profile(rm, cos);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			prof_ind = rm_find_free_port_drop_profile(rm);
+		else
+			prof_ind = rm_find_free_port_drop_profile_cos(rm, cos);
+		rc = rm_list_create(rm, &list);
+		break;
+	default:
+		break;
+	}
+
+	if ((prof_ind < 0) || rc) {
+		rc = -ENOSPC;
+		goto out;
+	} else
+		*prof_index = prof_ind;
+
+
+	switch (level) {
+	case Q_LEVEL:
+		node_profile = &(ctl->tm_q_lvl_drop_profiles[*prof_index]);
+		break;
+	case A_LEVEL:
+		node_profile = &(ctl->tm_a_lvl_drop_profiles[*prof_index]);
+		break;
+	case B_LEVEL:
+		node_profile = &(ctl->tm_b_lvl_drop_profiles[*prof_index]);
+		break;
+	case C_LEVEL:
+		node_profile = &(ctl->tm_c_lvl_drop_profiles[cos][*prof_index]);
+		break;
+	case P_LEVEL:
+		if (cos == (uint8_t)TM_INVAL) /* Global Port */
+			node_profile = &(ctl->tm_p_lvl_drop_profiles[*prof_index]);
+		else
+			node_profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][*prof_index]);
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+		break;
+	}
+
+	/* update SW image */
+	for (i = 0; i < 3; i++) {
+		node_profile->min_th_sw[i] = TM_DISABLE;  /**< Min Threshold ratio from RTT in % per color */
+		node_profile->max_th_sw[i] = TM_DISABLE;  /**< Max Threshold ratio from RTT in % per color */
+	}
+	node_profile->use_list = list;
+
+	/* DISABLED = CBTD only */
+	node_profile->out_bw = TM_DISABLE;
+	node_profile->aql_exp = TM_DISABLE;
+	node_profile->color_td_en = TM_DISABLE;
+	node_profile->aql_exp = 0;
+	for (i = 0; i < 3; i++) {
+		node_profile->curve_id[i].index = 0;
+		node_profile->scale_exp[i].exp = 22;
+		node_profile->scale_ratio[i].ratio = 0;
+		node_profile->min_threshold[i].thresh = 1023;
+		node_profile->dp_ratio[i].ratio = 0;
+	 }
+
+	/* TD threshold for 2.5G */
+	td_threshold = 4096000;
+	if (td_threshold > get_drop_threshold_definition()) {
+		node_profile->td_thresh_res = TM_ENABLE;
+		node_profile->td_threshold = td_threshold/1024;
+	} else {
+		node_profile->td_thresh_res = TM_DISABLE;
+		node_profile->td_threshold = td_threshold;
+	}
+	node_profile->cbtd_bw = 2500000;
+
+	/* update HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_drop_profile(hndl, *prof_index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_drop_profile(hndl, *prof_index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_drop_profile(hndl, cos, *prof_index);
+		break;
+	case P_LEVEL:
+		/* Port Drop profile should be set to hw later in time of port's
+		 * creation */
+		break;
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_DROP_PROFILE_FAILED;
+out:
+	if (rc) {
+		switch (level) {
+		case Q_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_queue_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case A_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_a_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case B_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_b_node_drop_profile(rm, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles,
+											*prof_index);
+			break;
+		case C_LEVEL:
+			if (prof_ind >= 0)
+				rm_free_c_node_drop_profile(rm, cos, *prof_index);
+			if (rc == TM_HW_DROP_PROFILE_FAILED)
+				set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[cos],
+											*prof_index);
+			break;
+		case P_LEVEL:
+			if (list)
+				rm_list_delete(rm, list);
+			if (prof_ind >= 0) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					rm_free_port_drop_profile(rm, *prof_index);
+				else
+					rm_free_port_drop_profile_cos(rm, cos, *prof_index);
+			}
+			if (rc == TM_HW_DROP_PROFILE_FAILED) {
+				if (cos == (uint8_t)TM_INVAL) /* Global Port */
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, *prof_index);
+				else
+					set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[cos], *prof_index);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_delete_drop_profile(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t prof_index)
+{
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EDOM;
+		goto out;
+	}
+
+	if (prof_index == 0) { /* reserved profile */
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:
+		if (prof_index >= TM_NUM_QUEUE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		if (ctl->tm_q_lvl_drop_profiles[prof_index].use_counter > 0) {
+			rc = -EPERM;
+			goto out;
+		}
+
+		/* free profile's entry in the RM (status is checked inside) */
+		rc = rm_free_queue_drop_profile(rm, prof_index);
+		if (rc < 0) {
+			rc = -EFAULT;
+			goto out;
+		}
+
+		/* set SW image entry to default values */
+		set_sw_drop_profile_default(ctl->tm_q_lvl_drop_profiles, prof_index);
+		break;
+	case A_LEVEL:
+		if (prof_index >= TM_NUM_A_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		if (ctl->tm_a_lvl_drop_profiles[prof_index].use_counter > 0) {
+			rc = -EPERM;
+			goto out;
+		}
+		/* free profile's entry in the RM (status is checked inside) */
+		rc = rm_free_a_node_drop_profile(rm, prof_index);
+		if (rc < 0) {
+			rc = -EFAULT;
+			goto out;
+		}
+
+		/* set SW image entry to default values */
+		set_sw_drop_profile_default(ctl->tm_a_lvl_drop_profiles, prof_index);
+		break;
+	case B_LEVEL:
+		if (prof_index >= TM_NUM_B_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		if (ctl->tm_b_lvl_drop_profiles[prof_index].use_counter > 0) {
+			rc = -EPERM;
+			goto out;
+		}
+		/* free profile's entry in the RM (status is checked inside) */
+		rc = rm_free_b_node_drop_profile(rm, prof_index);
+		if (rc < 0) {
+			rc = -EFAULT;
+			goto out;
+		}
+
+		/* set SW image entry to default values */
+		set_sw_drop_profile_default(ctl->tm_b_lvl_drop_profiles, prof_index);
+		break;
+	case C_LEVEL:
+		if (prof_index >= TM_NUM_C_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		if (cos >= TM_WRED_COS) {
+			rc = -ENODEV;
+			goto out;
+		}
+
+		if (ctl->tm_c_lvl_drop_profiles[cos][prof_index].use_counter > 0) {
+			rc = -EPERM;
+			goto out;
+		}
+		/* free profile's entry in the RM (status is checked inside) */
+		rc = rm_free_c_node_drop_profile(rm, cos, prof_index);
+		if (rc < 0) {
+			rc = -EFAULT;
+			goto out;
+		}
+
+		/* set SW image entry to default values */
+		set_sw_drop_profile_default(ctl->tm_c_lvl_drop_profiles[cos],
+									prof_index);
+		break;
+	case P_LEVEL:
+		if (prof_index >= TM_NUM_PORT_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		if (cos == (uint8_t)TM_INVAL) { /* Global Port */
+			if (ctl->tm_p_lvl_drop_profiles[prof_index].use_counter > 0) {
+				rc = -EPERM;
+				goto out;
+			}
+
+			rc = rm_list_delete(rm,
+								ctl->tm_p_lvl_drop_profiles[prof_index].use_list);
+			if (rc < 0) {
+				rc = -EPERM;
+				goto out;
+			}
+
+			/* free profile's entry in the RM (status is checked inside) */
+			rc = rm_free_port_drop_profile(rm, prof_index);
+			if (rc < 0) {
+				rc = -EFAULT;
+				goto out;
+			}
+
+			/* set SW image entry to default values */
+			set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles, prof_index);
+		} else {
+			if (cos >= TM_WRED_COS) {
+				rc = -ENODEV;
+				goto out;
+			}
+
+			if (ctl->tm_p_lvl_drop_profiles_cos[cos][prof_index].use_counter > 0) {
+				rc = -EPERM;
+				goto out;
+			}
+
+			rc = rm_list_delete(rm,
+				ctl->tm_p_lvl_drop_profiles_cos[cos][prof_index].use_list);
+			if (rc < 0) {
+				rc = -EPERM;
+				goto out;
+			}
+
+			/* free profile's entry in the RM (status is checked inside) */
+			rc = rm_free_port_drop_profile_cos(rm, cos, prof_index);
+			if (rc < 0) {
+				rc = -EFAULT;
+				goto out;
+			}
+
+			/* set SW image entry to default values */
+			set_sw_drop_profile_default(ctl->tm_p_lvl_drop_profiles_cos[cos], prof_index);
+		}
+		break;
+	default:
+		break;
+	}
+
+	/* set HW to default */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_drop_profile(hndl, prof_index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_nodes_drop_profile(hndl, prof_index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_nodes_drop_profile(hndl, prof_index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_nodes_drop_profile(hndl, cos, prof_index);
+		break;
+	default:
+		break;
+	}
+	if (rc)
+		rc = TM_HW_DROP_PROFILE_FAILED;
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+*/
+int tm_read_drop_profile(tm_handle hndl,
+						 enum tm_level level,
+						 uint8_t cos,
+						 uint16_t prof_index,
+						 struct tm_drop_profile_params *profile)
+{
+
+	uint8_t status;
+	int rc;
+	int i;
+	uint32_t td_threshold;
+	struct tm_drop_profile *drop_profile = NULL;
+	uint8_t color_num;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	color_num = ctl->dp_unit.local[level].color_num;
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (level > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:
+		if (prof_index >= TM_NUM_QUEUE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		/* check profile status */
+		rc = rm_queue_drop_profile_status(rm, prof_index, &status);
+		if ((rc < 0) || (status != RM_TRUE)) {
+			rc = -EFAULT;
+			goto out;
+		}
+		drop_profile = &(ctl->tm_q_lvl_drop_profiles[prof_index]);
+		break;
+	case A_LEVEL:
+		if (prof_index >= TM_NUM_A_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+		/* check profile status */
+		rc = rm_a_node_drop_profile_status(rm, prof_index, &status);
+		if ((rc < 0) || (status != RM_TRUE)) {
+			rc = -EFAULT;
+			goto out;
+		}
+		drop_profile = &(ctl->tm_a_lvl_drop_profiles[prof_index]);
+		break;
+	case B_LEVEL:
+		if (prof_index >= TM_NUM_B_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+
+		/* check profile status */
+		rc = rm_b_node_drop_profile_status(rm, prof_index, &status);
+		if ((rc < 0) || (status != RM_TRUE)) {
+			rc = -EFAULT;
+			goto out;
+		}
+		drop_profile = &(ctl->tm_b_lvl_drop_profiles[prof_index]);
+		break;
+	case C_LEVEL:
+		if (prof_index >= TM_NUM_C_NODE_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+		/* check profile status */
+		rc = rm_c_node_drop_profile_status(rm, cos, prof_index, &status);
+		if ((rc < 0) || (status != RM_TRUE)) {
+			rc = -EFAULT;
+			goto out;
+		}
+		drop_profile = &(ctl->tm_c_lvl_drop_profiles[cos][prof_index]);
+		break;
+	case P_LEVEL:
+		if (prof_index >= TM_NUM_PORT_DROP_PROF) {
+			rc = -EADDRNOTAVAIL;
+			goto out;
+		}
+		/* check profile status */
+		if (cos == (uint8_t)TM_INVAL) { /* Global Port */
+			rc = rm_port_drop_profile_status(rm, prof_index, &status);
+			if ((rc < 0) || (status != RM_TRUE)) {
+				rc = -EFAULT;
+				goto out;
+			}
+			drop_profile = &(ctl->tm_p_lvl_drop_profiles[prof_index]);
+		} else {
+			rc = rm_port_drop_profile_status_cos(rm, cos, prof_index, &status);
+			if ((rc < 0) || (status != RM_TRUE)) {
+				rc = -EFAULT;
+				goto out;
+			}
+			drop_profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][prof_index]);
+		}
+		break;
+	default:
+		rc = -EPERM;
+		goto out;
+		break;
+	}
+
+	profile->wred_catd_bw = drop_profile->out_bw;
+	profile->aql_exp = drop_profile->aql_exp;
+	if (drop_profile->out_bw == 0)
+		profile->wred_catd_mode = DISABLED;
+	else
+		profile->wred_catd_mode = drop_profile->color_td_en;
+
+	if (drop_profile->td_thresh_res == TM_ENABLE)
+		td_threshold = drop_profile->td_threshold*1024;
+	else
+		td_threshold = drop_profile->td_threshold;
+	profile->cbtd_bw = drop_profile->cbtd_bw;
+	if (profile->cbtd_bw != 0)
+		if (profile->cbtd_bw == TM_MAX_BW)
+			profile->cbtd_rtt_ratio = 0;
+		else
+			/* 64 = 100*1000*8*16/(TM_KBITS*TM_RTT) */
+			profile->cbtd_rtt_ratio = (td_threshold*64)/profile->cbtd_bw;
+	else
+		profile->cbtd_rtt_ratio = 0;
+	if (profile->wred_catd_mode != DISABLED) {
+		if (profile->wred_catd_mode == WRED) {
+			for (i = 0; i < color_num; i++) {/* for each configured color */
+				profile->curve_id[i] = drop_profile->curve_id[i].index;
+				profile->min_th[i] = drop_profile->min_th_sw[i];
+				profile->max_th[i] = drop_profile->max_th_sw[i];
+				profile->dp_ratio[i] = drop_profile->dp_ratio[i].ratio;
+			}
+
+			for (i = color_num; i < 3; i++) { /* for not configured color */
+				profile->curve_id[i] = 0;
+				profile->min_th[i] = 0;
+				profile->max_th[i] = 0;
+				profile->dp_ratio[i] = 0;
+			}
+		} else { /* CATD */
+			for (i = 0; i < color_num; i++) { /* for each configured color */
+				profile->min_th[i] = drop_profile->min_th_sw[i];
+				/* Unused fields */
+				profile->max_th[i] = 0;
+				profile->curve_id[i] = 0;
+				profile->dp_ratio[i] = 0;
+			}
+			for (i = color_num; i < 3; i++) { /* for not configured color */
+				profile->curve_id[i] = 0;
+				profile->min_th[i] = 0;
+				profile->max_th[i] = 0;
+				profile->dp_ratio[i] = 0;
+			}
+		}
+	} else {
+		for (i = 0; i < 3; i++) { /* for each color */
+			profile->curve_id[i] = 0;
+			profile->min_th[i] = 0;
+			profile->max_th[i] = 0;
+			profile->dp_ratio[i] = 0;
+		}
+	}
+
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_set_drop_color_num(tm_handle hndl,
+						enum tm_level lvl,
+						enum tm_color_num num)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (lvl > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	if (num > TM_3_COLORS) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	ctl->dp_unit.local[lvl].resolution = 6;
+
+	switch (num) {
+	case TM_1_COLORS:
+		ctl->dp_unit.local[lvl].color_num = 1;
+		break;
+	case TM_2_COLORS:
+		ctl->dp_unit.local[lvl].color_num = 2;
+		break;
+	case TM_3_COLORS:
+		ctl->dp_unit.local[lvl].color_num = 3;
+		ctl->dp_unit.local[lvl].resolution = 4;
+		break;
+	}
+
+	rc = set_hw_drop_color_num(hndl);
+	if (rc)
+		rc = TM_HW_COLOR_NUM_CONFIG_FAIL;
+
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_dp_source_set(tm_handle hndl,
+					 enum tm_level lvl,
+					 uint8_t color,
+					 enum tm_dp_source src)
+{
+	enum tm_dp_source src_old;
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters validity */
+	if (lvl > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	if (color > 2) {
+		rc = -ENODEV;
+		goto out;
+	}
+
+	if (src > TM_QL) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	src_old = ctl->dp_unit.local[lvl].dp_src[color];
+	if (src_old != src)
+	{
+		ctl->dp_unit.local[lvl].dp_src[color] = src;
+		rc = set_hw_dp_source(ctl);
+		if (rc < 0)
+			rc = TM_HW_AQM_CONFIG_FAIL;
+	}
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_set_drop_query_responce(tm_handle hndl,
+							uint8_t port_dp,
+							enum tm_level lvl)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters validity */
+	if (lvl > P_LEVEL) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	if ((port_dp != TM_ENABLE) && (port_dp != TM_DISABLE)) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = set_hw_dp_local_resp(ctl, port_dp, lvl);
+	if (rc)
+		rc = TM_HW_DP_QUERY_RESP_CONF_FAILED;
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_set_drop_queue_cos(tm_handle hndl,
+						uint32_t index,
+						uint8_t cos)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters validity */
+	if (index >= rm->rm_total_queues) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	if (cos >= TM_WRED_COS) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	ctl->tm_q_cos[index] = cos;
+
+	rc = set_hw_queue_cos(ctl, index);
+	if (rc)
+		rc = TM_HW_QUEUE_COS_CONF_FAILED;
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+#define SET_CURVE_DEFAULT       \
+	do {                        \
+		for (j = 0; j < TM_WRED_CURVE_POINTS; j++)\
+			curve->prob[j] = (uint8_t)tm_round_int((uint8_t)63 * (j+1), (uint8_t)TM_WRED_CURVE_POINTS); \
+	} while (0);
+
+
+int _tm_config_default_curves_sw(tm_handle hndl)
+{
+	struct tm_wred_curve *curve = NULL;
+	uint8_t cos;
+	int rc = -ENOSPC;
+	int j;
+	int curve_ind = -1;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	curve_ind = rm_find_free_wred_queue_curve(rm);
+	if (curve_ind < 0)
+		return rc;
+	curve = &(ctl->tm_wred_q_lvl_curves[curve_ind]);
+	SET_CURVE_DEFAULT
+
+	curve_ind = rm_find_free_wred_a_node_curve(rm);
+	if (curve_ind < 0)
+		return rc;
+	curve = &(ctl->tm_wred_a_lvl_curves[curve_ind]);
+	SET_CURVE_DEFAULT
+
+	curve_ind = rm_find_free_wred_b_node_curve(rm);
+	if (curve_ind < 0)
+		return rc;
+	curve = &(ctl->tm_wred_b_lvl_curves[curve_ind]);
+	SET_CURVE_DEFAULT
+
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		curve_ind = rm_find_free_wred_c_node_curve(rm, cos);
+		if (curve_ind < 0)
+			return rc;
+		curve = &(ctl->tm_wred_c_lvl_curves[cos][curve_ind]);
+		SET_CURVE_DEFAULT
+	}
+
+	curve_ind = rm_find_free_wred_port_curve(rm);
+	if (curve_ind < 0)
+		return rc;
+	curve = &(ctl->tm_wred_ports_curves[curve_ind]);
+	SET_CURVE_DEFAULT
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		curve_ind = rm_find_free_wred_port_curve_cos(rm, cos);
+		if (curve_ind < 0)
+			return rc;
+		curve = &(ctl->tm_wred_ports_curves_cos[cos][curve_ind]);
+		SET_CURVE_DEFAULT
+	}
+	return 0;
+}
+
+
+int _tm_config_default_curves_hw(tm_handle hndl)
+{
+	struct tm_wred_curve curve;
+	uint8_t cos;
+	int j;
+	int rc = TM_HW_WRED_CURVE_FAILED;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	for (j = 0; j < TM_WRED_CURVE_POINTS; j++)
+		curve.prob[j] = (uint8_t)tm_round_int((uint8_t)63 * (j+1), (uint8_t)TM_WRED_CURVE_POINTS);
+
+	rc = set_hw_queues_default_wred_curve(ctl, curve.prob);
+	if (rc)
+		return rc;
+	rc = set_hw_a_nodes_default_wred_curve(ctl, curve.prob);
+	if (rc)
+		return rc;
+	rc = set_hw_b_nodes_default_wred_curve(ctl, curve.prob);
+	if (rc)
+		return rc;
+
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		rc = set_hw_c_nodes_default_wred_curve(ctl, cos, curve.prob);
+		if (rc)
+			return rc;
+	}
+
+	rc = set_hw_ports_default_wred_curve(ctl, curve.prob);
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		rc = set_hw_ports_default_wred_curve_cos(ctl, cos, curve.prob);
+		if (rc)
+			return rc;
+	}
+	return 0;
+}
+
+
+int _tm_config_default_dp_mode(tm_handle hndl, int write_to_hw)
+{
+	int i;
+	int j;
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = 0;
+	for (i = Q_LEVEL; i <= P_LEVEL; i++) {
+		ctl->dp_unit.local[i].resolution = 6;
+		ctl->dp_unit.local[i].color_num = 2;
+		for (j = 0; j < 3; j++) {
+			ctl->dp_unit.local[i].max_p_mode[j] = TM_MAX_PROB_50/* TM_MAX_PROB_12H */;
+			ctl->dp_unit.local[i].dp_src[j] = TM_AQL;
+		}
+	}
+	if (write_to_hw) {
+		/* Download to HW */
+		/* Only Max Probability Mode should be downloaded, because all
+		 * the rest of parameters configured in HW by default */
+		rc = set_hw_max_dp_mode(ctl);
+		if (rc) rc = TM_HW_WRED_CURVE_FAILED;
+	}
+	return rc;
+}
+
+
+void __set_default_profile(struct tm_drop_profile *profile)
+{
+	int j;
+	profile->use_list = NULL;
+	profile->out_bw = 0;
+	profile->cbtd_bw = TM_MAX_BW;
+	profile->aql_exp = 0;
+	profile->td_thresh_res = TM_ENABLE;
+	profile->td_threshold = get_drop_threshold_definition();
+	profile->color_td_en = TM_DISABLE;
+	for (j = 0; j < 3; j++) {
+		profile->curve_id[j].index = 0;
+		profile->scale_exp[j].exp = 22;
+		profile->scale_ratio[j].ratio = 0;
+		profile->min_threshold[j].thresh = 1023;
+		profile->dp_ratio[j].ratio = 0;
+	}
+}
+
+
+int _tm_config_default_profiles_sw(tm_handle hndl)
+{
+	struct tm_drop_profile *profile = NULL;
+	uint8_t cos;
+	int rc = -ENOSPC;
+	struct rm_list *list = NULL;
+	int prof_ind = -1;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	prof_ind = rm_find_free_queue_drop_profile(rm);
+	if (prof_ind < 0)
+		return rc;
+	profile = &(ctl->tm_q_lvl_drop_profiles[prof_ind]);
+	__set_default_profile(profile);
+
+	prof_ind = rm_find_free_a_node_drop_profile(rm);
+	if (prof_ind < 0)
+		return rc;
+	profile = &(ctl->tm_a_lvl_drop_profiles[prof_ind]);
+	__set_default_profile(profile);
+
+	prof_ind = rm_find_free_b_node_drop_profile(rm);
+	if (prof_ind < 0)
+		return rc;
+	profile = &(ctl->tm_b_lvl_drop_profiles[prof_ind]);
+	__set_default_profile(profile);
+
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		prof_ind = rm_find_free_c_node_drop_profile(rm, cos);
+		if (prof_ind < 0)
+			return rc;
+		profile = &(ctl->tm_c_lvl_drop_profiles[cos][prof_ind]);
+		__set_default_profile(profile);
+	}
+	prof_ind = rm_find_free_port_drop_profile(rm);
+	if (prof_ind < 0) return rc;
+	profile = &(ctl->tm_p_lvl_drop_profiles[prof_ind]);
+	__set_default_profile(profile);
+	/* for port profiles  list is created ?*/
+	if (rm_list_create(rm, &list))
+		return rc;
+	profile->use_list = list;
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		prof_ind = rm_find_free_port_drop_profile_cos(rm, cos);
+		profile = &(ctl->tm_p_lvl_drop_profiles_cos[cos][prof_ind]);
+		__set_default_profile(profile);
+		if (rm_list_create(rm, &list))
+			return rc;
+		profile->use_list = list;
+	}
+	return 0;
+}
+
+
+int _tm_config_default_profiles_hw(tm_handle hndl)
+{
+	struct tm_drop_profile profile;
+	uint8_t cos;
+	int rc = TM_HW_WRED_CURVE_FAILED;
+	uint32_t portNo;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	__set_default_profile(&profile);
+
+	if (set_hw_queue_default_drop_profile(ctl, &profile) < 0)
+		return rc;
+	if (set_hw_a_nodes_default_drop_profile(ctl, &profile) < 0)
+		return rc;
+	if (set_hw_b_nodes_default_drop_profile(ctl, &profile) < 0)
+		return rc;
+	for (cos = 0; cos < TM_WRED_COS; cos++) {
+		if (set_hw_c_nodes_default_drop_profile(ctl,  &profile, cos) < 0)
+			return rc;
+	}
+	for (portNo = 0; portNo < get_tm_port_count() ; portNo++) {
+		if (set_hw_ports_default_drop_profile(ctl,  &profile, portNo) < 0)
+			return rc;
+		for (cos = 0; cos < TM_WRED_COS; cos++) {
+			if (set_hw_ports_default_drop_profile_cos(ctl,  &profile, cos, portNo) < 0)
+				return rc;
+		}
+	}
+	return 0;
+}
+
+
+int _tm_config_default_drop_sw(tm_handle hndl)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	rc = _tm_config_default_dp_mode(hndl, 0);
+	if (rc)
+		goto out;
+
+	rc = _tm_config_default_curves_sw(hndl);
+	if (rc)
+		goto out;
+
+	rc = _tm_config_default_profiles_sw(hndl);
+	if (rc)
+		goto out;
+
+out:
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+int _tm_config_default_drop_hw(tm_handle hndl)
+{
+	int rc;
+
+	rc = _tm_config_default_dp_mode(hndl, 1);
+	if (rc)
+		return rc;
+
+	rc = _tm_config_default_curves_hw(hndl);
+	if (rc)
+		return rc;
+
+	rc = _tm_config_default_profiles_hw(hndl);
+	if (rc)
+		return rc;
+	/* successful */
+	return 0;
+}
+
+
+/* Predefined Drop profiles */
+int tm_create_drop_profile_cbtd_100Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile_params profile;
+	int rc;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (level > P_LEVEL)
+		return -EPERM;
+
+	profile.cbtd_bw = 100000;
+	profile.cbtd_rtt_ratio = 0;
+	profile.wred_catd_bw = 0;
+	profile.aql_exp = 0;
+	profile.wred_catd_mode = DISABLED;
+	for (i = 0; i < 3; i++) {
+		profile.curve_id[i] = 0;
+		profile.dp_ratio[i] = 0;
+		profile.min_th[i] = 0;
+		profile.max_th[i] = 100;
+	}
+
+	rc = tm_create_drop_profile(ctl, level, cos, &profile, prof_index);
+	return rc;
+}
+
+
+int tm_create_drop_profile_wred_10Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile_params profile;
+	int rc;
+	int i;
+	uint8_t curve_ind;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (level > P_LEVEL)
+		return -EPERM;
+
+	rc = tm_create_wred_traditional_curve(ctl, level, cos, 50, &curve_ind);
+	if (rc)
+		return -ENOSPC;
+
+	profile.cbtd_bw = TM_MAX_BW;
+	profile.cbtd_rtt_ratio = 0;
+	profile.wred_catd_bw = 10000; /* 10Mb */
+	profile.aql_exp = 0;
+	profile.wred_catd_mode = WRED;
+	for (i = 0; i < 3; i++) {
+		profile.curve_id[i] = curve_ind;
+		profile.dp_ratio[i] = 0;
+		profile.min_th[i] = 10;
+		profile.max_th[i] = 100;
+	}
+
+	rc = tm_create_drop_profile(ctl, level, cos, &profile, prof_index);
+	return rc;
+}
+
+
+int tm_create_drop_profile_mixed_cbtd_100Mb_wred_10Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index)
+{
+	struct tm_drop_profile_params profile;
+	int rc;
+	int i;
+	uint8_t curve_ind;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (level > P_LEVEL)
+		return -EPERM;
+
+	rc = tm_create_wred_traditional_curve(ctl, level, cos, 50, &curve_ind);
+	if (rc)
+		return -ENOSPC;
+
+	profile.cbtd_bw = 100000;
+	profile.cbtd_rtt_ratio = 100;
+	profile.wred_catd_bw = 10000; /* 10Mb */
+	profile.aql_exp = 0;
+	profile.wred_catd_mode = WRED;
+	for (i = 0; i < 3; i++) {
+		profile.curve_id[i] = curve_ind;
+		profile.dp_ratio[i] = 0;
+		profile.min_th[i] = 0;
+		profile.max_th[i] = 100;
+	}
+
+	rc = tm_create_drop_profile(ctl, level, cos, &profile, prof_index);
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.h
new file mode 100644
index 0000000..86e49d6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_drop.h
@@ -0,0 +1,398 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef   	TM_DROP_H
+#define   	TM_DROP_H
+
+#include "tm_core_types.h"	 /* in order to define tm_handle */
+
+
+/** Create a WRED curve for a level.
+ * @param[in]	        	hndl	      TM lib handle
+ * @param[in]               level         A nodes level the WRED curve is created for
+ * @param[in]               cos	          CoS of RED Curve
+ * @param[in]               prob	      Array of 32 probability points (0-100%)
+ * @param[out]              curve_index   An index of a created WRED curve
+ *
+ * @note The cos parameter is relevant for C lvl only, else set TM_INVAL
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL        if hndl is NULL
+ * @retval -EBADF         if hndl is an invalid handle
+ * @retval -EADDRNOTAVAIL if level is invalid
+ * @retval -EPERM         if one of probabilities is out of range
+ * @retval -ENOSPC        if the WRED Curves table is fully allocated
+ * @retval -EBADMSG       if AQM Mode params are not configured for this lvl
+ * @retval TM_HW_WRED_CURVE_FAILED if download to HW fails
+ */
+int tm_create_wred_curve(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint8_t *prob,
+						uint8_t *curve_index);
+
+
+/** Create a WRED traditional curve for a level.
+ * @param[in]	        	hndl	      TM lib handle
+ * @param[in]               level         A nodes level the WRED curve is created for
+ * @param[in]               cos	          CoS of RED Curve
+ * @param[in]               mp  	      Non zero Max probability
+ * @param[out]              curve_index   An index of a created WRED curve
+ *
+ * @note The cos parameter is relevant for C lvl only, else set TM_INVAL.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL        if hndl is NULL
+ * @retval -EBADF         if hndl is an invalid handle
+ * @retval -EADDRNOTAVAIL if level is invalid
+ * @retval -ENOSPC        if the WRED Curves table is fully allocated
+ * @retval -EPERM         if max probability is not valid
+ * @retval -EBADMSG       if AQM Mode params are not configured for this lvl
+ * @retval TM_HW_WRED_CURVE_FAILED if download to HW fails
+ */
+int tm_create_wred_traditional_curve(tm_handle hndl,
+									 enum tm_level level,
+									 uint8_t cos,
+									 uint8_t mp,
+									 uint8_t *curve_index);
+
+/** Create a WRED flat curve for a level.
+ * @param[in]               hndl          TM lib handle
+ * @param[in]               level         A nodes level the WRED curve is created for
+ * @param[in]               cos           CoS of RED Curve
+ * @param[in]               cp            Non zero probability
+ * @param[out]              curve_index   An index of a created WRED curve
+ *
+ * @note The cos parameter is relevant for C lvl only, else set TM_INVAL.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL        if hndl is NULL
+ * @retval -EBADF         if hndl is an invalid handle
+ * @retval -EADDRNOTAVAIL if level is invalid
+ * @retval -ENOSPC        if the WRED Curves table is fully allocated
+ * @retval -EPERM         if curve probability is not valid
+ * @retval -EBADMSG       if AQM Mode params are not configured for this lvl
+ * @retval TM_HW_WRED_CURVE_FAILED if download to HW fails
+ */
+int tm_create_wred_flat_curve(tm_handle hndl,
+									 enum tm_level level,
+									 uint8_t cos,
+									 uint8_t cp,
+									 uint8_t *curve_index);
+
+
+/** Create Drop profile
+ * @param[in]       hndl         TM lib handle
+ * @param[in]       level        A nodes level to create a Drop profile for
+ * @param[in]       cos          CoS
+ * @param[in]       profile      Drop Profile configuration structure pointer
+ * @param[out]      prof_index   An index of the created Drop profile
+ *
+ * @note In case of Color Blind TD only set wred_catd_bw=0 and wred_catd_mode=CBTD_ONLY.
+ * @note In case of Color Blind TD disabled set cbtd_bw=TM_MAX_BW, cbtd_rtt_ratio=0.
+ * @note Cos of Drop Profile matches Cos of given curve.
+ * @note The CoS parameter is relevant for C and P level only,
+ *       else set TM_INVAL.
+ * @note For P level in Global mode set 'cos' = TM_INVAL, else
+ *       profile will be created for CoS mode.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL         if either hndl or profile is NULL
+ * @retval -EBADF          hndl is an invalid handle
+ * @retval -EPERM          if the level is invalid
+ * @retval -EACCES         if the wred_catd_bw or cbtd_bw is out of range
+ * @retval -EDOM           if wred/catd are not configured correctly
+ * @retval -EDOM           if cos in the profile is out of range
+ * @retval -ENODEV         if RED curve doesn't exist
+ * @retval -EFAULT         if exponents or index in the profile are out of range
+ * @retval -ENODATA        if wred_catd_mode is invalid
+ * @retval -ERANGE         if max_th is less that min_th
+ * @retval -ENOSPC         if level's Drop Profiles table is fully allocated
+ * @retval -EBADMSG        if AQM Mode params are not configured for this lvl
+ * @retval TM_HW_DROP_PROFILE_FAILED if download to HW fails
+*/
+int tm_create_drop_profile(tm_handle hndl,
+						   enum tm_level level,
+						   uint8_t cos,
+						   struct tm_drop_profile_params *profile,
+						   uint16_t *prof_index);
+
+
+/** Create 1G CBTD Drop profile
+ * @param[in] 		hndl      	 TM lib handle
+ * @param[in]       level        A nodes level to create a Drop profile for
+ * @param[in]       cos	         CoS
+ * @param[out]      prof_index	 An index of the created Drop profile
+ *
+ * @note The CoS parameter is relevant for C and P level only,
+ *       else set TM_INVAL.
+ * @note For P level in Global mode set 'cos' = TM_INVAL, else
+ *       profile will be created for CoS mode.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL         if either hndl or profile is NULL
+ * @retval -EBADF          hndl is an invalid handle
+ * @retval -EPERM          if the level is invalid
+ * @retval -EDOM           if cos in the profile is out of range
+ * @retval -ENOSPC         if level's Drop Profiles table is fully allocated
+ * @retval TM_HW_DROP_PROFILE_FAILED if download to HW fails
+*/
+int tm_create_drop_profile_1G(tm_handle hndl,
+						   enum tm_level level,
+						   uint8_t cos,
+						   uint16_t *prof_index);
+
+
+/** Create 2.5G CBTD Drop profile
+ * @param[in] 		hndl      	 TM lib handle
+ * @param[in]       level        A nodes level to create a Drop profile for
+ * @param[in]       cos	         CoS
+ * @param[out]      prof_index	 An index of the created Drop profile
+ *
+ * @note The CoS parameter is relevant for C and P level only,
+ *       else set TM_INVAL.
+ * @note For P level in Global mode set 'cos' = TM_INVAL, else
+ *       profile will be created for CoS mode.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL         if either hndl or profile is NULL
+ * @retval -EBADF          hndl is an invalid handle
+ * @retval -EPERM          if the level is invalid
+ * @retval -EDOM           if cos in the profile is out of range
+ * @retval -ENOSPC         if level's Drop Profiles table is fully allocated
+ * @retval TM_HW_DROP_PROFILE_FAILED if download to HW fails
+*/
+int tm_create_drop_profile_2_5G(tm_handle hndl,
+						   enum tm_level level,
+						   uint8_t cos,
+						   uint16_t *prof_index);
+
+
+/** Delete Drop profile
+ * @param[in] 	   hndl 	    TM lib handle
+ * @param[in]      level        A nodes level to delete a Drop profile for
+ * @param[in]      cos	        CoS
+ * @param[in]	   prof_index	An index to a profile to be deleted
+ *
+ * @note The CoS parameter is relevant for C and P level
+ *      only, else set TM_INVAL.
+ * @note For P level in Global mode set 'cos' = TM_INVAL, else
+ *       profile will be deleted for CoS mode.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL          if hndl is NULL
+ * @retval -EBADF           if hndl is an invalid handle
+ * @retval -EDOM            if the level is invalid
+ * @retval -EADDRNOTAVAIL   if prof_index is out of range
+ * @retval -EPERM           if profile is in use or reserved
+ * @retval -EFAULT          if no existing profile with this index
+ * @retval TM_HW_DROP_PROFILE_FAILED if download to HW fails
+*/
+int tm_delete_drop_profile(tm_handle hndl,
+						   enum tm_level level,
+						   uint8_t cos,
+						   uint16_t prof_index);
+
+
+/** Read Drop profile
+ * @param[in] 	   hndl	        TM lib handle
+ * @param[in]      level        A nodes level to read a Drop profile for
+ * @param[in]      cos	        CoS
+ * @param[in]	   prof_index	An index to a profile to be read out
+ * @param[in]      profile      Drop profile configuration struct pointer
+ *
+ * @note The cbtd_rtt_ratio calculated aproximately from the register's values
+ * @note The CoS parameter is relevant for C and P level only,
+ *       else set TM_INVAL.
+ * @note For P level in Global mode set 'cos' = TM_INVAL, else
+ *       profile will be read for CoS mode.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL           if hndl is NULL
+ * @retval -EBADF            if hndl is an invalid handle
+ * @retval -EPERM            if the level is invalid
+ * @retval -EADDRNOTAVAIL    if prof_index is out of range
+ * @retval -EFAULT           if no existing profile with this index
+ * @retval -EBADMSG          if AQM Mode params are not configured for this lvl
+ */
+int tm_read_drop_profile(tm_handle hndl,
+						 enum tm_level level,
+						 uint8_t cos,
+						 uint16_t prof_index,
+						 struct tm_drop_profile_params *profile);
+
+
+/** Set Drop (Egress) Colors number per level.
+ * @param[in] 	   hndl	        TM lib handle
+ * @param[in]      lvl          A nodes level to set colors number for
+ * @param[in]      num          Colors number
+ *
+ * @note This API should be called before all the rest Drop APIs (if
+ * need). By default there are two colors per each level.
+ * @note In case TM2TM usage, instead if this API should be called 'tm2tm_set_egress_drop_aqm_mode'.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL           if hndl is NULL
+ * @retval -EBADF            if hndl is an invalid handle
+ * @retval -EPERM            if level is invalid
+ * @retval -EFAULT           if num is invalid
+ * @retval TM_HW_COLOR_NUM_CONFIG_FAIL if download to HW fails
+ */
+int tm_set_drop_color_num(tm_handle hndl,
+						  enum tm_level lvl,
+						  enum tm_color_num num);
+
+
+/**  Change Drop Probability (DP) source.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     lvl         A nodes level to set source for
+ *   @param[in]     color       A color to set source for (0,1,2)
+ *   @param[in]     source      QL or AQL (0 - use AQL, 1 - use QL to calculate DP)
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF  if hndl is invalid.
+ *   @retval -EPERM  if level is invalid.
+ *   @retval -ENODEV if color is invalid.
+ *   @retval -EFAULT if status is out of range.
+ *   @retval TM_HW_AQM_CONFIG_FAIL if download to HW fails
+ */
+int tm_dp_source_set(tm_handle hndl,
+						enum tm_level lvl,
+						uint8_t color,
+						enum tm_dp_source source);
+
+
+/** Drop Query Response Select.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     port_dp     0 - Global, 1 - CoS.
+ *   @param[in]     lvl         Local response level (Q/A/B/C/Port).
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_dp is invalid.
+ *   @retval -EPERM if lvl out of range.
+ *   @retval TM_HW_DP_QUERY_RESP_CONF_FAILED if download to HW
+ *           fails.
+ */
+int tm_set_drop_query_responce(tm_handle hndl,
+							   uint8_t port_dp,
+							   enum tm_level lvl);
+
+
+/** Drop Queue Cos Select.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     index       Queue index.
+ *   @param[in]     cos         Cos.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if index or cos is invalid.
+ *   @retval TM_HW_QUEUE_COS_CONF_FAILED if download to HW fails.
+ */
+int tm_set_drop_queue_cos(tm_handle hndl,
+						  uint32_t index,
+						  uint8_t cos);
+
+
+/****************************************************************************************/
+/* functions for internal usage */
+
+/** Set default Drop configuration (curves & profiles) per level in database
+ * @param[in] 	   hndl	        TM lib handle
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL           if hndl is NULL
+ * @retval -EBADF            if hndl is an invalid handle
+ * @retval -ENOSPC           if level's Drop Profiles/WRED Curves table is fully allocated
+ */
+int _tm_config_default_drop_sw(tm_handle hndl);
+
+
+/** Set default values to drop related registers
+ * @param[in] 	   hndl	        TM lib handle
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL           if hndl is NULL
+ * @retval -EBADF            if hndl is an invalid handle
+ * @retval TM_HW_WRED_CURVE_FAILED if download to HW Curves fails
+ * @retval TM_HW_DROP_PROFILE_FAILED if download to HW Drop Profiles fails
+ */
+int _tm_config_default_drop_hw(tm_handle hndl);
+
+
+/* Predefined Drop profiles */
+int tm_create_drop_profile_cbtd_100Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index);
+
+
+int tm_create_drop_profile_wred_10Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index);
+
+
+int tm_create_drop_profile_mixed_cbtd_100Mb_wred_10Mb(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t *prof_index);
+
+
+int tm_update_drop_profile(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t index,
+						struct tm_drop_profile_params *profile);
+
+
+int tm_drop_profile_hw_set(tm_handle hndl,
+						enum tm_level level,
+						uint8_t cos,
+						uint16_t index);
+
+
+#endif   /* TM_DROP_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.c
new file mode 100644
index 0000000..367f68a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.c
@@ -0,0 +1,569 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_elig_prio_func.h"
+#include "tm_errcodes.h"
+#include "set_hw_registers.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_locking_interface.h"
+#include "rm_status.h"
+
+
+/* Auxiliary function */
+static uint16_t convert_elig_func_to_value(struct tm_elig_prio_func_out *elig_func)
+{
+	uint16_t var;
+
+	var = elig_func->max_tb;
+	var = var | (elig_func->min_tb << 1);
+	var = var | (elig_func->prop_prio << 2);
+	var = var | (elig_func->sched_prio << 5);
+	var = var | (elig_func->elig << 8);
+
+	return var;
+}
+
+#if 0
+static void convert_value_to_elig_func(uint16_t elig_val, struct tm_elig_prio_func_out *elig_func)
+{
+	/*
+	FuncOut[8]   - Elig.
+	FuncOut[7:5] - Scheduling Priority.
+	FuncOut[4:2] - Propagated Priority.
+	FuncOut[1]   - Use Min Token Bucket.
+	FuncOut[0]   - Use Max Token Bucket.
+	*/
+	uint8_t mask = 0x07;
+
+	elig_func->elig = (elig_val >> 8) & 0x01;
+	elig_func->max_tb = elig_val & 0x01;
+	elig_func->min_tb = elig_val & 0x02;
+	elig_func->prop_prio = (elig_val >> 2) & mask;
+	elig_func->sched_prio = (elig_val >> 5) & mask;
+}
+#endif
+
+static void set_sw_q_elig_prio_func(struct tm_elig_prio_func_queue *func_table,
+									uint16_t func_offset,
+									union tm_elig_prio_func *queue_func_out_arr)
+{
+	func_table[func_offset].tbl_entry.func_out[0] =
+		convert_elig_func_to_value(&(queue_func_out_arr->queue_elig_prio_func[0]));
+	func_table[func_offset].tbl_entry.func_out[1] =
+		convert_elig_func_to_value(&(queue_func_out_arr->queue_elig_prio_func[1]));
+	func_table[func_offset].tbl_entry.func_out[2] =
+		convert_elig_func_to_value(&(queue_func_out_arr->queue_elig_prio_func[2]));
+	func_table[func_offset].tbl_entry.func_out[3] =
+		convert_elig_func_to_value(&(queue_func_out_arr->queue_elig_prio_func[3]));
+}
+
+/**
+ */
+static void set_sw_n_elig_prio_func(struct tm_elig_prio_func_node *func_table,
+									uint16_t func_offset,
+									union tm_elig_prio_func *node_func_out_arr)
+{
+	int i;
+	for (i = 0; i < 8; i++)	{
+		/* Entry ID */
+		func_table[func_offset].tbl_entry[i].func_out[0] =
+			convert_elig_func_to_value(&(node_func_out_arr->node_elig_prio_func[i][0]));
+		func_table[func_offset].tbl_entry[i].func_out[1] =
+			convert_elig_func_to_value(&(node_func_out_arr->node_elig_prio_func[i][1]));
+		func_table[func_offset].tbl_entry[i].func_out[2] =
+			convert_elig_func_to_value(&(node_func_out_arr->node_elig_prio_func[i][2]));
+		func_table[func_offset].tbl_entry[i].func_out[3] =
+			convert_elig_func_to_value(&(node_func_out_arr->node_elig_prio_func[i][3]));
+	}
+}
+/**
+ */
+int tm_elig_prio_func_config(tm_handle hndl,
+							uint16_t elig_prio_func_index,
+							enum tm_level level,
+							union tm_elig_prio_func *func_value_arr)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (elig_prio_func_index >= TM_ELIG_FUNC_TABLE_SIZE)
+		return -EDOM;
+	/* TM_ELIG_Q_DEQ_DIS function udate is not allowed */
+	if (elig_prio_func_index == TM_ELIG_DEQ_DISABLE)
+		return -EDOM;
+	/* TM_NODE_DISABLED_FUN  slot is for internal use */
+	if (elig_prio_func_index == TM_NODE_DISABLED_FUN)
+		return -EDOM;
+
+	switch (level)
+	{
+		case Q_LEVEL:	{
+			/* Update SW image for queue level */
+			set_sw_q_elig_prio_func(ctl->tm_elig_prio_q_lvl_tbl, elig_prio_func_index, func_value_arr);
+			/* update HW */
+			rc = set_hw_q_elig_prio_func_entry(hndl, elig_prio_func_index);
+			break;
+		}
+		case A_LEVEL:	{
+			/* Update SW image for A node level */
+			set_sw_n_elig_prio_func(ctl->tm_elig_prio_a_lvl_tbl, elig_prio_func_index, func_value_arr);
+			/* update HW */
+			rc = set_hw_a_lvl_elig_prio_func_entry(hndl, elig_prio_func_index);
+			break;
+		}
+		case B_LEVEL:	{
+			/* Update SW image for B node level */
+			set_sw_n_elig_prio_func(ctl->tm_elig_prio_b_lvl_tbl, elig_prio_func_index, func_value_arr);
+			/* update HW */
+			rc = set_hw_b_lvl_elig_prio_func_entry(hndl, elig_prio_func_index);
+			break;
+		}
+		case C_LEVEL:	{
+			/* Update SW image for C node level */
+			set_sw_n_elig_prio_func(ctl->tm_elig_prio_c_lvl_tbl, elig_prio_func_index, func_value_arr);
+			/* update HW */
+			rc = set_hw_c_lvl_elig_prio_func_entry(hndl, elig_prio_func_index);
+			break;
+		}
+		case P_LEVEL:	{
+			/* Update SW image for Port level */
+			set_sw_n_elig_prio_func(ctl->tm_elig_prio_p_lvl_tbl, elig_prio_func_index, func_value_arr);
+			/* update HW */
+			rc = set_hw_p_lvl_elig_prio_func_entry(hndl, elig_prio_func_index);
+			break;
+		}
+		default: return -EADDRNOTAVAIL;
+	}
+	if (rc)
+		rc = -TM_HW_ELIG_PRIO_FUNC_FAILED;
+	return rc;
+}
+
+/**
+ */
+int tm_elig_prio_func_config_all_levels(tm_handle hndl,
+									uint16_t elig_prio_func_ptr,
+									union tm_elig_prio_func *func_value_arr)
+{
+
+	enum tm_level lvl;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (elig_prio_func_ptr >= TM_ELIG_FUNC_TABLE_SIZE)	{
+		rc = -EDOM;
+		goto out;
+	}
+
+	for (lvl = A_LEVEL; lvl <= P_LEVEL; lvl++)	{
+		rc = tm_elig_prio_func_config(ctl, elig_prio_func_ptr, lvl, func_value_arr);
+		if (rc)	{
+			rc = -TM_HW_ELIG_PRIO_FUNC_FAILED;
+			goto out;
+		}
+	}
+out:
+	return rc;
+}
+
+int tm_node_elig_set(tm_handle hndl, enum tm_level level, uint32_t index, uint8_t prio)
+{
+	int rc = 0;
+	uint8_t status;
+	uint8_t *elig_prio_func_ptr;
+	uint8_t type;
+	uint8_t current_prio;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check if node exists */
+	switch (level) {
+	case A_LEVEL:
+		if (index >= rm->rm_total_a_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case B_LEVEL:
+		if (index >= rm->rm_total_b_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case C_LEVEL:
+		if (index >= rm->rm_total_c_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case P_LEVEL:
+		if (index >= rm->rm_total_ports) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+	rc = rm_node_status(rm, level, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case A_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_a_node_array[index].elig_prio_func_ptr);
+		break;
+	case B_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_b_node_array[index].elig_prio_func_ptr);
+		break;
+	case C_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_c_node_array[index].elig_prio_func_ptr);
+		break;
+	case P_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_port_array[index].elig_prio_func_ptr);
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+
+	DECODE_ELIGIBLE_FUN(*elig_prio_func_ptr, type, current_prio);
+	/* test validity */
+	if (IS_VALID_N_TYPE_PRIO(type, current_prio)) /* valid previous eligible function */
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(type, prio);
+	else {
+		/* in case of disabled nodes or invalid eligible functions (set through direct API)
+		   eligible function is set to fixed priority
+		*/
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, prio);
+	}
+
+	/* Download to HW */
+	switch (level) {
+	case A_LEVEL:
+		rc = set_hw_a_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case P_LEVEL:
+		rc = set_hw_port_elig_prio_func_ptr(ctl, index);
+		break;
+	case Q_LEVEL:
+	default:
+		rc = -EACCES;
+	}
+	if (rc)
+		rc = TM_HW_ELIG_PRIO_FUNC_FAILED;
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+int tm_node_elig_set_propagated(tm_handle hndl, enum tm_level level, uint32_t index)
+{
+	int rc = 0;
+	uint8_t status;
+	uint8_t *elig_prio_func_ptr;
+	uint8_t type;
+	uint8_t current_prio;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check if node exists */
+	switch (level) {
+	case A_LEVEL:
+		if (index >= rm->rm_total_a_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case B_LEVEL:
+		if (index >= rm->rm_total_b_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case C_LEVEL:
+		if (index >= rm->rm_total_c_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case P_LEVEL:
+		if (index >= rm->rm_total_ports) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+	rc = rm_node_status(rm, level, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case A_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_a_node_array[index].elig_prio_func_ptr);
+		break;
+	case B_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_b_node_array[index].elig_prio_func_ptr);
+		break;
+	case C_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_c_node_array[index].elig_prio_func_ptr);
+		break;
+	case P_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_port_array[index].elig_prio_func_ptr);
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+
+	DECODE_ELIGIBLE_FUN(*elig_prio_func_ptr, type, current_prio);
+	/* test validity */
+	if (IS_VALID_N_TYPE_PRIO(type, current_prio)) /* valid previous eligible function */
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(type, PRIO_P);
+	else {
+		/* in case of disabled nodes or invalid eligible functions (set through direct API)
+		   eligible function is set to fixed priority
+		*/
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_P);
+	}
+
+	/* Download to HW */
+	switch (level) {
+	case A_LEVEL:
+		rc = set_hw_a_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case P_LEVEL:
+		rc = set_hw_port_elig_prio_func_ptr(ctl, index);
+		break;
+	case Q_LEVEL:
+	default:
+		rc = -EACCES;
+	}
+	if (rc)
+		rc = TM_HW_ELIG_PRIO_FUNC_FAILED;
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+int tm_queue_elig_set(tm_handle hndl, uint32_t index, uint8_t prio)
+{
+	int rc = 0;
+	uint8_t status;
+	uint8_t type;
+	uint8_t current_prio;
+	uint8_t *elig_prio_func_ptr;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check if queue exists */
+	if (index >= rm->rm_total_queues) {
+		rc = -EBADMSG;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, Q_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	elig_prio_func_ptr = &(ctl->tm_queue_array[index].elig_prio_func_ptr);
+
+	DECODE_ELIGIBLE_FUN(*elig_prio_func_ptr, type, current_prio);
+	/* test validity */
+	if (IS_VALID_Q_TYPE_PRIO(type, current_prio)) /* valid previous eligible function */
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(type, prio);
+	else {
+		/* in case of disabled nodes or invalid eligible functions (set through direct API)
+		   eligible function is set to fixed priority
+		*/
+		*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, prio);
+	}
+
+	/* Download to HW */
+	rc = set_hw_queue_elig_prio_func_ptr(ctl, index);
+	if (rc)
+		rc = TM_HW_ELIG_PRIO_FUNC_FAILED;
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+int tm_get_node_elig_prio_fun_info(tm_handle hndl, enum tm_level level, uint32_t index, uint8_t *prio, uint8_t *pmask)
+{
+	int rc = -EFAULT;
+	uint8_t	prio_fun;
+	uint8_t	mask;
+	uint16_t elig_func_table[32];
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	mask = 0;
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = get_hw_queue_elig_prio_func_ptr(hndl, index, &prio_fun);
+		if (rc == 0) {
+			rc = get_hw_elig_prio_func(hndl, level, prio_fun , elig_func_table);
+			if (rc == 0) {
+				for (i = 0; i < 4 ; i++)
+					mask = mask | (elig_func_table[i] & 0x3);
+			}
+		}
+		break;
+	case A_LEVEL:
+		rc = get_hw_a_node_elig_prio_func_ptr(hndl, index, &prio_fun);
+		if (rc == 0) {
+			rc = get_hw_elig_prio_func(hndl, level, prio_fun , elig_func_table);
+			if (rc == 0) {
+				for (i = 0; i < 32 ; i++)
+					mask = mask | (elig_func_table[i] & 0x3);
+			}
+		}
+		break;
+	case B_LEVEL:
+		rc = get_hw_b_node_elig_prio_func_ptr(hndl, index, &prio_fun);
+		if (rc == 0) {
+			rc = get_hw_elig_prio_func(hndl, level, prio_fun , elig_func_table);
+			if (rc == 0) {
+				for (i = 0; i < 32 ; i++)
+					mask = mask | (elig_func_table[i] & 0x3);
+			}
+		}
+		break;
+	case C_LEVEL:
+		rc = get_hw_c_node_elig_prio_func_ptr(hndl, index, &prio_fun);
+		if (rc == 0) {
+			rc = get_hw_elig_prio_func(hndl, level, prio_fun , elig_func_table);
+			if (rc == 0) {
+				for (i = 0; i < 32 ; i++)
+					mask = mask | (elig_func_table[i] & 0x3);
+			}
+		}
+		break;
+	case P_LEVEL:
+		rc = get_hw_port_elig_prio_func_ptr(hndl, index, &prio_fun);
+		if (rc == 0) {
+			rc = get_hw_elig_prio_func(hndl, level, prio_fun , elig_func_table);
+			if (rc == 0) {
+				for (i = 0; i < 32 ; i++)
+					mask = mask | (elig_func_table[i] & 0x3);
+			}
+		}
+		break;
+	}
+	if (rc == 0) {
+		if (prio)
+			*prio = prio_fun;
+		if (pmask)
+			*pmask = mask;
+	}
+	return rc;
+}
+
+
+
+int is_queue_elig_fun_uses_shaper(struct tm_elig_prio_func_queue *queue_func_table, uint8_t func_index)
+{
+	int mask;
+	if (func_index >= TM_ELIG_FUNC_TABLE_SIZE)
+		return -1;
+	/* if minTB or maxTB bit is used in at least one entry - this function uses shaper */
+	mask = 0;
+	mask = mask | (queue_func_table[func_index].tbl_entry.func_out[0] & 0x3);
+	mask = mask | (queue_func_table[func_index].tbl_entry.func_out[1] & 0x3);
+	mask = mask | (queue_func_table[func_index].tbl_entry.func_out[2] & 0x3);
+	mask = mask | (queue_func_table[func_index].tbl_entry.func_out[3] & 0x3);
+	return mask;
+}
+
+int is_node_elig_fun_uses_shaper(struct tm_elig_prio_func_node *node_func_table, uint8_t func_index)
+{
+	int i;
+	int mask;
+	if (func_index >= TM_ELIG_FUNC_TABLE_SIZE)
+		return -1;
+	mask = 0;
+	for (i = 0; i < 8 ; i++) {
+		/* if minTB or maxTB bit is used in at least one entry - this function uses shaper */
+		mask = mask | (node_func_table[func_index].tbl_entry[i].func_out[0] & 0x3);
+		mask = mask | (node_func_table[func_index].tbl_entry[i].func_out[1] & 0x3);
+		mask = mask | (node_func_table[func_index].tbl_entry[i].func_out[2] & 0x3);
+		mask = mask | (node_func_table[func_index].tbl_entry[i].func_out[3] & 0x3);
+	}
+	return mask;
+}
+
+
+/**
+ */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.h
new file mode 100644
index 0000000..0616af8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_elig_prio_func.h
@@ -0,0 +1,163 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_ELIG_PRIO_H
+#define TM_ELIG_PRIO_H
+
+#include "tm_core_types.h"
+
+/** Configure the Eligible Priority Function according
+*   to the User Application parameters
+*
+*	The new Eligible Priority Function is written to the
+*	proper Queue or Node level Eligible Table.
+*	A pointer in the API is provided to the location of the new Eligible Priority Function in the table.
+*
+*	Note:	The use of Eligible Function Pointer 63 on both Queue and Node level is forbidden.
+*			Eligible Function 63 is reserved to indicate that Queue/Node is not eligible.
+*
+*	@param[in]	hndl					TM lib handle
+*	@param[in]	elig_prio_func_ptr		The new configured eligible function pointer
+*	@param[in]	level					A level to configure the Eligible function with
+*	@param[in]	func_out_arr			The Eligible Priority Function structure array pointer
+*
+*   @retval zero on success.
+*   @retval -EINVAL if hndl is NULL.
+*   @retval -EBADF if hndl is an invalid handle.
+*	@retval -EDOM  if (elig_prio_func_ptr > 63)
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+int tm_elig_prio_func_config(tm_handle hndl,
+							 uint16_t elig_prio_func_ptr,
+							 enum tm_level level,
+							 union tm_elig_prio_func *func_out_arr);
+
+
+/** Configure the Eligible Priority Function according
+*   to the User Application parameters
+*
+*	The following API configures the same Eligible Priority Functions
+*	at all nodes (A, B, C, and Port) levels Elig. Prio. Tables
+*	according to the user?s parameters.
+*	It has the same functionality as tm_elig_prio_func_config()
+*	and can be used at the user convenience to configure the
+*	same eligible function to all the Nodes levels (except for Q level)
+*
+*	Note:	The use of Eligible Function Pointer 63 on both Queue and Node level is forbidden.
+*			Eligible Function 63 is reserved to indicate that Queue/Node is not eligible.
+*
+*	@param[in]	hndl					TM lib handle
+*	@param[in]	elig_prio_func_ptr		The new configured eligible function pointer
+*	@param[in]	func_out_arr			The Eligible Priority Function structure array pointer
+*
+*   @retval zero on success.
+*   @retval -EINVAL if hndl is NULL.
+*   @retval -EBADF if hndl is an invalid handle.
+*	@retval -EDOM  if (elig_prio_func_ptr > 63)
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+int tm_elig_prio_func_config_all_levels(tm_handle hndl,
+										uint16_t elig_prio_func_ptr,
+										union tm_elig_prio_func *func_out_arr);
+
+
+/** Configure the Eligible Priority Function to Node
+*
+*	@param[in]	hndl					TM lib handle
+*	@param[in]	level					Node level (P/C/B/A)
+*	@param[in]	index					Node index
+*	@param[in]	prio					The Eligible Priority Function pointer
+*
+*   @retval zero on success.
+*   @retval -EINVAL  if hndl is NULL.
+*   @retval -EBADF   if hndl is an invalid handle.
+*	@retval -EACCES  if level/prio is out of range
+*	@retval -EBADMSG if index is out of range
+*	@retval -EPERM if node is not in use
+*	@retval -ENODATA if unsupported case
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+int tm_node_elig_set(tm_handle hndl, enum tm_level level, uint32_t index, uint8_t prio);
+
+
+/** Configure the Eligible Priority Function to Queue
+*
+*	@param[in]	hndl					TM lib handle
+*	@param[in]	index					Queue index
+*	@param[in]	prio					The Eligible Priority Function pointer
+*
+*   @retval zero on success.
+*   @retval -EINVAL  if hndl is NULL.
+*   @retval -EBADF   if hndl is an invalid handle.
+*	@retval -EACCES  if prio is out of range
+*	@retval -EBADMSG if index is out of range
+*	@retval -EPERM if queue is not in use
+*	@retval -ENODATA if unsupported case
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+int tm_queue_elig_set(tm_handle hndl, uint32_t index, uint8_t prio);
+
+
+/** Configure the Eligible Node Priority as propagated priority (without shaping)
+*
+*	@param[in]	hndl					TM lib handle
+*	@param[in]	level					Node level (P/C/B/A)
+*	@param[in]	index					Node index
+
+*   @retval zero on success.
+*   @retval -EINVAL  if hndl is NULL.
+*   @retval -EBADF   if hndl is an invalid handle.
+*	@retval -EACCES  if level/prio is out of range
+*	@retval -EBADMSG if index is out of range
+*	@retval -EPERM if node is not in use
+*	@retval -ENODATA if unsupported case
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+
+int tm_node_elig_set_propagated(tm_handle hndl, enum tm_level level, uint32_t index);
+
+
+int tm_get_node_elig_prio_fun_info(tm_handle hndl, enum tm_level level, uint32_t index, uint8_t *prio, uint8_t *mask);
+
+
+
+int is_queue_elig_fun_uses_shaper(struct tm_elig_prio_func_queue *queue_func_table,
+									uint8_t func_index);
+
+int is_node_elig_fun_uses_shaper(struct tm_elig_prio_func_node *node_func_table,
+									uint8_t func_index);
+
+
+/* Auxiliary function
+uint16_t convert_elig_func_to_value(struct tm_elig_prio_func_out *elig_func);
+
+void convert_value_to_elig_func(uint16_t elig_val, struct tm_elig_prio_func_out *elig_func);
+
+ */
+#endif   /* TM_ELIG_PRIO_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_errcodes.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errcodes.h
new file mode 100644
index 0000000..0354251
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errcodes.h
@@ -0,0 +1,166 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef   	TM_ERRCODES_H
+#define   	TM_ERRCODES_H
+
+/** HW error codes */
+enum tm_hw_err_codes
+{
+	TM_HW_GEN_CONFIG_FAILED = 1,            /**< 1 */
+	TM_HW_WRED_CURVE_FAILED,                /**< 2 */
+	TM_HW_DROP_PROFILE_FAILED,              /**< 3 */
+	TM_HW_CONF_PER_SCHEME_FAILED,           /**< 4 */
+	TM_HW_TREE_CONFIG_FAIL,                 /**< 5 */
+	TM_HW_AGING_CONFIG_FAIL,                /**< 6 */
+	TM_HW_PORT_CONFIG_FAIL,                 /**< 7 */
+	TM_HW_C_NODE_CONFIG_FAIL,               /**< 8 */
+	TM_HW_B_NODE_CONFIG_FAIL,               /**< 9 */
+	TM_HW_A_NODE_CONFIG_FAIL,               /**< 10 */
+	TM_HW_QUEUE_CONFIG_FAIL,				/**< 11 */
+	TM_HW_CHANGE_SHAPING_STATUS_FAILED,     /**< 12 */
+	TM_HW_PORT_DWRR_BYTES_PER_BURST_FAILED, /**< 13 */
+	TM_HW_QMR_GET_ERRORS_FAILED,            /**< 14 */
+	TM_HW_BAP_GET_ERRORS_FAILED,            /**< 15 */
+	TM_HW_RCB_GET_ERRORS_FAILED,            /**< 16 */
+	TM_HW_SCHED_GET_ERRORS_FAILED,          /**< 17 */
+	TM_HW_DROP_GET_ERRORS_FAILED,           /**< 18 */
+	TM_HW_SHAPING_PROF_FAILED,              /**< 19 */
+	TM_HW_READ_PORT_STATUS_FAIL,            /**< 20 */
+	TM_HW_READ_C_NODE_STATUS_FAIL,          /**< 21 */
+	TM_HW_READ_B_NODE_STATUS_FAIL,          /**< 22 */
+	TM_HW_READ_A_NODE_STATUS_FAIL,          /**< 23 */
+	TM_HW_READ_QUEUE_STATUS_FAIL,           /**< 24 */
+	TM_HW_GET_QUEUE_LENGTH_FAIL,            /**< 25 */
+	TM_HW_GET_QMR_PKT_STAT_FAILED,          /**< 26 */
+	TM_HW_GET_RCB_PKT_STAT_FAILED,          /**< 27 */
+	TM_HW_SET_SMS_PORT_ATTR_FAILED,         /**< 28 */
+	TM_HW_ELIG_PRIO_FUNC_FAILED,            /**< 29 */
+	TM_HW_AQM_CONFIG_FAIL,                  /**< 30 */
+	TM_HW_COLOR_NUM_CONFIG_FAIL,            /**< 31 */
+	TM_HW_DP_QUERY_RESP_CONF_FAILED,        /**< 32 */
+	TM_HW_QUEUE_COS_CONF_FAILED,            /**< 33 */
+	TM_HW_TM2TM_GLOB_CONF_FAILED,           /**< 34 */
+	TM_HW_TM2TM_CHANNEL_CONF_FAILED,        /**< 35 */
+	TM_HW_TM2TM_LC_CONF_FAILED,             /**< 36 */
+	TM_HW_TM2TM_ENABLE_FAILED,              /**< 37 */
+
+	TM_HW_MAX_ERROR						/**< 38 */
+};
+
+/** SW (configuration) error codes */
+enum tm_conf_err_codes
+{
+	TM_CONF_INVALID_PROD_NAME = TM_HW_MAX_ERROR + 1, /**< 39 */ /* GT_BAD_VALUE */
+	TM_CONF_PER_RATE_L_K_N_NOT_FOUND,      /**< 40 */ /* GT_BAD_VALUE */
+	TM_CONF_RES_INC_BW_TS_NOT_FOUND,       /**< 41 */ /* GT_BAD_VALUE */
+	TM_CONF_RES_ACC_NOT_FOUND,             /**< 42 */ /* GT_BAD_VALUE */
+	TM_CONF_NON_RES_ACC_NOT_FOUND,         /**< 43 */ /* GT_BAD_VALUE */
+	TM_CONF_RES_INC_BW_TS_LESS_ONE,        /**< 44 */ /* GT_BAD_VALUE */
+	TM_CONF_BANK_UPD_RATE_NOT_FOUND,       /**< 45 */ /* GT_BAD_VALUE */
+	TM_CONF_UPD_RATE_NOT_FOUND,            /**< 46 */ /* GT_BAD_VALUE */
+	TM_CONF_NON_RES_INC_BW_TS_LESS_ONE,    /**< 47 */ /* GT_BAD_VALUE */
+	TM_CONF_PORT_IND_OOR,                  /**< 48 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_PORT_QUANTUM_OOR,              /**< 49 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_PORT_DWRR_PRIO_OOR,            /**< 50 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_P_WRED_PROF_REF_OOR,           /**< 51 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_PORT_BW_OOR,                   /**< 52 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_PORT_BS_OOR,                   /**< 53 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_Q_SHAPING_PROF_REF_OOR,        /**< 54 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_Q_QUANTUM_OOR,                 /**< 55 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_Q_WRED_PROF_REF_OOR,           /**< 56 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_A_NODE_IND_OOR,                /**< 57 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_A_SHAPING_PROF_REF_OOR,        /**< 58 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_A_QUANTUM_OOR,                 /**< 59 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_A_DWRR_PRIO_OOR,               /**< 60 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_A_WRED_PROF_REF_OOR,           /**< 61 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_B_NODE_IND_OOR,                /**< 62 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_B_SHAPING_PROF_REF_OOR,        /**< 63 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_B_QUANTUM_OOR,                 /**< 64 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_B_DWRR_PRIO_OOR,               /**< 65 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_B_WRED_PROF_REF_OOR,           /**< 66 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_NODE_IND_OOR,                /**< 67 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_SHAPING_PROF_REF_OOR,        /**< 68 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_QUANTUM_OOR,                 /**< 69 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_DWRR_PRIO_OOR,               /**< 70 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_WRED_PROF_REF_OOR,           /**< 71 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_C_WRED_COS_OOR,                /**< 72 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_ELIG_PRIO_FUNC_ID_OOR,         /**< 73 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_DP_COS_SEL_OOR,                /**< 74 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_EXT_HDR_SIZE_OOR,              /**< 75 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_CTRL_PKT_STR_OOR,              /**< 76 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_DELTA_RANGE_OOR,               /**< 77 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_EGR_ELEMS_OOR,           /**< 78 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_SRC_LVL_OOR,             /**< 79 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_BP_LVL_OOR,              /**< 80 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_BP_THRESH_OOR,           /**< 81 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_DP_LVL_OOR,              /**< 82 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_CTRL_HDR_OOR,            /**< 83 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_TM2TM_PORT_FOR_CTRL_PKT_OOR,   /**< 84 */ /* GT_OUT_OF_RANGE */
+	TM_CONF_PORT_SPEED_OOR,                /**< 85 */ /* GT_BAD_PARAM */
+	TM_CONF_PORT_MIN_SHAP_NOT_INC_BW_MULT, /**< 86 */ /* GT_BAD_PARAM */
+	TM_CONF_PORT_MAX_SHAP_NOT_INC_BW_MULT, /**< 87 */ /* GT_BAD_PARAM */
+	TM_CONF_PORT_SHAP_MAX_NOT_MULT_MIN,    /**< 88 */ /* GT_BAD_PARAM */
+	TM_CONF_PORT_BW_OUT_OF_SPEED,          /**< 89 */ /* GT_BAD_PARAM */
+	TM_CONF_INVALID_NUM_OF_C_NODES,        /**< 90 */ /* GT_BAD_PARAM */
+	TM_CONF_INVALID_NUM_OF_B_NODES,        /**< 91 */ /* GT_BAD_PARAM */
+	TM_CONF_INVALID_NUM_OF_A_NODES,        /**< 92 */ /* GT_BAD_PARAM */
+	TM_CONF_INVALID_NUM_OF_QUEUES,         /**< 93 */ /* GT_BAD_PARAM */
+	TM_CONF_LVL_MIN_BW_VIOLATION,          /**< 94 */ /* GT_BAD_PARAM */
+	TM_CONF_LVL_MAX_BW_VIOLATION,          /**< 95 */ /* GT_BAD_PARAM */
+	TM_CONF_LVL_MIN_INC_VIOLATION,         /**< 96 */ /* GT_BAD_PARAM */
+	TM_CONF_LVL_MIN_NOT_MULT_INC,          /**< 97 */ /* GT_BAD_PARAM */
+	TM_CONF_LVL_MAX_NOT_MULT_INC,          /**< 98 */ /* GT_BAD_PARAM */
+	TM_CONF_TM2TM_AQM_INVALID_COLOR_NUM,   /**< 99 */ /* GT_BAD_PARAM */
+	TM_CONF_MIN_SHAP_NOT_INC_BW_MULT,      /**< 100 */ /* GT_BAD_PARAM */
+	TM_CONF_MAX_SHAP_NOT_INC_BW_MULT,      /**< 101 */ /* GT_BAD_PARAM */
+	TM_CONF_SHAP_MAX_NOT_MULT_MIN,         /**< 102 */ /* GT_BAD_PARAM */
+	TM_CONF_SHAP_MIN_NOT_MULT_MIN,         /**< 103 */ /* GT_BAD_PARAM */
+	TM_CONF_REORDER_NODES_NOT_ADJECENT,    /**< 104 */ /* GT_BAD_PARAM */
+	TM_CONF_MIN_TOKEN_TOO_LARGE,           /**< 105 */ /* GT_BAD_SIZE */
+	TM_CONF_MAX_TOKEN_TOO_LARGE,           /**< 106 */ /* GT_BAD_SIZE */
+	TM_CONF_PORT_MIN_TOKEN_TOO_LARGE,      /**< 107 */ /* GT_BAD_SIZE */
+	TM_CONF_PORT_MAX_TOKEN_TOO_LARGE,      /**< 108 */ /* GT_BAD_SIZE */
+	TM_CONF_MAX_BW_TS_TOO_LARGE,           /**< 109 */ /* GT_BAD_SIZE */
+	TM_CONF_REORDER_CHILDREN_NOT_AVAIL,    /**< 110 */ /* GT_BAD_SIZE */
+	TM_CONF_PORT_IND_NOT_EXIST,            /**< 111 */ /* GT_BAD_STATE */
+	TM_CONF_A_NODE_IND_NOT_EXIST,          /**< 112 */ /* GT_BAD_STATE */
+	TM_CONF_B_NODE_IND_NOT_EXIST,          /**< 113 */ /* GT_BAD_STATE */
+	TM_CONF_C_NODE_IND_NOT_EXIST,          /**< 114 */ /* GT_BAD_STATE */
+	TM_CONF_CANNT_GET_LAD_FREQUENCY,       /**< 115 */ /* GT_GET_ERROR/? possibly not rel for CPSS */
+	TM_CONF_UPD_RATE_NOT_CONF_FOR_LEVEL,   /**< 116 */ /* GT_NOT_INITIALIZED */
+	TM_CONF_TM2TM_CHANNEL_NOT_CONFIGURED,  /**< 117 */ /* GT_NOT_INITIALIZED */
+	TM_CONF_PORT_IND_USED,                 /**< 118 */ /* GT_ALREADY_EXIST */
+	TM_CONF_NULL_LOGICAL_NAME,             /**< 119 */ /* GT_BAD_VALUE */
+	TM_CONF_WRONG_LOGICAL_NAME,            /**< 120 */ /* GT_BAD_VALUE */
+	TM_CONF_MAX_ERROR					   /**<121 */
+};
+
+
+#endif   /* TM_ERRCODES_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.c
new file mode 100644
index 0000000..32b7505
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.c
@@ -0,0 +1,61 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_errors.h"
+#include "tm_errcodes.h"
+#include "set_hw_registers.h"
+
+
+/**
+ */
+int tm_sched_get_errors(tm_handle hndl, struct tm_error_info *info)
+{
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+	rc = get_hw_sched_errors(ctl, info);
+	if (rc)
+		return TM_HW_SCHED_GET_ERRORS_FAILED;
+	return rc;
+}
+
+
+/**
+ */
+int tm_drop_get_errors(tm_handle hndl, struct tm_error_info *info)
+{
+	int rc;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = get_hw_drop_errors(ctl, info);
+	if (rc)
+		rc = TM_HW_DROP_GET_ERRORS_FAILED;
+	return rc;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.h
new file mode 100644
index 0000000..9e0403c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_errors.h
@@ -0,0 +1,62 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_ERRORS_H
+#define TM_ERRORS_H
+
+#include "tm_core_types.h"
+
+
+/** Get Scheduler errors
+ * @param[in]        hndl   TM lib handle
+ * @param[out]      info    Scheduler error information
+ *
+ * @return an integer return code.
+ * @retval zero on success.
+ * @retval -EINVAL if hndl is NULL.
+ * @retval -EBADF if hndl is invalid.
+ * @retval TM_HW_SCHED_GET_ERRORS_FAILED if reading from HW fails
+*/
+int tm_sched_get_errors(tm_handle hndl, struct tm_error_info *info);
+
+
+/** Get Drop Unit errors
+ * @param[in]       hndl    TM lib handle
+ * @param[out]      info    Drop Unit error information
+ *
+ * @return an integer return code.
+ * @retval zero on success.
+ * @retval -EINVAL if hndl is NULL.
+ * @retval -EBADF if hndl is invalid.
+ * @retval TM_HW_DROP_GET_ERRORS_FAILED if reading from HW fails
+*/
+int tm_drop_get_errors(tm_handle hndl, struct tm_error_info *info);
+
+
+#endif   /* TM_ERRORS_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_get_gen_param_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_get_gen_param_interface.h
new file mode 100644
index 0000000..7fc0940
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_get_gen_param_interface.h
@@ -0,0 +1,41 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_GET_GEN_PARAMS_H
+#define TM_GET_GEN_PARAMS_H
+
+#include "tm_core_types.h"
+
+
+int tm_get_gen_params(tm_handle hndl);
+
+
+#endif   /* TM_GET_GEN_PARAMS_H */
+
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_hw_configuration_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_hw_configuration_interface.h
new file mode 100644
index 0000000..2578899
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_hw_configuration_interface.h
@@ -0,0 +1,65 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_HW_CONFIGURATION_INTERFACE_H
+#define TM_HW_CONFIGURATION_INTERFACE_H
+
+/* interface for access to all hardware resources - interface is platform independent,
+ implementation is platform dependent, different files for different platforms
+*/
+
+/* initialization of all hardware resources returning result - 0 if success >0 if failed */
+unsigned int	init_tm_hardware_configuration(const char *cProductName);
+
+/* following function returns 1 if hardware resources were successfully initialized
+ otherwise 0 (finitialization failed or not performed) */
+unsigned int	is_tm_initialized(void);
+
+/* following functions return appropriate hardware value  or 0 if hardware initialization missed or failed */
+unsigned int	get_tm_port_count(void);
+unsigned int	get_tm_c_nodes_count(void);
+unsigned int	get_tm_b_nodes_count(void);
+unsigned int	get_tm_a_nodes_count(void);
+unsigned int	get_tm_queues_count(void);
+
+/* TM Frequency (in Hz) */
+unsigned int	get_TM_min_frequency(void);
+unsigned int	get_TM_max_frequency(void);
+
+/* periodic process definitions */
+unsigned int	get_queue_min_periodic_interval(void);
+unsigned int	get_a_level_min_periodic_interval(void);
+unsigned int	get_b_level_min_periodic_interval(void);
+unsigned int	get_c_level_min_periodic_interval(void);
+unsigned int	get_port_min_periodic_interval(void);
+
+/* drop threshold definition */
+unsigned int	get_drop_threshold_definition(void);
+
+
+#endif   /* TM_HW_CONFIGURATION_INTERFACE_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_locking_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_locking_interface.h
new file mode 100644
index 0000000..6da3b74
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_locking_interface.h
@@ -0,0 +1,77 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_LOCKING_INTERFACE_H
+#define TM_LOCKING_INTERFACE_H
+
+
+int	tm_create_locking_staff(void * environment_handle);
+int	tm_destroy_locking_staff(void * environment_handle);
+
+
+/** Lock the TM nodes configuration data from other threads.
+ *
+ * @param[in]   hndl    TM lib handle
+ *
+ * @return an integer return code.
+ * @retval 0 on success.
+ * @retval -EINVAL if hndl is NULL.
+ * @retval -EBADF if hndl is invalid.
+ */
+int tm_nodes_lock(void * environment_handle);
+
+/** Lock the TM Global configuration data from other threads.
+ */
+int tm_glob_lock(void * environment_handle);
+
+/** Lock the TM scheduling configuration data from other threads.
+ */
+int tm_sched_lock(void * environment_handle);
+
+/** Unlock TM nodes configuration data for other threads.
+ *
+ * @param[in]   hndl    TM lib handle
+ *
+ * @return an integer return code.
+ * @retval 0 on success.
+ * @retval -EINVAL if hndl is NULL.
+ * @retval -EBADF if hndl is invalid.
+ */
+int tm_nodes_unlock(void * environment_handle);
+
+/** Unlock the TM Global configuration data from other threads.
+ */
+int tm_glob_unlock(void * environment_handle);
+
+/** Unlock the TM Scheduling configuration data from other threads.
+ */
+int tm_sched_unlock(void * environment_handle);
+
+
+#endif   /* TM_LOCKING_INTERFACE_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.c
new file mode 100644
index 0000000..035cc4a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.c
@@ -0,0 +1,2255 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_create.h"
+#include "rm_status.h"
+#include "rm_alloc.h"
+#include "rm_free.h"
+#include "rm_reorder.h"
+#include "rm_list.h"
+#include "tm_locking_interface.h"
+#include "tm_errcodes.h"
+
+#include "tm_set_local_db_defaults.h"
+#include "set_hw_registers.h"
+#include "tm_os_interface.h"
+
+#include "tm_nodes_utils.h"
+#include "tm_nodes_ctl.h"
+#include "tm_hw_configuration_interface.h"
+
+
+/**
+ */
+static int tm_nodes_on_off(tm_handle hndl,
+			enum tm_level level,
+			uint32_t parent_node,
+			uint32_t first_child_node,
+			uint32_t last_child_node,
+			uint8_t enable)
+{
+	int rc;
+	uint32_t i;
+	uint8_t state;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (enable) {
+		rc = set_hw_deq_status(hndl, level, parent_node);
+		if (rc)
+			return rc;
+
+		for (i = first_child_node; i <= last_child_node; i++) {
+			rc = set_hw_deq_status(hndl, level-1, i);
+			if (rc)
+				return rc;
+		}
+	} else {
+		switch (level) {
+		case A_LEVEL:
+			state = ctl->tm_a_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_a_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, A_LEVEL, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_a_node_array[parent_node].elig_prio_func_ptr = state;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				state = ctl->tm_queue_array[i].elig_prio_func_ptr;
+				ctl->tm_queue_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, Q_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_queue_array[i].elig_prio_func_ptr = state;
+			}
+			break;
+		case B_LEVEL:
+			state = ctl->tm_b_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_b_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, B_LEVEL, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_b_node_array[parent_node].elig_prio_func_ptr = state;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				state = ctl->tm_a_node_array[i].elig_prio_func_ptr;
+				ctl->tm_a_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, A_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_a_node_array[i].elig_prio_func_ptr = state;
+			}
+			break;
+		case C_LEVEL:
+			state = ctl->tm_c_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_c_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, C_LEVEL, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_c_node_array[parent_node].elig_prio_func_ptr = state;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				state = ctl->tm_b_node_array[i].elig_prio_func_ptr;
+				ctl->tm_b_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, B_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_b_node_array[i].elig_prio_func_ptr = state;
+			}
+			break;
+		case P_LEVEL:
+			state = ctl->tm_port_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_port_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, P_LEVEL, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_port_array[parent_node].elig_prio_func_ptr = state;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				state = ctl->tm_c_node_array[i].elig_prio_func_ptr;
+				ctl->tm_c_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, C_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_c_node_array[i].elig_prio_func_ptr = state;
+			}
+			break;
+		default:
+			return -ERANGE;
+		}
+	}
+	return 0;
+}
+
+
+/**
+ */
+static int tm_copy_b_node(tm_handle hndl,
+			uint32_t index, /* copy this node */
+			uint32_t range, /* range of this node */
+			uint32_t parent, /* where to copy */
+			uint32_t *new_index)
+{
+	struct rm_node *rm_node = NULL;
+	struct tm_b_node *node1 = NULL;
+	struct tm_b_node *node2 = NULL;
+	int rc;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	node1 = &(ctl->tm_b_node_array[index]);
+	rc = rm_find_free_b_node(rm, parent, range);
+	if (rc < 0)
+		return -ENOBUFS;
+	*new_index = rc;
+
+	node2 = &(ctl->tm_b_node_array[*new_index]);
+	rm_node = &(rm->rm_b_node_array[*new_index]);
+	node2->parent_c_node = parent;
+	node2->first_child_a_node = rm_node->first_child;
+	node2->last_child_a_node = rm_node->last_child;
+	for (i = node2->first_child_a_node; i <= node2->last_child_a_node; i++)
+		ctl->tm_a_node_array[i].parent_b_node = *new_index;
+
+	node2->elig_prio_func_ptr = node1->elig_prio_func_ptr;
+	node2->dwrr_quantum = node1->dwrr_quantum;
+	node2->dwrr_priority = node1->dwrr_priority;
+
+	ctl->tm_b_lvl_drop_prof_ptr[*new_index] = node1->wred_profile_ref;
+	node2->wred_profile_ref = node1->wred_profile_ref;
+	ctl->tm_b_lvl_drop_profiles[node2->wred_profile_ref].use_counter++;
+
+	rc = set_hw_b_node(hndl, *new_index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	return rc;
+}
+
+
+/**
+ */
+static int tm_copy_a_node(tm_handle hndl,
+			uint32_t index, /* copy this node */
+			uint32_t range, /* range of this node */
+			uint32_t parent, /* where to copy */
+			uint32_t *new_index)
+{
+	struct rm_node *rm_node = NULL;
+	struct tm_a_node *node1 = NULL;
+	struct tm_a_node *node2 = NULL;
+	int rc;
+	uint32_t i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	node1 = &(ctl->tm_a_node_array[index]);
+	rc = rm_find_free_a_node(rm, parent, range);
+	if (rc < 0)
+		return -ENOBUFS;
+	*new_index = rc;
+
+	node2 = &(ctl->tm_a_node_array[*new_index]);
+	rm_node = &(rm->rm_a_node_array[*new_index]);
+	node2->parent_b_node = parent;
+	node2->first_child_queue = rm_node->first_child;
+	node2->last_child_queue = rm_node->last_child;
+	for (i = node2->first_child_queue; i <= node2->last_child_queue; i++)
+		ctl->tm_queue_array[i].parent_a_node = *new_index;
+
+	node2->elig_prio_func_ptr = node1->elig_prio_func_ptr;
+	node2->dwrr_quantum = node1->dwrr_quantum;
+	node2->dwrr_priority = node1->dwrr_priority;
+
+	ctl->tm_a_lvl_drop_prof_ptr[*new_index] = node1->wred_profile_ref;
+	node2->wred_profile_ref = node1->wred_profile_ref;
+	ctl->tm_a_lvl_drop_profiles[node2->wred_profile_ref].use_counter++;
+
+	rc = set_hw_a_node(hndl, *new_index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+
+	return rc;
+}
+
+
+/**
+ */
+int tm_c_nodes_switch(tm_handle hndl,
+			uint32_t index1,
+			uint32_t index2)
+{
+
+	int rc;
+	uint32_t i;
+	struct tm_c_node *node1 = NULL;
+	struct tm_c_node *node2 = NULL;
+	uint32_t first_child1;
+	uint32_t last_child1;
+	uint32_t first_child2;
+	uint32_t last_child2;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	node1 = &(ctl->tm_c_node_array[index1]);
+	node2 = &(ctl->tm_c_node_array[index2]);
+
+	first_child1 = node1->first_child_b_node;
+	last_child1  = node1->last_child_b_node;
+	first_child2 = node2->first_child_b_node;
+	last_child2  = node2->last_child_b_node;
+
+	/* Assumption: DeQ disable was performed outside */
+
+	rc = rm_nodes_switch(rm, RM_B_LVL, index1, index2,
+			 first_child1, last_child1,
+			 first_child2, last_child2);
+	if (rc)
+		return rc;
+
+	/* Update node1 */
+	node1->first_child_b_node = first_child2;
+	node1->last_child_b_node = last_child2;
+
+	rc = set_hw_map(ctl, C_LEVEL, index1);
+	if (rc)
+		return rc;
+
+	for (i = first_child2; i <= last_child2 ; i++) {
+		ctl->tm_b_node_array[i].parent_c_node = index1;
+		rc = set_hw_map(ctl, B_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	/* Update node2 */
+	node2->first_child_b_node = first_child1;
+	node2->last_child_b_node = last_child1;
+	rc = set_hw_map(ctl, C_LEVEL, index2);
+	if (rc)
+		return rc;
+
+	for (i = first_child1; i <= last_child1 ; i++) {
+		ctl->tm_b_node_array[i].parent_c_node = index2;
+		rc = set_hw_map(ctl, B_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
+
+
+/**
+ */
+int tm_b_nodes_switch(tm_handle hndl,
+			uint32_t index1,
+			uint32_t index2)
+{
+	int rc;
+	uint32_t i;
+	struct tm_b_node *node1 = NULL;
+	struct tm_b_node *node2 = NULL;
+	uint32_t first_child1;
+	uint32_t last_child1;
+	uint32_t first_child2;
+	uint32_t last_child2;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	node1 = &(ctl->tm_b_node_array[index1]);
+	node2 = &(ctl->tm_b_node_array[index2]);
+
+	first_child1 = node1->first_child_a_node;
+	last_child1  = node1->last_child_a_node;
+	first_child2 = node2->first_child_a_node;
+	last_child2  = node2->last_child_a_node;
+
+	/* Assumption: DeQ disable was performed outside */
+
+	rc = rm_nodes_switch(rm, RM_A_LVL, index1, index2,
+			first_child1, last_child1,
+			first_child2, last_child2);
+	if (rc)
+		return rc;
+
+	/* Update node1 */
+	node1->first_child_a_node = first_child2;
+	node1->last_child_a_node = last_child2;
+	rc = set_hw_map(ctl, B_LEVEL, index1);
+	if (rc)
+		return rc;
+
+	for (i = first_child2; i <= last_child2 ; i++) {
+		ctl->tm_a_node_array[i].parent_b_node = index1;
+		rc = set_hw_map(ctl, A_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	/* Update node2 */
+	node2->first_child_a_node = first_child1;
+	node2->last_child_a_node = last_child1;
+	rc = set_hw_map(ctl, B_LEVEL, index2);
+	if (rc)
+		return rc;
+
+	for (i = first_child1; i <= last_child1 ; i++) {
+		ctl->tm_a_node_array[i].parent_b_node = index2;
+		rc = set_hw_map(ctl, A_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
+
+
+/**
+ */
+int tm_a_nodes_switch(tm_handle hndl,
+			uint32_t index1,
+			uint32_t index2)
+{
+	int rc;
+	uint32_t i;
+	struct tm_a_node *node1 = NULL;
+	struct tm_a_node *node2 = NULL;
+	uint32_t first_child1;
+	uint32_t last_child1;
+	uint32_t first_child2;
+	uint32_t last_child2;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	node1 = &(ctl->tm_a_node_array[index1]);
+	node2 = &(ctl->tm_a_node_array[index2]);
+
+	first_child1 = node1->first_child_queue;
+	last_child1  = node1->last_child_queue;
+	first_child2 = node2->first_child_queue;
+	last_child2  = node2->last_child_queue;
+
+	/* Assumption: DeQ disable was performed outside */
+
+	rc = rm_nodes_switch(rm, RM_Q_LVL, index1, index2,
+			first_child1, last_child1,
+			first_child2, last_child2);
+	if (rc)
+		return rc;
+
+	/* Update node1 */
+	node1->first_child_queue = first_child2;
+	node1->last_child_queue = last_child2;
+	rc = set_hw_map(ctl, A_LEVEL, index1);
+	if (rc)
+		return rc;
+
+	for (i = first_child2; i <= last_child2 ; i++) {
+		ctl->tm_queue_array[i].parent_a_node = index1;
+		rc = set_hw_map(ctl, Q_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	/* Update node2 */
+	node2->first_child_queue = first_child1;
+	node2->last_child_queue = last_child1;
+	rc = set_hw_map(ctl, A_LEVEL, index2);
+	if (rc)
+		return rc;
+
+	for (i = first_child1; i <= last_child1 ; i++) {
+		ctl->tm_queue_array[i].parent_a_node = index2;
+		rc = set_hw_map(ctl, Q_LEVEL, i);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
+
+
+/** Copied from tm_nodes_ctl.
+ */
+static int tm_delete_a_node(tm_handle hndl, uint32_t index)
+{
+	struct tm_a_node *a_node = NULL;
+	uint32_t range;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	a_node = &(ctl->tm_a_node_array[index]);
+	range = a_node->last_child_queue - a_node->first_child_queue + 1;
+	rc = rm_free_a_node(rm, index, range);
+	if (rc)
+		return rc;
+
+	ctl->tm_a_lvl_drop_prof_ptr[index] = 0;
+	ctl->tm_a_lvl_drop_profiles[a_node->wred_profile_ref].use_counter--;
+	set_sw_a_node_default(ctl->tm_a_node_array, index, rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_a_node_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_a_node(hndl, index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_a_node_deficit_clear(ctl, index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+
+	return 0;
+}
+
+
+/** Copied from tm_nodes_ctl.
+ */
+static int tm_delete_b_node(tm_handle hndl, uint32_t index)
+{
+	struct tm_b_node *b_node = NULL;
+	uint32_t range;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	b_node = &(ctl->tm_b_node_array[index]);
+	range = b_node->last_child_a_node - b_node->first_child_a_node + 1;
+	rc = rm_free_b_node(rm, index, range);
+	if (rc)
+		return rc;
+
+	ctl->tm_b_lvl_drop_prof_ptr[index] = 0;
+	ctl->tm_b_lvl_drop_profiles[b_node->wred_profile_ref].use_counter--;
+	set_sw_b_node_default(ctl->tm_b_node_array, index, rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_b_node_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_b_node(hndl, index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_b_node_deficit_clear(ctl, index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	return 0;
+}
+
+
+/** Move first child of the from_node to the end of the to_node.
+ *  Assumption: first child of the from_node should free and consequent to the last child of to_node.
+ */
+int tm_node_move(tm_handle hndl,
+		 enum tm_level level,
+		 uint32_t from_node,
+		 uint32_t to_node)
+{
+	int rc;
+	uint32_t first_child_to_move;
+	uint32_t first_child_from_node;
+	uint32_t last_child_from_node;
+	uint32_t last_child_to_node;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	switch (level) {
+	case B_LEVEL:
+		first_child_from_node = ctl->tm_b_node_array[from_node].first_child_a_node;
+		last_child_from_node = ctl->tm_b_node_array[from_node].last_child_a_node;
+		last_child_to_node = ctl->tm_b_node_array[to_node].last_child_a_node;
+		break;
+	case C_LEVEL:
+		first_child_from_node = ctl->tm_c_node_array[from_node].first_child_b_node;
+		last_child_from_node = ctl->tm_c_node_array[from_node].last_child_b_node;
+		last_child_to_node = ctl->tm_c_node_array[to_node].last_child_b_node;
+		break;
+	default:
+		return -ERANGE;
+	}
+
+	/* Check if the from_node will be not empty after the move */
+	if (last_child_from_node - first_child_from_node < 1) {
+		rc = -EFAULT;
+		goto err_out;
+	}
+
+	/* Ensure the children of the from_node and to_node are adjecent */
+	if (last_child_to_node + 1 != first_child_from_node) {
+		rc = -EBUSY;
+		goto err_out;
+	}
+
+	/* Calculate new values for parent nodes */
+	first_child_to_move = first_child_from_node;
+	first_child_from_node = first_child_to_move + 1;
+	last_child_to_node = first_child_from_node - 1;
+
+	/* Disable dequeing on all child and parent node */
+	rc = tm_nodes_on_off(hndl, level, from_node,
+			first_child_to_move,
+			first_child_to_move,
+			TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_nodes_on_off(hndl, level, to_node, 0, 0, TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	/* Move children, reconfigure parents */
+	switch (level) {
+	case B_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_A_LVL, from_node, to_node, 1, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_b_node_array[from_node].first_child_a_node = first_child_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_b_node_array[to_node].last_child_a_node = last_child_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_a_node_array[first_child_to_move].parent_b_node = to_node;
+		rc = set_hw_map(ctl, A_LEVEL, first_child_to_move);
+		if (rc)
+			goto err_out;
+		break;
+	case C_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_B_LVL, from_node, to_node, 1, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_c_node_array[from_node].first_child_b_node = first_child_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_c_node_array[to_node].last_child_b_node = last_child_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_b_node_array[first_child_to_move].parent_c_node = to_node;
+		rc = set_hw_map(ctl, B_LEVEL, first_child_to_move);
+		if (rc)
+			goto err_out;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/* Enable all nodes again in HW from SW model*/
+	rc = tm_nodes_on_off(hndl, level, from_node,
+			first_child_to_move,
+			first_child_to_move,
+			TM_ENABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_nodes_on_off(hndl, level, to_node, 0, 0, TM_ENABLE);
+
+err_out:
+	 return rc;
+}
+
+
+
+/**
+ */
+static int tm_nodes_reshuffling(tm_handle hndl,
+				enum tm_level level, /* level of reshuffled nodes */
+				uint32_t index)      /* parent index */
+{
+	int rc;
+	struct tm_a_node *a_node = NULL;
+	struct tm_b_node *b_node = NULL;
+	struct tm_c_node *c_node = NULL;
+	uint32_t last_child;
+	uint32_t next_index;
+	uint32_t new_index;
+	uint32_t b_index;
+	uint32_t c_index;
+	uint32_t p_index;
+	uint32_t range;
+	uint8_t status;
+	struct tm_tree_change *change = NULL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	/* Check assymetric mode */
+	switch (level) {
+	case A_LEVEL:
+		b_node = &(ctl->tm_b_node_array[index]); /* parent node */
+		c_index = b_node->parent_c_node;
+		c_node = &(ctl->tm_c_node_array[c_index]);
+		break;
+	case B_LEVEL:
+		c_node = &(ctl->tm_c_node_array[index]); /* parent node */
+		break;
+	default:
+		return -ERANGE;
+	}
+	p_index = c_node->parent_port;
+	if (ctl->tm_port_array[p_index].sym_mode == TM_ENABLE)
+		return -EFAULT; /* symetric mode under the port */
+
+	switch (level) {
+	case A_LEVEL:
+		last_child = b_node->last_child_a_node;
+		next_index = last_child + 1;
+
+		if (next_index >= rm->rm_total_a_nodes)
+			return -ENOBUFS;
+
+		a_node = &(ctl->tm_a_node_array[next_index]);
+		b_index = a_node->parent_b_node; /* parent of neighbor node */
+
+		rc = rm_node_status(rm, A_LEVEL, next_index, &status);
+		if (rc)
+			goto err_out;
+
+		if (status == RM_FALSE) { /* free node */
+			rc = rm_node_status(rm, B_LEVEL, b_index, &status);
+			if (rc)
+				goto err_out;
+
+			/* parent initialization for all nodes in the last possible index */
+			if ((next_index < ctl->tm_b_node_array[b_index].first_child_a_node) ||
+				/* not in this parent's range */
+				(next_index > ctl->tm_b_node_array[b_index].last_child_a_node)  ||
+				/* not in this parent's range */
+				(status == RM_FALSE)) { /* parent is free too */
+			/* so the node is in free nodes pool */
+			rc = rm_expand_range(rm, RM_A_LVL, next_index, index);
+			if (rc)
+				goto err_out;
+
+			/* Update the range of current parent to include this node */
+			b_node->last_child_a_node++;
+
+			status = b_node->elig_prio_func_ptr;
+			b_node->elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, B_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			rc = set_hw_map(ctl, B_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			b_node->elig_prio_func_ptr = status;
+			rc = set_hw_deq_status(ctl, B_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			/* Update the range of the allocated child node */
+			a_node->parent_b_node = index;
+		} else {
+			/* parent is allocated, but neighbor node is free */
+			/* reallocate the node to expand the range of our current parent */
+			rc = tm_node_move(ctl, B_LEVEL, b_index, index);
+			if (rc)
+				goto err_out;
+
+			change = (struct tm_tree_change *)tm_malloc(sizeof(struct tm_tree_change));
+			change->type = TM_DISABLE;
+			change->index = b_index;
+			change->old_index = ctl->tm_b_node_array[b_index].last_child_a_node -
+				ctl->tm_b_node_array[b_index].first_child_a_node + 2;
+			change->new_index = change->old_index - 1;
+			change->next = ctl->list.next;
+			ctl->list.next = change;
+			}
+		} else {
+			/* the node is allocated and used */
+			/* copy next_index to spare node under the same parent */
+			range = a_node->last_child_queue - a_node->first_child_queue + 1;
+			rc = tm_copy_a_node(ctl, next_index, range, b_index, &new_index);
+			if (rc == -ENOBUFS) {
+				/* this parent is full */
+			rc = tm_nodes_reshuffling(ctl, A_LEVEL, b_index);
+			if (rc)
+				goto err_out;
+			else {
+				/* try copy A-node again */
+				rc = tm_copy_a_node(ctl, next_index, range, b_index, &new_index);
+				if (rc)
+					goto err_out;
+			}
+
+			/* switch ranges between copied nodes */
+			rc = tm_a_nodes_switch(ctl, next_index, new_index);
+			if (rc)
+				goto err_out;
+
+			/* delete next_index A-node */
+			rc = tm_delete_a_node(ctl, next_index);
+			if (rc)
+				goto err_out;
+
+			/* expand range of our original parent with freed node */
+			rc = tm_node_move(ctl, B_LEVEL, b_index, index);
+			if (rc)
+				goto err_out;
+
+			change = (struct tm_tree_change *)tm_malloc(sizeof(struct tm_tree_change));
+			change->type = TM_ENABLE;
+			change->index = b_index;
+			change->old_index = next_index;
+			change->new_index = new_index;
+			change->next = ctl->list.next;
+			ctl->list.next = change;
+		} else /* other error */
+		{
+			if (rc)
+				goto err_out;
+		}
+		}
+		break;
+	case B_LEVEL:
+		last_child = c_node->last_child_b_node;
+		next_index = last_child + 1;
+
+		if (next_index >= rm->rm_total_b_nodes)
+			return -ENOBUFS;
+
+		rc = rm_node_status(rm, B_LEVEL, next_index, &status);
+		if (rc)
+			goto err_out;
+
+		b_node = &(ctl->tm_b_node_array[next_index]);
+		c_index = b_node->parent_c_node; /* parent of neighbor node */
+
+		if (status == RM_FALSE) { /* free node */
+			rc = rm_node_status(rm, C_LEVEL, c_index, &status);
+			if (rc)
+				goto err_out;
+
+			/* parent initialization for all nodes in the last possible index */
+			if ((next_index < ctl->tm_c_node_array[c_index].first_child_b_node) ||
+				/* not in this parent's range */
+			(next_index > ctl->tm_c_node_array[c_index].last_child_b_node)  ||
+			/* not in this parent's range */
+			(status == RM_FALSE)) { /* parent is free too */
+			/* so the node is in free nodes pool */
+			rc = rm_expand_range(rm, RM_B_LVL, next_index, index);
+			if (rc)
+				goto err_out;
+			/* Update the range of current parent to include this node */
+			c_node->last_child_b_node++;
+
+			status = c_node->elig_prio_func_ptr;
+			c_node->elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, C_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			rc = set_hw_map(ctl, C_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			c_node->elig_prio_func_ptr = status;
+			rc = set_hw_deq_status(ctl, C_LEVEL, index);
+			if (rc)
+				goto err_out;
+
+			/* Update the range of the allocated child node */
+			b_node->parent_c_node = index;
+		} else {
+			/* parent is allocated, but neighbor node is free */
+			/* reallocate the node to expand the range of our current parent */
+			rc = tm_node_move(ctl, C_LEVEL, c_index, index);
+			if (rc)
+				goto err_out;
+
+			change = (struct tm_tree_change *)tm_malloc(sizeof(struct tm_tree_change));
+			change->type = TM_DISABLE;
+			change->index = c_index;
+			change->old_index = ctl->tm_c_node_array[c_index].last_child_b_node -
+				ctl->tm_c_node_array[c_index].first_child_b_node + 2;
+			change->new_index = change->old_index - 1;
+			change->next = ctl->list.next;
+			ctl->list.next = change;
+		}
+		} else {
+			/* the node is allocated and used */
+			/* copy next_index to spare node under the same parent */
+			range = b_node->last_child_a_node - b_node->first_child_a_node + 1;
+			rc = tm_copy_b_node(ctl, next_index, range, c_index, &new_index);
+			if (rc == -ENOBUFS) { /* this parent is full */
+			rc = tm_nodes_reshuffling(ctl, B_LEVEL, c_index);
+			if (rc)
+				goto err_out;
+			else {
+			/* try copy B-node again */
+			rc = tm_copy_b_node(ctl, next_index, range, c_index, &new_index);
+			if (rc)
+				goto err_out;
+			}
+
+			/* switch ranges between copied nodes */
+			rc = tm_b_nodes_switch(ctl, next_index, new_index);
+			if (rc)
+				goto err_out;
+
+			/* delete next_index B-node */
+			rc = tm_delete_b_node(ctl, next_index);
+			if (rc)
+				goto err_out;
+
+			/* expand range of our original parent with freed node */
+			rc = tm_node_move(ctl, C_LEVEL, c_index, index);
+			if (rc)
+				goto err_out;
+
+			change = (struct tm_tree_change *)tm_malloc(sizeof(struct tm_tree_change));
+			change->type = TM_ENABLE;
+			change->index = c_index;
+			change->old_index = next_index;
+			change->new_index = new_index;
+			change->next = ctl->list.next;
+			ctl->list.next = change;
+		} else /* other error */
+		{
+			if (rc)
+				goto err_out;
+		}
+		}
+		break;
+	default:
+		return -ERANGE;
+	}
+
+err_out:
+	return rc;
+}
+
+
+static int port_update_sw_image(tm_handle hndl,
+								enum tm_port_bw port_speed,
+								struct tm_port_params *params,
+								uint8_t port_index)
+{
+	int i;
+	int rc;
+	struct tm_port *port = NULL;
+	struct tm_drop_profile *profile;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	port = &(ctl->tm_port_array[port_index]);
+
+	/* Update Port SW DB */
+	port->port_speed = port_speed;
+	port->wred_profile_ref = params->wred_profile_ref;
+	ctl->tm_p_lvl_drop_prof_ptr[port_index] = params->wred_profile_ref;
+	ctl->tm_p_lvl_drop_profiles[params->wred_profile_ref].use_counter++;
+	profile = &(ctl->tm_p_lvl_drop_profiles[port->wred_profile_ref]);
+	rc = rm_list_add_index(ctl->rm, profile->use_list, port_index, P_LEVEL);
+	if (rc)
+		return TM_CONF_P_WRED_PROF_REF_OOR;
+
+#ifdef MV_QMTM_NSS_A0
+	/* DWRR for Port */
+	for (i = 0; i < 8; i++)
+		port->dwrr_quantum[i].quantum = params->quantum[i];
+#endif
+	/* DWRR for C-nodes in Port's range */
+	port->dwrr_priority = 0;
+	for (i = 0; i < 8; i++)
+		port->dwrr_priority =
+			port->dwrr_priority | (params->dwrr_priority[i] << i);
+
+	/* Update sw image with eligible priority function pointer */
+	port->elig_prio_func_ptr = params->elig_prio_func_ptr;
+
+	return rc;
+}
+
+
+/**
+ */
+static int port_calc_ranges(uint16_t parents,
+				uint32_t children,
+				uint32_t *norm_range,
+				uint32_t *last_range)
+{
+	uint32_t range;
+	uint32_t remainder;
+
+	if (parents == 1) {
+		*norm_range = 0;
+		*last_range = children;
+		return 0;
+	}
+
+	range = children / parents;
+	if (range * parents != children)
+		range = range + 1;
+
+	if (range * parents != children)
+		remainder = children - range * (parents - 1);
+	else
+		remainder = range;
+
+	if (remainder > range)
+		return -ENOMEM;
+
+	*norm_range = range;
+	*last_range = remainder;
+	return 0;
+}
+
+
+/**
+ */
+static void set_a_node_params_default(struct tm_a_node_params *params)
+{
+	int i;
+
+	if (params) {
+		params->quantum = 0x40;
+		params->wred_profile_ref = 0;
+		for (i = 0; i < 8; i++)
+			params->dwrr_priority[i] = 0;
+		params->elig_prio_func_ptr = 0;
+	}
+}
+
+
+/**
+ */
+static void set_b_node_params_default(struct tm_b_node_params *params)
+{
+	int i;
+
+	if (params) {
+		params->quantum = 0x40;
+		params->wred_profile_ref = 0;
+		for (i = 0; i < 8; i++)
+			params->dwrr_priority[i] = 0;
+		params->elig_prio_func_ptr = 0;
+	}
+}
+
+
+/**
+ */
+static void set_c_node_params_default(struct tm_c_node_params *params)
+{
+	int i;
+
+	if (params) {
+		params->quantum = 0x40;
+		params->wred_cos = 0;
+		for (i = 0; i < 8; i++) {
+			params->dwrr_priority[i] = 0;
+			params->wred_profile_ref[i] = 0;
+		}
+		params->elig_prio_func_ptr = 0;
+	}
+}
+
+/***************************************************************************
+ * Port Creation
+ ***************************************************************************/
+
+/**
+ */
+int tm_create_asym_port(tm_handle hndl, uint8_t port_index,
+						enum tm_port_bw port_speed,
+						struct tm_port_params *params)
+{
+	struct tm_port *port = NULL;
+	struct rm_node *rm_port = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+#ifdef MV_QMTM_NSS_A0
+	uint32_t min_port_quant;
+	uint32_t max_pkg_len_bursts;
+	uint8_t res_min_bw = 0;
+	uint8_t res_max_bw = 0;
+	uint8_t div_exp = 0;
+#endif
+	struct tm_drop_profile *profile = NULL;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports) {
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_FALSE))
+	{
+		rc = TM_CONF_PORT_IND_USED;
+		goto out;
+	}
+
+	/* check port drop profile reference */
+	if (params->wred_profile_ref > TM_NUM_PORT_DROP_PROF)
+	{
+		rc = TM_CONF_P_WRED_PROF_REF_OOR;
+		goto out;
+	}
+
+	/* check if the referenced port drop profile exists */
+	rc = rm_port_drop_profile_status(rm, params->wred_profile_ref, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = TM_CONF_P_WRED_PROF_REF_OOR;
+		goto out;
+	}
+
+	/* Port params */
+	/* DWRR for Port */
+#ifdef MV_QMTM_NSS_A0
+	min_port_quant = 4*ctl->port_ch_emit*ctl->dwrr_bytes_burst_limit;
+	max_pkg_len_bursts = (ctl->mtu + ctl->min_pkg_size)/16;
+	max_pkg_len_bursts = max_pkg_len_bursts/0x40; /* in 64B units */
+	if (min_port_quant < max_pkg_len_bursts)
+		min_port_quant = max_pkg_len_bursts;
+	min_port_quant = min_port_quant/TM_PORT_QUANTUM_UNIT; /* in 64B units */
+	for (i = 0; i < 8; i++)
+		if ((params->quantum[i] < min_port_quant) ||
+			(params->quantum[i] > 0x1FF))
+		{ /* 9 bits */
+			rc = TM_CONF_PORT_QUANTUM_OOR;
+			goto out;
+		}
+#endif
+	/* DWRR for C-nodes in Port's range */
+	for (i = 0; i < 8; i++) {
+		if ((params->dwrr_priority[i] != TM_DISABLE) &&
+			(params->dwrr_priority[i] != TM_ENABLE)) {
+			rc = TM_CONF_PORT_DWRR_PRIO_OOR;
+			goto out;
+		}
+	}
+
+	if (params->elig_prio_func_ptr > 63)
+	{ /* maximum function id 0..63 */
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+		goto out;
+	}
+
+	if ((params->num_of_children > rm->rm_c_node_cnt) ||
+		(params->num_of_children == 0)) {
+		rc = TM_CONF_INVALID_NUM_OF_C_NODES;
+		goto out;
+	}
+
+
+	rc = rm_init_port(rm, port_index, params->num_of_children);
+	if (rc)
+		goto out;
+
+	port = &(ctl->tm_port_array[port_index]);
+	rm_port = &(rm->rm_port_array[port_index]);
+	port->sym_mode = TM_DISABLE;
+	port->first_child_c_node = rm_port->first_child;
+	port->last_child_c_node = rm_port->last_child;
+	for (i = port->first_child_c_node; i <= port->last_child_c_node; i++)
+		ctl->tm_c_node_array[i].parent_port = port_index;
+
+
+	port_update_sw_image(hndl, port_speed, params, port_index);
+	/* Download to HW */
+	rc = set_hw_port(hndl, port_index);
+	if (rc < 0)
+		rc = TM_HW_PORT_CONFIG_FAIL;
+
+out:
+	if (rc) {
+		if (rc == TM_HW_PORT_CONFIG_FAIL) {
+			rm_free_port(rm, port_index, 0);
+			set_sw_port_default(ctl->tm_port_array, port_index, rm);
+			ctl->tm_p_lvl_drop_prof_ptr[port_index] = 0;
+			ctl->tm_p_lvl_drop_profiles[params->wred_profile_ref].use_counter--;
+			profile = &(ctl->tm_p_lvl_drop_profiles[port->wred_profile_ref]);
+			rm_list_del_index(rm, profile->use_list, port_index, P_LEVEL);
+		}
+	}
+	tm_sched_unlock(TM_ENV(ctl));
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_port(tm_handle hndl, uint8_t port_index,
+				enum tm_port_bw port_speed,
+				struct tm_port_params *params,
+				uint16_t num_of_c_nodes,
+				uint16_t num_of_b_nodes,
+				uint16_t num_of_a_nodes,
+				uint32_t num_of_queues)
+{
+	struct tm_port *port = NULL;
+	uint16_t parents;
+	uint32_t children;
+	uint32_t norm_range;
+	uint32_t last_range;
+	uint8_t status;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports)
+	{
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_FALSE))
+	{
+		rc = TM_CONF_PORT_IND_USED;
+		goto out;
+	}
+
+	if ((num_of_c_nodes > rm->rm_c_node_cnt) ||
+		(num_of_c_nodes == 0))
+	{
+		rc = TM_CONF_INVALID_NUM_OF_C_NODES;
+		goto out;
+	}
+
+	if ((num_of_b_nodes > rm->rm_b_node_cnt) ||
+		(num_of_c_nodes > num_of_b_nodes))
+	{
+		rc = TM_CONF_INVALID_NUM_OF_B_NODES;
+		goto out;
+	}
+
+	if ((num_of_a_nodes > rm->rm_a_node_cnt) ||
+		(num_of_b_nodes > num_of_a_nodes))
+	{
+		rc = TM_CONF_INVALID_NUM_OF_A_NODES;
+		goto out;
+	}
+
+	if ((num_of_queues > rm->rm_queue_cnt) ||
+		(num_of_a_nodes > num_of_queues))
+	{
+		rc = TM_CONF_INVALID_NUM_OF_QUEUES;
+		goto out;
+	}
+
+	/* Calculate ranges */
+	port = &(ctl->tm_port_array[port_index]);
+	params->num_of_children = num_of_c_nodes;
+
+	/* C to B levels ranges */
+	parents = num_of_c_nodes;
+	children = num_of_b_nodes;
+
+	rc = port_calc_ranges(parents, children, &norm_range, &last_range);
+	if (rc < 0)
+		goto out;
+
+	port->children_range.norm_range[C_LEVEL-1] = norm_range;
+	port->children_range.last_range[C_LEVEL-1] = last_range;
+
+	/* B to A levels ranges */
+	parents = num_of_b_nodes;
+	children = num_of_a_nodes;
+
+	rc = port_calc_ranges(parents, children, &norm_range, &last_range);
+	if (rc < 0)
+		goto out;
+
+	port->children_range.norm_range[B_LEVEL-1] = norm_range;
+	port->children_range.last_range[B_LEVEL-1] = last_range;
+
+	/* A to Q levels ranges */
+	parents = num_of_a_nodes;
+	children = num_of_queues;
+
+	rc = port_calc_ranges(parents, children, &norm_range, &last_range);
+	if (rc < 0)
+		goto out;
+
+	port->children_range.norm_range[A_LEVEL-1] = norm_range;
+	port->children_range.last_range[A_LEVEL-1] = last_range;
+
+	rc = tm_create_asym_port(ctl, port_index, port_speed, params);
+	if (rc)
+		goto out;
+
+	/* Set sym mode */
+	port->sym_mode = TM_ENABLE;
+
+out:
+	return rc;
+}
+
+
+/**
+ */
+int tm_config_port_drop_per_cos(tm_handle hndl, uint8_t port_index,
+				struct tm_port_drop_per_cos *params)
+{
+	struct tm_ctl *ctl = hndl;
+	struct rmctl *rm = NULL;
+	struct tm_port *port = NULL;
+	struct tm_drop_profile *profile = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+
+	if (!ctl)
+		return -EINVAL;
+	if (ctl->magic != TM_MAGIC)
+		return -EBADF;
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	rm = ctl->rm;
+
+	/* Check if port exists */
+	if (port_index >= rm->rm_total_ports) {
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+	rc = rm_node_status(rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+
+	/* check port drop profile reference */
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (params->wred_cos & (1<<i)) {
+			if (params->wred_profile_ref[i] >= TM_NUM_PORT_DROP_PROF) {
+				rc = TM_CONF_P_WRED_PROF_REF_OOR;
+				goto out;
+			} else {
+				/* check if the referenced c-node drop profile exists */
+				rc = rm_port_drop_profile_status_cos(rm, (uint8_t)i,
+												params->
+												wred_profile_ref[i],
+												&status);
+				if ((rc) || (status != RM_TRUE)) {
+					rc = TM_CONF_P_WRED_PROF_REF_OOR;
+					goto out;
+				}
+			}
+		}
+	}
+
+	port = &(ctl->tm_port_array[port_index]);
+	for (i = 0; i < TM_WRED_COS; i++) {
+		/* Update Drop profile pointer */
+		if (params->wred_cos & (1<<i)) {
+			ctl->tm_p_lvl_drop_prof_ptr_cos[i][port_index] = params->wred_profile_ref[i];
+			profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][params->wred_profile_ref[i]]);
+			ctl->tm_p_lvl_drop_profiles_cos[i][params->wred_profile_ref[i]].use_counter++;
+
+			rc = rm_list_add_index(rm, profile->use_list, port_index, P_LEVEL);
+			if (rc) {
+				rc = TM_CONF_P_WRED_PROF_REF_OOR;
+				goto out;
+			}
+			port->wred_profile_ref_cos[i] = params->wred_profile_ref[i];
+		} else {
+			ctl->tm_p_lvl_drop_prof_ptr_cos[i][port_index] = 0;
+			ctl->tm_p_lvl_drop_profiles_cos[i][0].use_counter++;
+			port->wred_profile_ref_cos[i] = 0;
+		}
+	}
+	port->wred_cos = params->wred_cos;
+
+	/* Download to HW */
+	for (i = 0; i < TM_WRED_COS; i++)
+	{
+		rc = set_hw_port_drop_cos(hndl, port_index, (uint8_t)i);
+		if (rc < 0) {
+			rc = TM_HW_PORT_CONFIG_FAIL;
+			goto out;
+		}
+	}
+
+out:
+	if (rc) {
+		if (rc == TM_HW_PORT_CONFIG_FAIL) {
+			for (i = 0; i < TM_WRED_COS; i++) {
+				if (params->wred_cos & (1<<i)) {
+					ctl->tm_p_lvl_drop_prof_ptr_cos[i][port_index] = 0;
+					ctl->tm_p_lvl_drop_profiles_cos[i][params->wred_profile_ref[i]].use_counter--;
+					profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+					rm_list_del_index(rm, profile->use_list, port_index, P_LEVEL);
+					port->wred_profile_ref_cos[i] = 0;
+				}
+			}
+			port->wred_cos = 0; /* bit map */
+		}
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/***************************************************************************
+ * Queue Creation
+ ***************************************************************************/
+
+/**
+ */
+int tm_create_queue_to_port(tm_handle hndl, uint8_t port_index,
+							struct tm_queue_params *q_params,
+							struct tm_a_node_params *a_params,
+							struct tm_b_node_params *b_params,
+							struct tm_c_node_params *c_params,
+							uint32_t *queue_index,
+							uint32_t *a_node_index,
+							uint32_t *b_node_index,
+							uint32_t *c_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_a_node_to_port(hndl, port_index, a_params, b_params, c_params,
+								  a_node_index, b_node_index, c_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_queue_to_a_node(hndl, *a_node_index, q_params, queue_index);
+	if (rc)
+	{
+		rm_free_a_node(rm, *a_node_index, 0);
+		rm_free_b_node(rm, *b_node_index, 0);
+		rm_free_c_node(rm, *c_node_index, 0);
+		set_sw_a_node_default(ctl->tm_a_node_array, *a_node_index, rm);
+		set_sw_b_node_default(ctl->tm_b_node_array, *b_node_index, rm);
+		set_sw_c_node_default(ctl->tm_c_node_array, *c_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_trans_queue_to_port(tm_handle hndl,
+								uint8_t port_index,
+								struct tm_queue_params *q_params,
+								uint32_t *queue_index)
+{
+	struct tm_port *port = NULL;
+	struct tm_c_node_params c_params;
+	struct tm_b_node_params b_params;
+	struct tm_a_node_params a_params;
+	uint32_t c_index;
+	uint32_t b_index;
+	uint32_t a_index;
+	uint8_t status;
+	int rc = 0;
+	int q_flag = TM_DISABLE;
+	int p_flag = TM_DISABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports) {
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_PORT_IND_NOT_EXIST;
+		goto out;
+	}
+
+	if (ctl->tm_port_array[port_index].sym_mode != TM_ENABLE) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	port = &(ctl->tm_port_array[port_index]);
+	c_index = port->first_child_c_node;
+
+	/* Check that there is only one possible child in path to queues */
+	if (c_index != port->last_child_c_node) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	if ((port->children_range.norm_range[B_LEVEL] != 0) ||
+	   (port->children_range.last_range[B_LEVEL] != 1)) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	if ((port->children_range.norm_range[A_LEVEL] != 0) ||
+	(port->children_range.last_range[A_LEVEL] != 1)) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	/* q_params are checked inside one of the internal calls */
+
+	/* Find free queue */
+	rc = rm_node_status(rm, C_LEVEL, c_index, &status);
+	if (rc)
+		goto out;
+	if (status != RM_TRUE) {
+		/* Transparent path C-B-A-nodes doesn't exist */
+		/* Create transparent path */
+		set_a_node_params_default(&a_params);
+		set_b_node_params_default(&b_params);
+		set_c_node_params_default(&c_params);
+		rc = tm_create_a_node_to_port(ctl, port_index,
+					&a_params, &b_params, &c_params,
+					&a_index, &b_index, &c_index);
+		if (rc)
+			goto out;
+		p_flag = TM_ENABLE;
+		q_flag = TM_ENABLE;
+	} else {
+		/* Transparent path C-B-A-nodes exists */
+		b_index = ctl->tm_c_node_array[c_index].first_child_b_node;
+		a_index = ctl->tm_b_node_array[b_index].first_child_a_node;
+		if (rm->rm_a_node_array[a_index].cnt != 0)
+			q_flag = TM_ENABLE;
+	}
+	/* No free queue found */
+	if (q_flag != TM_ENABLE) {
+		rc = -ENOBUFS;
+		goto out;
+	}
+	rc = tm_create_queue_to_a_node(hndl, a_index, q_params, queue_index);
+
+out:
+	if (rc) {
+		if (p_flag == TM_ENABLE) {
+			tm_delete_node(ctl, A_LEVEL, a_index);
+			tm_delete_node(ctl, B_LEVEL, b_index);
+			tm_delete_node(ctl, C_LEVEL, c_index);
+		}
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_queue_to_c_node(tm_handle hndl, uint32_t c_node_index,
+							  struct tm_queue_params *q_params,
+							  struct tm_a_node_params *a_params,
+							  struct tm_b_node_params *b_params,
+							  uint32_t *queue_index,
+							  uint32_t *a_node_index,
+							  uint32_t *b_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_a_node_to_c_node(hndl, c_node_index, a_params, b_params,
+									a_node_index, b_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_queue_to_a_node(hndl, *a_node_index, q_params, queue_index);
+	if (rc)
+	{
+		rm_free_a_node(rm, *a_node_index, 0);
+		rm_free_b_node(rm, *b_node_index, 0);
+		set_sw_a_node_default(ctl->tm_a_node_array, *a_node_index, rm);
+		set_sw_b_node_default(ctl->tm_b_node_array, *b_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_queue_to_b_node(tm_handle hndl, uint32_t b_node_index,
+							  struct tm_queue_params *q_params,
+							  struct tm_a_node_params *a_params,
+							  uint32_t *queue_index,
+							  uint32_t *a_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_a_node_to_b_node(hndl, b_node_index, a_params, a_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_queue_to_a_node(hndl, *a_node_index, q_params, queue_index);
+	if (rc)
+	{
+		rm_free_a_node(rm, *a_node_index, 0);
+		set_sw_a_node_default(ctl->tm_a_node_array, *a_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_queue_to_a_node(tm_handle hndl, uint32_t a_node_index,
+							struct tm_queue_params *q_params,
+							uint32_t *queue_index)
+{
+	struct tm_queue *queue = NULL;
+	uint8_t status;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (a_node_index >= rm->rm_total_a_nodes) {
+		rc = TM_CONF_A_NODE_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, A_LEVEL, a_node_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_A_NODE_IND_NOT_EXIST;
+		goto out;
+	}
+
+	/* Queue params */
+	if (q_params->elig_prio_func_ptr > 63) { /* maximum function id 0..63 */
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+		goto out;
+	}
+
+	/* check if queue drop profile already exists */
+	rc = rm_queue_drop_profile_status(rm, q_params->wred_profile_ref, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_Q_WRED_PROF_REF_OOR;
+		goto out;
+	}
+#ifdef MV_QMTM_NOT_NSS
+	/* DWRR for Queue */
+	if ((q_params->quantum < ctl->min_quantum)
+		|| (q_params->quantum > 256 * ctl->min_quantum)) {
+		rc = TM_CONF_Q_QUANTUM_OOR;
+		goto out;
+	}
+#endif
+	/* Find free Queue */
+	rc = rm_find_free_queue(rm, a_node_index);
+	if (rc < 0)
+		goto out;
+	*queue_index = rc;
+
+	queue = &(ctl->tm_queue_array[*queue_index]);
+	queue->parent_a_node = a_node_index;
+
+	/* Update Queue SW DB */
+	queue->wred_profile_ref = q_params->wred_profile_ref;
+	ctl->tm_q_lvl_drop_prof_ptr[*queue_index] = q_params->wred_profile_ref;
+	ctl->tm_q_lvl_drop_profiles[q_params->wred_profile_ref].use_counter++;
+	queue->elig_prio_func_ptr = q_params->elig_prio_func_ptr;
+
+	/* DWRR for Queue - update even if disabled */
+	queue->dwrr_quantum = q_params->quantum;
+
+	/* Download Queue to HW */
+	rc = set_hw_queue(ctl, *queue_index);
+	if (rc) {
+		rc = TM_HW_QUEUE_CONFIG_FAIL;
+		goto out;
+	}
+
+	rc = set_hw_queue_shaping_def(ctl, *queue_index);
+	if (rc)
+		rc = TM_HW_QUEUE_CONFIG_FAIL;
+out:
+	if (rc) {
+		if (rc == TM_HW_QUEUE_CONFIG_FAIL) {
+			rm_free_queue(rm, *queue_index);
+			set_sw_queue_default(ctl->tm_queue_array, *queue_index, rm);
+			ctl->tm_q_lvl_drop_prof_ptr[*queue_index] = 0;
+			ctl->tm_q_lvl_drop_profiles[q_params->wred_profile_ref].use_counter--;
+		}
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/***************************************************************************
+ * A-node Creation
+ ***************************************************************************/
+
+/**
+ */
+int tm_create_a_node_to_port(tm_handle hndl, uint8_t port_index,
+							 struct tm_a_node_params *a_params,
+							 struct tm_b_node_params *b_params,
+							 struct tm_c_node_params *c_params,
+							 uint32_t *a_node_index,
+							 uint32_t *b_node_index,
+							 uint32_t *c_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_b_node_to_port(hndl, port_index, b_params, c_params,
+								  b_node_index, c_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_a_node_to_b_node(hndl, *b_node_index, a_params,
+									a_node_index);
+	if (rc)
+	{
+		rm_free_b_node(rm, *b_node_index, 0);
+		rm_free_c_node(rm, *c_node_index, 0);
+		set_sw_b_node_default(ctl->tm_b_node_array, *b_node_index, rm);
+		set_sw_c_node_default(ctl->tm_c_node_array, *c_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_a_node_to_c_node(tm_handle hndl, uint32_t c_node_index,
+							   struct tm_a_node_params *a_params,
+							   struct tm_b_node_params *b_params,
+							   uint32_t *a_node_index,
+							   uint32_t *b_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_b_node_to_c_node(hndl, c_node_index, b_params, b_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_a_node_to_b_node(hndl, *b_node_index, a_params,
+									a_node_index);
+	if (rc)
+	{
+		rm_free_b_node(rm, *b_node_index, 0);
+		set_sw_b_node_default(ctl->tm_b_node_array, *b_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_a_node_to_b_node(tm_handle hndl, uint32_t b_node_index,
+							   struct tm_a_node_params *a_params,
+							   uint32_t *a_node_index)
+{
+	struct rm_node *rm_node = NULL;
+	struct tm_a_node *node = NULL;
+	uint8_t status;
+	uint32_t range;
+	uint16_t c_node_index;
+	uint16_t port_index;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (b_node_index >= rm->rm_total_b_nodes)
+	{
+		rc = TM_CONF_B_NODE_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, B_LEVEL, b_node_index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = TM_CONF_B_NODE_IND_NOT_EXIST;
+		goto out;
+	}
+
+	/* A-node params */
+#ifdef MV_QMTM_NOT_NSS
+	/* DWRR for A-node */
+	if ((a_params->quantum < ctl->min_quantum)
+		|| (a_params->quantum > 256 * ctl->min_quantum)) {
+		rc = TM_CONF_A_QUANTUM_OOR;
+		goto out;
+	}
+#endif
+	/* DWRR for Queues in A-node's range */
+	for (i = 0; i < 8; i++) {
+		if ((a_params->dwrr_priority[i] != TM_DISABLE) &&
+			(a_params->dwrr_priority[i] != TM_ENABLE)) {
+			rc = TM_CONF_A_DWRR_PRIO_OOR;
+			goto out;
+		}
+	}
+
+	if (a_params->elig_prio_func_ptr > 63) { /* maximum function id 0..63 */
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+		goto out;
+	}
+
+
+	/* check if the referenced a-node drop profile exists */
+	rc = rm_a_node_drop_profile_status(rm, a_params->wred_profile_ref, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_A_WRED_PROF_REF_OOR;
+		goto out;
+	}
+
+	c_node_index = ctl->tm_b_node_array[b_node_index].parent_c_node;
+	port_index = ctl->tm_c_node_array[c_node_index].parent_port;
+	if (ctl->tm_port_array[port_index].sym_mode == TM_ENABLE) /* symetric mode under the port */ {
+		if (rm->rm_b_node_array[b_node_index].cnt == 1) /* the A node is the last child in range */
+			range = ctl->tm_port_array[port_index].children_range.last_range[A_LEVEL-1];
+		else
+			range = ctl->tm_port_array[port_index].children_range.norm_range[A_LEVEL-1];
+	} else /* asymetric mode under the port */
+		range = a_params->num_of_children;
+
+	if ((range > rm->rm_queue_cnt) || (range == 0)) {
+		rc = TM_CONF_INVALID_NUM_OF_QUEUES;
+		goto out;
+	}
+
+	/* Find free A-node */
+	rc = rm_find_free_a_node(rm, b_node_index, range);
+	if (rc == -ENOBUFS) {
+		rc = tm_nodes_reshuffling(ctl, A_LEVEL, b_node_index);
+		if (rc < 0)
+			goto out;
+		rc = rm_find_free_a_node(rm, b_node_index, range);
+	}
+	if (rc < 0)
+		goto out;
+	*a_node_index = rc;
+
+	node = &(ctl->tm_a_node_array[*a_node_index]);
+	rm_node = &(rm->rm_a_node_array[*a_node_index]);
+	node->first_child_queue = rm_node->first_child;
+	node->last_child_queue = rm_node->last_child;
+	for (i = node->first_child_queue; i <= node->last_child_queue; i++)
+		ctl->tm_queue_array[i].parent_a_node = *a_node_index;
+	node = &(ctl->tm_a_node_array[*a_node_index]);
+
+	/* Update A-Node SW DB */
+	/* Update Drop profile pointer */
+	ctl->tm_a_lvl_drop_prof_ptr[*a_node_index] = a_params->wred_profile_ref;
+	node->wred_profile_ref = a_params->wred_profile_ref;
+	ctl->tm_a_lvl_drop_profiles[a_params->wred_profile_ref].use_counter++;
+	node->elig_prio_func_ptr = a_params->elig_prio_func_ptr;
+
+	/* DWRR for A-node - update even if disabled */
+	node->dwrr_quantum = a_params->quantum;
+
+	/* DWRR for Queues in A-node's range */
+	node->dwrr_priority = 0;
+	for (i = 0; i < 8; i++)
+		node->dwrr_priority =
+			node->dwrr_priority | (a_params->dwrr_priority[i] << i);
+
+	/* Download A-Node to HW */
+	rc = set_hw_a_node(hndl, *a_node_index);
+	if (rc) {
+		rc = TM_HW_A_NODE_CONFIG_FAIL;
+		goto out;
+	}
+
+	rc = set_hw_a_node_shaping_def(hndl, *a_node_index);
+	if (rc)
+		rc = TM_HW_SHAPING_PROF_FAILED;
+
+out:
+	if (rc)
+	{
+		if (rc == TM_HW_A_NODE_CONFIG_FAIL)
+		{
+			rm_free_a_node(rm, *a_node_index, 0);
+			set_sw_a_node_default(ctl->tm_a_node_array, *a_node_index, rm);
+			ctl->tm_a_lvl_drop_prof_ptr[*a_node_index] = 0;
+			ctl->tm_a_lvl_drop_profiles[a_params->wred_profile_ref].use_counter--;
+		}
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/***************************************************************************
+ * B-node Creation
+ ***************************************************************************/
+
+/**
+ */
+int tm_create_b_node_to_port(tm_handle hndl, uint8_t port_index,
+							 struct tm_b_node_params *b_params,
+							 struct tm_c_node_params *c_params,
+							 uint32_t *b_node_index,
+							 uint32_t *c_node_index)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_create_c_node_to_port(hndl, port_index, c_params, c_node_index);
+	if (rc)
+		return rc;
+
+	rc = tm_create_b_node_to_c_node(hndl, *c_node_index, b_params,
+									b_node_index);
+	if (rc)
+	{
+		rm_free_c_node(rm, *c_node_index, 0);
+		set_sw_c_node_default(ctl->tm_c_node_array, *c_node_index, rm);
+	}
+	return rc;
+}
+
+
+/**
+ */
+int tm_create_b_node_to_c_node(tm_handle hndl, uint32_t c_node_index,
+							   struct tm_b_node_params *b_params,
+							   uint32_t *b_node_index)
+{
+	struct rm_node *rm_node = NULL;
+	struct tm_b_node *node = NULL;
+	uint8_t status;
+	uint16_t port_index;
+	uint32_t range;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (c_node_index >= rm->rm_total_c_nodes)
+	{
+		rc = TM_CONF_C_NODE_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, C_LEVEL, c_node_index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = TM_CONF_C_NODE_IND_NOT_EXIST;
+		goto out;
+	}
+
+	/* B-node params */
+#ifdef MV_QMTM_NOT_NSS
+	/* DWRR for B-node */
+	if ((b_params->quantum < ctl->min_quantum)
+		|| (b_params->quantum > 256 * ctl->min_quantum)) {
+		rc = TM_CONF_B_QUANTUM_OOR;
+		goto out;
+	}
+#endif
+	/* DWRR for A-nodes in B-node's range */
+	for (i = 0; i < 8; i++) {
+		if ((b_params->dwrr_priority[i] != TM_DISABLE) &&
+			(b_params->dwrr_priority[i] != TM_ENABLE)) {
+			rc = TM_CONF_B_DWRR_PRIO_OOR;
+			goto out;
+		}
+	}
+
+	if (b_params->wred_profile_ref >= TM_NUM_B_NODE_DROP_PROF) {
+		rc = TM_CONF_B_WRED_PROF_REF_OOR;
+		goto out;
+	}
+
+	if (b_params->elig_prio_func_ptr > 63) { /* maximum function id 0..63 */
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+		goto out;
+	}
+
+	/* check if the referenced b-node drop profile exists */
+	rc = rm_b_node_drop_profile_status(rm, b_params->wred_profile_ref, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_B_WRED_PROF_REF_OOR;
+		goto out;
+	}
+
+	port_index = ctl->tm_c_node_array[c_node_index].parent_port;
+	if (ctl->tm_port_array[port_index].sym_mode == TM_ENABLE) /* symetric mode under the port */ {
+		if (rm->rm_c_node_array[c_node_index].cnt == 1) /* the B node is the last child in range */
+			range = ctl->tm_port_array[port_index].children_range.last_range[B_LEVEL-1];
+		else
+			range = ctl->tm_port_array[port_index].children_range.norm_range[B_LEVEL-1];
+	} else /* asymetric mode under the port */
+		range = b_params->num_of_children;
+	if ((range > rm->rm_a_node_cnt) || (range == 0)) {
+		rc = TM_CONF_INVALID_NUM_OF_A_NODES;
+		goto out;
+	}
+
+	/* Find free B-node */
+	rc = rm_find_free_b_node(rm, c_node_index, range);
+	if (rc == -ENOBUFS) {
+		rc = tm_nodes_reshuffling(ctl, B_LEVEL, c_node_index);
+		if (rc < 0)
+			goto out;
+		rc = rm_find_free_b_node(rm, c_node_index, range);
+	}
+	if (rc < 0)
+		goto out;
+	*b_node_index = rc;
+
+	node = &(ctl->tm_b_node_array[*b_node_index]);
+	rm_node = &(rm->rm_b_node_array[*b_node_index]);
+	node->first_child_a_node = rm_node->first_child;
+	node->last_child_a_node = rm_node->last_child;
+	for (i = node->first_child_a_node; i <= node->last_child_a_node; i++)
+		ctl->tm_a_node_array[i].parent_b_node = *b_node_index;
+
+	/* Update B-Node SW DB */
+	node->elig_prio_func_ptr = b_params->elig_prio_func_ptr;
+
+	/* Update Drop profile pointer */
+	ctl->tm_b_lvl_drop_prof_ptr[*b_node_index] = b_params->wred_profile_ref;
+	node->wred_profile_ref = b_params->wred_profile_ref;
+	ctl->tm_b_lvl_drop_profiles[b_params->wred_profile_ref].use_counter++;
+
+	/* DWRR for B-node - update even if disabled */
+	node->dwrr_quantum = b_params->quantum;
+
+	/* DWRR for A-nodes in B-node's range */
+	node->dwrr_priority = 0;
+	for (i = 0; i < 8; i++)
+		node->dwrr_priority =
+			node->dwrr_priority | (b_params->dwrr_priority[i] << i);
+
+	/* Download B-Node to HW */
+	rc = set_hw_b_node(hndl, *b_node_index);
+	if (rc) {
+		rc = TM_HW_B_NODE_CONFIG_FAIL;
+		goto out;
+	}
+
+	rc = set_hw_b_node_shaping_def(hndl, *b_node_index);
+	if (rc)
+		rc = TM_HW_SHAPING_PROF_FAILED;
+
+out:
+	if (rc) {
+		if (rc == TM_HW_B_NODE_CONFIG_FAIL) {
+			rm_free_b_node(rm, *b_node_index, 0);
+			set_sw_b_node_default(ctl->tm_b_node_array, *b_node_index, rm);
+			ctl->tm_b_lvl_drop_prof_ptr[*b_node_index] = 0;
+			ctl->tm_b_lvl_drop_profiles[b_params->wred_profile_ref].use_counter--;
+		}
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/***************************************************************************
+ * C-node Creation
+ ***************************************************************************/
+
+/**
+ */
+int tm_create_c_node_to_port(tm_handle hndl, uint8_t port_index,
+							 struct tm_c_node_params *c_params,
+							 uint32_t *c_node_index)
+{
+	struct rm_node *rm_node = NULL;
+	struct tm_c_node *node = NULL;
+	uint8_t status;
+	uint16_t range;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports) {
+		rc = TM_CONF_PORT_IND_OOR;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = TM_CONF_PORT_IND_NOT_EXIST;
+		goto out;
+	}
+
+	/* C-node params */
+	if (ctl->tm_port_array[port_index].sym_mode == TM_ENABLE) /* symetric mode under the port */ {
+		if (rm->rm_port_array[port_index].cnt == 1) /* the C node is the last child in range */
+			range = ctl->tm_port_array[port_index].children_range.last_range[C_LEVEL-1];
+		else
+			range = ctl->tm_port_array[port_index].children_range.norm_range[C_LEVEL-1];
+	} else /* asymetric mode under the port */
+		range = c_params->num_of_children;
+	if ((range > rm->rm_b_node_cnt) || (range == 0)) {
+		rc = TM_CONF_INVALID_NUM_OF_B_NODES;
+		goto out;
+	}
+#ifdef MV_QMTM_NOT_NSS
+	/* DWRR for C-node */
+	if ((c_params->quantum < ctl->min_quantum)
+		|| (c_params->quantum > 256 * ctl->min_quantum)) {
+		rc = TM_CONF_C_QUANTUM_OOR;
+		goto out;
+	}
+#endif
+	if (c_params->elig_prio_func_ptr > 63) { /* maximum function id 0..63 */
+		rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+		goto out;
+	}
+
+	/* DWRR for B-nodes in C-node's range */
+	for (i = 0; i < 8; i++) {
+		if ((c_params->dwrr_priority[i] != TM_DISABLE) &&
+			(c_params->dwrr_priority[i] != TM_ENABLE)) {
+			rc = TM_CONF_C_DWRR_PRIO_OOR;
+			goto out;
+		}
+	}
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (c_params->wred_cos & (1<<i)) {
+			if (c_params->wred_profile_ref[i] >= TM_NUM_C_NODE_DROP_PROF) {
+				rc = TM_CONF_C_WRED_PROF_REF_OOR;
+				goto out;
+			} else {
+				/* check if the referenced c-node drop profile exists */
+				rc = rm_c_node_drop_profile_status(rm, (uint8_t)i,
+												   c_params->
+												   wred_profile_ref[i],
+												   &status);
+				if ((rc) || (status != RM_TRUE)) {
+					rc = TM_CONF_C_WRED_PROF_REF_OOR;
+					goto out;
+				}
+			}
+		}
+	}
+
+	/* Find free C-node */
+	rc = rm_find_free_c_node(rm, port_index, range);
+	if (rc < 0)
+		goto out;
+	*c_node_index = rc;
+
+	node = &(ctl->tm_c_node_array[*c_node_index]);
+	rm_node = &(rm->rm_c_node_array[*c_node_index]);
+	node->first_child_b_node = rm_node->first_child;
+	node->last_child_b_node = rm_node->last_child;
+	for (i = node->first_child_b_node; i <= node->last_child_b_node; i++)
+		ctl->tm_b_node_array[i].parent_c_node = *c_node_index;
+
+	/* Update C-node SW DB */
+	node->elig_prio_func_ptr = c_params->elig_prio_func_ptr;
+
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		/* Update Drop profile pointer */
+		if (c_params->wred_cos & (1<<i)) {
+			ctl->tm_c_lvl_drop_prof_ptr[i][*c_node_index] = c_params->wred_profile_ref[i];
+			ctl->tm_c_lvl_drop_profiles[i][c_params->wred_profile_ref[i]].use_counter++;
+			node->wred_profile_ref[i] = c_params->wred_profile_ref[i];
+		} else {
+			ctl->tm_c_lvl_drop_prof_ptr[i][*c_node_index] = 0;
+			ctl->tm_c_lvl_drop_profiles[i][0].use_counter++;
+			node->wred_profile_ref[i] = 0;
+		}
+	}
+
+	/* update Wred CoS for future usage within the HW update */
+	node->wred_cos = c_params->wred_cos;
+
+	/* DWRR for C-node - update even if disabled */
+	node->dwrr_quantum = c_params->quantum;
+
+	/* DWRR for B-nodes in C-node's range */
+	node->dwrr_priority = 0;
+	for (i = 0; i < 8; i++)
+		node->dwrr_priority =
+			node->dwrr_priority | (c_params->dwrr_priority[i] << i);
+
+	/* Download C-node to HW */
+	rc = set_hw_c_node(hndl, *c_node_index);
+	if (rc) {
+		rc = TM_HW_C_NODE_CONFIG_FAIL;
+		goto out;
+	}
+
+	rc = set_hw_c_node_shaping_def(hndl, *c_node_index);
+	if (rc)
+		rc = TM_HW_SHAPING_PROF_FAILED;
+
+out:
+	if (rc) {
+		if (rc == TM_HW_C_NODE_CONFIG_FAIL) {
+			rm_free_c_node(rm, *c_node_index, 0);
+			set_sw_c_node_default(ctl->tm_c_node_array, *c_node_index, rm);
+			for (i = 0; i < TM_WRED_COS; i++) {
+				if (c_params->wred_cos & (1<<i)) {
+					ctl->tm_c_lvl_drop_prof_ptr[i][*c_node_index] = 0;
+					ctl->tm_c_lvl_drop_profiles[i][c_params->wred_profile_ref[i]].use_counter--;
+				}
+			}
+		}
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.h
new file mode 100644
index 0000000..33d4e83
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_create.h
@@ -0,0 +1,625 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef   	TM_NODES_CREATE_H
+#define   	TM_NODES_CREATE_H
+
+#include "tm_core_types.h"
+
+
+/***************************************************************************
+ * Port Creation
+ ***************************************************************************/
+
+/** Create Assymetric Port and download its parameters to HW.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index.
+ *   @param[in]     port_speed      Port physical bandwidth.
+ *   @param[in]     params          Port parameters structure pointer.
+ *   @param[in]     num_of_c_nodes  Number of C-nodes under port.
+ *   @param[in]     num_of_b_nodes  Number of B-nodes under port.
+ *   @param[in]     num_of_a_nodes  Number of A-nodes under port.
+ *   @param[in]     num_of_queues   Number of Queues under port.
+
+ *   @note:
+ *   Valid number of nodes per level must be multiple of number nodes
+ *   on upper level (parent nodes) in case of equal distribution. And
+ *   in case of unequal distribution all parent nodes except the last
+ *   one must have the same children range and the last parent node -
+ *   number of children less that the range. In case of not valid
+ *   number will be returned -EACCES error code.
+ *   @note: if port will be used for transparent queues, set the number_of_c/b/a_nodes = 1.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOMEM if memory allocation in RM fails.
+ *   @retval -EACCES if number of nodes per level is not valid.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_USED if port_index is already used.
+ *   @retval TM_CONF_PORT_SPEED_OOR if port_speed is out of range.
+ *
+ *   @retval TM_CONF_P_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_PORT_BW_OUT_OF_SPEED.
+ *   @retval TM_CONF_PORT_QUANTUM_OOR.
+ *   @retval TM_CONF_PORT_DWRR_PRIO_OOR.
+ *
+ *   @retval TM_CONF_INVALID_NUM_OF_C_NODES.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is
+ *   oor
+ *
+ *   @retval TM_CONF_PORT_BW_OOR
+ *   @retval TM_CONF_PORT_BS_OOR
+ *   @retval TM_CONF_PORT_MIN_TOKEN_TOO_LARGE.
+ *   @retval TM_CONF_PORT_MAX_TOKEN_TOO_LARGE.
+ *   @retval TM_CONF_PORT_MIN_SHAP_NOT_INC_BW_MULT
+ *   @retval TM_CONF_PORT_MAX_SHAP_NOT_INC_BW_MULT
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_create_asym_port(tm_handle hndl, uint8_t port_index,
+					enum tm_port_bw port_speed,
+					struct tm_port_params *params);
+
+/** Create Port and download its parameters to HW.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index.
+ *   @param[in]     port_speed      Port physical bandwidth.
+ *   @param[in]     params          Port parameters structure pointer.
+ *   @param[in]     num_of_c_nodes  Number of C-nodes under port.
+ *   @param[in]     num_of_b_nodes  Number of B-nodes under port.
+ *   @param[in]     num_of_a_nodes  Number of A-nodes under port.
+ *   @param[in]     num_of_queues   Number of Queues under port.
+
+ *   @note:
+ *   Valid number of nodes per level must be multiple of number nodes
+ *   on upper level (parent nodes) in case of equal distribution. And
+ *   in case of unequal distribution all parent nodes except the last
+ *   one must have the same children range and the last parent node -
+ *   number of children less that the range. In case of not valid
+ *   number will be returned -EACCES error code.
+ *   @note: if port will be used for transparent queues, set the number_of_c/b/a_nodes = 1.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOMEM if memory allocation in RM fails.
+ *   @retval -EACCES if number of nodes per level is not valid.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_USED if port_index is already used.
+ *   @retval TM_CONF_PORT_SPEED_OOR if port_speed is out of range.
+ *
+ *   @retval TM_CONF_P_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_PORT_BW_OUT_OF_SPEED.
+ *   @retval TM_CONF_PORT_QUANTUM_OOR.
+ *   @retval TM_CONF_PORT_DWRR_PRIO_OOR.
+ *
+ *   @retval TM_CONF_INVALID_NUM_OF_C_NODES.
+ *   @retval TM_CONF_INVALID_NUM_OF_B_NODES.
+ *   @retval TM_CONF_INVALID_NUM_OF_A_NODES.
+ *   @retval TM_CONF_INVALID_NUM_OF_QUEUES.
+ *
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is
+ *   oor
+ *
+ *   @retval TM_CONF_PORT_BW_OOR
+ *   @retval TM_CONF_PORT_BS_OOR
+ *   @retval TM_CONF_PORT_MIN_TOKEN_TOO_LARGE.
+ *   @retval TM_CONF_PORT_MAX_TOKEN_TOO_LARGE.
+ *   @retval TM_CONF_PORT_MIN_SHAP_NOT_INC_BW_MULT
+ *   @retval TM_CONF_PORT_MAX_SHAP_NOT_INC_BW_MULT
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_create_port(tm_handle hndl, uint8_t port_index,
+					enum tm_port_bw port_speed,
+					struct tm_port_params *params,
+					uint16_t num_of_c_nodes,
+					uint16_t num_of_b_nodes,
+					uint16_t num_of_a_nodes,
+					uint32_t num_of_queues);
+
+
+/** Configure Port's Drop per Cos and download its parameters to HW.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index.
+ *   @param[in]     params          Port Drop parameters per Cos structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *
+ *   @retval TM_CONF_P_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_config_port_drop_per_cos(tm_handle hndl, uint8_t port_index,
+				struct tm_port_drop_per_cos *params);
+
+
+/***************************************************************************
+ * Queue Creation
+ ***************************************************************************/
+
+/** Create path from Queue to Port.
+ *
+ *  @note fields.shaping in parameters may get
+ *  TM_INF_PROFILE value when there is no shaping to the queue/node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index to connect queue.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[in]     c_params        C-node parameters structure pointer.
+ *   @param[out]    queue_index     Queue index pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *   @param[out]    c_node_index    C-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free C-nodes under the Port can be added.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_NOT_EXIST if port_index is not in use.
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_Q_PRIORITY_OOR.
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_C_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_C_PRIORITY_OOR.
+ *   @retval TM_CONF_C_QUANTUM_OOR.
+ *   @retval TM_CONF_C_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_C_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if queue download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if C-node download to HW fails.
+ */
+int tm_create_queue_to_port(tm_handle hndl, uint8_t port_index,
+							struct tm_queue_params *q_params,
+							struct tm_a_node_params *a_params,
+							struct tm_b_node_params *b_params,
+							struct tm_c_node_params *c_params,
+							uint32_t *queue_index,
+							uint32_t *a_node_index,
+							uint32_t *b_node_index,
+							uint32_t *c_node_index);
+
+
+/** Create transparent path from Queue to Port.
+ *
+ *  @note This API introduces 'transparent' concept to TM nodes
+ *  structure that deals with Queues and Ports only. In this case no
+ *  configuration is needed for A,B,C level nodes, this nodes
+ *  are created automatically (one C-node, one B-node and one
+ *  A-node) and they are 'transparent' from the system point of
+ *  view. Transparent path can be created under symmetric port
+ *  only. To delete Queue from the structure - use
+ *  'tm_delete_node' API with level Q_LEVEL. To update queue
+ *  parameters - use 'tm_update_queue' API. To delete Port from
+ *  the structure use 'tm_delete_trans_port' API. Applying any
+ *  other APIs on nodes underlying the port can cause unexpected
+ *  behavior of the system.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index to connect queue.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *   @param[out]    queue_index     Queue index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port is assymetric.
+ *   @retval -ENOBUFS if no free queues under the Port can be added.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_NOT_EXIST if port_index is not in use.
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if queue download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if C-node download to HW fails.
+ */
+int tm_create_trans_queue_to_port(tm_handle hndl, uint8_t port_index,
+								struct tm_queue_params *q_params,
+								uint32_t *queue_index);
+
+
+/** Create path from Queue to C-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index to connect queue.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[out]    queue_index     Queue index pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free B-nodes under the C-node can be added.
+ *   @retval TM_CONF_C_NODE_IND_OOR if c_node_index is out of range.
+ *   @retval TM_CONF_C_NODE_IND_NOT_EXIST if c_node_index is not in use.
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_Q_PRIORITY_OOR.
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if queue download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ */
+int tm_create_queue_to_c_node(tm_handle hndl, uint32_t c_node_index,
+							struct tm_queue_params *q_params,
+							struct tm_a_node_params *a_params,
+							struct tm_b_node_params *b_params,
+							uint32_t *queue_index,
+							uint32_t *a_node_index,
+							uint32_t *b_node_index);
+
+
+/** Create path from Queue to B-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     b_node_index    B-node index to connect queue.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[out]    queue_index     Queue index pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free A-nodes under the B-node can be added.
+ *   @retval TM_CONF_B_NODE_IND_OOR if b_node_index is out of range.
+ *   @retval TM_CONF_B_NODE_IND_NOT_EXIST if b_node_index is not in use.
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_Q_PRIORITY_OOR.
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if queue download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ */
+int tm_create_queue_to_b_node(tm_handle hndl, uint32_t b_node_index,
+							struct tm_queue_params *q_params,
+							struct tm_a_node_params *a_params,
+							uint32_t *queue_index,
+							uint32_t *a_node_index);
+
+
+/** Create path from Queue to A-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     a_node_index    A-node index to connect queue.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *   @param[out]    queue_index     Queue index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free Queues under the A-node can be added.
+ *   @retval TM_CONF_A_NODE_IND_OOR if a_node_index is out of range.
+ *   @retval TM_CONF_A_NODE_IND_NOT_EXIST if a_node_index is not in use.
+ *
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_Q_PRIORITY_OOR.
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if queue download to HW fails.
+ */
+int tm_create_queue_to_a_node(tm_handle hndl, uint32_t a_node_index,
+							struct tm_queue_params *q_params,
+							uint32_t *queue_index);
+
+
+/***************************************************************************
+ * A-node Creation
+ ***************************************************************************/
+
+/** Create path from A-node to Port.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index to connect queue.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[in]     c_params        C-node parameters structure pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *   @param[out]    c_node_index    C-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free C-nodes under the Port can be added.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_NOT_EXIST if port_index is not in use.
+ *
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_C_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_C_PRIORITY_OOR.
+ *   @retval TM_CONF_C_QUANTUM_OOR.
+ *   @retval TM_CONF_C_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_C_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_INVALID_NUM_OF_QUEUES.
+ *
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if C-node download to HW fails.
+ */
+int tm_create_a_node_to_port(tm_handle hndl, uint8_t port_index,
+							struct tm_a_node_params *a_params,
+							struct tm_b_node_params *b_params,
+							struct tm_c_node_params *c_params,
+							uint32_t *a_node_index,
+							uint32_t *b_node_index,
+							uint32_t *c_node_index);
+
+
+/** Create path from A-node to C-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index to connect queue.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free B-nodes under the C-node can be added.
+ *   @retval TM_CONF_C_NODE_IND_OOR if c_node_index is out of range.
+ *   @retval TM_CONF_C_NODE_IND_NOT_EXIST if c_node_index is not in use.
+ *
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_INVALID_NUM_OF_QUEUES.
+ *
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ */
+int tm_create_a_node_to_c_node(tm_handle hndl, uint32_t c_node_index,
+								struct tm_a_node_params *a_params,
+								struct tm_b_node_params *b_params,
+								uint32_t *a_node_index,
+								uint32_t *b_node_index);
+
+
+/** Create path from A-node to B-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     b_node_index    B-node index to connect queue.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *   @param[out]    a_node_index    A-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free A-nodes under the B-node can be added.
+ *   @retval TM_CONF_B_NODE_IND_OOR if b_node_index is out of range.
+ *   @retval TM_CONF_B_NODE_IND_NOT_EXIST if b_node_index is not in use.
+ *
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_CONF_INVALID_NUM_OF_QUEUES.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if A-node download to HW fails.
+ */
+int tm_create_a_node_to_b_node(tm_handle hndl, uint32_t b_node_index,
+								struct tm_a_node_params *a_params,
+								uint32_t *a_node_index);
+
+
+/***************************************************************************
+ * B-node Creation
+ ***************************************************************************/
+
+/** Create path from B-node to Port.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index to connect queue.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[in]     c_params        C-node parameters structure pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *   @param[out]    c_node_index    C-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free C-nodes under the Port can be added.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_NOT_EXIST if port_index is not in use.
+ *
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_C_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_C_PRIORITY_OOR.
+ *   @retval TM_CONF_C_QUANTUM_OOR.
+ *   @retval TM_CONF_C_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_C_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_INVALID_NUM_OF_A_NODES.
+ *
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if C-node download to HW fails.
+ */
+int tm_create_b_node_to_port(tm_handle hndl, uint8_t port_index,
+							struct tm_b_node_params *b_params,
+							struct tm_c_node_params *c_params,
+							uint32_t *b_node_index,
+							uint32_t *c_node_index);
+
+
+/** Create path from B-node to C-node.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index to connect queue.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *   @param[out]    b_node_index    B-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free B-nodes under the C-node can be added.
+ *   @retval TM_CONF_C_NODE_IND_OOR if c_node_index is out of range.
+ *   @retval TM_CONF_C_NODE_IND_NOT_EXIST if c_node_index is not in use.
+ *
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_CONF_INVALID_NUM_OF_A_NODES.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if B-node download to HW fails.
+ */
+int tm_create_b_node_to_c_node(tm_handle hndl, uint32_t c_node_index,
+								struct tm_b_node_params *b_params,
+								uint32_t *b_node_index);
+
+
+/***************************************************************************
+ * C-node Creation
+ ***************************************************************************/
+
+/** Create path from C-node to Port.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_index      Port index to connect queue.
+ *   @param[in]     c_params        C-node parameters structure pointer.
+ *   @param[out]    c_node_index    C-node index pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ENOBUFS if no free C-nodes under the Port can be added.
+ *   @retval TM_CONF_PORT_IND_OOR if port_index is out of range.
+ *   @retval TM_CONF_PORT_IND_NOT_EXIST if port_index is not in use.
+ *
+ *   @retval TM_CONF_C_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_C_PRIORITY_OOR.
+ *   @retval TM_CONF_C_QUANTUM_OOR.
+ *   @retval TM_CONF_C_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_B_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_CONF_INVALID_NUM_OF_B_NODES.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is
+ *   oor
+ *
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if C-node download to HW fails.
+ */
+int tm_create_c_node_to_port(tm_handle hndl, uint8_t port_index,
+							struct tm_c_node_params *c_params,
+							uint32_t *c_node_index);
+
+
+#endif 	 /* TM_NODES_CREATE_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.c
new file mode 100644
index 0000000..0284a20
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.c
@@ -0,0 +1,466 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "common/mv_sw_if.h"
+
+#include "rm_status.h"
+#include "rm_free.h"
+#include "rm_list.h"
+#include "tm_locking_interface.h"
+#include "tm_core_types.h"
+#include "tm_errcodes.h"
+
+#include "tm_set_local_db_defaults.h"
+#include "set_hw_registers.h"
+#include "tm_os_interface.h"
+
+
+/**
+ */
+static int tm_delete_port(tm_handle hndl, uint8_t index)
+{
+	struct tm_port *port = NULL;
+	struct tm_drop_profile *profile = NULL;
+	uint16_t range;
+	int rc;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	port = &(ctl->tm_port_array[index]);
+	range = port->last_child_c_node - port->first_child_c_node + 1;
+
+	rc = rm_free_port(ctl->rm, index, range);
+	if (rc)
+		return rc;
+
+	profile = &(ctl->tm_p_lvl_drop_profiles[port->wred_profile_ref]);
+	rc = rm_list_del_index(ctl->rm, profile->use_list, index, P_LEVEL);
+	if (rc)
+		return rc;
+
+	ctl->tm_p_lvl_drop_profiles[ctl->tm_p_lvl_drop_prof_ptr[index]].
+		use_counter--;
+	ctl->tm_p_lvl_drop_prof_ptr[index] = 0;
+
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (port->wred_cos & (1<<i)) {
+			profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+			rc = rm_list_del_index(ctl->rm, profile->use_list, index, P_LEVEL);
+			if (rc)
+				return rc;
+		}
+		ctl->tm_p_lvl_drop_profiles_cos[i][ctl->tm_p_lvl_drop_prof_ptr_cos[i][index]].
+			use_counter--;
+		ctl->tm_p_lvl_drop_prof_ptr_cos[i][index] = 0;
+	}
+
+
+	set_sw_port_default(ctl->tm_port_array, index, ctl->rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_port_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_port(hndl, index);
+	if (rc)
+		return TM_HW_PORT_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_port_deficit_clear(hndl, index);
+	if (rc)
+		return TM_HW_PORT_CONFIG_FAIL;
+
+	return 0;
+}
+
+
+/**
+ */
+static int tm_delete_c_node(tm_handle hndl, uint32_t index)
+{
+
+	struct tm_c_node *c_node = NULL;
+	uint16_t range;
+	int rc;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	c_node = &(ctl->tm_c_node_array[index]);
+	range = c_node->last_child_b_node - c_node->first_child_b_node + 1;
+	rc = rm_free_c_node(ctl->rm, index, range);
+	if (rc)
+		return rc;
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		ctl->tm_c_lvl_drop_profiles[i][ctl->tm_c_lvl_drop_prof_ptr[i][index]].
+			use_counter--;
+		ctl->tm_c_lvl_drop_prof_ptr[i][index] = 0;
+	}
+
+	set_sw_c_node_default(ctl->tm_c_node_array, index, ctl->rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_c_node_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_c_node(hndl, index);
+	if (rc)
+		return TM_HW_C_NODE_CONFIG_FAIL;
+
+	rc = set_hw_c_node_shaping_def(ctl, index);
+	if (rc)
+		return TM_HW_C_NODE_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_c_node_deficit_clear(hndl, index);
+	if (rc)
+		return TM_HW_C_NODE_CONFIG_FAIL;
+
+	return rc;
+}
+
+
+/**
+ */
+static int tm_delete_b_node(tm_handle hndl, uint32_t index)
+{
+
+	struct tm_b_node *b_node = NULL;
+	uint16_t range;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	b_node = &(ctl->tm_b_node_array[index]);
+	range = b_node->last_child_a_node - b_node->first_child_a_node + 1;
+	rc = rm_free_b_node(ctl->rm, index, range);
+	if (rc)
+		return rc;
+
+	ctl->tm_b_lvl_drop_prof_ptr[index] = 0;
+	ctl->tm_b_lvl_drop_profiles[b_node->wred_profile_ref].use_counter--;
+	set_sw_b_node_default(ctl->tm_b_node_array, index, ctl->rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_b_node_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_b_node(hndl, index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	rc = set_hw_b_node_shaping_def(ctl, index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_b_node_deficit_clear(hndl, index);
+	if (rc)
+		return TM_HW_B_NODE_CONFIG_FAIL;
+
+	return rc;
+}
+
+
+/**
+ */
+static int tm_delete_a_node(tm_handle hndl, uint32_t index)
+{
+	struct tm_a_node *a_node = NULL;
+	uint32_t range;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	a_node = &(ctl->tm_a_node_array[index]);
+	range = a_node->last_child_queue - a_node->first_child_queue + 1;
+	rc = rm_free_a_node(ctl->rm, index, range);
+	if (rc)
+		return rc;
+
+	ctl->tm_a_lvl_drop_prof_ptr[index] = 0;
+	ctl->tm_a_lvl_drop_profiles[a_node->wred_profile_ref].use_counter--;
+	set_sw_a_node_default(ctl->tm_a_node_array, index, ctl->rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_a_node_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_a_node(hndl, index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+
+	rc = set_hw_a_node_shaping_def(ctl, index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+
+	/* Clear DWRR Deficit */
+	rc = set_hw_a_node_deficit_clear(hndl, index);
+	if (rc)
+		return TM_HW_A_NODE_CONFIG_FAIL;
+	return rc;
+}
+
+
+/**
+ */
+static int tm_delete_queue(tm_handle hndl, uint32_t index)
+{
+	struct tm_queue *queue = NULL;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	queue = &(ctl->tm_queue_array[index]);
+	rc = rm_free_queue(ctl->rm, index);
+	if (rc)
+		return rc;
+
+	ctl->tm_q_lvl_drop_prof_ptr[index] = 0;
+	ctl->tm_q_lvl_drop_profiles[queue->wred_profile_ref].use_counter--;
+	set_sw_queue_default(ctl->tm_queue_array, index, rm);
+
+	/* Update SW image with DeQ disable function pointer */
+	ctl->tm_queue_array[index].elig_prio_func_ptr = 63;
+
+	rc = set_hw_queue(ctl, index);
+	if (rc)
+		return TM_HW_QUEUE_CONFIG_FAIL;
+
+	rc = set_hw_queue_shaping_def(ctl, index);
+	if (rc)
+		return TM_HW_QUEUE_CONFIG_FAIL;
+
+	/* Clear Queue DWRR Deficit */
+	rc = set_hw_queue_deficit_clear(ctl, index);
+	if (rc)
+		return TM_HW_QUEUE_CONFIG_FAIL;
+
+	return rc;
+}
+
+
+/**
+ */
+int tm_delete_node(tm_handle hndl, enum tm_level lvl, uint32_t index)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	switch (lvl) {
+	case P_LEVEL:
+		rc = rm_node_status(ctl->rm, P_LEVEL, index, &status);
+		if ((!rc) && (status != RM_TRUE)) rc = -ENODATA;
+		if (rc) goto out;
+		rc = tm_delete_port(hndl, (uint8_t)index);
+		break;
+	case C_LEVEL:
+		rc = rm_node_status(ctl->rm, C_LEVEL, index, &status);
+		if ((!rc) && (status != RM_TRUE)) rc = -ENODATA;
+		if (rc) goto out;
+		rc = tm_delete_c_node(hndl, index);
+		break;
+	case B_LEVEL:
+		rc = rm_node_status(ctl->rm, B_LEVEL, index, &status);
+		if ((!rc) && (status != RM_TRUE)) rc = -ENODATA;
+		if (rc) goto out;
+		rc = tm_delete_b_node(hndl, index);
+		break;
+	case A_LEVEL:
+		rc = rm_node_status(ctl->rm, A_LEVEL, index, &status);
+		if ((!rc) && (status != RM_TRUE)) rc = -ENODATA;
+		if (rc) goto out;
+		rc = tm_delete_a_node(hndl, index);
+		break;
+	case Q_LEVEL:
+		rc = rm_node_status(ctl->rm, Q_LEVEL, index, &status);
+		if ((!rc) && (status != RM_TRUE)) rc = -ENODATA;
+		if (rc) goto out;
+		rc = tm_delete_queue(hndl, index);
+		break;
+	default:
+		/* can't happend*/
+		rc = -ERANGE;
+	}
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_delete_trans_port(tm_handle hndl, uint8_t index)
+{
+	uint8_t status;
+	int rc;
+	int i;
+	int j;
+	int k;
+	int l;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	rc = rm_node_status(ctl->rm, P_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENOMSG;
+		goto out;
+	}
+
+
+	for (i = ctl->tm_port_array[index].first_child_c_node;
+		 i <= ctl->tm_port_array[index].last_child_c_node; i++)
+	{
+		rc = rm_node_status(ctl->rm, C_LEVEL, i, &status);
+		if (rc)
+			goto out;
+		if (status != RM_TRUE)
+			break;
+
+		for (j = ctl->tm_c_node_array[i].first_child_b_node;
+			 j <= ctl->tm_c_node_array[i].last_child_b_node; j++)
+		{
+			rc = rm_node_status(ctl->rm, B_LEVEL, j, &status);
+			if (rc)
+				goto out;
+			if (status != RM_TRUE)
+				break;
+
+			for (k = ctl->tm_b_node_array[j].first_child_a_node;
+				 k <= ctl->tm_b_node_array[j].last_child_a_node; k++)
+			{
+				rc = rm_node_status(ctl->rm, A_LEVEL, k, &status);
+				if (rc)
+					goto out;
+				if (status != RM_TRUE)
+					break;
+
+				for (l = ctl->tm_a_node_array[k].first_child_queue;
+					 l <= ctl->tm_a_node_array[k].last_child_queue; l++)
+				{
+					rc = tm_delete_queue(hndl, l);
+					if ((rc) && (rc != -ENOMSG))
+						goto out;
+				}
+				rc = tm_delete_a_node(hndl, k);
+				if (rc)
+					goto out;
+			}
+			rc = tm_delete_b_node(hndl, j);
+			if (rc)
+				goto out;
+		}
+		rc = tm_delete_c_node(hndl, i);
+		if (rc)
+			goto out;
+	}
+
+	rc = tm_delete_port(hndl, index);
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_nodes_read_next_change(tm_handle hndl, struct tm_tree_change *change)
+{
+	struct tm_tree_change *elem = NULL;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	elem = ctl->list.next;
+	if (elem == NULL) { /* empty list */
+		rc = -ENOBUFS;
+		goto out;
+	}
+
+	ctl->list.next = elem->next;
+	change->type = elem->type;
+	change->index = elem->index;
+	change->old_index = elem->old_index;
+	change->new_index = elem->new_index;
+	change->next = NULL;
+	tm_free(elem);
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_clean_list(tm_handle hndl)
+{
+
+	struct tm_tree_change *elem = NULL;
+	int rc = 0;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	while (ctl->list.next != NULL) {
+		elem = ctl->list.next;
+		ctl->list.next = elem->next;
+		tm_free(elem);
+	}
+	tm_nodes_unlock(TM_ENV(ctl));
+
+	return rc;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.h
new file mode 100644
index 0000000..616c814
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_ctl.h
@@ -0,0 +1,108 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_CTL_H
+#define TM_NODES_CTL_H
+
+#include "tm_core_types.h"
+
+/**  Delete node from scheduling hierarchy.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     level       Scheduling level: Queue/A/B/C-node/Port.
+ *   @param[in]     node_id     Node index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ERANGE if level is out of range.
+ *   @retval -EFAULT if node index is out of range.
+ *   @retval -ENODATA if node is not in use (free).
+ *   @retval -EBUSY if any of children is still in use.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_delete_node(tm_handle hndl, enum tm_level level, uint32_t node_id);
+
+
+/**  Delete port and all its subtree from scheduling hierarchy.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     index       Port index.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port index is out of range.
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if download to HW fails.
+ */
+int tm_delete_trans_port(tm_handle hndl, uint8_t index);
+
+
+/***************************************************************************
+ * Reshuffling
+ ***************************************************************************/
+
+/** Read next tree index/range change after reshuffling.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[out]    change          Change structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -@EINVAL if hndl is NULL.
+ *   @retval -@EBADF if hndl is invalid.
+ *   @retval -@ENOBUFS if list is empty.
+ */
+int tm_nodes_read_next_change(tm_handle hndl, struct tm_tree_change *change);
+
+
+/** Empty list of reshuffling changes.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -@EINVAL if hndl is NULL.
+ *   @retval -@EBADF if hndl is invalid.
+ */
+int tm_clean_list(tm_handle hndl);
+
+
+#endif   /* TM_NODES_CTL_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.c
new file mode 100644
index 0000000..944ada6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.c
@@ -0,0 +1,535 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_read.h"
+#include "tm_errcodes.h"
+#include "tm_nodes_utils.h"
+#include "tm_os_interface.h"
+#include "tm_locking_interface.h"
+
+#include "rm_internal_types.h"
+#include "rm_status.h"
+#include "set_hw_registers.h"
+
+
+/***************************************************************************
+ * Read Configuration
+ ***************************************************************************/
+
+/**
+ */
+int tm_read_queue_configuration(tm_handle hndl, uint32_t queue_index,
+								struct tm_queue_params *params)
+{
+	struct tm_queue *node = NULL;
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (queue_index >= rm->rm_total_queues) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(ctl->rm, Q_LEVEL, queue_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_queue_array[queue_index]);
+	params->quantum = node->dwrr_quantum;
+	params->wred_profile_ref = node->wred_profile_ref;
+	params->elig_prio_func_ptr = node->elig_prio_func_ptr;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_a_node_configuration(tm_handle hndl, uint32_t node_index,
+								struct tm_a_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_a_node *node = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_a_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, A_LEVEL, node_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_a_node_array[node_index]);
+	params->quantum = node->dwrr_quantum;
+	for (i = 0; i < 8; i++) {
+		if ((node->dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+	params->wred_profile_ref = node->wred_profile_ref;
+	params->elig_prio_func_ptr = node->elig_prio_func_ptr;
+	params->num_of_children = node->last_child_queue - node->first_child_queue + 1;
+
+	*p_first_child = node->first_child_queue;
+	*p_last_child = node->last_child_queue;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_b_node_configuration(tm_handle hndl, uint32_t node_index,
+								struct tm_b_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_b_node *node = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_b_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, B_LEVEL, node_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_b_node_array[node_index]);
+	params->quantum = node->dwrr_quantum;
+	for (i = 0; i < 8; i++) {
+		if ((node->dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+	params->wred_profile_ref = node->wred_profile_ref;
+	params->elig_prio_func_ptr = node->elig_prio_func_ptr;
+	params->num_of_children = node->last_child_a_node - node->first_child_a_node + 1;
+	*p_first_child = node->first_child_a_node;
+	*p_last_child = node->last_child_a_node;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_c_node_configuration(tm_handle hndl, uint32_t node_index,
+								struct tm_c_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_c_node *node = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_c_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, C_LEVEL, node_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_c_node_array[node_index]);
+	params->quantum = node->dwrr_quantum;
+	for (i = 0; i < 8; i++)
+		if ((node->dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	params->wred_cos = node->wred_cos;
+	for (i = 0; i < TM_WRED_COS; i++)
+		params->wred_profile_ref[i] = node->wred_profile_ref[i];
+	params->elig_prio_func_ptr = node->elig_prio_func_ptr;
+	params->num_of_children = node->last_child_b_node - node->first_child_b_node + 1;
+
+	*p_first_child = node->first_child_b_node;
+	*p_last_child = node->last_child_b_node;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+/**
+ */
+int tm_read_port_configuration(tm_handle hndl, uint32_t port_index,
+							struct tm_port_params *params,
+							struct tm_port_drop_per_cos *cos_params,
+							uint32_t *p_first_child,
+							uint32_t *p_last_child)
+{
+	struct tm_port *port = NULL;
+	uint8_t status;
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(ctl->rm, P_LEVEL, port_index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	port = &(ctl->tm_port_array[port_index]);
+
+	for (i = 0; i < 8; i++) {
+		if ((port->dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+
+	params->elig_prio_func_ptr = port->elig_prio_func_ptr;
+	params->wred_profile_ref = port->wred_profile_ref;
+
+#ifdef MV_QMTM_NSS_A0
+	for (i = 0; i < 8; i++)
+		params->quantum[i] = port->dwrr_quantum[i].quantum;
+#endif
+
+	cos_params->wred_cos = port->wred_cos;
+	for (i = 0; i < TM_WRED_COS; i++)
+		cos_params->wred_profile_ref[i] = port->wred_profile_ref_cos[i];
+	params->num_of_children = port->last_child_c_node - port->first_child_c_node + 1;
+	*p_first_child = port->first_child_c_node;
+	*p_last_child = port->last_child_c_node;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+/**
+ */
+int tm_read_queue_configuration_hw(tm_handle hndl, uint32_t index,
+								struct tm_queue_params *params)
+{
+	struct tm_queue node = {0};
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (index >= rm->rm_total_queues) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = get_hw_queue(ctl, index, &node);
+	if (rc)
+		goto out;
+	params->quantum = node.dwrr_quantum;
+	params->wred_profile_ref = node.wred_profile_ref;
+	params->elig_prio_func_ptr = node.elig_prio_func_ptr;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_a_node_configuration_hw(tm_handle hndl, uint32_t node_index,
+								struct tm_a_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_a_node node = {0};
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_a_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = get_hw_a_node(ctl, node_index, &node);
+	if (rc)
+		goto out;
+	params->quantum = node.dwrr_quantum;
+	for (i = 0; i < 8; i++) {
+		if ((node.dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+	params->wred_profile_ref = node.wred_profile_ref;
+	params->elig_prio_func_ptr = node.elig_prio_func_ptr;
+	params->num_of_children = node.last_child_queue - node.first_child_queue + 1;
+
+	*p_first_child = node.first_child_queue;
+	*p_last_child = node.last_child_queue;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_b_node_configuration_hw(tm_handle hndl, uint32_t node_index,
+								struct tm_b_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_b_node node = {0};
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_b_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = get_hw_b_node(ctl, node_index, &node);
+	if (rc)
+		goto out;
+	params->quantum = node.dwrr_quantum;
+	for (i = 0; i < 8; i++) {
+		if ((node.dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+	params->wred_profile_ref = node.wred_profile_ref;
+	params->elig_prio_func_ptr = node.elig_prio_func_ptr;
+	params->num_of_children = node.last_child_a_node - node.first_child_a_node + 1;
+
+	*p_first_child = node.first_child_a_node;
+	*p_last_child = node.last_child_a_node;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_c_node_configuration_hw(tm_handle hndl, uint32_t node_index,
+								struct tm_c_node_params *params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child)
+{
+	struct tm_c_node node = {0};
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (node_index >= rm->rm_total_c_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = get_hw_c_node(ctl, node_index, &node);
+	if (rc)
+		goto out;
+	params->quantum = node.dwrr_quantum;
+	for (i = 0; i < 8; i++)
+		if ((node.dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	for (i = 0; i < TM_WRED_COS; i++)
+		params->wred_profile_ref[i] = node.wred_profile_ref[i];
+	params->elig_prio_func_ptr = node.elig_prio_func_ptr;
+	params->num_of_children = node.last_child_b_node - node.first_child_b_node + 1;
+
+	*p_first_child = node.first_child_b_node;
+	*p_last_child = node.last_child_b_node;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+/**
+ */
+int tm_read_port_configuration_hw(tm_handle hndl, uint32_t port_index,
+							struct tm_port_params *params,
+							struct tm_port_drop_per_cos *cos_params,
+							uint32_t *p_first_child,
+							uint32_t *p_last_child)
+{
+	struct tm_port port = {0};
+	int rc = 0;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (port_index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = get_hw_port(ctl, port_index, &port);
+	if (rc)
+		goto out;
+
+	for (i = 0; i < 8; i++) {
+		if ((port.dwrr_priority & (1 << i)) != 0)
+			params->dwrr_priority[i] = TM_ENABLE;
+		else
+			params->dwrr_priority[i] = TM_DISABLE;
+	}
+
+	params->elig_prio_func_ptr = port.elig_prio_func_ptr;
+	params->num_of_children = port.last_child_c_node - port.first_child_c_node + 1;
+
+
+	*p_first_child = port.first_child_c_node;
+	*p_last_child = port.last_child_c_node;
+
+#ifdef MV_QMTM_NSS_A0
+	for (i = 0; i < 8; i++)
+		params->quantum[i] = port.dwrr_quantum[i].quantum;
+#endif
+
+	/* No Drop Profile Ptrs in HW, will be replaced by SW */
+	params->wred_profile_ref = ctl->tm_port_array[port_index].wred_profile_ref;
+	cos_params->wred_cos = ctl->tm_port_array[port_index].wred_cos;
+	for (i = 0; i < TM_WRED_COS; i++)
+		cos_params->wred_profile_ref[i] = ctl->tm_port_array[port_index].wred_profile_ref_cos[i];
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.h
new file mode 100644
index 0000000..ba32fcb
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_read.h
@@ -0,0 +1,228 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_READ_H
+#define TM_NODES_READ_H
+
+#include "tm_core_types.h"
+
+
+/***************************************************************************
+ * Read Configuration
+ ***************************************************************************/
+
+/** Read queue software configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     queue_index     Queue index.
+ *   @param[out]    q_params        Queue parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if queue_index is out of range.
+ *   @retval -ENODATA if queue_index is not in use.
+ */
+int tm_read_queue_configuration(tm_handle hndl, uint32_t queue_index,
+								struct tm_queue_params *q_params);
+
+
+/** Read A-node software configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     a_node_index    A-node index.
+ *   @param[out]    a_params        A-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if a_node_index is out of range.
+ *   @retval -ENODATA if a_node_index is not in use.
+ */
+int tm_read_a_node_configuration(tm_handle hndl, uint32_t a_node_index,
+								struct tm_a_node_params *a_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read B-node software configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     b_node_index    B-node index.
+ *   @param[out]    b_params        B-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if b_node_index is out of range.
+ *   @retval -ENODATA if b_node_index is not in use.
+ */
+int tm_read_b_node_configuration(tm_handle hndl, uint32_t b_node_index,
+								struct tm_b_node_params *b_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read C-node software configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index.
+ *   @param[out]    c_params        C-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if c_node_index is out of range.
+ *   @retval -ENODATA if c_node_index is not in use.
+ */
+int tm_read_c_node_configuration(tm_handle hndl, uint32_t c_node_index,
+								struct tm_c_node_params *c_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read Port software configuration.
+ *
+ *   @param[in]     hndl          TM lib handle.
+ *   @param[in]     port_index    Port index.
+ *   @param[out]    params        Port parameters structure pointer.
+ *
+ *   @note The CIR and EIR bw may deviate from the originally configured
+ *   by tm_create_port or tm_update_port by the
+ *   bw accuracy parameter for P_LEVEL provisioned in tm_configure_periodic_scheme API.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_index is out of range.
+ *   @retval -ENODATA if port_index is not in use.
+ */
+int tm_read_port_configuration(tm_handle hndl, uint32_t port_index,
+							struct tm_port_params *params,
+							struct tm_port_drop_per_cos *cos_params,
+							uint32_t *p_first_child,
+							uint32_t *p_last_child);
+
+
+/** Read queue hardware configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     queue_index     Queue index.
+ *   @param[out]    q_params        Queue parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if queue_index is out of range.
+ */
+int tm_read_queue_configuration_hw(tm_handle hndl, uint32_t queue_index,
+								struct tm_queue_params *params);
+
+
+/** Read A-node hardware configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     a_node_index    A-node index.
+ *   @param[out]    a_params        A-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if a_node_index is out of range.
+ */
+int tm_read_a_node_configuration_hw(tm_handle hndl, uint32_t a_node_index,
+								struct tm_a_node_params *a_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read B-node hardware configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     b_node_index    B-node index.
+ *   @param[out]    b_params        B-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if b_node_index is out of range.
+ */
+int tm_read_b_node_configuration_hw(tm_handle hndl, uint32_t b_node_index,
+								struct tm_b_node_params *b_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read C-node hardware configuration.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index.
+ *   @param[out]    c_params        C-node parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if c_node_index is out of range.
+ */
+int tm_read_c_node_configuration_hw(tm_handle hndl, uint32_t c_node_index,
+								struct tm_c_node_params *c_params,
+								uint32_t *p_first_child,
+								uint32_t *p_last_child);
+
+
+/** Read Port hardware configuration.
+ *
+ *   @param[in]     hndl          TM lib handle.
+ *   @param[in]     port_index    Port index.
+ *   @param[out]    params        Port parameters structure pointer.
+ *
+ *   @note Drop Profile references only still are taken from SW.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_index is out of range.
+ */
+int tm_read_port_configuration_hw(tm_handle hndl, uint32_t port_index,
+							struct tm_port_params *params,
+							struct tm_port_drop_per_cos *cos_params,
+							uint32_t *p_first_child,
+							uint32_t *p_last_child);
+
+#endif   /* TM_NODES_READ_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.c
new file mode 100644
index 0000000..81ee9da
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.c
@@ -0,0 +1,661 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_reorder.h"
+#include "tm_errcodes.h"
+#include "rm_internal_types.h"
+#include "rm_reorder.h"
+#include "rm_status.h"
+#include "set_hw_registers.h"
+#include "tm_locking_interface.h"
+
+/**
+ */
+static int tm_reorder_check_node(tm_handle hndl, enum tm_level level, uint16_t node)
+{
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	switch (level) {
+	case A_LEVEL:
+		if (node >= rm->rm_total_a_nodes)
+			return TM_CONF_A_NODE_IND_OOR;
+		break;
+	case B_LEVEL:
+		if (node >= rm->rm_total_b_nodes)
+			return TM_CONF_B_NODE_IND_OOR;
+		break;
+	case C_LEVEL:
+		if (node >= rm->rm_total_c_nodes)
+			return TM_CONF_C_NODE_IND_OOR;
+		break;
+	case P_LEVEL:
+		if (node >= rm->rm_total_ports)
+			return TM_CONF_PORT_IND_OOR;
+		break;
+	default:
+		return -ERANGE;
+	}
+	return 0;
+}
+
+
+/**
+ */
+static int tm_reorder_get_node_children(tm_handle hndl,
+										enum tm_level level,
+										uint16_t node_index,
+										uint16_t *first_child_node,
+										uint16_t *last_child_node)
+{
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	switch (level) {
+	case A_LEVEL:
+		*first_child_node = ctl->tm_a_node_array[node_index].first_child_queue;
+		*last_child_node = ctl->tm_a_node_array[node_index].last_child_queue;
+		break;
+	case B_LEVEL:
+		*first_child_node = (uint16_t) ctl->tm_b_node_array[node_index].first_child_a_node;
+		*last_child_node = (uint16_t) ctl->tm_b_node_array[node_index].last_child_a_node;
+		break;
+	case C_LEVEL:
+		*first_child_node = (uint16_t) ctl->tm_c_node_array[node_index].first_child_b_node;
+		*last_child_node = (uint16_t) ctl->tm_c_node_array[node_index].last_child_b_node;
+		break;
+	case P_LEVEL:
+		*first_child_node = (uint16_t) ctl->tm_port_array[node_index].first_child_c_node;
+		*last_child_node = (uint16_t) ctl->tm_port_array[node_index].last_child_c_node;
+		break;
+	default:
+		return -ERANGE;
+	}
+	return 0;
+}
+
+
+/**
+ */
+static int tm_reorder_nodes_on_off(tm_handle hndl,
+								   enum tm_level level,
+								   uint16_t parent_node,
+								   uint16_t first_child_node,
+								   uint16_t last_child_node,
+								   uint8_t enable)
+{
+	int rc;
+	uint16_t i;
+	uint8_t elig_status;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (enable) {
+		rc = set_hw_deq_status(hndl, level, parent_node);
+		if (rc)
+			return rc;
+		for (i = first_child_node; i <= last_child_node; i++) {
+			rc = set_hw_deq_status(hndl, (enum tm_level)(level-1), i);
+			if (rc)
+				return rc;
+		}
+	} else { /* Disable all DeQ */
+		switch (level) {
+		case A_LEVEL:
+			elig_status = ctl->tm_a_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_a_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, level, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_a_node_array[parent_node].elig_prio_func_ptr = elig_status;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				elig_status = ctl->tm_queue_array[i].elig_prio_func_ptr;
+				ctl->tm_queue_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, Q_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_queue_array[i].elig_prio_func_ptr = elig_status;
+			}
+			break;
+		case B_LEVEL:
+			elig_status = ctl->tm_b_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_b_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, level, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_b_node_array[parent_node].elig_prio_func_ptr = elig_status;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				elig_status = ctl->tm_a_node_array[i].elig_prio_func_ptr;
+				ctl->tm_a_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, A_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_a_node_array[i].elig_prio_func_ptr = elig_status;
+			}
+			break;
+		case C_LEVEL:
+			elig_status = ctl->tm_c_node_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_c_node_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, level, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_c_node_array[parent_node].elig_prio_func_ptr = elig_status;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				elig_status = ctl->tm_b_node_array[i].elig_prio_func_ptr;
+				ctl->tm_b_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, B_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_b_node_array[i].elig_prio_func_ptr = elig_status;
+			}
+			break;
+		case P_LEVEL:
+			elig_status = ctl->tm_port_array[parent_node].elig_prio_func_ptr;
+			ctl->tm_port_array[parent_node].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+			rc = set_hw_deq_status(ctl, level, parent_node);
+			if (rc)
+				return rc;
+			ctl->tm_port_array[parent_node].elig_prio_func_ptr = elig_status;
+
+			for (i = first_child_node; i <= last_child_node; i++) {
+				elig_status = ctl->tm_c_node_array[i].elig_prio_func_ptr;
+				ctl->tm_c_node_array[i].elig_prio_func_ptr = TM_ELIG_DEQ_DISABLE;
+				rc = set_hw_deq_status(ctl, C_LEVEL, i);
+				if (rc)
+					return rc;
+				ctl->tm_c_node_array[i].elig_prio_func_ptr = elig_status;
+			}
+			break;
+		default:
+			return -ERANGE;
+		}
+	}
+	return 0;
+}
+
+
+/**
+ */
+int tm_nodes_move(tm_handle hndl,
+		enum tm_level level,
+		uint16_t number_of_children,
+		uint16_t from_node,
+		uint16_t to_node)
+{
+	int rc;
+	int i;
+	int direction = 0;
+	uint8_t status;
+	uint16_t first_child_node_from_node;
+	uint16_t last_child_node_from_node;
+	uint16_t first_child_node_to_node;
+	uint16_t last_child_node_to_node;
+	uint16_t first_child_to_move;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	if ((level < A_LEVEL) || (level > P_LEVEL))
+		return -ERANGE;
+
+	rc = tm_reorder_check_node(hndl, level, from_node);
+	if (rc)
+		return rc;
+
+	rc = tm_reorder_check_node(hndl, level, to_node);
+	if (rc)
+		return rc;
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check SW model that operation is possible */
+	rc = rm_node_status(rm, level, from_node, &status);
+	if (rc || (status != RM_TRUE))
+		goto err_out;
+
+	rc = rm_node_status(rm, level, to_node, &status);
+	if (rc || (status != RM_TRUE))
+		goto err_out;
+
+	rc = tm_reorder_get_node_children(hndl, level, from_node,
+									  &first_child_node_from_node,
+									  &last_child_node_from_node);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_get_node_children(hndl, level, to_node,
+									  &first_child_node_to_node,
+									  &last_child_node_to_node);
+	if (rc)
+		goto err_out;
+
+	/* Check special node modification conditions */
+	if (last_child_node_from_node - first_child_node_from_node < number_of_children)
+	{
+		rc = TM_CONF_REORDER_CHILDREN_NOT_AVAIL;
+		goto err_out;
+	}
+
+	/* Ensure the children of the from_node and to_node are adjecent */
+	if (last_child_node_from_node + 1 == first_child_node_to_node)
+		direction = 1;
+	else if (last_child_node_to_node + 1 == first_child_node_from_node)
+		direction = -1;
+	if (!direction)
+	{
+		rc = TM_CONF_REORDER_NODES_NOT_ADJECENT;
+		goto err_out;
+	}
+
+	/* Calculate new values for parent nodes */
+	if (direction > 0)
+	{
+		first_child_to_move = first_child_node_to_node - number_of_children;
+		first_child_node_to_node = first_child_to_move;
+		last_child_node_from_node = first_child_to_move - 1;
+	} else {
+		first_child_to_move = first_child_node_from_node;
+		first_child_node_from_node = first_child_to_move + number_of_children;
+		last_child_node_to_node = first_child_node_from_node - 1;
+	}
+
+
+	/* Disable dequeing on all child and parent node */
+	rc = tm_reorder_nodes_on_off(hndl, level, from_node, first_child_to_move,
+		(uint16_t)(first_child_to_move + number_of_children - 1), TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_nodes_on_off(hndl, level, to_node, 0, 0, TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	/* Move children, reconfigure parents */
+	switch (level)
+	{
+	case A_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_Q_LVL, from_node, to_node, number_of_children, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_a_node_array[from_node].first_child_queue = first_child_node_from_node;
+		ctl->tm_a_node_array[from_node].last_child_queue = last_child_node_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_a_node_array[to_node].first_child_queue = first_child_node_to_node;
+		ctl->tm_a_node_array[to_node].last_child_queue = last_child_node_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_to_move; i < first_child_to_move + number_of_children; i++)
+		{
+			ctl->tm_queue_array[i].parent_a_node = to_node;
+			rc = set_hw_map(ctl, Q_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case B_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_A_LVL, from_node, to_node, number_of_children, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_b_node_array[from_node].first_child_a_node = first_child_node_from_node;
+		ctl->tm_b_node_array[from_node].last_child_a_node = last_child_node_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_b_node_array[to_node].first_child_a_node = first_child_node_to_node;
+		ctl->tm_b_node_array[to_node].last_child_a_node = last_child_node_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_to_move; i < first_child_to_move + number_of_children; i++)
+		{
+			ctl->tm_a_node_array[i].parent_b_node = to_node;
+			rc = set_hw_map(ctl, A_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case C_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_B_LVL, from_node, to_node, number_of_children, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_c_node_array[from_node].first_child_b_node = first_child_node_from_node;
+		ctl->tm_c_node_array[from_node].last_child_b_node = last_child_node_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_c_node_array[to_node].first_child_b_node = first_child_node_to_node;
+		ctl->tm_c_node_array[to_node].last_child_b_node = last_child_node_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_to_move; i < first_child_to_move + number_of_children; i++)
+		{
+			ctl->tm_b_node_array[i].parent_c_node = to_node;
+			rc = set_hw_map(ctl, B_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case P_LEVEL:
+		/* RM */
+		rc = rm_nodes_move(rm, RM_C_LVL, from_node, to_node, number_of_children, first_child_to_move);
+		if (rc)
+			goto err_out;
+
+		/* TM */
+		ctl->tm_port_array[from_node].first_child_c_node = first_child_node_from_node;
+		ctl->tm_port_array[from_node].last_child_c_node = last_child_node_from_node;
+		rc = set_hw_map(ctl, level, from_node);
+		if (rc)
+			goto err_out;
+
+		ctl->tm_port_array[to_node].first_child_c_node = first_child_node_to_node;
+		ctl->tm_port_array[to_node].last_child_c_node = last_child_node_to_node;
+		rc = set_hw_map(ctl, level, to_node);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_to_move; i < first_child_to_move + number_of_children; i++)
+		{
+			ctl->tm_c_node_array[i].parent_port = (uint8_t)to_node;
+			rc = set_hw_map(ctl, C_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/* Enable all nodes again in HW from SW model*/
+	rc = tm_reorder_nodes_on_off(hndl, level, from_node, first_child_to_move,
+		(uint16_t)(first_child_to_move + number_of_children - 1), TM_ENABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_nodes_on_off(hndl, level, to_node, 0, 0, TM_ENABLE);
+
+err_out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_nodes_switch(tm_handle hndl,
+					enum tm_level level,
+					uint16_t node_a,
+					uint16_t node_b)
+{
+	int rc, i;
+	uint8_t status;
+	uint16_t first_child_node_a;
+	uint16_t last_child_node_a;
+	uint16_t first_child_node_b;
+	uint16_t last_child_node_b;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	if ((level < A_LEVEL) || (level > P_LEVEL))
+		return -ERANGE;
+
+	rc = tm_reorder_check_node(hndl, level, node_a);
+	if (rc)
+		return rc;
+
+	rc = tm_reorder_check_node(hndl, level, node_b);
+	if (rc)
+		return rc;
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check SW model that operation is possible */
+	rc = rm_node_status(rm, level, node_a, &status);
+	if (rc || (status != RM_TRUE))
+		goto err_out;
+
+	rc = rm_node_status(rm, level, node_b, &status);
+	if (rc || (status != RM_TRUE))
+		goto err_out;
+
+	/* Retrieve values for both parents on children used */
+	rc = tm_reorder_get_node_children(hndl, level, node_a, &first_child_node_a, &last_child_node_a);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_get_node_children(hndl, level, node_b, &first_child_node_b, &last_child_node_b);
+	if (rc)
+		goto err_out;
+
+	/* Disable dequeing on all child and parent node */
+	rc = tm_reorder_nodes_on_off(hndl, level, node_a, first_child_node_a, last_child_node_a, TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_nodes_on_off(hndl, level, node_b, first_child_node_b, last_child_node_b, TM_DISABLE);
+	if (rc)
+		goto err_out;
+
+	/* Move children, switch parents */
+	switch (level)
+	{
+	case A_LEVEL:
+		rc  = rm_nodes_switch(rm, RM_Q_LVL, node_a, node_b,
+							  first_child_node_a, last_child_node_a,
+							  first_child_node_b, last_child_node_b);
+		if (rc)
+			goto err_out;
+
+		/* Update node_a... */
+		ctl->tm_a_node_array[node_a].first_child_queue = first_child_node_b;
+		ctl->tm_a_node_array[node_a].last_child_queue = last_child_node_b;
+		rc = set_hw_map(ctl, level, node_a);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_b; i <= last_child_node_b ; i++)
+		{
+			ctl->tm_queue_array[i].parent_a_node = node_a;
+			rc = set_hw_map(ctl, Q_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+
+		/* Update node_b... */
+		ctl->tm_a_node_array[node_b].first_child_queue = first_child_node_a;
+		ctl->tm_a_node_array[node_b].last_child_queue = last_child_node_a;
+		rc = set_hw_map(ctl, level, node_b);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_a; i <= last_child_node_a ; i++)
+		{
+			ctl->tm_queue_array[i].parent_a_node = node_b;
+			rc = set_hw_map(ctl, Q_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case B_LEVEL:
+		rc  = rm_nodes_switch(rm, RM_A_LVL, node_a, node_b,
+							  first_child_node_a, last_child_node_a,
+							  first_child_node_b, last_child_node_b);
+		if (rc)
+			goto err_out;
+
+		/* Update node_a... */
+		ctl->tm_b_node_array[node_a].first_child_a_node = first_child_node_b;
+		ctl->tm_b_node_array[node_a].last_child_a_node = last_child_node_b;
+		rc = set_hw_map(ctl, level, node_a);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_b; i <= last_child_node_b ; i++)
+		{
+			ctl->tm_a_node_array[i].parent_b_node = node_a;
+			rc = set_hw_map(ctl, A_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+
+		/* Update node_b... */
+		ctl->tm_b_node_array[node_b].first_child_a_node = first_child_node_a;
+		ctl->tm_b_node_array[node_b].last_child_a_node = last_child_node_a;
+		rc = set_hw_map(ctl, level, node_b);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_a; i <= last_child_node_a ; i++)
+		{
+			ctl->tm_a_node_array[i].parent_b_node = node_b;
+			rc = set_hw_map(ctl, A_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case C_LEVEL:
+		rc  = rm_nodes_switch(rm, RM_B_LVL, node_a, node_b,
+							  first_child_node_a, last_child_node_a,
+							  first_child_node_b, last_child_node_b);
+		if (rc)
+			goto err_out;
+
+		/* Update node_a... */
+		ctl->tm_c_node_array[node_a].first_child_b_node = first_child_node_b;
+		ctl->tm_c_node_array[node_a].last_child_b_node = last_child_node_b;
+		rc = set_hw_map(ctl, level, node_a);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_b; i <= last_child_node_b ; i++)
+		{
+			ctl->tm_b_node_array[i].parent_c_node = node_a;
+			rc = set_hw_map(ctl, B_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+
+		/* Update node_b... */
+		ctl->tm_c_node_array[node_b].first_child_b_node = first_child_node_a;
+		ctl->tm_c_node_array[node_b].last_child_b_node = last_child_node_a;
+		rc = set_hw_map(ctl, level, node_b);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_a; i <= last_child_node_a ; i++)
+		{
+			ctl->tm_b_node_array[i].parent_c_node = node_b;
+			rc = set_hw_map(ctl, B_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	case P_LEVEL:
+		rc  = rm_nodes_switch(rm, RM_C_LVL, node_a, node_b,
+							  first_child_node_a, last_child_node_a,
+							  first_child_node_b, last_child_node_b);
+		if (rc)
+			goto err_out;
+
+		/* Update node_a... */
+		ctl->tm_port_array[node_a].first_child_c_node = first_child_node_b;
+		ctl->tm_port_array[node_a].last_child_c_node = last_child_node_b;
+		rc = set_hw_map(ctl, level, node_a);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_b; i <= last_child_node_b ; i++)
+		{
+			ctl->tm_c_node_array[i].parent_port = (uint8_t)node_a;
+			rc = set_hw_map(ctl, C_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+
+		/* Update node_b... */
+		ctl->tm_port_array[node_b].first_child_c_node = first_child_node_a;
+		ctl->tm_port_array[node_b].last_child_c_node = last_child_node_a;
+		rc = set_hw_map(ctl, level, node_b);
+		if (rc)
+			goto err_out;
+
+		for (i = first_child_node_a; i <= last_child_node_a ; i++)
+		{
+			ctl->tm_c_node_array[i].parent_port = (uint8_t)node_b;
+			rc = set_hw_map(ctl, C_LEVEL, i);
+			if (rc)
+				goto err_out;
+		}
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/* Enable all nodes again in HW */
+	rc = tm_reorder_nodes_on_off(hndl, level, node_a, first_child_node_a, last_child_node_a, TM_ENABLE);
+	if (rc)
+		goto err_out;
+
+	rc = tm_reorder_nodes_on_off(hndl, level, node_b, first_child_node_b, last_child_node_b, TM_ENABLE);
+
+err_out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.h
new file mode 100644
index 0000000..c770a36
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_reorder.h
@@ -0,0 +1,82 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_REORDER_H
+#define TM_NODES_REORDER_H
+
+#include "tm_core_types.h"
+
+
+ /** Move a number of children from one parent node to another.
+  *  The two nodes must have children with adjecent indicies.
+  *  The from_node must have number_of_children + 1 children.
+  *
+  *  @param[in]    hndl                 TM lib handle
+  *  @param[in]    level                Node level of parents
+  *  @param[in]    number_of_children   The number of children to move
+  *  @param[in]    from_node            Parent node to move children from
+  *  @param[in]    to_node              Parent node to move children to
+  *
+  *  @return an integer return code
+  *  @retval 0 on success
+  *  @retval -EINVAL if hndl is NULL
+  *  @retval -EBADF if hndl is invalid
+  *  @retval -ERANGE if level is invalid
+  *  @retval TM_CONF_[LEVEL]_NODE_IND_OOR if node index is not available on level
+  *  @retval TM_CONF_REORDER_CHILDREN_NOT_AVAIL if from_node does not have enough children for operation
+  *  @retval TM_CONF_REORDER_NODES_NOT_ADJECENT if from_node and to_node do not have adjecent children nodes
+  */
+int tm_nodes_move(tm_handle hndl,
+				  enum tm_level level,
+				  uint16_t number_of_children,
+				  uint16_t from_node,
+				  uint16_t to_node);
+
+
+ /** Switch children between two nodes.
+  *
+  *  @param[in]    hndl                 TM lib handle
+  *  @param[in]    level                Node level
+  *  @param[in]    node_a               Node A index in switch
+  *  @param[in]    node_b               Node B index in switch
+  *
+  *  @return an integer return code
+  *  @retval 0 on success
+  *  @retval -EINVAL if hndl is NULL
+  *  @retval -EBADF if hndl is invalid
+  *  @retval -ERANGE if level is invalid
+  *  @retval TM_CONF_[LEVEL]_NODE_IND_OOR if node index is not available on level
+  */
+int tm_nodes_switch(tm_handle hndl,
+					enum tm_level level,
+					uint16_t node_a,
+					uint16_t node_b);
+
+
+#endif   /* TM_NODES_REORDER_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.c
new file mode 100644
index 0000000..b68f275
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.c
@@ -0,0 +1,296 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_status.h"
+#include "rm_internal_types.h"
+#include "rm_status.h"
+#include "tm_errcodes.h"
+#include "tm_nodes_utils.h"
+#include "tm_locking_interface.h"
+#include "set_hw_registers.h"
+
+
+/**
+ */
+int tm_read_port_status(tm_handle hndl,
+						uint8_t index,
+						struct tm_port_status *tm_status)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	if (index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = -ENODATA;
+		goto out;
+	}
+
+	rc = get_hw_port_status(ctl, index, tm_status);
+	if (rc)
+		rc = TM_HW_READ_PORT_STATUS_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_c_node_status(tm_handle hndl,
+						  uint32_t index,
+						  struct tm_node_status *tm_status)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_c_nodes)
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, C_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = -ENODATA;
+		goto out;
+	}
+
+	rc = get_hw_c_node_status(ctl, index, tm_status);
+	if (rc)
+		rc = TM_HW_READ_C_NODE_STATUS_FAIL;
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_b_node_status(tm_handle hndl,
+						  uint32_t index,
+						  struct tm_node_status *tm_status)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_b_nodes)
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, B_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = -ENODATA;
+		goto out;
+	}
+
+	rc = get_hw_b_node_status(ctl, index, tm_status);
+	if (rc)
+		rc = TM_HW_READ_B_NODE_STATUS_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_a_node_status(tm_handle hndl,
+						  uint32_t index,
+						  struct tm_node_status *tm_status)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_a_nodes)
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, A_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = -ENODATA;
+		goto out;
+	}
+
+
+	rc = get_hw_a_node_status(ctl, index, tm_status);
+	if (rc)
+		rc = TM_HW_READ_A_NODE_STATUS_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_read_queue_status(tm_handle hndl,
+						 uint32_t index,
+						 struct tm_node_status *tm_status)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_queues) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, Q_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	rc = get_hw_queue_status(ctl, index, tm_status);
+	if (rc)
+		rc = TM_HW_READ_QUEUE_STATUS_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_drop_get_queue_length(tm_handle hndl,
+							 enum tm_level level,
+							 uint32_t index,
+							 uint32_t *av_q_length)
+{
+	uint8_t status;
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	switch (level)
+	{
+	case Q_LEVEL:
+		if (index >= rm->rm_total_queues)
+			rc = -EFAULT;
+		break;
+	case A_LEVEL:
+		if (index >= rm->rm_total_a_nodes)
+			rc = -EFAULT;
+		break;
+	case B_LEVEL:
+		if (index >= rm->rm_total_b_nodes)
+			rc = -EFAULT;
+		break;
+	case C_LEVEL:
+		if (index >= rm->rm_total_c_nodes)
+			rc = -EFAULT;
+		break;
+	case P_LEVEL:
+		if (index >= rm->rm_total_ports)
+			rc = -EFAULT;
+		break;
+	default:
+		rc = -ERANGE;
+	}
+	if (rc)
+		goto out;
+
+	rc = rm_node_status(rm, level, index, &status);
+	if ((rc) || (status != RM_TRUE))
+	{
+		rc = -ENODATA;
+		goto out;
+	}
+
+	rc = get_hw_queue_length(ctl, level, index,
+							av_q_length);
+	if (rc)
+		rc = TM_HW_GET_QUEUE_LENGTH_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.h
new file mode 100644
index 0000000..45ab06e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_status.h
@@ -0,0 +1,148 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_STATUS_H
+#define TM_NODES_STATUS_H
+
+#include "tm_core_types.h"
+
+
+/**  Read Port status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     port_id     Port index.
+ *   @param[out]    status      Port status structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_id is out of range.
+ *   @retval -ENODATA if port_id is not in use.
+ *   @retval TM_HW_READ_PORT_STATUS_FAIL if read from HW fails.
+ */
+int tm_read_port_status(tm_handle hndl, uint8_t port_id,
+						struct tm_port_status *status);
+
+
+/**  Read C-node status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     c_node_ind  C-node index.
+ *   @param[out]    status      Node status structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if c_node_ind is out of range.
+ *   @retval -ENODATA if c_node_ind is not in use.
+ *   @retval TM_HW_READ_C_NODE_STATUS_FAIL if read from HW fails.
+ */
+int tm_read_c_node_status(tm_handle hndl, uint32_t c_node_ind,
+						  struct tm_node_status *status);
+
+
+/**  Read B-node status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     b_node_ind  B-node ind.
+ *   @param[out]    status      Node status structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if b_node_ind is out of range.
+ *   @retval -ENODATA if b_node_ind is not in use.
+ *   @retval TM_HW_READ_B_NODE_STATUS_FAIL if read from HW fails.
+ */
+int tm_read_b_node_status(tm_handle hndl, uint32_t b_node_ind,
+						  struct tm_node_status *status);
+
+
+/**  Read A-node status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     a_node_ind  A-node ind.
+ *   @param[out]    status      Node status structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if a_node_ind is out of range.
+ *   @retval -ENODATA if a_node_ind is not in use.
+ *   @retval TM_HW_READ_A_NODE_STATUS_FAIL if read from HW fails.
+ */
+int tm_read_a_node_status(tm_handle hndl, uint32_t a_node_ind,
+						  struct tm_node_status *status);
+
+
+/**  Read Queue status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     queue_ind   Queue index.
+ *   @param[out]    status      Node status structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if queue_ind is out of range.
+ *   @retval -ENODATA if queue_ind is not in use.
+ *   @retval TM_HW_READ_Q_STATUS_FAIL if read from HW fails.
+ */
+int tm_read_queue_status(tm_handle hndl, uint32_t queue_ind,
+						 struct tm_node_status *status);
+
+
+/**  Read Queue drop length.
+ *
+ *   @param[in]     hndl                TM lib handle.
+ *   @param[in]     lvl                 TM level.
+ *   @param[in]     index               Port/node/queue index.
+ *   @param[out]    av_queue_length     Pointer to average Queue length.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -ERANGE if level is out of range.
+ *   @retval -EFAULT if index is out of range.
+ *   @retval -ENODATA if index is not in use.
+ *   @retval TM_HW_GET_QUEUE_LENGTH_FAIL if read from HW fails.
+ */
+int tm_drop_get_queue_length(tm_handle hndl,
+							 enum tm_level lvl,
+							 uint32_t index,
+							 uint32_t *av_queue_length);
+
+
+#endif   /* TM_NODES_STATUS_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.c
new file mode 100644
index 0000000..5606e0e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.c
@@ -0,0 +1,104 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_tree.h"
+
+#include "tm_locking_interface.h"
+#include "tm_errcodes.h"
+
+#include "set_hw_registers.h"
+
+
+/**
+ */
+int tm_tree_change_status(tm_handle hndl, uint8_t status)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	if ((status != TM_ENABLE) && (status != TM_DISABLE))
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	ctl->tree_deq_status = status;
+
+	rc = set_hw_tree_deq_status(hndl);
+	if (rc < 0)
+		rc = TM_HW_TREE_CONFIG_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+#ifdef MV_QMTM_NSS_A0
+/**
+ */
+int tm_tree_set_dwrr_prio(tm_handle hndl, uint8_t * prios)
+{
+	int rc ;
+	int i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	ctl->tree_dwrr_priority = 0;
+	for (i = 0; i < 8; i++)
+	{
+		if ((prios[i] != TM_ENABLE) && (prios[i] != TM_DISABLE))
+		{
+			rc = -EFAULT;
+			goto out;
+		}
+		ctl->tree_dwrr_priority = ctl->tree_dwrr_priority | (prios[i] << i);
+	}
+
+	rc = set_hw_tree_dwrr_priority(hndl);
+	if (rc)
+		rc = TM_HW_TREE_CONFIG_FAIL;
+
+out:
+	if (rc < 0)
+		ctl->tree_dwrr_priority = 0;
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+#endif
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.h
new file mode 100644
index 0000000..dd7c83a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_tree.h
@@ -0,0 +1,69 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_TREE_H
+#define TM_NODES_TREE_H
+
+#include "tm_core_types.h"
+
+
+/**  Change the tree DeQ status.
+ *
+ *   @param[in]     hndl        TM lib handle.
+ *   @param[in]     status      Tree status.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if status is out of range.
+ *   @retval TM_HW_TREE_CONFIG_FAIL if download to HW fails.
+ */
+int tm_tree_change_status(tm_handle hndl, uint8_t status);
+
+#ifdef MV_QMTM_NSS_A0
+/**  Change the tree DWRR priority.
+ *
+ *   @brief: set prios[i] = TM_DISABLE, if DWRR for prio i is disabled,
+ *           set prios[i] = TM_ENABLE if DWRR for prio i is enabled
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     prios           Priority array pointer structure.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval TM_HW_TREE_CONFIG_FAIL if download to HW fails.
+ */
+int tm_tree_set_dwrr_prio(tm_handle hndl, uint8_t *prios);
+#endif
+
+
+#endif   /* TM_NODES_TREE_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.c
new file mode 100644
index 0000000..69c668e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.c
@@ -0,0 +1,1002 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_update.h"
+#include "tm_errcodes.h"
+#include "tm_locking_interface.h"
+#include "rm_internal_types.h"
+#include "rm_status.h"
+#include "rm_list.h"
+#include "tm_errcodes.h"
+#include "tm_nodes_utils.h"
+#include "set_hw_registers.h"
+#include "tm_hw_configuration_interface.h"
+#include "tm_elig_prio_func.h"
+
+
+/***************************************************************************
+ * Parameters Update
+ ***************************************************************************/
+
+/**
+ */
+int tm_update_queue(tm_handle hndl, uint32_t index,
+					struct tm_queue_params *params)
+{
+	uint8_t status;
+	int rc;
+	uint8_t fl_change = TM_DISABLE;
+	struct tm_queue *queue = NULL;
+	uint8_t shaping = TM_ENABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (index >= rm->rm_total_queues) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, Q_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	queue = &(ctl->tm_queue_array[index]);
+
+	if (params->elig_prio_func_ptr != (uint8_t)TM_INVAL) {
+
+		switch (is_queue_elig_fun_uses_shaper(ctl->tm_elig_prio_q_lvl_tbl, params->elig_prio_func_ptr)) {
+		case -1:
+			rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+			goto out;
+			break;
+		case 0:
+			shaping = TM_DISABLE;
+			break;
+		default:
+			shaping = TM_ENABLE;
+			break;
+		}
+		if (shaping == TM_ENABLE) {
+			/* TBD: check if shaping enabled on this level */
+			/* if (ctl->level_data[level].shaping_status == TM_DISABLE) {
+				rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+				goto out;
+			} */
+		}
+
+		queue->elig_prio_func_ptr = params->elig_prio_func_ptr;
+		fl_change = TM_ENABLE;
+	}
+
+	if (params->quantum != (uint16_t)TM_INVAL) {
+#ifdef MV_QMTM_NOT_NSS
+		/* Check param */
+		if ((params->quantum < ctl->min_quantum)
+			|| (params->quantum > 256 * ctl->min_quantum)) {
+			rc = TM_CONF_Q_QUANTUM_OOR;
+			goto out;
+		}
+#endif
+		/* Update SW DB */
+		/* Update quantum even if DWRR is disabled */
+		queue->dwrr_quantum = params->quantum;
+		fl_change = TM_ENABLE;
+	}
+
+	if ((params->wred_profile_ref != queue->wred_profile_ref) &&
+		(params->wred_profile_ref != (uint8_t)TM_INVAL)) {
+		/* check if queue drop profile already exists */
+		rc = rm_queue_drop_profile_status(rm, params->wred_profile_ref, &status);
+		if ((rc) || (status != RM_TRUE))
+		{
+			rc = TM_CONF_Q_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* Update SW DB */
+		ctl->tm_q_lvl_drop_profiles[queue->wred_profile_ref].use_counter--;
+		/* assert(ctl->tm_q_lvl_drop_profiles[queue->wred_profile_ref].use_counter >= 0); */
+		queue->wred_profile_ref = params->wred_profile_ref;
+		ctl->tm_q_lvl_drop_prof_ptr[index] = params->wred_profile_ref;
+		ctl->tm_q_lvl_drop_profiles[queue->wred_profile_ref].use_counter++;
+		fl_change = TM_ENABLE;
+	}
+
+	/* Download to HW */
+	if (fl_change == TM_ENABLE) {
+		rc = set_hw_queue(ctl, index);
+		if (rc)
+			rc = TM_HW_QUEUE_CONFIG_FAIL;
+	}
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_update_a_node(tm_handle hndl, uint32_t index,
+					 struct tm_a_node_params *params)
+{
+	uint8_t status;
+	uint8_t dwrr_priority_t;
+	int rc;
+	int i;
+	/*uint8_t fl_change = TM_DISABLE;*/
+	struct tm_a_node *node = NULL;
+	uint8_t shaping = TM_ENABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (index >= rm->rm_total_a_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, A_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_a_node_array[index]);
+
+	if (params->elig_prio_func_ptr != (uint8_t) TM_INVAL) {
+		switch (is_node_elig_fun_uses_shaper(ctl->tm_elig_prio_a_lvl_tbl, params->elig_prio_func_ptr)) {
+		case -1:
+			rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+			goto out;
+			break;
+		case 0:
+			shaping = TM_DISABLE;
+			break;
+		default:
+			shaping = TM_ENABLE;
+			break;
+		}
+		if (shaping == TM_ENABLE) {
+			/* TBD: check if shaping enabled on this level */
+			/* if (ctl->level_data[level].shaping_status == TM_DISABLE) {
+				rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+				goto out;
+			} */
+		}
+
+		node->elig_prio_func_ptr = params->elig_prio_func_ptr;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* DWRR for A-node */
+	if (params->quantum != (uint16_t)TM_INVAL) {
+#ifdef MV_QMTM_NOT_NSS
+		if ((params->quantum < ctl->min_quantum)
+			|| (params->quantum > 256 * ctl->min_quantum)) {
+			rc = TM_CONF_A_QUANTUM_OOR;
+			goto out;
+		}
+#endif
+		/* Update SW DB */
+		node->dwrr_quantum = params->quantum;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* DWRR for Queues in A-node's range */
+	if ((params->dwrr_priority[0] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[1] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[2] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[3] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[4] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[5] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[6] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[7] != (uint8_t)TM_INVAL)) {
+		/* Check params */
+		dwrr_priority_t = 0;
+		for (i = 0; i < 8; i++) {
+			if (params->dwrr_priority[i] != (uint8_t)TM_INVAL) {
+				if ((params->dwrr_priority[i] != TM_DISABLE) &&
+					(params->dwrr_priority[i] != TM_ENABLE)) {
+					rc = TM_CONF_A_DWRR_PRIO_OOR;
+					goto out;
+				}
+				dwrr_priority_t =
+					dwrr_priority_t | (params->dwrr_priority[i] << i);
+			} else
+				dwrr_priority_t = (dwrr_priority_t & ~(0x1 << i)) |
+					(node->dwrr_priority & (0x1 << i));
+		}
+
+		/* Update SW DB */
+		node->dwrr_priority = dwrr_priority_t;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	if ((params->wred_profile_ref != node->wred_profile_ref) &&
+		(params->wred_profile_ref != (uint8_t)TM_INVAL)) {
+		/* check if a node drop profile already exists */
+		rc = rm_a_node_drop_profile_status(rm, params->wred_profile_ref, &status);
+		if ((rc) || (status != RM_TRUE)) {
+			rc = TM_CONF_A_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* Update SW DB */
+		ctl->tm_a_lvl_drop_profiles[node->wred_profile_ref].use_counter--;
+		/* assert(ctl->tm_a_lvl_drop_profiles[node->wred_profile_ref].use_counter >= 0); */
+		node->wred_profile_ref = params->wred_profile_ref;
+		ctl->tm_a_lvl_drop_prof_ptr[index] = params->wred_profile_ref;
+		ctl->tm_a_lvl_drop_profiles[node->wred_profile_ref].use_counter++;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* Download to HW */
+	rc = set_hw_a_node(ctl, index);
+	if (rc)
+		rc = TM_HW_A_NODE_CONFIG_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_update_b_node(tm_handle hndl, uint32_t index,
+					 struct tm_b_node_params *params)
+{
+	uint8_t status;
+	uint8_t dwrr_priority_t;
+	int rc;
+	int i;
+	/*uint8_t fl_change = TM_DISABLE;*/
+	struct tm_b_node *node = NULL;
+	uint8_t shaping = TM_ENABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (index >= rm->rm_total_b_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, B_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_b_node_array[index]);
+
+	if (params->elig_prio_func_ptr != (uint8_t)TM_INVAL) {
+		switch (is_node_elig_fun_uses_shaper(ctl->tm_elig_prio_b_lvl_tbl, params->elig_prio_func_ptr)) {
+		case -1:
+			rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+			goto out;
+			break;
+		case 0:
+			shaping = TM_DISABLE;
+			break;
+		default:
+			shaping = TM_ENABLE;
+			break;
+		}
+
+		if (shaping == TM_ENABLE) {
+			/* TBD: check if shaping enabled on this level */
+			/* if (ctl->level_data[level].shaping_status == TM_DISABLE) {
+				rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+				goto out;
+			} */
+		}
+
+		node->elig_prio_func_ptr = params->elig_prio_func_ptr;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+
+	/* DWRR for B-node */
+	if (params->quantum != (uint16_t)TM_INVAL) {
+#ifdef MV_QMTM_NOT_NSS
+		/* Check params */
+		if ((params->quantum < ctl->min_quantum)
+			|| (params->quantum > 256 * ctl->min_quantum)) {
+			rc = TM_CONF_B_QUANTUM_OOR;
+			goto out;
+		}
+#endif
+		/* Update SW DB */
+		node->dwrr_quantum = params->quantum;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* DWRR for A-nodes in B-node's range */
+	if ((params->dwrr_priority[0] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[1] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[2] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[3] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[4] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[5] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[6] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[7] != (uint8_t)TM_INVAL)) {
+		/* Check params */
+		dwrr_priority_t = 0;
+		for (i = 0; i < 8; i++) {
+			if (params->dwrr_priority[i] != (uint8_t)TM_INVAL) {
+				if ((params->dwrr_priority[i] != TM_DISABLE) &&
+					(params->dwrr_priority[i] != TM_ENABLE)) {
+					rc = TM_CONF_B_DWRR_PRIO_OOR;
+					goto out;
+				}
+				dwrr_priority_t =
+					dwrr_priority_t | (params->dwrr_priority[i] << i);
+			} else
+				dwrr_priority_t = (dwrr_priority_t & ~(0x1 << i)) |
+					(node->dwrr_priority & (0x1 << i));
+		}
+
+		/* Update SW DB */
+		node->dwrr_priority = dwrr_priority_t;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	if ((params->wred_profile_ref != (uint8_t)TM_INVAL) &&
+		(params->wred_profile_ref != (uint8_t)TM_INVAL)) {
+		/* Check param */
+		if (params->wred_profile_ref >= TM_NUM_B_NODE_DROP_PROF)
+		{
+			rc = TM_CONF_B_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* check if b node drop profile already exists */
+		rc = rm_b_node_drop_profile_status(rm, params->wred_profile_ref, &status);
+		if ((rc) || (status != RM_TRUE))
+		{
+			rc = TM_CONF_B_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* Update SW DB */
+		ctl->tm_b_lvl_drop_profiles[node->wred_profile_ref].use_counter--;
+		/* assert(ctl->tm_b_lvl_drop_profiles[node->wred_profile_ref].use_counter >= 0); */
+		node->wred_profile_ref = params->wred_profile_ref;
+		ctl->tm_b_lvl_drop_prof_ptr[index] = params->wred_profile_ref;
+		ctl->tm_b_lvl_drop_profiles[node->wred_profile_ref].use_counter++;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* Download to HW */
+	rc = set_hw_b_node(ctl, index);
+	if (rc)
+		rc = TM_HW_B_NODE_CONFIG_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_update_c_node(tm_handle hndl, uint32_t index,
+					 struct tm_c_node_params *params)
+{
+	uint8_t status;
+	uint8_t dwrr_priority_t;
+	uint8_t cos_map;
+	uint8_t old_wred_profile_ref;
+	int rc = 0;
+	int i;
+	/*uint8_t fl_change = TM_DISABLE;*/
+	struct tm_c_node *node = NULL;
+	uint8_t shaping = TM_ENABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* Check parameters validity */
+	if (index >= rm->rm_total_c_nodes) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, C_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	node = &(ctl->tm_c_node_array[index]);
+
+	if (params->elig_prio_func_ptr != (uint8_t)TM_INVAL) {
+		switch (is_node_elig_fun_uses_shaper(ctl->tm_elig_prio_c_lvl_tbl, params->elig_prio_func_ptr)) {
+		case -1:
+			rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+			goto out;
+			break;
+		case 0:
+			shaping = TM_DISABLE;
+			break;
+		default:
+			shaping = TM_ENABLE;
+			break;
+		}
+
+		if (shaping == TM_ENABLE) {
+			/* TBD: check if shaping enabled on this level */
+			/* if (ctl->level_data[level].shaping_status == TM_DISABLE) {
+				rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+				goto out;
+			} */
+		}
+
+		node->elig_prio_func_ptr = params->elig_prio_func_ptr;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+
+	/* DWRR for C-node */
+	if (params->quantum != (uint16_t)TM_INVAL) {
+#ifdef MV_QMTM_NOT_NSS
+		/* Check params */
+		if ((params->quantum < ctl->min_quantum)
+			|| (params->quantum > 256 * ctl->min_quantum)) {
+			rc = TM_CONF_C_QUANTUM_OOR;
+			goto out;
+		}
+#endif
+		/* Update SW DB */
+		node->dwrr_quantum = params->quantum;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	/* DWRR for B-nodes in C-node's range */
+	if ((params->dwrr_priority[0] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[1] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[2] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[3] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[4] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[5] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[6] != (uint8_t)TM_INVAL) ||
+		(params->dwrr_priority[7] != (uint8_t)TM_INVAL)) {
+		/* Check params */
+		dwrr_priority_t = 0;
+		for (i = 0; i < 8; i++) {
+			if (params->dwrr_priority[i] != (uint8_t)TM_INVAL) {
+				if ((params->dwrr_priority[i] != TM_DISABLE) &&
+					(params->dwrr_priority[i] != TM_ENABLE)) {
+					rc = TM_CONF_C_DWRR_PRIO_OOR;
+					goto out;
+				}
+				dwrr_priority_t =
+					dwrr_priority_t | (params->dwrr_priority[i] << i);
+			} else
+				dwrr_priority_t = (dwrr_priority_t & ~(0x1 << i)) |
+					(node->dwrr_priority & (0x1 << i));
+		}
+
+		/* Update SW DB */
+		node->dwrr_priority = dwrr_priority_t;
+		/*fl_change = TM_ENABLE;*/
+	}
+
+	cos_map = node->wred_cos;
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (params->wred_profile_ref[i] != (uint8_t)TM_INVAL) {
+			if (params->wred_cos & (1<<i)) {
+				/* apply new drop profile for this cos */
+				/* Check param */
+				if (params->wred_profile_ref[i] >= TM_NUM_C_NODE_DROP_PROF) {
+					rc = TM_CONF_C_WRED_PROF_REF_OOR;
+					goto out;
+				}
+
+				/* check if c node drop profile already exists */
+				rc = rm_c_node_drop_profile_status(rm, (uint8_t)i,
+					params->wred_profile_ref[i], &status);
+				if ((rc) || (status != RM_TRUE)) {
+					rc = TM_CONF_C_WRED_PROF_REF_OOR;
+					goto out;
+				}
+
+				if (params->wred_profile_ref[i] != node->wred_profile_ref[i]) {
+					/* Update SW DB */
+					old_wred_profile_ref = ctl->tm_c_lvl_drop_prof_ptr[i][index];
+					ctl->tm_c_lvl_drop_profiles[i][old_wred_profile_ref].use_counter--;
+					ctl->tm_c_lvl_drop_prof_ptr[i][index] = params->wred_profile_ref[i];
+					ctl->tm_c_lvl_drop_profiles[i][params->wred_profile_ref[i]].use_counter++;
+					node->wred_profile_ref[i] = params->wred_profile_ref[i];
+
+					/* update Wred CoS for future usage within the HW update */
+					cos_map =
+						(cos_map & ~(0x1<<i)) | (params->wred_cos & (0x1<<i));
+					/*fl_change = TM_ENABLE;*/
+				} else {
+					/* set wred_cos bit is the same */
+					cos_map =
+						(cos_map & ~(0x1<<i)) | (params->wred_cos & (0x1<<i));
+				}
+			} else { /* remove the use in old drop profile */
+				if (node->wred_cos & (0x1<<i)) {
+					/* the profile was in use */
+					/* Update SW DB */
+					old_wred_profile_ref = ctl->tm_c_lvl_drop_prof_ptr[i][index];
+					ctl->tm_c_lvl_drop_profiles[i][old_wred_profile_ref].use_counter--;
+					/* assert(ctl->tm_c_lvl_drop_profiles[i][old_wred_profile_ref].use_counter >= 0); */
+					ctl->tm_c_lvl_drop_prof_ptr[i][index] = TM_NO_DROP_PROFILE;
+					ctl->tm_c_lvl_drop_profiles[i]
+					[params->wred_profile_ref[TM_NO_DROP_PROFILE]].use_counter++;
+					node->wred_profile_ref[i] = TM_NO_DROP_PROFILE;
+
+					/* update Wred CoS for future usage within the HW update */
+					cos_map = (cos_map & ~(0x1 << i));
+					/*fl_change = TM_ENABLE;*/
+				}
+			}
+		}
+	}
+	node->wred_cos = cos_map;
+
+	rc = set_hw_c_node(ctl, index);
+	if (rc)
+		rc = TM_HW_C_NODE_CONFIG_FAIL;
+
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_update_port_scheduling(tm_handle hndl,
+				uint8_t index,
+				uint8_t elig_prio_func_ptr,
+#ifdef MV_QMTM_NSS_A0
+				uint16_t *quantum, /* 8 cells array */
+#endif
+				uint8_t *dwrr_priority) /* 8 cells array */
+{
+	struct tm_port *port = NULL;
+	uint8_t status;
+#ifdef MV_QMTM_NSS_A0
+	uint32_t min_port_quant;
+	uint32_t max_pkg_len_bursts;
+#endif
+	uint8_t dwrr_priority_t;
+	int rc = 0;
+	int i;
+	uint8_t shaping = TM_ENABLE;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc) {
+		tm_nodes_unlock(TM_ENV(ctl));
+		return rc;
+	}
+
+	if (index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	port = &(ctl->tm_port_array[index]);
+
+	if (elig_prio_func_ptr != (uint8_t)TM_INVAL) {
+		switch (is_node_elig_fun_uses_shaper(ctl->tm_elig_prio_p_lvl_tbl, elig_prio_func_ptr)) {
+		case -1:
+			rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+			goto out;
+			break;
+		case 0:
+			shaping = TM_DISABLE;
+			break;
+		default:
+			shaping = TM_ENABLE;
+			break;
+		}
+
+		if (shaping == TM_ENABLE) {
+			/* TBD: check if shaping enabled on this level */
+			/* if (ctl->level_data[level].shaping_status == TM_DISABLE) {
+				rc = TM_CONF_ELIG_PRIO_FUNC_ID_OOR;
+				goto out;
+			} */
+		}
+		port->elig_prio_func_ptr = elig_prio_func_ptr;
+	}
+
+#ifdef MV_QMTM_NSS_A0
+	/* DWRR for Port */
+	if ((quantum[0] != (uint16_t)TM_INVAL) ||
+		(quantum[1] != (uint16_t)TM_INVAL) ||
+		(quantum[2] != (uint16_t)TM_INVAL) ||
+		(quantum[3] != (uint16_t)TM_INVAL) ||
+		(quantum[4] != (uint16_t)TM_INVAL) ||
+		(quantum[5] != (uint16_t)TM_INVAL) ||
+		(quantum[6] != (uint16_t)TM_INVAL) ||
+		(quantum[7] != (uint16_t)TM_INVAL))
+	{
+		/* Check quantum */
+		min_port_quant = 4*ctl->port_ch_emit*ctl->dwrr_bytes_burst_limit;
+		/* 4*PortChunksEmitPerSel*PortDWRRBytesPerBurstsLimit */
+		max_pkg_len_bursts = (ctl->mtu + ctl->min_pkg_size)/16;
+		if (min_port_quant < max_pkg_len_bursts)
+			min_port_quant = max_pkg_len_bursts;
+		min_port_quant = min_port_quant/0x40; /* in 64B units */
+		for (i = 0; i < 8; i++)
+		{
+			if (quantum[i] != (uint16_t)TM_INVAL)
+			{
+				if (quantum[i] > 0x200)
+				{ /* maximum 9 bits */
+					rc = TM_CONF_PORT_QUANTUM_OOR;
+					goto out;
+				}
+				if (quantum[i] < min_port_quant)
+				{
+					rc = TM_CONF_PORT_QUANTUM_OOR;
+					goto out;
+				} else {
+					/* Update SW DB */
+					port->dwrr_quantum[i].quantum = quantum[i];
+				}
+			}
+		}
+	}
+#endif
+
+	/* DWRR for C-nodes in Port's range */
+	dwrr_priority_t = 0;
+	if ((dwrr_priority[0] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[1] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[2] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[3] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[4] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[5] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[6] != (uint8_t)TM_INVAL) ||
+		(dwrr_priority[7] != (uint8_t)TM_INVAL)) {
+		/* Check params and update SW DB */
+		for (i = 0; i < 8; i++) {
+			if (dwrr_priority[i] != (uint8_t)TM_INVAL) {
+				if ((dwrr_priority[i] != TM_DISABLE) &&
+					(dwrr_priority[i] != TM_ENABLE)) {
+					rc = TM_CONF_PORT_DWRR_PRIO_OOR;
+					goto out;
+				}
+				dwrr_priority_t = dwrr_priority_t | (dwrr_priority[i] << i);
+			} else
+				dwrr_priority_t = (dwrr_priority_t & ~(0x1 << i)) |
+					(port->dwrr_priority & (0x1 << i));
+		}
+	}
+
+	/* Update SW DB */
+	port->dwrr_priority = dwrr_priority_t;
+	rc = set_hw_port_scheduling(hndl, index);
+	if (rc) {
+		rc = TM_HW_PORT_CONFIG_FAIL;
+		goto out;
+	}
+
+	/* Download Queue eligible function pointer (from profile) to HW */
+	rc = set_hw_deq_status(hndl, P_LEVEL, index);
+	if (rc)
+		rc = TM_HW_ELIG_PRIO_FUNC_FAILED;
+
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+/**
+ */
+int tm_update_port_drop(tm_handle hndl, uint8_t index, uint8_t wred_profile_ref)
+{
+	struct tm_port *port = NULL;
+	struct tm_drop_profile *profile = NULL;
+	uint8_t status;
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	port = &(ctl->tm_port_array[index]);
+
+	if ((wred_profile_ref != (uint8_t)TM_INVAL) &&
+		(wred_profile_ref != port->wred_profile_ref)) {
+		/* Check param */
+		if (wred_profile_ref >= TM_NUM_PORT_DROP_PROF) {
+			rc = TM_CONF_P_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* check if port drop profile already exists */
+		rc = rm_port_drop_profile_status(rm, wred_profile_ref, &status);
+		if ((rc) || (status != RM_TRUE)) {
+			rc = TM_CONF_P_WRED_PROF_REF_OOR;
+			goto out;
+		}
+
+		/* Update SW DB */
+		profile = &(ctl->tm_p_lvl_drop_profiles[port->wred_profile_ref]);
+		profile->use_counter--;
+		/* assert(profile->use_counter >= 0); */
+
+		/* remove node from list of old drop profile */
+		rc = rm_list_del_index(rm, profile->use_list, index, P_LEVEL);
+		if (rc) {
+			rc = TM_CONF_P_WRED_PROF_REF_OOR;
+			goto out;
+		}
+		port->wred_profile_ref = wred_profile_ref;
+		/* add node to the list of new drop profile */
+		profile = &(ctl->tm_p_lvl_drop_profiles[port->wred_profile_ref]);
+		rc = rm_list_add_index(rm, profile->use_list, index, P_LEVEL);
+		if (rc) {
+			rc = TM_CONF_P_WRED_PROF_REF_OOR;
+			goto out;
+		}
+		ctl->tm_p_lvl_drop_prof_ptr[index] = wred_profile_ref;
+		profile->use_counter++;
+
+		/* Download to HW the values of new drop profile to the port */
+		rc = set_hw_port_drop(hndl, index);
+		if (rc)
+			rc = TM_HW_PORT_CONFIG_FAIL;
+	}
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+/**
+ */
+int tm_update_port_drop_cos(tm_handle hndl,
+							uint8_t index,
+							struct tm_port_drop_per_cos *params)
+{
+	struct tm_port *port = NULL;
+	struct tm_drop_profile *profile = NULL;
+	uint8_t status;
+	uint8_t new_cos_status;
+	uint8_t old_cos_status;
+	int rc = 0;
+	uint8_t i;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl);
+
+	rc = tm_nodes_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if (index >= rm->rm_total_ports) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	rc = rm_node_status(rm, P_LEVEL, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -ENODATA;
+		goto out;
+	}
+
+	port = &(ctl->tm_port_array[index]);
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (params->wred_profile_ref[i] != (uint8_t)TM_INVAL) {
+			new_cos_status = params->wred_cos & (1<<i);
+			old_cos_status = port->wred_cos & (1<<i);
+
+			if ((old_cos_status == new_cos_status) && (old_cos_status >= 1)
+				&& (params->wred_profile_ref[i] == port->wred_profile_ref_cos[i]))
+				goto out;
+
+			/* Old Drop Profile reference should be replaced by new */
+			if ((old_cos_status == new_cos_status) && (old_cos_status >= 1)) {
+				/* Check new Drop Profile reference */
+				if (params->wred_profile_ref[i] >= TM_NUM_PORT_DROP_PROF) {
+					rc = TM_CONF_P_WRED_PROF_REF_OOR;
+					goto out;
+				}
+
+				/* Check if new Drop Profile already exists */
+				rc = rm_port_drop_profile_status_cos(rm, i, params->wred_profile_ref[i], &status);
+				if ((rc) || (status != RM_TRUE)) {
+					rc = TM_CONF_P_WRED_PROF_REF_OOR;
+					goto out;
+				}
+
+				/* Remove old Drop Profile reference */
+				profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+				profile->use_counter--;
+				/* assert(profile->use_counter >= 0); */
+
+				/* remove node from list of old drop profile */
+				rc = rm_list_del_index(rm, profile->use_list, index, P_LEVEL);
+				if (rc) {
+					rc = TM_CONF_P_WRED_PROF_REF_OOR;
+					goto out;
+				}
+
+				/* Add new Drop Profile reference */
+				port->wred_profile_ref_cos[i] = params->wred_profile_ref[i];
+
+				/* add node to the list of new drop profile */
+				profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+				rc = rm_list_add_index(rm, profile->use_list, index, P_LEVEL);
+				if (rc) {
+					rc = TM_CONF_P_WRED_PROF_REF_OOR;
+					goto out;
+				}
+				ctl->tm_p_lvl_drop_prof_ptr_cos[i][index] = params->wred_profile_ref[i];
+				profile->use_counter++;
+
+				/* Download to HW the values of new drop profile to the port */
+				rc = set_hw_port_drop_cos(hndl, index, i);
+				if (rc)
+					rc = TM_HW_PORT_CONFIG_FAIL;
+			} else {
+				/* Add new Drop Profile reference (wred_cos bit 0->1) */
+				if (old_cos_status == 0) {
+					/* Check new Drop Profile reference */
+					if (params->wred_profile_ref[i] >= TM_NUM_PORT_DROP_PROF) {
+						rc = TM_CONF_P_WRED_PROF_REF_OOR;
+						goto out;
+					}
+
+					/* Check if new Drop Profile already exists */
+					rc = rm_port_drop_profile_status_cos(rm, i, params->wred_profile_ref[i],
+						&status);
+					if ((rc) || (status != RM_TRUE)) {
+						rc = TM_CONF_P_WRED_PROF_REF_OOR;
+						goto out;
+					}
+
+					/* Add new Drop Profile reference */
+					port->wred_profile_ref_cos[i] = params->wred_profile_ref[i];
+
+					/* add node to the list of new drop profile */
+					profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+					rc = rm_list_add_index(rm, profile->use_list, index, P_LEVEL);
+					if (rc) {
+						rc = TM_CONF_P_WRED_PROF_REF_OOR;
+						goto out;
+					}
+					ctl->tm_p_lvl_drop_prof_ptr_cos[i][index] = params->wred_profile_ref[i];
+					profile->use_counter++;
+
+					port->wred_cos |= (1<<i);
+
+					/* Download to HW the values of new drop profile to the port */
+					rc = set_hw_port_drop_cos(hndl, index, i);
+					if (rc)
+						rc = TM_HW_PORT_CONFIG_FAIL;
+				}
+				/* Remove old Drop Profile reference (wred_cos bit 1->0) */
+				else {
+					profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][port->wred_profile_ref_cos[i]]);
+					profile->use_counter--;
+					/* assert(profile->use_counter >= 0); */
+
+					/* remove node from list of old drop profile */
+					rc = rm_list_del_index(rm, profile->use_list, index, P_LEVEL);
+					if (rc) {
+						rc = TM_CONF_P_WRED_PROF_REF_OOR;
+						goto out;
+					}
+
+					/* set default values */
+					port->wred_profile_ref_cos[i] = TM_NO_DROP_PROFILE;
+
+					/* add node to the list of default drop profile */
+					profile = &(ctl->tm_p_lvl_drop_profiles_cos[i][TM_NO_DROP_PROFILE]);
+					rc = rm_list_add_index(rm, profile->use_list, index, P_LEVEL);
+					if (rc) {
+						rc = TM_CONF_P_WRED_PROF_REF_OOR;
+						goto out;
+					}
+					ctl->tm_p_lvl_drop_prof_ptr_cos[i][index] = TM_NO_DROP_PROFILE;
+					profile->use_counter++;
+
+					port->wred_cos &= ~(1<<i);
+
+					/* Download to HW the default values to the port */
+					rc = set_hw_port_drop_cos(hndl, index, i);
+					if (rc)
+						rc = TM_HW_PORT_CONFIG_FAIL;
+				}
+			}
+		}
+	}
+out:
+	tm_nodes_unlock(TM_ENV(ctl));
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.h
new file mode 100644
index 0000000..ce0f7e7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_update.h
@@ -0,0 +1,251 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_UPDATE_H
+#define TM_NODES_UPDATE_H
+
+#include "tm_core_types.h"
+
+/***************************************************************************
+ * Parameters Update
+ ***************************************************************************/
+
+/** Update queue parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @note wred_profile_ref parameter will be updated in any case,
+ *   set it's value to be the same as in DB if you don't want to change it.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     queue_index     Queue index to be updated.
+ *   @param[in]     q_params        Queue parameters structure pointer.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if queue_index is out of range.
+ *   @retval -ENODATA if queue_index is not in use.
+ *
+ *   @retval TM_CONF_Q_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_Q_PRIORITY_OOR.
+ *   @retval TM_CONF_Q_QUANTUM_OOR.
+ *   @retval TM_CONF_Q_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *   @retval TM_HW_ELIG_PRIO_FUNC_FAILED if queue eligible function
+ *   pointer download to HW failed .
+ *
+ *   @retval TM_HW_QUEUE_CONFIG_FAIL if download to HW fails..
+ */
+int tm_update_queue(tm_handle hndl, uint32_t queue_index,
+					struct tm_queue_params *q_params);
+
+
+/** Update A-node parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     a_node_index    A-node index to be updated.
+ *   @param[in]     a_params        A-node parameters structure pointer.
+ *
+ *   @note 'num_of_children' cann't be updated.
+ *   @note wred_profile_ref parameter will be updated in any case,
+ *   set it's value to be the same as in DB if you don't want to change it.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if a_node_index is out of range.
+ *   @retval -ENODATA if a_node_index is not in use.
+ *
+ *   @retval TM_CONF_A_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_A_PRIORITY_OOR.
+ *   @retval TM_CONF_A_QUANTUM_OOR.
+ *   @retval TM_CONF_A_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_A_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *   @retval TM_HW_A_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_ELIG_PRIO_FUNC_FAILED if A node eligible function
+ *   pointer download to HW failed .
+ */
+int tm_update_a_node(tm_handle hndl, uint32_t a_node_index,
+					 struct tm_a_node_params *a_params);
+
+
+/** Update B-node parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     b_node_index    B-node index to be updated.
+ *   @param[in]     b_params        B-node parameters structure pointer.
+ *
+ *   @note 'num_of_children' cann't be updated.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if b_node_index is out of range.
+ *   @retval -ENODATA if b_node_index is not in use.
+ *
+ *   @retval TM_CONF_B_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_B_PRIORITY_OOR.
+ *   @retval TM_CONF_B_QUANTUM_OOR.
+ *   @retval TM_CONF_B_DWRR_PRIO_OOR.
+ *   @retvak TM_CONF_B_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_HW_B_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_ELIG_PRIO_FUNC_FAILED if B node eligible function
+ *   pointer download to HW failed .
+ */
+int tm_update_b_node(tm_handle hndl, uint32_t b_node_index,
+					 struct tm_b_node_params *b_params);
+
+
+/** Update C-node parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *   @note  wred_cos can only be updated together with wred_profile_ref.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     c_node_index    C-node index to be updated.
+ *   @param[in]     c_params        C-node parameters structure pointer.
+ *
+ *   @note 'num_of_children' cann't be updated.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if c_node_index is out of range.
+ *   @retval -ENODATA if c_node_index is not in use.
+ *
+ *   @retval TM_CONF_C_SHAPING_PROF_REF_OOR.
+ *   @retval TM_CONF_C_PRIORITY_OOR.
+ *   @retval TM_CONF_C_QUANTUM_OOR.
+ *   @retval TM_CONF_C_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_C_WRED_PROF_REF_OOR.
+ *   @retval TM_CONF_C_WRED_COS_OOR.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_HW_C_NODE_CONFIG_FAIL if download to HW fails.
+ *   @retval TM_HW_ELIG_PRIO_FUNC_FAILED if C node eligible function
+ *   pointer download to HW failed .
+ */
+int tm_update_c_node(tm_handle hndl, uint32_t c_node_index,
+					 struct tm_c_node_params *c_params);
+
+
+/** Update Port Scheduling parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @param[in]     hndl            TM lib handle.
+ *   @param[in]     port_id         Port index to be updated.
+ *   @param[in]     elig_prio_func  Eligible Priority Function pointer.
+ *   @param[in]     quantum         Port quantum 8 cells array.
+ *   @param[in]     dwrr_priority   Port dwrr priority pointer for C-level.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_index is out of range.
+ *   @retval -ENODATA if port_index is not in use.
+ *
+ *   @retval TM_CONF_PORT_PRIORITY_OOR.
+ *   @retval TM_CONF_PORT_QUANTUM_OOR.
+ *   @retval TM_CONF_PORT_DWRR_PRIO_OOR.
+ *   @retval TM_CONF_ELIG_PRIO_FUNC_ID_OOR if eligible function id is oor
+ *
+ *   @retval TM_HW_ELIG_PRIO_FUNC_FAILED if port eligible function
+ *   pointer download to HW failed .
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_update_port_scheduling(tm_handle hndl, uint8_t port_id,
+							uint8_t elig_prio_func_ptr,
+#ifdef MV_QMTM_NSS_A0
+							uint16_t *quantum,
+#endif
+							uint8_t *dwrr_priority);
+
+
+/** Update Port Drop parameters.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @param[in]     hndl                TM lib handle.
+ *   @param[in]     port_index          Port index to be updated.
+ *   @param[in]     wred_profile_ref    Port Drop Profile reference.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_index is out of range.
+ *   @retval -ENODATA if port_index is not in use.
+ *
+ *   @retval TM_CONF_P_WRED_PROF_REF_OOR.
+ *
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_update_port_drop(tm_handle hndl,
+						uint8_t port_index,
+						uint8_t wred_profile_ref);
+
+/** Update Port Drop parameters per Cos.
+ *
+ *   @brief when error occurs, the entry is considered inconsistent.
+ *
+ *   @param[in]     hndl                TM lib handle.
+ *   @param[in]     port_index          Port index to be updated.
+ *   @param[in]     params              Port Drop parameters structure per Cos.
+ *
+ *   @return an integer return code.
+ *   @retval zero on success.
+ *   @retval -EINVAL if hndl is NULL.
+ *   @retval -EBADF if hndl is invalid.
+ *   @retval -EFAULT if port_index is out of range.
+ *   @retval -ENODATA if port_index is not in use.
+ *
+ *   @retval TM_CONF_P_WRED_PROF_REF_OOR.
+ *   @retval TM_HW_PORT_CONFIG_FAIL if download to HW fails.
+ */
+int tm_update_port_drop_cos(tm_handle hndl,
+							uint8_t index,
+							struct tm_port_drop_per_cos *params);
+
+#endif   /* TM_NODES_UPDATE_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.c
new file mode 100644
index 0000000..9ec4508
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.c
@@ -0,0 +1,88 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_nodes_utils.h"
+#include "tm_errcodes.h"
+#include "tm_defs.h"
+#include "tm_os_interface.h"
+#include "tm_elig_prio_func.h"
+#include "set_hw_registers.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_hw_configuration_interface.h"
+
+
+/** Configure the default Eligible Priority Functions
+*   to the Queue and Nodes (A...Port) Elig. Prio. Tables
+*
+*   The tm_config_elig_prio_func_table() configures the
+*   default Eligible Priority functions to be usable by the user
+*   The configuration is done to all Nodes levels (A...Port) with
+*   the same default Eligible functions.
+*   Queue level Table is configured with different default functions
+*   which are suitable to its operation.
+*
+*   @param[in]		hndl		TM lib handle
+*   @param[in]		updateHW	if 0 - not update HW / otherwise update HW
+*
+*   @retval zero on success.
+*   @retval -EINVAL if hndl is NULL.
+*   @retval -EBADF if hndl is an invalid handle.
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+int tm_config_elig_prio_func_table(tm_handle hndl, int updateHW)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* Update SW image */
+	set_default_queue_elig_prio_func_table(ctl->tm_elig_prio_q_lvl_tbl);
+
+	set_default_node_elig_prio_func_table(ctl->tm_elig_prio_a_lvl_tbl);
+	set_default_node_elig_prio_func_table(ctl->tm_elig_prio_b_lvl_tbl);
+	set_default_node_elig_prio_func_table(ctl->tm_elig_prio_c_lvl_tbl);
+	set_default_node_elig_prio_func_table(ctl->tm_elig_prio_p_lvl_tbl);
+
+	if (updateHW) {
+		/* update HW */
+		rc = set_hw_elig_prio_func_tbl_q_level(hndl);
+		if (rc) return rc;
+		rc = set_hw_elig_prio_func_tbl_a_level(hndl);
+		if (rc) return rc;
+		rc = set_hw_elig_prio_func_tbl_b_level(hndl);
+		if (rc) return rc;
+		rc = set_hw_elig_prio_func_tbl_c_level(hndl);
+		if (rc) return rc;
+		rc = set_hw_elig_prio_func_tbl_p_level(hndl);
+		if (rc) return rc;
+	}
+	if (rc)
+		return TM_HW_ELIG_PRIO_FUNC_FAILED;
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.h
new file mode 100644
index 0000000..98e9a0d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_nodes_utils.h
@@ -0,0 +1,57 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_NODES_H
+#define TM_NODES_H
+
+#include "tm_core_types.h"
+
+/** Configure the default Eligible Priority Functions
+*   to the Queue and Nodes (A...Port) Elig. Prio. Tables
+*
+*   The tm_config_elig_prio_func_table() configures the
+*   default Eligible Priority functions to be usable by the user
+*   The configuration is done to all Nodes levels (A...Port) with
+*   the same default Eligible functions.
+*   Queue level Table is configured with different default functions
+*   which are suitable to its operation.
+*
+*   @param[in]		hndl		TM lib handle
+*   @param[in]		updateHW	if 0 - not update HW / otherwise update HW
+*
+*   @retval zero on success.
+*   @retval -EINVAL if hndl is NULL.
+*   @retval -EBADF if hndl is an invalid handle.
+*	@retval TM_HW_ELIG_PRIO_FUNC_FAILED when the configuration to the HW failed
+*/
+
+int tm_config_elig_prio_func_table(tm_handle hndl, int updateHW);
+
+
+#endif   /* TM_NODES_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_os_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_os_interface.h
new file mode 100644
index 0000000..89454e6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_os_interface.h
@@ -0,0 +1,44 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_OS_INTERFACE_H
+#define TM_OS_INTERFACE_H
+
+#include "common/mv_sw_if.h"
+
+
+void *tm_malloc(unsigned int size);
+void  tm_free(void *ptr);
+void *tm_memset(void *s, int c, unsigned int n);
+void *tm_memcpy(void *dest, const void *src, unsigned int n);
+
+
+int    tm_abs(int x);
+
+#endif   /* TM_OS_INTERFACE_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.c
new file mode 100644
index 0000000..0c17b78
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.c
@@ -0,0 +1,54 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "common/mv_sw_if.h"
+
+#include "tm_registers_processing.h"
+void __set_field(void * address, int shift, int width, int value)
+{
+	uint64_t * pvar=(uint64_t *) address;
+
+	uint64_t mask= (1 << width) - 1 ;
+	uint64_t uvalue=value;
+	uvalue &= mask; /* removing extra hi bits (if any) */
+	mask = ~(mask << shift);
+	uvalue <<= shift;
+	*pvar = (*pvar & mask) | uvalue;
+
+}
+
+unsigned int __get_field(void * address, int shift, int width)
+{
+	uint64_t * pvar=(uint64_t *) address;
+	uint64_t uvalue;
+	uint64_t mask= (1 <<width)-1;
+	mask <<= shift;
+	uvalue= (*pvar & mask);
+	uvalue >>=shift;
+	return (unsigned int) uvalue;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.h
new file mode 100644
index 0000000..621cb35
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_registers_processing.h
@@ -0,0 +1,144 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_REGISTER_INTERFACE_H
+#define TM_REGISTER_INTERFACE_H
+
+
+void __set_field(void * address, int shift, int width, int value);
+
+unsigned int __get_field(void * address, int shift, int width);
+
+
+/* workaround for MSVS variadic macros bug - all variadic parameters are passed inside macro as 1 parameter (first in list) other are empty
+ so I use __VA_ARGS__ inside macro  and following macros in order to extract parameters from VA_ARGS_
+ The following dummy macro is used because this action needs additional macro nesting level (???)
+*/
+#define DUMMY_MACRO(x) x
+
+#define PARAM_1_OF_4(a, b, c, d) a
+#define PARAM_2_OF_4(a, b, c, d) b
+#define PARAM_3_OF_4(a, b, c, d) c
+#define PARAM_4_OF_4(a, b, c, d) d
+
+#define PARAM_1_OF_3(a, b, c) a
+#define PARAM_2_OF_3(a, b, c) b
+#define PARAM_3_OF_3(a, b, c) c
+
+#define PARAM_1_OF_2(a, b) a
+#define PARAM_2_OF_2(a, b) b
+
+/* intermediate macros */
+
+#define	 TM_REG_ROW_SET(field_name, shift, width, default_value, ...)\
+	(else\
+	if (strcmp(DUMMY_MACRO(PARAM_1_OF_3(__VA_ARGS__)), #field_name) == 0) {\
+		__set_field(TM_REGISTER_VAR_PTR(PARAM_2_OF_3(__VA_ARGS__)), shift,\
+		width, DUMMY_MACRO(PARAM_3_OF_3(__VA_ARGS__)));\
+	})
+
+#define	 TM_REG_ROW_RESET(field_name, shift, width, default_value, ...)\
+	__set_field(TM_REGISTER_VAR_PTR(__VA_ARGS__), shift, width, default_value);
+
+#define	 TM_REG_ROW_GET(field_name, shift, width, default_value, ...)\
+	(else\
+	if (strcmp(DUMMY_MACRO(PARAM_1_OF_4(__VA_ARGS__)), #field_name) == 0) {\
+		DUMMY_MACRO(PARAM_3_OF_4(__VA_ARGS__)) = \
+		PARAM_4_OF_4(__VA_ARGS__)__get_field(TM_REGISTER_VAR_PTR(PARAM_2_OF_4(__VA_ARGS__)), shift, width);\
+	})
+
+#define	 TM_REG_ROW_DUMP(field_name, shift, width, default_value, ...)\
+		fprintf(DUMMY_MACRO(PARAM_2_OF_2(__VA_ARGS__)), "    %s (shift=%d, width=%d) value=%u\n",\
+		#field_name, shift, width, __get_field(TM_REGISTER_VAR_PTR(PARAM_1_OF_2(__VA_ARGS__)), shift, width));
+
+
+
+/* the register variable of some register type must be unique in the scope of it's definition
+   It's name is defined by register name in the following macro.
+   Two following macros should be used everywhere instead of direct usage of
+   refister variable name and address
+*/
+#define	TM_REGISTER_VAR_NAME(register) register##_var
+#define	TM_REGISTER_VAR_ADDR(register) TM_REGISTER_VAR_PTR(TM_REGISTER_VAR_NAME(register))
+
+/* if use register description using shifts: */
+#if defined(SHIFT_TABLE)
+	/* the register variable is defined as 8 bytes memory block */
+	#define	TM_REGISTER_VAR(register_name) char TM_REGISTER_VAR_NAME(register_name)[8];
+	#define	TM_REGISTER_VAR_PTR(register_var)  (void*)register_var
+
+	#define	 TM_REGISTER_SET(register, param_name, param_value) \
+	{\
+		if (0) ;\
+		register(SET, #param_name, register, param_value)\
+		else { \
+		fprintf(stderr, "%s line:%d unknown parameter %s used assignment. aboriting.\n",\
+		__FILE__, __LINE__, #param_name);	exit(1); } \
+	}
+
+	#define	 TM_REGISTER_GET(register, param_name, param_value,casting) \
+	{\
+		if (0) ;\
+		register(GET, #param_name, register, param_value, casting)\
+		else { \
+		fprintf(stderr, "%s line:%d unknown parameter %s used in read request. aboriting.\n",\
+		__FILE__, __LINE__, #param_name);	exit(1); } \
+	}
+
+	#define	TM_REGISTER_RESET(register) \
+	{\
+		memset(TM_REGISTER_VAR_NAME(register), 0, sizeof(char)*8);\
+		register(RESET, register)\
+	}
+
+	#define	 TM_REGISTER_DUMP(register, file_handle) \
+	{\
+		fprintf(file_handle, " register %s:\n", #register);\
+		register(DUMP, register, file_handle)\
+	}
+
+/* if use register description using  structure declaration: */
+
+#elif defined(STRUCTS)
+
+	#define STRUCTURE_INITIALIZATION_CODE = {0}
+	#define	TM_REGISTER_VAR(register)  struct register TM_REGISTER_VAR_NAME(register) STRUCTURE_INITIALIZATION_CODE;
+	#define	TM_REGISTER_VAR_PTR(register_var)  (void*)&register_var
+
+	#define	TM_REGISTER_SET(register, param_name, param_value) {\
+		TM_REGISTER_VAR_NAME(register).param_name = param_value; }
+	#define	TM_REGISTER_GET(register, param_name, param_value, casting) {\
+		param_value = casting TM_REGISTER_VAR_NAME(register).param_name; }
+
+	#define	TM_REGISTER_RESET(register)  /* nothing to do */
+	#define	TM_REGISTER_DUMP(register_name, file_handle) /* nothing to do */
+#else
+/* error here - data declaration method must be selected */
+#endif
+
+#endif   /* TM_REGISTER_INTERFACE_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_rw_registers_interface.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_rw_registers_interface.h
new file mode 100644
index 0000000..ce63de7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_rw_registers_interface.h
@@ -0,0 +1,46 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_RW_REGISTERS_INTERFACE_H
+#define TM_RW_REGISTERS_INTERFACE_H
+
+extern uint8_t tm_debug_on;
+
+int set_hw_connection(void *environment_handle);
+int flush_hw_connection(void *environment_handle);
+int reset_hw_connection(void *environment_handle, int error);
+int close_hw_connection(void *environment_handle);
+
+int tm_register_read(void *environment_handle, void *vpAddress, void *vpData);
+int tm_register_write(void *environment_handle, void *vpAddress, void *vpData);
+
+int tm_table_entry_read(void *environment_handle, void *vpAddress, long int index, void *vpData);
+int tm_table_entry_write(void *environment_handle, void *vpAddress, long int index, void *vpData);
+
+
+#endif   /* TM_RW_REGISTERS_INTERFACE_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.c
new file mode 100644
index 0000000..878517f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.c
@@ -0,0 +1,218 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_sched.h"
+#include "tm_errcodes.h"
+#include "tm_nodes_utils.h"
+#include "tm_locking_interface.h"
+#include "set_hw_registers.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_os_interface.h"
+#include "tm_hw_configuration_interface.h"
+
+/**
+*/
+int tm_get_node_min_quantum(tm_handle hndl, uint16_t *min_quantum)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	*min_quantum = ctl->min_quantum;
+	return rc;
+}
+
+/**
+*/
+int tm_mtu_set(tm_handle hndl, uint32_t mtu)
+{
+	int rc = 0;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	if (mtu > TM_MAX_MTU)
+		return -EFAULT;
+
+	ctl->mtu = mtu;
+	ctl->min_quantum = (mtu + ctl->min_pkg_size)/TM_NODE_QUANTUM_UNIT;
+	return rc;
+}
+
+/**
+*/
+int tm_elig_to_prio(tm_handle hndl, enum tm_level level, uint8_t elig)
+{
+	uint8_t type;
+	uint8_t prio;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* check parameters */
+	if (level > P_LEVEL)
+		return -EFAULT;
+
+	DECODE_ELIGIBLE_FUN(elig, type, prio);
+	if (level == Q_LEVEL) {
+		if (IS_VALID_Q_TYPE_PRIO(type, prio)) /* valid eligible function */
+			return prio;
+		else
+			return -EBADMSG;
+	} else {
+		if (IS_VALID_N_TYPE_PRIO(type, prio)) {
+			/* valid eligible function */
+			if (prio == PRIO_P) /* propagated priority found */
+				return -1;
+			else
+				return prio;
+		} else
+			return -EBADMSG;
+	}
+}
+
+#ifdef MV_QMTM_NSS_A0
+/**
+*/
+int tm_sched_general_config(tm_handle hndl, uint8_t port_ext_bp)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+
+	rc = tm_glob_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	if ((port_ext_bp != TM_ENABLE) && (port_ext_bp != TM_DISABLE))
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	/* update relevant fields in hndl */
+	ctl->port_ext_bp_en = port_ext_bp;
+
+	rc = set_hw_gen_conf(hndl);
+	if (rc < 0)
+		rc = TM_HW_GEN_CONFIG_FAILED;
+
+out:
+	if (rc)
+	{
+		if (rc > 0)
+			set_sw_gen_conf_default(hndl);
+	}
+	tm_glob_unlock(TM_ENV(ctl));
+	return rc;
+}
+#endif
+
+
+int tm_configure_fixed_periodic_scheme_2_5G(tm_handle hndl, enum tm_level level)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_fixed_queue_periodic_scheme(hndl);
+		break;
+	case A_LEVEL:
+		rc = set_hw_fixed_a_level_periodic_scheme(hndl);
+		break;
+	case B_LEVEL:
+		rc = set_hw_fixed_b_level_periodic_scheme(hndl);
+		break;
+	case C_LEVEL:
+		rc = set_hw_fixed_c_level_periodic_scheme(hndl);
+		break;
+	case P_LEVEL:
+		rc = set_hw_fixed_port_periodic_scheme(hndl);
+		break;
+	default:
+		rc = -EFAULT;
+		goto out;
+	}
+	if (rc) {
+		rc = TM_HW_CONF_PER_SCHEME_FAILED;
+		goto out;
+	}
+
+	ctl->periodic_scheme_state = TM_ENABLE;
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+#ifdef MV_QMTM_NSS_A0
+/**
+ */
+int tm_port_level_set_dwrr_bytes_per_burst_limit(tm_handle hndl, uint8_t bytes)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters validity */
+	if (bytes > 0x7F)
+	{
+		rc = -EFAULT;
+		goto out;
+	}
+
+	ctl->dwrr_bytes_burst_limit = bytes;
+
+	rc = set_hw_dwrr_limit(hndl);
+	if (rc < 0)
+	{
+		/* set to default */
+		ctl->dwrr_bytes_burst_limit = 0x40;
+		rc = TM_HW_PORT_DWRR_BYTES_PER_BURST_FAILED;
+	}
+
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+#endif
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.h
new file mode 100644
index 0000000..bc8fd03
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_sched.h
@@ -0,0 +1,121 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef	TM_SCHED_H
+#define	TM_SCHED_H
+
+#include "tm_core_types.h"
+
+/** Get Node's minimal quantum size
+ * @param[in]	hndl			TM lib handle
+ * @param[out]	min_quantum		Min quantum size
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if hndl is an invalid handle
+*/
+int tm_get_node_min_quantum(tm_handle hndl, uint16_t *min_quantum);
+
+
+/** Set Maximal Transmission Unit size
+ * @param[in]	hndl			TM lib handle
+ * @param[in]	mtu				MTU size
+ *
+ * @note should be called once at system initialization to set default values
+ * User's responsibility to keep updated all already configured quantums
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if hndl is an invalid handle
+ * @retval -EFAULT if mtu is out of range
+*/
+int tm_mtu_set(tm_handle hndl, uint32_t mtu);
+
+/** Convert eligible function to priority
+ * @param[in]	hndl			TM lib handle
+ * @param[in]	level			TM level
+ * @param[in]	elig			eligible function
+ *
+ * @return an integer return code
+ * @retval priority on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if hndl is an invalid handle
+ * @retval -EFAULT if level is out of range
+ * @retval -EBADMSG if elig can't be converted to prio
+*/
+int tm_elig_to_prio(tm_handle hndl, enum tm_level level, uint8_t elig);
+
+#ifdef MV_QMTM_NSS_A0
+/** Configure TM general registers.
+ * @param[in]	hndl	           TM lib handle
+ * @param[in]	port_ext_bp        En/Dis port external BP
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if hndl is an invalid handle
+ * @retval -EFAULT if one of the parameters is out of range
+ * @retval  TM_HW_GEN_CONFIG_FAILED if download to HW fails
+*/
+int tm_sched_general_config(tm_handle hndl, uint8_t port_ext_bp);
+#endif
+
+
+/** Configure Periodic Scheme for level for fixed shaper of 2.5Giga
+ * @param[in]	hndl			TM lib handle
+ * @param[in]	level			Scheduling level: Queue/A/B/C/Port.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if hndl is an invalid handle
+ * @retval -EFAULT if level is out of range
+ * @retval  TM_HW_CONF_PER_SCHEME_FAILED if download to HW fails
+*/
+int tm_configure_fixed_periodic_scheme_2_5G(tm_handle hndl, enum tm_level level);
+
+
+#ifdef MV_QMTM_NSS_A0
+/** Set the number of DWRR bytes per busrt limit for all ports.
+ * @param [in]      hndl	TM lib handle
+ * @param [in]      bytes   Number of bytes per burst limit
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF  if  hndl is an invalid handle
+ * @retval -EFAULT if number of bytes is out of range
+ * @retval TM_HW_PORT_SET_DWRR_BYTES_BURST_FAILED if download to HW fails.
+*/
+int tm_port_level_set_dwrr_bytes_per_burst_limit(tm_handle hndl, uint8_t bytes);
+#endif
+
+#endif   /* TM_SCHED_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.c
new file mode 100644
index 0000000..247bc0b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.c
@@ -0,0 +1,2113 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_set_local_db_defaults.h"
+#include "tm_core_types.h"
+#include "rm_list.h"
+#include "rm_internal_types.h"
+
+
+/**
+ */
+int set_sw_sched_conf_default(void * hndl)
+{
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+
+	/* HW defaults configuration */
+	ctl->periodic_scheme_state = TM_DISABLE; /* periodic scheme
+											  * configured - yes/no */
+
+#ifdef MV_QMTM_NSS_A0
+	ctl->dwrr_bytes_burst_limit = 0x20;
+	ctl->tree_dwrr_priority = 0;
+#endif
+	ctl->tree_deq_status = TM_ENABLE;
+
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_gen_conf_default(void * hndl)
+{
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+#ifdef MV_QMTM_NSS_A0
+	ctl->port_ext_bp_en = 1;
+#endif
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_drop_profile_default(struct tm_drop_profile *profile,
+							uint32_t prof_index)
+{
+	int i;
+
+	for (i = 0; i < 3; i++) {
+		profile[prof_index].scale_exp[i].exp = 0; /* 1 Burst unit */
+		profile[prof_index].scale_ratio[i].ratio = 0;
+		profile[prof_index].curve_id[i].index = 0;
+		profile[prof_index].dp_ratio[i].ratio = 0;
+		profile[prof_index].min_threshold[i].thresh = 0x0; /* 0 Bursts  */
+	}
+	profile[prof_index].out_bw = 0;
+	profile[prof_index].cbtd_bw = 0;
+	profile[prof_index].aql_exp = 0; /* Forget Factor = 1, AQL=QL */
+	profile[prof_index].color_td_en = 0; /* Disabled */
+	profile[prof_index].td_thresh_res = 0; /* 16B */
+	profile[prof_index].td_threshold = 0; /* 0 Bursts */
+	profile[prof_index].use_counter = 0;
+	profile[prof_index].use_list = NULL;
+	return 0;
+}
+
+/*
+ Used for all levels WRED queues
+*/
+/**
+ */
+int set_sw_wred_curve_default(struct tm_wred_curve *curve, uint16_t curve_index)
+{
+	int i;
+
+	for (i = 0; i < TM_WRED_CURVE_POINTS; i++)
+		curve[curve_index].prob[i] = 0;
+
+	return 0;
+}
+
+/**
+ */
+int set_sw_queue_default(struct tm_queue *array,
+									uint32_t queue_ind,
+									struct rmctl *rm)
+{
+	(void)rm;
+
+	array[queue_ind].installed = TM_DISABLE;
+	array[queue_ind].dwrr_quantum = 0x40;
+	array[queue_ind].wred_profile_ref = 0;
+	array[queue_ind].elig_prio_func_ptr = 0;
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_a_node_default(struct tm_a_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm)
+{
+	(void)rm;
+
+	array[node_ind].dwrr_quantum = 0x40;
+	array[node_ind].dwrr_priority = 0;
+	array[node_ind].wred_profile_ref = 0;
+	array[node_ind].elig_prio_func_ptr = 0;
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_b_node_default(struct tm_b_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm)
+{
+	(void)rm;
+
+	array[node_ind].dwrr_quantum = 0x40;
+	array[node_ind].dwrr_priority = 0;
+	array[node_ind].wred_profile_ref = 0;
+	array[node_ind].elig_prio_func_ptr = 0;
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_c_node_default(struct tm_c_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm)
+{
+	(void)rm;
+
+	array[node_ind].dwrr_quantum = 0x40;
+	array[node_ind].dwrr_priority = 0;
+	array[node_ind].wred_cos = 0;
+	array[node_ind].wred_profile_ref[0] = 0;
+	array[node_ind].wred_profile_ref[1] = 0;
+	array[node_ind].wred_profile_ref[2] = 0;
+	array[node_ind].wred_profile_ref[3] = 0;
+	array[node_ind].wred_profile_ref[4] = 0;
+	array[node_ind].wred_profile_ref[5] = 0;
+	array[node_ind].wred_profile_ref[6] = 0;
+	array[node_ind].wred_profile_ref[7] = 0;
+	array[node_ind].elig_prio_func_ptr = 0;
+	return 0;
+}
+
+
+/**
+ */
+int set_sw_port_default(struct tm_port *array,
+									  uint8_t port_ind,
+									  struct rmctl *rm)
+{
+	int i;
+
+	(void)rm;
+
+#ifdef MV_QMTM_NSS_A0
+	array[port_ind].dwrr_quantum[0].quantum = 0x10;
+	array[port_ind].dwrr_quantum[1].quantum = 0x10;
+	array[port_ind].dwrr_quantum[2].quantum = 0x10;
+	array[port_ind].dwrr_quantum[3].quantum = 0x10;
+	array[port_ind].dwrr_quantum[4].quantum = 0x10;
+	array[port_ind].dwrr_quantum[5].quantum = 0x10;
+	array[port_ind].dwrr_quantum[6].quantum = 0x10;
+	array[port_ind].dwrr_quantum[7].quantum = 0x10;
+#endif
+	array[port_ind].dwrr_priority = 0;
+	array[port_ind].port_speed = TM_1G_PORT;
+	array[port_ind].wred_profile_ref = 0;
+	for (i = 0; i < TM_WRED_COS; i++)
+		array[port_ind].wred_profile_ref_cos[i] = 0;
+	array[port_ind].wred_cos = 0;   /* bit map */
+	array[port_ind].elig_prio_func_ptr = 0;
+	return 0;
+}
+
+
+#define	SP_0		0
+#define	SP_1		1
+#define	SP_2		2
+#define	SP_3		3
+#define	SP_4		4
+#define	SP_5		5
+#define	SP_6		6
+#define	SP_7		7
+
+#define	PP_0		0
+#define	PP_1		1
+#define	PP_2		2
+#define	PP_3		3
+#define	PP_4		4
+#define	PP_5		5
+#define	PP_6		6
+#define	PP_7		7
+
+
+#define	FIX_PRIO_0		0
+#define	FIX_PRIO_1		1
+#define	FIX_PRIO_2		2
+#define	FIX_PRIO_3		3
+#define	FIX_PRIO_4		4
+#define	FIX_PRIO_5		5
+#define	FIX_PRIO_6		6
+#define	FIX_PRIO_7		7
+
+
+#define	USE_MIN_TB		1
+#define	USE_MAX_TB		1
+#define	NOT_USE_MIN_TB	0
+#define	NOT_USE_MAX_TB	0
+
+#define	POS_MIN_TB		0
+#define	POS_MAX_TB		0
+#define	NEG_MIN_TB		1
+#define	NEG_MAX_TB		1
+
+
+#define	ELIGIBLE(scheduled_priority, propagated_priority, use_minTB, useMaxTB) \
+		((1 << 8) | (scheduled_priority << 5) | (propagated_priority << 2) | (use_minTB << 1) | useMaxTB)
+#define	NOT_ELIGIBLE	0
+
+#define	STRICT_PRIORITY(scheduled_priority, propagated_priority) \
+	ELIGIBLE(scheduled_priority, propagated_priority, NOT_USE_MIN_TB, NOT_USE_MAX_TB)
+
+#define	FIX_PRIORITY(priority)  ELIGIBLE(priority, priority, NOT_USE_MIN_TB, NOT_USE_MAX_TB)
+
+
+#define Q_ENTRY(min_flag, max_flag)	tbl_entry.func_out[2*min_flag+max_flag]
+/*	assert((int)function_ID < (int)TM_ELIG_FUNC_TABLE_SIZE); \*/
+
+#define QUEUE_ELIG_FUNCTION(function_ID, p0, p1, p2, p3) \
+do {\
+	func_table[function_ID].p0;\
+	func_table[function_ID].p1;\
+	func_table[function_ID].p2;\
+	func_table[function_ID].p3;\
+} while (0)
+
+#define QUEUE_ELIG_FUN_FIXED_PRIORITY(function_ID, priority) \
+	{\
+		QUEUE_ELIG_FUNCTION(function_ID,\
+		Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = priority,\
+		Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = priority,\
+		Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = priority,\
+		Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = priority);\
+	}
+
+#define QUEUE_DEQ_DISABLE(function_ID) QUEUE_ELIG_FUN_FIXED_PRIORITY(function_ID, NOT_ELIGIBLE)
+
+#define N_ENTRY(min_flag, max_flag, priority)	tbl_entry[min_flag*4 + max_flag*2 + priority/4].func_out[priority & 3]
+/*	assert((int)function_ID < (int)TM_ELIG_FUNC_TABLE_SIZE); \*/
+
+#define NODE_ELIG_FUNCTION(function_ID, p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15,\
+	p16, p17, p18, p19, p20, p21, p22, p23, p24, p25, p26, p27, p28, p29, p30, p31) \
+do {\
+	func_table[function_ID].p0;\
+	func_table[function_ID].p1;\
+	func_table[function_ID].p2;\
+	func_table[function_ID].p3;\
+	func_table[function_ID].p4;\
+	func_table[function_ID].p5;\
+	func_table[function_ID].p6;\
+	func_table[function_ID].p7;\
+	func_table[function_ID].p8;\
+	func_table[function_ID].p9;\
+	func_table[function_ID].p10;\
+	func_table[function_ID].p11;\
+	func_table[function_ID].p12;\
+	func_table[function_ID].p13;\
+	func_table[function_ID].p14;\
+	func_table[function_ID].p15;\
+	func_table[function_ID].p16;\
+	func_table[function_ID].p17;\
+	func_table[function_ID].p18;\
+	func_table[function_ID].p19;\
+	func_table[function_ID].p20;\
+	func_table[function_ID].p21;\
+	func_table[function_ID].p22;\
+	func_table[function_ID].p23;\
+	func_table[function_ID].p24;\
+	func_table[function_ID].p25;\
+	func_table[function_ID].p26;\
+	func_table[function_ID].p27;\
+	func_table[function_ID].p28;\
+	func_table[function_ID].p29;\
+	func_table[function_ID].p30;\
+	func_table[function_ID].p31;\
+} while (0)
+
+#define NODE_ELIG_FUN_FIXED_PRIORITY(function_ID, priority) \
+	{\
+		NODE_ELIG_FUNCTION(function_ID,\
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = priority, \
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = priority, \
+			/*  ---------------------------------- */\
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = priority, \
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = priority, \
+			/*  ---------------------------------- */\
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = priority, \
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = priority, \
+			/*  ---------------------------------- */\
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = priority, \
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = priority);\
+	}
+
+#define NODE_DEQ_DISABLE(function_ID)	{NODE_ELIG_FUN_FIXED_PRIORITY(function_ID, NOT_ELIGIBLE); }
+
+/*   Queues default EligibleFunction   table */
+/**
+ */
+void set_default_queue_elig_prio_func_table(struct tm_elig_prio_func_queue *func_table)
+{
+	int i;
+	/* initialize memory */
+	for (i = 0; i < TM_ELIG_FUNC_TABLE_SIZE ; i++)
+		QUEUE_DEQ_DISABLE(i);
+
+	/*  setup default functions  */
+	/*
+	===================================================================================================
+	   shapeless functions
+	===================================================================================================
+	*/
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_0),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_0),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_0),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_0));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P1,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_1),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_1),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_1),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_1));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P2,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_2),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_2),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_2),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_2));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P3,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_3),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_3),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_3),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_3));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P4,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_4),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_4),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_4),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_4));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P5,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_5),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_5),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_5),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_5));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P6,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_6),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_6),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_6),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_6));
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_FIXED_P7,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_7),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_7),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = FIX_PRIORITY(FIX_PRIO_7),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = FIX_PRIORITY(FIX_PRIO_7));
+
+	/*
+	===================================================================================================
+	   eligible functions uses only min shaper
+	===================================================================================================
+	*/
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_0, PP_0 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P1,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_1, PP_1 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_1, PP_1 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P2,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_2, PP_2 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_2, PP_2 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P3,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_3, PP_3 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_3, PP_3 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P4,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_4, PP_4 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_4, PP_4 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P5,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_5, PP_5 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_5, PP_5 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P6,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_6, PP_7 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_6, PP_7 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_MIN_SHP_P7,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_7, PP_7 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_7, PP_7 , USE_MIN_TB, NOT_USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = NOT_ELIGIBLE,
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	/*
+	===================================================================================================
+	   eligible functions using min & max shaping
+	===================================================================================================
+	*/
+	/* fixed priority functions*/
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P0_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_0, PP_0 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P1_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_1, PP_1 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_1, PP_1 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P2_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_2, PP_2 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_2, PP_2 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P3_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_3, PP_3 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_3, PP_3 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P4_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_4, PP_4 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_4, PP_4 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P5_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_5, PP_5 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_5, PP_5 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P6_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_6, PP_6 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_6, PP_6 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+	QUEUE_ELIG_FUNCTION(TM_ELIG_Q_SHP_MIN_SHP_P7_MAX_SHP_P0,
+			Q_ENTRY(POS_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_7, PP_7 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(POS_MIN_TB, NEG_MAX_TB) = ELIGIBLE(SP_7, PP_7 , USE_MIN_TB,     USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, POS_MAX_TB) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, USE_MAX_TB),
+			Q_ENTRY(NEG_MIN_TB, NEG_MAX_TB) = NOT_ELIGIBLE);
+
+
+	/* reserved   DeqDisable function - don't change*/
+	QUEUE_DEQ_DISABLE(TM_ELIG_DEQ_DISABLE);
+	/* reduced macro example - with assert : function Id < TM_ELIG_FUNC_TABLE_SIZE  failed */
+	/* QUEUE_ELIG_FUN_FIXED_PRIORITY(65 ,FIX_PRIORITY(FIX_PRIO_7));	*/
+}
+
+
+/* nodes default EligibleFunction  table*/
+/**
+ */
+void set_default_node_elig_prio_func_table(struct tm_elig_prio_func_node *func_table)
+{
+	int i;
+	/* initialize memory */
+	for (i = 0; i < TM_ELIG_FUNC_TABLE_SIZE ; i++)
+		NODE_DEQ_DISABLE(i);
+
+	/*  setup default functions  */
+
+	/*
+	===================================================================================================
+	   shapeless functions
+	===================================================================================================
+	*/
+	/* fixed priority functions*/
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_0),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_0),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_0),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_0),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_0));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P1,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P2,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_2),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_2),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_2),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_2),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_2));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P3,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_3),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_3),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_3),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_3),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_3));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P4,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_4),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_4),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_4),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_4),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_4));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P5,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P6,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_6),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_6),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_6),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_6),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_6));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_P7,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_7),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_7),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_7),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_7),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_7));
+
+	/* shapeless propagated priority  function*/
+	NODE_ELIG_FUNCTION(TM_ELIG_N_FIXED_PP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 , NOT_USE_MIN_TB, NOT_USE_MAX_TB));
+
+	/*
+	===================================================================================================
+	   functions uses min shaper only
+	===================================================================================================
+	*/
+	/* fixed priority min shaper functions */
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P1,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P2,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P3,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P4,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P5,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P6,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_P7,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+	/* propagated priority  min shaper function*/
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP_PP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	/*
+	===================================================================================================
+	   functions uses min & max shapers
+	===================================================================================================
+	*/
+	/* fixed priority min & max shaper functions */
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P0_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P1_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P2_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P3_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P4_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P5_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P6_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_P7_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	/* propagated priority min & max shaper function */
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_MIN_SHP_PP_MAX_SHP_P0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_6, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	/*
+	===================================================================================================
+	   obsolette functions here
+	===================================================================================================
+	*/
+#if 0
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_PP_MAX_TB_0,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MAX_INC_MIN_SHP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+
+
+
+
+
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PRIO1,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_1),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_1));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PRIO5,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = FIX_PRIORITY(FIX_PRIO_5),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = FIX_PRIORITY(FIX_PRIO_5));
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_MIN_SHP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA_SP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 , NOT_USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA_SHP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA_SP_MIN_SHP,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA_SHP_IGN,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_1, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_2, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_3, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_4, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_PPA_MIN_SHP_SP_IGN,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_5, PP_0 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_1 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_5, PP_2 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_5, PP_3 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_4P_MIN_4P_MAX,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+	NODE_ELIG_FUNCTION(TM_ELIG_N_SHP_PP_TB,
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, POS_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_4) = ELIGIBLE(SP_4, PP_4 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_5) = ELIGIBLE(SP_5, PP_5 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_6) = ELIGIBLE(SP_6, PP_6 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			N_ENTRY(POS_MIN_TB, NEG_MAX_TB, PP_7) = ELIGIBLE(SP_7, PP_7 ,     USE_MIN_TB, NOT_USE_MAX_TB),
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_0) = ELIGIBLE(SP_0, PP_0 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_1) = ELIGIBLE(SP_1, PP_1 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_2) = ELIGIBLE(SP_2, PP_2 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_3) = ELIGIBLE(SP_3, PP_3 , NOT_USE_MIN_TB,     USE_MAX_TB),
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, POS_MAX_TB, PP_7) = NOT_ELIGIBLE,
+			/*  ---------------------------------- */
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_0) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_1) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_2) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_3) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_4) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_5) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_6) = NOT_ELIGIBLE,
+			N_ENTRY(NEG_MIN_TB, NEG_MAX_TB, PP_7) = NOT_ELIGIBLE);
+
+#endif
+
+	NODE_DEQ_DISABLE(TM_ELIG_DEQ_DISABLE);
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.h
new file mode 100644
index 0000000..bcc045a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_set_local_db_defaults.h
@@ -0,0 +1,67 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_SET_LOCAL_DB_DEFAULTS_H
+#define TM_SET_LOCAL_DB_DEFAULTS_H
+
+#include "tm_core_types.h"
+#include "rm_internal_types.h"
+
+
+int set_sw_sched_conf_default(void * hndl);
+int set_sw_gen_conf_default(void * hndl);
+
+int	set_sw_drop_profile_default(struct tm_drop_profile *profile,
+							uint32_t prof_index);
+
+int set_sw_wred_curve_default(struct tm_wred_curve *curve,
+											uint16_t curve_index);
+int set_sw_queue_default(struct tm_queue *array,
+									   uint32_t queue_ind,
+									   struct rmctl *rm);
+
+
+int set_sw_a_node_default(struct tm_a_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm);
+
+int set_sw_b_node_default(struct tm_b_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm);
+
+int set_sw_c_node_default(struct tm_c_node *array,
+										uint32_t node_ind,
+										struct rmctl *rm);
+int set_sw_port_default(struct tm_port *array,
+									uint8_t port_ind,
+									struct rmctl *rm);
+/* initializing default values for eligible functions tables*/
+void set_default_node_elig_prio_func_table(struct tm_elig_prio_func_node *func_table);
+void set_default_queue_elig_prio_func_table(struct tm_elig_prio_func_queue  *func_table);
+
+#endif   /* TM_SET_LOCAL_DB_DEFAULTS_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.c b/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.c
new file mode 100644
index 0000000..2c7fc0d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.c
@@ -0,0 +1,366 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_shaping.h"
+#include "tm_defs.h"
+#include "tm_errcodes.h"
+#include "tm_locking_interface.h"
+#include "rm_alloc.h"
+#include "rm_status.h"
+#include "rm_free.h"
+#include "rm_list.h"
+#include "rm_internal_types.h"
+
+#include "tm_set_local_db_defaults.h"
+#include "set_hw_registers.h"
+#include "tm_nodes_utils.h"
+
+int tm_fixed_port_shaping_change_status(tm_handle hndl, uint8_t status)
+{
+	int rc;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check parameters validity */
+	if ((status != TM_ENABLE) && (status != TM_DISABLE)) {
+		rc = -EACCES;
+		goto out;
+	}
+
+	rc = set_hw_fixed_port_shaping_status((tm_handle)ctl, status);
+	if (rc < 0)
+		rc = TM_HW_CHANGE_SHAPING_STATUS_FAILED;
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+int tm_set_shaping_ex(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw,
+					uint32_t ebw,
+					uint32_t *pcbs,
+					uint32_t *pebs
+					)
+{
+	int rc = 0;
+	uint8_t status;
+	uint8_t type;
+	uint8_t prio;
+	uint8_t *elig_prio_func_ptr;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check if queue/node exists */
+	switch (level) {
+	case Q_LEVEL:
+		if (index >= rm->rm_total_queues) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case A_LEVEL:
+		if (index >= rm->rm_total_a_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case B_LEVEL:
+		if (index >= rm->rm_total_b_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case C_LEVEL:
+		if (index >= rm->rm_total_c_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case P_LEVEL:
+		if (index >= rm->rm_total_ports) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+	rc = rm_node_status(rm, level, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	if ((cbw > TM_MAX_SHAPING_BW) || (ebw > TM_MAX_SHAPING_BW)) {
+		rc = -EFAULT;
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_queue_array[index].elig_prio_func_ptr);
+		break;
+	case A_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_a_node_array[index].elig_prio_func_ptr);
+		break;
+	case B_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_b_node_array[index].elig_prio_func_ptr);
+		break;
+	case C_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_c_node_array[index].elig_prio_func_ptr);
+		break;
+	case P_LEVEL:
+		elig_prio_func_ptr = &(ctl->tm_port_array[index].elig_prio_func_ptr);
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+
+	DECODE_ELIGIBLE_FUN(*elig_prio_func_ptr, type, prio);
+
+	if (ebw) {
+		/*  using extra b/w */
+		if (level == Q_LEVEL) {
+			if (IS_VALID_Q_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_0);
+			}
+		} else {
+			if (IS_VALID_N_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINMAXTB_SHAPING, PRIO_0);
+			}
+		}
+	} else if (cbw) {
+		/* using only min shaping */
+		if (level == Q_LEVEL) {
+			if (IS_VALID_Q_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_0);
+			}
+		} else {
+			if (IS_VALID_N_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(MINTB_SHAPING, PRIO_0);
+			}
+		}
+	} else {
+		/* using fixed priority (without shaping) */
+		if (level == Q_LEVEL) {
+			if (IS_VALID_Q_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_0);
+			}
+		} else {
+			if (IS_VALID_N_TYPE_PRIO(type, prio))
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, prio);
+			else {
+				/* if eligible function is invalid or disabled - it is set to  min/max TB  priority 0 */
+				*elig_prio_func_ptr = ENCODE_ELIGIBLE_FUN(FIXED_PRIORITY, PRIO_0);
+			}
+		}
+	}
+	/* Download to HW */
+	switch (level) {
+	case Q_LEVEL:
+		rc = set_hw_queue_shaping_ex(ctl, index, cbw, ebw, pcbs, pebs);
+		if (rc)
+			goto out;
+		rc = set_hw_queue_elig_prio_func_ptr(ctl, index);
+		break;
+	case A_LEVEL:
+		rc = set_hw_a_node_shaping_ex(ctl, index, cbw, ebw, pcbs, pebs);
+		if (rc)
+			goto out;
+		rc = set_hw_a_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case B_LEVEL:
+		rc = set_hw_b_node_shaping_ex(ctl, index, cbw, ebw, pcbs, pebs);
+		if (rc)
+			goto out;
+		rc = set_hw_b_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case C_LEVEL:
+		rc = set_hw_c_node_shaping_ex(ctl, index, cbw, ebw, pcbs, pebs);
+		if (rc)
+			goto out;
+		rc = set_hw_c_node_elig_prio_func_ptr(ctl, index);
+		break;
+	case P_LEVEL:
+		rc = set_hw_port_shaping_ex(ctl, index, cbw, ebw, pcbs, pebs);
+		if (rc)
+			goto out;
+		rc = set_hw_port_elig_prio_func_ptr(ctl, index);
+		break;
+	}
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
+
+
+int tm_set_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw,
+					uint32_t ebw)
+{
+	return tm_set_shaping_ex(hndl, level, index, cbw, ebw, NULL, NULL);
+}
+
+int tm_set_min_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw)
+{
+	return tm_set_shaping_ex(hndl, level, index, cbw, 0, NULL, NULL);
+}
+
+int tm_set_no_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index)
+{
+	return tm_set_shaping_ex(hndl, level, index, 0, 0, NULL, NULL);
+}
+
+
+
+
+int tm_read_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t *cir,
+					uint32_t *eir,
+					uint32_t *cbs,
+					uint32_t *ebs
+					)
+{
+	int rc = 0;
+	uint8_t status;
+
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	DECLARE_RM_HANDLE(rm, ctl->rm)
+	CHECK_TM_CTL_PTR(ctl)
+
+	rc = tm_sched_lock(TM_ENV(ctl));
+	if (rc)
+		return rc;
+
+	/* check if queue/node exists */
+	switch (level) {
+	case Q_LEVEL:
+		if (index >= rm->rm_total_queues) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case A_LEVEL:
+		if (index >= rm->rm_total_a_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case B_LEVEL:
+		if (index >= rm->rm_total_b_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case C_LEVEL:
+		if (index >= rm->rm_total_c_nodes) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	case P_LEVEL:
+		if (index >= rm->rm_total_ports) {
+			rc = -EBADMSG;
+			goto out;
+		}
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+	rc = rm_node_status(rm, level, index, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -EPERM;
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = get_hw_queue_shaping(hndl, index, cir, eir, cbs, ebs);
+		break;
+	case A_LEVEL:
+		rc = get_hw_a_node_shaping(hndl, index, cir, eir, cbs, ebs);
+		break;
+	case B_LEVEL:
+		rc = get_hw_b_node_shaping(hndl, index, cir, eir, cbs, ebs);
+		break;
+	case C_LEVEL:
+		rc = get_hw_c_node_shaping(hndl, index, cir, eir, cbs, ebs);
+		break;
+	case P_LEVEL:
+		rc = get_hw_port_shaping(hndl, index, cir, eir, cbs, ebs);
+		break;
+	default:
+		rc = -EACCES;
+		goto out;
+	}
+
+out:
+	tm_sched_unlock(TM_ENV(ctl));
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.h b/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.h
new file mode 100644
index 0000000..4ec455e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/core/tm_shaping.h
@@ -0,0 +1,168 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef   	TM_SHAPING_H
+#define   	TM_SHAPING_H
+
+#include "tm_core_types.h"
+
+/** Enable/Disable shaping for a given port:
+ * @param[in]	hndl	TM lib handle
+ * @param[in]	status  Enable/Disable shaping
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if  tm_hndl is an invalid handle
+ * @retval -EFAULT if level is invalid
+ * @retval TM_HW_CHANGE_SHAPING_STATUS_FAILED if download to HW fails
+*/
+int tm_fixed_port_shaping_change_status(tm_handle hndl, uint8_t status);
+
+
+/** Set shaping (CIR & EIR):
+ * @param[in]	hndl		TM lib handle
+ * @param[in]	level		TM level.
+ * @param[in]	index		Port/node/queue index.
+ * @param[in]	cbw			Committed shaping BW [in resolution of 1Mb, in steps of 10Mb].
+ * @param[in]	ebw			Effective shaping BW [in resolution of 1Mb, in steps of 10Mb].
+ *
+ * @note: eligible function will be changed accordingly.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if tm_hndl is an invalid handle
+ * @retval -EFAULT if cbw/ebw is more than max allowed shaping bw
+ * @retval TM_HW_SHAPING_PROF_FAILED if download to HW fails
+*/
+int tm_set_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw,
+					uint32_t ebw);
+
+
+/** Set minimal shaping (CIR):
+ * @param[in]	hndl		TM lib handle
+ * @param[in]	level		TM level.
+ * @param[in]	index		Port/node/queue index.
+ * @param[in]	cbw			Committed shaping BW [in resolution of 1Mb, in steps of 10Mb].
+ *
+ * @note: eligible function will be changed accordingly.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if tm_hndl is an invalid handle
+ * @retval -EFAULT if cbw is more than max allowed shaping bw
+ * @retval TM_HW_SHAPING_PROF_FAILED if download to HW fails
+*/
+int tm_set_min_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw);
+
+/** Set node shapingless:
+ * @param[in]	hndl		TM lib handle
+ * @param[in]	level		TM level.
+ * @param[in]	index		Port/node/queue index.
+ *
+ * @note: eligible function will be changed accordingly.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if tm_hndl is an invalid handle
+ * @retval TM_HW_SHAPING_PROF_FAILED if download to HW fails
+*/
+int tm_set_no_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index);
+
+/** Read shaping:
+ * @param[in]	hndl		TM lib handle
+ * @param[in]	level		TM level.
+ * @param[in]	index		Port/node/queue index.
+ * @param[out]	cir			Committed shaping rate in steps of 10Mb.
+ * @param[out]	eir			Extra shaping rate in steps of 10Mb.
+ * @param[out]	cbs			Committed burst size in kB.
+ * @param[out]	ebs			Extra burst size in kB.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if tm_hndl is an invalid handle
+ * @retval -EACCES if level is out of range
+ * @retval -EBADMSG if index is out of range
+ * @retval -EPERM if port/node/queue doesn't exist
+*/
+int tm_read_shaping(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t *cir,
+					uint32_t *eir,
+					uint32_t *cbs,
+					uint32_t *ebs);
+
+/** Set shaping (CIR & EIR CBS & EBS):
+ * @param[in]	hndl		TM lib handle
+ * @param[in]	level		TM level.
+ * @param[in]	index		Port/node/queue index.
+ * @param[in]	cbw			Committed shaping BW [in resolution of 1Mb, in steps of 10Mb].
+ * @param[in]	ebw			Extra shaping BW [in resolution of 1Mb, in steps of 10Mb].
+ * @param[in]	pcbs		(pointer to) Committed BurstSize.
+ * @param[in]	pcbs		(pointer to) Extra BurstSize.
+ *
+ * @note: eligible function will be changed accordingly.
+ *
+ * @return an integer return code
+ * @retval 0 on success
+ * @retval -EINVAL if hndl is NULL
+ * @retval -EBADF if tm_hndl is an invalid handle
+ * @retval -EFAULT if cbw/ebw is more than max allowed shaping bw
+ * @retval -TM_CONF_MIN_TOKEN_TOO_LARGE if cbs or ebs is too small to provide required b/w
+ * @retval TM_HW_SHAPING_PROF_FAILED if download to HW fails
+ comment :
+	1. If cbs/ebs is less than minimal possible for required b/w - the TM_CONF_MIN_TOKEN_TOO_LARGE
+	error is returned & *pcbs  and *ebs are updated to minimal possible values.
+	2. If Setting  pcbs/pebs is NULL  the appropriate cbs/ebs parameter is set to default(minimal possible) value
+*/
+
+int tm_set_shaping_ex(tm_handle hndl,
+					enum tm_level level,
+					uint32_t index,
+					uint32_t cbw,
+					uint32_t ebw,
+					uint32_t *pcbs,
+					uint32_t *pebs
+					);
+
+
+#endif   /* TM_SHAPING_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/mv_tm.c b/drivers/net/ethernet/marvell/pp3/tm/mv_tm.c
new file mode 100644
index 0000000..db686f2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/mv_tm.c
@@ -0,0 +1,1407 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mv_tm.h"
+#include "tm_os_interface.h"
+#include "tm_core_types.h"
+#include "tm_alias.h"
+#include "tm_locking_interface.h"
+#include "tm_ctl.h"
+#include "tm_rw_registers_interface.h"
+#include "tm_drop.h"
+#include "tm_sched.h"
+#include "tm_shaping.h"
+#include "tm_nodes_create.h"
+#include "tm_nodes_status.h"
+#include "tm_nodes_update.h"
+#include "set_hw_registers.h"
+
+struct qmtm *qmtm_hndl;
+enum mv_tm_config mv_active_config;
+void __iomem *tm_regs_base;
+const char *tm_prod_str;
+
+
+static const char *tm_config_str(enum mv_tm_config config)
+{
+	const char *str;
+
+	switch (config) {
+	case TM_DEFAULT_CONFIG:
+		str = "default";
+		break;
+	case TM_CFG1_CONFIG:
+		str = "cfg1";
+		break;
+	case TM_2xPPC_CONFIG:
+		str = "2xppc";
+		break;
+	case TM_CFG3_CONFIG:
+		str = "cfg3";
+		break;
+	default:
+		str = "Unknown";
+	}
+	return str;
+}
+
+int tm_global_init(void __iomem *base, const char *prod_str)
+{
+	if (tm_regs_base || tm_prod_str) {
+		pr_info("%s is already called\n", __func__);
+		return -1;
+	}
+	if (!base || !prod_str) {
+		pr_info("%s: invalid parameters\n", __func__);
+		return -1;
+	}
+	tm_regs_base = base;
+	tm_prod_str = prod_str;
+
+	return 0;
+}
+
+int tm_open(void)
+{
+	struct qmtm * henv;
+	int rc = 0;
+
+	if (!tm_regs_base || !tm_prod_str) {
+		pr_err("%s: tm_global_init is not called yet\n", __func__);
+
+	}
+	if (qmtm_hndl) {
+		pr_info("tm_open is already called\n");
+		return 0;
+	}
+
+	henv = (struct qmtm *)tm_malloc(sizeof(struct qmtm));
+	if (henv == NULL) {
+		pr_err("malloc of TM handler failed");
+		return -1;
+	}
+
+	mv_active_config = TM_INVALID_CONFIG;
+
+
+	tm_memset(henv, 0, sizeof(struct qmtm));
+	henv->magic = TM_MAGIC;
+	qmtm_hndl = henv;
+	init_tm_alias_struct(tm_regs_base);
+	init_tm_init_offset_struct();
+	rc = tm_create_locking_staff(henv);
+	if (rc)
+		goto out;
+
+	tm_debug_on = TM_DISABLE;
+
+	rc = tm_lib_open(tm_prod_str, henv, (tm_handle *)(&(henv->tmctl)));
+	if (rc) {
+		rc = tm_to_qmtm_errcode(rc);
+		pr_err("TM lib open failed");
+		goto out;
+	}
+
+	rc = set_hw_connection(henv);
+	if (rc)
+		goto out;
+
+	rc = tm_lib_init_hw(henv->tmctl);
+	if (rc) {
+		rc = tm_to_qmtm_errcode(rc);
+		pr_err("TM lib init failed");
+		goto out;
+	}
+
+out:
+	if (rc) {
+		tm_lib_close(henv->tmctl);
+		tm_free(henv);
+		qmtm_hndl = NULL;
+		pr_err("TM open failed");
+	} else
+		pr_info("TM open completed successfuly\n");
+
+	return rc;
+}
+EXPORT_SYMBOL(tm_open);
+
+int tm_close(void)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* close library handle, if opened  */
+	if (ctl) {
+		/* release tm API library resources*/
+		rc = tm_lib_close(ctl);
+		if (rc) {
+			rc = tm_to_qmtm_errcode(rc);
+			goto out;
+		}
+	}
+
+	/* Attempt close anyway
+	 */
+	close_hw_connection(henv);
+
+	/* Free environment
+	 */
+	tm_destroy_locking_staff(henv);
+
+	tm_free(henv);
+	qmtm_hndl = NULL;
+out:
+	TM_WRAPPER_END(hndl);
+}
+EXPORT_SYMBOL(tm_close);
+
+int tm_check_args(struct qmtm *hndl, struct tm_ctl **ctl, struct qmtm **env)
+{
+	if (hndl == NULL)
+		return -EINVAL;
+	if (hndl->magic != TM_MAGIC)
+		return -EBADF;
+	if ((hndl->tmctl) && (hndl->tmctl->magic != TM_MAGIC))
+		return -EBADF;
+
+	*ctl = hndl->tmctl;
+	*env = NULL;
+
+	return 0;
+}
+
+int tm_drop_profiles_config(tm_handle hndl)
+{
+	uint16_t index; /* drop profile index */
+	uint8_t i, j;
+	int rc;
+
+	for (i = 0; i < 15/*(TM_NUM_PORT_DROP_PROF-1)*/; i++) { /* Drop Profile #0 reserved for NO_DROP */
+		rc = tm_create_drop_profile_2_5G(hndl, P_LEVEL, (uint8_t)TM_INVAL, &index);
+		if (rc) {
+			pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+			return rc;
+		}
+
+		for (j = 0; j < TM_WRED_COS; j++) {
+			rc = tm_create_drop_profile_2_5G(hndl, P_LEVEL, j, &index);
+			if (rc) {
+				pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+				return rc;
+			}
+		}
+	}
+
+	for (i = 0; i < (TM_NUM_C_NODE_DROP_PROF-1); i++) { /* Drop Profile #0 reserved for NO_DROP */
+		for (j = 0; j < TM_WRED_COS; j++) {
+			rc = tm_create_drop_profile_2_5G(hndl, C_LEVEL, j, &index);
+			if (rc) {
+				pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+				return rc;
+			}
+		}
+	}
+
+	for (i = 0; i < (TM_NUM_B_NODE_DROP_PROF-1); i++) { /* Drop Profile #0 reserved for NO_DROP */
+		rc = tm_create_drop_profile_2_5G(hndl, B_LEVEL, j, &index);
+		if (rc) {
+			pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+			return rc;
+		}
+	}
+
+	for (i = 0; i < (TM_NUM_A_NODE_DROP_PROF-1); i++) { /* Drop Profile #0 reserved for NO_DROP */
+		rc = tm_create_drop_profile_2_5G(hndl, A_LEVEL, j, &index);
+		if (rc) {
+			pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+			return rc;
+		}
+	}
+
+	for (i = 0; i < (TM_NUM_QUEUE_DROP_PROF-1); i++) { /* Drop Profile #0 reserved for NO_DROP */
+		rc = tm_create_drop_profile_2_5G(hndl, Q_LEVEL, j, &index);
+		if (rc) {
+			pr_info("*** (TM_SCN) ***: tm_drop_profiles_config: rc %d.\n", rc);
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+int tm_build_tree_under_port(tm_handle hndl, uint8_t port_index,
+				uint16_t num_of_c_nodes,
+				uint16_t num_of_b_nodes,
+				uint16_t num_of_a_nodes,
+				uint32_t num_of_queues)
+{
+	struct tm_c_node_params c_params;
+	struct tm_b_node_params b_params;
+	struct tm_a_node_params a_params;
+	struct tm_queue_params  q_params;
+
+	int rc = 0;
+	uint32_t i, n;
+	/* relative node index in children range under some parent node */
+	uint32_t queue, a_node, b_node, c_node;
+
+	uint32_t q_ind;              /* Queue index pointer  */
+	uint32_t a_ind;              /* A-node index pointer */
+	uint32_t b_ind;              /* B-node index pointer */
+	uint32_t c_ind;              /* C-node index pointer */
+
+	q_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	q_params.quantum = 0x40;
+
+	a_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	a_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	a_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		a_params.dwrr_priority[i] = TM_DISABLE;
+
+	b_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	b_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	b_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		b_params.dwrr_priority[i] = TM_DISABLE;
+
+	c_params.wred_cos = 0;
+	c_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		c_params.wred_profile_ref[i] = TM_NO_DROP_PROFILE;
+	c_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		c_params.dwrr_priority[i] = TM_DISABLE;
+
+	a_params.num_of_children = num_of_queues;
+	b_params.num_of_children = num_of_a_nodes;
+	c_params.num_of_children = num_of_b_nodes;
+
+	for (c_node = 0; c_node < num_of_c_nodes; c_node++) {
+		/* Connects C nodes to the port (port_index), returns the created C node index */
+		rc = tm_create_c_node_to_port(hndl, port_index, &c_params, &c_ind);
+		if (rc) {
+			pr_info("*** (TM_SCN) *** tm_create_c_node_to_port: rc %d.\n", rc);
+			return rc;
+		}
+
+		for (b_node = 0; b_node < num_of_b_nodes; b_node++) {
+			if (mv_active_config == TM_2xPPC_CONFIG) {
+				if (port_index == TM_A0_PORT_PPC0_1) {
+					if ((c_node == 0) && (b_node == 0)) /* B1 */
+						b_params.num_of_children = 5;
+					else if ((c_node == 0) && (b_node == 1)) /* B2 */
+						b_params.num_of_children = 6;
+					else
+						b_params.num_of_children = num_of_a_nodes;
+				}
+			}
+			/* Connects B nodes to C nodes (c_ind), returns the created B node index */
+			rc = tm_create_b_node_to_c_node(hndl, c_ind, &b_params, &b_ind);
+			if (rc) {
+				pr_info("*** (TM_SCN) *** tm_create_b_node_to_c_node: rc %d.\n", rc);
+				return rc;
+			}
+
+			for (a_node = 0; a_node < b_params.num_of_children; a_node++) {
+				/* Connects A nodes to B nodes (b_ind), returns the created A node index */
+				rc = tm_create_a_node_to_b_node(hndl, b_ind, &a_params, &a_ind);
+				if (rc) {
+					pr_info("*** (TM_SCN) *** tm_create_a_node_to_b_node: rc %d.\n", rc);
+					return rc;
+				}
+
+				for (queue = 0; queue < num_of_queues; queue++) {
+					n = queue%4;
+					switch (n) {
+					case 0: /* P0 */
+						q_params.elig_prio_func_ptr = TM_ELIG_Q_FIXED_P0;
+						break;
+
+					case 1: /* P1 */
+						q_params.elig_prio_func_ptr = TM_ELIG_Q_FIXED_P1;
+						break;
+
+					case 2: /* P2 */
+						q_params.elig_prio_func_ptr = TM_ELIG_Q_FIXED_P2;
+						break;
+
+					case 3: /* P3 */
+						q_params.elig_prio_func_ptr = TM_ELIG_Q_FIXED_P3;
+						break;
+
+					default:
+						return -3;
+					}
+
+					/* Connects queue to A nodes (a_ind), returns the created queue index */
+					/* In quantum of 4 queues per A node                                  */
+					rc = tm_create_queue_to_a_node(hndl, a_ind, &q_params, &q_ind);
+					if (rc) {
+						pr_info("*** (TM_SCN) *** tm_create_queue_to_a_node. rc %d\n", rc);
+						return rc;
+					}
+				 }
+			}
+		}
+	}
+
+	return rc;
+}
+
+int tm_defzero(void)
+{
+	struct tm_ctl *hndl = NULL;
+	int rc = 0;
+
+	pr_info("*** TM DefZero Scenario ***\n");
+
+	/* Write default registers */
+	rc = tm_lib_init_hw_def(hndl);
+	if (rc == 0)
+		pr_info("TM DefZero Scenario Completed Successfuly\n");
+	else
+		pr_info("TM DefZero Scenario Completed with Error %d\n", rc);
+	return rc;
+}
+
+/* Default scenario configuration */
+int tm_defcon(void)
+{
+	struct tm_ctl *hndl;
+	struct tm_port_params p_params;
+	enum tm_port_bw port_speed = TM_10G_PORT;
+
+	uint32_t cbw = MV_TM_2HG_BW; /* shaping rate 2.5G */
+	uint16_t dp_index = 1; /* drop profile index */
+	uint8_t port_index;
+	uint8_t i;
+	int rc;
+	uint16_t num_of_c_nodes = 0, num_of_b_nodes = 0, num_of_a_nodes = 0, num_queues = 0;
+	enum tm_level lvl;
+
+	if (!qmtm_hndl) {
+		rc = tm_open();
+		if (rc)
+			goto err_out;
+	}
+
+	if (mv_active_config != TM_INVALID_CONFIG) {
+		pr_warn("Warning: TM already configured to %s, cannot reconfig TM\n", tm_config_str(mv_active_config));
+		return 0;
+	}
+
+	pr_info("*** TM DefCon Scenario ***\n");
+	hndl = qmtm_hndl->tmctl;
+	mv_active_config = TM_DEFAULT_CONFIG;
+
+	/* Drop configuration - Drop profiles: out_BW = 2.5Gbps, Color blind TD */
+	rc = tm_drop_profiles_config(hndl);
+	if (rc) {
+		rc = -3;
+		goto err_out;
+	}
+
+	for (lvl = Q_LEVEL; lvl <= P_LEVEL; lvl++) {
+		rc = tm_configure_fixed_periodic_scheme_2_5G(hndl, lvl);
+		if (rc) {
+			rc = -3;
+			goto err_out;
+		}
+	}
+	p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	p_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		p_params.dwrr_priority[i] = TM_DISABLE;
+
+	/* Build TM Tree */
+	for (port_index = TM_A0_PORT_PPC0_0; port_index <= TM_A0_PORT_DROP1; port_index++) {
+		num_of_c_nodes = 1;
+		if ((port_index == TM_A0_PORT_PPC0_0) || (port_index == TM_A0_PORT_HMAC)) {
+			/* 128 queues */
+			num_of_b_nodes = 8;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+		} else if (port_index == TM_A0_PORT_PPC0_1) {
+			/* 64 queues */
+			num_of_b_nodes = 4;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+		} else if ((port_index == TM_A0_PORT_PPC1_MNT0) || (port_index == TM_A0_PORT_PPC1_MNT1)) {
+			num_of_b_nodes = 0;
+			num_of_a_nodes = 0;
+			num_queues     = 0;
+		} else if (port_index == TM_A0_PORT_EMAC0) {
+			/* 32 queues */
+			num_of_b_nodes = 2;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+		} else {
+			/* All other ports has 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+		}
+
+		switch (port_index) {
+		case TM_A0_PORT_PPC0_0:
+		case TM_A0_PORT_PPC0_1:
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_PPC1_MNT0:
+		case TM_A0_PORT_PPC1_MNT1:
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_EMAC0:
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_EMAC1:
+		case TM_A0_PORT_EMAC2:
+		case TM_A0_PORT_EMAC3:
+		case TM_A0_PORT_EMAC4:
+		case TM_A0_PORT_EMAC_LPB:
+			port_speed = TM_1G_PORT;
+			break;
+		case TM_A0_PORT_CMAC_IN:
+		case TM_A0_PORT_CMAC_LA:
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_HMAC:
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_UNUSED0:
+			/* These ports do not exists */
+			continue;
+		case TM_A0_PORT_DROP0:
+		case TM_A0_PORT_DROP1:
+			port_speed	 = TM_10G_PORT;
+			break;
+		}
+
+		if (port_index == TM_A0_PORT_EMAC0) {
+			/* 2.5G "shaping" drop */
+			p_params.wred_profile_ref = (uint8_t) dp_index;
+			rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+				num_of_c_nodes,
+				(num_of_b_nodes*num_of_c_nodes),
+				(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+				(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		} else {
+			/* No shaping */
+			p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+			if ((port_index == TM_A0_PORT_PPC1_MNT0) || (port_index == TM_A0_PORT_PPC1_MNT1))
+				rc = tm_create_asym_port(hndl, port_index, port_speed, &p_params);
+			else
+				rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+					num_of_c_nodes,
+					(num_of_b_nodes*num_of_c_nodes),
+					(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+					(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		}
+		if (rc) {
+			pr_info("*** (TM_SCN) *** tm_create_port: rc %d.\n", rc);
+			pr_info("*** (TM_SCN) *** port_index              : %d\n", port_index);
+			pr_info("*** (TM_SCN) *** port_speed              : %d\n", port_speed);
+			pr_info("*** (TM_SCN) *** num_of_c_nodes          : %d\n", num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_b_c_nodes        : %d\n", num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_nodes      : %d\n",
+				num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_queue_nodes: %d\n",
+				num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			goto err_out;
+		}
+
+		if ((port_index == TM_A0_PORT_PPC1_MNT0) || (port_index == TM_A0_PORT_PPC1_MNT1))
+			continue;
+
+		rc = tm_build_tree_under_port(hndl, port_index,
+			num_of_c_nodes, num_of_b_nodes, num_of_a_nodes, num_queues);
+		if (rc)
+			goto err_out;
+	}
+
+	/* 2.5G shaping on port EMAC0 */
+	rc = tm_set_min_shaping(hndl, P_LEVEL, TM_A0_PORT_EMAC0, cbw);
+
+err_out:
+	if (rc == 0)
+		pr_info("TM DefCon Scenario Completed Successfuly\n");
+	else
+		pr_info("TM DefCon Scenario Completed with Error %d\n", rc);
+	return rc;
+}
+EXPORT_SYMBOL(tm_defcon);
+
+/* cfg1 scenario configuration */
+int tm_cfg1(void)
+{
+	struct tm_ctl *hndl;
+	struct tm_port_params p_params;
+	enum tm_port_bw port_speed = TM_10G_PORT;
+
+	uint32_t cbw = MV_TM_2HG_BW; /* shaping rate 2.5G */
+	uint16_t dp_index = 1; /* drop profile index */
+	uint8_t port_index;
+	uint8_t i;
+	int rc;
+	uint16_t num_of_c_nodes = 0, num_of_b_nodes = 0, num_of_a_nodes = 0, num_queues = 0;
+	enum tm_level lvl;
+
+	if (!qmtm_hndl) {
+		rc = tm_open();
+		if (rc)
+			goto err_out;
+	}
+
+	if (mv_active_config != TM_INVALID_CONFIG) {
+		pr_warn("Warning: TM already configured to %s, cannot reconfig TM\n", tm_config_str(mv_active_config));
+		return 0;
+	}
+
+	pr_info("*** TM cfg1 Scenario ***\n");
+	hndl = qmtm_hndl->tmctl;
+	mv_active_config = TM_CFG1_CONFIG;
+
+	/* Drop configuration - Drop profiles: out_BW = 2.5Gbps, Color blind TD */
+	rc = tm_drop_profiles_config(hndl);
+	if (rc) {
+		rc = -3;
+		goto err_out;
+	}
+
+	for (lvl = Q_LEVEL; lvl <= P_LEVEL; lvl++) {
+		rc = tm_configure_fixed_periodic_scheme_2_5G(hndl, lvl);
+		if (rc) {
+			rc = -3;
+			goto err_out;
+		}
+	}
+	p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	p_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		p_params.dwrr_priority[i] = TM_DISABLE;
+
+	/* Build TM Tree */
+	for (port_index = TM_A0_PORT_PPC0_0; port_index <= TM_A0_PORT_DROP1; port_index++) {
+		num_of_c_nodes = 1;
+
+		switch (port_index) {
+		case TM_A0_PORT_PPC0_0:
+			/* 128 queues */
+			num_of_b_nodes = 8;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_PPC0_1:
+		case TM_A0_PORT_PPC1_MNT0:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_PPC1_MNT1:
+			/* 32 queues */
+			num_of_b_nodes = 2;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_EMAC0:
+			/* 32 queues */
+			num_of_b_nodes = 2;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_EMAC1:
+		case TM_A0_PORT_EMAC2:
+		case TM_A0_PORT_EMAC3:
+		case TM_A0_PORT_EMAC4:
+		case TM_A0_PORT_EMAC_LPB:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_1G_PORT;
+			break;
+		case TM_A0_PORT_CMAC_IN:
+			/* 64 queues */
+			num_of_b_nodes = 4;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			break;
+		case TM_A0_PORT_CMAC_LA:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_HMAC:
+			/* 80 queues */
+			num_of_b_nodes = 5;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_UNUSED0:
+		case TM_A0_PORT_DROP0:
+		case TM_A0_PORT_DROP1:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			num_queues     = 4;
+			port_speed	 = TM_10G_PORT;
+			break;
+		}
+
+		if (port_index == TM_A0_PORT_EMAC0) {
+			/* 2.5G "shaping" drop */
+			p_params.wred_profile_ref = (uint8_t) dp_index;
+			rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+				num_of_c_nodes,
+				(num_of_b_nodes*num_of_c_nodes),
+				(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+				(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		} else {
+			/* No shaping */
+			p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+			if (port_index == TM_A0_PORT_PPC0_1)
+				rc = tm_create_asym_port(hndl, port_index, port_speed, &p_params);
+			else
+				rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+					num_of_c_nodes,
+					(num_of_b_nodes*num_of_c_nodes),
+					(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+					(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		}
+		if (rc) {
+			pr_info("*** (TM_SCN) *** tm_create_port: rc %d.\n", rc);
+			pr_info("*** (TM_SCN) *** port_index              : %d\n", port_index);
+			pr_info("*** (TM_SCN) *** port_speed              : %d\n", port_speed);
+			pr_info("*** (TM_SCN) *** num_of_c_nodes          : %d\n", num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_b_c_nodes        : %d\n", num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_nodes      : %d\n",
+				num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_queue_nodes: %d\n",
+				num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			goto err_out;
+		}
+/*
+		if (port_index == TM_A0_PORT_PPC0_1)
+			continue;
+*/
+		rc = tm_build_tree_under_port(hndl, port_index,
+			num_of_c_nodes, num_of_b_nodes, num_of_a_nodes, num_queues);
+		if (rc)
+			goto err_out;
+	}
+
+	/* 2.5G shaping on port EMAC0 */
+	rc = tm_set_min_shaping(hndl, P_LEVEL, TM_A0_PORT_EMAC0, cbw);
+
+err_out:
+	if (rc == 0)
+		pr_info("TM cfg1 Scenario Completed Successfuly\n");
+	else
+		pr_info("TM cfg1 Scenario Completed with Error %d\n", rc);
+	return rc;
+}
+EXPORT_SYMBOL(tm_cfg1);
+
+
+/* 2xPPC scenario configuration */
+int tm_2xppc(void)
+{
+	struct tm_ctl *hndl;
+	struct tm_port_params p_params;
+	enum tm_port_bw port_speed = TM_10G_PORT;
+
+	uint32_t cbw = MV_TM_2HG_BW; /* shaping rate 2.5G */
+	uint16_t dp_index = 1; /* drop profile index */
+	uint8_t port_index;
+	uint8_t i;
+	int rc;
+	uint16_t num_of_c_nodes = 0, num_of_b_nodes = 0, num_of_a_nodes = 0, num_queues = 0;
+	enum tm_level lvl;
+
+	if (!qmtm_hndl) {
+		rc = tm_open();
+		if (rc)
+			goto err_out;
+	}
+
+	if (mv_active_config != TM_INVALID_CONFIG) {
+		pr_warn("Warning: TM already configured to %s, cannot reconfig TM\n", tm_config_str(mv_active_config));
+		return 0;
+	}
+
+	pr_info("*** TM 2xPPC Scenario ***\n");
+	hndl = qmtm_hndl->tmctl;
+	mv_active_config = TM_2xPPC_CONFIG;
+
+	/* Drop configuration - Drop profiles: out_BW = 2.5Gbps, Color blind TD */
+	rc = tm_drop_profiles_config(hndl);
+	if (rc) {
+		rc = -3;
+		goto err_out;
+	}
+
+	for (lvl = Q_LEVEL; lvl <= P_LEVEL; lvl++) {
+		rc = tm_configure_fixed_periodic_scheme_2_5G(hndl, lvl);
+		if (rc) {
+			rc = -3;
+			goto err_out;
+		}
+	}
+	p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	p_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		p_params.dwrr_priority[i] = TM_DISABLE;
+
+	/* Build TM Tree */
+	for (port_index = TM_A0_PORT_PPC0_0; port_index <= TM_A0_PORT_DROP1; port_index++) {
+		num_of_c_nodes = 1;
+		num_queues     = 4;
+
+		switch (port_index) {
+		case TM_A0_PORT_PPC0_0:
+			/* 4 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 1;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_PPC0_1:
+			/* non-equal queue distribution */
+			num_of_b_nodes = 7;
+			num_of_a_nodes = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_PPC1_MNT0:
+		case TM_A0_PORT_PPC1_MNT1:
+			/* 32 queues */
+			num_of_b_nodes = 2;
+			num_of_a_nodes = 4;
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_EMAC0:
+			/* 32 queues */
+			num_of_b_nodes = 2;
+			num_of_a_nodes = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_EMAC1:
+		case TM_A0_PORT_EMAC2:
+		case TM_A0_PORT_EMAC3:
+		case TM_A0_PORT_EMAC4:
+		case TM_A0_PORT_EMAC_LPB:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			port_speed = TM_1G_PORT;
+			break;
+		case TM_A0_PORT_CMAC_IN:
+			/* 64 queues */
+			num_of_b_nodes = 4;
+			num_of_a_nodes = 4;
+			break;
+		case TM_A0_PORT_CMAC_LA:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			port_speed = TM_10G_PORT;
+			break;
+		case TM_A0_PORT_HMAC:
+			/* 80 queues */
+			num_of_b_nodes = 5;
+			num_of_a_nodes = 4;
+			port_speed = TM_2HG_PORT;
+			break;
+		case TM_A0_PORT_UNUSED0:
+		case TM_A0_PORT_DROP0:
+		case TM_A0_PORT_DROP1:
+			/* 16 queues */
+			num_of_b_nodes = 1;
+			num_of_a_nodes = 4;
+			port_speed	 = TM_10G_PORT;
+			break;
+		}
+
+		if (port_index == TM_A0_PORT_EMAC0) {
+			/* 2.5G "shaping" drop */
+			p_params.wred_profile_ref = (uint8_t) dp_index;
+			rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+				num_of_c_nodes,
+				(num_of_b_nodes*num_of_c_nodes),
+				(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+				(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		} else {
+			/* No shaping */
+			p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+			if (port_index == TM_A0_PORT_PPC0_1)
+				rc = tm_create_asym_port(hndl, port_index, port_speed, &p_params);
+			else
+				rc = tm_create_port(hndl, port_index, port_speed, &p_params,
+					num_of_c_nodes,
+					(num_of_b_nodes*num_of_c_nodes),
+					(num_of_a_nodes*num_of_b_nodes*num_of_c_nodes),
+					(num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes));
+		}
+		if (rc) {
+			pr_info("*** (TM_SCN) *** tm_create_port: rc %d.\n", rc);
+			pr_info("*** (TM_SCN) *** port_index              : %d\n", port_index);
+			pr_info("*** (TM_SCN) *** port_speed              : %d\n", port_speed);
+			pr_info("*** (TM_SCN) *** num_of_c_nodes          : %d\n", num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_b_c_nodes        : %d\n", num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_nodes      : %d\n",
+				num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			pr_info("*** (TM_SCN) *** num_of_a_b_c_queue_nodes: %d\n",
+				num_queues*num_of_a_nodes*num_of_b_nodes*num_of_c_nodes);
+			goto err_out;
+		}
+
+		rc = tm_build_tree_under_port(hndl, port_index,
+			num_of_c_nodes, num_of_b_nodes, num_of_a_nodes, num_queues);
+		if (rc)
+			goto err_out;
+	}
+
+	/* 2.5G shaping on port EMAC0 */
+	rc = tm_set_min_shaping(hndl, P_LEVEL, TM_A0_PORT_EMAC0, cbw);
+
+err_out:
+	if (rc == 0)
+		pr_info("TM 2xPPC Scenario Completed Successfuly\n");
+	else
+		pr_info("TM 2xPPC Scenario Completed with Error %d\n", rc);
+	return rc;
+}
+EXPORT_SYMBOL(tm_2xppc);
+
+int __tm_create_default_c_node(tm_handle hndl, uint8_t port_index,
+				uint16_t num_of_b_children,
+				uint32_t *c_ind_ptr)
+{
+	struct tm_c_node_params c_params;
+	int i;
+	int rc = 0;
+
+	c_params.wred_cos = 0;
+	c_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		c_params.wred_profile_ref[i] = TM_NO_DROP_PROFILE;
+	c_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		c_params.dwrr_priority[i] = TM_DISABLE;
+	c_params.num_of_children = num_of_b_children;
+
+	/* Connects C nodes to the port (port_index), returns the created C node index */
+	rc = tm_create_c_node_to_port(hndl, port_index, &c_params, c_ind_ptr);
+/* */	if (rc)
+		pr_info("*** (TM_SCN) *** tm_create_c_node_to_port:  port:%d rc %d.\n", port_index, rc);
+
+	return rc;
+}
+int __tm_create_default_b_node(tm_handle hndl, uint16_t c_node_index,
+				uint16_t num_of_a_children,
+				uint32_t *b_ind_ptr)
+{
+	struct tm_b_node_params b_params;
+	int i;
+	int rc = 0;
+	b_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	b_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	b_params.quantum = 0x40;
+	b_params.num_of_children = num_of_a_children;
+	for (i = 0; i < 8; i++)
+		b_params.dwrr_priority[i] = TM_DISABLE;
+
+	rc = tm_create_b_node_to_c_node(hndl, c_node_index, &b_params, b_ind_ptr);
+/* */	if (rc)
+		pr_info("*** (TM_SCN) *** tm_create_b_node_to_c_node:  c_node : %d , rc %d.\n", c_node_index , rc);
+
+	return rc;
+}
+
+int __tm_create_default_a_node_with_queues(tm_handle hndl, uint16_t b_node_index,
+				uint16_t num_of_queues,
+				uint32_t *a_ind_ptr, uint32_t *last_queue_ptr)
+{
+	struct tm_a_node_params a_params;
+	struct tm_queue_params  q_params;
+	int i;
+
+	int rc = 0;
+	/* relative node index in children range under some parent node */
+	uint32_t queue;
+
+
+	a_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	a_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	a_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		a_params.dwrr_priority[i] = TM_DISABLE;
+	a_params.num_of_children = num_of_queues;
+
+	q_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	q_params.quantum = 0x40;
+	q_params.elig_prio_func_ptr = TM_ELIG_Q_DEFAULT;
+
+	/* Connects A node to B node (b_ind), returns the created A node index */
+	rc = tm_create_a_node_to_b_node(hndl, b_node_index, &a_params, a_ind_ptr);
+	if (rc) {
+		pr_info("*** (TM_SCN) *** tm_create_a_node_to_b_node:  b_node:%d , rc %d.\n", b_node_index, rc);
+		return rc;
+	}
+	/* create default queues to A-node */
+	for (queue = 0; queue < num_of_queues; queue++) {
+		/* Connects queue to A nodes (a_ind), returns the created queue index */
+		rc = tm_create_queue_to_a_node(hndl, *a_ind_ptr, &q_params, last_queue_ptr);
+		if (rc) {
+			pr_info("*** (TM_SCN) *** tm_create_queue_to_a_node. a_node:%d,   rc %d\n", *a_ind_ptr, rc);
+			return rc;
+		}
+	}
+	return rc;
+}
+
+int __tm_create_default_p_c_path(tm_handle hndl, uint8_t port_index,
+								enum tm_port_bw port_speed,
+								uint16_t num_of_b_children,
+								uint32_t *c_ind_ptr)
+{
+	struct tm_port_params p_params;
+	struct tm_c_node_params c_params;
+	int i;
+	int rc = 0;
+
+	p_params.wred_profile_ref = TM_NO_DROP_PROFILE;
+	p_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		p_params.dwrr_priority[i] = TM_DISABLE;
+
+	p_params.num_of_children = 1;
+
+	rc = tm_create_asym_port(hndl, port_index, port_speed, &p_params);
+	if (rc) {
+		pr_info("*** (TM_SCN) *** tm_create_asym_port: port : %d,  rc %d.\n", port_index, rc);
+		return rc;
+	}
+
+	c_params.wred_cos = 0;
+	c_params.elig_prio_func_ptr = TM_ELIG_N_DEFAULT;
+	for (i = 0; i < 8; i++)
+		c_params.wred_profile_ref[i] = TM_NO_DROP_PROFILE;
+	c_params.quantum = 0x40;
+	for (i = 0; i < 8; i++)
+		c_params.dwrr_priority[i] = TM_DISABLE;
+	c_params.num_of_children = num_of_b_children;
+
+	/* Connects C nodes to the port (port_index), returns the created C node index */
+	rc = tm_create_c_node_to_port(hndl, port_index, &c_params, c_ind_ptr);
+	if (rc)
+		pr_info("*** (TM_SCN) *** tm_create_c_node_to_port: port : %d , c_node: %d , rc %d.\n",
+				port_index, *c_ind_ptr, rc);
+
+	return rc;
+}
+
+int __tm_create_default_b_a_path(tm_handle hndl, uint16_t c_node_index,
+								uint16_t num_of_a_children,
+								uint16_t num_of_queues,
+								uint32_t *b_ind_ptr,
+								uint32_t *last_a_ind_ptr,
+								uint32_t *last_queue_ptr)
+{
+	int rc = 0;
+	int i;
+	rc = __tm_create_default_b_node(hndl, c_node_index, num_of_a_children, b_ind_ptr);
+	if (rc)
+		return rc;
+	for (i = 0; i < num_of_a_children; i++) {
+		rc = __tm_create_default_a_node_with_queues(hndl,
+													*b_ind_ptr,
+													num_of_queues,
+													last_a_ind_ptr,
+													last_queue_ptr);
+		if (rc)
+			return rc;
+	}
+	return rc;
+}
+
+#define	CREATE_P_C_PATH(port, port_speed, total_num_of_b_nodes)	\
+do {\
+	port_index = port;\
+	rc = __tm_create_default_p_c_path(hndl, port_index, port_speed, total_num_of_b_nodes , &c_node_index);\
+/* pr_info("TM cfg3 tree : port :  %d\n", port); */\
+	if (rc)\
+		goto err_out;\
+} while (0)
+
+#define	CREATE_B_NODE(a_nodes_per_b_node_num)	\
+do {\
+	rc =  __tm_create_default_b_node(hndl, c_node_index, a_nodes_per_b_node_num, &b_node_index);\
+/* pr_info("TM cfg3 tree : b_node :  %d\n", b_node_index); */\
+	if (rc)\
+		goto err_out;\
+} while (0)
+
+#define	CREATE_A_PATH(queues_per_anode)	\
+do {\
+	rc = __tm_create_default_a_node_with_queues(hndl,\
+			b_node_index, queues_per_anode, &a_node_index, &queue_index);\
+	if (rc)\
+		goto err_out;\
+}  while (0)
+
+#define	CREATE_A_PATH_SET(a_nodes_num, queues_per_anode)	\
+do {\
+	for (i = 0; i < a_nodes_num ; i++) {\
+		rc = __tm_create_default_a_node_with_queues(hndl,\
+				b_node_index, queues_per_anode, &a_node_index, &queue_index);\
+		if (rc)\
+			goto err_out;\
+	} \
+/*pr_info("                             last used Queue index  :  %d\n", queue_index);*/\
+} while (0)
+
+#define	CREATE_B_A_PATH(a_nodes_per_b_node_num, queues_per_anode)	\
+do {\
+		rc = __tm_create_default_b_a_path(hndl, c_node_index,\
+				a_nodes_per_b_node_num, queues_per_anode, &b_node_index, &a_node_index, &queue_index);\
+		if (rc)\
+			goto err_out;\
+/*pr_info("                             last used A-node index :  %d\n", a_node_index);*/\
+/*pr_info("                             last used Queue index  :  %d\n", queue_index);*/\
+} while (0)
+
+#define	CREATE_B_A_PATH_SET(b_nodes_num, a_nodes_per_b_node_num, queues_per_anode)	\
+do {\
+	for (i = 0; i < b_nodes_num ; i++) {\
+		rc = __tm_create_default_b_a_path(hndl, c_node_index,\
+				a_nodes_per_b_node_num, queues_per_anode, &b_node_index, &a_node_index, &queue_index);\
+		if (rc)\
+			goto err_out;\
+	} \
+/*pr_info("                             last used A-node index :  %d\n", a_node_index);*/\
+/*pr_info("                             last used Queue index  :  %d\n", queue_index);*/\
+} while (0)
+
+#define PRINT_CREATE_TREE_INFO(port) \
+/*
+do {\
+	pr_info(" PORT :  %s (%d)\n", #port, port);\
+	pr_info("                         last used C-node index :  %d\n", c_node_index);\
+	pr_info("                         last used B-node index :  %d\n", b_node_index);\
+	pr_info("                         last used A-node index :  %d\n", a_node_index);\
+	pr_info("                         last used Queue  index :  %d\n", queue_index);\
+} while (0)
+*/
+
+int tm_cfg3_tree(void)
+{
+	struct tm_ctl *hndl;
+
+	uint8_t port_index;
+	int rc;
+	uint32_t	queue_index = 0;
+	uint32_t	a_node_index = 0;
+	uint32_t	b_node_index = 0;
+	uint32_t	c_node_index = 0;
+	int		i;
+	enum tm_level lvl;
+
+	if (!qmtm_hndl) {
+		rc = tm_open();
+		if (rc)
+			goto err_out;
+	}
+
+	if (mv_active_config != TM_INVALID_CONFIG) {
+		pr_warn("Warning: TM already configured to %s, cannot reconfig TM\n", tm_config_str(mv_active_config));
+		return 0;
+	}
+
+	pr_info("*** TM cfg3 Scenario ***\n");
+	mv_active_config = TM_CFG3_CONFIG;
+	hndl = qmtm_hndl->tmctl;
+
+	/* Drop configuration - Drop profiles: out_BW = 2.5Gbps, Color blind TD */
+	rc = tm_drop_profiles_config(hndl);
+	if (rc) {
+		rc = -3;
+		goto err_out;
+	}
+
+	for (lvl = Q_LEVEL; lvl <= P_LEVEL; lvl++) {
+		rc = tm_configure_fixed_periodic_scheme_2_5G(hndl, lvl);
+		if (rc) {
+			rc = -3;
+			goto err_out;
+		}
+	}
+	/**********************************************************************************/
+	/* port TM_A0_PORT_PPC0_0 (0) : 1, 3*4*4+1*(1*8+1*2 +1*2+1*4)+1*(4*8+4*0+8*4)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_PPC0_0, TM_10G_PORT, 8 /*  total b_nodes per c_node */);
+		/* create three 4*4 branches */
+		CREATE_B_A_PATH_SET(4, 1/*A nodes per B*/, 4/*queues per A*/);
+		/* follows belowing assymmetric structure creation */
+		CREATE_B_A_PATH(8/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(12/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_PPC0_0);
+/**/
+#if 0
+	rc = tm_update_port_drop(hndl, TM_A0_PORT_PPC0_0, 1 /*drop profile for 2_5G */);
+	if (rc)
+		goto err_out;
+#endif
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_PPC0_1 (1) :  1*4*4+1*(1*8+1*2 +1*2+1*4)+1*(4*8+4*0+8*4)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_PPC0_1, TM_10G_PORT, 1 /*  total b_nodes per c_node */);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_PPC0_1);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_PPC1_MNT0 (2) : 1 , 1*4*4           ( c, b a q nodes mapping)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_PPC1_MNT0, TM_10G_PORT, 1 /* total b_nodes per c_node */);
+		/* create two 4*4 branches */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_PPC1_MNT0);
+/**/
+	/**********************************************************************************/
+	/* port TM_A0_PORT_PPC1_MNT1-3 : 1 , 2*4*4           ( c, b a q nodes mapping)    */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_PPC1_MNT1, TM_10G_PORT, 2 /* total b_nodes per c_node */);
+		/* create two 4*4 branches */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_PPC1_MNT1);
+/**/
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC0-4 : 1 , 1*1*12+ 1*(4*4+1*2+2*1) ( c, b a q nodes mapping)*/
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC0, TM_10G_PORT, 2 /* total b_nodes per c_node */);
+		/* create two 4*4 branches */
+		CREATE_B_A_PATH(1/*A nodes per B*/, 12/*queues per A*/);
+		CREATE_B_NODE(7/*A nodes per B*/);
+			CREATE_A_PATH(4/*queues per A*/);
+			CREATE_A_PATH(4/*queues per A*/);
+			CREATE_A_PATH(4/*queues per A*/);
+			CREATE_A_PATH(4/*queues per A*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+	/* 2.5G shaping on port EMAC0
+	rc = tm_set_min_shaping(hndl, P_LEVEL, TM_A0_PORT_EMAC0, 2500);
+	*/
+	/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC0);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC1-5 : 1 , 1*(1*12+1*2+2*1)       ( c, b a q nodes mapping)  */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC1, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		CREATE_B_NODE(4/*A nodes per B*/);
+			CREATE_A_PATH(12/*queues per A*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC1);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC2-6 : 1 , 1*(1*12+1*2+2*1)       ( c, b a q nodes mapping)  */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC2, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		CREATE_B_NODE(4/*A nodes per B*/);
+			CREATE_A_PATH(12/*queues per A*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC2);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC3-7 : 1 ,1*(1*12+1*2+2*1)       ( c, b a q nodes mapping)  */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC3, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		CREATE_B_NODE(4/*A nodes per B*/);
+			CREATE_A_PATH(12/*queues per A*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC3);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC4-8 : 1 , 1*4*4           ( c, b a q nodes mapping)        */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC4, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC4);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_EMAC_LPB-9 : 1 , 1*4*4           ( c, b a q nodes mapping)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_EMAC_LPB, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_EMAC_LPB);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_CMAC_IN-10 : 1 , 4*4*4           ( c, b a q nodes mapping)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_CMAC_IN, TM_10G_PORT, 4/* total b_nodes per c_node */);
+		/* create  four  4*4 branches */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_CMAC_IN);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_CMAC_LA-11 : 1 , 1*4*4           ( c, b a q nodes mapping)     */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_CMAC_LA, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_CMAC_LA);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_HMAC-12 : 1 , 2*1*16 + 2*2*8 + 1*(2*2 + 12*1) ( c, b a q nodes mapping)        */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_HMAC, TM_10G_PORT, 5/* total b_nodes per c_node */);
+		/* create  five  4*4 branches */
+		CREATE_B_A_PATH(1/*A nodes per B*/, 16/*queues per A*/);
+		CREATE_B_A_PATH(1/*A nodes per B*/, 16/*queues per A*/);
+		CREATE_B_A_PATH(2/*A nodes per B*/, 8/*queues per A*/);
+		CREATE_B_A_PATH(2/*A nodes per B*/, 8/*queues per A*/);
+		CREATE_B_NODE(14/*total A nodes per B*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(2/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+			CREATE_A_PATH(1/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_HMAC);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_UNUSED0-13 : 1 ,1*4*4           ( c b a  nodes mapping)        */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_UNUSED0, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_UNUSED0);
+/**/
+
+	/**********************************************************************************/
+	/* port TM_A0_PORT_DROP0-14 : 1 , 1*4*4           ( c, b a q nodes mapping)       */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_DROP0, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_DROP0);
+/**/
+	/**********************************************************************************/
+	/* port TM_A0_PORT_DROP1-15 : 1 , 1*4*4           ( c, b a q nodes mapping)       */
+	/**********************************************************************************/
+	CREATE_P_C_PATH(TM_A0_PORT_DROP1, TM_10G_PORT, 1/* total b_nodes per c_node */);
+		/* create 4*4 branch */
+		CREATE_B_A_PATH(4/*A nodes per B*/, 4/*queues per A*/);
+/**/
+PRINT_CREATE_TREE_INFO(TM_A0_PORT_DROP1);
+/**/
+
+/*
+rc = tm_dump_port_hw(hndl, TM_A0_PORT_PPC0_0);
+rc = tm_dump_port_hw(hndl, TM_A0_PORT_HMAC);
+*/
+
+	/* here all C-node, B-node & Queue resources are already used */
+	/*
+	pr_info("TM cfg3 tree : valid tree created:\n");
+	pr_info("                         last used C-node index :  %d\n", c_node_index);
+	pr_info("                         last used B-node index :  %d\n", b_node_index);
+	pr_info("                         last used A-node index :  %d\n", a_node_index);
+	pr_info("                         last used Queue  index :  %d\n", queue_index);
+	*/
+
+err_out:
+	if (rc == 0)
+		pr_info("TM cfg3 tree Completed Successfuly\n");
+	else
+		pr_info("TM cfg3 Completed with Error %d\n", rc);
+	return rc;
+}
+EXPORT_SYMBOL(tm_cfg3_tree);
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/mv_tm.h b/drivers/net/ethernet/marvell/pp3/tm/mv_tm.h
new file mode 100644
index 0000000..4ab4b1c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/mv_tm.h
@@ -0,0 +1,170 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef MV_TM__H
+#define MV_TM__H
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "tm_to_qmtm_enums.h"
+
+/* Ports Numbers */
+#define TM_A0_PORT_PPC0_0     0
+#define TM_A0_PORT_PPC0_1     1
+#define TM_A0_PORT_PPC1_MNT0  2
+#define TM_A0_PORT_PPC1_MNT1  3
+#define TM_A0_PORT_EMAC0      4
+#define TM_A0_PORT_EMAC1      5
+#define TM_A0_PORT_EMAC2      6
+#define TM_A0_PORT_EMAC3      7
+#define TM_A0_PORT_EMAC4      8
+#define TM_A0_PORT_EMAC_LPB   9
+#define TM_A0_PORT_CMAC_IN    10
+#define TM_A0_PORT_CMAC_LA    11
+#define TM_A0_PORT_HMAC       12
+#define TM_A0_PORT_UNUSED0    13
+#define TM_A0_PORT_DROP0      14
+#define TM_A0_PORT_DROP1      15
+
+#define MV_TM_MAX_PORTS			16
+
+/* Predefined Shaping rate */
+#define MV_TM_1G_BW			1000
+#define MV_TM_2HG_BW		2500
+#define MV_TM_6G_BW			6000
+
+extern uint8_t tm_debug_on;
+extern struct qmtm *qmtm_hndl;
+extern void __iomem *tm_regs_base;
+extern const char *tm_prod_str;
+
+enum mv_tm_level {
+	TM_Q_LEVEL = 0,
+	TM_A_LEVEL,
+	TM_B_LEVEL,
+	TM_C_LEVEL,
+	TM_P_LEVEL
+};
+
+
+enum mv_tm_config {
+	TM_INVALID_CONFIG = 0,
+	TM_DEFAULT_CONFIG,
+	TM_CFG1_CONFIG,
+	TM_2xPPC_CONFIG,
+	TM_CFG3_CONFIG,
+	TM_LAST_CONFIG
+};
+
+
+/**
+ * @brief   Data structure for qmtm adaptation
+ */
+struct qmtm {
+	u32 magic;                 /**< magic number of tm struct */
+	struct tm_ctl *tmctl;      /**< Internal TM handle (into TM core) */
+};
+
+/**
+ * @brief   Declare a TM environment and check consitency
+ */
+#define TM_ENVIRONMENT(_name, _handle) \
+		struct qmtm *_name = (	struct qmtm *)(_handle); \
+	if ((_name) == NULL) { \
+		return -EINVAL; \
+	} \
+	if ((_name)->magic != TM_MAGIC) { \
+		return -EBADF; \
+	} \
+
+/**
+ * @brief   Wrapper macro to initialize variables from handle pointer
+ */
+#define	TM_WRAPPER_BEGIN(_handle, _ctl, _henv)	\
+	struct tm_ctl *_ctl; \
+	struct qmtm *_henv; \
+	int rc; \
+	rc = tm_check_args(_handle, &(_ctl), &(_henv)); \
+	if (rc != 0) { \
+		return rc; \
+	}
+
+/**
+ * @brief   Check arguments and get pointers
+ *
+ */
+int tm_check_args(struct qmtm *hndl, struct tm_ctl **ctl, struct qmtm **env);
+
+/**
+ * @brief   Wrapper macro to check for errors and return
+ */
+#define	TM_WRAPPER_END(_handle)	\
+	if (rc) { \
+		rc = tm_to_qmtm_errcode(rc); \
+	} \
+	return rc;
+
+/* TM unit once time global initialization */
+int tm_global_init(void __iomem *base, const char *prod_str);
+
+/**
+ * @brief   create  & initialize TM configuration library  database.
+  */
+int tm_open(void);
+
+/**
+ * @brief   Close TM configuration library.
+  */
+int tm_close(void);
+
+int tm_defzero(void);
+int tm_defcon(void);
+int tm_cfg1(void);
+int tm_2xppc(void);
+
+
+int tm_cfg3_tree(void);
+
+
+/**
+ * @brief   Init SysFS.
+ *
+ * @return an integer return code.
+ */
+int mv_pp3_tm_sysfs_init(struct kobject *pp3_kobj);
+
+
+/**
+ * @brief   Exit SysFS.
+ *
+ * @return an integer return code.
+ */
+int mv_pp3_tm_sysfs_exit(struct kobject *hmac_kobj);
+
+
+#endif /* MV_TM__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/TM.h b/drivers/net/ethernet/marvell/pp3/tm/platform/TM.h
new file mode 100644
index 0000000..a15ac6d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/TM.h
@@ -0,0 +1,35 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_H
+#define TM_H
+
+#include "tm_alias.h"
+#include "tm_payloads.h"
+
+#endif /* TM_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.c
new file mode 100644
index 0000000..96f853c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.c
@@ -0,0 +1,707 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_alias.h"
+#include "tm_os_interface.h"
+
+struct tm_alias TM;
+struct tm_alias tm_index_offset;
+
+
+/** Register alias definition for the RevA TM unit.
+ */
+void init_tm_alias_struct(void __iomem *base)
+{
+	TM.silicon_base = base;
+
+	TM.Drop.AlvlDropPrfTailDrpThresh = 0x00491200;
+	TM.Drop.AlvlDropPrfWREDDPRatio = 0x004911C0;
+	TM.Drop.AlvlDropPrfWREDMinThresh = 0x00491180;
+	TM.Drop.AlvlDropPrfWREDParams = 0x00491100;
+	TM.Drop.AlvlDropPrfWREDScaleRatio = 0x00491140;
+	TM.Drop.AlvlDropProb = 0x0049BC00;
+	TM.Drop.AlvlDropProfPtr = 0x00491000;
+	TM.Drop.AlvlInstAndAvgQueueLength = 0x0049B800;
+	TM.Drop.AlvlREDCurve.Color[0] = 0x00492000; /* Color[0] */
+	TM.Drop.AlvlREDCurve.Color[1] = 0x00492800; /* Color[1] */
+	TM.Drop.AlvlREDCurve.Color[2] =  0x00493000; /* Color[2] */
+	TM.Drop.BlvlDropPrfTailDrpThresh = 0x00490140;
+	TM.Drop.BlvlDropPrfWREDDPRatio = 0x00490100;
+	TM.Drop.BlvlDropPrfWREDMinThresh = 0x004900C0;
+	TM.Drop.BlvlDropPrfWREDParams = 0x00490040;
+	TM.Drop.BlvlDropPrfWREDScaleRatio = 0x00490080;
+	TM.Drop.BlvlDropProb = 0x0049B500;
+	TM.Drop.BlvlDropProfPtr = 0x00490000;
+	TM.Drop.BlvlInstAndAvgQueueLength = 0x0049B400;
+	TM.Drop.BlvlREDCurve[0].Table = 0x00490400;
+	TM.Drop.BlvlREDCurve[1].Table = 0x00490500;
+	TM.Drop.BlvlREDCurve[2].Table = 0x00490600;
+	TM.Drop.BlvlREDCurve[3].Table = 0x00490700;
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[0] = 0x00488A80; /* CoS[0] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[1] =  0x00488A90; /* CoS[1] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[2] = 0x00488AA0; /* CoS[2] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[3] = 0x00488AB0; /* CoS[3] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[4] = 0x00488AC0; /* CoS[4] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[5] = 0x00488AD0; /* CoS[5] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[6] = 0x00488AE0; /* CoS[6] */
+	TM.Drop.ClvlDropPrfTailDrpThresh.CoS[7] = 0x00488AF0; /* CoS[7] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[0] = 0x00488A00; /* CoS[0] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[1] = 0x00488A10; /* CoS[1] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[2] = 0x00488A20; /* CoS[2] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[3] =  0x00488A30; /* CoS[3] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[4] = 0x00488A40; /* CoS[4] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[5] = 0x00488A50; /* CoS[5] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[6] = 0x00488A60; /* CoS[6] */
+	TM.Drop.ClvlDropPrfWREDDPRatio.CoS[7] = 0x00488A70; /* CoS[7] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[0] = 0x00488980; /* CoS[0] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[1] = 0x00488990; /* CoS[1] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[2] = 0x004889A0; /* CoS[2] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[3] = 0x004889B0; /* CoS[3] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[4] = 0x004889C0; /* CoS[4] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[5] = 0x004889D0; /* CoS[5] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[6] = 0x004889E0; /* CoS[6] */
+	TM.Drop.ClvlDropPrfWREDMinThresh.CoS[7] = 0x004889F0; /* CoS[7] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[0] =  0x00488880; /* CoS[0] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[1] =  0x00488890; /* CoS[1] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[2] =  0x004888A0; /* CoS[2] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[3] =  0x004888B0; /* CoS[3] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[4] =  0x004888C0; /* CoS[4] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[5] =  0x004888D0; /* CoS[5] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[6] =  0x004888E0; /* CoS[6] */
+	TM.Drop.ClvlDropPrfWREDParams.CoS[7] =  0x004888F0; /* CoS[7] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[0] = 0x00488900; /* CoS[0] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[1] = 0x00488910; /* CoS[1] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[2] = 0x00488920; /* CoS[2] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[3] = 0x00488930; /* CoS[3] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[4] = 0x00488940; /* CoS[4] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[5] = 0x00488950; /* CoS[5] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[6] = 0x00488960; /* CoS[6] */
+	TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[7] = 0x00488970; /* CoS[7] */
+	TM.Drop.ClvlDropProb = 0x0049B000;
+	TM.Drop.ClvlDropProfPtr_CoS[0] = 0x00488800; /* ClvlDropProfPtr_CoS[0] */
+	TM.Drop.ClvlDropProfPtr_CoS[1] = 0x00488810; /* ClvlDropProfPtr_CoS[1] */
+	TM.Drop.ClvlDropProfPtr_CoS[2] = 0x00488820; /* ClvlDropProfPtr_CoS[2] */
+	TM.Drop.ClvlDropProfPtr_CoS[3] = 0x00488830; /* ClvlDropProfPtr_CoS[3] */
+	TM.Drop.ClvlDropProfPtr_CoS[4] = 0x00488840; /* ClvlDropProfPtr_CoS[4] */
+	TM.Drop.ClvlDropProfPtr_CoS[5] = 0x00488850; /* ClvlDropProfPtr_CoS[5] */
+	TM.Drop.ClvlDropProfPtr_CoS[6] = 0x00488860; /* ClvlDropProfPtr_CoS[6] */
+	TM.Drop.ClvlDropProfPtr_CoS[7] = 0x00488870; /* ClvlDropProfPtr_CoS[7] */
+	TM.Drop.ClvlInstAndAvgQueueLength = 0x0049AC00;
+	TM.Drop.ClvlREDCurve.CoS[0] = 0x0048A000; /* CoS[0] */
+	TM.Drop.ClvlREDCurve.CoS[1] = 0x0048A400; /* CoS[1] */
+	TM.Drop.ClvlREDCurve.CoS[2] = 0x0048A800; /* CoS[2] */
+	TM.Drop.ClvlREDCurve.CoS[3] = 0x0048AC00; /* CoS[3] */
+	TM.Drop.ClvlREDCurve.CoS[4] = 0x0048B000; /* CoS[4] */
+	TM.Drop.ClvlREDCurve.CoS[5] = 0x0048B400; /* CoS[5] */
+	TM.Drop.ClvlREDCurve.CoS[6] = 0x0048B800; /* CoS[6] */
+	TM.Drop.ClvlREDCurve.CoS[7] = 0x0048BC00; /* CoS[7] */
+	TM.Drop.DPSource = 0x00480048;
+	TM.Drop.Drp_Decision_hierarchy_to_Query_debug = 0x00480060;
+	TM.Drop.Drp_Decision_to_Query_debug = 0x00480058;
+	TM.Drop.EccConfig = 0x0049E000;
+	TM.Drop.ErrCnt = 0x00480010;
+	TM.Drop.ErrStus = 0x00480000;
+	TM.Drop.ExcCnt = 0x00480018;
+	TM.Drop.ExcMask = 0x00480020;
+	TM.Drop.FirstExc = 0x00480008;
+	TM.Drop.ForceErr = 0x00480030;
+	TM.Drop.Id = 0x00480028;
+	TM.Drop.PortDropPrfTailDrpThresh = 0x00488200;
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[0] = 0x00485000; /* PortDropPrfTailDrpThresh_CoSRes[0] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[1] = 0x00485080; /* PortDropPrfTailDrpThresh_CoSRes[1] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[2] = 0x00485100; /* PortDropPrfTailDrpThresh_CoSRes[2] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[3] = 0x00485180; /* PortDropPrfTailDrpThresh_CoSRes[3] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[4] = 0x00485200; /* PortDropPrfTailDrpThresh_CoSRes[4] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[5] = 0x00485280; /* PortDropPrfTailDrpThresh_CoSRes[5] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[6] = 0x00485300; /* PortDropPrfTailDrpThresh_CoSRes[6] */
+	TM.Drop.PortDropPrfTailDrpThresh_CoSRes[7] = 0x00485380; /* PortDropPrfTailDrpThresh_CoSRes[7] */
+	TM.Drop.PortDropPrfWREDDPRatio = 0x00488180;
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[0] = 0x00484C00; /* PortDropPrfWREDDPRatio_CoSRes[0] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[1] = 0x00484C80; /* PortDropPrfWREDDPRatio_CoSRes[1] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[2] = 0x00484D00; /* PortDropPrfWREDDPRatio_CoSRes[2] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[3] = 0x00484D80; /* PortDropPrfWREDDPRatio_CoSRes[3] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[4] = 0x00484E00; /* PortDropPrfWREDDPRatio_CoSRes[4] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[5] = 0x00484E80; /* PortDropPrfWREDDPRatio_CoSRes[5] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[6] = 0x00484F00; /* PortDropPrfWREDDPRatio_CoSRes[6] */
+	TM.Drop.PortDropPrfWREDDPRatio_CoSRes[7] = 0x00484F80; /* PortDropPrfWREDDPRatio_CoSRes[7] */
+	TM.Drop.PortDropPrfWREDMinThresh = 0x00488100;
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[0] = 0x00484800; /* PortDropPrfWREDMinThresh_CoSRes[0] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[1] = 0x00484880; /* PortDropPrfWREDMinThresh_CoSRes[1] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[2] = 0x00484900; /* PortDropPrfWREDMinThresh_CoSRes[2] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[3] = 0x00484980; /* PortDropPrfWREDMinThresh_CoSRes[3] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[4] = 0x00484A00; /* PortDropPrfWREDMinThresh_CoSRes[4] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[5] = 0x00484A80; /* PortDropPrfWREDMinThresh_CoSRes[5] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[6] = 0x00484B00; /* PortDropPrfWREDMinThresh_CoSRes[6] */
+	TM.Drop.PortDropPrfWREDMinThresh_CoSRes[7] = 0x00484B80; /* PortDropPrfWREDMinThresh_CoSRes[7] */
+	TM.Drop.PortDropPrfWREDParams = 0x00488000;
+	TM.Drop.PortDropPrfWREDParams_CoSRes[0] = 0x00484000; /* PortDropPrfWREDParams_CoSRes[0] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[1] = 0x00484080; /* PortDropPrfWREDParams_CoSRes[1] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[2] = 0x00484100; /* PortDropPrfWREDParams_CoSRes[2] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[3] = 0x00484180; /* PortDropPrfWREDParams_CoSRes[3] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[4] = 0x00484200; /* PortDropPrfWREDParams_CoSRes[4] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[5] = 0x00484280; /* PortDropPrfWREDParams_CoSRes[5] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[6] = 0x00484300; /* PortDropPrfWREDParams_CoSRes[6] */
+	TM.Drop.PortDropPrfWREDParams_CoSRes[7] = 0x00484380; /* PortDropPrfWREDParams_CoSRes[7] */
+	TM.Drop.PortDropPrfWREDScaleRatio = 0x00488080;
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[0] = 0x00484400; /* PortDropPrfWREDScaleRatio_CoSRes[0] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[1] = 0x00484480; /* PortDropPrfWREDScaleRatio_CoSRes[1] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[2] = 0x00484500; /* PortDropPrfWREDScaleRatio_CoSRes[2] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[3] = 0x00484580; /* PortDropPrfWREDScaleRatio_CoSRes[3] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[4] = 0x00484600; /* PortDropPrfWREDScaleRatio_CoSRes[4] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[5] = 0x00484600; /* PortDropPrfWREDScaleRatio_CoSRes[5] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[6] = 0x00484700; /* PortDropPrfWREDScaleRatio_CoSRes[6] */
+	TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[7] = 0x00484780; /* PortDropPrfWREDScaleRatio_CoSRes[7] */
+	TM.Drop.PortDropProb = 0x0049A080;
+	TM.Drop.PortDropProbPerCoS_CoS[0] = 0x0049A800; /* CoS[0] */
+	TM.Drop.PortDropProbPerCoS_CoS[1] = 0x0049A880; /* CoS[1] */
+	TM.Drop.PortDropProbPerCoS_CoS[2] = 0x0049A900; /* CoS[2] */
+	TM.Drop.PortDropProbPerCoS_CoS[3] = 0x0049A980; /* CoS[3] */
+	TM.Drop.PortDropProbPerCoS_CoS[4] = 0x0049AA00; /* CoS[4] */
+	TM.Drop.PortDropProbPerCoS_CoS[5] = 0x0049AA80; /* CoS[5] */
+	TM.Drop.PortDropProbPerCoS_CoS[6] = 0x0049AB00; /* CoS[6] */
+	TM.Drop.PortDropProbPerCoS_CoS[7] = 0x0049AB80; /* CoS[7] */
+	TM.Drop.PortInstAndAvgQueueLength = 0x0049A000;
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[0] = 0x0049A400; /* CoS[0] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[1] = 0x0049A480; /* CoS[1] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[2] = 0x0049A500; /* CoS[2] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[3] = 0x0049A580; /* CoS[3] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[4] = 0x0049A600; /* CoS[4] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[5] = 0x0049A680; /* CoS[5] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[6] = 0x0049A700; /* CoS[6] */
+	TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[7] = 0x0049A780; /* CoS[7] */
+	TM.Drop.PortREDCurve = 0x00488400;
+	TM.Drop.PortREDCurve_CoS[0] = 0x00486000; /* PortREDCurve_CoS[0] */
+	TM.Drop.PortREDCurve_CoS[1] = 0x00486400; /* PortREDCurve_CoS[1] */
+	TM.Drop.PortREDCurve_CoS[2] = 0x00486800; /* PortREDCurve_CoS[2] */
+	TM.Drop.PortREDCurve_CoS[3] = 0x00486C00; /* PortREDCurve_CoS[3] */
+	TM.Drop.PortREDCurve_CoS[4] = 0x00487000; /* PortREDCurve_CoS[4] */
+	TM.Drop.PortREDCurve_CoS[5] = 0x00487400; /* PortREDCurve_CoS[5] */
+	TM.Drop.PortREDCurve_CoS[6] = 0x00487800; /* PortREDCurve_CoS[6] */
+	TM.Drop.PortREDCurve_CoS[7] = 0x00487C00; /* PortREDCurve_CoS[7] */
+	TM.Drop.QueueAvgQueueLength = 0x0049C000;
+	TM.Drop.QueueCoSConf = 0x00498000;
+	TM.Drop.QueueDropPrfTailDrpThresh = 0x00494600;
+	TM.Drop.QueueDropPrfWREDDPRatio = 0x00494580;
+	TM.Drop.QueueDropPrfWREDMinThresh = 0x00494500;
+	TM.Drop.QueueDropPrfWREDParams = 0x00494400;
+	TM.Drop.QueueDropPrfWREDScaleRatio = 0x00494480;
+	TM.Drop.QueueDropProb = 0x0049D000;
+	TM.Drop.QueueDropProfPtr = 0x00494000;
+	TM.Drop.QueueREDCurve.Color[0] = 0x00496000; /* Color[0] */
+	TM.Drop.QueueREDCurve.Color[1] = 0x00496800; /* Color[1] */
+	TM.Drop.QueueREDCurve.Color[2] = 0x00497000; /* Color[2] */
+	TM.Drop.RespLocalDPSel = 0x00480050;
+	TM.Drop.WREDDropProbMode = 0x00480038;
+	TM.Drop.WREDMaxProbModePerColor = 0x00480040;
+
+	TM.Sched.ALevelShaperBucketNeg = 0x0045AC00;
+	TM.Sched.ALvltoBlvlAndQueueRangeMap = 0x00453400;
+	TM.Sched.AlvlDWRRPrioEn = 0x00452C00;
+	TM.Sched.AlvlDef = 0x0045B000;
+	TM.Sched.AlvlEligPrioFunc = 0x00451000;
+	TM.Sched.AlvlEligPrioFuncPtr = 0x00452000;
+	TM.Sched.AlvlPerConf = 0x00450000;
+	TM.Sched.AlvlPerRateShpPrms = 0x00450008;
+	TM.Sched.AlvlPerRateShpPrmsInt = 0x00463BA0;
+	TM.Sched.AlvlQuantum = 0x00453000;
+	TM.Sched.AlvlShpBucketLvls = 0x0045A800;
+	TM.Sched.AlvlTokenBucketBurstSize = 0x00452800;
+	TM.Sched.AlvlTokenBucketTokenEnDiv = 0x00452400; //0x00449100;
+	TM.Sched.BLevelShaperBucketNeg = 0x0045A500;
+	TM.Sched.BLvltoClvlAndAlvlRangeMap = 0x00449500;
+	TM.Sched.BlvlDWRRPrioEn = 0x00449300;
+	TM.Sched.BlvlDef = 0x0045A600;
+	TM.Sched.BlvlEligPrioFunc = 0x00448000;
+	TM.Sched.BlvlEligPrioFuncPtr = 0x00449000;
+	TM.Sched.BlvlPerConf = 0x00447000;
+	TM.Sched.BlvlPerRateShpPrms = 0x00447008;
+	TM.Sched.BlvlPerRateShpPrmsInt = 0x004616E0;
+	TM.Sched.BlvlQuantum = 0x00449400;
+	TM.Sched.BlvlShpBucketLvls = 0x0045A400;
+	TM.Sched.BlvlTokenBucketBurstSize = 0x00449200;
+	TM.Sched.BlvlTokenBucketTokenEnDiv = 0x00449100;
+	TM.Sched.CLevelShaperBucketNeg = 0x0045A280;
+	TM.Sched.CLvlDef = 0x0045A300;
+	TM.Sched.ClvlDWRRPrioEn = 0x00446180;
+	TM.Sched.ClvlEligPrioFunc = 0x00445000;
+	TM.Sched.ClvlEligPrioFuncPtr = 0x00446000;
+	TM.Sched.ClvlPerConf = 0x00444000;
+	TM.Sched.ClvlPerRateShpPrms = 0x00444008;
+	TM.Sched.ClvlPerRateShpPrmsInt = 0x00460B60;
+	TM.Sched.ClvlQuantum = 0x00446200;
+	TM.Sched.ClvlShpBucketLvls = 0x0045A200;
+	TM.Sched.ClvlTokenBucketBurstSize = 0x00446100;
+	TM.Sched.ClvlTokenBucketTokenEnDiv = 0x00446080;
+	TM.Sched.ClvltoPortAndBlvlRangeMap = 0x00446280;
+	TM.Sched.EccConfig = 0x00470000;
+	TM.Sched.ErrCnt = 0x00440018;
+	TM.Sched.ErrStus = 0x00440000;
+	TM.Sched.ExcCnt = 0x00440010;
+	TM.Sched.ExcMask = 0x00440020;
+	TM.Sched.FirstExc = 0x00440008;
+	TM.Sched.ForceErr = 0x00440030;
+	TM.Sched.Id = 0x00440028;
+	TM.Sched.PortDWRRBytesPerBurstsLimit = 0x00441018;
+	TM.Sched.PortDWRRPrioEn = 0x00443180;
+	TM.Sched.PortDefPrioHi = 0x0045A180;
+	TM.Sched.PortDefPrioLo = 0x0045A100;
+	TM.Sched.PortEligPrioFunc = 0x00442000;
+	TM.Sched.PortEligPrioFuncPtr = 0x00443000;
+	TM.Sched.PortExtBPEn = 0x00441010;
+	TM.Sched.PortPerConf = 0x00441000;
+	TM.Sched.PortPerRateShpPrms = 0x00441008;
+	TM.Sched.PortPerRateShpPrmsInt = 0x00460308;
+	TM.Sched.PortQuantumsPriosHi = 0x00443280;
+	TM.Sched.PortQuantumsPriosLo = 0x00443200;
+	TM.Sched.PortRangeMap = 0x00443300;
+	TM.Sched.PortShaperBucketNeg = 0x0045A080;
+	TM.Sched.PortShpBucketLvls = 0x0045A000;
+	TM.Sched.PortTokenBucketBurstSize = 0x00443100;
+	TM.Sched.PortTokenBucketTokenEnDiv = 0x00443080;
+	TM.Sched.QueueAMap = 0x00459000;
+	TM.Sched.QueueDef = 0x0045E000;
+	TM.Sched.QueueEligPrioFunc = 0x00454200;
+	TM.Sched.QueueEligPrioFuncPtr = 0x00455000;
+	TM.Sched.QueuePerConf = 0x00454000;
+	TM.Sched.QueuePerRateShpPrms = 0x00454008;
+	TM.Sched.QueuePerRateShpPrmsInt = 0x00465748;
+	TM.Sched.QueueQuantum = 0x00458000;
+	TM.Sched.QueueShaperBucketNeg = 0x0045D000;
+	TM.Sched.QueueShpBucketLvls = 0x0045C000;
+	TM.Sched.QueueTokenBucketBurstSize = 0x00457000;
+	TM.Sched.QueueTokenBucketTokenEnDiv = 0x00456000;
+	TM.Sched.ScrubDisable = 0x0045F008;
+	TM.Sched.ScrubSlotAlloc = 0x00440038;
+	TM.Sched.TreeDWRRPrioEn = 0x00440050;
+	TM.Sched.TreeDeqEn = 0x00440048;
+}
+
+void init_tm_init_offset_struct()
+{
+	int i;
+	tm_memset(&tm_index_offset, 0, sizeof(tm_index_offset));
+
+	tm_index_offset.Drop.QueueDropPrfWREDParams = 0x8;
+	tm_index_offset.Drop.QueueDropPrfWREDScaleRatio = 0x8;
+	tm_index_offset.Drop.QueueDropPrfWREDMinThresh = 0x8;
+	tm_index_offset.Drop.QueueDropPrfTailDrpThresh = 0x8;
+	tm_index_offset.Drop.QueueDropPrfWREDDPRatio = 0x8;
+	for (i = 0; i < 3; i++)
+		tm_index_offset.Drop.QueueREDCurve.Color[i] = 0x8;
+
+	tm_index_offset.Drop.AlvlDropPrfWREDParams = 0x8;
+	tm_index_offset.Drop.AlvlDropPrfWREDScaleRatio = 0x8;
+	tm_index_offset.Drop.AlvlDropPrfWREDMinThresh = 0x8;
+	tm_index_offset.Drop.AlvlDropPrfTailDrpThresh = 0x8;
+	tm_index_offset.Drop.AlvlDropPrfWREDDPRatio = 0x8;
+	for (i = 0; i < 3; i++)
+		tm_index_offset.Drop.AlvlREDCurve.Color[i] = 0x8;
+
+	tm_index_offset.Drop.BlvlDropPrfWREDParams = 0x8;
+	tm_index_offset.Drop.BlvlDropPrfWREDScaleRatio = 0x8;
+	tm_index_offset.Drop.BlvlDropPrfWREDMinThresh = 0x8;
+	tm_index_offset.Drop.BlvlDropPrfTailDrpThresh = 0x8;
+	tm_index_offset.Drop.BlvlDropPrfWREDDPRatio = 0x8;
+	for (i = 0; i < 3; i++)
+		tm_index_offset.Drop.BlvlREDCurve[i].Table = 0x8;
+
+	for (i = 0; i < 8; i++) {
+		tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[i] = 0x8;
+		tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[i] = 0x8;
+		tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[i] = 0x8;
+		tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[i] = 0x8;
+		tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[i] = 0x8;
+		tm_index_offset.Drop.ClvlREDCurve.CoS[i] = 0x8;
+	}
+
+
+	tm_index_offset.Drop.PortREDCurve = 0x8;
+	tm_index_offset.Drop.PortDropPrfWREDParams = 0x8;
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio = 0x8;
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh = 0x8;
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh = 0x8;
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio = 0x8;
+
+	for (i = 0; i < 8; i++) {
+		tm_index_offset.Drop.PortREDCurve_CoS[i] = 0x8;
+		tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[i] = 0x8;
+		tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[i] = 0x8;
+		tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[i] = 0x8;
+		tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[i]  = 0x8;
+		tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[i] = 0x8;
+	}
+	tm_index_offset.Sched.QueueTokenBucketTokenEnDiv = 0x8;
+	tm_index_offset.Sched.QueueTokenBucketBurstSize = 0x8;
+	tm_index_offset.Sched.AlvlTokenBucketTokenEnDiv = 0x8;
+	tm_index_offset.Sched.AlvlTokenBucketBurstSize = 0x8;
+	tm_index_offset.Sched.BlvlTokenBucketTokenEnDiv = 0x8;
+	tm_index_offset.Sched.BlvlTokenBucketBurstSize = 0x8;
+	tm_index_offset.Sched.ClvlTokenBucketTokenEnDiv = 0x8;
+	tm_index_offset.Sched.ClvlTokenBucketBurstSize = 0x8;
+
+	tm_index_offset.Sched.PortRangeMap = 0x8;
+	tm_index_offset.Sched.ClvltoPortAndBlvlRangeMap = 0x8;
+	tm_index_offset.Sched.BLvltoClvlAndAlvlRangeMap = 0x8;
+	tm_index_offset.Sched.ALvltoBlvlAndQueueRangeMap = 0x8;
+	tm_index_offset.Sched.QueueAMap = 0x8;
+
+	tm_index_offset.Sched.QueueEligPrioFunc = 0x8;
+	tm_index_offset.Sched.QueueEligPrioFuncPtr = 0x8;
+	tm_index_offset.Sched.QueueQuantum = 0x8;
+	tm_index_offset.Drop.QueueDropProfPtr = 0x8;
+	tm_index_offset.Drop.QueueAvgQueueLength = 0x8;
+
+	tm_index_offset.Sched.ALvltoBlvlAndQueueRangeMap = 0x8;
+	tm_index_offset.Sched.AlvlEligPrioFunc = 0x8;
+	tm_index_offset.Sched.AlvlEligPrioFuncPtr = 0x8;
+	tm_index_offset.Sched.AlvlQuantum = 0x8;
+	tm_index_offset.Sched.AlvlDWRRPrioEn = 0x8;
+	tm_index_offset.Drop.AlvlDropProfPtr = 0x8;
+	tm_index_offset.Drop.AlvlInstAndAvgQueueLength = 0x8;
+
+	tm_index_offset.Sched.BLvltoClvlAndAlvlRangeMap = 0x8;
+	tm_index_offset.Sched.BlvlEligPrioFunc = 0x8;
+	tm_index_offset.Sched.BlvlEligPrioFuncPtr = 0x8;
+	tm_index_offset.Sched.BlvlQuantum = 0x8;
+	tm_index_offset.Sched.BlvlDWRRPrioEn = 0x8;
+	tm_index_offset.Drop.BlvlDropProfPtr = 0x8;
+	tm_index_offset.Drop.BlvlInstAndAvgQueueLength = 0x8;
+
+	tm_index_offset.Sched.ClvltoPortAndBlvlRangeMap = 0x8;
+	tm_index_offset.Sched.ClvlEligPrioFunc = 0x8;
+	tm_index_offset.Sched.ClvlEligPrioFuncPtr = 0x8;
+	tm_index_offset.Sched.ClvlQuantum = 0x8;
+	tm_index_offset.Sched.ClvlDWRRPrioEn = 0x8;
+	for (i = 0; i < 8; i++)
+		tm_index_offset.Drop.ClvlDropProfPtr_CoS[i] = 0x8;
+	tm_index_offset.Drop.ClvlInstAndAvgQueueLength = 0x8;
+
+	tm_index_offset.Sched.PortEligPrioFunc = 0x8;
+	tm_index_offset.Sched.PortEligPrioFuncPtr = 0x8;
+
+	tm_index_offset.Sched.PortTokenBucketTokenEnDiv = 0x8;
+	tm_index_offset.Sched.PortTokenBucketBurstSize = 0x8;
+
+	tm_index_offset.Sched.PortQuantumsPriosLo = 0x8;
+	tm_index_offset.Sched.PortQuantumsPriosHi = 0x8;
+	tm_index_offset.Sched.PortDWRRPrioEn = 0x8;
+	tm_index_offset.Drop.PortInstAndAvgQueueLength = 0x8;
+
+	tm_index_offset.Sched.PortDefPrioHi = 0x8;
+	tm_index_offset.Sched.PortDefPrioLo = 0x8;
+
+	tm_index_offset.Sched.CLvlDef = 0x8;
+	tm_index_offset.Sched.BlvlDef = 0x8;
+	tm_index_offset.Sched.AlvlDef = 0x8;
+	tm_index_offset.Sched.QueueDef = 0x8;
+	tm_index_offset.Drop.QueueCoSConf = 0x8; /* index is entry not the q number */
+
+	tm_index_offset.Sched.ClvlShpBucketLvls = 0x8;
+	tm_index_offset.Sched.PortShpBucketLvls = 0x8;
+	tm_index_offset.Sched.BlvlShpBucketLvls = 0x8;
+	tm_index_offset.Sched.AlvlShpBucketLvls = 0x8;
+
+	tm_index_offset.Drop.AlvlDropProb = 0x8;
+	tm_index_offset.Drop.ClvlDropProb = 0x8;
+	tm_index_offset.Drop.BlvlDropProb = 0x8;
+
+#ifdef SMADAR
+	tm_index_offset.Drop.AlvlDropPrfWREDDPRatio = 0x40;
+	tm_index_offset.Drop.AlvlDropPrfWREDMinThresh = 0x40;
+	tm_index_offset.Drop.AlvlDropPrfWREDParams = 0x40;
+	tm_index_offset.Drop.AlvlDropPrfWREDScaleRatio = 0x40;
+	tm_index_offset.Drop.AlvlDropProb = 0x400;
+	tm_index_offset.Drop.AlvlDropProfPtr = 0x8; /* 32 * 0x8 = 256B */
+	tm_index_offset.Drop.AlvlInstAndAvgQueueLength = 0x400;
+	tm_index_offset.Drop.AlvlREDCurve.Color[0] = 0x800; /* Color[0] */
+	tm_index_offset.Drop.AlvlREDCurve.Color[1] = 0x800; /* Color[1] */
+	tm_index_offset.Drop.AlvlREDCurve.Color[2] =  0x800; /* Color[2] */
+	tm_index_offset.Drop.BlvlDropPrfTailDrpThresh = 0x00490140;
+	tm_index_offset.Drop.BlvlDropPrfWREDDPRatio = 0x00490100;
+	tm_index_offset.Drop.BlvlDropPrfWREDMinThresh = 0x004900C0;
+	tm_index_offset.Drop.BlvlDropPrfWREDParams = 0x00490040;
+	tm_index_offset.Drop.BlvlDropPrfWREDScaleRatio = 0x00490080;
+	tm_index_offset.Drop.BlvlDropProb = 0x0049B500;
+	tm_index_offset.Drop.BlvlDropProfPtr = 0x00490000;
+	tm_index_offset.Drop.BlvlInstAndAvgQueueLength = 0x0049B400;
+	tm_index_offset.Drop.BlvlREDCurve[0].Table = 0x00490400;
+	tm_index_offset.Drop.BlvlREDCurve[1].Table = 0x00490500;
+	tm_index_offset.Drop.BlvlREDCurve[2].Table = 0x00490600;
+	tm_index_offset.Drop.BlvlREDCurve[3].Table = 0x00490700;
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[0] = 0x00488A80; /* CoS[0] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[1] =  0x00488A90; /* CoS[1] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[2] = 0x00488AA0; /* CoS[2] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[3] = 0x00488AB0; /* CoS[3] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[4] = 0x00488AC0; /* CoS[4] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[5] = 0x00488AD0; /* CoS[5] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[6] = 0x00488AE0; /* CoS[6] */
+	tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[7] = 0x00488AF0; /* CoS[7] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[0] = 0x00488A00; /* CoS[0] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[1] = 0x00488A10; /* CoS[1] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[2] = 0x00488A20; /* CoS[2] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[3] =  0x00488A30; /* CoS[3] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[4] = 0x00488A40; /* CoS[4] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[5] = 0x00488A50; /* CoS[5] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[6] = 0x00488A60; /* CoS[6] */
+	tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[7] = 0x00488A70; /* CoS[7] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[0] = 0x00488980; /* CoS[0] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[1] = 0x00488990; /* CoS[1] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[2] = 0x004889A0; /* CoS[2] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[3] = 0x004889B0; /* CoS[3] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[4] = 0x004889C0; /* CoS[4] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[5] = 0x004889D0; /* CoS[5] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[6] = 0x004889E0; /* CoS[6] */
+	tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[7] = 0x004889F0; /* CoS[7] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[0] =  0x00488880; /* CoS[0] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[1] =  0x00488890; /* CoS[1] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[2] =  0x004888A0; /* CoS[2] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[3] =  0x004888B0; /* CoS[3] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[4] =  0x004888C0; /* CoS[4] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[5] =  0x004888D0; /* CoS[5] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[6] =  0x004888E0; /* CoS[6] */
+	tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[7] =  0x004888F0; /* CoS[7] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[0] = 0x00488900; /* CoS[0] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[1] = 0x00488910; /* CoS[1] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[2] = 0x00488920; /* CoS[2] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[3] = 0x00488930; /* CoS[3] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[4] = 0x00488940; /* CoS[4] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[5] = 0x00488950; /* CoS[5] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[6] = 0x00488960; /* CoS[6] */
+	tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[7] = 0x00488970; /* CoS[7] */
+	tm_index_offset.Drop.ClvlDropProb = 0x0049B000;
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[0] = 0x00488800; /* ClvlDropProfPtr_CoS[0] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[1] = 0x00488810; /* ClvlDropProfPtr_CoS[1] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[2] = 0x00488820; /* ClvlDropProfPtr_CoS[2] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[3] = 0x00488830; /* ClvlDropProfPtr_CoS[3] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[4] = 0x00488840; /* ClvlDropProfPtr_CoS[4] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[5] = 0x00488850; /* ClvlDropProfPtr_CoS[5] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[6] = 0x00488860; /* ClvlDropProfPtr_CoS[6] */
+	tm_index_offset.Drop.ClvlDropProfPtr_CoS[7] = 0x00488870; /* ClvlDropProfPtr_CoS[7] */
+	tm_index_offset.Drop.ClvlInstAndAvgQueueLength = 0x0049AC00;
+	tm_index_offset.Drop.ClvlREDCurve.CoS[0] = 0x0048A000; /* CoS[0] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[1] = 0x0048A400; /* CoS[1] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[2] = 0x0048A800; /* CoS[2] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[3] = 0x0048AC00; /* CoS[3] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[4] = 0x0048B000; /* CoS[4] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[5] = 0x0048B400; /* CoS[5] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[6] = 0x0048B800; /* CoS[6] */
+	tm_index_offset.Drop.ClvlREDCurve.CoS[7] = 0x0048BC00; /* CoS[7] */
+	tm_index_offset.Drop.DPSource = 0x00480048;
+	tm_index_offset.Drop.ErrCnt = 0x00480010;
+	tm_index_offset.Drop.ErrStus = 0x00480000;
+	tm_index_offset.Drop.ExcCnt = 0x00480018;
+	tm_index_offset.Drop.ExcMask = 0x00480020;
+	tm_index_offset.Drop.FirstExc = 0x00480008;
+	tm_index_offset.Drop.ForceErr = 0x00480030;
+	tm_index_offset.Drop.Id = 0x00480028;
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh = 0x00488200;
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[0] = 0x00485000; /* PortDropPrfTailDrpThresh_CoSRes[0] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[1] = 0x00485080; /* PortDropPrfTailDrpThresh_CoSRes[1] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[2] = 0x00485100; /* PortDropPrfTailDrpThresh_CoSRes[2] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[3] = 0x00485180; /* PortDropPrfTailDrpThresh_CoSRes[3] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[4] = 0x00485200; /* PortDropPrfTailDrpThresh_CoSRes[4] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[5] = 0x00485280; /* PortDropPrfTailDrpThresh_CoSRes[5] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[6] = 0x00485300; /* PortDropPrfTailDrpThresh_CoSRes[6] */
+	tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[7] = 0x00485380; /* PortDropPrfTailDrpThresh_CoSRes[7] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio = 0x00488180;
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[0] = 0x00484C00; /* PortDropPrfWREDDPRatio_CoSRes[0] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[1] = 0x00484C80; /* PortDropPrfWREDDPRatio_CoSRes[1] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[2] = 0x00484D00; /* PortDropPrfWREDDPRatio_CoSRes[2] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[3] = 0x00484D80; /* PortDropPrfWREDDPRatio_CoSRes[3] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[4] = 0x00484E00; /* PortDropPrfWREDDPRatio_CoSRes[4] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[5] = 0x00484E80; /* PortDropPrfWREDDPRatio_CoSRes[5] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[6] = 0x00484F00; /* PortDropPrfWREDDPRatio_CoSRes[6] */
+	tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[7] = 0x00484F80; /* PortDropPrfWREDDPRatio_CoSRes[7] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh = 0x00488100;
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[0] = 0x00484800; /* PortDropPrfWREDMinThresh_CoSRes[0] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[1] = 0x00484880; /* PortDropPrfWREDMinThresh_CoSRes[1] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[2] = 0x00484900; /* PortDropPrfWREDMinThresh_CoSRes[2] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[3] = 0x00484980; /* PortDropPrfWREDMinThresh_CoSRes[3] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[4] = 0x00484A00; /* PortDropPrfWREDMinThresh_CoSRes[4] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[5] = 0x00484A80; /* PortDropPrfWREDMinThresh_CoSRes[5] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[6] = 0x00484B00; /* PortDropPrfWREDMinThresh_CoSRes[6] */
+	tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[7] = 0x00484B80; /* PortDropPrfWREDMinThresh_CoSRes[7] */
+	tm_index_offset.Drop.PortDropPrfWREDParams = 0x00488000;
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[0] = 0x00484000; /* PortDropPrfWREDParams_CoSRes[0] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[1] = 0x00484080; /* PortDropPrfWREDParams_CoSRes[1] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[2] = 0x00484100; /* PortDropPrfWREDParams_CoSRes[2] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[3] = 0x00484180; /* PortDropPrfWREDParams_CoSRes[3] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[4] = 0x00484200; /* PortDropPrfWREDParams_CoSRes[4] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[5] = 0x00484280; /* PortDropPrfWREDParams_CoSRes[5] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[6] = 0x00484300; /* PortDropPrfWREDParams_CoSRes[6] */
+	tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[7] = 0x00484380; /* PortDropPrfWREDParams_CoSRes[7] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio = 0x00488080;
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[0] = 0x00484400; /* PortDropPrfWREDScaleRatio_CoSRes[0] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[1] = 0x00484480; /* PortDropPrfWREDScaleRatio_CoSRes[1] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[2] = 0x00484500; /* PortDropPrfWREDScaleRatio_CoSRes[2] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[3] = 0x00484580; /* PortDropPrfWREDScaleRatio_CoSRes[3] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[4] = 0x00484600; /* PortDropPrfWREDScaleRatio_CoSRes[4] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[5] = 0x00484600; /* PortDropPrfWREDScaleRatio_CoSRes[5] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[6] = 0x00484700; /* PortDropPrfWREDScaleRatio_CoSRes[6] */
+	tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[7] = 0x00484780; /* PortDropPrfWREDScaleRatio_CoSRes[7] */
+	tm_index_offset.Drop.PortDropProb = 0x0049A080;
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[0] = 0x0049A800; /* CoS[0] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[1] = 0x0049A880; /* CoS[1] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[2] = 0x0049A900; /* CoS[2] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[3] = 0x0049A980; /* CoS[3] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[4] = 0x0049AA00; /* CoS[4] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[5] = 0x0049AA80; /* CoS[5] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[6] = 0x0049AB00; /* CoS[6] */
+	tm_index_offset.Drop.PortDropProbPerCoS_CoS[7] = 0x0049AB80; /* CoS[7] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLength = 0x0049A000;
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[0] = 0x0049A400; /* CoS[0] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[1] = 0x0049A480; /* CoS[1] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[2] = 0x0049A500; /* CoS[2] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[3] = 0x0049A580; /* CoS[3] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[4] = 0x0049A600; /* CoS[4] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[5] = 0x0049A680; /* CoS[5] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[6] = 0x0049A700; /* CoS[6] */
+	tm_index_offset.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[7] = 0x0049A780; /* CoS[7] */
+	tm_index_offset.Drop.PortREDCurve_CoS[0] = 0x00486000; /* PortREDCurve_CoS[0] */
+	tm_index_offset.Drop.PortREDCurve_CoS[1] = 0x00486400; /* PortREDCurve_CoS[1] */
+	tm_index_offset.Drop.PortREDCurve_CoS[2] = 0x00486800; /* PortREDCurve_CoS[2] */
+	tm_index_offset.Drop.PortREDCurve_CoS[3] = 0x00486C00; /* PortREDCurve_CoS[3] */
+	tm_index_offset.Drop.PortREDCurve_CoS[4] = 0x00487000; /* PortREDCurve_CoS[4] */
+	tm_index_offset.Drop.PortREDCurve_CoS[5] = 0x00487400; /* PortREDCurve_CoS[5] */
+	tm_index_offset.Drop.PortREDCurve_CoS[6] = 0x00487800; /* PortREDCurve_CoS[6] */
+	tm_index_offset.Drop.PortREDCurve_CoS[7] = 0x00487C00; /* PortREDCurve_CoS[7] */
+	tm_index_offset.Drop.QueueAvgQueueLength = 0x0049C000;
+	tm_index_offset.Drop.QueueCoSConf = 0x00498000;
+	tm_index_offset.Drop.QueueDropPrfTailDrpThresh = 0x00494600;
+	tm_index_offset.Drop.QueueDropPrfWREDDPRatio = 0x00494580;
+	tm_index_offset.Drop.QueueDropPrfWREDMinThresh = 0x00494500;
+	tm_index_offset.Drop.QueueDropPrfWREDParams = 0x00494400;
+	tm_index_offset.Drop.QueueDropPrfWREDScaleRatio = 0x00494480;
+	tm_index_offset.Drop.QueueDropProb = 0x0049D000;
+	tm_index_offset.Drop.QueueDropProfPtr = 0x00494000;
+	tm_index_offset.Drop.QueueREDCurve.Color[0] = 0x00496000; /* Color[0] */
+	tm_index_offset.Drop.QueueREDCurve.Color[1] = 0x00496800; /* Color[1] */
+	tm_index_offset.Drop.QueueREDCurve.Color[2] = 0x00497000; /* Color[2] */
+	tm_index_offset.Drop.RespLocalDPSel = 0x00480050;
+	tm_index_offset.Drop.WREDDropProbMode = 0x00480038;
+	tm_index_offset.Drop.WREDMaxProbModePerColor = 0x00480040;
+
+
+	tm_index_offset.Sched.ALevelShaperBucketNeg = 0x0045AC00;
+	tm_index_offset.Sched.ALvltoBlvlAndQueueRangeMap = 0x07690000;
+	tm_index_offset.Sched.AlvlDWRRPrioEn = 0x07670000;
+	tm_index_offset.Sched.AlvlDef = 0x07780000;
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[0] = 0x07630000; /* Entry[0] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[1] = 0x07630001; /* Entry[1] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[2] = 0x07630002; /* Entry[2] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[3] = 0x07630003; /* Entry[3] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[4] = 0x07630004; /* Entry[4] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[5] = 0x07630005; /* Entry[5] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[6] = 0x07630006; /* Entry[6] */
+	tm_index_offset.Sched.AlvlEligPrioFunc.Entry[7] = 0x07630007; /* Entry[7] */
+	tm_index_offset.Sched.AlvlEligPrioFuncPtr = 0x07640000;
+	tm_index_offset.Sched.AlvlPerConf = 0x06D90000;
+	tm_index_offset.Sched.AlvlPerRateShpPrms = 0x06DA0000;
+	tm_index_offset.Sched.AlvlQuantum = 0x07680000;
+	tm_index_offset.Sched.AlvlShpBucketLvls = 0x07770000;
+	tm_index_offset.Sched.AlvlTokenBucketBurstSize = 0x07660000;
+	tm_index_offset.Sched.AlvlTokenBucketTokenEnDiv = 0x07650000;
+	tm_index_offset.Sched.BLevelShaperBucketNeg = 0x077D0000;
+	tm_index_offset.Sched.BLvltoClvlAndAlvlRangeMap = 0x07620000;
+	tm_index_offset.Sched.BlvlDWRRPrioEn = 0x07600000;
+	tm_index_offset.Sched.BlvlDef = 0x07760000;
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[0] = 0x075C0000; /* Entry[0] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[1] = 0x075C0001; /* Entry[1] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[2] = 0x075C0002; /* Entry[2] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[3] = 0x075C0003; /* Entry[3] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[4] = 0x075C0004; /* Entry[4] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[5] = 0x075C0005; /* Entry[5] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[6] = 0x075C0006; /* Entry[6] */
+	tm_index_offset.Sched.BlvlEligPrioFunc.Entry[7] = 0x075C0007; /* Entry[7] */
+
+	tm_index_offset.Sched.BlvlEligPrioFuncPtr = 0x075D0000;
+	tm_index_offset.Sched.BlvlPerConf = 0x06D70000;
+	tm_index_offset.Sched.BlvlPerRateShpPrms = 0x06D80000;
+	tm_index_offset.Sched.BlvlQuantum = 0x07610000;
+	tm_index_offset.Sched.BlvlShpBucketLvls = 0x07750000;
+	tm_index_offset.Sched.BlvlTokenBucketBurstSize = 0x075F0000;
+	tm_index_offset.Sched.BlvlTokenBucketTokenEnDiv = 0x075E0000;
+	tm_index_offset.Sched.CLevelShaperBucketNeg = 0x077C0000;
+	tm_index_offset.Sched.CLvlDef = 0x07740000;
+	tm_index_offset.Sched.ClvlDWRRPrioEn = 0x07590000;
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[0] = 0x07550000; /* Entry[0] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[1] = 0x07550001; /* Entry[1] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[2] = 0x07550002; /* Entry[2] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[3] = 0x07550003; /* Entry[3] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[4] = 0x07550004; /* Entry[4] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[5] = 0x07550005; /* Entry[5] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[6] = 0x07550006; /* Entry[6] */
+	tm_index_offset.Sched.ClvlEligPrioFunc.Entry[7] = 0x07550007; /* Entry[7] */
+	tm_index_offset.Sched.ClvlEligPrioFuncPtr = 0x07560000;
+	tm_index_offset.Sched.ClvlPerConf = 0x06D50000;
+	tm_index_offset.Sched.ClvlPerRateShpPrms = 0x06D60000;
+	tm_index_offset.Sched.ClvlQuantum = 0x075A0000;
+	tm_index_offset.Sched.ClvlShpBucketLvls = 0x07730000;
+	tm_index_offset.Sched.ClvlTokenBucketBurstSize = 0x07580000;
+	tm_index_offset.Sched.ClvlTokenBucketTokenEnDiv = 0x07570000;
+	tm_index_offset.Sched.ClvltoPortAndBlvlRangeMap = 0x075B0000;
+	tm_index_offset.Sched.PortDWRRBytesPerBurstsLimit = 0x06D40000;
+	tm_index_offset.Sched.PortDWRRPrioEn = 0x07510000;
+	tm_index_offset.Sched.PortDefPrioHi = 0x07720000;
+	tm_index_offset.Sched.PortDefPrioLo = 0x07710000;
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[0] = 0x074D0000; /* Entry[0] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[1] = 0x074D0001; /* Entry[1] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[2] = 0x074D0002; /* Entry[2] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[3] = 0x074D0003; /* Entry[3] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[4] = 0x074D0004; /* Entry[4] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[5] = 0x074D0005; /* Entry[5] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[6] = 0x074D0006; /* Entry[6] */
+	tm_index_offset.Sched.PortEligPrioFunc.Entry[7] = 0x074D0007; /* Entry[7] */
+	tm_index_offset.Sched.PortEligPrioFuncPtr = 0x074E0000;
+	tm_index_offset.Sched.PortExtBPEn = 0x06D30000;
+	tm_index_offset.Sched.PortPerConf = 0x06D10000;
+	tm_index_offset.Sched.PortPerRateShpPrms = 0x06D20000;
+	tm_index_offset.Sched.PortQuantumsPriosHi = 0x07530000;
+	tm_index_offset.Sched.PortQuantumsPriosLo = 0x07520000;
+	tm_index_offset.Sched.PortRangeMap = 0x07540000;
+	tm_index_offset.Sched.PortShaperBucketNeg = 0x077B0000;
+	tm_index_offset.Sched.PortShpBucketLvls = 0x07700000;
+	tm_index_offset.Sched.PortTokenBucketBurstSize = 0x07500000;
+	tm_index_offset.Sched.PortTokenBucketTokenEnDiv = 0x074F0000;
+	tm_index_offset.Sched.QueueAMap = 0x076F0000;
+	tm_index_offset.Sched.QueueDef = 0x077A0000;
+	tm_index_offset.Sched.QueueEligPrioFunc = 0x076A0000;
+	tm_index_offset.Sched.QueueEligPrioFuncPtr = 0x076B0000;
+	tm_index_offset.Sched.QueuePerConf = 0x06DB0000;
+	tm_index_offset.Sched.QueuePerRateShpPrms = 0x06DC0000;
+	tm_index_offset.Sched.QueueQuantum = 0x076E0000;
+	tm_index_offset.Sched.QueueShaperBucketNeg = 0x077F0000;
+	tm_index_offset.Sched.QueueShpBucketLvls = 0x07790000;
+	tm_index_offset.Sched.QueueTokenBucketBurstSize = 0x076D0000;
+	tm_index_offset.Sched.QueueTokenBucketTokenEnDiv = 0x076C0000;
+	tm_index_offset.Sched.ScrubSlotAlloc = 0x06CD0000;
+	tm_index_offset.Sched.TreeDWRRPrioEn = 0x06D00000;
+	tm_index_offset.Sched.TreeDeqEn = 0x06CF0000;
+
+#endif
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.h
new file mode 100644
index 0000000..7dbe789
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_alias.h
@@ -0,0 +1,294 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_ALIAS_H
+#define TM_ALIAS_H
+
+#include "common/mv_sw_if.h"
+
+/** Register alias declaration for the TM unit.
+ */
+extern struct tm_alias {
+
+	void __iomem *silicon_base;
+	struct {
+		int AlvlDropPrfTailDrpThresh;
+		int AlvlDropPrfWREDDPRatio;
+		int AlvlDropPrfWREDMinThresh;
+		int AlvlDropPrfWREDParams;
+		int AlvlDropPrfWREDScaleRatio;
+		int AlvlDropProb;
+		int AlvlDropProfPtr;
+		int AlvlInstAndAvgQueueLength;
+		struct {
+			int Color[3];
+		} AlvlREDCurve;
+		int BlvlDropPrfTailDrpThresh;
+		int BlvlDropPrfWREDDPRatio;
+		int BlvlDropPrfWREDMinThresh;
+		int BlvlDropPrfWREDParams;
+		int BlvlDropPrfWREDScaleRatio;
+		int BlvlDropProb;
+		int BlvlDropProfPtr;
+		int BlvlInstAndAvgQueueLength;
+		struct {
+			int Table;
+		} BlvlREDCurve[4];
+		struct {
+			int CoS[8];
+		} ClvlDropPrfTailDrpThresh;
+		struct {
+			int CoS[8];
+		} ClvlDropPrfWREDDPRatio;
+		struct {
+			int CoS[8];
+		} ClvlDropPrfWREDMinThresh;
+		struct {
+			int CoS[8];
+		} ClvlDropPrfWREDParams;
+		struct {
+			int CoS[8];
+		} ClvlDropPrfWREDScaleRatio;
+		int ClvlDropProb;
+		int ClvlDropProfPtr_CoS[8];
+		int ClvlInstAndAvgQueueLength;
+		struct {
+			int CoS[8];
+		} ClvlREDCurve;
+		int DPSource;
+		int Drp_Decision_hierarchy_to_Query_debug;/*NEW*/
+		int Drp_Decision_to_Query_debug;/*NEW*/
+		int EccConfig;/*NEW*/
+		int EccMemParams[43];/*NEW*/
+		int ErrCnt;
+		int ErrStus;
+		int ExcCnt;
+		int ExcMask;
+		int FirstExc;
+		int ForceErr;
+		int Id;
+		int PortDropPrfTailDrpThresh;
+		int PortDropPrfTailDrpThresh_CoSRes[8];
+		int PortDropPrfWREDDPRatio;
+		int PortDropPrfWREDDPRatio_CoSRes[8];
+		int PortDropPrfWREDMinThresh;
+		int PortDropPrfWREDMinThresh_CoSRes[8];
+		int PortDropPrfWREDParams;
+		int PortDropPrfWREDParams_CoSRes[8];
+		int PortDropPrfWREDScaleRatio;
+		int PortDropPrfWREDScaleRatio_CoSRes[8];
+		int PortDropProb;
+		int PortDropProbPerCoS_CoS[8];
+		int PortInstAndAvgQueueLength;
+		struct {
+			int CoS[8];
+		} PortInstAndAvgQueueLengthPerCoS;
+		int PortREDCurve;
+		int PortREDCurve_CoS[8];
+		int QueueAvgQueueLength;
+		int QueueCoSConf;
+		int QueueDropPrfTailDrpThresh;
+		int QueueDropPrfWREDDPRatio;
+		int QueueDropPrfWREDMinThresh;
+		int QueueDropPrfWREDParams;
+		int QueueDropPrfWREDScaleRatio;
+		int QueueDropProb;
+		int QueueDropProfPtr;
+		struct {
+			int Color[3];
+		} QueueREDCurve;
+		int RespLocalDPSel;
+		int WREDDropProbMode;
+		int WREDMaxProbModePerColor;
+	} Drop;
+	struct {
+		int ALevelShaperBucketNeg;
+		int ALvltoBlvlAndQueueRangeMap;
+		int AlvlBankEccErrStatus;/*NEW*/
+		int AlvlDWRRPrioEn;
+		int AlvlDef;
+		int AlvlEccErrStatus;/*NEW*/
+		int AlvlEligPrioFunc;
+		int AlvlEligPrioFuncPtr;
+		int AlvlL0ClusterStateHi;/*NEW*/
+		int AlvlL0ClusterStateLo;/*NEW*/
+		int AlvlL1ClusterStateHi;/*NEW*/
+		int AlvlL1ClusterStateLo;/*NEW*/
+		int AlvlL2ClusterStateHi;/*NEW*/
+		int AlvlL2ClusterStateLo;/*NEW*/
+		int AlvlMyQ;/*NEW*/
+		int AlvlMyQEccErrStatus;/*NEW*/
+		int AlvlNodeState;/*NEW*/
+		int AlvlPerConf;
+		int AlvlPerRateShpPrms;
+		int AlvlPerRateShpPrmsInt;/*NEW*/
+		int AlvlPerStatus;/*NEW*/
+		int AlvlQuantum;
+		int AlvlRRDWRRStatus01;/*NEW*/
+		int AlvlRRDWRRStatus23;/*NEW*/
+		int AlvlRRDWRRStatus45;/*NEW*/
+		int AlvlRRDWRRStatus67;/*NEW*/
+		int AlvlShpBucketLvls;
+		int AlvlTokenBucketBurstSize;
+		int AlvlTokenBucketTokenEnDiv;
+		int AlvlWFS;/*NEW*/
+		int BLevelShaperBucketNeg;
+		int BLvltoClvlAndAlvlRangeMap;
+		int BlvlBankEccErrStatus;/*NEW*/
+		int BlvlDWRRPrioEn;
+		int BlvlDef;
+		int BlvlEccErrStatus;/*NEW*/
+		int BlvlEligPrioFunc;
+		int BlvlEligPrioFuncPtr;
+		int BlvlL0ClusterStateHi;/*NEW*/
+		int BlvlL0ClusterStateLo;/*NEW*/
+		int BlvlL1ClusterStateHi;/*NEW*/
+		int BlvlL1ClusterStateLo;/*NEW*/
+		int BlvlMyQ;/*NEW*/
+		int BlvlMyQEccErrStatus;/*NEW*/
+		int BlvlNodeState;/*NEW*/
+		int BlvlPerConf;
+		int BlvlPerRateShpPrms;
+		int BlvlPerRateShpPrmsInt;/*NEW*/
+		int BlvlPerStatus;/*NEW*/
+		int BlvlQuantum;
+		int BlvlRRDWRRStatus01;/*NEW*/
+		int BlvlRRDWRRStatus23;/*NEW*/
+		int BlvlRRDWRRStatus45;/*NEW*/
+		int BlvlRRDWRRStatus67;/*NEW*/
+		int BlvlShpBucketLvls;
+		int BlvlTokenBucketBurstSize;
+		int BlvlTokenBucketTokenEnDiv;
+		int BlvlWFS;/*NEW*/
+		int CLevelShaperBucketNeg;
+		int CLvlDef;
+		int ClvlBPFromSTF;/*NEW*/
+		int ClvlBankEccErrStatus;/*NEW*/
+		int ClvlDWRRPrioEn;
+		int ClvlEccErrStatus;/*NEW*/
+		int ClvlEligPrioFunc;
+		int ClvlEligPrioFuncPtr;
+		int ClvlL0ClusterStateHi;/*NEW*/
+		int ClvlL0ClusterStateLo;/*NEW*/
+		int ClvlMyQ;/*NEW*/
+		int ClvlMyQEccErrStatus;/*NEW*/
+		int ClvlNodeState;/*NEW*/
+		int ClvlPerConf;
+		int ClvlPerRateShpPrms;
+		int ClvlPerRateShpPrmsInt;/*NEW*/
+		int ClvlPerStatus;/*NEW*/
+		int ClvlQuantum;
+		int ClvlRRDWRRStatus01;/*NEW*/
+		int ClvlRRDWRRStatus23;/*NEW*/
+		int ClvlRRDWRRStatus45;/*NEW*/
+		int ClvlRRDWRRStatus67;/*NEW*/
+		int ClvlShpBucketLvls;
+		int ClvlTokenBucketBurstSize;
+		int ClvlTokenBucketTokenEnDiv;
+		int ClvlWFS;/*NEW*/
+		int ClvltoPortAndBlvlRangeMap;
+		int EccConfig;/*NEW*/
+		int EccMemParams[46];/*NEW*/
+		int ErrCnt;
+		int ErrStus;
+		int ExcCnt;
+		int ExcMask;
+		int FirstExc;
+		int ForceErr;
+		int GeneralEccErrStatus;/*NEW*/
+		int Id;
+		int PortBPFromQMgr;/*NEW*/
+		int PortBPFromSTF;/*NEW*/
+		int PortBankEccErrStatus;/*NEW*/
+		int PortDWRRBytesPerBurstsLimit;
+		int PortDWRRPrioEn;
+		int PortDefPrioHi;
+		int PortDefPrioLo;
+		int PortEccErrStatus;/*NEW*/
+		int PortEligPrioFunc;
+		int PortEligPrioFuncPtr;
+		int PortExtBPEn;
+		int PortMyQ;/*NEW*/
+		int PortNodeState;/*NEW*/
+		int PortPerConf;
+		int PortPerRateShpPrms;
+		int PortPerRateShpPrmsInt;/*NEW*/
+		int PortPerStatus;/*NEW*/
+		int PortQuantumsPriosHi;
+		int PortQuantumsPriosLo;
+		int PortRRDWRRStatus01;/*NEW*/
+		int PortRRDWRRStatus23;/*NEW*/
+		int PortRRDWRRStatus45;/*NEW*/
+		int PortRRDWRRStatus67;/*NEW*/
+		int PortRangeMap;
+		int PortShaperBucketNeg;
+		int PortShpBucketLvls;
+		int PortTokenBucketBurstSize;
+		int PortTokenBucketTokenEnDiv;
+		int PortWFS;/*NEW*/
+		int QueueAMap;
+		int QueueBank0EccErrStatus;/*NEW*/
+		int QueueBank1EccErrStatus;/*NEW*/
+		int QueueBank2EccErrStatus;/*NEW*/
+		int QueueBank3EccErrStatus;/*NEW*/
+		int QueueDef;
+		int QueueEccErrStatus;/*NEW*/
+		int QueueEligPrioFunc;
+		int QueueEligPrioFuncPtr;
+		int QueueL0ClusterStateHi;/*NEW*/
+		int QueueL0ClusterStateLo;/*NEW*/
+		int QueueL1ClusterStateHi;/*NEW*/
+		int QueueL1ClusterStateLo;/*NEW*/
+		int QueueL2ClusterStateHi;/*NEW*/
+		int QueueL2ClusterStateLo;/*NEW*/
+		int QueueNodeState;/*NEW*/
+		int QueuePerConf;
+		int QueuePerRateShpPrms;
+		int QueuePerRateShpPrmsInt;/*NEW*/
+		int QueuePerStatus;/*NEW*/
+		int QueueQuantum;
+		int QueueShaperBucketNeg;
+		int QueueShpBucketLvls;
+		int QueueTokenBucketBurstSize;
+		int QueueTokenBucketTokenEnDiv;
+		int QueueWFS;/*NEW*/
+		int ScrubDisable;/*NEW*/
+		int ScrubSlotAlloc;
+		int TreeDWRRPrioEn;
+		int TreeDeqEn;
+		int TreeRRDWRRStatus;/*NEW*/
+	} Sched;
+} TM;
+
+extern struct tm_alias tm_index_offset;
+
+
+void init_tm_alias_struct(void __iomem *base);
+void init_tm_init_offset_struct(void);
+
+#endif /* TM_ALIAS_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_get_gen_param_implementation.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_get_gen_param_implementation.c
new file mode 100644
index 0000000..4568a7e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_get_gen_param_implementation.c
@@ -0,0 +1,51 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_get_gen_param_interface.h"
+#include "tm_set_local_db_defaults.h"
+#include "tm_errcodes.h"
+#include "set_hw_registers.h"
+#include "tm_hw_configuration_interface.h"
+
+
+int tm_get_gen_params(tm_handle hndl)
+{
+	int rc = 0;
+	DECLARE_TM_CTL_PTR(ctl, hndl)
+	CHECK_TM_CTL_PTR(ctl)
+
+	/* get other general parameters */
+	ctl->min_pkg_size = 0x40; /* in Chunks (64 bytes), reset value: 0x20 (2kb) */
+	ctl->mtu = 2000;          /* bytes, Maximal Transmission Unit */
+#ifdef MV_QMTM_NSS_A0
+	ctl->port_ch_emit
+#endif
+	ctl->min_quantum = (ctl->mtu + ctl->min_pkg_size)/TM_NODE_QUANTUM_UNIT;
+
+	return rc;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_hw_conf.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_hw_conf.c
new file mode 100644
index 0000000..05a2db6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_hw_conf.c
@@ -0,0 +1,152 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm/core/tm_hw_configuration_interface.h"
+
+/* below all NSS harware definitions */
+
+/* Max number of nodes supported by HW */
+/** Max number of queues supported by HW */
+#define NSS_TM_MAX_QUEUES   512 /* SN 128*1024*/
+/** Max number of A-nodes supported by HW */
+#define NSS_TM_MAX_A_NODES  128 /* SN 32*1024 */
+/** Max number of B-nodes supported by HW */
+#define NSS_TM_MAX_B_NODES  32 /* SN 8*1024 */
+/** Max number of C-nodes supported by HW */
+#define NSS_TM_MAX_C_NODES  16 /* SN 1024 */
+/** Max number of Ports supported by HW */
+#define NSS_TM_MAX_PORTS    16 /* SN 192 */
+
+
+#define NSS_QUEUE_MIN_PERIODIC_INTERVAL			512
+#define NSS_A_LEVEL__MIN_PERIODIC_INTERVAL		512
+#define NSS_B_LEVEL__MIN_PERIODIC_INTERVAL		1024
+#define NSS_C_LEVEL__MIN_PERIODIC_INTERVAL		1024
+#define NSS_PORT__MIN_PERIODIC_INTERVAL			48
+
+static	unsigned int	__isInitialized = 1;
+
+static	unsigned int	__totalPortCount;
+static	unsigned int	__totalCnodesCount;
+static	unsigned int	__totalBnodesCount;
+static	unsigned int	__totalAnodesCount;
+static	unsigned int	__totalQueuesCount;
+
+static	unsigned int	__queueMinPeriodicInterval;
+static	unsigned int	__a_LevelMinPeriodicInterval;
+static	unsigned int	__b_LevelMinPeriodicInterval;
+static	unsigned int	__c_LevelMinPeriodicInterval;
+static	unsigned int	__portMinPeriodicInterval;
+
+
+unsigned int init_tm_hardware_configuration(const char *cProductName)
+{
+/* here all parameters should be readed from database or hardware ...
+ (in case of various h/w configuration)
+ if failed - error > 0 is returned */
+
+	/* currently it is assigned from hardcoded definitions. */
+	__totalPortCount = NSS_TM_MAX_PORTS;
+	__totalCnodesCount = NSS_TM_MAX_C_NODES;
+	__totalBnodesCount = NSS_TM_MAX_B_NODES;
+	__totalAnodesCount = NSS_TM_MAX_A_NODES;
+	__totalQueuesCount = NSS_TM_MAX_QUEUES;
+
+	__queueMinPeriodicInterval = NSS_QUEUE_MIN_PERIODIC_INTERVAL;
+	__a_LevelMinPeriodicInterval = NSS_A_LEVEL__MIN_PERIODIC_INTERVAL;
+	__b_LevelMinPeriodicInterval = NSS_B_LEVEL__MIN_PERIODIC_INTERVAL;
+	__c_LevelMinPeriodicInterval = NSS_C_LEVEL__MIN_PERIODIC_INTERVAL;
+	__portMinPeriodicInterval = NSS_PORT__MIN_PERIODIC_INTERVAL;
+
+
+	/* successful initialization */
+	__isInitialized = 1;
+	return 0;
+}
+
+
+unsigned int	is_tm_initialized()
+{
+	return __isInitialized;
+}
+
+unsigned int	get_tm_port_count()
+{
+	return __totalPortCount;
+}
+unsigned int	get_tm_a_nodes_count()
+{
+	return __totalAnodesCount;
+}
+unsigned int	get_tm_b_nodes_count()
+{
+	return __totalBnodesCount;
+}
+unsigned int	get_tm_c_nodes_count()
+{
+	return __totalCnodesCount;
+}
+unsigned int	get_tm_queues_count()
+{
+	return __totalQueuesCount;
+}
+
+
+unsigned int	get_queue_min_periodic_interval()
+{
+	return __queueMinPeriodicInterval;
+}
+unsigned int	get_a_level_min_periodic_interval()
+{
+	return __a_LevelMinPeriodicInterval;
+}
+unsigned int	get_b_level_min_periodic_interval()
+{
+	return __b_LevelMinPeriodicInterval;
+}
+unsigned int	get_c_level_min_periodic_interval()
+{
+	return __c_LevelMinPeriodicInterval;
+}
+unsigned int	get_port_min_periodic_interval()
+{
+	return __portMinPeriodicInterval;
+}
+
+/** Minimum TM Frequency (in Hz) */
+#define TM_MIN_FREQUENCY 250000000
+/** Max TM Frequency (in Hz) */
+#define TM_MAX_FREQUENCY 250000000
+
+unsigned int	get_TM_min_frequency() { return TM_MIN_FREQUENCY; }
+unsigned int	get_TM_max_frequency() { return TM_MAX_FREQUENCY; }
+
+#define PROFILE_TD_THRESHOLD	0x7FFFF /* 19 bits */
+
+
+unsigned int	get_drop_threshold_definition() { return PROFILE_TD_THRESHOLD; }
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_locking_imp.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_locking_imp.c
new file mode 100644
index 0000000..e7ddc2d
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_locking_imp.c
@@ -0,0 +1,91 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_locking_interface.h"
+#include "tm_alias.h"
+
+
+int	tm_create_locking_staff(void * environment_handle)
+{
+	return 0;
+}
+
+
+int	tm_destroy_locking_staff(void * environment_handle)
+{
+
+	return 0;
+}
+
+
+/**
+ */
+int tm_glob_lock(void * environment_handle)
+{
+	return 0;
+}
+
+
+/**
+ */
+int tm_glob_unlock(void * environment_handle)
+{
+	return 0;
+}
+
+
+/**
+ */
+int tm_nodes_lock(void * environment_handle)
+{
+	return 0;
+}
+
+
+/**
+ */
+int tm_nodes_unlock(void * environment_handle)
+{
+	return 0;
+}
+
+
+/**
+ */
+int tm_sched_lock(void * environment_handle)
+{
+	return 0;
+}
+
+
+/**
+ */
+int tm_sched_unlock(void * environment_handle)
+{
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_os_if.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_os_if.c
new file mode 100644
index 0000000..15e4741
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_os_if.c
@@ -0,0 +1,68 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "common/mv_sw_if.h"
+#include "tm/core/tm_os_interface.h"
+
+/* memory */
+void *tm_malloc(unsigned int size)
+{
+	return kmalloc(size, GFP_KERNEL);
+}
+
+/**
+ */
+void tm_free(void *ptr)
+{
+	kfree(ptr);
+}
+
+/**
+ */
+void *tm_memset(void *s, int c, unsigned int n)
+{
+	return memset(s, c, n);
+}
+
+/**
+ */
+void *tm_memcpy(void *dest, const void *src, unsigned int n)
+{
+	return memcpy(dest, src, n);
+}
+
+
+/**
+ */
+int tm_abs(int x)
+{
+	if (x < 0)
+		return -x;
+	return x;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_payloads.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_payloads.h
new file mode 100644
index 0000000..cb49f2b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_payloads.h
@@ -0,0 +1,2667 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_PAYLOADS_H
+#define TM_PAYLOADS_H
+
+/** NPU Register payload TM_Sched_AlvlBankEccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.AlvlBankEccErrStatus.
+ */
+struct TM_Sched_AlvlBankEccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Drop_DPSource (PLID#1264).
+ *
+ * Used by TM.Drop.DPSource.
+ */
+struct TM_Drop_DPSource {
+	uint64_t QueueSrc:3;        /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[3-7] */
+	uint64_t AlvlSrc:3;         /**< byte[0-7],bit[8-10] */
+	uint64_t _reserved_2:5;     /**< byte[0-7],bit[11-15] */
+	uint64_t BlvlSrc:3;         /**< byte[0-7],bit[16-18] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[19-23] */
+	uint64_t ClvlSrc:3;         /**< byte[0-7],bit[24-26] */
+	uint64_t _reserved_4:5;     /**< byte[0-7],bit[27-31] */
+	uint64_t PortSrc:3;         /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_5:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1264 */
+
+/** NPU Register payload TM_Sched_QueueL1ClusterStateLo (PLID#1390).
+ *
+ * Used by TM.Sched.QueueL1ClusterStateLo.
+ */
+struct TM_Sched_QueueL1ClusterStateLo {
+	uint64_t Status:40;         /**< byte[0-7],bit[0-39] */
+	uint64_t _reserved_1:24;    /**< byte[0-7],bit[40-63] */
+}; /* PLID#1390 */
+
+/** NPU Register payload TM_Drop_BlvlDropPrfWREDDPRatio (PLID#1421).
+ *
+ * Used by TM.Drop.BlvlDropPrfWREDDPRatio.
+ */
+struct TM_Drop_BlvlDropPrfWREDDPRatio {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Sched_ClvlRRDWRRStatus01 (PLID#1383).
+ *
+ * Used by TM.Sched.ClvlRRDWRRStatus01.
+ */
+struct TM_Sched_ClvlRRDWRRStatus01 {
+	uint64_t Status:26;         /**< byte[0-7],bit[0-25] */
+	uint64_t _reserved_1:38;    /**< byte[0-7],bit[26-63] */
+}; /* PLID#1383 */
+
+/** NPU Register payload TM_Sched_PortBPFromQMgr (PLID#1380).
+ *
+ * Used by TM.Sched.PortBPFromQMgr.
+ */
+struct TM_Sched_PortBPFromQMgr {
+	uint64_t BP;                /**< byte[0-7] */
+}; /* PLID#1380 */
+
+/** NPU Register payload TM_Drop_PortInstAndAvgQueueLength (PLID#1429).
+ *
+ * Used by TM.Drop.PortInstAndAvgQueueLength.
+ */
+struct TM_Drop_PortInstAndAvgQueueLength {
+	uint64_t QL:29;             /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t AQL:29;            /**< byte[0-7],bit[32-60] */
+	uint64_t _reserved_2:3;     /**< byte[0-7],bit[61-63] */
+}; /* PLID#1429 */
+
+/** NPU Register payload TM_Sched_BlvlPerStatus (PLID#1245).
+ *
+ * Used by TM.Sched.BlvlPerStatus.
+ */
+struct TM_Sched_BlvlPerStatus {
+	uint64_t PerRoundCnt:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[10-31] */
+	uint64_t PerPointer:11;     /**< byte[0-7],bit[32-42] */
+	uint64_t _reserved_2:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1245 */
+
+/** NPU Register payload TM_Sched_ClvltoPortAndBlvlRangeMap (PLID#1405).
+ *
+ * Used by TM.Sched.ClvltoPortAndBlvlRangeMap.
+ */
+struct TM_Sched_ClvltoPortAndBlvlRangeMap {
+	uint64_t BlvlLo:5;          /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:19;    /**< byte[0-7],bit[5-23] */
+	uint64_t BlvlHi:5;          /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_2:19;    /**< byte[0-7],bit[29-47] */
+	uint64_t Port:4;            /**< byte[0-7],bit[48-51] */
+	uint64_t _reserved_3:12;    /**< byte[0-7],bit[52-63] */
+}; /* PLID#1405 */
+
+/** NPU Register payload TM_Sched_AlvlDWRRPrioEn (PLID#1398).
+ *
+ * Used by TM.Sched.AlvlDWRRPrioEn.
+ */
+struct TM_Sched_AlvlDWRRPrioEn {
+	uint64_t En:8;              /**< byte[0-7],bit[0-7] */
+	uint64_t _reserved_1:56;    /**< byte[0-7],bit[8-63] */
+}; /* PLID#1398 */
+
+/** NPU Register payload TM_Drop_QueueREDCurve_Color (PLID#1423).
+ *
+ * Used by TM.Drop.QueueREDCurve.Color[0-2].
+ */
+struct TM_Drop_QueueREDCurve_Color {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Sched_ErrCnt (PLID#1180).
+ *
+ * Used by TM.Sched.ErrCnt.
+ */
+struct TM_Sched_ErrCnt {
+	uint64_t Cnt:16;            /**< byte[0-7],bit[0-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1180 */
+
+/** NPU Register payload TM_Sched_PortMyQ (PLID#1377).
+ *
+ * Used by TM.Sched.PortMyQ.
+ */
+struct TM_Sched_PortMyQ {
+	uint64_t Status:40;         /**< byte[0-7],bit[0-39] */
+	uint64_t _reserved_1:24;    /**< byte[0-7],bit[40-63] */
+}; /* PLID#1377 */
+
+/** NPU Register payload TM_Sched_QueuePerStatus (PLID#1393).
+ *
+ * Used by TM.Sched.QueuePerStatus.
+ */
+struct TM_Sched_QueuePerStatus {
+	uint64_t PerRoundCnt:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[10-31] */
+	uint64_t PerPointer:11;     /**< byte[0-7],bit[32-42] */
+	uint64_t _reserved_2:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1393 */
+
+/** NPU Register payload TM_Sched_PortShpBucketLvls (PLID#1411).
+ *
+ * Used by TM.Sched.PortShpBucketLvls.
+ */
+struct TM_Sched_PortShpBucketLvls {
+	uint64_t MinLvl:28;         /**< byte[0-7],bit[0-27] */
+	uint64_t _reserved_1:4;     /**< byte[0-7],bit[28-31] */
+	uint64_t MaxLvl:28;         /**< byte[0-7],bit[32-59] */
+	uint64_t _reserved_2:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1411 */
+
+/** NPU Register payload TM_Sched_ClvlDWRRPrioEn (PLID#1398).
+ *
+ * Used by TM.Sched.ClvlDWRRPrioEn.
+ */
+struct TM_Sched_ClvlDWRRPrioEn {
+	uint64_t En:8;              /**< byte[0-7],bit[0-7] */
+	uint64_t _reserved_1:56;    /**< byte[0-7],bit[8-63] */
+}; /* PLID#1398 */
+
+/** NPU Register payload TM_Sched_QueueBank3EccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.QueueBank3EccErrStatus.
+ */
+struct TM_Sched_QueueBank3EccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Sched_AlvlDef (PLID#1414).
+ *
+ * Used by TM.Sched.AlvlDef.
+ */
+struct TM_Sched_AlvlDef {
+	uint64_t Deficit:22;        /**< byte[0-7],bit[0-21] */
+	uint64_t _reserved_1:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1414 */
+
+/** NPU Register payload TM_Sched_BlvlWFS (PLID#1379).
+ *
+ * Used by TM.Sched.BlvlWFS.
+ */
+struct TM_Sched_BlvlWFS {
+	uint64_t WFS:32;            /**< byte[0-7],bit[0-31] */
+	uint64_t _reserved_1:32;    /**< byte[0-7],bit[32-63] */
+}; /* PLID#1379 */
+
+/** NPU Register payload TM_Sched_ClvlEligPrioFuncPtr (PLID#1395).
+ *
+ * Used by TM.Sched.ClvlEligPrioFuncPtr.
+ */
+struct TM_Sched_ClvlEligPrioFuncPtr {
+	uint64_t Ptr:6;             /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1395 */
+
+/** NPU Register payload TM_Drop_BlvlDropPrfWREDScaleRatio (PLID#1419).
+ *
+ * Used by TM.Drop.BlvlDropPrfWREDScaleRatio.
+ */
+struct TM_Drop_BlvlDropPrfWREDScaleRatio {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_BlvlMyQ (PLID#1386).
+ *
+ * Used by TM.Sched.BlvlMyQ.
+ */
+struct TM_Sched_BlvlMyQ {
+	uint64_t Status:28;         /**< byte[0-7],bit[0-27] */
+	uint64_t _reserved_1:36;    /**< byte[0-7],bit[28-63] */
+}; /* PLID#1386 */
+
+/** NPU Register payload TM_Sched_EccMemParams (PLID#1231).
+ *
+ * Used by TM.Sched.EccMemParams[0-45].
+ */
+struct TM_Sched_EccMemParams {
+	uint64_t Counter:8;         /**< byte[0-7],bit[0-7] */
+	uint64_t Address:24;        /**< byte[0-7],bit[8-31] */
+	uint64_t Syndrom:32;        /**< byte[0-7],bit[32-63] */
+}; /* PLID#1231 */
+
+/** NPU Register payload TM_Sched_TMtoTMBlvlBPState (PLID#1385).
+ *
+ * Used by TM.Sched.TMtoTMBlvlBPState.
+ */
+struct TM_Sched_TMtoTMBlvlBPState {
+	uint64_t BPState:1;         /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1385 */
+
+/** NPU Register payload TM_Sched_BlvlL0ClusterStateHi (PLID#1417).
+ *
+ * Used by TM.Sched.BlvlL0ClusterStateHi.
+ */
+struct TM_Sched_BlvlL0ClusterStateHi {
+	uint64_t status;            /**< byte[0-7] */
+}; /* PLID#1417 */
+
+/** NPU Register payload TM_Drop_TMtoTMPktGenQuantum (PLID#1266).
+ *
+ * Used by TM.Drop.TMtoTMPktGenQuantum.
+ */
+struct TM_Drop_TMtoTMPktGenQuantum {
+	uint64_t Quantum:16;        /**< byte[0-7],bit[0-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1266 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDMinThresh (PLID#1420).
+ *
+ * Used by TM.Drop.PortDropPrfWREDMinThresh.
+ */
+struct TM_Drop_PortDropPrfWREDMinThresh {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_ClvlNodeState (PLID#1381).
+ *
+ * Used by TM.Sched.ClvlNodeState.
+ */
+struct TM_Sched_ClvlNodeState {
+	uint64_t State:11;          /**< byte[0-7],bit[0-10] */
+	uint64_t _reserved_1:53;    /**< byte[0-7],bit[11-63] */
+}; /* PLID#1381 */
+
+/** NPU Register payload TM_Drop_PortInstAndAvgQueueLengthPerCoS_CoS (PLID#1429).
+ *
+ * Used by TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[0-7].
+ */
+struct TM_Drop_PortInstAndAvgQueueLengthPerCoS_CoS {
+	uint64_t QL:29;             /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t AQL:29;            /**< byte[0-7],bit[32-60] */
+	uint64_t _reserved_2:3;     /**< byte[0-7],bit[61-63] */
+}; /* PLID#1429 */
+
+/** NPU Register payload TM_Drop_Drp_Decision_to_Query_debug (PLID#1268).
+ *
+ * Used by TM.Drop.Drp_Decision_to_Query_debug.
+ */
+struct TM_Drop_Drp_Decision_to_Query_debug {
+	uint64_t Decision_fields:27;/**< byte[0-7],bit[0-26] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[27-31] */
+	uint64_t Debug_En:1;        /**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1268 */
+
+/** NPU Register payload TM_Sched_PortBankEccErrStatus (PLID#1239).
+ *
+ * Used by TM.Sched.PortBankEccErrStatus.
+ */
+struct TM_Sched_PortBankEccErrStatus {
+	uint64_t UncEccErr:2;       /**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:14;    /**< byte[0-7],bit[2-15] */
+	uint64_t CorrEccErr:2;      /**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_2:46;    /**< byte[0-7],bit[18-63] */
+}; /* PLID#1239 */
+
+/** NPU Register payload TM_Sched_AlvlRRDWRRStatus45 (PLID#1389).
+ *
+ * Used by TM.Sched.AlvlRRDWRRStatus45.
+ */
+struct TM_Sched_AlvlRRDWRRStatus45 {
+	uint64_t Status:34;         /**< byte[0-7],bit[0-33] */
+	uint64_t _reserved_1:30;    /**< byte[0-7],bit[34-63] */
+}; /* PLID#1389 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDDPRatio_CoSRes (PLID#1421).
+ *
+ * Used by TM.Drop.PortDropPrfWREDDPRatio_CoSRes[0-7].
+ */
+struct TM_Drop_PortDropPrfWREDDPRatio_CoSRes {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Drop_Drp_Decision_hierarchy_to_Query_debug (PLID#1269).
+ *
+ * Used by TM.Drop.Drp_Decision_hierarchy_to_Query_debug.
+ */
+struct TM_Drop_Drp_Decision_hierarchy_to_Query_debug {
+	uint64_t Hierarchy_fields:46;/**< byte[0-7],bit[0-45] */
+	uint64_t _reserved_1:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1269 */
+
+/** NPU Register payload TM_Drop_ExcCnt (PLID#1180).
+ *
+ * Used by TM.Drop.ExcCnt.
+ */
+struct TM_Drop_ExcCnt {
+	uint64_t Cnt:16;            /**< byte[0-7],bit[0-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1180 */
+
+/** NPU Register payload TM_Drop_FirstExc (PLID#1259).
+ *
+ * Used by TM.Drop.FirstExc.
+ */
+struct TM_Drop_FirstExc {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t QuesryRespSyncFifoFull:1;/**< byte[0-7],bit[3] */
+	uint64_t QueryReqFifoOverflow:1;/**< byte[0-7],bit[4] */
+	uint64_t AgingFifoOverflow:1;/**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1259 */
+
+/** NPU Register payload TM_Sched_PortNodeState (PLID#1376).
+ *
+ * Used by TM.Sched.PortNodeState.
+ */
+struct TM_Sched_PortNodeState {
+	uint64_t State:18;          /**< byte[0-7],bit[0-17] */
+	uint64_t _reserved_1:46;    /**< byte[0-7],bit[18-63] */
+}; /* PLID#1376 */
+
+/** NPU Register payload TM_Sched_ClvlRRDWRRStatus67 (PLID#1383).
+ *
+ * Used by TM.Sched.ClvlRRDWRRStatus67.
+ */
+struct TM_Sched_ClvlRRDWRRStatus67 {
+	uint64_t Status:26;         /**< byte[0-7],bit[0-25] */
+	uint64_t _reserved_1:38;    /**< byte[0-7],bit[26-63] */
+}; /* PLID#1383 */
+
+/** NPU Register payload TM_Sched_QueueEligPrioFunc (PLID#1408).
+ *
+ * Used by TM.Sched.QueueEligPrioFunc.
+ */
+struct TM_Sched_QueueEligPrioFunc {
+	uint64_t FuncOut0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t FuncOut1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t FuncOut2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t FuncOut3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1408 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDDPRatio (PLID#1421).
+ *
+ * Used by TM.Drop.PortDropPrfWREDDPRatio.
+ */
+struct TM_Drop_PortDropPrfWREDDPRatio {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Sched_BlvlRRDWRRStatus67 (PLID#1363).
+ *
+ * Used by TM.Sched.BlvlRRDWRRStatus67.
+ */
+struct TM_Sched_BlvlRRDWRRStatus67 {
+	uint64_t Status:30;         /**< byte[0-7],bit[0-29] */
+	uint64_t _reserved_1:34;    /**< byte[0-7],bit[30-63] */
+}; /* PLID#1363 */
+
+/** NPU Register payload TM_Sched_BlvlL1ClusterStateHi (PLID#1387).
+ *
+ * Used by TM.Sched.BlvlL1ClusterStateHi.
+ */
+struct TM_Sched_BlvlL1ClusterStateHi {
+	uint64_t Status:42;         /**< byte[0-7],bit[0-41] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1387 */
+
+/** NPU Register payload TM_Drop_QueueDropPrfWREDParams (PLID#1426).
+ *
+ * Used by TM.Drop.QueueDropPrfWREDParams.
+ */
+struct TM_Drop_QueueDropPrfWREDParams {
+	uint64_t CurveIndexColor0:3;/**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[3-7] */
+	uint64_t CurveIndexColor1:3;/**< byte[0-7],bit[8-10] */
+	uint64_t _reserved_2:5;     /**< byte[0-7],bit[11-15] */
+	uint64_t CurveIndexColor2:3;/**< byte[0-7],bit[16-18] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[19-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1426 */
+
+/** NPU Register payload TM_Sched_PortBPFromSTF (PLID#1380).
+ *
+ * Used by TM.Sched.PortBPFromSTF.
+ */
+struct TM_Sched_PortBPFromSTF {
+	uint64_t BP;                /**< byte[0-7] */
+}; /* PLID#1380 */
+
+/** NPU Register payload TM_Sched_ExcMask (PLID#1248).
+ *
+ * Used by TM.Sched.ExcMask.
+ */
+struct TM_Sched_ExcMask {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t BPBSat:1;          /**< byte[0-7],bit[3] */
+	uint64_t TBNegSat:1;        /**< byte[0-7],bit[4] */
+	uint64_t FIFOOvrflowErr:1;  /**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1248 */
+
+/** NPU Register payload TM_Drop_BlvlDropProb (PLID#1430).
+ *
+ * Used by TM.Drop.BlvlDropProb.
+ */
+struct TM_Drop_BlvlDropProb {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Sched_TMtoTMBpFIFOBp (PLID#1206).
+ *
+ * Used by TM.Sched.TMtoTMBpFIFOBp.
+ */
+struct TM_Sched_TMtoTMBpFIFOBp {
+	uint64_t ClrThresh:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:27;    /**< byte[0-7],bit[5-31] */
+	uint64_t SetThresh:5;       /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_2:27;    /**< byte[0-7],bit[37-63] */
+}; /* PLID#1206 */
+
+/** NPU Register payload TM_Sched_PortWFS (PLID#1379).
+ *
+ * Used by TM.Sched.PortWFS.
+ */
+struct TM_Sched_PortWFS {
+	uint64_t WFS:32;            /**< byte[0-7],bit[0-31] */
+	uint64_t _reserved_1:32;    /**< byte[0-7],bit[32-63] */
+}; /* PLID#1379 */
+
+/** NPU Register payload TM_Drop_PortDropPrfTailDrpThresh (PLID#1422).
+ *
+ * Used by TM.Drop.PortDropPrfTailDrpThresh.
+ */
+struct TM_Drop_PortDropPrfTailDrpThresh {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Sched_PortRRDWRRStatus45 (PLID#1378).
+ *
+ * Used by TM.Sched.PortRRDWRRStatus45.
+ */
+struct TM_Sched_PortRRDWRRStatus45 {
+	uint64_t Status:20;         /**< byte[0-7],bit[0-19] */
+	uint64_t _reserved_1:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1378 */
+
+/** NPU Register payload TM_Sched_QueueBank1EccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.QueueBank1EccErrStatus.
+ */
+struct TM_Sched_QueueBank1EccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Drop_AlvlDropPrfWREDParams (PLID#1426).
+ *
+ * Used by TM.Drop.AlvlDropPrfWREDParams.
+ */
+struct TM_Drop_AlvlDropPrfWREDParams {
+	uint64_t CurveIndexColor0:3;/**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[3-7] */
+	uint64_t CurveIndexColor1:3;/**< byte[0-7],bit[8-10] */
+	uint64_t _reserved_2:5;     /**< byte[0-7],bit[11-15] */
+	uint64_t CurveIndexColor2:3;/**< byte[0-7],bit[16-18] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[19-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1426 */
+
+/** NPU Register payload TM_Sched_PortTokenBucketBurstSize (PLID#1397).
+ *
+ * Used by TM.Sched.PortTokenBucketBurstSize.
+ */
+struct TM_Sched_PortTokenBucketBurstSize {
+	uint64_t MinBurstSz:17;     /**< byte[0-7],bit[0-16] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[17-31] */
+	uint64_t MaxBurstSz:17;     /**< byte[0-7],bit[32-48] */
+	uint64_t _reserved_2:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1397 */
+
+/** NPU Register payload TM_Sched_BlvlPerRateShpPrms (PLID#1254).
+ *
+ * Used by TM.Sched.BlvlPerRateShpPrms.
+ */
+struct TM_Sched_BlvlPerRateShpPrms {
+	uint64_t N:14;              /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t K:14;              /**< byte[0-7],bit[16-29] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t L:14;              /**< byte[0-7],bit[32-45] */
+	uint64_t _reserved_3:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1254 */
+
+/** NPU Register payload TM_Sched_BlvlDef (PLID#1414).
+ *
+ * Used by TM.Sched.BlvlDef.
+ */
+struct TM_Sched_BlvlDef {
+	uint64_t Deficit:22;        /**< byte[0-7],bit[0-21] */
+	uint64_t _reserved_1:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1414 */
+
+/** NPU Register payload TM_Drop_AlvlDropPrfTailDrpThresh (PLID#1422).
+ *
+ * Used by TM.Drop.AlvlDropPrfTailDrpThresh.
+ */
+struct TM_Drop_AlvlDropPrfTailDrpThresh {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Sched_ClvlRRDWRRStatus23 (PLID#1383).
+ *
+ * Used by TM.Sched.ClvlRRDWRRStatus23.
+ */
+struct TM_Sched_ClvlRRDWRRStatus23 {
+	uint64_t Status:26;         /**< byte[0-7],bit[0-25] */
+	uint64_t _reserved_1:38;    /**< byte[0-7],bit[26-63] */
+}; /* PLID#1383 */
+
+/** NPU Register payload TM_Sched_PortEligPrioFunc (PLID#1394).
+ *
+ * Used by TM.Sched.PortEligPrioFunc.
+ */
+struct TM_Sched_PortEligPrioFunc {
+	uint64_t FuncOut0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t FuncOut1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t FuncOut2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t FuncOut3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1394 */
+
+/** NPU Register payload TM_Sched_ClvlMyQEccErrStatus (PLID#1242).
+ *
+ * Used by TM.Sched.ClvlMyQEccErrStatus.
+ */
+struct TM_Sched_ClvlMyQEccErrStatus {
+	uint64_t UncEccErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t CorrEccErr:1;      /**< byte[0-7],bit[16] */
+	uint64_t _reserved_2:47;    /**< byte[0-7],bit[17-63] */
+}; /* PLID#1242 */
+
+/** NPU Register payload TM_Sched_ExcCnt (PLID#1180).
+ *
+ * Used by TM.Sched.ExcCnt.
+ */
+struct TM_Sched_ExcCnt {
+	uint64_t Cnt:16;            /**< byte[0-7],bit[0-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1180 */
+
+/** NPU Register payload TM_Sched_QueueL0ClusterStateHi (PLID#1417).
+ *
+ * Used by TM.Sched.QueueL0ClusterStateHi.
+ */
+struct TM_Sched_QueueL0ClusterStateHi {
+	uint64_t status;            /**< byte[0-7] */
+}; /* PLID#1417 */
+
+/** NPU Register payload TM_Sched_AlvlRRDWRRStatus67 (PLID#1389).
+ *
+ * Used by TM.Sched.AlvlRRDWRRStatus67.
+ */
+struct TM_Sched_AlvlRRDWRRStatus67 {
+	uint64_t Status:34;         /**< byte[0-7],bit[0-33] */
+	uint64_t _reserved_1:30;    /**< byte[0-7],bit[34-63] */
+}; /* PLID#1389 */
+
+/** NPU Register payload TM_Sched_QueuePerRateShpPrms (PLID#1254).
+ *
+ * Used by TM.Sched.QueuePerRateShpPrms.
+ */
+struct TM_Sched_QueuePerRateShpPrms {
+	uint64_t N:14;              /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t K:14;              /**< byte[0-7],bit[16-29] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t L:14;              /**< byte[0-7],bit[32-45] */
+	uint64_t _reserved_3:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1254 */
+
+/** NPU Register payload TM_Sched_QueueWFS (PLID#1379).
+ *
+ * Used by TM.Sched.QueueWFS.
+ */
+struct TM_Sched_QueueWFS {
+	uint64_t WFS:32;            /**< byte[0-7],bit[0-31] */
+	uint64_t _reserved_1:32;    /**< byte[0-7],bit[32-63] */
+}; /* PLID#1379 */
+
+/** NPU Register payload TM_Sched_QueueDef (PLID#1414).
+ *
+ * Used by TM.Sched.QueueDef.
+ */
+struct TM_Sched_QueueDef {
+	uint64_t Deficit:22;        /**< byte[0-7],bit[0-21] */
+	uint64_t _reserved_1:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1414 */
+
+/** NPU Register payload TM_Drop_PortDropPrfTailDrpThresh_CoSRes (PLID#1422).
+ *
+ * Used by TM.Drop.PortDropPrfTailDrpThresh_CoSRes[0-7].
+ */
+struct TM_Drop_PortDropPrfTailDrpThresh_CoSRes {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Drop_WREDDropProbMode (PLID#1262).
+ *
+ * Used by TM.Drop.WREDDropProbMode.
+ */
+struct TM_Drop_WREDDropProbMode {
+	uint64_t Queue:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[1-7] */
+	uint64_t Alvl:1;            /**< byte[0-7],bit[8] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t Blvl:1;            /**< byte[0-7],bit[16] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[17-23] */
+	uint64_t Clvl:1;            /**< byte[0-7],bit[24] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t Port:1;            /**< byte[0-7],bit[32] */
+	uint64_t _reserved_5:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1262 */
+
+/** NPU Register payload TM_Sched_GeneralEccErrStatus (PLID#1235).
+ *
+ * Used by TM.Sched.GeneralEccErrStatus.
+ */
+struct TM_Sched_GeneralEccErrStatus {
+	uint64_t UncEccErr:6;       /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:10;    /**< byte[0-7],bit[6-15] */
+	uint64_t CorrEccErr:6;      /**< byte[0-7],bit[16-21] */
+	uint64_t _reserved_2:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1235 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDMinThresh_CoSRes (PLID#1420).
+ *
+ * Used by TM.Drop.PortDropPrfWREDMinThresh_CoSRes[0-7].
+ */
+struct TM_Drop_PortDropPrfWREDMinThresh_CoSRes {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_PortRangeMap (PLID#1401).
+ *
+ * Used by TM.Sched.PortRangeMap.
+ */
+struct TM_Sched_PortRangeMap {
+	uint64_t Lo:4;              /**< byte[0-7],bit[0-3] */
+	uint64_t _reserved_1:20;    /**< byte[0-7],bit[4-23] */
+	uint64_t Hi:4;              /**< byte[0-7],bit[24-27] */
+	uint64_t _reserved_2:36;    /**< byte[0-7],bit[28-63] */
+}; /* PLID#1401 */
+
+/** NPU Register payload TM_Sched_BlvlL1ClusterStateLo (PLID#1387).
+ *
+ * Used by TM.Sched.BlvlL1ClusterStateLo.
+ */
+struct TM_Sched_BlvlL1ClusterStateLo {
+	uint64_t Status:42;         /**< byte[0-7],bit[0-41] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1387 */
+
+/** NPU Register payload TM_Sched_ClvlPerConf (PLID#1256).
+ *
+ * Used by TM.Sched.ClvlPerConf.
+ */
+struct TM_Sched_ClvlPerConf {
+	uint64_t PerEn:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t PerInterval:12;    /**< byte[0-7],bit[16-27] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[28-47] */
+	uint64_t DecEn:1;           /**< byte[0-7],bit[48] */
+	uint64_t _reserved_3:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1256 */
+
+/** NPU Register payload TM_Drop_QueueDropProb (PLID#1430).
+ *
+ * Used by TM.Drop.QueueDropProb.
+ */
+struct TM_Drop_QueueDropProb {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Sched_AlvlEligPrioFunc (PLID#1394).
+ *
+ * Used by TM.Sched.AlvlEligPrioFunc.
+ */
+struct TM_Sched_AlvlEligPrioFunc {
+	uint64_t FuncOut0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t FuncOut1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t FuncOut2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t FuncOut3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1394 */
+
+/** NPU Register payload TM_Drop_PortREDCurve_CoS (PLID#1423).
+ *
+ * Used by TM.Drop.PortREDCurve_CoS[0-7].
+ */
+struct TM_Drop_PortREDCurve_CoS {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Sched_PortExtBPEn (PLID#1189).
+ *
+ * Used by TM.Sched.PortExtBPEn.
+ */
+struct TM_Sched_PortExtBPEn {
+	uint64_t En:1;              /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1189 */
+
+/** NPU Register payload TM_Sched_AlvlL0ClusterStateHi (PLID#1417).
+ *
+ * Used by TM.Sched.AlvlL0ClusterStateHi.
+ */
+struct TM_Sched_AlvlL0ClusterStateHi {
+	uint64_t status;            /**< byte[0-7] */
+}; /* PLID#1417 */
+
+/** NPU Register payload TM_Sched_BlvlQuantum (PLID#1404).
+ *
+ * Used by TM.Sched.BlvlQuantum.
+ */
+struct TM_Sched_BlvlQuantum {
+	uint64_t Quantum:14;        /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:50;    /**< byte[0-7],bit[14-63] */
+}; /* PLID#1404 */
+
+/** NPU Register payload TM_Sched_Id (PLID#1249).
+ *
+ * Used by TM.Sched.Id.
+ */
+struct TM_Sched_Id {
+	uint64_t UID:8;             /**< byte[0-7],bit[0-7] */
+	uint64_t SUID:8;            /**< byte[0-7],bit[8-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1249 */
+
+/** NPU Register payload TM_Sched_PortRRDWRRStatus67 (PLID#1378).
+ *
+ * Used by TM.Sched.PortRRDWRRStatus67.
+ */
+struct TM_Sched_PortRRDWRRStatus67 {
+	uint64_t Status:20;         /**< byte[0-7],bit[0-19] */
+	uint64_t _reserved_1:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1378 */
+
+/** NPU Register payload TM_Drop_QueueDropPrfTailDrpThresh (PLID#1422).
+ *
+ * Used by TM.Drop.QueueDropPrfTailDrpThresh.
+ */
+struct TM_Drop_QueueDropPrfTailDrpThresh {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Sched_ClvlBPFromSTF (PLID#1380).
+ *
+ * Used by TM.Sched.ClvlBPFromSTF.
+ */
+struct TM_Sched_ClvlBPFromSTF {
+	uint64_t BP;                /**< byte[0-7] */
+}; /* PLID#1380 */
+
+/** NPU Register payload TM_Sched_BlvlEligPrioFuncPtr (PLID#1395).
+ *
+ * Used by TM.Sched.BlvlEligPrioFuncPtr.
+ */
+struct TM_Sched_BlvlEligPrioFuncPtr {
+	uint64_t Ptr:6;             /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1395 */
+
+/** NPU Register payload TM_Drop_ErrCnt (PLID#1180).
+ *
+ * Used by TM.Drop.ErrCnt.
+ */
+struct TM_Drop_ErrCnt {
+	uint64_t Cnt:16;            /**< byte[0-7],bit[0-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1180 */
+
+/** NPU Register payload TM_Sched_AlvlPerRateShpPrms (PLID#1254).
+ *
+ * Used by TM.Sched.AlvlPerRateShpPrms.
+ */
+struct TM_Sched_AlvlPerRateShpPrms {
+	uint64_t N:14;              /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t K:14;              /**< byte[0-7],bit[16-29] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t L:14;              /**< byte[0-7],bit[32-45] */
+	uint64_t _reserved_3:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1254 */
+
+/** NPU Register payload TM_Sched_QueuePerConf (PLID#1257).
+ *
+ * Used by TM.Sched.QueuePerConf.
+ */
+struct TM_Sched_QueuePerConf {
+	uint64_t PerEn:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t PerInterval:12;    /**< byte[0-7],bit[16-27] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[28-47] */
+	uint64_t DecEn:1;           /**< byte[0-7],bit[48] */
+	uint64_t _reserved_3:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1257 */
+
+/** NPU Register payload TM_Drop_AlvlDropPrfWREDDPRatio (PLID#1421).
+ *
+ * Used by TM.Drop.AlvlDropPrfWREDDPRatio.
+ */
+struct TM_Drop_AlvlDropPrfWREDDPRatio {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Sched_AlvlQuantum (PLID#1404).
+ *
+ * Used by TM.Sched.AlvlQuantum.
+ */
+struct TM_Sched_AlvlQuantum {
+	uint64_t Quantum:14;        /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:50;    /**< byte[0-7],bit[14-63] */
+}; /* PLID#1404 */
+
+/** NPU Register payload TM_Drop_QueueAvgQueueLength (PLID#1431).
+ *
+ * Used by TM.Drop.QueueAvgQueueLength.
+ */
+struct TM_Drop_QueueAvgQueueLength {
+	uint64_t AQL:29;            /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:35;    /**< byte[0-7],bit[29-63] */
+}; /* PLID#1431 */
+
+/** NPU Register payload TM_Sched_BLevelShaperBucketNeg (PLID#1416).
+ *
+ * Used by TM.Sched.BLevelShaperBucketNeg.
+ */
+struct TM_Sched_BLevelShaperBucketNeg {
+	uint64_t MinTBNeg:32;       /**< byte[0-7],bit[0-31] */
+	uint64_t MaxTBNeg:32;       /**< byte[0-7],bit[32-63] */
+}; /* PLID#1416 */
+
+/** NPU Register payload TM_Drop_ForceErr (PLID#1183).
+ *
+ * Used by TM.Drop.ForceErr.
+ */
+struct TM_Drop_ForceErr {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1183 */
+
+/** NPU Register payload TM_Sched_PortDWRRBytesPerBurstsLimit (PLID#1255).
+ *
+ * Used by TM.Sched.PortDWRRBytesPerBurstsLimit.
+ */
+struct TM_Sched_PortDWRRBytesPerBurstsLimit {
+	uint64_t limit:7;           /**< byte[0-7],bit[0-6] */
+	uint64_t _reserved_1:57;    /**< byte[0-7],bit[7-63] */
+}; /* PLID#1255 */
+
+/** NPU Register payload TM_Sched_EccConfig (PLID#1258).
+ *
+ * Used by TM.Sched.EccConfig.
+ */
+struct TM_Sched_EccConfig {
+	uint64_t LockFirstErronousEvent:1;/**< byte[0-7],bit[0] */
+	uint64_t ErrInsMode:1;      /**< byte[0-7],bit[1] */
+	uint64_t QtoAErrInsEnable:1;/**< byte[0-7],bit[2] */
+	uint64_t AIDErrInsEnable:1; /**< byte[0-7],bit[3] */
+	uint64_t CPerConfErrInsEnable:1;/**< byte[0-7],bit[4] */
+	uint64_t BPerConfErrInsEnable:1;/**< byte[0-7],bit[5] */
+	uint64_t CTBErrInsEnable:1; /**< byte[0-7],bit[6] */
+	uint64_t BTBErrInsEnable:1; /**< byte[0-7],bit[7] */
+	uint64_t CTBNegErrInsEnable:1;/**< byte[0-7],bit[8] */
+	uint64_t CTBNeg2ErrInsEnable:1;/**< byte[0-7],bit[9] */
+	uint64_t BTBNegErrInsEnable:1;/**< byte[0-7],bit[10] */
+	uint64_t BTBNeg2ErrInsEnable:1;/**< byte[0-7],bit[11] */
+	uint64_t ATBNegErrInsEnable:1;/**< byte[0-7],bit[12] */
+	uint64_t ATBNeg2ErrInsEnable:1;/**< byte[0-7],bit[13] */
+	uint64_t QTBNegErrInsEnable:4;/**< byte[0-7],bit[14-17] */
+	uint64_t QTBNeg2ErrInsEnable:4;/**< byte[0-7],bit[18-21] */
+	uint64_t QWFSErrInsEnable:4;/**< byte[0-7],bit[22-25] */
+	uint64_t AWFSErrInsEnable:1;/**< byte[0-7],bit[26] */
+	uint64_t BWFSErrInsEnable:1;/**< byte[0-7],bit[27] */
+	uint64_t CMyQErrInsEnable:1;/**< byte[0-7],bit[28] */
+	uint64_t BMyQErrInsEnable:1;/**< byte[0-7],bit[29] */
+	uint64_t AMyQErrInsEnable:1;/**< byte[0-7],bit[30] */
+	uint64_t PDWRRErrInsEnable:1;/**< byte[0-7],bit[31] */
+	uint64_t CDWRRErrInsEnable:1;/**< byte[0-7],bit[32] */
+	uint64_t BDWRRErrInsEnable:1;/**< byte[0-7],bit[33] */
+	uint64_t ADWRRErrInsEnable:1;/**< byte[0-7],bit[34] */
+	uint64_t CParentErrInsEnable:1;/**< byte[0-7],bit[35] */
+	uint64_t BParentErrInsEnable:1;/**< byte[0-7],bit[36] */
+	uint64_t AParentErrInsEnable:1;/**< byte[0-7],bit[37] */
+	uint64_t CLastErrInsEnable:1;/**< byte[0-7],bit[38] */
+	uint64_t BLastErrInsEnable:1;/**< byte[0-7],bit[39] */
+	uint64_t ALastErrInsEnable:1;/**< byte[0-7],bit[40] */
+	uint64_t QLastErrInsEnable:1;/**< byte[0-7],bit[41] */
+	uint64_t QFuncErrInsEnable:1;/**< byte[0-7],bit[42] */
+	uint64_t AStateErrInsEnable:1;/**< byte[0-7],bit[43] */
+	uint64_t QStateErrInsEnable:1;/**< byte[0-7],bit[44] */
+	uint64_t BGrandParentErrInsEnable:1;/**< byte[0-7],bit[45] */
+	uint64_t AGrandParentErrInsEnable:1;/**< byte[0-7],bit[46] */
+	uint64_t QGrandParentErrInsEnable:1;/**< byte[0-7],bit[47] */
+	uint64_t _reserved_1:16;    /**< byte[0-7],bit[48-63] */
+}; /* PLID#1258 */
+
+/** NPU Register payload TM_Sched_QueueBank0EccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.QueueBank0EccErrStatus.
+ */
+struct TM_Sched_QueueBank0EccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Drop_QueueDropProfPtr (PLID#1427).
+ *
+ * Used by TM.Drop.QueueDropProfPtr.
+ */
+struct TM_Drop_QueueDropProfPtr {
+	uint64_t ProfPtr0:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t _reserved_1:4;     /**< byte[0-7],bit[12-15] */
+	uint64_t ProfPtr1:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t _reserved_2:4;     /**< byte[0-7],bit[28-31] */
+	uint64_t ProfPtr2:12;       /**< byte[0-7],bit[32-43] */
+	uint64_t _reserved_3:4;     /**< byte[0-7],bit[44-47] */
+	uint64_t ProfPtr3:12;       /**< byte[0-7],bit[48-59] */
+	uint64_t _reserved_4:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1427 */
+
+/** NPU Register payload TM_Drop_AlvlDropProb (PLID#1430).
+ *
+ * Used by TM.Drop.AlvlDropProb.
+ */
+struct TM_Drop_AlvlDropProb {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Drop_QueueDropPrfWREDMinThresh (PLID#1420).
+ *
+ * Used by TM.Drop.QueueDropPrfWREDMinThresh.
+ */
+struct TM_Drop_QueueDropPrfWREDMinThresh {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_ALvltoBlvlAndQueueRangeMap (PLID#1407).
+ *
+ * Used by TM.Sched.ALvltoBlvlAndQueueRangeMap.
+ */
+struct TM_Sched_ALvltoBlvlAndQueueRangeMap {
+	uint64_t QueueLo:9;         /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[9-23] */
+	uint64_t QueueHi:9;         /**< byte[0-7],bit[24-32] */
+	uint64_t _reserved_2:15;    /**< byte[0-7],bit[33-47] */
+	uint64_t Blvl:5;            /**< byte[0-7],bit[48-52] */
+	uint64_t _reserved_3:11;    /**< byte[0-7],bit[53-63] */
+}; /* PLID#1407 */
+
+/** NPU Register payload TM_Sched_QueueAMap (PLID#1410).
+ *
+ * Used by TM.Sched.QueueAMap.
+ */
+struct TM_Sched_QueueAMap {
+	uint64_t Alvl:7;            /**< byte[0-7],bit[0-6] */
+	uint64_t _reserved_1:57;    /**< byte[0-7],bit[7-63] */
+}; /* PLID#1410 */
+
+/** NPU Register payload TM_Sched_BlvlBankEccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.BlvlBankEccErrStatus.
+ */
+struct TM_Sched_BlvlBankEccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Sched_QueueL2ClusterStateLo (PLID#1392).
+ *
+ * Used by TM.Sched.QueueL2ClusterStateLo.
+ */
+struct TM_Sched_QueueL2ClusterStateLo {
+	uint64_t Status:48;         /**< byte[0-7],bit[0-47] */
+	uint64_t _reserved_1:16;    /**< byte[0-7],bit[48-63] */
+}; /* PLID#1392 */
+
+/** NPU Register payload TM_Drop_AlvlDropPrfWREDScaleRatio (PLID#1419).
+ *
+ * Used by TM.Drop.AlvlDropPrfWREDScaleRatio.
+ */
+struct TM_Drop_AlvlDropPrfWREDScaleRatio {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_BlvlShpBucketLvls (PLID#1413).
+ *
+ * Used by TM.Sched.BlvlShpBucketLvls.
+ */
+struct TM_Sched_BlvlShpBucketLvls {
+	uint64_t MinLvl:23;         /**< byte[0-7],bit[0-22] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[23-31] */
+	uint64_t MaxLvl:23;         /**< byte[0-7],bit[32-54] */
+	uint64_t _reserved_2:9;     /**< byte[0-7],bit[55-63] */
+}; /* PLID#1413 */
+
+/** NPU Register payload TM_Drop_ClvlDropPrfTailDrpThresh_CoS (PLID#1422).
+ *
+ * Used by TM.Drop.ClvlDropPrfTailDrpThresh.CoS[0-7].
+ */
+struct TM_Drop_ClvlDropPrfTailDrpThresh_CoS {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Drop_ErrStus (PLID#1259).
+ *
+ * Used by TM.Drop.ErrStus.
+ */
+struct TM_Drop_ErrStus {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t QuesryRespSyncFifoFull:1;/**< byte[0-7],bit[3] */
+	uint64_t QueryReqFifoOverflow:1;/**< byte[0-7],bit[4] */
+	uint64_t AgingFifoOverflow:1;/**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1259 */
+
+/** NPU Register payload TM_Sched_AlvlPerConf (PLID#1257).
+ *
+ * Used by TM.Sched.AlvlPerConf.
+ */
+struct TM_Sched_AlvlPerConf {
+	uint64_t PerEn:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t PerInterval:12;    /**< byte[0-7],bit[16-27] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[28-47] */
+	uint64_t DecEn:1;           /**< byte[0-7],bit[48] */
+	uint64_t _reserved_3:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1257 */
+
+/** NPU Register payload TM_Sched_ClvlL0ClusterStateLo (PLID#1384).
+ *
+ * Used by TM.Sched.ClvlL0ClusterStateLo.
+ */
+struct TM_Sched_ClvlL0ClusterStateLo {
+	uint64_t Status;            /**< byte[0-7] */
+}; /* PLID#1384 */
+
+/** NPU Register payload TM_Sched_AlvlL1ClusterStateLo (PLID#1390).
+ *
+ * Used by TM.Sched.AlvlL1ClusterStateLo.
+ */
+struct TM_Sched_AlvlL1ClusterStateLo {
+	uint64_t Status:40;         /**< byte[0-7],bit[0-39] */
+	uint64_t _reserved_1:24;    /**< byte[0-7],bit[40-63] */
+}; /* PLID#1390 */
+
+/** NPU Register payload TM_Sched_QueueBank2EccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.QueueBank2EccErrStatus.
+ */
+struct TM_Sched_QueueBank2EccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Sched_ClvlPerStatus (PLID#1244).
+ *
+ * Used by TM.Sched.ClvlPerStatus.
+ */
+struct TM_Sched_ClvlPerStatus {
+	uint64_t PerRoundCnt:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[10-31] */
+	uint64_t PerPointer:9;      /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_2:23;    /**< byte[0-7],bit[41-63] */
+}; /* PLID#1244 */
+
+/** NPU Register payload TM_Sched_PortPerRateShpPrms (PLID#1254).
+ *
+ * Used by TM.Sched.PortPerRateShpPrms.
+ */
+struct TM_Sched_PortPerRateShpPrms {
+	uint64_t N:14;              /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t K:14;              /**< byte[0-7],bit[16-29] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t L:14;              /**< byte[0-7],bit[32-45] */
+	uint64_t _reserved_3:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1254 */
+
+/** NPU Register payload TM_Sched_PortRRDWRRStatus01 (PLID#1378).
+ *
+ * Used by TM.Sched.PortRRDWRRStatus01.
+ */
+struct TM_Sched_PortRRDWRRStatus01 {
+	uint64_t Status:20;         /**< byte[0-7],bit[0-19] */
+	uint64_t _reserved_1:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1378 */
+
+/** NPU Register payload TM_Sched_BlvlPerConf (PLID#1257).
+ *
+ * Used by TM.Sched.BlvlPerConf.
+ */
+struct TM_Sched_BlvlPerConf {
+	uint64_t PerEn:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t PerInterval:12;    /**< byte[0-7],bit[16-27] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[28-47] */
+	uint64_t DecEn:1;           /**< byte[0-7],bit[48] */
+	uint64_t _reserved_3:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1257 */
+
+/** NPU Register payload TM_Sched_BlvlNodeState (PLID#1381).
+ *
+ * Used by TM.Sched.BlvlNodeState.
+ */
+struct TM_Sched_BlvlNodeState {
+	uint64_t State:11;          /**< byte[0-7],bit[0-10] */
+	uint64_t _reserved_1:53;    /**< byte[0-7],bit[11-63] */
+}; /* PLID#1381 */
+
+/** NPU Register payload TM_Sched_AlvlL1ClusterStateHi (PLID#1390).
+ *
+ * Used by TM.Sched.AlvlL1ClusterStateHi.
+ */
+struct TM_Sched_AlvlL1ClusterStateHi {
+	uint64_t Status:40;         /**< byte[0-7],bit[0-39] */
+	uint64_t _reserved_1:24;    /**< byte[0-7],bit[40-63] */
+}; /* PLID#1390 */
+
+/** NPU Register payload TM_Sched_BlvlPerRateShpPrmsInt (PLID#1238).
+ *
+ * Used by TM.Sched.BlvlPerRateShpPrmsInt.
+ */
+struct TM_Sched_BlvlPerRateShpPrmsInt {
+	uint64_t B:3;               /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:29;    /**< byte[0-7],bit[3-31] */
+	uint64_t I:3;               /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_2:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1238 */
+
+/** NPU Register payload TM_Sched_PortQuantumsPriosHi (PLID#1400).
+ *
+ * Used by TM.Sched.PortQuantumsPriosHi.
+ */
+struct TM_Sched_PortQuantumsPriosHi {
+	uint64_t Quantum4:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t Quantum5:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t Quantum6:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t Quantum7:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1400 */
+
+/** NPU Register payload TM_Sched_AlvlL2ClusterStateHi (PLID#1391).
+ *
+ * Used by TM.Sched.AlvlL2ClusterStateHi.
+ */
+struct TM_Sched_AlvlL2ClusterStateHi {
+	uint64_t Status:46;         /**< byte[0-7],bit[0-45] */
+	uint64_t _reserved_1:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1391 */
+
+/** NPU Register payload TM_Drop_AlvlInstAndAvgQueueLength (PLID#1429).
+ *
+ * Used by TM.Drop.AlvlInstAndAvgQueueLength.
+ */
+struct TM_Drop_AlvlInstAndAvgQueueLength {
+	uint64_t QL:29;             /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t AQL:29;            /**< byte[0-7],bit[32-60] */
+	uint64_t _reserved_2:3;     /**< byte[0-7],bit[61-63] */
+}; /* PLID#1429 */
+
+/** NPU Register payload TM_Sched_BlvlTokenBucketBurstSize (PLID#1403).
+ *
+ * Used by TM.Sched.BlvlTokenBucketBurstSize.
+ */
+struct TM_Sched_BlvlTokenBucketBurstSize {
+	uint64_t MinBurstSz:12;     /**< byte[0-7],bit[0-11] */
+	uint64_t _reserved_1:20;    /**< byte[0-7],bit[12-31] */
+	uint64_t MaxBurstSz:12;     /**< byte[0-7],bit[32-43] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[44-63] */
+}; /* PLID#1403 */
+
+/** NPU Register payload TM_Drop_AlvlREDCurve_Color (PLID#1423).
+ *
+ * Used by TM.Drop.AlvlREDCurve.Color[0-2].
+ */
+struct TM_Drop_AlvlREDCurve_Color {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Drop_EccConfig (PLID#1270).
+ *
+ * Used by TM.Drop.EccConfig.
+ */
+struct TM_Drop_EccConfig {
+	uint64_t LockFirstErronousEvent:1;/**< byte[0-7],bit[0] */
+	uint64_t ErrInsMode:1;      /**< byte[0-7],bit[1] */
+	uint64_t QAqlErrInsEnable:1;/**< byte[0-7],bit[2] */
+	uint64_t AAqlErrInsEnable:1;/**< byte[0-7],bit[3] */
+	uint64_t BAqlErrInsEnable:1;/**< byte[0-7],bit[4] */
+	uint64_t CAqlErrInsEnable:1;/**< byte[0-7],bit[5] */
+	uint64_t PAqlErrInsEnable:1;/**< byte[0-7],bit[6] */
+	uint64_t PAqlCoSErrInsEnable:1;/**< byte[0-7],bit[7] */
+	uint64_t QCoSErrInsEnable:1;/**< byte[0-7],bit[8] */
+	uint64_t AProfPtrErrInsEnable:1;/**< byte[0-7],bit[9] */
+	uint64_t BProfPtrErrInsEnable:1;/**< byte[0-7],bit[10] */
+	uint64_t CProfPtrErrInsEnable:8;/**< byte[0-7],bit[11-18] */
+	uint64_t QCurveErrInsEnable:3;/**< byte[0-7],bit[19-21] */
+	uint64_t ACurveErrInsEnable:3;/**< byte[0-7],bit[22-24] */
+	uint64_t QProfErrInsEnable:1;/**< byte[0-7],bit[25] */
+	uint64_t AProfErrInsEnable:1;/**< byte[0-7],bit[26] */
+	uint64_t BProfErrInsEnable:1;/**< byte[0-7],bit[27] */
+	uint64_t CProfErrInsEnable:8;/**< byte[0-7],bit[28-35] */
+	uint64_t PProfErrInsEnable:8;/**< byte[0-7],bit[36-43] */
+	uint64_t PGProfErrInsEnable:1;/**< byte[0-7],bit[44] */
+	uint64_t _reserved_1:19;    /**< byte[0-7],bit[45-63] */
+}; /* PLID#1270 */
+
+/** NPU Register payload TM_Drop_ClvlDropProfPtr_CoS (PLID#1424).
+ *
+ * Used by TM.Drop.ClvlDropProfPtr_CoS[0-7].
+ */
+struct TM_Drop_ClvlDropProfPtr_CoS {
+	uint64_t ProfPtr0:1;        /**< byte[0-7],bit[0-0] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[1-7] */
+	uint64_t ProfPtr1:1;        /**< byte[0-7],bit[8-8] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t ProfPtr2:1;        /**< byte[0-7],bit[16-16] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[17-23] */
+	uint64_t ProfPtr3:1;        /**< byte[0-7],bit[24-24] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t ProfPtr4:1;        /**< byte[0-7],bit[32-32] */
+	uint64_t _reserved_5:7;     /**< byte[0-7],bit[33-39] */
+	uint64_t ProfPtr5:1;        /**< byte[0-7],bit[40-40] */
+	uint64_t _reserved_6:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t ProfPtr6:1;        /**< byte[0-7],bit[48-48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t ProfPtr7:1;        /**< byte[0-7],bit[56-56] */
+	uint64_t _reserved_8:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1424 */
+
+/** NPU Register payload TM_Sched_PortShaperBucketNeg (PLID#1415).
+ *
+ * Used by TM.Sched.PortShaperBucketNeg.
+ */
+struct TM_Sched_PortShaperBucketNeg {
+	uint64_t MinTBNeg:32;       /**< byte[0-7],bit[0-31] */
+	uint64_t MaxNeg:32;         /**< byte[0-7],bit[32-63] */
+}; /* PLID#1415 */
+
+/** NPU Register payload TM_Drop_BlvlDropPrfWREDParams (PLID#1418).
+ *
+ * Used by TM.Drop.BlvlDropPrfWREDParams.
+ */
+struct TM_Drop_BlvlDropPrfWREDParams {
+	uint64_t CurveIndexColor0:2;/**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[2-7] */
+	uint64_t CurveIndexColor1:2;/**< byte[0-7],bit[8-9] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t CurveIndexColor2:2;/**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_3:6;     /**< byte[0-7],bit[18-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1418 */
+
+/** NPU Register payload TM_Sched_TMtoTMPortBPState (PLID#1380).
+ *
+ * Used by TM.Sched.TMtoTMPortBPState.
+ */
+struct TM_Sched_TMtoTMPortBPState {
+	uint64_t BP;                /**< byte[0-7] */
+}; /* PLID#1380 */
+
+/** NPU Register payload TM_Sched_AlvlPerStatus (PLID#1245).
+ *
+ * Used by TM.Sched.AlvlPerStatus.
+ */
+struct TM_Sched_AlvlPerStatus {
+	uint64_t PerRoundCnt:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:22;    /**< byte[0-7],bit[10-31] */
+	uint64_t PerPointer:11;     /**< byte[0-7],bit[32-42] */
+	uint64_t _reserved_2:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1245 */
+
+/** NPU Register payload TM_Sched_AlvlNodeState (PLID#1381).
+ *
+ * Used by TM.Sched.AlvlNodeState.
+ */
+struct TM_Sched_AlvlNodeState {
+	uint64_t State:11;          /**< byte[0-7],bit[0-10] */
+	uint64_t _reserved_1:53;    /**< byte[0-7],bit[11-63] */
+}; /* PLID#1381 */
+
+/** NPU Register payload TM_Sched_PortDefPrioLo (PLID#1412).
+ *
+ * Used by TM.Sched.PortDefPrioLo.
+ */
+struct TM_Sched_PortDefPrioLo {
+	uint64_t Deficit0:16;       /**< byte[0-7],bit[0-15] */
+	uint64_t Deficit1:16;       /**< byte[0-7],bit[16-31] */
+	uint64_t Deficit2:16;       /**< byte[0-7],bit[32-47] */
+	uint64_t Deficit3:16;       /**< byte[0-7],bit[48-63] */
+}; /* PLID#1412 */
+
+/** NPU Register payload TM_Sched_ClvlMyQ (PLID#1382).
+ *
+ * Used by TM.Sched.ClvlMyQ.
+ */
+struct TM_Sched_ClvlMyQ {
+	uint64_t Status:34;         /**< byte[0-7],bit[0-33] */
+	uint64_t _reserved_1:30;    /**< byte[0-7],bit[34-63] */
+}; /* PLID#1382 */
+
+/** NPU Register payload TM_Sched_CLevelShaperBucketNeg (PLID#1416).
+ *
+ * Used by TM.Sched.CLevelShaperBucketNeg.
+ */
+struct TM_Sched_CLevelShaperBucketNeg {
+	uint64_t MinTBNeg:32;       /**< byte[0-7],bit[0-31] */
+	uint64_t MaxTBNeg:32;       /**< byte[0-7],bit[32-63] */
+}; /* PLID#1416 */
+
+/** NPU Register payload TM_Sched_ClvlTokenBucketBurstSize (PLID#1403).
+ *
+ * Used by TM.Sched.ClvlTokenBucketBurstSize.
+ */
+struct TM_Sched_ClvlTokenBucketBurstSize {
+	uint64_t MinBurstSz:12;     /**< byte[0-7],bit[0-11] */
+	uint64_t _reserved_1:20;    /**< byte[0-7],bit[12-31] */
+	uint64_t MaxBurstSz:12;     /**< byte[0-7],bit[32-43] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[44-63] */
+}; /* PLID#1403 */
+
+/** NPU Register payload TM_Drop_BlvlDropProfPtr (PLID#1424).
+ *
+ * Used by TM.Drop.BlvlDropProfPtr.
+ */
+struct TM_Drop_BlvlDropProfPtr {
+	uint64_t ProfPtr0:3;        /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[3-7] */
+	uint64_t ProfPtr1:3;        /**< byte[0-7],bit[8-10] */
+	uint64_t _reserved_2:5;     /**< byte[0-7],bit[11-15] */
+	uint64_t ProfPtr2:3;        /**< byte[0-7],bit[16-18] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[19-23] */
+	uint64_t ProfPtr3:3;        /**< byte[0-7],bit[24-26] */
+	uint64_t _reserved_4:5;     /**< byte[0-7],bit[27-31] */
+	uint64_t ProfPtr4:3;        /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_5:5;     /**< byte[0-7],bit[35-39] */
+	uint64_t ProfPtr5:3;        /**< byte[0-7],bit[40-42] */
+	uint64_t _reserved_6:5;     /**< byte[0-7],bit[43-47] */
+	uint64_t ProfPtr6:3;        /**< byte[0-7],bit[48-50] */
+	uint64_t _reserved_7:5;     /**< byte[0-7],bit[51-55] */
+	uint64_t ProfPtr7:3;        /**< byte[0-7],bit[56-58] */
+	uint64_t _reserved_8:5;     /**< byte[0-7],bit[59-63] */
+}; /* PLID#1424 */
+
+/** NPU Register payload TM_Sched_BlvlRRDWRRStatus23 (PLID#1363).
+ *
+ * Used by TM.Sched.BlvlRRDWRRStatus23.
+ */
+struct TM_Sched_BlvlRRDWRRStatus23 {
+	uint64_t Status:30;         /**< byte[0-7],bit[0-29] */
+	uint64_t _reserved_1:34;    /**< byte[0-7],bit[30-63] */
+}; /* PLID#1363 */
+
+/** NPU Register payload TM_Drop_ExcMask (PLID#1260).
+ *
+ * Used by TM.Drop.ExcMask.
+ */
+struct TM_Drop_ExcMask {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t QuesryRespSyncFifoFull:1;/**< byte[0-7],bit[3] */
+	uint64_t QueryReqFifoOverflow:1;/**< byte[0-7],bit[4] */
+	uint64_t AgingFifoOverflow:1;/**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1260 */
+
+/** NPU Register payload TM_Drop_ClvlInstAndAvgQueueLength (PLID#1429).
+ *
+ * Used by TM.Drop.ClvlInstAndAvgQueueLength.
+ */
+struct TM_Drop_ClvlInstAndAvgQueueLength {
+	uint64_t QL:29;             /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t AQL:29;            /**< byte[0-7],bit[32-60] */
+	uint64_t _reserved_2:3;     /**< byte[0-7],bit[61-63] */
+}; /* PLID#1429 */
+
+/** NPU Register payload TM_Sched_QueuePerRateShpPrmsInt (PLID#1238).
+ *
+ * Used by TM.Sched.QueuePerRateShpPrmsInt.
+ */
+struct TM_Sched_QueuePerRateShpPrmsInt {
+	uint64_t B:3;               /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:29;    /**< byte[0-7],bit[3-31] */
+	uint64_t I:3;               /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_2:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1238 */
+
+/** NPU Register payload TM_Sched_ClvlTokenBucketTokenEnDiv (PLID#1402).
+ *
+ * Used by TM.Sched.ClvlTokenBucketTokenEnDiv.
+ */
+struct TM_Sched_ClvlTokenBucketTokenEnDiv {
+	uint64_t MinToken:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t MinTokenRes:3;     /**< byte[0-7],bit[12-14] */
+	uint64_t _reserved_1:1;     /**< byte[0-7],bit[15] */
+	uint64_t MaxToken:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t MaxTokenRes:3;     /**< byte[0-7],bit[28-30] */
+	uint64_t _reserved_2:1;     /**< byte[0-7],bit[31] */
+	uint64_t MinDivExp:3;       /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[35-39] */
+	uint64_t MaxDivExp:3;       /**< byte[0-7],bit[40-42] */
+	uint64_t _reserved_4:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1402 */
+
+/** NPU Register payload TM_Sched_QueueNodeState (PLID#1381).
+ *
+ * Used by TM.Sched.QueueNodeState.
+ */
+struct TM_Sched_QueueNodeState {
+	uint64_t State:11;          /**< byte[0-7],bit[0-10] */
+	uint64_t _reserved_1:53;    /**< byte[0-7],bit[11-63] */
+}; /* PLID#1381 */
+
+/** NPU Register payload TM_Drop_RespLocalDPSel (PLID#1265).
+ *
+ * Used by TM.Drop.RespLocalDPSel.
+ */
+struct TM_Drop_RespLocalDPSel {
+	uint64_t DPSel:3;           /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:5;     /**< byte[0-7],bit[3-7] */
+	uint64_t PortDPSel:1;       /**< byte[0-7],bit[8] */
+	uint64_t _reserved_2:55;    /**< byte[0-7],bit[9-63] */
+}; /* PLID#1265 */
+
+/** NPU Register payload TM_Sched_PortRRDWRRStatus23 (PLID#1378).
+ *
+ * Used by TM.Sched.PortRRDWRRStatus23.
+ */
+struct TM_Sched_PortRRDWRRStatus23 {
+	uint64_t Status:20;         /**< byte[0-7],bit[0-19] */
+	uint64_t _reserved_1:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1378 */
+
+/** NPU Register payload TM_Sched_TreeDeqEn (PLID#1251).
+ *
+ * Used by TM.Sched.TreeDeqEn.
+ */
+struct TM_Sched_TreeDeqEn {
+	uint64_t En:1;              /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1251 */
+
+/** NPU Register payload TM_Drop_EccMemParams (PLID#1231).
+ *
+ * Used by TM.Drop.EccMemParams[0-42].
+ */
+struct TM_Drop_EccMemParams {
+	uint64_t Counter:8;         /**< byte[0-7],bit[0-7] */
+	uint64_t Address:24;        /**< byte[0-7],bit[8-31] */
+	uint64_t Syndrom:32;        /**< byte[0-7],bit[32-63] */
+}; /* PLID#1231 */
+
+/** NPU Register payload TM_Sched_PortDefPrioHi (PLID#1412).
+ *
+ * Used by TM.Sched.PortDefPrioHi.
+ */
+struct TM_Sched_PortDefPrioHi {
+	uint64_t Deficit0:16;       /**< byte[0-7],bit[0-15] */
+	uint64_t Deficit1:16;       /**< byte[0-7],bit[16-31] */
+	uint64_t Deficit2:16;       /**< byte[0-7],bit[32-47] */
+	uint64_t Deficit3:16;       /**< byte[0-7],bit[48-63] */
+}; /* PLID#1412 */
+
+/** NPU Register payload TM_Sched_ClvlWFS (PLID#1379).
+ *
+ * Used by TM.Sched.ClvlWFS.
+ */
+struct TM_Sched_ClvlWFS {
+	uint64_t WFS:32;            /**< byte[0-7],bit[0-31] */
+	uint64_t _reserved_1:32;    /**< byte[0-7],bit[32-63] */
+}; /* PLID#1379 */
+
+/** NPU Register payload TM_Sched_AlvlL0ClusterStateLo (PLID#1384).
+ *
+ * Used by TM.Sched.AlvlL0ClusterStateLo.
+ */
+struct TM_Sched_AlvlL0ClusterStateLo {
+	uint64_t Status;            /**< byte[0-7] */
+}; /* PLID#1384 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDScaleRatio_CoSRes (PLID#1419).
+ *
+ * Used by TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[0-7].
+ */
+struct TM_Drop_PortDropPrfWREDScaleRatio_CoSRes {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_QueueTokenBucketTokenEnDiv (PLID#1402).
+ *
+ * Used by TM.Sched.QueueTokenBucketTokenEnDiv.
+ */
+struct TM_Sched_QueueTokenBucketTokenEnDiv {
+	uint64_t MinToken:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t MinTokenRes:3;     /**< byte[0-7],bit[12-14] */
+	uint64_t _reserved_1:1;     /**< byte[0-7],bit[15] */
+	uint64_t MaxToken:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t MaxTokenRes:3;     /**< byte[0-7],bit[28-30] */
+	uint64_t _reserved_2:1;     /**< byte[0-7],bit[31] */
+	uint64_t MinDivExp:3;       /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[35-39] */
+	uint64_t MaxDivExp:3;       /**< byte[0-7],bit[40-42] */
+	uint64_t _reserved_4:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1402 */
+
+/** NPU Register payload TM_Sched_QueueQuantum (PLID#1404).
+ *
+ * Used by TM.Sched.QueueQuantum.
+ */
+struct TM_Sched_QueueQuantum {
+	uint64_t Quantum:14;        /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:50;    /**< byte[0-7],bit[14-63] */
+}; /* PLID#1404 */
+
+/** NPU Register payload TM_Sched_AlvlMyQ (PLID#1388).
+ *
+ * Used by TM.Sched.AlvlMyQ.
+ */
+struct TM_Sched_AlvlMyQ {
+	uint64_t Status:22;         /**< byte[0-7],bit[0-21] */
+	uint64_t _reserved_1:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1388 */
+
+/** NPU Register payload TM_Sched_TMtoTMAlvlBPState (PLID#1385).
+ *
+ * Used by TM.Sched.TMtoTMAlvlBPState.
+ */
+struct TM_Sched_TMtoTMAlvlBPState {
+	uint64_t BPState:1;         /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1385 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDParams (PLID#1418).
+ *
+ * Used by TM.Drop.PortDropPrfWREDParams.
+ */
+struct TM_Drop_PortDropPrfWREDParams {
+	uint64_t CurveIndexColor0:2;/**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[2-7] */
+	uint64_t CurveIndexColor1:2;/**< byte[0-7],bit[8-9] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t CurveIndexColor2:2;/**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_3:6;     /**< byte[0-7],bit[18-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1418 */
+
+/** NPU Register payload TM_Sched_AlvlTokenBucketBurstSize (PLID#1403).
+ *
+ * Used by TM.Sched.AlvlTokenBucketBurstSize.
+ */
+struct TM_Sched_AlvlTokenBucketBurstSize {
+	uint64_t MinBurstSz:12;     /**< byte[0-7],bit[0-11] */
+	uint64_t _reserved_1:20;    /**< byte[0-7],bit[12-31] */
+	uint64_t MaxBurstSz:12;     /**< byte[0-7],bit[32-43] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[44-63] */
+}; /* PLID#1403 */
+
+/** NPU Register payload TM_Sched_AlvlMyQEccErrStatus (PLID#1242).
+ *
+ * Used by TM.Sched.AlvlMyQEccErrStatus.
+ */
+struct TM_Sched_AlvlMyQEccErrStatus {
+	uint64_t UncEccErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t CorrEccErr:1;      /**< byte[0-7],bit[16] */
+	uint64_t _reserved_2:47;    /**< byte[0-7],bit[17-63] */
+}; /* PLID#1242 */
+
+/** NPU Register payload TM_Sched_ClvlBankEccErrStatus (PLID#1243).
+ *
+ * Used by TM.Sched.ClvlBankEccErrStatus.
+ */
+struct TM_Sched_ClvlBankEccErrStatus {
+	uint64_t UncEccErr:4;       /**< byte[0-7],bit[0-3] */
+	uint64_t _reserved_1:12;    /**< byte[0-7],bit[4-15] */
+	uint64_t CorrEccErr:4;      /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_2:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1243 */
+
+/** NPU Register payload TM_Drop_ClvlDropPrfWREDMinThresh_CoS (PLID#1420).
+ *
+ * Used by TM.Drop.ClvlDropPrfWREDMinThresh.CoS[0-7].
+ */
+struct TM_Drop_ClvlDropPrfWREDMinThresh_CoS {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_ClvlL0ClusterStateHi (PLID#1417).
+ *
+ * Used by TM.Sched.ClvlL0ClusterStateHi.
+ */
+struct TM_Sched_ClvlL0ClusterStateHi {
+	uint64_t status;            /**< byte[0-7] */
+}; /* PLID#1417 */
+
+/** NPU Register payload TM_Drop_ClvlREDCurve_CoS (PLID#1423).
+ *
+ * Used by TM.Drop.ClvlREDCurve.CoS[0-7].
+ */
+struct TM_Drop_ClvlREDCurve_CoS {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Sched_QueueEccErrStatus (PLID#1246).
+ *
+ * Used by TM.Sched.QueueEccErrStatus.
+ */
+struct TM_Sched_QueueEccErrStatus {
+	uint64_t UncEccErr:7;       /**< byte[0-7],bit[0-6] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[7-15] */
+	uint64_t CorrEccErr:7;      /**< byte[0-7],bit[16-22] */
+	uint64_t _reserved_2:41;    /**< byte[0-7],bit[23-63] */
+}; /* PLID#1246 */
+
+/** NPU Register payload TM_Sched_PortTokenBucketTokenEnDiv (PLID#1396).
+ *
+ * Used by TM.Sched.PortTokenBucketTokenEnDiv.
+ */
+struct TM_Sched_PortTokenBucketTokenEnDiv {
+	uint64_t MinToken:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t MinTokenRes:3;     /**< byte[0-7],bit[12-14] */
+	uint64_t _reserved_1:1;     /**< byte[0-7],bit[15] */
+	uint64_t MaxToken:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t MaxTokenRes:3;     /**< byte[0-7],bit[28-30] */
+	uint64_t _reserved_2:1;     /**< byte[0-7],bit[31] */
+	uint64_t Periods:13;        /**< byte[0-7],bit[32-44] */
+	uint64_t _reserved_3:19;    /**< byte[0-7],bit[45-63] */
+}; /* PLID#1396 */
+
+/** NPU Register payload TM_Drop_BlvlREDCurve_Table (PLID#1423).
+ *
+ * Used by TM.Drop.BlvlREDCurve[0-3].Table.
+ */
+struct TM_Drop_BlvlREDCurve_Table {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Sched_ClvlPerRateShpPrms (PLID#1254).
+ *
+ * Used by TM.Sched.ClvlPerRateShpPrms.
+ */
+struct TM_Sched_ClvlPerRateShpPrms {
+	uint64_t N:14;              /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t K:14;              /**< byte[0-7],bit[16-29] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t L:14;              /**< byte[0-7],bit[32-45] */
+	uint64_t _reserved_3:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1254 */
+
+/** NPU Register payload TM_Sched_QueueTokenBucketBurstSize (PLID#1403).
+ *
+ * Used by TM.Sched.QueueTokenBucketBurstSize.
+ */
+struct TM_Sched_QueueTokenBucketBurstSize {
+	uint64_t MinBurstSz:12;     /**< byte[0-7],bit[0-11] */
+	uint64_t _reserved_1:20;    /**< byte[0-7],bit[12-31] */
+	uint64_t MaxBurstSz:12;     /**< byte[0-7],bit[32-43] */
+	uint64_t _reserved_2:20;    /**< byte[0-7],bit[44-63] */
+}; /* PLID#1403 */
+
+/** NPU Register payload TM_Sched_AlvlEligPrioFuncPtr (PLID#1395).
+ *
+ * Used by TM.Sched.AlvlEligPrioFuncPtr.
+ */
+struct TM_Sched_AlvlEligPrioFuncPtr {
+	uint64_t Ptr:6;             /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1395 */
+
+/** NPU Register payload TM_Sched_PortEccErrStatus (PLID#1239).
+ *
+ * Used by TM.Sched.PortEccErrStatus.
+ */
+struct TM_Sched_PortEccErrStatus {
+	uint64_t UncEccErr:2;       /**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:14;    /**< byte[0-7],bit[2-15] */
+	uint64_t CorrEccErr:2;      /**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_2:46;    /**< byte[0-7],bit[18-63] */
+}; /* PLID#1239 */
+
+/** NPU Register payload TM_Sched_TMtoTMQueueBPState (PLID#1385).
+ *
+ * Used by TM.Sched.TMtoTMQueueBPState.
+ */
+struct TM_Sched_TMtoTMQueueBPState {
+	uint64_t BPState:1;         /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1385 */
+
+/** NPU Register payload TM_Drop_QueueDropPrfWREDScaleRatio (PLID#1419).
+ *
+ * Used by TM.Drop.QueueDropPrfWREDScaleRatio.
+ */
+struct TM_Drop_QueueDropPrfWREDScaleRatio {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_BlvlRRDWRRStatus01 (PLID#1363).
+ *
+ * Used by TM.Sched.BlvlRRDWRRStatus01.
+ */
+struct TM_Sched_BlvlRRDWRRStatus01 {
+	uint64_t Status:30;         /**< byte[0-7],bit[0-29] */
+	uint64_t _reserved_1:34;    /**< byte[0-7],bit[30-63] */
+}; /* PLID#1363 */
+
+/** NPU Register payload TM_Sched_BLvltoClvlAndAlvlRangeMap (PLID#1406).
+ *
+ * Used by TM.Sched.BLvltoClvlAndAlvlRangeMap.
+ */
+struct TM_Sched_BLvltoClvlAndAlvlRangeMap {
+	uint64_t AlvlLo:7;          /**< byte[0-7],bit[0-6] */
+	uint64_t _reserved_1:17;    /**< byte[0-7],bit[7-23] */
+	uint64_t AlvlHi:7;          /**< byte[0-7],bit[24-30] */
+	uint64_t _reserved_2:17;    /**< byte[0-7],bit[31-47] */
+	uint64_t Clvl:4;            /**< byte[0-7],bit[48-51] */
+	uint64_t _reserved_3:12;     /**< byte[0-7],bit[52-63] */
+}; /* PLID#1406 */
+
+/** NPU Register payload TM_Drop_AlvlDropPrfWREDMinThresh (PLID#1420).
+ *
+ * Used by TM.Drop.AlvlDropPrfWREDMinThresh.
+ */
+struct TM_Drop_AlvlDropPrfWREDMinThresh {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_BlvlMyQEccErrStatus (PLID#1242).
+ *
+ * Used by TM.Sched.BlvlMyQEccErrStatus.
+ */
+struct TM_Sched_BlvlMyQEccErrStatus {
+	uint64_t UncEccErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t CorrEccErr:1;      /**< byte[0-7],bit[16] */
+	uint64_t _reserved_2:47;    /**< byte[0-7],bit[17-63] */
+}; /* PLID#1242 */
+
+/** NPU Register payload TM_Sched_ClvlQuantum (PLID#1404).
+ *
+ * Used by TM.Sched.ClvlQuantum.
+ */
+struct TM_Sched_ClvlQuantum {
+	uint64_t Quantum:14;        /**< byte[0-7],bit[0-13] */
+	uint64_t _reserved_1:50;    /**< byte[0-7],bit[14-63] */
+}; /* PLID#1404 */
+
+/** NPU Register payload TM_Sched_QueueL2ClusterStateHi (PLID#1392).
+ *
+ * Used by TM.Sched.QueueL2ClusterStateHi.
+ */
+struct TM_Sched_QueueL2ClusterStateHi {
+	uint64_t Status:48;         /**< byte[0-7],bit[0-47] */
+	uint64_t _reserved_1:16;    /**< byte[0-7],bit[48-63] */
+}; /* PLID#1392 */
+
+/** NPU Register payload TM_Sched_ClvlRRDWRRStatus45 (PLID#1383).
+ *
+ * Used by TM.Sched.ClvlRRDWRRStatus45.
+ */
+struct TM_Sched_ClvlRRDWRRStatus45 {
+	uint64_t Status:26;         /**< byte[0-7],bit[0-25] */
+	uint64_t _reserved_1:38;    /**< byte[0-7],bit[26-63] */
+}; /* PLID#1383 */
+
+/** NPU Register payload TM_Drop_PortDropProb (PLID#1430).
+ *
+ * Used by TM.Drop.PortDropProb.
+ */
+struct TM_Drop_PortDropProb {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Drop_QueueDropPrfWREDDPRatio (PLID#1421).
+ *
+ * Used by TM.Drop.QueueDropPrfWREDDPRatio.
+ */
+struct TM_Drop_QueueDropPrfWREDDPRatio {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDScaleRatio (PLID#1419).
+ *
+ * Used by TM.Drop.PortDropPrfWREDScaleRatio.
+ */
+struct TM_Drop_PortDropPrfWREDScaleRatio {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_AlvlTokenBucketTokenEnDiv (PLID#1402).
+ *
+ * Used by TM.Sched.AlvlTokenBucketTokenEnDiv.
+ */
+struct TM_Sched_AlvlTokenBucketTokenEnDiv {
+	uint64_t MinToken:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t MinTokenRes:3;     /**< byte[0-7],bit[12-14] */
+	uint64_t _reserved_1:1;     /**< byte[0-7],bit[15] */
+	uint64_t MaxToken:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t MaxTokenRes:3;     /**< byte[0-7],bit[28-30] */
+	uint64_t _reserved_2:1;     /**< byte[0-7],bit[31] */
+	uint64_t MinDivExp:3;       /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[35-39] */
+	uint64_t MaxDivExp:3;       /**< byte[0-7],bit[40-42] */
+	uint64_t _reserved_4:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1402 */
+
+/** NPU Register payload TM_Drop_TMtoTMDPCoSSel (PLID#1267).
+ *
+ * Used by TM.Drop.TMtoTMDPCoSSel.
+ */
+struct TM_Drop_TMtoTMDPCoSSel {
+	uint64_t CDPCoSSel:3;       /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:61;    /**< byte[0-7],bit[3-63] */
+}; /* PLID#1267 */
+
+/** NPU Register payload TM_Sched_FirstExc (PLID#1247).
+ *
+ * Used by TM.Sched.FirstExc.
+ */
+struct TM_Sched_FirstExc {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t BPBSat:1;          /**< byte[0-7],bit[3] */
+	uint64_t TBNegSat:1;        /**< byte[0-7],bit[4] */
+	uint64_t FIFOOvrflowErr:1;  /**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1247 */
+
+/** NPU Register payload TM_Sched_QueueShaperBucketNeg (PLID#1416).
+ *
+ * Used by TM.Sched.QueueShaperBucketNeg.
+ */
+struct TM_Sched_QueueShaperBucketNeg {
+	uint64_t MinTBNeg:32;       /**< byte[0-7],bit[0-31] */
+	uint64_t MaxTBNeg:32;       /**< byte[0-7],bit[32-63] */
+}; /* PLID#1416 */
+
+/** NPU Register payload TM_Sched_PortDWRRPrioEn (PLID#1398).
+ *
+ * Used by TM.Sched.PortDWRRPrioEn.
+ */
+struct TM_Sched_PortDWRRPrioEn {
+	uint64_t En:8;              /**< byte[0-7],bit[0-7] */
+	uint64_t _reserved_1:56;    /**< byte[0-7],bit[8-63] */
+}; /* PLID#1398 */
+
+/** NPU Register payload TM_Sched_PortEligPrioFuncPtr (PLID#1395).
+ *
+ * Used by TM.Sched.PortEligPrioFuncPtr.
+ */
+struct TM_Sched_PortEligPrioFuncPtr {
+	uint64_t Ptr:6;             /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1395 */
+
+/** NPU Register payload TM_Sched_ClvlEccErrStatus (PLID#1241).
+ *
+ * Used by TM.Sched.ClvlEccErrStatus.
+ */
+struct TM_Sched_ClvlEccErrStatus {
+	uint64_t UncEccErr:5;       /**< byte[0-7],bit[0-4] */
+	uint64_t _reserved_1:11;    /**< byte[0-7],bit[5-15] */
+	uint64_t CorrEccErr:5;      /**< byte[0-7],bit[16-20] */
+	uint64_t _reserved_2:43;    /**< byte[0-7],bit[21-63] */
+}; /* PLID#1241 */
+
+/** NPU Register payload TM_Sched_PortPerConf (PLID#1253).
+ *
+ * Used by TM.Sched.PortPerConf.
+ */
+struct TM_Sched_PortPerConf {
+	uint64_t PerEn:1;           /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:15;    /**< byte[0-7],bit[1-15] */
+	uint64_t PerInterval:8;     /**< byte[0-7],bit[16-23] */
+	uint64_t _reserved_2:24;    /**< byte[0-7],bit[24-47] */
+	uint64_t DecEn:1;           /**< byte[0-7],bit[48] */
+	uint64_t _reserved_3:15;    /**< byte[0-7],bit[49-63] */
+}; /* PLID#1253 */
+
+/** NPU Register payload TM_Sched_PortQuantumsPriosLo (PLID#1399).
+ *
+ * Used by TM.Sched.PortQuantumsPriosLo.
+ */
+struct TM_Sched_PortQuantumsPriosLo {
+	uint64_t Quantum0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t Quantum1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t Quantum2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t Quantum3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1399 */
+
+/** NPU Register payload TM_Sched_AlvlL2ClusterStateLo (PLID#1391).
+ *
+ * Used by TM.Sched.AlvlL2ClusterStateLo.
+ */
+struct TM_Sched_AlvlL2ClusterStateLo {
+	uint64_t Status:46;         /**< byte[0-7],bit[0-45] */
+	uint64_t _reserved_1:18;    /**< byte[0-7],bit[46-63] */
+}; /* PLID#1391 */
+
+/** NPU Register payload TM_Sched_ClvlEligPrioFunc (PLID#1394).
+ *
+ * Used by TM.Sched.ClvlEligPrioFunc.
+ */
+struct TM_Sched_ClvlEligPrioFunc {
+	uint64_t FuncOut0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t FuncOut1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t FuncOut2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t FuncOut3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1394 */
+
+/** NPU Register payload TM_Sched_TreeDWRRPrioEn (PLID#1252).
+ *
+ * Used by TM.Sched.TreeDWRRPrioEn.
+ */
+struct TM_Sched_TreeDWRRPrioEn {
+	uint64_t PrioEn:8;          /**< byte[0-7],bit[0-7] */
+	uint64_t _reserved_1:56;    /**< byte[0-7],bit[8-63] */
+}; /* PLID#1252 */
+
+/** NPU Register payload TM_Sched_QueueL1ClusterStateHi (PLID#1390).
+ *
+ * Used by TM.Sched.QueueL1ClusterStateHi.
+ */
+struct TM_Sched_QueueL1ClusterStateHi {
+	uint64_t Status:40;         /**< byte[0-7],bit[0-39] */
+	uint64_t _reserved_1:24;    /**< byte[0-7],bit[40-63] */
+}; /* PLID#1390 */
+
+/** NPU Register payload TM_Sched_AlvlWFS (PLID#1379).
+ *
+ * Used by TM.Sched.AlvlWFS.
+ */
+struct TM_Sched_AlvlWFS {
+	uint64_t WFS:32;            /**< byte[0-7],bit[0-31] */
+	uint64_t _reserved_1:32;    /**< byte[0-7],bit[32-63] */
+}; /* PLID#1379 */
+
+/** NPU Register payload TM_Drop_Id (PLID#1261).
+ *
+ * Used by TM.Drop.Id.
+ */
+struct TM_Drop_Id {
+	uint64_t UID:8;             /**< byte[0-7],bit[0-7] */
+	uint64_t SUID:8;            /**< byte[0-7],bit[8-15] */
+	uint64_t _reserved_1:48;    /**< byte[0-7],bit[16-63] */
+}; /* PLID#1261 */
+
+/** NPU Register payload TM_Drop_ClvlDropPrfWREDDPRatio_CoS (PLID#1421).
+ *
+ * Used by TM.Drop.ClvlDropPrfWREDDPRatio.CoS[0-7].
+ */
+struct TM_Drop_ClvlDropPrfWREDDPRatio_CoS {
+	uint64_t DPRatio0:6;        /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t DPRatio1:6;        /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t DPRatio2:4;        /**< byte[0-7],bit[16-19] */
+	uint64_t _reserved_3:44;    /**< byte[0-7],bit[20-63] */
+}; /* PLID#1421 */
+
+/** NPU Register payload TM_Sched_BlvlL0ClusterStateLo (PLID#1384).
+ *
+ * Used by TM.Sched.BlvlL0ClusterStateLo.
+ */
+struct TM_Sched_BlvlL0ClusterStateLo {
+	uint64_t Status;            /**< byte[0-7] */
+}; /* PLID#1384 */
+
+/** NPU Register payload TM_Drop_ClvlDropPrfWREDScaleRatio_CoS (PLID#1419).
+ *
+ * Used by TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[0-7].
+ */
+struct TM_Drop_ClvlDropPrfWREDScaleRatio_CoS {
+	uint64_t ScaleRatioColor0:10;/**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t ScaleRatioColor1:10;/**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t ScaleRatioColor2:10;/**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1419 */
+
+/** NPU Register payload TM_Sched_BlvlTokenBucketTokenEnDiv (PLID#1402).
+ *
+ * Used by TM.Sched.BlvlTokenBucketTokenEnDiv.
+ */
+struct TM_Sched_BlvlTokenBucketTokenEnDiv {
+	uint64_t MinToken:12;       /**< byte[0-7],bit[0-11] */
+	uint64_t MinTokenRes:3;     /**< byte[0-7],bit[12-14] */
+	uint64_t _reserved_1:1;     /**< byte[0-7],bit[15] */
+	uint64_t MaxToken:12;       /**< byte[0-7],bit[16-27] */
+	uint64_t MaxTokenRes:3;     /**< byte[0-7],bit[28-30] */
+	uint64_t _reserved_2:1;     /**< byte[0-7],bit[31] */
+	uint64_t MinDivExp:3;       /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_3:5;     /**< byte[0-7],bit[35-39] */
+	uint64_t MaxDivExp:3;       /**< byte[0-7],bit[40-42] */
+	uint64_t _reserved_4:21;    /**< byte[0-7],bit[43-63] */
+}; /* PLID#1402 */
+
+/** NPU Register payload TM_Sched_AlvlPerRateShpPrmsInt (PLID#1238).
+ *
+ * Used by TM.Sched.AlvlPerRateShpPrmsInt.
+ */
+struct TM_Sched_AlvlPerRateShpPrmsInt {
+	uint64_t B:3;               /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:29;    /**< byte[0-7],bit[3-31] */
+	uint64_t I:3;               /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_2:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1238 */
+
+/** NPU Register payload TM_Drop_PortDropProbPerCoS_CoS (PLID#1430).
+ *
+ * Used by TM.Drop.PortDropProbPerCoS_CoS[0-7].
+ */
+struct TM_Drop_PortDropProbPerCoS_CoS {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Sched_ClvlShpBucketLvls (PLID#1413).
+ *
+ * Used by TM.Sched.ClvlShpBucketLvls.
+ */
+struct TM_Sched_ClvlShpBucketLvls {
+	uint64_t MinLvl:23;         /**< byte[0-7],bit[0-22] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[23-31] */
+	uint64_t MaxLvl:23;         /**< byte[0-7],bit[32-54] */
+	uint64_t _reserved_2:9;     /**< byte[0-7],bit[55-63] */
+}; /* PLID#1413 */
+
+/** NPU Register payload TM_Sched_AlvlRRDWRRStatus01 (PLID#1389).
+ *
+ * Used by TM.Sched.AlvlRRDWRRStatus01.
+ */
+struct TM_Sched_AlvlRRDWRRStatus01 {
+	uint64_t Status:34;         /**< byte[0-7],bit[0-33] */
+	uint64_t _reserved_1:30;    /**< byte[0-7],bit[34-63] */
+}; /* PLID#1389 */
+
+/** NPU Register payload TM_Sched_ClvlPerRateShpPrmsInt (PLID#1238).
+ *
+ * Used by TM.Sched.ClvlPerRateShpPrmsInt.
+ */
+struct TM_Sched_ClvlPerRateShpPrmsInt {
+	uint64_t B:3;               /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:29;    /**< byte[0-7],bit[3-31] */
+	uint64_t I:3;               /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_2:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1238 */
+
+/** NPU Register payload TM_Sched_TreeRRDWRRStatus (PLID#1237).
+ *
+ * Used by TM.Sched.TreeRRDWRRStatus.
+ */
+struct TM_Sched_TreeRRDWRRStatus {
+	uint64_t Status;            /**< byte[0-7] */
+}; /* PLID#1237 */
+
+/** NPU Register payload TM_Sched_CLvlDef (PLID#1414).
+ *
+ * Used by TM.Sched.CLvlDef.
+ */
+struct TM_Sched_CLvlDef {
+	uint64_t Deficit:22;        /**< byte[0-7],bit[0-21] */
+	uint64_t _reserved_1:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1414 */
+
+/** NPU Register payload TM_Drop_QueueCoSConf (PLID#1428).
+ *
+ * Used by TM.Drop.QueueCoSConf.
+ */
+struct TM_Drop_QueueCoSConf {
+	uint64_t QueueCos0:3;       /**< byte[0-7],bit[0-2] */
+	uint64_t QueueCos1:3;       /**< byte[0-7],bit[3-5] */
+	uint64_t QueueCos2:3;       /**< byte[0-7],bit[6-8] */
+	uint64_t QueueCos3:3;       /**< byte[0-7],bit[9-11] */
+	uint64_t _reserved_1:52;    /**< byte[0-7],bit[12-63] */
+}; /* PLID#1428 */
+
+/** NPU Register payload TM_Sched_QueueL0ClusterStateLo (PLID#1384).
+ *
+ * Used by TM.Sched.QueueL0ClusterStateLo.
+ */
+struct TM_Sched_QueueL0ClusterStateLo {
+	uint64_t Status;            /**< byte[0-7] */
+}; /* PLID#1384 */
+
+/** NPU Register payload TM_Sched_ScrubDisable (PLID#1236).
+ *
+ * Used by TM.Sched.ScrubDisable.
+ */
+struct TM_Sched_ScrubDisable {
+	uint64_t Dis:1;             /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1236 */
+
+/** NPU Register payload TM_Sched_ScrubSlotAlloc (PLID#1250).
+ *
+ * Used by TM.Sched.ScrubSlotAlloc.
+ */
+struct TM_Sched_ScrubSlotAlloc {
+	uint64_t QueueSlots:6;      /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t AlvlSlots:6;       /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t BlvlSlots:6;       /**< byte[0-7],bit[16-21] */
+	uint64_t _reserved_3:2;     /**< byte[0-7],bit[22-23] */
+	uint64_t ClvlSlots:6;       /**< byte[0-7],bit[24-29] */
+	uint64_t _reserved_4:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t PortSlots:6;       /**< byte[0-7],bit[32-37] */
+	uint64_t _reserved_5:26;    /**< byte[0-7],bit[38-63] */
+}; /* PLID#1250 */
+
+/** NPU Register payload TM_Sched_ALevelShaperBucketNeg (PLID#1416).
+ *
+ * Used by TM.Sched.ALevelShaperBucketNeg.
+ */
+struct TM_Sched_ALevelShaperBucketNeg {
+	uint64_t MinTBNeg:32;       /**< byte[0-7],bit[0-31] */
+	uint64_t MaxTBNeg:32;       /**< byte[0-7],bit[32-63] */
+}; /* PLID#1416 */
+
+/** NPU Register payload TM_Sched_TMtoTMClvlBPState (PLID#1385).
+ *
+ * Used by TM.Sched.TMtoTMClvlBPState.
+ */
+struct TM_Sched_TMtoTMClvlBPState {
+	uint64_t BPState:1;         /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1385 */
+
+/** NPU Register payload TM_Sched_AlvlShpBucketLvls (PLID#1413).
+ *
+ * Used by TM.Sched.AlvlShpBucketLvls.
+ */
+struct TM_Sched_AlvlShpBucketLvls {
+	uint64_t MinLvl:23;         /**< byte[0-7],bit[0-22] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[23-31] */
+	uint64_t MaxLvl:23;         /**< byte[0-7],bit[32-54] */
+	uint64_t _reserved_2:9;     /**< byte[0-7],bit[55-63] */
+}; /* PLID#1413 */
+
+/** NPU Register payload TM_Drop_BlvlDropPrfWREDMinThresh (PLID#1420).
+ *
+ * Used by TM.Drop.BlvlDropPrfWREDMinThresh.
+ */
+struct TM_Drop_BlvlDropPrfWREDMinThresh {
+	uint64_t MinTHColor0:10;    /**< byte[0-7],bit[0-9] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t MinTHColor1:10;    /**< byte[0-7],bit[16-25] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[26-31] */
+	uint64_t MinTHColor2:10;    /**< byte[0-7],bit[32-41] */
+	uint64_t _reserved_3:22;    /**< byte[0-7],bit[42-63] */
+}; /* PLID#1420 */
+
+/** NPU Register payload TM_Sched_QueueEligPrioFuncPtr (PLID#1409).
+ *
+ * Used by TM.Sched.QueueEligPrioFuncPtr.
+ */
+struct TM_Sched_QueueEligPrioFuncPtr {
+	uint64_t Ptr:6;             /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1409 */
+
+/** NPU Register payload TM_Drop_ClvlDropProb (PLID#1430).
+ *
+ * Used by TM.Drop.ClvlDropProb.
+ */
+struct TM_Drop_ClvlDropProb {
+	uint64_t DropProb:13;       /**< byte[0-7],bit[0-12] */
+	uint64_t _reserved_1:51;    /**< byte[0-7],bit[13-63] */
+}; /* PLID#1430 */
+
+/** NPU Register payload TM_Sched_ForceErr (PLID#1183).
+ *
+ * Used by TM.Sched.ForceErr.
+ */
+struct TM_Sched_ForceErr {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1183 */
+
+/** NPU Register payload TM_Drop_PortDropPrfWREDParams_CoSRes (PLID#1418).
+ *
+ * Used by TM.Drop.PortDropPrfWREDParams_CoSRes[0-7].
+ */
+struct TM_Drop_PortDropPrfWREDParams_CoSRes {
+	uint64_t CurveIndexColor0:2;/**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[2-7] */
+	uint64_t CurveIndexColor1:2;/**< byte[0-7],bit[8-9] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t CurveIndexColor2:2;/**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_3:6;     /**< byte[0-7],bit[18-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1418 */
+
+/** NPU Register payload TM_Drop_ClvlDropPrfWREDParams_CoS (PLID#1418).
+ *
+ * Used by TM.Drop.ClvlDropPrfWREDParams.CoS[0-7].
+ */
+struct TM_Drop_ClvlDropPrfWREDParams_CoS {
+	uint64_t CurveIndexColor0:2;/**< byte[0-7],bit[0-1] */
+	uint64_t _reserved_1:6;     /**< byte[0-7],bit[2-7] */
+	uint64_t CurveIndexColor1:2;/**< byte[0-7],bit[8-9] */
+	uint64_t _reserved_2:6;     /**< byte[0-7],bit[10-15] */
+	uint64_t CurveIndexColor2:2;/**< byte[0-7],bit[16-17] */
+	uint64_t _reserved_3:6;     /**< byte[0-7],bit[18-23] */
+	uint64_t ScaleExpColor0:5;  /**< byte[0-7],bit[24-28] */
+	uint64_t _reserved_4:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t ScaleExpColor1:5;  /**< byte[0-7],bit[32-36] */
+	uint64_t _reserved_5:3;     /**< byte[0-7],bit[37-39] */
+	uint64_t ScaleExpColor2:5;  /**< byte[0-7],bit[40-44] */
+	uint64_t _reserved_6:3;     /**< byte[0-7],bit[45-47] */
+	uint64_t ColorTDEn:1;       /**< byte[0-7],bit[48] */
+	uint64_t _reserved_7:7;     /**< byte[0-7],bit[49-55] */
+	uint64_t AQLExp:4;          /**< byte[0-7],bit[56-59] */
+	uint64_t _reserved_8:4;     /**< byte[0-7],bit[60-63] */
+}; /* PLID#1418 */
+
+/** NPU Register payload TM_Sched_BlvlEccErrStatus (PLID#1235).
+ *
+ * Used by TM.Sched.BlvlEccErrStatus.
+ */
+struct TM_Sched_BlvlEccErrStatus {
+	uint64_t UncEccErr:6;       /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:10;    /**< byte[0-7],bit[6-15] */
+	uint64_t CorrEccErr:6;      /**< byte[0-7],bit[16-21] */
+	uint64_t _reserved_2:42;    /**< byte[0-7],bit[22-63] */
+}; /* PLID#1235 */
+
+/** NPU Register payload TM_Sched_BlvlRRDWRRStatus45 (PLID#1363).
+ *
+ * Used by TM.Sched.BlvlRRDWRRStatus45.
+ */
+struct TM_Sched_BlvlRRDWRRStatus45 {
+	uint64_t Status:30;         /**< byte[0-7],bit[0-29] */
+	uint64_t _reserved_1:34;    /**< byte[0-7],bit[30-63] */
+}; /* PLID#1363 */
+
+/** NPU Register payload TM_Sched_QueueShpBucketLvls (PLID#1413).
+ *
+ * Used by TM.Sched.QueueShpBucketLvls.
+ */
+struct TM_Sched_QueueShpBucketLvls {
+	uint64_t MinLvl:23;         /**< byte[0-7],bit[0-22] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[23-31] */
+	uint64_t MaxLvl:23;         /**< byte[0-7],bit[32-54] */
+	uint64_t _reserved_2:9;     /**< byte[0-7],bit[55-63] */
+}; /* PLID#1413 */
+
+/** NPU Register payload TM_Sched_PortPerRateShpPrmsInt (PLID#1238).
+ *
+ * Used by TM.Sched.PortPerRateShpPrmsInt.
+ */
+struct TM_Sched_PortPerRateShpPrmsInt {
+	uint64_t B:3;               /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:29;    /**< byte[0-7],bit[3-31] */
+	uint64_t I:3;               /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_2:29;    /**< byte[0-7],bit[35-63] */
+}; /* PLID#1238 */
+
+/** NPU Register payload TM_Drop_BlvlDropPrfTailDrpThresh (PLID#1422).
+ *
+ * Used by TM.Drop.BlvlDropPrfTailDrpThresh.
+ */
+struct TM_Drop_BlvlDropPrfTailDrpThresh {
+	uint64_t TailDropThresh:19; /**< byte[0-7],bit[0-18] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t TailDropThreshRes:1;/**< byte[0-7],bit[32] */
+	uint64_t _reserved_2:31;    /**< byte[0-7],bit[33-63] */
+}; /* PLID#1422 */
+
+/** NPU Register payload TM_Drop_AlvlDropProfPtr (PLID#1425).
+ *
+ * Used by TM.Drop.AlvlDropProfPtr.
+ */
+struct TM_Drop_AlvlDropProfPtr {
+	uint64_t ProfPtr0:3;        /**< byte[0-7],bit[0-2] */
+	uint64_t _reserved_1:13;    /**< byte[0-7],bit[3-15] */
+	uint64_t ProfPtr1:3;        /**< byte[0-7],bit[16-18] */
+	uint64_t _reserved_2:13;    /**< byte[0-7],bit[19-31] */
+	uint64_t ProfPtr2:3;        /**< byte[0-7],bit[32-34] */
+	uint64_t _reserved_3:13;    /**< byte[0-7],bit[35-47] */
+	uint64_t ProfPtr3:3;        /**< byte[0-7],bit[48-50] */
+	uint64_t _reserved_4:13;    /**< byte[0-7],bit[51-63] */
+}; /* PLID#1425 */
+
+/** NPU Register payload TM_Drop_WREDMaxProbModePerColor (PLID#1263).
+ *
+ * Used by TM.Drop.WREDMaxProbModePerColor.
+ */
+struct TM_Drop_WREDMaxProbModePerColor {
+	uint64_t Queue:6;           /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:2;     /**< byte[0-7],bit[6-7] */
+	uint64_t Alvl:6;            /**< byte[0-7],bit[8-13] */
+	uint64_t _reserved_2:2;     /**< byte[0-7],bit[14-15] */
+	uint64_t Blvl:6;            /**< byte[0-7],bit[16-21] */
+	uint64_t _reserved_3:2;     /**< byte[0-7],bit[22-23] */
+	uint64_t Clvl:6;            /**< byte[0-7],bit[24-29] */
+	uint64_t _reserved_4:2;     /**< byte[0-7],bit[30-31] */
+	uint64_t Port:6;            /**< byte[0-7],bit[32-37] */
+	uint64_t _reserved_5:26;    /**< byte[0-7],bit[38-63] */
+}; /* PLID#1263 */
+
+/** NPU Register payload TM_Sched_AlvlEccErrStatus (PLID#1246).
+ *
+ * Used by TM.Sched.AlvlEccErrStatus.
+ */
+struct TM_Sched_AlvlEccErrStatus {
+	uint64_t UncEccErr:7;       /**< byte[0-7],bit[0-6] */
+	uint64_t _reserved_1:9;     /**< byte[0-7],bit[7-15] */
+	uint64_t CorrEccErr:7;      /**< byte[0-7],bit[16-22] */
+	uint64_t _reserved_2:41;    /**< byte[0-7],bit[23-63] */
+}; /* PLID#1246 */
+
+/** NPU Register payload TM_Sched_AlvlRRDWRRStatus23 (PLID#1389).
+ *
+ * Used by TM.Sched.AlvlRRDWRRStatus23.
+ */
+struct TM_Sched_AlvlRRDWRRStatus23 {
+	uint64_t Status:34;         /**< byte[0-7],bit[0-33] */
+	uint64_t _reserved_1:30;    /**< byte[0-7],bit[34-63] */
+}; /* PLID#1389 */
+
+/** NPU Register payload TM_Sched_ErrStus (PLID#1247).
+ *
+ * Used by TM.Sched.ErrStus.
+ */
+struct TM_Sched_ErrStus {
+	uint64_t ForcedErr:1;       /**< byte[0-7],bit[0] */
+	uint64_t CorrECCErr:1;      /**< byte[0-7],bit[1] */
+	uint64_t UncECCErr:1;       /**< byte[0-7],bit[2] */
+	uint64_t BPBSat:1;          /**< byte[0-7],bit[3] */
+	uint64_t TBNegSat:1;        /**< byte[0-7],bit[4] */
+	uint64_t FIFOOvrflowErr:1;  /**< byte[0-7],bit[5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1247 */
+
+/** NPU Register payload TM_Drop_PortREDCurve (PLID#1423).
+ *
+ * Used by TM.Drop.PortREDCurve.
+ */
+struct TM_Drop_PortREDCurve {
+	uint64_t Prob:6;            /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1423 */
+
+/** NPU Register payload TM_Sched_BlvlEligPrioFunc (PLID#1394).
+ *
+ * Used by TM.Sched.BlvlEligPrioFunc.
+ */
+struct TM_Sched_BlvlEligPrioFunc {
+	uint64_t FuncOut0:9;        /**< byte[0-7],bit[0-8] */
+	uint64_t _reserved_1:7;     /**< byte[0-7],bit[9-15] */
+	uint64_t FuncOut1:9;        /**< byte[0-7],bit[16-24] */
+	uint64_t _reserved_2:7;     /**< byte[0-7],bit[25-31] */
+	uint64_t FuncOut2:9;        /**< byte[0-7],bit[32-40] */
+	uint64_t _reserved_3:7;     /**< byte[0-7],bit[41-47] */
+	uint64_t FuncOut3:9;        /**< byte[0-7],bit[48-56] */
+	uint64_t _reserved_4:7;     /**< byte[0-7],bit[57-63] */
+}; /* PLID#1394 */
+
+/** NPU Register payload TM_Drop_BlvlInstAndAvgQueueLength (PLID#1429).
+ *
+ * Used by TM.Drop.BlvlInstAndAvgQueueLength.
+ */
+struct TM_Drop_BlvlInstAndAvgQueueLength {
+	uint64_t QL:29;             /**< byte[0-7],bit[0-28] */
+	uint64_t _reserved_1:3;     /**< byte[0-7],bit[29-31] */
+	uint64_t AQL:29;            /**< byte[0-7],bit[32-60] */
+	uint64_t _reserved_2:3;     /**< byte[0-7],bit[61-63] */
+}; /* PLID#1429 */
+
+/** NPU Register payload TM_Sched_PortPerStatus (PLID#1240).
+ *
+ * Used by TM.Sched.PortPerStatus.
+ */
+struct TM_Sched_PortPerStatus {
+	uint64_t PerPointer:6;      /**< byte[0-7],bit[0-5] */
+	uint64_t _reserved_1:58;    /**< byte[0-7],bit[6-63] */
+}; /* PLID#1240 */
+
+/** NPU Register payload TM_Sched_BlvlDWRRPrioEn (PLID#1398).
+ *
+ * Used by TM.Sched.BlvlDWRRPrioEn.
+ */
+struct TM_Sched_BlvlDWRRPrioEn {
+	uint64_t En:8;              /**< byte[0-7],bit[0-7] */
+	uint64_t _reserved_1:56;    /**< byte[0-7],bit[8-63] */
+}; /* PLID#1398 */
+
+/** NPU Register payload TM_Drop_AgingUpdEnable (PLID#1251).
+ *
+ * Used by TM.Drop.AgingUpdEnable.
+ */
+struct TM_Drop_AgingUpdEnable {
+	uint64_t En:1;              /**< byte[0-7],bit[0] */
+	uint64_t _reserved_1:63;    /**< byte[0-7],bit[1-63] */
+}; /* PLID#1251 */
+
+#endif /* TM_PAYLOADS_H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_platform_implementation_definitions.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_platform_implementation_definitions.h
new file mode 100644
index 0000000..ee03d29
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_platform_implementation_definitions.h
@@ -0,0 +1,91 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_PLATFORM_IMPLEMENTATION_DEFINITIONS_H
+#define TM_PLATFORM_IMPLEMENTATION_DEFINITIONS_H
+
+
+#include "tm.h"
+#include "tm_core_types.h"
+
+
+/**
+ * @brief   Declare a QMTM environment and check consitency
+ */
+#define QMTM_ENVIRONMENT(_name, _handle) \
+		struct qmtm *_name = (struct tm *)(_handle); \
+	if ((_name) == NULL) { \
+		return -EINVAL; \
+	} \
+	if ((_name)->magic != TM_MAGIC) { \
+		return -EBADF; \
+	} \
+
+/**
+ * @brief   Check arguments and get pointers
+ *
+ * @param[in]   hndl    TM handle
+ * @param[out]  ctl     TM core handle
+ * @param[out]  env     TM struct pointer
+ *
+ * @retval  Zero on success
+ * @retval  -EBADF On bad file descriptor
+ * @retval  -EINVAL On bad arguments
+ */
+int tm_check_args(struct qmtm *hndl, struct tm_ctl **ctl, struct qmtm **env);
+
+/**
+ * @brief   Wrapper macro to initialize variables from handle pointer
+ */
+#define	TM_WRAPPER_BEGIN(_handle, _ctl, _henv)	\
+	struct tm_ctl *_ctl; \
+	struct qmtm *_henv; \
+	int rc; \
+	rc = tm_check_args(_handle, &(_ctl), &(_henv)); \
+	if (rc != 0) { \
+		return rc; \
+	}
+
+/**
+ * @brief   Wrapper macro to check for errors and return
+ */
+#define	TM_WRAPPER_END(_handle)	\
+	if (rc) { \
+		rc = tm_to_qmtm_errcode(rc); \
+	} \
+	return rc;
+
+
+#define	TM_REGVAR(_type, _var)  struct _type _var
+#define	TM_REGVAR_ADDR(_var)   (&(_var))
+
+/* if the structure is defined it can be zero memored */
+/* the Linux platform  generates warning for this action */
+
+#endif  /* TM_PLATFORM_IMPLEMENTATION_DEFINITIONS_H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_rw_registers_implementation.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_rw_registers_implementation.c
new file mode 100644
index 0000000..2f9a065
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_rw_registers_implementation.c
@@ -0,0 +1,722 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+
+#include "tm_alias.h"
+#include "tm_rw_registers_interface.h"
+#include "tm_core_types.h"
+
+
+#define QMTM_REGISTER_SIZE	2 /* All register size is 8 Bytes - 64 bits */
+
+#define MV_PP3_HW_READ	mv_pp3_hw_read
+#define MV_PP3_HW_WRITE	mv_pp3_hw_write
+/*
+#define MV_PP3_HW_READ(access_addr, words_num, data_ptr) 0
+#define MV_PP3_HW_WRITE(access_addr, words_num, data_ptr) 0
+*/
+static void tm_regs_get_address_string(u32 address, int index, char *regName);
+static void tm_regs_get_offset(u32 address, int index, u32 *offset);
+
+
+/**
+ */
+int set_hw_connection(void *handle)
+{
+	int rc = 0;
+	return rc;
+}
+
+
+/**
+ */
+int flush_hw_connection(void *handle)
+{
+	int rc = 0;
+	return rc;
+}
+
+
+/**
+ */
+int reset_hw_connection(void *handle, int error)
+{
+	int rc = 0;
+	return rc;
+}
+
+
+/**
+ */
+int close_hw_connection(void *handle)
+{
+	int rc = 0;
+	return rc;
+}
+
+
+/**
+ */
+int tm_table_entry_read(void *handle,
+				void *vpAddress,
+				long int index,
+				void *vpData)
+{
+	u32 tbl_addr = *(int *)vpAddress;
+	u32 offset = 0;
+	u32 *dataPtr = (u32 *)vpData;
+	int rc = 0;
+
+	tm_regs_get_offset(tbl_addr, index, &offset);
+	MV_PP3_HW_READ(TM.silicon_base+tbl_addr+offset, QMTM_REGISTER_SIZE, dataPtr);
+	if (tm_debug_on == 1) {
+		char reg_name[100];
+		tm_regs_get_address_string(tbl_addr, index, reg_name);
+		pr_info("R  %-32s: 0x%x + 0x%x = 0x%08x\n", reg_name, tbl_addr, offset, *(unsigned int *)vpData);
+	}
+
+	return rc;
+}
+
+
+/**
+ */
+int tm_table_entry_write(void *handle,
+				void *vpAddress,
+				long int index,
+				void *vpData)
+{
+	u32 tbl_addr = *(int *)vpAddress;
+	u32 offset = 0;
+	u32 *dataPtr = (u32 *)vpData;
+	int rc = 0;
+	/* u32 readData; */
+
+	tm_regs_get_offset(tbl_addr, index, &offset);
+
+	if (tm_debug_on == 1) { /* TBD: DefZero */
+/*	MV_PP3_HW_READ(TM.silicon_base+tbl_addr+offset, QMTM_REGISTER_SIZE, &readData);
+	if (readData != *dataPtr)
+		pr_info("!!!  %-32s: 0x%x + 0x%x = 0x%08x\n", reg_name, tbl_addr, offset, (unsigned int)readData);
+		*/
+	}
+
+	MV_PP3_HW_WRITE(TM.silicon_base+tbl_addr+offset, QMTM_REGISTER_SIZE, dataPtr);
+	if (tm_debug_on == 1) {
+		char reg_name[100];
+		tm_regs_get_address_string(*(int *)vpAddress, index, reg_name);
+		pr_info("W  %-32s: 0x%x + 0x%x = 0x%08x\n", reg_name, tbl_addr, offset, *(unsigned int *)vpData);
+	}
+
+	return rc;
+}
+
+
+/**
+ */
+int tm_register_write(void *handle, void *vpAddress, void *vpData)
+{
+	return tm_table_entry_write(handle, vpAddress, 0, vpData);
+}
+
+
+int tm_register_read(void *handle, void *vpAddress, void *vpData)
+{
+	return tm_table_entry_read(handle, vpAddress, 0, vpData);
+
+}
+
+
+static void tm_regs_get_address_string(u32 address, int index, char *regName)
+{
+	int i;
+
+	sprintf(regName, "Unknown");
+	/* Registers */
+	if (address == TM.Drop.ErrStus)
+		sprintf(regName, "TM.Drop.ErrStus                ");
+	else if (address == TM.Drop.FirstExc)
+		sprintf(regName, "TM.Drop.FirstExc               ");
+	else if (address == TM.Drop.ErrCnt)
+		sprintf(regName, "TM.Drop.ErrCnt                 ");
+	else if (address == TM.Drop.ExcCnt)
+		sprintf(regName, "TM.Drop.ExcCnt                 ");
+	else if (address == TM.Drop.ExcMask)
+		sprintf(regName, "TM.Drop.ExcMask                ");
+	else if (address == TM.Drop.Id)
+		sprintf(regName, "TM.Drop.Id                     ");
+	else if (address == TM.Drop.ForceErr)
+		sprintf(regName, "TM.Drop.ForceErr               ");
+	else if (address == TM.Drop.WREDDropProbMode)
+		sprintf(regName, "TM.Drop.WREDDropProbMode       ");
+	else if (address == TM.Drop.WREDMaxProbModePerColor)
+		sprintf(regName, "TM.Drop.WREDMaxProbModePerColor");
+	else if (address == TM.Drop.DPSource)
+		sprintf(regName, "TM.Drop.DPSource               ");
+	else if (address == TM.Drop.Drp_Decision_hierarchy_to_Query_debug)
+		sprintf(regName, "TM.Drop.Drp_Decision_hierarchy_to_Query_debug  ");
+	else if (address == TM.Drop.Drp_Decision_to_Query_debug)
+		sprintf(regName, "TM.Drop.Drp_Decision_to_Query_debug  ");
+	else if (address == TM.Drop.EccConfig)
+		sprintf(regName, "TM.Drop.EccConfig              ");
+	else if (address == TM.Drop.RespLocalDPSel)
+		sprintf(regName, "TM.Drop.RespLocalDPSel         ");
+
+	/* Ports */
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (address == TM.Drop.PortDropPrfWREDParams_CoSRes[i])
+			sprintf(regName, "TM.Drop.PortDropPrfWREDParams_CoSRes0%d     port%d", i, index);
+		else if (address == TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[i])
+			sprintf(regName, "TM.Drop.PortDropPrfWREDScaleRatio_CoSRes0%d port%d", i, index);
+		else if (address == TM.Drop.PortDropPrfWREDMinThresh_CoSRes[i])
+			sprintf(regName, "TM.Drop.PortDropPrfWREDMinThresh_CoSRes0%d  port%d", i, index);
+		else if (address == TM.Drop.PortDropPrfWREDDPRatio_CoSRes[i])
+			sprintf(regName, "TM.Drop.PortDropPrfWREDDPRatio_CoSRes0%d    port%d", i, index);
+		else if (address == TM.Drop.PortDropPrfTailDrpThresh_CoSRes[i])
+			sprintf(regName, "TM.Drop.PortDropPrfTailDrpThresh_CoSRes0%d  port%d", i, index);
+		else if (address == TM.Drop.PortREDCurve_CoS[i])
+			sprintf(regName, "TM.Drop.PortREDCurve_CoS_%d %d                    ", i, index);
+	}
+
+	if (address == TM.Drop.PortDropPrfWREDParams)
+		sprintf(regName, "TM.Drop.PortDropPrfWREDParams       port%d", index);
+	else if (address == TM.Drop.PortDropPrfWREDScaleRatio)
+		sprintf(regName, "TM.Drop.PortDropPrfWREDScaleRatio   port%d", index);
+	else if (address == TM.Drop.PortDropPrfWREDMinThresh)
+		sprintf(regName, "TM.Drop.PortDropPrfWREDMinThresh    port%d", index);
+	else if (address == TM.Drop.PortDropPrfWREDDPRatio)
+		sprintf(regName, "TM.Drop.PortDropPrfWREDDPRatio      port%d", index);
+	else if (address == TM.Drop.PortDropPrfTailDrpThresh)
+		sprintf(regName, "TM.Drop.PortDropPrfTailDrpThresh    port%d", index);
+	else if (address == TM.Drop.PortREDCurve)
+		sprintf(regName, "TM.Drop.PortREDCurve[%d]", index);
+
+	/* C Level */
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (address == TM.Drop.ClvlDropProfPtr_CoS[i])
+			/* Special case, more than one index in entry */
+			sprintf(regName, "TM.Drop.ClvlDropProfPtr.CoS[%d]      C%d", i, index);
+		else if (address == TM.Drop.ClvlDropPrfWREDParams.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlDropPrfWREDParams.CoS[%d]     profile%d", i, index);
+		else if (address == TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[%d] profile%d", i, index);
+		else if (address == TM.Drop.ClvlDropPrfWREDMinThresh.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlDropPrfWREDMinThresh.CoS[%d]  profile%d", i, index);
+		else if (address == TM.Drop.ClvlDropPrfWREDDPRatio.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlDropPrfWREDDPRatio.CoS[%d]    profile%d", i, index);
+		else if (address == TM.Drop.ClvlDropPrfTailDrpThresh.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlDropPrfTailDrpThresh.CoS[%d   profile%d]", i, index);
+		else if (address == TM.Drop.ClvlREDCurve.CoS[i])
+			sprintf(regName, "TM.Drop.ClvlREDCurve.CoS[%d][%d]", i, index); /* 128/32 = 4 curves */
+	}
+
+	/* B level */
+	if (address == TM.Drop.BlvlDropProfPtr)
+		/* Special case, more than one index in entry */
+		sprintf(regName, "TM.Drop.BlvlDropProfPtr             B%d", index);
+	else if (address == TM.Drop.BlvlDropPrfWREDParams)
+		sprintf(regName, "TM.Drop.BlvlDropPrfWREDParams     profile%d", index); /* 8 Profiles */
+	else if (address == TM.Drop.BlvlDropPrfWREDScaleRatio)
+		sprintf(regName, "TM.Drop.BlvlDropPrfWREDScaleRatio profile%d", index); /* 8 Profiles */
+	else if (address == TM.Drop.BlvlDropPrfWREDMinThresh)
+		sprintf(regName, "TM.Drop.BlvlDropPrfWREDMinThresh  profile%d", index); /* 8 Profiles */
+	else if (address == TM.Drop.BlvlDropPrfWREDDPRatio)
+		sprintf(regName, "TM.Drop.BlvlDropPrfWREDDPRatio    profile%d", index); /* 8 Profiles */
+	else if (address == TM.Drop.BlvlDropPrfTailDrpThresh)
+		sprintf(regName, "TM.Drop.BlvlDropPrfTailDrpThresh  profile%d", index); /* 8 Profiles */
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.BlvlREDCurve[i].Table)
+			sprintf(regName, "TM.Drop.BlvlREDCurve[%d][%d]", i, index); /* 32/32 = 1 curves */
+	}
+
+	/* A Level */
+	if (address == TM.Drop.AlvlDropProb)
+		sprintf(regName, "TM.Drop.AlvlDropProb              A%d", index);
+	else if (address == TM.Drop.AlvlDropPrfWREDParams)
+		sprintf(regName, "TM.Drop.AlvlDropPrfWREDParams     profile%d", index);/* 8 Profiles */
+	else if (address == TM.Drop.AlvlDropPrfWREDScaleRatio)
+		sprintf(regName, "TM.Drop.AlvlDropPrfWREDScaleRatio profile%d", index);/* 8 Profiles */
+	else if (address == TM.Drop.AlvlDropPrfWREDMinThresh)
+		sprintf(regName, "TM.Drop.AlvlDropPrfWREDMinThresh  profile%d", index);/* 8 Profiles */
+	else if (address == TM.Drop.AlvlDropPrfWREDDPRatio)
+		sprintf(regName, "TM.Drop.AlvlDropPrfWREDDPRatio    profile%d", index);/* 8 Profiles */
+	else if (address == TM.Drop.AlvlDropPrfTailDrpThresh)
+		sprintf(regName, "TM.Drop.AlvlDropPrfTailDrpThresh  profile%d", index);/* 8 Profiles */
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.AlvlREDCurve.Color[i])
+			sprintf(regName, "TM.Drop.AlvlREDCurve.Color[%d][%d]", i, index);/* 256/32 = 8 Curves */
+	}
+
+	/* Queue Level */
+	if (address == TM.Drop.QueueDropProfPtr)
+		/* Special case, more than one index in entry */
+		sprintf(regName, "TM.Drop.QueueDropProfPtr            Q%d", index);
+	else if (address == TM.Drop.QueueDropPrfWREDParams)
+		sprintf(regName, "TM.Drop.QueueDropPrfWREDParams     profile%d", index);/* 16 Profiles */
+	else if (address == TM.Drop.QueueDropPrfWREDScaleRatio)
+		sprintf(regName, "TM.Drop.QueueDropPrfWREDScaleRatio profile%d", index);/* 16 Profiles */
+	else if (address == TM.Drop.QueueDropPrfWREDMinThresh)
+		sprintf(regName, "TM.Drop.QueueDropPrfWREDMinThresh  profile%d", index);/* 16 Profiles */
+	else if (address == TM.Drop.QueueDropPrfWREDDPRatio)
+		sprintf(regName, "TM.Drop.QueueDropPrfWREDDPRatio    profile%d", index);/* 16 Profiles */
+	else if (address == TM.Drop.QueueDropPrfTailDrpThresh)
+		sprintf(regName, "TM.Drop.QueueDropPrfTailDrpThresh  profile%d", index);/* 16 Profiles */
+
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.QueueREDCurve.Color[i])
+			sprintf(regName, "TM.Drop.QueueREDCurve.Color[%d][%d]", i, index);/* 256/32 = 8 Curves */
+	}
+	if (address == TM.Drop.QueueCoSConf)
+		/* 128 * 4CoS = 512Nodes */
+		sprintf(regName, "TM.Drop.QueueCoSConf               Q%d...Q%d", index*4, index*4+3);
+
+	/* Port Level */
+	else if (address == TM.Drop.PortInstAndAvgQueueLength)
+		sprintf(regName, "TM.Drop.PortInstAndAvgQueueLength  port%d", index); /*16 ports*/
+	else if (address == TM.Drop.PortDropProb)
+		sprintf(regName, "TM.Drop.PortDropProb               port%d", index);/* 16 ports*/
+
+	for (i = 0; i < 8; i++) {
+		if (address == TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS[i])
+			/* 8 CoS 16 Ports */
+			sprintf(regName, "TM.Drop.PortInstAndAvgQueueLengthPerCoS.CoS0%d port%d", i, index);
+		else if (address == TM.Drop.PortDropProbPerCoS_CoS[i])
+			/* 8 CoS 16 Ports */
+			sprintf(regName, "TM.Drop.PortDropProbPerCoS.CoS0%d              port%d", i, index);
+	}
+	/* C Level */
+	if (address == TM.Drop.ClvlInstAndAvgQueueLength)
+		sprintf(regName, "TM.Drop.ClvlInstAndAvgQueueLength C%d", index);/* 16 C */
+	else if (address == TM.Drop.ClvlDropProb)
+		sprintf(regName, "TM.Drop.ClvlDropProb"); /* 128 = 8CoS * 16C */
+	/* B level */
+	else if (address == TM.Drop.BlvlInstAndAvgQueueLength)
+		sprintf(regName, "TM.Drop.BlvlInstAndAvgQueueLength B%d", index); /* 32 B Nodes */
+	else if (address == TM.Drop.BlvlDropProb)
+		sprintf(regName, "TM.Drop.BlvlDropProb              B%d", index); /* 32 B Nodes */
+	/* A Level */
+	else if (address == TM.Drop.AlvlDropProfPtr)
+		/* Special case, more than one index in entry */
+		sprintf(regName, "TM.Drop.AlvlDropProfPtr             A%d", index);
+	else if (address == TM.Drop.AlvlInstAndAvgQueueLength)
+		sprintf(regName, "TM.Drop.AlvlInstAndAvgQueueLength A%d", index);/* 128 A Nodes */
+	/* Queue Level */
+	else if (address == TM.Drop.QueueAvgQueueLength)
+		sprintf(regName, "TM.Drop.QueueAvgQueueLength       Q%d", index); /* 512 Queues */
+	else if (address == TM.Drop.QueueDropProb)
+		sprintf(regName, "TM.Drop.QueueDropProb             Q%d", index);	/* 512 Queues */
+
+	/* Registers*/
+	else if (address == TM.Sched.ScrubDisable)
+		sprintf(regName, "TM.Sched.ScrubDisable");
+	else if (address == TM.Sched.ScrubSlotAlloc)
+		sprintf(regName, "TM.Sched.ScrubSlotAlloc");
+	else if (address == TM.Sched.EccConfig)
+		sprintf(regName, "TM.Sched.EccConfig");
+	else if (address == TM.Sched.ExcMask)
+		sprintf(regName, "TM.Sched.ExcMask");
+	else if (address == TM.Sched.TreeDeqEn)
+		sprintf(regName, "TM.Sched.TreeDeqEn");
+	else if (address == TM.Sched.TreeDWRRPrioEn)
+		sprintf(regName, "TM.Sched.TreeDWRRPrioEn");
+	else if (address == TM.Sched.PortPerConf)
+		sprintf(regName, "TM.Sched.PortPerConf");
+	else if (address == TM.Sched.PortPerRateShpPrms)
+		sprintf(regName, "TM.Sched.PortPerRateShpPrms");
+	else if (address == TM.Sched.PortPerRateShpPrmsInt)
+		sprintf(regName, "TM.Sched.PortPerRateShpPrmsInt");
+	else if (address == TM.Sched.PortExtBPEn)
+		sprintf(regName, "TM.Sched.PortExtBPEn");
+	else if (address == TM.Sched.PortDWRRBytesPerBurstsLimit)
+		sprintf(regName, "TM.Sched.PortDWRRBytesPerBurstsLimit");
+	else if (address == TM.Sched.ClvlPerConf)
+		sprintf(regName, "TM.Sched.ClvlPerConf");
+	else if (address == TM.Sched.ClvlPerRateShpPrms)
+		sprintf(regName, "TM.Sched.ClvlPerRateShpPrms");
+	else if (address == TM.Sched.ClvlPerRateShpPrmsInt)
+		sprintf(regName, "TM.Sched.ClvlPerRateShpPrmsInt");
+	else if (address == TM.Sched.BlvlPerConf)
+		sprintf(regName, "TM.Sched.BlvlPerConf");
+	else if (address == TM.Sched.BlvlPerRateShpPrms)
+		sprintf(regName, "TM.Sched.BlvlPerRateShpPrms");
+	else if (address == TM.Sched.BlvlPerRateShpPrmsInt)
+		sprintf(regName, "TM.Sched.BlvlPerRateShpPrmsInt");
+	else if (address == TM.Sched.AlvlPerConf)
+		sprintf(regName, "TM.Sched.AlvlPerConf");
+	else if (address == TM.Sched.AlvlPerRateShpPrms)
+		sprintf(regName, "TM.Sched.AlvlPerRateShpPrms");
+	else if (address == TM.Sched.AlvlPerRateShpPrmsInt)
+		sprintf(regName, "TM.Sched.AlvlPerRateShpPrmsInt");
+	else if (address == TM.Sched.QueuePerConf)
+		sprintf(regName, "TM.Sched.QueuePerConf");
+	else if (address == TM.Sched.QueuePerRateShpPrms)
+		sprintf(regName, "TM.Sched.QueuePerRateShpPrms");
+	else if (address == TM.Sched.QueuePerRateShpPrmsInt)
+		sprintf(regName, "TM.Sched.QueuePerRateShpPrmsInt");
+	/* tables*/
+	else if (address == TM.Sched.PortEligPrioFuncPtr)
+		sprintf(regName, "TM.Sched.PortEligPrioFuncPtr        port%d", index);
+	else if (address == TM.Sched.PortTokenBucketTokenEnDiv)
+		sprintf(regName, "TM.Sched.PortTokenBucketTokenEnDiv  port%d", index);
+	else if (address == TM.Sched.PortTokenBucketBurstSize)
+		sprintf(regName, "TM.Sched.PortTokenBucketBurstSize   port%d", index);
+	else if (address == TM.Sched.PortDWRRPrioEn)
+		sprintf(regName, "TM.Sched.PortDWRRPrioEn             port%d", index);
+	else if (address == TM.Sched.PortQuantumsPriosLo)
+		sprintf(regName, "TM.Sched.PortQuantumsPriosLo        port%d", index);
+	else if (address == TM.Sched.PortQuantumsPriosHi)
+		sprintf(regName, "TM.Sched.PortQuantumsPriosHi        port%d", index);
+	else if (address == TM.Sched.PortRangeMap)
+		sprintf(regName, "TM.Sched.PortRangeMap               port%d", index);
+	else if (address == TM.Sched.PortEligPrioFunc)
+		sprintf(regName, "TM.Sched.PortEligPrioFunc           port%d", index);
+
+	if (address == TM.Sched.ClvlEligPrioFunc)
+		sprintf(regName, "TM.Sched.ClvlEligPrioFunc           C%d", index);
+	else if (address == TM.Sched.ClvlEligPrioFuncPtr)
+		sprintf(regName, "TM.Sched.ClvlEligPrioFuncPtr        C%d", index);
+	else if (address == TM.Sched.ClvlTokenBucketTokenEnDiv)
+		sprintf(regName, "TM.Sched.ClvlTokenBucketTokenEnDiv  C%d", index);
+	else if (address == TM.Sched.ClvlTokenBucketBurstSize)
+		sprintf(regName, "TM.Sched.ClvlTokenBucketBurstSize   C%d", index);
+	else if (address == TM.Sched.ClvlDWRRPrioEn)
+		sprintf(regName, "TM.Sched.ClvlDWRRPrioEn             C%d", index);
+	else if (address == TM.Sched.ClvlQuantum)
+		sprintf(regName, "TM.Sched.ClvlQuantum                C%d", index);
+	else if (address == TM.Sched.ClvltoPortAndBlvlRangeMap)
+		sprintf(regName, "TM.Sched.ClvltoPortAndBlvlRangeMap  C%d", index);
+
+	if (address == TM.Sched.BlvlEligPrioFunc)
+		sprintf(regName, "TM.Sched.BlvlEligPrioFunc           B%d", index);
+	else if (address == TM.Sched.BlvlEligPrioFuncPtr)
+		sprintf(regName, "TM.Sched.BlvlEligPrioFuncPtr        B%d", index);
+	else if (address == TM.Sched.BlvlTokenBucketTokenEnDiv)
+		sprintf(regName, "TM.Sched.BlvlTokenBucketTokenEnDiv  B%d", index);
+	else if (address == TM.Sched.BlvlTokenBucketBurstSize)
+		sprintf(regName, "TM.Sched.BlvlTokenBucketBurstSize   B%d", index);
+	else if (address == TM.Sched.BlvlDWRRPrioEn)
+		sprintf(regName, "TM.Sched.BlvlDWRRPrioEn             B%d", index);
+	else if (address == TM.Sched.BlvlQuantum)
+		sprintf(regName, "TM.Sched.BlvlQuantum                B%d", index);
+	else if (address == TM.Sched.BLvltoClvlAndAlvlRangeMap)
+		sprintf(regName, "TM.Sched.BLvltoClvlAndAlvlRangeMap  B%d", index);
+
+	if (address == TM.Sched.AlvlEligPrioFunc)
+		sprintf(regName, "TM.Sched.AlvlEligPrioFunc           A%d", index);
+	else if (address == TM.Sched.AlvlEligPrioFuncPtr)
+		sprintf(regName, "TM.Sched.AlvlEligPrioFuncPtr        A%d", index);
+	else if (address == TM.Sched.AlvlTokenBucketTokenEnDiv)
+		sprintf(regName, "TM.Sched.AlvlTokenBucketTokenEnDiv  A%d", index);
+	else if (address == TM.Sched.AlvlTokenBucketBurstSize)
+		sprintf(regName, "TM.Sched.AlvlTokenBucketBurstSize   A%d", index);
+	else if (address == TM.Sched.AlvlDWRRPrioEn)
+		sprintf(regName, "TM.Sched.AlvlDWRRPrioEn             A%d", index);
+	else if (address == TM.Sched.AlvlQuantum)
+		sprintf(regName, "TM.Sched.AlvlQuantum                A%d", index);
+	else if (address == TM.Sched.ALvltoBlvlAndQueueRangeMap)
+		sprintf(regName, "TM.Sched.ALvltoBlvlAndQueueRangeMap A%d", index);
+
+	else if (address == TM.Sched.QueueEligPrioFunc)
+		sprintf(regName, "TM.Sched.QueueEligPrioFunc          Q%d", index);
+	else if (address == TM.Sched.QueueEligPrioFuncPtr)
+		sprintf(regName, "TM.Sched.QueueEligPrioFuncPtr       Q%d", index);
+	else if (address == TM.Sched.QueueTokenBucketTokenEnDiv)
+		sprintf(regName, "TM.Sched.QueueTokenBucketTokenEnDiv Q%d", index);
+	else if (address == TM.Sched.QueueTokenBucketBurstSize)
+		sprintf(regName, "TM.Sched.QueueTokenBucketBurstSize  Q%d", index);
+	else if (address == TM.Sched.QueueQuantum)
+		sprintf(regName, "TM.Sched.QueueQuantum               Q%d", index);
+	else if (address == TM.Sched.QueueAMap)
+		sprintf(regName, "TM.Sched.QueueAMap                  Q%d", index);
+
+	else if (address == TM.Sched.PortShpBucketLvls)
+		sprintf(regName, "TM.Sched.PortShpBucketLvls          Port%d", index);
+	else if (address == TM.Sched.PortDefPrioHi)
+		sprintf(regName, "TM.Sched.PortDefPrioHi              Port%d", index);
+	else if (address == TM.Sched.PortDefPrioLo)
+		sprintf(regName, "TM.Sched.PortDefPrioLo              Port%d", index);
+
+	else if (address == TM.Sched.ClvlShpBucketLvls)
+		sprintf(regName, "TM.Sched.ClvlShpBucketLvls          C%d", index);
+	else if (address == TM.Sched.CLvlDef)
+		sprintf(regName, "TM.Sched.CLvlDef                    C%d", index);
+
+	else if (address == TM.Sched.BlvlShpBucketLvls)
+		sprintf(regName, "TM.Sched.BlvlShpBucketLvls          B%d", index);
+	else if (address == TM.Sched.BlvlDef)
+		sprintf(regName, "TM.Sched.BlvlDef                    B%d", index);
+
+	else if (address == TM.Sched.AlvlShpBucketLvls)
+		sprintf(regName, "TM.Sched.AlvlShpBucketLvls          A%d", index);
+	else if (address == TM.Sched.AlvlDef)
+		sprintf(regName, "TM.Sched.AlvlDef                    A%d", index);
+
+	else if (address == TM.Sched.QueueShpBucketLvls)
+		sprintf(regName, "TM.Sched.QueueShpBucketLvls         Q%d", index);
+	else if (address == TM.Sched.QueueDef)
+		sprintf(regName, "TM.Sched.QueueDef                   Q%d", index);
+
+	/*end of unit Sched*/
+}
+
+
+static void tm_regs_get_offset(u32 address, int index, u32 *offset)
+{
+	int i;
+	*offset = 0;
+
+	/* Queue level */
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.QueueREDCurve.Color[i])
+			*offset = tm_index_offset.Drop.QueueREDCurve.Color[i] * index;
+	}
+	if (address == TM.Drop.QueueDropPrfWREDParams)
+		*offset = tm_index_offset.Drop.QueueDropPrfWREDParams * index;
+	else if (address == TM.Drop.QueueDropPrfWREDScaleRatio)
+		*offset = tm_index_offset.Drop.QueueDropPrfWREDScaleRatio * index;
+	else if (address == TM.Drop.QueueDropPrfWREDMinThresh)
+		*offset = tm_index_offset.Drop.QueueDropPrfWREDMinThresh * index;
+	else if (address == TM.Drop.QueueDropPrfTailDrpThresh)
+		*offset = tm_index_offset.Drop.QueueDropPrfTailDrpThresh * index;
+	else if (address == TM.Drop.QueueDropPrfWREDDPRatio)
+		*offset = tm_index_offset.Drop.QueueDropPrfWREDDPRatio * index;
+
+	/* A level */
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.AlvlREDCurve.Color[i])
+			*offset = tm_index_offset.Drop.AlvlREDCurve.Color[i] * index;
+	}
+	if (address == TM.Drop.AlvlDropPrfWREDParams)
+		*offset = tm_index_offset.Drop.AlvlDropPrfWREDParams * index;
+	else if (address == TM.Drop.AlvlDropPrfWREDScaleRatio)
+		*offset = tm_index_offset.Drop.AlvlDropPrfWREDScaleRatio * index;
+	else if (address == TM.Drop.AlvlDropPrfWREDMinThresh)
+		*offset = tm_index_offset.Drop.AlvlDropPrfWREDMinThresh * index;
+	else if (address == TM.Drop.AlvlDropPrfTailDrpThresh)
+		*offset = tm_index_offset.Drop.AlvlDropPrfTailDrpThresh * index;
+	else if (address == TM.Drop.AlvlDropPrfWREDDPRatio)
+		*offset = tm_index_offset.Drop.AlvlDropPrfWREDDPRatio * index;
+
+	/* B level */
+	for (i = 0; i < 3; i++) {
+		if (address == TM.Drop.BlvlREDCurve[i].Table)
+			*offset = tm_index_offset.Drop.BlvlREDCurve[i].Table * index;
+	}
+	if (address == TM.Drop.BlvlDropPrfWREDParams)
+		*offset = tm_index_offset.Drop.BlvlDropPrfWREDParams * index;
+	else if (address == TM.Drop.BlvlDropPrfWREDScaleRatio)
+		*offset = tm_index_offset.Drop.BlvlDropPrfWREDScaleRatio * index;
+	else if (address == TM.Drop.BlvlDropPrfWREDMinThresh)
+		*offset = tm_index_offset.Drop.BlvlDropPrfWREDMinThresh * index;
+	else if (address == TM.Drop.BlvlDropPrfTailDrpThresh)
+		*offset = tm_index_offset.Drop.BlvlDropPrfTailDrpThresh * index;
+	else if (address == TM.Drop.BlvlDropPrfWREDDPRatio)
+		*offset = tm_index_offset.Drop.BlvlDropPrfWREDDPRatio * index;
+
+	/* C level */
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (address == TM.Drop.ClvlREDCurve.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlREDCurve.CoS[i] * index;
+		else if (address == TM.Drop.ClvlDropPrfWREDParams.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropPrfWREDParams.CoS[i] * index;
+		else if (address == TM.Drop.ClvlDropPrfWREDScaleRatio.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropPrfWREDScaleRatio.CoS[i] * index;
+		else if (address == TM.Drop.ClvlDropPrfWREDMinThresh.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropPrfWREDMinThresh.CoS[i] * index;
+		else if (address == TM.Drop.ClvlDropPrfTailDrpThresh.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropPrfTailDrpThresh.CoS[i] * index;
+		else if (address == TM.Drop.ClvlDropPrfWREDDPRatio.CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropPrfWREDDPRatio.CoS[i] * index;
+	}
+
+	/* Port level */
+	if (address == TM.Drop.PortREDCurve)
+		*offset = tm_index_offset.Drop.PortREDCurve * index;
+	else if (address == TM.Drop.PortDropPrfWREDParams)
+		*offset = tm_index_offset.Drop.PortDropPrfWREDParams * index;
+	else if (address == TM.Drop.PortDropPrfWREDScaleRatio)
+		*offset = tm_index_offset.Drop.PortDropPrfWREDScaleRatio * index;
+	else if (address == TM.Drop.PortDropPrfWREDMinThresh)
+		*offset = tm_index_offset.Drop.PortDropPrfWREDMinThresh * index;
+	else if (address == TM.Drop.PortDropPrfTailDrpThresh)
+		*offset = tm_index_offset.Drop.PortDropPrfTailDrpThresh * index;
+	else if (address == TM.Drop.PortDropPrfWREDDPRatio)
+		*offset = tm_index_offset.Drop.PortDropPrfWREDDPRatio * index;
+
+	for (i = 0; i < TM_WRED_COS; i++) {
+		if (address == TM.Drop.PortREDCurve_CoS[i])
+			*offset = tm_index_offset.Drop.PortREDCurve_CoS[i] * index;
+		else if (address == TM.Drop.PortDropPrfWREDParams_CoSRes[i])
+			*offset = tm_index_offset.Drop.PortDropPrfWREDParams_CoSRes[i] * index;
+		else if (address == TM.Drop.PortDropPrfWREDScaleRatio_CoSRes[i])
+			*offset = tm_index_offset.Drop.PortDropPrfWREDScaleRatio_CoSRes[i] * index;
+		else if (address == TM.Drop.PortDropPrfWREDMinThresh_CoSRes[i])
+			*offset = tm_index_offset.Drop.PortDropPrfWREDMinThresh_CoSRes[i] * index;
+		else if (address == TM.Drop.PortDropPrfWREDDPRatio_CoSRes[i])
+			*offset = tm_index_offset.Drop.PortDropPrfWREDDPRatio_CoSRes[i] * index;
+		else if (address == TM.Drop.PortDropPrfTailDrpThresh_CoSRes[i])
+			*offset = tm_index_offset.Drop.PortDropPrfTailDrpThresh_CoSRes[i] * index;
+	}
+
+	if (address == TM.Sched.QueueTokenBucketTokenEnDiv)
+		*offset = tm_index_offset.Sched.QueueTokenBucketTokenEnDiv * index;
+	else if (address == TM.Sched.QueueTokenBucketBurstSize)
+		*offset = tm_index_offset.Sched.QueueTokenBucketBurstSize * index;
+	else if (address == TM.Sched.AlvlTokenBucketTokenEnDiv)
+		*offset = tm_index_offset.Sched.AlvlTokenBucketTokenEnDiv * index;
+	else if (address == TM.Sched.AlvlTokenBucketBurstSize)
+		*offset = tm_index_offset.Sched.AlvlTokenBucketBurstSize * index;
+	else if (address == TM.Sched.BlvlTokenBucketTokenEnDiv)
+		*offset = tm_index_offset.Sched.BlvlTokenBucketTokenEnDiv * index;
+	else if (address == TM.Sched.BlvlTokenBucketBurstSize)
+		*offset = tm_index_offset.Sched.BlvlTokenBucketBurstSize * index;
+	else if (address == TM.Sched.ClvlTokenBucketTokenEnDiv)
+		*offset = tm_index_offset.Sched.ClvlTokenBucketTokenEnDiv * index;
+	else if (address == TM.Sched.ClvlTokenBucketBurstSize)
+		*offset = tm_index_offset.Sched.ClvlTokenBucketBurstSize * index;
+
+	else if (address == TM.Sched.PortRangeMap)
+		*offset = tm_index_offset.Sched.PortRangeMap * index;
+	else if (address == TM.Sched.ClvltoPortAndBlvlRangeMap)
+		*offset = tm_index_offset.Sched.ClvltoPortAndBlvlRangeMap * index;
+	else if (address == TM.Sched.BLvltoClvlAndAlvlRangeMap)
+		*offset = tm_index_offset.Sched.BLvltoClvlAndAlvlRangeMap * index;
+	else if (address == TM.Sched.ALvltoBlvlAndQueueRangeMap)
+		*offset = tm_index_offset.Sched.ALvltoBlvlAndQueueRangeMap * index;
+	else if (address == TM.Sched.QueueAMap)
+		*offset = tm_index_offset.Sched.QueueAMap * index;
+
+	else if (address == TM.Sched.QueueEligPrioFunc)
+		*offset = tm_index_offset.Sched.QueueEligPrioFunc * index;
+	else if (address == TM.Sched.QueueEligPrioFuncPtr)
+		*offset = tm_index_offset.Sched.QueueEligPrioFuncPtr * index;
+	else if (address == TM.Sched.QueueQuantum)
+		*offset = tm_index_offset.Sched.QueueQuantum * index;
+	else if (address == TM.Drop.QueueDropProfPtr)
+		*offset = tm_index_offset.Drop.QueueDropProfPtr * index;
+	else if (address == TM.Drop.QueueAvgQueueLength)
+		*offset = tm_index_offset.Drop.QueueAvgQueueLength * index;
+
+	else if (address == TM.Sched.ALvltoBlvlAndQueueRangeMap)
+		*offset = tm_index_offset.Sched.ALvltoBlvlAndQueueRangeMap * index;
+	else if (address == TM.Sched.AlvlEligPrioFunc)
+		*offset = tm_index_offset.Sched.AlvlEligPrioFunc * index;
+	else if (address == TM.Sched.AlvlEligPrioFuncPtr)
+		*offset = tm_index_offset.Sched.AlvlEligPrioFuncPtr * index;
+	else if (address == TM.Sched.AlvlQuantum)
+		*offset = tm_index_offset.Sched.AlvlQuantum * index;
+	else if (address == TM.Sched.AlvlDWRRPrioEn)
+		*offset = tm_index_offset.Sched.AlvlDWRRPrioEn * index;
+	else if (address == TM.Drop.AlvlDropProfPtr)
+		*offset = tm_index_offset.Drop.AlvlDropProfPtr * index;
+	else if (address == TM.Drop.AlvlInstAndAvgQueueLength)
+		*offset = tm_index_offset.Drop.AlvlInstAndAvgQueueLength * index;
+
+	else if (address == TM.Sched.BLvltoClvlAndAlvlRangeMap)
+		*offset = tm_index_offset.Sched.BLvltoClvlAndAlvlRangeMap * index;
+	else if (address == TM.Sched.BlvlEligPrioFunc)
+		*offset = tm_index_offset.Sched.BlvlEligPrioFunc * index;
+	else if (address == TM.Sched.BlvlEligPrioFuncPtr)
+		*offset = tm_index_offset.Sched.BlvlEligPrioFuncPtr * index;
+	else if (address == TM.Sched.BlvlQuantum)
+		*offset = tm_index_offset.Sched.BlvlQuantum * index;
+	else if (address == TM.Sched.BlvlDWRRPrioEn)
+		*offset = tm_index_offset.Sched.BlvlDWRRPrioEn * index;
+	else if (address == TM.Drop.BlvlDropProfPtr)
+		*offset = tm_index_offset.Drop.BlvlDropProfPtr * index;
+	else if (address == TM.Drop.BlvlInstAndAvgQueueLength)
+		*offset = tm_index_offset.Drop.BlvlInstAndAvgQueueLength * index;
+
+	else if (address == TM.Sched.ClvltoPortAndBlvlRangeMap)
+		*offset = tm_index_offset.Sched.ClvltoPortAndBlvlRangeMap * index;
+	else if (address == TM.Sched.ClvlEligPrioFunc)
+		*offset = tm_index_offset.Sched.ClvlEligPrioFunc * index;
+	else if (address == TM.Sched.ClvlEligPrioFuncPtr)
+		*offset = tm_index_offset.Sched.ClvlEligPrioFuncPtr * index;
+	else if (address == TM.Sched.ClvlQuantum)
+		*offset = tm_index_offset.Sched.ClvlQuantum * index;
+	else if (address == TM.Sched.ClvlDWRRPrioEn)
+		*offset = tm_index_offset.Sched.ClvlDWRRPrioEn * index;
+	else if (address == TM.Drop.ClvlInstAndAvgQueueLength)
+		*offset = tm_index_offset.Drop.ClvlInstAndAvgQueueLength * index;
+	for (i = 0; i < 8; i++) {
+		if (address == TM.Drop.ClvlDropProfPtr_CoS[i])
+			*offset = tm_index_offset.Drop.ClvlDropProfPtr_CoS[i] * index;
+	}
+
+	if (address == TM.Sched.PortEligPrioFunc)
+		*offset = tm_index_offset.Sched.PortEligPrioFunc * index;
+	else if (address == TM.Sched.PortEligPrioFuncPtr)
+		*offset = tm_index_offset.Sched.PortEligPrioFuncPtr * index;
+	else if (address == TM.Sched.PortTokenBucketTokenEnDiv)
+		*offset = tm_index_offset.Sched.PortTokenBucketTokenEnDiv * index;
+	else if (address == TM.Sched.PortTokenBucketBurstSize)
+		*offset = tm_index_offset.Sched.PortTokenBucketBurstSize * index;
+
+	else if (address == TM.Sched.PortQuantumsPriosLo)
+		*offset = tm_index_offset.Sched.PortQuantumsPriosLo * index;
+	else if (address == TM.Sched.PortQuantumsPriosHi)
+		*offset = tm_index_offset.Sched.PortQuantumsPriosHi * index;
+	else if (address == TM.Sched.PortDWRRPrioEn)
+		*offset = tm_index_offset.Sched.PortDWRRPrioEn * index;
+	else if (address == TM.Drop.PortInstAndAvgQueueLength)
+		*offset = tm_index_offset.Drop.PortInstAndAvgQueueLength * index;
+
+	else if (address == TM.Sched.PortDefPrioHi)
+		*offset = tm_index_offset.Sched.PortDefPrioHi * index;
+	else if (address == TM.Sched.PortDefPrioLo)
+		*offset = tm_index_offset.Sched.PortDefPrioLo * index;
+
+	else if (address == TM.Sched.CLvlDef)
+		*offset = tm_index_offset.Sched.CLvlDef * index;
+	else if (address == TM.Sched.BlvlDef)
+		*offset = tm_index_offset.Sched.BlvlDef * index;
+	else if (address == TM.Sched.AlvlDef)
+		*offset = tm_index_offset.Sched.AlvlDef * index;
+	else if (address == TM.Sched.QueueDef)
+		*offset = tm_index_offset.Sched.QueueDef * index;
+	else if (address == TM.Drop.QueueCoSConf)
+		*offset = tm_index_offset.Drop.QueueCoSConf * index;
+
+	else if (address == TM.Sched.ClvlShpBucketLvls)
+		*offset = tm_index_offset.Sched.ClvlShpBucketLvls * index;
+	else if (address == TM.Sched.PortShpBucketLvls)
+		*offset = tm_index_offset.Sched.PortShpBucketLvls * index;
+	else if (address == TM.Sched.BlvlShpBucketLvls)
+		*offset = tm_index_offset.Sched.BlvlShpBucketLvls * index;
+	else if (address == TM.Sched.AlvlShpBucketLvls)
+		*offset = tm_index_offset.Sched.AlvlShpBucketLvls * index;
+	else if (address == TM.Drop.AlvlDropProb)
+		*offset = tm_index_offset.Drop.AlvlDropProb * index;
+	else if (address == TM.Drop.ClvlDropProb)
+		*offset = tm_index_offset.Drop.ClvlDropProb * index;
+	else if (address == TM.Drop.BlvlDropProb)
+		*offset = tm_index_offset.Drop.BlvlDropProb * index;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs.c
new file mode 100644
index 0000000..301bb0b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs.c
@@ -0,0 +1,1146 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_sysfs_debug.h"
+#include "tm_sysfs_drop.h"
+#include "tm_sysfs_shaping.h"
+#include "mv_tm_drop.h"
+#include "mv_tm_sched.h"
+#include "mv_tm_shaping.h"
+#include "mv_tm_scheme.h"
+
+#define PR_ERR_CODE(_rc)	\
+{							\
+	pr_err("%s: operation failed (rc=%d)\n", __func__, _rc);	\
+}
+
+#define PR_INFO_CALLED		\
+{							\
+	pr_info("%s is called\n", attr->attr.name);	\
+}
+
+static struct qmtm **hndl;
+
+static ssize_t mv_tm_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cd                         debug               - move to TM Debug sysfs directory\n");
+	o += scnprintf(b+o, s-o, "cd                         drop                - move to TM Drop sysfs directory\n");
+	o += scnprintf(b+o, s-o, "cd                         shaping             - move to TM Shaping sysfs directory\n");
+	o += scnprintf(b+o, s-o, "echo [sc]                > config              - create default tree configuration\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]             > node_show           - show node's parameters (SW DB)\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]             > node_show_hw        - show node's parameters (HW)\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [pr]        > prio_set            - set node's priority\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]             > prio_set_propagated - set node's propagated priority\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [w]         > dwrr_weight         - set node's DWRR weight\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [pr] [0|1]  > dwrr_enable         - enable/disable DWRR for the priority on node\n");
+	o += scnprintf(b+o, s-o, "echo [0|1]               > dequeue             - enable/disable DeQ tree status\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	o += scnprintf(b+o, s-o, "parameters:\n");
+	o += scnprintf(b+o, s-o, "        [l]       - level: 4-Port, 3-C level, 2-B level, 1-A level, 0-Queue\n");
+	o += scnprintf(b+o, s-o, "        [i]       - index\n");
+	o += scnprintf(b+o, s-o, "        [sc]      - scenario: 0 - defcon, 1 - cfg1, 2 - 2xPPC, 3 - cfg3 tree\n");
+	o += scnprintf(b+o, s-o, "        [w]       - DWRR weight [in 256 bytes units]\n");
+	o += scnprintf(b+o, s-o, "        [pr]      - priority [0-7]\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+
+static ssize_t mv_tm_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		off = mv_tm_help(buf);
+	else if (!strcmp(name, "debug")) {
+		pr_info("debug\n");
+	} else if (!strcmp(name, "drop")) {
+		pr_info("drop\n");
+	} else if (!strcmp(name, "shaping")) {
+		pr_info("shaping\n");
+	} else
+		off = mv_tm_help(buf);
+
+	return off;
+}
+
+
+static ssize_t mv_tm_config(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err = 0;
+	unsigned long   flags = 0;
+
+	u32 level = 0;
+	u32 index = 0;
+	u32 en = 0;
+	u32 prio = 0;
+	int fields;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "config")) {
+		u32 sc = 0;
+		fields = sscanf(buf, "%u", &sc);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		if (sc == 0) {
+			pr_info("Configure default tree scenario\n");
+			err = tm_defcon();
+		} else if (sc == 1) {
+			pr_info("Configure cfg1 scenario\n");
+			err = tm_cfg1();
+		} else if (sc == 2) {
+			pr_info("Configure 2xPPC scenario\n");
+			err = tm_2xppc();
+		} else if (sc == 3) {
+			pr_info("Configure cfg3 scenario\n");
+			err = tm_cfg3_tree();
+		} else {
+			err = 1;
+			pr_info("unknown configuration.\n");
+		}
+		if (err)
+			PR_ERR_CODE(err)
+		else
+			pr_info("Configuration completed successfuly\n");
+	} else if (!strcmp(name, "node_show")) {
+		int parent;
+
+		fields = sscanf(buf, "%d %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_node_show(%d, %u) is called\n",
+				level,
+				index);
+		err = tm_sysfs_read_node(level, (u16)index);
+		if (err)
+			PR_ERR_CODE(err)
+
+		if (!mv_tm_scheme_parent_node_get(level, index, &parent))
+			pr_info("Parent node is: %s #%d\n", tm_sysfs_level_str(level + 1), parent);
+	} else if (!strcmp(name, "node_show_hw")) {
+		fields = sscanf(buf, "%d %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_node_show_hw(%d, %u) is called\n",
+				level,
+				index);
+		err = tm_sysfs_read_node_hw(level, (u16)index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "prio_set")) {
+		fields = sscanf(buf, "%d %u %u", &level, &index, &prio);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_prio_set(%d, %u, %u) is called\n",
+				level,
+				index,
+				prio);
+		err = mv_tm_prio_set(level, (u16)index, prio);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "prio_set_propagated")) {
+		fields = sscanf(buf, "%d %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_prio_set_propagated(%d, %u) is called\n",
+				level,
+				index);
+		err = mv_tm_prio_set_propagated(level, (u16)index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "dwrr_weight")) {
+		u32 quantum = 0;
+		fields = sscanf(buf, "%d %u %u", &level, &index, &quantum);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("dwrr_weight(%d %u %u) is called\n",
+				level, index, quantum);
+		err = mv_tm_dwrr_weight(level, (u16)index, quantum);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "dwrr_enable")) {
+		fields = sscanf(buf, "%d %u %u %u", &level, &index, &prio, &en);
+		err = (fields != 4) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("dwrr_enable(%d %u %u %u) is called\n",
+				level, index, prio, en);
+		err = mv_tm_dwrr_enable(level, (u16)index, (u8)prio, (u8)en);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "dequeue")) {
+		fields = sscanf(buf, "%u", &en);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_dequeue( %u) is called\n", en);
+		err = mv_tm_tree_status_set((u8)en);
+		if (err)
+			PR_ERR_CODE(err)
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+/* SYSFS initialization */
+static DEVICE_ATTR(help,			S_IRUSR, mv_tm_show, NULL);
+static DEVICE_ATTR(config,			S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(node_show,			S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(node_show_hw,		S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(prio_set,			S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(prio_set_propagated,		S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(dwrr_weight,			S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(dwrr_enable,			S_IWUSR, NULL, mv_tm_config);
+static DEVICE_ATTR(dequeue,			S_IWUSR, NULL, mv_tm_config);
+
+static struct attribute *mv_tm_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_config.attr,
+	&dev_attr_node_show.attr,
+	&dev_attr_node_show_hw.attr,
+	&dev_attr_prio_set.attr,
+	&dev_attr_prio_set_propagated.attr,
+	&dev_attr_dwrr_weight.attr,
+	&dev_attr_dwrr_enable.attr,
+	&dev_attr_dequeue.attr,
+	NULL
+};
+
+static struct attribute_group mv_tm_group = {
+	.attrs = mv_tm_attrs,
+};
+
+
+/*********/
+/* Debug */
+/*********/
+static ssize_t mv_tm_debug_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cat                      help_debug           - show this help\n");
+	o += scnprintf(b+o, s-o, "cat                      open                 - initiate TM module\n");
+	o += scnprintf(b+o, s-o, "cat                      close                - close TM module\n");
+	o += scnprintf(b+o, s-o, "cat                      ports_name           - print tm ports name\n");
+#if 0 /* TBD */
+	o += scnprintf(b+o, s-o, "cat                      drop_errors          - dump drop errors\n");
+#endif
+	o += scnprintf(b+o, s-o, "echo [0|1]             > enable_debug         - enable debug printing\n");
+	o += scnprintf(b+o, s-o, "echo [a] [l32] [h32]   > write_tm_reg         - write [l32] [h32] to tm reg [a]\n");
+	o += scnprintf(b+o, s-o, "echo [a]               > read_tm_reg          - read tm reg [a]\n");
+	o += scnprintf(b+o, s-o, "echo [a] [cnt] [int]   > dump_tm_regs         - dump tm regs\n");
+	o += scnprintf(b+o, s-o, "echo [i]               > dump_port_hw         - print tm tree under port from HW\n");
+	o += scnprintf(b+o, s-o, "echo [timeout]         > trace_queues         - trace packet path in tm (Qs only)\n");
+	o += scnprintf(b+o, s-o, "echo [timeout]         > trace_path           - trace packet path in tm\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]           > dump_elig_func       - print eligible function value\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [elig]    > set_elig             - set node's eligible function\n");
+	o += scnprintf(b+o, s-o, "echo [q1] [q2] [elig]  > set_elig_per_q_range - set eligible function per queues range\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	o += scnprintf(b+o, s-o, "parameters:\n");
+	o += scnprintf(b+o, s-o, "        [l]       - level: 4-Port, 3-C level, 2-B level, 1-A level, 0-Queue\n");
+	o += scnprintf(b+o, s-o, "        [i]       - index\n");
+	o += scnprintf(b+o, s-o, "        [a]       - register address\n");
+	o += scnprintf(b+o, s-o, "        [l32]     - register value - low 32 bits\n");
+	o += scnprintf(b+o, s-o, "        [h32]     - register value - high 32 bits\n");
+	o += scnprintf(b+o, s-o, "        [cnt]     - count\n");
+	o += scnprintf(b+o, s-o, "        [int]     - intervals\n");
+	o += scnprintf(b+o, s-o, "        [timeout] - timeout in seconds\n");
+	o += scnprintf(b+o, s-o, "        [elig]    - eligible priority function [0-63]\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+
+static ssize_t mv_tm_debug_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help_debug"))
+		off = mv_tm_debug_help(buf);
+	else if (!strcmp(name, "open")) {
+		PR_INFO_CALLED
+		off = tm_open();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+		else
+			pr_info("TM open completed successfuly, handle is (0x%X)\n", (u32)hndl);
+	} else if (!strcmp(name, "close")) {
+		PR_INFO_CALLED
+		off = tm_close();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+		else
+			pr_info("TM close completed successfuly\n");
+	} else if (!strcmp(name, "ports_name")) {
+		off = tm_sysfs_print_ports_name();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+#if 0 /* TBD */
+	} else if (!strcmp(name, "drop_errors")) {
+		struct tm_error_info info;
+		off = tm_drop_get_errors(hndl, &info);
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+		else {
+			pr_info("Drop Errors:\n");
+			pr_info("    error counter		= %d\n", info.error_counter);
+			pr_info("    exception counter  = %d\n", info.exception_counter);
+		}
+#endif
+	} else if (!strcmp(name, "help"))
+		off = mv_tm_debug_help(buf);
+	else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+
+static ssize_t mv_tm_debug_config(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err = 0;
+	unsigned long   flags = 0;
+
+	int l, i;
+	u32 en = 0;
+	u32 reg_addr = 0;
+	u32 reg_val[2] = {0, 0};
+	u32 index = 0;
+	u32 elig = 0;
+	u32 timeout = 5;
+	int fields;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "enable_debug")) {
+		fields = sscanf(buf, "%u", &en);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		err = tm_sysfs_enable_debug(en);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "write_tm_reg")) {
+		fields = sscanf(buf, "%x %x %x", &reg_addr, &reg_val[0], &reg_val[1]);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		mv_pp3_hw_write(reg_addr + mv_pp3_nss_regs_vaddr_get(), 2, reg_val);
+	} else if (!strcmp(name, "read_tm_reg")) {
+		fields = sscanf(buf, "%x", &reg_addr);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		mv_pp3_hw_read(reg_addr + mv_pp3_nss_regs_vaddr_get(), 2, reg_val);
+		for (i = 0; i < 2; i++)
+			pr_info("0x%x = 0x%08x\n", reg_addr+i*4, reg_val[i]);
+	} else if (!strcmp(name, "dump_tm_regs")) {
+		u32 cnt = 1, interval = 1;
+		fields = sscanf(buf, "%x %u %u", &reg_addr, &cnt, &interval);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("Dumping TM regs: Reg: 0x%x, Count: %u, Interval: %u\n", reg_addr, cnt, interval);
+		for (i = 0; i < cnt; i++) {
+			mv_pp3_hw_read(reg_addr + mv_pp3_nss_regs_vaddr_get() , 2, reg_val);
+			pr_info("0x%x = 0x%08x\n", reg_addr+0*4, reg_val[0]);
+			pr_info("0x%x = 0x%08x\n", reg_addr+1*4, reg_val[1]);
+			reg_addr += 8 * interval;
+		}
+	} else if (!strcmp(name, "dump_port_hw")) {
+		fields = sscanf(buf, "%u", &index);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_sysfs_dump_port_hw(%u) is called\n", index);
+		err = tm_sysfs_dump_port_hw(index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "trace_queues")) {
+		fields = sscanf(buf, "%u", &timeout);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		err = tm_sysfs_trace_queues(timeout, 0);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "trace_path")) {
+		fields = sscanf(buf, "%u", &timeout);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		err = tm_sysfs_trace_queues(timeout, 1);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "dump_elig_func")) {
+		fields = sscanf(buf, "%u %u", &l, &i);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		err = tm_sysfs_show_elig_func(l, i);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "set_elig")) {
+		fields = sscanf(buf, "%d %u %u", &l, &index, &elig);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_set_elig(%d, %u, %u) is called\n",
+				l,
+				index,
+				elig);
+		err = tm_sysfs_set_elig(l, (u16)index, elig);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "set_elig_per_q_range")) {
+		u32 start;
+		u32 end;
+		fields = sscanf(buf, "%d %u %u", &start, &end, &elig);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		err = tm_sysfs_set_elig_per_queue_range(start, end, elig);
+		if (err)
+			PR_ERR_CODE(err)
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help_debug,				S_IRUSR, mv_tm_debug_show, NULL);
+static DEVICE_ATTR(open,					S_IRUSR, mv_tm_debug_show, NULL);
+static DEVICE_ATTR(close,					S_IRUSR, mv_tm_debug_show, NULL);
+static DEVICE_ATTR(ports_name,				S_IRUSR, mv_tm_debug_show, NULL);
+#if 0 /* TBD */
+static DEVICE_ATTR(drop_errors,				S_IRUSR, mv_tm_debug_show, NULL);
+#endif
+static DEVICE_ATTR(enable_debug,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(write_tm_reg,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(read_tm_reg,				S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(dump_tm_regs,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(dump_port_hw,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(trace_queues,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(trace_path,				S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(dump_elig_func,			S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(set_elig,				S_IWUSR, NULL, mv_tm_debug_config);
+static DEVICE_ATTR(set_elig_per_q_range,	S_IWUSR, NULL, mv_tm_debug_config);
+
+static struct attribute *mv_tm_debug_attrs[] = {
+	&dev_attr_help_debug.attr,
+	&dev_attr_open.attr,
+	&dev_attr_close.attr,
+	&dev_attr_ports_name.attr,
+#if 0 /* TBD */
+	&dev_attr_drop_errors.attr,
+#endif
+	&dev_attr_enable_debug.attr,
+	&dev_attr_write_tm_reg.attr,
+	&dev_attr_read_tm_reg.attr,
+	&dev_attr_dump_tm_regs.attr,
+	&dev_attr_dump_port_hw.attr,
+	&dev_attr_trace_queues.attr,
+	&dev_attr_trace_path.attr,
+	&dev_attr_dump_elig_func.attr,
+	&dev_attr_set_elig.attr,
+	&dev_attr_set_elig_per_q_range.attr,
+	NULL
+};
+
+static struct attribute_group mv_tm_debug_group = {
+	.name = "debug",
+	.attrs = mv_tm_debug_attrs,
+};
+
+
+/********/
+/* Drop */
+/********/
+static ssize_t mv_tm_drop_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cat                          help_drop         - show this help\n");
+	o += scnprintf(b+o, s-o, "cat                          profiles          - show all existing Drop profiles\n");
+	o += scnprintf(b+o, s-o, "cat                          curves            - show all existing WRED curves\n");
+	o += scnprintf(b+o, s-o, "cat                          params_show       - show configured parameters\n");
+
+	o += scnprintf(b+o, s-o, "echo [thr]                 > cbtd_thr_set      - set CBTD threshold\n");
+	o += scnprintf(b+o, s-o, "echo [clr][thr]            > catd_thr_set      - set CATD threshold\n");
+	o += scnprintf(b+o, s-o, "echo [clr][min][max]       > wred_thr_set      - set WRED thresholds\n");
+	o += scnprintf(b+o, s-o, "echo [clr][cur][sc]        > wred_curve_set    - set WRED curve index and scaling\n");
+
+	o += scnprintf(b+o, s-o, "echo [l][i][cos]           > profile_set       - update Drop Profile params to HW\n");
+	o += scnprintf(b+o, s-o, "echo [l][i][cos]           > profile_clear     - set Drop Profile to default\n");
+	o += scnprintf(b+o, s-o, "echo [l][i][cos]           > profile_show      - show Drop profile's parameters\n");
+
+	/* Configuration by BW */
+	o += scnprintf(b+o, s-o, "echo [l][i][cos][cb][wred] > wred_profile_set  - update Drop Profile (CBTD & WRED)\n");
+	o += scnprintf(b+o, s-o, "echo [l][i][cos][cb][ca]   > catd_profile_set  - update Drop Profile (CBTD & CATD)\n");
+	o += scnprintf(b+o, s-o, "echo [l][i][cos]           > profile_bw_show   - show Drop profile's parameters (in BW)\n");
+
+	o += scnprintf(b+o, s-o, "echo [l][cos][mp]          > wred_curve_create - create traditional WRED curve\n");
+	o += scnprintf(b+o, s-o, "echo [l][1|2|3]            > color_num_set     - set number of colors\n");
+	o += scnprintf(b+o, s-o, "echo [i][cos]              > queue_cos_set     - queue cos select\n");
+	o += scnprintf(b+o, s-o, "echo [l][i][cos][dp]       > profile_ptr_set   - update Node's pointer to Drop Profile\n");
+#ifdef MV_QMTM_NSS_A0
+	o += scnprintf(b+o, s-o, "echo [l][c][s]             > dp_source_set\n");
+	o += scnprintf(b+o, s-o, "echo [l][dp]               > set_drop_query_responce\n");
+#endif
+	o += scnprintf(b+o, s-o, "\n");
+
+	o += scnprintf(b+o, s-o, "parameters:\n");
+	o += scnprintf(b+o, s-o, "        [l]      - level: 4-Port, 3-C level, 2-B level, 1-A level, 0-Queue\n");
+	o += scnprintf(b+o, s-o, "        [i]      - index\n");
+	o += scnprintf(b+o, s-o, "        [cos]    - cos [0-7, '-1' - if not relevant]\n");
+	o += scnprintf(b+o, s-o, "        [clr]    - color: 0-Green, 1-Yellow, 2-Red, 7-All\n");
+	o += scnprintf(b+o, s-o, "        [cur]    - curve index\n");
+	o += scnprintf(b+o, s-o, "        [sc]     - curve scaling\n");
+	o += scnprintf(b+o, s-o, "        [thr]    - TD threshold [burst = 16 bytes]\n");
+	o += scnprintf(b+o, s-o, "        [min]    - min threshold [burst = 16 bytes]\n");
+	o += scnprintf(b+o, s-o, "        [max]    - max threshold [burst = 16 bytes]\n");
+	o += scnprintf(b+o, s-o, "        [cb]     - color blind TD bw [Kbps]\n");
+	o += scnprintf(b+o, s-o, "        [ca]     - color aware TD bw [Kbps]\n");
+	o += scnprintf(b+o, s-o, "        [wred]   - WRED bw [Kbps]\n");
+	o += scnprintf(b+o, s-o, "        [mp]     - maximum probability [1-100]\n");
+	o += scnprintf(b+o, s-o, "        [dp]     - drop profile index\n");
+
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+
+static ssize_t mv_tm_drop_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help_drop"))
+		off = mv_tm_drop_help(buf);
+	else if (!strcmp(name, "profiles")) {
+		PR_INFO_CALLED
+		off = tm_sysfs_read_drop_profiles();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+	} else if (!strcmp(name, "curves")) {
+		PR_INFO_CALLED
+		off = tm_sysfs_read_wred_curves();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+	} else if (!strcmp(name, "params_show")) {
+		PR_INFO_CALLED
+		off = tm_sysfs_params_show();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+	} else if (!strcmp(name, "help"))
+		off = mv_tm_debug_help(buf);
+	else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+
+static ssize_t mv_tm_drop_config(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err = 0;
+	unsigned long   flags = 0;
+
+	u32 level;
+	u32 index;
+	int cos;
+	int color = 0;
+	u32 threshold = 0;
+	u32 cb_bw = 0;
+	u32 ca_wred_bw = 0;
+	int fields;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "cbtd_thr_set")) {
+		fields = sscanf(buf, "%u", &threshold);
+		err = (fields != 1) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_cbtd_thr_set(%u) is called\n",
+				threshold);
+		err = tm_sysfs_cbtd_thr_set(threshold);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "catd_thr_set")) {
+		fields = sscanf(buf, "%d %u", &color, &threshold);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_catd_thr_set(%d, %u) is called\n",
+				color,
+				threshold);
+		err = tm_sysfs_catd_thr_set(color, threshold);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "wred_thr_set")) {
+		u32 min_thr = 0;
+		u32 max_thr = 0;
+		fields = sscanf(buf, "%d %u %u", &color, &min_thr, &max_thr);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_wred_thr_set(%d, %u, %u) is called\n",
+				color,
+				min_thr,
+				max_thr);
+		err = tm_sysfs_wred_thr_set(color, min_thr, max_thr);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "wred_curve_set")) {
+		u32 scale = 0;
+		fields = sscanf(buf, "%d %u %u", &color, &index, &scale);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_wred_curve_set(%d, %u, %u) is called\n",
+				color,
+				index,
+				scale);
+		err = tm_sysfs_wred_curve_set(color, index, scale);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "profile_set")) {
+		fields = sscanf(buf, "%u %u %d", &level, &index, &cos);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_profile_set(%u, %u, %d) is called\n",
+				level,
+				index,
+				cos);
+		err = tm_sysfs_drop_profile_set(level, (u16)index, cos);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "profile_clear")) {
+		fields = sscanf(buf, "%u %u %d", &level, &index, &cos);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_profile_clear(%u, %u, %d) is called\n",
+				level,
+				index,
+				cos);
+		err = mv_tm_drop_profile_clear(level, index, cos);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "profile_show")) {
+		fields = sscanf(buf, "%u %u %d", &level, &index, &cos);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_profile_show(%u, %u, %d) is called\n",
+			level,
+			index,
+			cos);
+		err = tm_sysfs_read_drop_profile(level, cos, (u16)index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "wred_profile_set")) {
+		fields = sscanf(buf, "%u %u %d %u %u", &level, &index, &cos, &cb_bw, &ca_wred_bw);
+		err = (fields != 5) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_wred_profile_set(%u, %u, %d, %u, %u) is called\n",
+				level,
+				index,
+				cos,
+				cb_bw,
+				ca_wred_bw);
+		err = mv_tm_update_drop_profile_wred(level, cos, index, cb_bw, ca_wred_bw);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "catd_profile_set")) {
+		fields = sscanf(buf, "%u %u %d %u %u", &level, &index, &cos, &cb_bw, &ca_wred_bw);
+		err = (fields != 5) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_catd_profile_set(%u, %u, %d, %u, %u) is called\n",
+				level,
+				index,
+				cos,
+				cb_bw,
+				ca_wred_bw);
+		err = mv_tm_update_drop_profile_catd(level, cos, index, cb_bw, ca_wred_bw);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "profile_bw_show")) {
+		fields = sscanf(buf, "%u %u %d", &level, &index, &cos);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("profile_bw_show(%u, %u, %d) is called\n",
+			level,
+			index,
+			cos);
+		err = tm_sysfs_read_drop_profile_bw(level, cos, (u16)index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "wred_curve_create")) {
+		u32 mp;
+		fields = sscanf(buf, "%u %d %u", &level, &cos, &mp);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_create_wred_curve (%u %d %u) is called\n",
+			level,
+			cos,
+			mp);
+		err = mv_tm_create_wred_curve(level, cos, mp, (uint8_t *)&index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "color_num_set")) {
+		fields = sscanf(buf, "%u %d", &level, &color);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_color_num_set(%u, %d) is called\n",
+				level,
+				color);
+		err = mv_tm_color_num_set(level, color);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "queue_cos_set")) {
+		fields = sscanf(buf, "%u %d", &index, &cos);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_queue_cos_set(%u, %d) is called\n",
+			index,
+			cos);
+		err = mv_tm_queue_cos_set(index, cos);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "profile_ptr_set")) {
+		u32 dp = 0;
+		fields = sscanf(buf, "%u %u %d %u", &level, &index, &cos, &dp);
+		err = (fields != 4) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("tm_profile_ptr_set(%u, %u, %d, %u) is called\n",
+			level,
+			index,
+			cos,
+			dp);
+		err = mv_tm_dp_set(level, index, cos, dp);
+		if (err)
+			PR_ERR_CODE(err)
+#if 0
+	} else if (!strcmp(name, "dp_source_set")) {
+		/* Read pool and value */
+		sscanf(buf, "%d %d %d", &level, &color, &source);
+		rc = tm_dp_source_set(hndl, level, color, source);
+		if (rc)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("set_drop_color_num: Level %d color %d source %d\n", level, color, source);
+	}
+	else if (!strcmp(name, "set_drop_query_responce")) {
+		/* Read pool and value */
+		sscanf(buf, "%d %d", &level, &port_dp);
+		rc = tm_set_drop_query_responce(hndl, port_dp, level);
+		if (rc)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("set_drop_query_responce: Level %d port_dp %d\n", level, port_dp);
+#endif
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help_drop,			S_IRUSR, mv_tm_drop_show, NULL);
+static DEVICE_ATTR(profiles,			S_IRUSR, mv_tm_drop_show, NULL);
+static DEVICE_ATTR(curves,				S_IRUSR, mv_tm_drop_show, NULL);
+static DEVICE_ATTR(params_show,			S_IRUSR, mv_tm_drop_show, NULL);
+static DEVICE_ATTR(cbtd_thr_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(catd_thr_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(wred_thr_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(wred_curve_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(profile_set,			S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(profile_clear,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(profile_show,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(wred_profile_set,	S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(catd_profile_set,	S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(profile_bw_show,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(wred_curve_create,	S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(color_num_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(queue_cos_set,		S_IWUSR, NULL, mv_tm_drop_config);
+static DEVICE_ATTR(profile_ptr_set,		S_IWUSR, NULL, mv_tm_drop_config);
+
+static struct attribute *mv_tm_drop_attrs[] = {
+	&dev_attr_help_drop.attr,
+	&dev_attr_profiles.attr,
+	&dev_attr_curves.attr,
+	&dev_attr_params_show.attr,
+	&dev_attr_cbtd_thr_set.attr,
+	&dev_attr_catd_thr_set.attr,
+	&dev_attr_wred_thr_set.attr,
+	&dev_attr_wred_curve_set.attr,
+	&dev_attr_profile_set.attr,
+	&dev_attr_profile_clear.attr,
+	&dev_attr_profile_show.attr,
+	&dev_attr_wred_profile_set.attr,
+	&dev_attr_catd_profile_set.attr,
+	&dev_attr_profile_bw_show.attr,
+	&dev_attr_wred_curve_create.attr,
+	&dev_attr_color_num_set.attr,
+	&dev_attr_queue_cos_set.attr,
+	&dev_attr_profile_ptr_set.attr,
+	NULL
+};
+
+static struct attribute_group mv_tm_drop_group = {
+	.name = "drop",
+	.attrs = mv_tm_drop_attrs,
+};
+
+
+/***********/
+/* Shaping */
+/***********/
+static ssize_t mv_tm_shaping_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cat                                  help_shaping    - show this help\n");
+	o += scnprintf(b+o, s-o, "cat                                  shaping         - show all existing Shaping configurations\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [cir] [eir]             > set_shaping     - set shaping\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [cir]                   > set_min_shaping - set minimal shaping\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i] [cir] [eir] [cbs] [ebs] > set_shaping_ex  - set shaping including burst sizes\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]                         > set_no_shaping  - disables shaping on node\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]                         > show_shaping    - show shaping parameters (CIR & EIR only)\n");
+	o += scnprintf(b+o, s-o, "echo [l] [i]                         > show_shaping_ex - show shaping parameters (bw & burst sizes)\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	o += scnprintf(b+o, s-o, "parameters:\n");
+	o += scnprintf(b+o, s-o, "        [l]    - level: 4-Port, 3-C level, 2-B level, 1-A level, 0-Queue\n");
+	o += scnprintf(b+o, s-o, "        [i]    - index\n");
+	o += scnprintf(b+o, s-o, "        [cir]  - committed shaping rate [in resolution of 1Mb, in steps of 10Mb]\n");
+	o += scnprintf(b+o, s-o, "        [eir]  - excessive shaping rate [in resolution of 1Mb, in steps of 10Mb]\n");
+	o += scnprintf(b+o, s-o, "        [cbs]  - committed burst size [in KBytes]\n");
+	o += scnprintf(b+o, s-o, "        [ebs]  - excessive burst size [in KBytes]\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+
+static ssize_t mv_tm_shaping_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help_shaping"))
+		off = mv_tm_shaping_help(buf);
+	else if (!strcmp(name, "shaping")) {
+		PR_INFO_CALLED
+		off = tm_sysfs_read_shaping();
+		if (off != MV_OK)
+			PR_ERR_CODE(off)
+	} else if (!strcmp(name, "help"))
+		off = mv_tm_debug_help(buf);
+	else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+
+static ssize_t mv_tm_shaping_config(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err = 0;
+	unsigned long   flags = 0;
+
+	u32 level = 0;
+	u32 index = 0;
+	u32 cbw = 0;
+	u32 ebw = 0;
+	u32 cbs = 0;
+	u32 ebs = 0;
+	u8 elig_fun = 0;
+	u8 mask = 0;
+
+	int fields;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+	if (!strcmp(name, "set_shaping_ex")) {
+		fields = sscanf(buf, "%u %u %u %u %u %u", &level, &index, &cbw, &ebw, &cbs, &ebs);
+		err = (fields != 6) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("set_shaping_ex( %u, %u, %u, %u %u %u) is called\n",
+				level,
+				index,
+				cbw,
+				ebw,
+				cbs,
+				ebs);
+		err = mv_tm_set_shaping_ex((enum mv_tm_level)level, index, cbw, ebw, &cbs, &ebs);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "set_shaping")) {
+		fields = sscanf(buf, "%u %u %u %u", &level, &index, &cbw, &ebw);
+		err = (fields != 4) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("set_shaping( %u, %u, %u, %u) is called\n",
+				level,
+				index,
+				cbw,
+				ebw);
+		err = mv_tm_set_shaping((enum mv_tm_level)level, index, cbw, ebw);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "set_min_shaping")) {
+		fields = sscanf(buf, "%u %u %u", &level, &index, &cbw);
+		err = (fields != 3) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("set_min_shaping( %u, %u, %u) is called\n",
+				level,
+				index,
+				cbw);
+		err = mv_tm_set_min_shaping((enum mv_tm_level)level, index, cbw);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "set_no_shaping")) {
+		fields = sscanf(buf, "%u %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("set_no_shaping( %u, %u) is called\n",
+				level,
+				index);
+		err = mv_tm_set_no_shaping((enum mv_tm_level)level, index);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "show_shaping")) {
+		fields = sscanf(buf, "%u %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("show_shaping( %u, %u) is called\n",
+				level,
+				index);
+		err = mv_tm_get_shaping((enum mv_tm_level)level, index, &cbw, &ebw);
+		pr_info("cir:	%d\n", cbw);
+		pr_info("eir:	%d\n", ebw);
+		if (err)
+			PR_ERR_CODE(err)
+	} else if (!strcmp(name, "show_shaping_ex")) {
+		fields = sscanf(buf, "%u %u", &level, &index);
+		err = (fields != 2) ? 1 : 0;
+		if (err)
+			PR_ERR_CODE(err)
+		pr_info("show_shaping_ex( %u, %u) is called\n",
+				level,
+				index);
+		err = mv_tm_get_shaping_full_info((enum mv_tm_level)level, index, &elig_fun, &mask, &cbw, &ebw, &cbs, &ebs);
+		pr_info("Eligible function  : %d\n", elig_fun);
+		if (mask & 2)
+			pr_info("  cir:	%8d(Mb/s)     cbs: %4d(KBytes)\n", cbw, cbs);
+		else
+			pr_info("  cir:	%8d(Mb/s)     cbs: %4d(KBytes)  (shaper not used!)\n", cbw, cbs);
+		if (mask & 1)
+			pr_info("  eir:	%8d(Mb/s)     ebs: %4d(KBytes)\n", ebw, ebs);
+		else
+			pr_info("  eir:	%8d(Mb/s)     ebs: %4d(KBytes)  (shaper not used!)\n", ebw, ebs);
+		if (err)
+			PR_ERR_CODE(err)
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help_shaping,			S_IRUSR, mv_tm_shaping_show, NULL);
+static DEVICE_ATTR(shaping,					S_IRUSR, mv_tm_shaping_show, NULL);
+static DEVICE_ATTR(set_shaping,				S_IWUSR, NULL, mv_tm_shaping_config);
+static DEVICE_ATTR(set_min_shaping,			S_IWUSR, NULL, mv_tm_shaping_config);
+static DEVICE_ATTR(set_shaping_ex,			S_IWUSR, NULL, mv_tm_shaping_config);
+static DEVICE_ATTR(set_no_shaping,			S_IWUSR, NULL, mv_tm_shaping_config);
+static DEVICE_ATTR(show_shaping,			S_IWUSR, NULL, mv_tm_shaping_config);
+static DEVICE_ATTR(show_shaping_ex,			S_IWUSR, NULL, mv_tm_shaping_config);
+
+static struct attribute *mv_tm_shaping_attrs[] = {
+	&dev_attr_help_shaping.attr,
+	&dev_attr_shaping.attr,
+	&dev_attr_set_shaping.attr,
+	&dev_attr_set_min_shaping.attr,
+	&dev_attr_set_shaping_ex.attr,
+	&dev_attr_set_no_shaping.attr,
+	&dev_attr_show_shaping.attr,
+	&dev_attr_show_shaping_ex.attr,
+	NULL
+};
+
+static struct attribute_group mv_tm_shaping_group = {
+	.name = "shaping",
+	.attrs = mv_tm_shaping_attrs,
+};
+
+
+/*******************************/
+/* SysFS Init & Exit functions */
+/*******************************/
+int mv_pp3_tm_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+	struct kobject *tm_kobj;
+
+	tm_kobj = kobject_create_and_add("tm", pp3_kobj);
+	if (!tm_kobj) {
+		pr_err(KERN_ERR"%s: cannot create tm kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(tm_kobj, &mv_tm_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for tm%d\n", err);
+		return err;
+	}
+
+	err = sysfs_create_group(tm_kobj, &mv_tm_debug_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for tm debug%d\n", err);
+		return err;
+	}
+
+	err = sysfs_create_group(tm_kobj, &mv_tm_drop_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for tm drop%d\n", err);
+		return err;
+	}
+
+	err = sysfs_create_group(tm_kobj, &mv_tm_shaping_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for tm shaping%d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+
+int mv_pp3_tm_sysfs_exit(struct kobject *tm_kobj)
+{
+	sysfs_remove_group(tm_kobj, &mv_tm_group);
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.c
new file mode 100644
index 0000000..7716ccd
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.c
@@ -0,0 +1,471 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_sysfs_debug.h"
+#include "tm/mv_tm.h"
+
+#include "tm_os_interface.h"
+#include "tm_nodes_update.h"
+#include "tm_nodes_read.h"
+#include "tm_nodes_status.h"
+#include "tm_sched.h"
+#include "set_hw_registers.h"
+
+uint8_t tm_debug_on;
+
+const char *tm_sysfs_level_str(int level)
+{
+	const char *str;
+
+	switch (level) {
+	case Q_LEVEL:
+		str = "Queue";
+		break;
+	case A_LEVEL:
+		str = "Anode";
+		break;
+	case B_LEVEL:
+		str = "Bnode";
+		break;
+	case C_LEVEL:
+		str = "Cnode";
+		break;
+	case P_LEVEL:
+		str = "Port";
+		break;
+	default:
+		str = "Unknown";
+	}
+	return str;
+}
+
+int tm_sysfs_enable_debug(uint8_t en)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if ((en != TM_ENABLE) && (en != TM_DISABLE))
+		pr_info("Error: en should be TM_ENABLE/TM_DISABLE\n");
+	tm_debug_on = en;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_read_node(int level, uint16_t index)
+{
+	int i;
+	uint32_t cos = TM_INVAL;
+	struct tm_queue_params q_params = {0};
+	struct tm_a_node_params a_params = {0};
+	struct tm_b_node_params b_params = {0};
+	struct tm_c_node_params c_params = {0};
+	struct tm_port_params params;
+	struct tm_port_drop_per_cos cos_params = {0};
+	uint32_t av_queue_length;
+	uint32_t first_child;
+	uint32_t last_child;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	tm_memset(&params, 0, sizeof(struct tm_port_params));
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = tm_read_queue_configuration(ctl, index, &q_params);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", q_params.elig_prio_func_ptr);
+			pr_info("Priority:		%d\n", tm_elig_to_prio(ctl, Q_LEVEL, q_params.elig_prio_func_ptr));
+			pr_info("Drop profile index:		%d\n", q_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", q_params.quantum);
+		}
+		break;
+	case A_LEVEL:
+		rc = tm_read_a_node_configuration(ctl, index, &a_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", a_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, A_LEVEL, a_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index:		%d\n", a_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", a_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, a_params.dwrr_priority[i]);
+			pr_info("First child queue : %d, Last child queue : %d\n", first_child, last_child);
+		}
+		break;
+	case B_LEVEL:
+		rc = tm_read_b_node_configuration(ctl, index, &b_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", b_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, B_LEVEL, b_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index:		%d\n", b_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", b_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, b_params.dwrr_priority[i]);
+			pr_info("First child A-node : %d, Last child A-node : %d\n", first_child, last_child);
+		}
+		break;
+	case C_LEVEL:
+		rc = tm_read_c_node_configuration(ctl, index, &c_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", c_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, C_LEVEL, c_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index (per Cos):");
+			for (cos = 0; cos < 8; cos++)
+				if (c_params.wred_cos & (1 << cos))
+					pr_info("	Cos %d:		%d\n", cos, c_params.wred_profile_ref[cos]);
+			pr_info("Quantum value:		%d\n", c_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, c_params.dwrr_priority[i]);
+			pr_info("First child B-node : %d, Last child B-node : %d\n", first_child, last_child);
+		}
+		break;
+	case P_LEVEL:
+		rc = tm_read_port_configuration(ctl, index, &params, &cos_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, P_LEVEL, params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index (Global):	%d\n", params.wred_profile_ref);
+			pr_info("Drop profile index (per Cos):");
+			for (cos = 0; cos < 8; cos++)
+				if (cos_params.wred_cos & (1 << cos))
+					pr_info("	Cos %d:	%d\n", cos, cos_params.wred_profile_ref[cos]);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, params.dwrr_priority[i]);
+			pr_info("First child C-node : %d, Last child C-node : %d\n", first_child, last_child);
+		}
+		break;
+	}
+	if (rc) {
+		pr_info("tm_read_node error: %d\n", rc);
+		goto out;
+	}
+
+	rc = tm_drop_get_queue_length(ctl, level, index, &av_queue_length);
+	if (rc != 0)
+		pr_info("tm_drop_get_queue_length error: %d\n", rc);
+	else
+		pr_info("Queue Length:	%d\n", (int)av_queue_length);
+
+out:
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_read_node_hw(int level, uint16_t index)
+{
+	int i;
+	uint32_t cos = TM_INVAL;
+	struct tm_queue_params q_params = {0};
+	struct tm_a_node_params a_params = {0};
+	struct tm_b_node_params b_params = {0};
+	struct tm_c_node_params c_params = {0};
+	struct tm_port_params params;
+	struct tm_port_drop_per_cos cos_params = {0};
+	uint32_t av_queue_length;
+	uint32_t first_child;
+	uint32_t last_child;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	tm_memset(&params, 0, sizeof(struct tm_port_params));
+
+	switch (level) {
+	case Q_LEVEL:
+		rc = tm_read_queue_configuration_hw(ctl, index, &q_params);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", q_params.elig_prio_func_ptr);
+			pr_info("Priority:		%d\n", tm_elig_to_prio(ctl, Q_LEVEL, q_params.elig_prio_func_ptr));
+			pr_info("Drop profile index:		%d\n", q_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", q_params.quantum);
+		}
+		break;
+	case A_LEVEL:
+		rc = tm_read_a_node_configuration_hw(ctl, index, &a_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", a_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, A_LEVEL, a_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index:		%d\n", a_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", a_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, a_params.dwrr_priority[i]);
+			pr_info("First child queue : %d, Last child queue : %d\n", first_child, last_child);
+		}
+		break;
+	case B_LEVEL:
+		rc = tm_read_b_node_configuration_hw(ctl, index, &b_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", b_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, B_LEVEL, b_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index:		%d\n", b_params.wred_profile_ref);
+			pr_info("Quantum value:		%d\n", b_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, b_params.dwrr_priority[i]);
+			pr_info("First child A-node : %d, Last child A-node : %d\n", first_child, last_child);
+		}
+		break;
+	case C_LEVEL:
+		rc = tm_read_c_node_configuration_hw(ctl, index, &c_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", c_params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, C_LEVEL, c_params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index (per Cos) - all Cos printed:\n");
+			for (cos = 0; cos < 8; cos++)
+				pr_info("	Cos %d:		%d\n", cos, c_params.wred_profile_ref[cos]);
+			pr_info("Quantum value:		%d\n", c_params.quantum);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, c_params.dwrr_priority[i]);
+			pr_info("First child B-node : %d, Last child B-node : %d\n", first_child, last_child);
+		}
+		break;
+	case P_LEVEL:
+		rc = tm_read_port_configuration_hw(ctl, index, &params, &cos_params, &first_child, &last_child);
+		if (rc == 0) {
+			pr_info("Eligible priority function:	%d\n", params.elig_prio_func_ptr);
+			i = tm_elig_to_prio(ctl, P_LEVEL, params.elig_prio_func_ptr);
+			if (i == -1)
+				pr_info("Priority:		propagated\n");
+			else
+				pr_info("Priority:		%d\n", i);
+			pr_info("Drop profile index (Global):	%d\n", params.wred_profile_ref);
+			pr_info("Drop profile index (per Cos):");
+			for (cos = 0; cos < 8; cos++)
+				if (cos_params.wred_cos & (1 << cos))
+					pr_info("	Cos %d:	%d\n", cos, cos_params.wred_profile_ref[cos]);
+			for (i = 0; i < 8; i++)
+				pr_info("DWRR priority %d:		%d\n", i, params.dwrr_priority[i]);
+			pr_info("First child C-node : %d, Last child C-node : %d\n", first_child, last_child);
+		}
+		break;
+	}
+	if (rc) {
+		pr_info("tm_read_node_hw error: %d\n", rc);
+		goto out;
+	}
+
+	rc = tm_drop_get_queue_length(ctl, level, index, &av_queue_length);
+	if (rc != 0)
+		pr_info("tm_drop_get_queue_length error: %d\n", rc);
+	else
+		pr_info("Queue Length:	%d\n", (int)av_queue_length);
+
+out:
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_print_ports_name(void)
+{
+	int i;
+
+	for (i = 0; i < MV_TM_MAX_PORTS; i++)
+		switch (i) {
+		case TM_A0_PORT_PPC0_0:
+			pr_info("port%02d: PPC0_0\n", i);
+			break;
+		case TM_A0_PORT_PPC0_1:
+			pr_info("port%02d: PPC0_1\n", i);
+			break;
+		case TM_A0_PORT_PPC1_MNT0:
+			pr_info("port%02d: PPC1_MNT0\n", i);
+			break;
+		case TM_A0_PORT_PPC1_MNT1:
+			pr_info("port%02d: PPC1_MNT1\n", i);
+			break;
+		case TM_A0_PORT_EMAC0:
+			pr_info("port%02d: EMAC0\n", i);
+			break;
+		case TM_A0_PORT_EMAC1:
+			pr_info("port%02d: EMAC1\n", i);
+			break;
+		case TM_A0_PORT_EMAC2:
+			pr_info("port%02d: EMAC2\n", i);
+			break;
+		case TM_A0_PORT_EMAC3:
+			pr_info("port%02d: EMAC3\n", i);
+			break;
+		case TM_A0_PORT_EMAC4:
+			pr_info("port%02d: EMAC4\n", i);
+			break;
+		case TM_A0_PORT_EMAC_LPB:
+			pr_info("port%02d: EMAC_LPB\n", i);
+			break;
+		case TM_A0_PORT_CMAC_IN:
+			pr_info("port%02d: CMAC_IN\n", i);
+			break;
+		case TM_A0_PORT_CMAC_LA:
+			pr_info("port%02d: CMAC_LA\n", i);
+			break;
+		case TM_A0_PORT_HMAC:
+			pr_info("port%02d: HMAC\n", i);
+			break;
+		case TM_A0_PORT_UNUSED0:
+			pr_info("port%02d: UNUSED0\n", i);
+			break;
+		case TM_A0_PORT_DROP0:
+			pr_info("port%02d: DROP0\n", i);
+			break;
+		case TM_A0_PORT_DROP1:
+			pr_info("port%02d: DROP1\n", i);
+			break;
+		default:
+			pr_info("Error: Undefined port!\n");
+		}
+
+	return 0;
+}
+
+int tm_sysfs_dump_port_hw(uint32_t port_index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_dump_port_hw(ctl, port_index);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_trace_queues(uint32_t timeout, uint8_t full_path)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (timeout < 1000) /* else its ms*/
+		timeout *= 1000;
+
+	rc = check_hw_drop_path(ctl, timeout, full_path);
+	if (rc != 0)
+		pr_info("check_hw_drop_path error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_set_elig(int level,
+					uint16_t index,
+					uint32_t eligible)
+{
+	int i;
+	struct tm_queue_params q_params;
+	struct tm_a_node_params a_params;
+	struct tm_b_node_params b_params;
+	struct tm_c_node_params c_params;
+	uint8_t dwrr_priority[8] = {0, 0, 0, 0, 0, 0, 0, 0};
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case Q_LEVEL:
+		q_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		q_params.elig_prio_func_ptr = (uint8_t) eligible;
+		q_params.quantum = (uint16_t) TM_INVAL;
+		rc = tm_update_queue(ctl, index, &q_params);
+		break;
+	case A_LEVEL:
+		a_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		a_params.elig_prio_func_ptr = (uint8_t) eligible;
+		a_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			a_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_a_node(ctl, index, &a_params);
+		break;
+	case B_LEVEL:
+		b_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		b_params.elig_prio_func_ptr = (uint8_t) eligible;
+		b_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			b_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_b_node(ctl, index, &b_params);
+		break;
+	case C_LEVEL:
+		c_params.wred_cos = 0xff;
+		for (i = 0; i < TM_WRED_COS; i++)
+			c_params.wred_profile_ref[i] = (uint8_t) TM_INVAL;
+		c_params.elig_prio_func_ptr = (uint8_t) eligible;
+		c_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			c_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_c_node(ctl, index, &c_params);
+		break;
+	case P_LEVEL:
+		for (i = 0; i < 8; i++)
+			dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_port_scheduling(ctl, index, (uint8_t) eligible, dwrr_priority);
+		break;
+	default:
+		rc = -3;
+		break;
+	}
+	if (rc != 0)
+		pr_info("tm_set_elig error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_set_elig_per_queue_range(uint32_t startInd, uint32_t endInd, uint8_t elig)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = set_hw_elig_per_queue_range(ctl, startInd, endInd, elig);
+	if (rc != 0)
+		pr_info("set_hw_elig_per_queue_range error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_show_elig_func(int level, uint32_t func_index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = show_hw_elig_prio_func(ctl, level, func_index);
+	if (rc != 0)
+		pr_info("show_hw_elig_prio_func error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.h
new file mode 100644
index 0000000..7ed581b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_debug.h
@@ -0,0 +1,54 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_SYSFS_DEBUG__H
+#define TM_SYSFS_DEBUG__H
+
+#include "common/mv_sw_if.h"
+
+int tm_sysfs_enable_debug(uint8_t en);
+
+int tm_sysfs_read_node(int level, uint16_t index);
+
+int tm_sysfs_read_node_hw(int level, uint16_t index);
+
+int tm_sysfs_print_ports_name(void);
+
+int tm_sysfs_dump_port_hw(uint32_t port_index);
+
+int tm_sysfs_trace_queues(uint32_t timeout, uint8_t full_path);
+
+int tm_sysfs_set_elig(int level, uint16_t index, uint32_t eligible);
+
+int tm_sysfs_set_elig_per_queue_range(uint32_t startInd, uint32_t endInd, uint8_t elig);
+
+int tm_sysfs_show_elig_func(int level, uint32_t index);
+
+const char *tm_sysfs_level_str(int level);
+
+#endif /* TM_DEBUG_SYSFS__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.c
new file mode 100644
index 0000000..abffc92
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.c
@@ -0,0 +1,564 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_sysfs_drop.h"
+#include "mv_tm_drop.h"
+#include "tm/mv_tm.h"
+#include "tm_drop.h"
+#include "tm_hw_configuration_interface.h"
+#include "rm_list.h"
+#include "rm_status.h"
+
+#define TM_ALL_COLORS			7
+
+static struct mv_tm_drop_profile context;
+static uint8_t flag = TM_DISABLE;
+static char *level_names_arr[] = { "Q", "A", "B", "C", "P"};
+
+static void set_dp_default(void)
+{
+	int i;
+
+	context.color_td_en = TM_DISABLE;
+	context.cbtd_threshold = get_drop_threshold_definition() * TM_1K; /* Max */
+
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		context.curve_id[i] = 0;
+		context.curve_scale[i] = 0;
+		context.min_threshold[i] = 0x0; /* 0 Bursts */
+		context.max_threshold[i] = 0x0; /* 0 Bursts */
+	}
+}
+
+int tm_sysfs_read_drop_profiles(void)
+{
+	uint8_t cos;
+	uint16_t prof_index;
+	struct tm_drop_profile_params dp_profile;
+	int level;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	for (level = P_LEVEL; level >= Q_LEVEL; level--) {
+		if ((level == P_LEVEL) || (level == C_LEVEL)) {
+			pr_info("TM %s Level Drop Profiles Indexes (per Cos):\n", level_names_arr[level]);
+			for (cos = 0; cos < TM_WRED_COS; cos++) {
+				rc = 0;
+				for (prof_index = 1; rc == 0; prof_index++) {
+					rc = tm_read_drop_profile(ctl,
+						TM_LEVEL(level),
+						cos,
+						prof_index,
+						&dp_profile);
+					if (rc)
+						break;
+				}
+				if (prof_index - 1)
+					pr_info("   Cos %d: %d-%d\n", cos, 1, prof_index - 1);
+				else
+					pr_info("   Cos %d: None\n", cos);
+			}
+		}
+		if (level == C_LEVEL)
+			continue;
+
+		rc = 0;
+		for (prof_index = 1; rc == 0; prof_index++) {
+			rc = tm_read_drop_profile(ctl,
+				TM_LEVEL(level),
+				(uint8_t)TM_INVAL,
+				prof_index,
+				&dp_profile);
+			if (rc)
+				break;
+		}
+		if (prof_index - 1)
+			pr_info("TM %s Level Drop Profiles Indexes: %d-%d\n",
+					level_names_arr[level], 1, prof_index - 1);
+		else
+			pr_info("TM %s Level Drop Profiles Indexes: None\n",
+					level_names_arr[level]);
+	}
+
+	rc = 0;
+
+	TM_WRAPPER_END(tm_hndl);
+}
+
+int tm_sysfs_read_wred_curves(void)
+{
+	char *level_names_arr[] = { "Q", "A", "B", "C", "P"};
+
+	uint8_t cos;
+	uint8_t status;
+	uint16_t index;
+	int level;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	for (level = P_LEVEL; level >= Q_LEVEL; level--) {
+		switch (level) {
+		case P_LEVEL:
+			for (index = 1; index <= TM_NUM_WRED_PORT_CURVES; index++) {
+				rc = rm_wred_port_curve_status(ctl->rm, index, &status);
+				if (rc) {
+					rc = -1;
+					TM_WRAPPER_END(tm_hndl);
+				}
+
+				if (status == TM_DISABLE) /* end */
+					break;
+			}
+			if (index - 1)
+				pr_info("TM %s Level WRED Curves Indexes (Global): %d-%d\n",
+						level_names_arr[level], 1, index - 1);
+			else
+				pr_info("P_LEVEL!: index = %d, rc = %d, status = %d, level = %s\n", index, rc, status, level_names_arr[level]);
+				pr_info("TM %s Level WRED Curves Indexes: None\n",
+						level_names_arr[level]);
+
+			pr_info("TM %s Level WRED Curves Indexes (per Cos):\n", level_names_arr[level]);
+			for (cos = 0; cos < TM_WRED_COS; cos++) {
+				for (index = 1; index <= TM_NUM_WRED_PORT_CURVES; index++) {
+					rc = rm_wred_port_curve_status_cos(ctl->rm, cos, index, &status);
+					if (rc) {
+						rc = -1;
+						TM_WRAPPER_END(tm_hndl);
+					}
+
+					if (status == TM_DISABLE) /* end */
+						break;
+				}
+				if (index - 1)
+					pr_info("   Cos %d: %d-%d\n", cos, 1, index - 1);
+				else
+					pr_info("   Cos %d: None\n", cos);
+			}
+			break;
+
+		case C_LEVEL:
+			pr_info("TM %s Level WRED Curves Indexes (per Cos):\n", level_names_arr[level]);
+			for (cos = 0; cos < TM_WRED_COS; cos++) {
+				for (index = 1; index <= TM_NUM_WRED_PORT_CURVES; index++) {
+					rc = rm_wred_c_node_curve_status(ctl->rm, cos, index, &status);
+					if (rc) {
+						rc = -1;
+						TM_WRAPPER_END(tm_hndl);
+					}
+
+					if (status == TM_DISABLE) /* end */
+						break;
+				}
+				if (index - 1)
+					pr_info("   Cos %d: %d-%d\n", cos, 1, index - 1);
+				else
+					pr_info("   Cos %d: None\n", cos);
+			}
+			break;
+
+		case B_LEVEL:
+			for (index = 1; index <= TM_NUM_WRED_B_NODE_CURVES; index++) {
+				rc = rm_wred_b_node_curve_status(ctl->rm, index, &status);
+				if (rc) {
+					rc = -1;
+					TM_WRAPPER_END(tm_hndl);
+				}
+
+				if (status == TM_DISABLE) /* end */
+					break;
+			}
+			if (index - 1)
+				pr_info("TM %s Level WRED Curves Indexes: %d-%d\n",
+						level_names_arr[level], 1, index - 1);
+			else
+				pr_info("TM %s Level WRED Curves Indexes: None\n",
+						level_names_arr[level]);
+			break;
+
+		case A_LEVEL:
+			for (index = 1; index <= TM_NUM_WRED_A_NODE_CURVES; index++) {
+				rc = rm_wred_a_node_curve_status(ctl->rm, index, &status);
+				if (rc) {
+					rc = -1;
+					TM_WRAPPER_END(tm_hndl);
+				}
+
+				if (status == TM_DISABLE) /* end */
+					break;
+			}
+			if (index - 1)
+				pr_info("TM %s Level WRED Curves Indexes: %d-%d\n",
+						level_names_arr[level], 1, index - 1);
+			else
+				pr_info("TM %s Level WRED Curves Indexes: None\n",
+						level_names_arr[level]);
+			break;
+
+		case Q_LEVEL:
+			for (index = 1; index <= TM_NUM_WRED_QUEUE_CURVES; index++) {
+				rc = rm_wred_queue_curve_status(ctl->rm, index, &status);
+				if (rc) {
+					rc = -1;
+					TM_WRAPPER_END(tm_hndl);
+				}
+
+				if (status == TM_DISABLE) /* end */
+					break;
+			}
+			if (index - 1)
+				pr_info("TM %s Level WRED Curves Indexes: %d-%d\n",
+						level_names_arr[level], 1, index - 1);
+			else
+				pr_info("TM %s Level WRED Curves Indexes: None\n",
+						level_names_arr[level]);
+			break;
+		} /* switch */
+	}
+
+	TM_WRAPPER_END(tm_hndl);
+}
+
+int tm_sysfs_params_show(void)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		set_dp_default();
+		flag = TM_ENABLE;
+	}
+
+	pr_info("cbtd threshold:			%d\n", context.cbtd_threshold);
+	if (context.color_td_en)
+		pr_info("CATD mode:");
+	else
+		pr_info("WRED mode:");
+
+	pr_info("min_th[]:			%d %d %d\n",
+		context.min_threshold[0],
+		context.min_threshold[1],
+		context.min_threshold[2]);
+
+	if (context.color_td_en == TM_DISABLE) {
+		pr_info("max_th[]:			%d %d %d\n",
+			context.max_threshold[0],
+			context.max_threshold[1],
+			context.max_threshold[2]);
+
+		pr_info("curve_id[]:		%d %d %d\n",
+			context.curve_id[0],
+			context.curve_id[1],
+			context.curve_id[2]);
+
+		pr_info("curve_scale[]:		%d %d %d\n",
+			context.curve_scale[0],
+			context.curve_scale[1],
+			context.curve_scale[2]);
+	}
+
+	TM_WRAPPER_END(tm_hndl);
+}
+
+int tm_sysfs_read_drop_profile(int level, int cos, uint16_t index)
+{
+	struct tm_drop_profile *dp;
+	int i;
+	uint8_t lvl;
+	uint32_t ind;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case Q_LEVEL:
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case A_LEVEL:
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case B_LEVEL:
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case C_LEVEL:
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case P_LEVEL:
+		if (cos == -1)
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		else
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		break;
+	default:
+		rc = -1;
+		goto out;
+	}
+
+	if (dp->td_thresh_res)
+		pr_info("cbtd threshold:			%d\n", dp->td_threshold * TM_1K);
+	else
+		pr_info("cbtd threshold:			%d\n", dp->td_threshold);
+
+	if (dp->color_td_en)
+		pr_info("CATD mode:\n");
+	else
+		pr_info("WRED mode:\n");
+
+	pr_info("min_th[]:			%d %d %d\n",
+			dp->min_th_sw[0],
+			dp->min_th_sw[1],
+			dp->min_th_sw[2]);
+
+	if (dp->color_td_en == TM_DISABLE) {
+		pr_info("max_th[]:			%d %d %d\n",
+			dp->max_th_sw[0],
+			dp->max_th_sw[1],
+			dp->max_th_sw[2]);
+
+		pr_info("curve_id[]:		%d %d %d\n",
+			dp->curve_id[0].index,
+			dp->curve_id[1].index,
+			dp->curve_id[2].index);
+
+		pr_info("curve_scale[]:		%d %d %d\n",
+			dp->dp_ratio[0].ratio,
+			dp->dp_ratio[1].ratio,
+			dp->dp_ratio[2].ratio);
+	}
+
+	if ((level == P_LEVEL) && (dp->use_counter != 0)) {
+		/* list not empty */
+		pr_info("Ports list:");
+		for (i = dp->use_counter; i > 0; i--) {
+			if (i == dp->use_counter) {
+				rc = rm_list_reset_to_start(ctl->rm, dp->use_list, &ind, &lvl);
+				pr_info(" %d", ind);
+			} else {
+				rc = rm_list_next_index(ctl->rm, dp->use_list, &ind, &lvl);
+				pr_info(" %d", ind);
+			}
+		}
+		pr_info("\n");
+	}
+out:
+	if (rc)
+		pr_info("tm_sysfs_read_drop_profile error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_read_drop_profile_bw(int level, int cos, uint16_t prof_index)
+{
+	struct tm_drop_profile_params dp_profile = {0};
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (cos == -1)
+		rc = tm_read_drop_profile(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, prof_index, &dp_profile);
+	else
+		rc = tm_read_drop_profile(ctl, TM_LEVEL(level), (uint8_t) cos, prof_index, &dp_profile);
+	if (rc == 0) {
+		pr_info("wred_catd_bw:		%d\n", dp_profile.wred_catd_bw);
+		pr_info("cbtd_bw:			%d\n", dp_profile.cbtd_bw);
+		/*pr_info("cbtd_rtt_ratio:	%d\n", dp_profile.cbtd_rtt_ratio);*/
+		/*pr_info("aql_exp:			%d\n", dp_profile.aql_exp);*/
+		pr_info("wred_catd_mode:	%d\n", dp_profile.wred_catd_mode);
+		pr_info("curve_id[]:		%d %d %d\n",
+				dp_profile.curve_id[0],
+				dp_profile.curve_id[1],
+				dp_profile.curve_id[2]);
+
+		pr_info("dp_ratio[]:        %d %d %d\n",
+				dp_profile.dp_ratio[0],
+				dp_profile.dp_ratio[1],
+				dp_profile.dp_ratio[2]);
+
+		pr_info("min_th[]:          %d %d %d\n",
+				dp_profile.min_th[0],
+				dp_profile.min_th[1],
+				dp_profile.min_th[2]);
+
+		pr_info("max_th[]:          %d %d %d\n",
+				dp_profile.max_th[0],
+				dp_profile.max_th[1],
+				dp_profile.max_th[2]);
+	} else
+		pr_info("tm_read_drop_profile error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_cbtd_thr_set(uint32_t threshold)
+{
+	uint32_t max_thresh;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		set_dp_default();
+		flag = TM_ENABLE;
+	}
+
+	max_thresh = get_drop_threshold_definition() * TM_1K;
+	if (threshold > max_thresh) {
+		rc = -1;
+		pr_info("tm_sysfs_cbtd_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+	context.cbtd_threshold = threshold;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_catd_thr_set(int color, uint32_t threshold)
+{
+	int i;
+	uint32_t max_thresh;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		set_dp_default();
+		flag = TM_ENABLE;
+	}
+
+	max_thresh = 1023 * (uint32_t)(1 << 22);
+	if (threshold > max_thresh) {
+		rc = -1;
+		pr_info("tm_sysfs_catd_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (((color > 3) && (color != TM_ALL_COLORS)) || (color < 0)) {
+		rc = -1;
+		pr_info("tm_sysfs_catd_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (color == TM_ALL_COLORS) {
+		for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+			context.min_threshold[i] = threshold;
+			context.max_threshold[i] = 0;
+		}
+	} else {
+		context.min_threshold[color] = threshold;
+		context.max_threshold[color] = 0;
+	}
+	context.color_td_en = TM_ENABLE;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_wred_thr_set(int color, uint32_t min, uint32_t max)
+{
+	int i;
+	uint32_t max_thresh;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		set_dp_default();
+		flag = TM_ENABLE;
+	}
+
+	max_thresh = 1023 * (uint32_t)(1 << 22);
+	if ((max > max_thresh) || (min > max)) {
+		rc = -1;
+		pr_info("tm_sysfs_wred_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (((color > 3) && (color != TM_ALL_COLORS)) || (color < 0)) {
+		rc = -1;
+		pr_info("tm_sysfs_catd_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (color == TM_ALL_COLORS) {
+		for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+			context.min_threshold[i] = min;
+			context.max_threshold[i] = max;
+		}
+	} else {
+		context.min_threshold[color] = min;
+		context.max_threshold[color] = max;
+	}
+	context.color_td_en = TM_DISABLE;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_wred_curve_set(int color, uint32_t curve_ind, uint32_t curve_scale)
+{
+	int i;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		set_dp_default();
+		flag = TM_ENABLE;
+	}
+
+	if (curve_ind > 8) {
+		rc = -1;
+		pr_info("tm_sysfs_wred_curve_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (((color > 3) && (color != TM_ALL_COLORS)) || (color < 0)) {
+		rc = -1;
+		pr_info("tm_sysfs_catd_thr_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (color == TM_ALL_COLORS)
+		for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+			context.curve_id[i] = curve_ind;
+			context.curve_scale[i] = curve_scale;
+		}
+	else {
+		context.curve_id[color] = curve_ind;
+		context.curve_scale[color] = curve_scale;
+	}
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+int tm_sysfs_drop_profile_set(int level, uint16_t index, int cos)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (flag == TM_DISABLE) {
+		rc = -2;
+		pr_info("tm_sysfs_drop_profile_set error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	rc = mv_tm_drop_profile_set(level, index, cos, &context);
+	set_dp_default();
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.h
new file mode 100644
index 0000000..3b32167
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_drop.h
@@ -0,0 +1,55 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_SYSFS_DROP__H
+#define TM_SYSFS_DROP__H
+
+#include "common/mv_sw_if.h"
+
+int tm_sysfs_read_drop_profiles(void);
+
+int tm_sysfs_read_wred_curves(void);
+
+int tm_sysfs_params_show(void);
+
+int tm_sysfs_read_drop_profile(int level, int cos, uint16_t prof_index);
+
+int tm_sysfs_read_drop_profile_bw(int level, int cos, uint16_t prof_index);
+
+int tm_sysfs_cbtd_thr_set(uint32_t threshold);
+
+int tm_sysfs_catd_thr_set(int color, uint32_t threshold);
+
+int tm_sysfs_wred_thr_set(int color, uint32_t min, uint32_t max);
+
+int tm_sysfs_wred_curve_set(int color, uint32_t curve_ind, uint32_t curve_scale);
+
+int tm_sysfs_drop_profile_set(int level, uint16_t index, int cos);
+
+
+#endif /* TM_SYSFS_DROP__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.c
new file mode 100644
index 0000000..e690c2f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.c
@@ -0,0 +1,98 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_sysfs_shaping.h"
+#include "mv_tm_shaping.h"
+#include "tm/mv_tm.h"
+#include "tm_shaping.h"
+#include "tm_hw_configuration_interface.h"
+
+static char *level_names_arr[] = { "Q", "A", "B", "C", "P"};
+
+int tm_sysfs_read_shaping(void)
+{
+	uint32_t profiles_num = 0;
+	int level;
+	uint32_t cir = 0;
+	uint32_t eir = 0;
+	int i;
+	uint32_t total_nodes = 0;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	for (level = P_LEVEL; level >= Q_LEVEL; level--) {
+		switch (level) {
+		case P_LEVEL:
+			total_nodes = get_tm_port_count();
+			break;
+		case C_LEVEL:
+			total_nodes = get_tm_c_nodes_count();
+			break;
+		case B_LEVEL:
+			total_nodes = get_tm_b_nodes_count();
+			break;
+		case A_LEVEL:
+			total_nodes = get_tm_a_nodes_count();
+			break;
+		case Q_LEVEL:
+			total_nodes = get_tm_queues_count();
+			break;
+		default:
+			rc = -1;
+			TM_WRAPPER_END(tm_hndl);
+		}
+		rc = 0;
+		profiles_num = 0;
+		cir = 0;
+		eir = 0;
+		for (i = 0; i < total_nodes; i++) {
+			rc = tm_read_shaping(ctl,
+				TM_LEVEL(level),
+				i,
+				&cir,
+				&eir,
+				NULL,
+				NULL);
+			if (rc)
+				continue;
+			if ((cir != TM_MAX_SHAPING_BW) || (eir != TM_MAX_SHAPING_BW))
+				profiles_num++;
+		}
+		if (profiles_num != 0)
+			pr_info("TM %s Level Shaping Configurations: %d\n",
+					level_names_arr[level], profiles_num);
+		else
+			pr_info("TM %s Level Shaping Configurations: None\n",
+					level_names_arr[level]);
+	}
+
+	rc = 0;
+
+	TM_WRAPPER_END(tm_hndl);
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.h
new file mode 100644
index 0000000..ad4f862
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_sysfs_shaping.h
@@ -0,0 +1,37 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_SYSFS_SHAPING__H
+#define TM_SYSFS_SHAPING__H
+
+#include "common/mv_sw_if.h"
+
+int tm_sysfs_read_shaping(void);
+
+#endif /* TM_SYSFS_SHAPING__H */
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.c b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.c
new file mode 100644
index 0000000..8c074e3
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.c
@@ -0,0 +1,169 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "tm_to_qmtm_enums.h"
+#include "tm_errcodes.h"
+
+
+/*#define CONVERT_ERROR_CODE(code)  if (rc==code) return QM##code;*/
+#define CONVERT_ERROR_CODE(code)  if (rc == code) return code;
+
+
+
+int	tm_to_qmtm_errcode(int rc)
+{
+/** HW error codes */
+	CONVERT_ERROR_CODE(TM_HW_GEN_CONFIG_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_WRED_CURVE_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_DROP_PROFILE_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_CONF_PER_SCHEME_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_TREE_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_AGING_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_PORT_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_C_NODE_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_B_NODE_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_A_NODE_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_QUEUE_CONFIG_FAIL)
+
+	/**< 11 */
+	CONVERT_ERROR_CODE(TM_HW_CHANGE_SHAPING_STATUS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_PORT_DWRR_BYTES_PER_BURST_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_QMR_GET_ERRORS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_BAP_GET_ERRORS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_RCB_GET_ERRORS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_SCHED_GET_ERRORS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_DROP_GET_ERRORS_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_SHAPING_PROF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_READ_PORT_STATUS_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_READ_C_NODE_STATUS_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_READ_B_NODE_STATUS_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_READ_A_NODE_STATUS_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_READ_QUEUE_STATUS_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_GET_QUEUE_LENGTH_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_GET_QMR_PKT_STAT_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_GET_RCB_PKT_STAT_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_SET_SMS_PORT_ATTR_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_ELIG_PRIO_FUNC_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_AQM_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_COLOR_NUM_CONFIG_FAIL)
+	CONVERT_ERROR_CODE(TM_HW_DP_QUERY_RESP_CONF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_QUEUE_COS_CONF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_TM2TM_GLOB_CONF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_TM2TM_CHANNEL_CONF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_TM2TM_LC_CONF_FAILED)
+	CONVERT_ERROR_CODE(TM_HW_TM2TM_ENABLE_FAILED)
+
+
+/** configuration  error codes */
+	CONVERT_ERROR_CODE(TM_CONF_INVALID_PROD_NAME)
+	CONVERT_ERROR_CODE(TM_CONF_PER_RATE_L_K_N_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_RES_INC_BW_TS_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_RES_ACC_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_NON_RES_ACC_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_RES_INC_BW_TS_LESS_ONE)
+	CONVERT_ERROR_CODE(TM_CONF_BANK_UPD_RATE_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_UPD_RATE_NOT_FOUND)
+	CONVERT_ERROR_CODE(TM_CONF_NON_RES_INC_BW_TS_LESS_ONE)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_IND_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_QUANTUM_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_DWRR_PRIO_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_P_WRED_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_BW_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_BS_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_Q_SHAPING_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_Q_QUANTUM_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_Q_WRED_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_A_NODE_IND_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_A_SHAPING_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_A_QUANTUM_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_A_DWRR_PRIO_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_A_WRED_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_B_NODE_IND_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_B_SHAPING_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_B_QUANTUM_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_B_DWRR_PRIO_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_B_WRED_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_NODE_IND_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_SHAPING_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_QUANTUM_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_DWRR_PRIO_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_WRED_PROF_REF_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_C_WRED_COS_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_ELIG_PRIO_FUNC_ID_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_DP_COS_SEL_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_EXT_HDR_SIZE_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_CTRL_PKT_STR_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_DELTA_RANGE_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_EGR_ELEMS_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_SRC_LVL_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_BP_LVL_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_BP_THRESH_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_DP_LVL_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_CTRL_HDR_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_PORT_FOR_CTRL_PKT_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_SPEED_OOR)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_MIN_SHAP_NOT_INC_BW_MULT)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_MAX_SHAP_NOT_INC_BW_MULT)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_SHAP_MAX_NOT_MULT_MIN)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_BW_OUT_OF_SPEED)
+	CONVERT_ERROR_CODE(TM_CONF_INVALID_NUM_OF_C_NODES)
+	CONVERT_ERROR_CODE(TM_CONF_INVALID_NUM_OF_B_NODES)
+	CONVERT_ERROR_CODE(TM_CONF_INVALID_NUM_OF_A_NODES)
+	CONVERT_ERROR_CODE(TM_CONF_INVALID_NUM_OF_QUEUES)
+	CONVERT_ERROR_CODE(TM_CONF_LVL_MIN_BW_VIOLATION)
+	CONVERT_ERROR_CODE(TM_CONF_LVL_MAX_BW_VIOLATION)
+	CONVERT_ERROR_CODE(TM_CONF_LVL_MIN_INC_VIOLATION)
+	CONVERT_ERROR_CODE(TM_CONF_LVL_MIN_NOT_MULT_INC)
+	CONVERT_ERROR_CODE(TM_CONF_LVL_MAX_NOT_MULT_INC)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_AQM_INVALID_COLOR_NUM)
+	CONVERT_ERROR_CODE(TM_CONF_MIN_SHAP_NOT_INC_BW_MULT)
+	CONVERT_ERROR_CODE(TM_CONF_MAX_SHAP_NOT_INC_BW_MULT)
+	CONVERT_ERROR_CODE(TM_CONF_SHAP_MAX_NOT_MULT_MIN)
+	CONVERT_ERROR_CODE(TM_CONF_SHAP_MIN_NOT_MULT_MIN)
+	CONVERT_ERROR_CODE(TM_CONF_REORDER_NODES_NOT_ADJECENT)
+	CONVERT_ERROR_CODE(TM_CONF_MIN_TOKEN_TOO_LARGE)
+	CONVERT_ERROR_CODE(TM_CONF_MAX_TOKEN_TOO_LARGE)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_MIN_TOKEN_TOO_LARGE)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_MAX_TOKEN_TOO_LARGE)
+	CONVERT_ERROR_CODE(TM_CONF_MAX_BW_TS_TOO_LARGE)
+	CONVERT_ERROR_CODE(TM_CONF_REORDER_CHILDREN_NOT_AVAIL)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_IND_NOT_EXIST)
+	CONVERT_ERROR_CODE(TM_CONF_A_NODE_IND_NOT_EXIST)
+	CONVERT_ERROR_CODE(TM_CONF_B_NODE_IND_NOT_EXIST)
+	CONVERT_ERROR_CODE(TM_CONF_C_NODE_IND_NOT_EXIST)
+	CONVERT_ERROR_CODE(TM_CONF_CANNT_GET_LAD_FREQUENCY)
+	CONVERT_ERROR_CODE(TM_CONF_UPD_RATE_NOT_CONF_FOR_LEVEL)
+	CONVERT_ERROR_CODE(TM_CONF_TM2TM_CHANNEL_NOT_CONFIGURED)
+	CONVERT_ERROR_CODE(TM_CONF_PORT_IND_USED)
+	CONVERT_ERROR_CODE(TM_CONF_NULL_LOGICAL_NAME)
+	CONVERT_ERROR_CODE(TM_CONF_WRONG_LOGICAL_NAME)
+
+	return rc;
+}
+
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.h b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.h
new file mode 100644
index 0000000..bbccb08
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/platform/tm_to_qmtm_enums.h
@@ -0,0 +1,39 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef TM_TO_QMTM_ENUMS_H
+#define TM_TO_QMTM_ENUMS_H
+
+#include "tm_defs.h"
+
+int	tm_to_qmtm_errcode(int rc);
+
+#define	TM_LEVEL(qmtm_level_value)				((enum tm_level)qmtm_level_value)
+#define	TM_COLOR_NUM(qmtm_color_num_value)		((enum tm_color_num)qmtm_color_num_value)
+
+#endif /* _TM_TO_QMTM_ERRRS_H_ */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.c b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.c
new file mode 100644
index 0000000..37fe019
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.c
@@ -0,0 +1,621 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mv_tm_drop.h"
+#include "tm_core_types.h"
+#include "tm_drop.h"
+#include "rm_status.h"
+#include "tm_hw_configuration_interface.h"
+#include "tm_nodes_update.h"
+#include "tm_nodes_status.h"
+
+static int tm_round_int(uint32_t val, uint32_t divider)
+{
+	return (val * 100 + 50) / (divider * 100);
+}
+
+static int check_curve(rmctl_t hndl, enum mv_tm_level level, uint8_t index, int cos, uint8_t *status)
+{
+	int rc = 0;
+
+	switch (level) {
+	case TM_Q_LEVEL:
+		if (index >= TM_NUM_WRED_QUEUE_CURVES)
+			return -1;
+		rc = rm_wred_queue_curve_status(hndl, index, status);
+		break;
+	case TM_A_LEVEL:
+		if (index >= TM_NUM_WRED_A_NODE_CURVES)
+			return -1;
+		rc = rm_wred_a_node_curve_status(hndl, index, status);
+		break;
+	case TM_B_LEVEL:
+		if (index >= TM_NUM_WRED_B_NODE_CURVES)
+			return -1;
+		rc = rm_wred_b_node_curve_status(hndl, index, status);
+		break;
+	case TM_C_LEVEL:
+		if (cos > TM_WRED_COS)
+			return -2;
+		if (index >= TM_NUM_WRED_C_NODE_CURVES)
+			return -1;
+		rc = rm_wred_c_node_curve_status(hndl, cos, index, status);
+		break;
+	case TM_P_LEVEL:
+		if (index >= TM_NUM_WRED_PORT_CURVES)
+			return -1;
+		if (cos == -1) /* Global Port */
+			rc = rm_wred_port_curve_status(hndl, index, status);
+		else
+			rc = rm_wred_port_curve_status_cos(hndl, cos, index, status);
+		break;
+	default:
+		return -3;
+	}
+	return rc;
+}
+
+/* Public functions to be called from external modules */
+int mv_tm_create_wred_curve(enum mv_tm_level level, int cos, uint8_t mp, uint8_t *index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (cos == -1)
+		rc = tm_create_wred_traditional_curve(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, mp, index);
+	else
+		rc = tm_create_wred_traditional_curve(ctl, TM_LEVEL(level), cos, mp, index);
+	if (rc != 0)
+		pr_info("tm_create_wred_traditional_curve error: %d\n", rc);
+	else
+		pr_info("tm_create_wred_traditional_curve level=%d, cos=%d, mp=%d, index=%d\n",
+			level, cos, mp, (int)(*index));
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_create_wred_curve);
+
+int mv_tm_create_flat_wred_curve(enum mv_tm_level level, int cos, uint8_t cp, uint8_t *curve_index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (cos == -1)
+		rc = tm_create_wred_flat_curve(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, cp, curve_index);
+	else
+		rc = tm_create_wred_flat_curve(ctl, TM_LEVEL(level), cos, cp, curve_index);
+	if (rc != 0)
+		pr_info("tm_create_wred_flat_curve error: %d\n", rc);
+	else
+		pr_info("tm_create_wred_flat_curve level=%d, cos=%d, cp=%d, curve index=%d\n",
+			level, cos, cp, (int)(*curve_index));
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_create_flat_wred_curve);
+
+
+
+int mv_tm_drop_profile_set(enum mv_tm_level level, uint32_t index, int cos, struct mv_tm_drop_profile *profile)
+{
+	struct tm_drop_profile *dp;
+	int i;
+	uint8_t exp;
+	uint8_t status;
+	uint16_t ratio;
+	uint32_t max_thresh;
+	uint32_t threshold;
+	uint32_t min;
+	uint32_t max;
+	uint32_t thresh_scaled = 0;
+	uint32_t min_thresh_scaled = 0;
+	uint32_t max_thresh_scaled = 0;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case TM_Q_LEVEL:
+		if (index >= MV_TM_NUM_QUEUE_DROP_PROF) {
+			rc = -1;
+			goto out;
+		}
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case TM_A_LEVEL:
+		if (index >= MV_TM_NUM_A_NODE_DROP_PROF) {
+			rc = -1;
+			goto out;
+		}
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case TM_B_LEVEL:
+		if (index >= MV_TM_NUM_B_NODE_DROP_PROF) {
+			rc = -1;
+			goto out;
+		}
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case TM_C_LEVEL:
+		if ((cos >= MV_TM_WRED_COS) || (cos <= 0) || (index >= MV_TM_NUM_C_NODE_DROP_PROF)) {
+			rc = -1;
+			goto out;
+		}
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case TM_P_LEVEL:
+		if (index >= MV_TM_NUM_PORT_DROP_PROF) {
+			rc = -1;
+			goto out;
+		}
+		if (cos == -1)
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		else {
+			if ((cos >= MV_TM_WRED_COS) || (cos <= 0)) {
+				rc = -1;
+				goto out;
+			}
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		}
+		break;
+	default:
+		rc = -1;
+		goto out;
+	}
+
+	/* CBTD */
+	threshold = profile->cbtd_threshold;
+	max_thresh = get_drop_threshold_definition() * TM_1K;
+	if (threshold > max_thresh) {
+		rc = -2;
+		goto out;
+	}
+
+	if (threshold > get_drop_threshold_definition()) {
+		dp->td_thresh_res = TM_ENABLE;
+		dp->td_threshold = threshold/TM_1K;
+	} else {
+		dp->td_thresh_res = TM_DISABLE;
+		dp->td_threshold = threshold;
+	}
+
+	/* CATD/WRED */
+	dp->color_td_en = profile->color_td_en;
+	max_thresh = 1023 * (uint32_t)(1 << 22);
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		if (profile->color_td_en == TM_ENABLE) { /* CATD mode */
+			threshold = profile->min_threshold[i];
+			if (threshold > max_thresh) {
+				rc = -2;
+				goto out;
+			}
+
+			for (exp = 0; exp < 22; exp++) {
+				thresh_scaled = threshold/(uint32_t)(1<<exp);
+				if (thresh_scaled < TM_1K)
+					break;
+			}
+			dp->min_threshold[i].thresh = (uint16_t)thresh_scaled;
+			dp->scale_exp[i].exp = exp;
+			dp->scale_ratio[i].ratio = 0;
+			dp->curve_id[i].index = 0;
+			dp->dp_ratio[i].ratio = 0;
+			dp->min_th_sw[i] = threshold;
+			dp->max_th_sw[i] = 0;
+		} else { /* WRED mode */
+			min = profile->min_threshold[i];
+			max = profile->max_threshold[i];
+			dp->min_th_sw[i] = min;
+			dp->max_th_sw[i] = max;
+			if ((min == 0) && (max == 0)) {
+				dp->curve_id[i].index = 0;
+				dp->dp_ratio[i].ratio = 0;
+				dp->scale_exp[i].exp = 22;
+				dp->scale_ratio[i].ratio = 0;
+				dp->min_threshold[i].thresh = 1023;
+			} else {
+				if ((max > max_thresh) || (min > max)) {
+					rc = -2;
+					goto out;
+				}
+
+				/* check that curve exists */
+				rc = check_curve(ctl->rm, level, profile->curve_id[i], cos, &status);
+				if ((rc < 0) || (status != RM_TRUE)) {
+					rc = -3;
+					goto out;
+				}
+				dp->curve_id[i].index = profile->curve_id[i];
+				dp->dp_ratio[i].ratio = profile->curve_scale[i];
+
+				for (exp = 0; exp < 22; exp++) {
+					max_thresh_scaled = max/(uint32_t)(1 << exp);
+					if (max_thresh_scaled < TM_1K)
+						break;
+				}
+				min_thresh_scaled = min/(uint32_t)(1 << exp);
+				/* 1024 * 32 = 0x8000 */
+				ratio = (uint16_t)tm_round_int(0x8000, (max_thresh_scaled - min_thresh_scaled + 1));
+
+				dp->scale_exp[i].exp = exp;
+				if (ratio > 1023)
+					dp->scale_ratio[i].ratio = 1023;
+				else
+					dp->scale_ratio[i].ratio = ratio;
+				dp->min_threshold[i].thresh = (uint16_t)min_thresh_scaled;
+			}
+		}
+	}
+
+	dp->out_bw = TM_INVAL;
+	dp->cbtd_bw = TM_INVAL;
+	dp->aql_exp = 0; /* Forget Factor = 1, AQL=QL */;
+
+	if (cos == -1)
+		rc = tm_drop_profile_hw_set(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, index);
+	else
+		rc = tm_drop_profile_hw_set(ctl, TM_LEVEL(level), cos, index);
+out:
+	if (rc)
+		pr_info("mv_tm_drop_profile_set error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_drop_profile_set);
+
+int mv_tm_drop_profile_get(enum mv_tm_level level, uint32_t index, int cos, struct mv_tm_drop_profile *profile)
+{
+	struct tm_drop_profile *dp;
+	int i;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case Q_LEVEL:
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case A_LEVEL:
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case B_LEVEL:
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case C_LEVEL:
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case P_LEVEL:
+		if (cos == -1)
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		else
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		break;
+	default:
+		rc = -1;
+		pr_info("mv_tm_drop_profile_get error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	if (dp->td_thresh_res)
+		profile->cbtd_threshold = dp->td_threshold * TM_1K;
+	else
+		profile->cbtd_threshold = dp->td_threshold;
+
+	profile->color_td_en = dp->color_td_en;
+
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		profile->min_threshold[i] = dp->min_th_sw[i];
+#if 0 /* TBD: remove */
+		if ((dp->scale_ratio[i].ratio == 0) && (dp->color_td_en == TM_DISABLE))
+			profile->min_threshold[i] = 0;
+		else
+			profile->min_threshold[i] = (dp->min_threshold[i].thresh) * (1 << (dp->scale_exp[i].exp));
+#endif
+
+		if (dp->color_td_en == TM_DISABLE) {
+			profile->max_threshold[i] = dp->max_th_sw[i];
+			profile->curve_id[i] = dp->curve_id[i].index;
+			profile->curve_scale[i] = dp->dp_ratio[i].ratio;
+#if 0 /* TBD: remove */
+		for (i = 0; i < 3; i++)
+			if (dp->scale_ratio[i].ratio == 0)
+				max_th[i] = 0;
+			else {
+				/* 1024 * 32 = 0x8000 */
+				max_th[i] = (uint16_t)tm_round_int(0x8000,
+					(dp->scale_ratio[i].ratio)) + dp->min_threshold[i].thresh - 1;
+				max_th[i] = max_th[i] * (1 << (dp->scale_exp[i].exp));
+			}
+#endif
+		} else {
+			profile->max_threshold[i] = 0;
+			profile->curve_id[i] = 0;
+			profile->curve_scale[i] = 0;
+		}
+	}
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_drop_profile_get);
+
+int mv_tm_drop_profile_clear(enum mv_tm_level level, uint32_t index, int cos)
+{
+	struct tm_drop_profile *dp;
+	int i;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case Q_LEVEL:
+		dp = &(ctl->tm_q_lvl_drop_profiles[index]);
+		break;
+	case A_LEVEL:
+		dp = &(ctl->tm_a_lvl_drop_profiles[index]);
+		break;
+	case B_LEVEL:
+		dp = &(ctl->tm_b_lvl_drop_profiles[index]);
+		break;
+	case C_LEVEL:
+		dp = &(ctl->tm_c_lvl_drop_profiles[cos][index]);
+		break;
+	case P_LEVEL:
+		if (cos == -1)
+			dp = &(ctl->tm_p_lvl_drop_profiles[index]);
+		else
+			dp = &(ctl->tm_p_lvl_drop_profiles_cos[cos][index]);
+		break;
+	default:
+		rc = -1;
+		pr_info("mv_tm_drop_profile_clear error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	dp->out_bw = 0;
+	dp->cbtd_bw = 0;
+	dp->aql_exp = 0; /* Forget Factor = 1, AQL=QL */;
+	dp->td_thresh_res = TM_ENABLE; /* 16KB */
+	dp->td_threshold = get_drop_threshold_definition(); /* Max */
+	dp->color_td_en = TM_DISABLE;
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		dp->scale_exp[i].exp = 22; /* TBD: default in Cider is incorrect: 1 Burst unit */
+		dp->scale_ratio[i].ratio = 0;
+		dp->curve_id[i].index = 0;
+		dp->dp_ratio[i].ratio = 0;
+		dp->min_threshold[i].thresh = 0x3FF; /* TBD: default in Cider is incorrect: 0 Bursts */
+		dp->min_th_sw[i] = 0x3FF;
+		dp->max_th_sw[i] = dp->min_th_sw[i] * (uint32_t)(1 << dp->scale_exp[i].exp);
+	}
+
+	if (cos == -1)
+		rc = tm_drop_profile_hw_set(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, index);
+	else
+		rc = tm_drop_profile_hw_set(ctl, TM_LEVEL(level), cos, index);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_drop_profile_clear);
+
+int mv_tm_update_drop_profile_wred(enum mv_tm_level level, int cos, uint32_t prof_index,
+								uint32_t cb_bw, uint32_t wred_bw)
+{
+	struct tm_drop_profile_params profile;
+	int i;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	profile.wred_catd_bw = wred_bw;
+	profile.cbtd_bw = cb_bw;
+
+	profile.cbtd_rtt_ratio = 100;
+	profile.aql_exp = 0;
+	profile.wred_catd_mode = WRED;
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		profile.curve_id[i] = 0;
+		profile.dp_ratio[i] = 0;
+		profile.min_th[i] = 0;
+		profile.max_th[i] = 100;
+	}
+
+	if (cos == -1)
+		rc = tm_update_drop_profile(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, prof_index, &profile);
+	else
+		rc = tm_update_drop_profile(ctl, TM_LEVEL(level), cos, prof_index, &profile);
+	if (rc == -ENODEV) {
+		rc = tm_create_wred_traditional_curve(ctl, TM_LEVEL(level), cos, 50, &profile.curve_id[0]);
+		if (rc)
+			return -ENOSPC;
+		profile.curve_id[1] = profile.curve_id[0];
+		profile.curve_id[2] = profile.curve_id[0];
+
+		/* Try again */
+		if (cos == -1)
+			rc = tm_update_drop_profile(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, prof_index, &profile);
+		else
+			rc = tm_update_drop_profile(ctl, TM_LEVEL(level), cos, prof_index, &profile);
+	}
+	if (rc != 0)
+		pr_info("tm_update_drop_profile_wred error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_update_drop_profile_wred);
+
+int mv_tm_update_drop_profile_catd(enum mv_tm_level level, int cos, uint32_t prof_index,
+								uint32_t cb_bw, uint32_t ca_bw)
+{
+	struct tm_drop_profile_params profile;
+	int i;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	profile.wred_catd_bw = ca_bw;
+	profile.cbtd_bw = cb_bw;
+
+	profile.cbtd_rtt_ratio = 100;
+	profile.aql_exp = 0;
+	profile.wred_catd_mode = CATD;
+	for (i = 0; i < MV_TM_NUM_OF_COLORS; i++) {
+		profile.curve_id[i] = 0;
+		profile.dp_ratio[i] = 0;
+		profile.min_th[i] = 100;
+		profile.max_th[i] = 100;
+	}
+
+	if (cos == -1)
+		rc = tm_update_drop_profile(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, prof_index, &profile);
+	else
+		rc = tm_update_drop_profile(ctl, TM_LEVEL(level), cos, prof_index, &profile);
+	if (rc == -ENODEV) {
+		rc = tm_create_wred_traditional_curve(ctl, TM_LEVEL(level), cos, 50, &profile.curve_id[0]);
+		if (rc)
+			return -ENOSPC;
+		profile.curve_id[1] = profile.curve_id[0];
+		profile.curve_id[2] = profile.curve_id[0];
+
+		/* Try again */
+		if (cos == -1)
+			rc = tm_update_drop_profile(ctl, TM_LEVEL(level), (uint8_t) TM_INVAL, prof_index, &profile);
+		else
+			rc = tm_update_drop_profile(ctl, TM_LEVEL(level), cos, prof_index, &profile);
+	}
+	if (rc != 0)
+		pr_info("tm_update_drop_profile_catd error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_update_drop_profile_catd);
+
+int mv_tm_color_num_set(enum mv_tm_level level, int color)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if ((color < 0) || (color > 3)) {
+		rc = -1;
+		goto out;
+	}
+
+	rc = tm_set_drop_color_num(ctl, TM_LEVEL(level), color - 1);
+
+out:
+	if (rc != 0)
+		pr_info("mv_tm_color_num_set error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_color_num_set);
+
+int mv_tm_queue_cos_set(uint32_t index, int cos)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (cos < 0) {
+		rc = -1;
+		goto out;
+	}
+
+	rc = tm_set_drop_queue_cos(ctl, index, cos);
+
+out:
+	if (rc != 0)
+		pr_info("mv_tm_queue_cos_set error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_queue_cos_set);
+
+int mv_tm_dp_set(enum mv_tm_level level, uint32_t index, int cos, uint32_t drop_profile)
+{
+	int i;
+	struct tm_queue_params q_params;
+	struct tm_a_node_params a_params;
+	struct tm_b_node_params b_params;
+	struct tm_c_node_params c_params;
+	struct tm_port_drop_per_cos params;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case TM_Q_LEVEL:
+		q_params.wred_profile_ref = (uint8_t) drop_profile;
+		q_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		q_params.quantum = (uint16_t) TM_INVAL;
+		rc = tm_update_queue(ctl, index, &q_params);
+		break;
+	case TM_A_LEVEL:
+		a_params.wred_profile_ref = (uint8_t) drop_profile;
+		a_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		a_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			a_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_a_node(ctl, index, &a_params);
+		break;
+	case TM_B_LEVEL:
+		b_params.wred_profile_ref = (uint8_t) drop_profile;
+		b_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		b_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			b_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_b_node(ctl, index, &b_params);
+		break;
+	case TM_C_LEVEL:
+		c_params.wred_cos = 0xff;
+		for (i = 0; i < TM_WRED_COS; i++)
+			c_params.wred_profile_ref[i] = (uint8_t) TM_INVAL;
+		c_params.wred_profile_ref[cos] = (uint8_t) drop_profile;
+		c_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		c_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			c_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_c_node(ctl, index, &c_params);
+		break;
+	case TM_P_LEVEL:
+		if (cos == -1)
+			rc = tm_update_port_drop(ctl, index, (uint8_t) drop_profile);
+		else {
+			params.wred_cos = 0xff;
+			for (i = 0; i < TM_WRED_COS; i++)
+				params.wred_profile_ref[i] = (uint8_t)TM_INVAL;
+			params.wred_profile_ref[cos] = (uint8_t) drop_profile;
+			rc = tm_update_port_drop_cos(ctl, index, &params);
+		}
+		break;
+	default:
+		rc = -3;
+		break;
+	}
+	if (rc != 0)
+		pr_info("mv_tm_dp_set error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_dp_set);
+
+int mv_tm_queue_length_get(enum mv_tm_level level, uint32_t index, uint32_t *av_queue_length)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_drop_get_queue_length(ctl, TM_LEVEL(level), index, av_queue_length);
+	if (rc)
+		pr_info("mv_tm_queue_length_get error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_queue_length_get);
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.h b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.h
new file mode 100644
index 0000000..f0d91e2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_drop.h
@@ -0,0 +1,95 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef MV_TM_DROP__H
+#define MV_TM_DROP__H
+
+#include "common/mv_sw_if.h"
+#include "tm/mv_tm.h"
+#include "tm_core_types.h"
+
+#define MV_TM_NUM_OF_COLORS				3
+#define MV_TM_WRED_COS					TM_WRED_COS
+
+#define MV_TM_NUM_QUEUE_DROP_PROF		TM_NUM_QUEUE_DROP_PROF
+#define MV_TM_NUM_A_NODE_DROP_PROF		TM_NUM_A_NODE_DROP_PROF
+#define MV_TM_NUM_B_NODE_DROP_PROF		TM_NUM_B_NODE_DROP_PROF
+#define MV_TM_NUM_C_NODE_DROP_PROF		TM_NUM_C_NODE_DROP_PROF
+#define MV_TM_NUM_PORT_DROP_PROF		TM_NUM_PORT_DROP_PROF
+
+/* NSS Drop profile */
+struct mv_tm_drop_profile {
+	/* CBTD */
+	uint32_t cbtd_threshold;                     /* Color Blind Tail Drop Threshold in resolution 16B */
+
+	/* CATD/WRED */
+	uint8_t  color_td_en;                        /* Colored Tail Drop Enable: 0 - WRED, 1 - CATD */
+	uint32_t min_threshold[MV_TM_NUM_OF_COLORS]; /* RED curve Min threshold per color [0..2] */
+	uint32_t max_threshold[MV_TM_NUM_OF_COLORS]; /* RED curve Max threshold per color [0..2] */
+	uint8_t  curve_id[MV_TM_NUM_OF_COLORS];      /* RED curve index per color[0..2] */
+	uint8_t  curve_scale[MV_TM_NUM_OF_COLORS];   /* Used for scaling of DP [0..2] */
+};
+
+/* create traditional WRED curve, where mp - max probability [1-100%] */
+int mv_tm_create_wred_curve(enum mv_tm_level level, int cos, uint8_t mp, uint8_t *curve_index);
+
+/* create flat WRED curve, where mp - max probability [1-100%] */
+int mv_tm_create_flat_wred_curve(enum mv_tm_level level, int cos, uint8_t cp, uint8_t *curve_index);
+
+/* update Drop Profile params to HW */
+int mv_tm_drop_profile_set(enum mv_tm_level level, uint32_t profile_index, int cos,
+							struct mv_tm_drop_profile *profile);
+
+/* get Drop Profile */
+int mv_tm_drop_profile_get(enum mv_tm_level level, uint32_t profile_index, int cos,
+							struct mv_tm_drop_profile *profile);
+
+/* set Drop Profile to default */
+int mv_tm_drop_profile_clear(enum mv_tm_level level, uint32_t profile_index, int cos);
+
+/* update Drop Profile (CBTD & WRED), parameters in Kbps */
+int mv_tm_update_drop_profile_wred(enum mv_tm_level level, int cos, uint32_t profile_index,
+									uint32_t cb_bw, uint32_t wred_bw);
+
+/* update Drop Profile (CBTD & CATD), parameters in Kbps */
+int mv_tm_update_drop_profile_catd(enum mv_tm_level level, int cos, uint32_t profile_index,
+									uint32_t cb_bw, uint32_t ca_bw);
+
+/* set number of colors in system (by default there are 2 colors in the system for better resolution) */
+int mv_tm_color_num_set(enum mv_tm_level level, int color);
+
+/* queue cos select */
+int mv_tm_queue_cos_set(uint32_t node_index, int cos);
+
+/* update Queue/Node/Port pointer to Drop Profile */
+int mv_tm_dp_set(enum mv_tm_level level, uint32_t node_index, int cos, uint32_t drop_profile);
+
+/* update Queue/Node/Port queue length */
+int mv_tm_queue_length_get(enum mv_tm_level level, uint32_t index, uint32_t *av_queue_length);
+
+#endif /* MV_TM_DROP__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.c b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.c
new file mode 100644
index 0000000..1b66b1b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.c
@@ -0,0 +1,243 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mv_tm_sched.h"
+#include "tm_nodes_tree.h"
+#include "tm_nodes_update.h"
+#include "tm_elig_prio_func.h"
+
+
+int mv_tm_quantum_range_get(uint32_t mtu, uint32_t *min_quantum, uint32_t *max_quantum)
+{
+	uint16_t quantum;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	quantum = (mtu + ctl->min_pkg_size)/TM_NODE_QUANTUM_UNIT;
+	*min_quantum = quantum;
+	*max_quantum = 256 * quantum;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_quantum_range_get);
+
+int mv_tm_mtu_set(uint32_t mtu)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_mtu_set(ctl, mtu);
+	if (rc != 0)
+		pr_info("mv_tm_mtu_set error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_mtu_set);
+
+int mv_tm_tree_status_set(int status)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_tree_change_status(ctl, (uint8_t)status);
+	if (rc != 0)
+		pr_info("tm_tree_change_status error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_tree_status_set);
+
+int mv_tm_prio_set(enum mv_tm_level level,
+					uint32_t index,
+					uint8_t prio)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (prio >= MV_TM_NUM_OF_PRIO) {
+		rc = -1;
+		goto out;
+	}
+
+	if (level == TM_Q_LEVEL)
+		rc = tm_queue_elig_set(ctl, index, prio);
+	else
+		rc = tm_node_elig_set(ctl, TM_LEVEL(level), index, prio);
+out:
+	if (rc)
+		pr_info("tm_node_prio_set error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_prio_set);
+
+int mv_tm_prio_set_propagated(enum mv_tm_level level,
+					uint32_t index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (level == TM_Q_LEVEL)
+		pr_info("not applicable for queues!\n");
+	else
+		rc = tm_node_elig_set_propagated(ctl, TM_LEVEL(level), index);
+
+	if (rc)
+		pr_info("tm_node_prio_set_propagated error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_prio_set_propagated);
+
+int mv_tm_dwrr_weight(enum mv_tm_level level,
+					uint32_t index,
+					uint32_t quantum)
+{
+	int i;
+	struct tm_queue_params q_params;
+	struct tm_a_node_params a_params;
+	struct tm_b_node_params b_params;
+	struct tm_c_node_params c_params;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	switch (level) {
+	case TM_Q_LEVEL:
+		q_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		q_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		q_params.quantum = quantum;
+		rc = tm_update_queue(ctl, index, &q_params);
+		break;
+	case TM_A_LEVEL:
+		a_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		a_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		a_params.quantum = quantum;
+		for (i = 0; i < 8; i++)
+			a_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_a_node(ctl, index, &a_params);
+		break;
+	case TM_B_LEVEL:
+		b_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		b_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		b_params.quantum = quantum;
+		for (i = 0; i < 8; i++)
+			b_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_b_node(ctl, index, &b_params);
+		break;
+	case TM_C_LEVEL:
+		c_params.wred_cos = 0xff;
+		for (i = 0; i < TM_WRED_COS; i++)
+			c_params.wred_profile_ref[i] = (uint8_t) TM_INVAL;
+		c_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		c_params.quantum = quantum;
+		for (i = 0; i < 8; i++)
+			c_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		rc = tm_update_c_node(ctl, index, &c_params);
+		break;
+	case TM_P_LEVEL:
+		pr_info("DWRR Quantum is not supported on Port level!\n");
+		rc = -1;
+	default:
+		rc = -3;
+		break;
+	}
+	if (rc != 0)
+		pr_info("tm_dwrr_weight error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_dwrr_weight);
+
+
+int mv_tm_dwrr_enable(enum mv_tm_level level,
+					uint32_t index,
+					uint8_t prio,
+					int en)
+{
+	int i;
+	struct tm_a_node_params a_params;
+	struct tm_b_node_params b_params;
+	struct tm_c_node_params c_params;
+	uint8_t dwrr_prio[8] = {0};
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if ((en != TM_ENABLE) && (en != TM_DISABLE)) {
+		rc = -1;
+		goto out;
+	}
+
+	if (prio >= MV_TM_NUM_OF_PRIO) {
+		rc = -2;
+		goto out;
+	}
+
+	switch (level) {
+	case TM_Q_LEVEL:
+		pr_info("DWRR priority for Queue level should be set on A-node.\n");
+		rc = -1;
+		break;
+	case TM_A_LEVEL:
+		a_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		a_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		a_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			a_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		a_params.dwrr_priority[prio] = (uint8_t) en;
+		rc = tm_update_a_node(ctl, index, &a_params);
+		break;
+	case TM_B_LEVEL:
+		b_params.wred_profile_ref = (uint8_t) TM_INVAL;
+		b_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		b_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			b_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		b_params.dwrr_priority[prio] = (uint8_t) en;
+		rc = tm_update_b_node(ctl, index, &b_params);
+		break;
+	case TM_C_LEVEL:
+		c_params.wred_cos = 0xff;
+		for (i = 0; i < TM_WRED_COS; i++)
+			c_params.wred_profile_ref[i] = (uint8_t) TM_INVAL;
+		c_params.elig_prio_func_ptr = (uint8_t) TM_INVAL;
+		c_params.quantum = (uint16_t) TM_INVAL;
+		for (i = 0; i < 8; i++)
+			c_params.dwrr_priority[i] = (uint8_t) TM_INVAL;
+		c_params.dwrr_priority[prio] = (uint8_t) en;
+		rc = tm_update_c_node(ctl, index, &c_params);
+		break;
+	case TM_P_LEVEL:
+		for (i = 0; i < 8; i++)
+			dwrr_prio[i] = (uint8_t)TM_INVAL;
+		dwrr_prio[prio] = (uint8_t) en;
+		rc = tm_update_port_scheduling(ctl, index, (uint8_t)TM_INVAL, dwrr_prio);
+		break;
+	default:
+		rc = -3;
+		break;
+	}
+out:
+	if (rc)
+		pr_info("tm_enable_dwrr error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_dwrr_enable);
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.h b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.h
new file mode 100644
index 0000000..0dff4af
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_sched.h
@@ -0,0 +1,62 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef MV_TM_SCHED__H
+#define MV_TM_SCHED__H
+
+#include "common/mv_sw_if.h"
+#include "tm/mv_tm.h"
+#include "tm_sched.h"
+
+/* Number of priorities */
+#define MV_TM_NUM_OF_PRIO			8
+
+/* get Node's minimal & maximal quantum size */
+int mv_tm_quantum_range_get(uint32_t mtu, uint32_t *min, uint32_t *max);
+
+/* set Maximal Transmission Unit size */
+/* note: should be called once at system initialization to set default values */
+/* User's responsibility to keep updated all already configured quantums */
+int mv_tm_mtu_set(uint32_t mtu);
+
+/* set the tree DeQ status */
+int mv_tm_tree_status_set(int status);
+
+/* set Queue/Node/Port priority */
+int mv_tm_prio_set(enum mv_tm_level level, uint32_t index, uint8_t prio);
+
+/* set  propagated priority  to Node/Port*/
+int mv_tm_prio_set_propagated(enum mv_tm_level level, uint32_t index);
+
+/* set DWRR weight (quantum) to Queue/Node */
+int mv_tm_dwrr_weight(enum mv_tm_level level, uint32_t index, uint32_t quantum);
+
+/* enable/disable DWRR to the given priority on the Queue/Node */
+int mv_tm_dwrr_enable(enum mv_tm_level level, uint32_t index, uint8_t prio, int en);
+
+#endif /* MV_TM_SCHED__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.c b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.c
new file mode 100644
index 0000000..7bdaa94
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.c
@@ -0,0 +1,443 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mv_tm_scheme.h"
+#include "tm_core_types.h"
+#include "rm_status.h"
+
+static uint8_t source_num[SOURCE_LAST] = {2, 2, 4, 2, 1, 2};
+
+static uint8_t type_base[SOURCE_LAST] = {TM_A0_PORT_PPC0_0,
+						TM_A0_PORT_PPC1_MNT0,
+						TM_A0_PORT_EMAC0,
+						TM_A0_PORT_CMAC_IN,
+						TM_A0_PORT_HMAC,
+						TM_A0_PORT_DROP0};
+
+static uint8_t port_type[MV_TM_MAX_PORTS] = {SOURCE_PPC_DP,
+						SOURCE_PPC_DP,
+						SOURCE_PPC_MNT,
+						SOURCE_PPC_MNT,
+						SOURCE_EMAC,
+						SOURCE_EMAC,
+						SOURCE_EMAC,
+						SOURCE_EMAC,
+						SOURCE_LAST, /* EMAC 4 not in use */
+						SOURCE_LAST, /* EMAC LB not in use */
+						SOURCE_CMAC,
+						SOURCE_CMAC,
+						SOURCE_HMAC,
+						SOURCE_LAST,
+						SOURCE_DROP,
+						SOURCE_DROP};
+
+/* Return number of ports for given type.
+   Example: return 2 for tm_scheme_type_ports_num(SOURCE_PPC_MNT).
+   Return -1 for invalid type. */
+int mv_tm_scheme_type_ports_num(enum mv_tm_source_type type)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (type >= SOURCE_LAST)
+		rc = -1;
+	else
+		rc = source_num[type];
+	if (rc < 0)
+		pr_info("mv_tm_scheme_type_ports_num error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_type_ports_num);
+
+/* Translate source type and id to port id.
+   Example: return 7 for tm_scheme_source_to_port(SOURCE_EMAC, 3) for A0.
+   Return -1 if source id is invalid. */
+int mv_tm_scheme_source_to_port(enum mv_tm_source_type type, int id)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if ((type >= SOURCE_LAST) || (id >= source_num[type]))
+		rc = -1;
+	else
+		rc = type_base[type] + id;
+	if (rc < 0)
+		pr_info("mv_tm_scheme_source_to_port error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_source_to_port);
+
+/* Translate port id to source type and source id, return -1 if port id is invalid. */
+int mv_tm_scheme_port_to_source(int port_id, int *source_id)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (port_id >= MV_TM_MAX_PORTS) {
+		rc = -1;
+		goto out;
+	}
+
+	rc = port_type[port_id];
+
+	if (source_id)
+		*source_id = port_id - type_base[rc];
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_port_to_source error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_port_to_source);
+
+/* Return total number of ports. */
+int mv_tm_scheme_ports_num(void)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = MV_TM_MAX_PORTS;
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_ports_num);
+
+/* Return base and number of A nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_a_node_get(int port_id, int *base, int *num)
+{
+	int i, j;
+	int sum = 0;
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* check that port is legal and in use */
+	rc = rm_node_status(ctl->rm, P_LEVEL, port_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+
+	for (i = ctl->tm_port_array[port_id].first_child_c_node;
+		i <= ctl->tm_port_array[port_id].last_child_c_node; i++) {
+
+		rc = rm_node_status(ctl->rm, C_LEVEL, i, &status);
+		if ((rc) || (status != RM_TRUE)) {
+			rc = -1;
+			goto out;
+		}
+
+		for (j = ctl->tm_c_node_array[i].first_child_b_node;
+			j <= ctl->tm_c_node_array[i].last_child_b_node; j++) {
+				rc = rm_node_status(ctl->rm, B_LEVEL, j, &status);
+				if ((rc) || (status != RM_TRUE)) {
+					rc = -1;
+					goto out;
+				}
+
+			/* static configuration*/
+			sum += (ctl->tm_b_node_array[j].last_child_a_node -
+				ctl->tm_b_node_array[j].first_child_a_node + 1);
+		}
+	}
+	*num = sum;
+
+	i = ctl->tm_port_array[port_id].first_child_c_node;
+	j = ctl->tm_c_node_array[i].first_child_b_node;
+	*base = ctl->tm_b_node_array[j].first_child_a_node;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_port_a_node_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_port_a_node_get);
+
+/* Return base and number of B nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_b_nodes_get(int port_id, int *base, int *num)
+{
+	int i;
+	int sum = 0;
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* check that port is legal and in use */
+	rc = rm_node_status(ctl->rm, P_LEVEL, port_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+
+	for (i = ctl->tm_port_array[port_id].first_child_c_node;
+		i <= ctl->tm_port_array[port_id].last_child_c_node; i++) {
+
+		rc = rm_node_status(ctl->rm, C_LEVEL, i, &status);
+		if ((rc) || (status != RM_TRUE)) {
+			rc = -1;
+			goto out;
+		}
+		/* static configuration*/
+		sum += (ctl->tm_c_node_array[i].last_child_b_node -
+			ctl->tm_c_node_array[i].first_child_b_node + 1);
+	}
+	*num = sum;
+
+	i = ctl->tm_port_array[port_id].first_child_c_node;
+	*base = ctl->tm_c_node_array[i].first_child_b_node;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_port_b_nodes_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_port_b_nodes_get);
+
+/* Return base and number of C nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_c_nodes_get(int port_id, int *base, int *num)
+{
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* check that port is legal and in use */
+	rc = rm_node_status(ctl->rm, P_LEVEL, port_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+	if (base)
+		*base = ctl->tm_port_array[port_id].first_child_c_node;
+	if (num)
+		*num = ctl->tm_port_array[port_id].last_child_c_node -
+			ctl->tm_port_array[port_id].first_child_c_node + 1;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_port_c_nodes_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_port_c_nodes_get);
+
+
+/* Return base and number of B nodes that attached to C node number cnode_id.
+   Return -1 if cnode_id is invalid or not in use. */
+int mv_tm_scheme_c_node_b_nodes_get(int cnode_id, int *base, int *num)
+{
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* check that port is legal and in use */
+	rc = rm_node_status(ctl->rm, C_LEVEL, cnode_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+	if (base)
+		*base = ctl->tm_c_node_array[cnode_id].first_child_b_node;
+	if (num)
+		*num = ctl->tm_c_node_array[cnode_id].last_child_b_node -
+			ctl->tm_c_node_array[cnode_id].first_child_b_node + 1;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_c_node_b_nodes_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_c_node_b_nodes_get);
+
+
+
+/* Return base and number of queues that attached to A node number anode_id.
+   Return -1 if anode_id is invalid or not in use. */
+int mv_tm_scheme_b_node_a_nodes_get(int bnode_id, int *base, int *num)
+{
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = rm_node_status(ctl->rm, B_LEVEL, bnode_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+
+	if (base)
+		*base = ctl->tm_b_node_array[bnode_id].first_child_a_node;
+	if (num)
+		*num = ctl->tm_b_node_array[bnode_id].last_child_a_node -
+			ctl->tm_b_node_array[bnode_id].first_child_a_node + 1;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_b_node_a_nodes_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_b_node_a_nodes_get);
+
+/* Return base and number of queues that attached to A node number anode_id.
+   Return -1 if anode_id is invalid or not in use. */
+int mv_tm_scheme_a_node_queues_get(int anode_id, int *base, int *num)
+{
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = rm_node_status(ctl->rm, A_LEVEL, anode_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+
+	if (base)
+		*base = ctl->tm_a_node_array[anode_id].first_child_queue;
+	if (num)
+		*num = ctl->tm_a_node_array[anode_id].last_child_queue -
+			ctl->tm_a_node_array[anode_id].first_child_queue + 1;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_a_node_queues_get error: %d\n", rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_a_node_queues_get);
+
+
+/* Retrun A node, B node, C node and port number that attached to queue number q_id.
+   Return -1 if q_id is invalid or not in use. */
+int mv_tm_scheme_queue_path_get(int q_id, int *anode, int *bnode, int *cnode, int *port)
+{
+	uint8_t status;
+
+	int a_node, b_node, c_node, p;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = rm_node_status(ctl->rm, Q_LEVEL, q_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		rc = -1;
+		goto out;
+	}
+
+	a_node = ctl->tm_queue_array[q_id].parent_a_node;
+	b_node = ctl->tm_a_node_array[a_node].parent_b_node;
+	c_node = ctl->tm_b_node_array[b_node].parent_c_node;
+	p = ctl->tm_c_node_array[c_node].parent_port;
+
+	if (anode)
+		*anode = a_node;
+	if (bnode)
+		*bnode = b_node;
+	if (cnode)
+		*cnode = c_node;
+	if (port)
+		*port = p;
+out:
+	if (rc < 0)
+		pr_info("mv_tm_scheme_queue_path_get error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_queue_path_get);
+
+
+int mv_tm_scheme_sub_nodes_get(enum tm_level level, int node_id, int *base, int *num)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	if (!base || !num) {
+		rc = -1;
+		goto out;
+	}
+
+	switch (level) {
+	case A_LEVEL:		/**< A-nodes Level */
+		rc = mv_tm_scheme_a_node_queues_get(node_id, base, num);
+		break;
+	case B_LEVEL:		/**< B-nodes Level */
+		rc = mv_tm_scheme_b_node_a_nodes_get(node_id, base, num);
+		break;
+	case C_LEVEL:		/**< C-nodes Level */
+		rc = mv_tm_scheme_c_node_b_nodes_get(node_id, base, num);
+		break;
+	case P_LEVEL:		/**< Ports Level */
+		rc = mv_tm_scheme_port_c_nodes_get(node_id, base, num);
+		break;
+	default:
+		rc = -1;
+		break;
+	}
+out:
+	if (rc < 0)
+		pr_info("%s error: %d\n", __func__, rc);
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_sub_nodes_get);
+
+
+int mv_tm_scheme_parent_node_get(enum tm_level level, int node_id, int *parent)
+{
+	uint8_t status;
+
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	/* check that node_id is legal */
+	rc = rm_node_status(ctl->rm, level, node_id, &status);
+	if ((rc) || (status != RM_TRUE)) {
+		pr_err("%s: Failed - TM level #%d, Node #%d is invalid\n", __func__, level, node_id);
+		rc = -1;
+		goto out;
+	}
+	if (!parent) {
+		rc = -1;
+		pr_err("%s: Failed - parent is NULL\n", __func__);
+		goto out;
+	}
+
+	switch (level) {
+	case Q_LEVEL:		/**< Q-nodes Level */
+		*parent = ctl->tm_queue_array[node_id].parent_a_node;
+		break;
+	case A_LEVEL:		/**< A-nodes Level */
+		*parent = ctl->tm_a_node_array[node_id].parent_b_node;
+		break;
+	case B_LEVEL:		/**< B-nodes Level */
+		*parent = ctl->tm_b_node_array[node_id].parent_c_node;
+		break;
+	case C_LEVEL:		/**< C-nodes Level */
+		*parent = ctl->tm_c_node_array[node_id].parent_port;
+		break;
+	case P_LEVEL:		/**< Ports Level */
+		pr_info("No parents for port level\n");
+		rc = -1;
+		break;
+	default:
+		pr_err("%s: Failed - Unexpected TM level %d\n", __func__, level);
+		rc = -1;
+		break;
+	}
+out:
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_scheme_parent_node_get);
+
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.h b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.h
new file mode 100644
index 0000000..6315905
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_scheme.h
@@ -0,0 +1,93 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef MV_TM_SCHEME__H
+#define MV_TM_SCHEME__H
+
+#include "common/mv_sw_if.h"
+#include "tm/mv_tm.h"
+
+enum mv_tm_source_type {
+	SOURCE_PPC_DP,  /* PP Data Path ports */
+	SOURCE_PPC_MNT, /* PP Control ports */
+	SOURCE_EMAC,    /* EMAC ports */
+	SOURCE_CMAC,    /* CMAC ports */
+	SOURCE_HMAC,    /* HMAC ports */
+	SOURCE_DROP,    /* Drop ports */
+	SOURCE_LAST
+};
+
+/* Return number of ports for given type.
+   Example: return 2 for tm_scheme_type_ports_num(SOURCE_PPC_MNT).
+   Return -1 for invalid type. */
+int mv_tm_scheme_type_ports_num(enum mv_tm_source_type type);
+
+/* Translate source type and id to port id.
+   Example: return 7 for tm_scheme_source_to_port(SOURCE_EMAC, 3) for A0.
+   Return -1 if source id is invalid. */
+int mv_tm_scheme_source_to_port(enum mv_tm_source_type type, int id);
+
+/* Translate port id to source type and source id, return -1 if port id is invalid. */
+int mv_tm_scheme_port_to_source(int port_id, int *source_id);
+
+/* Return total number of ports. */
+int mv_tm_scheme_ports_num(void);
+
+/* Return base and number of A nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_a_node_get(int port_id, int *base, int *num);
+
+/* Return base and number of B nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_b_nodes_get(int port_id, int *base, int *num);
+
+/* Return base and number of C nodes that attached to port number port_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_port_c_nodes_get(int port_id, int *base, int *num);
+
+
+/* Return base and number of B nodes that attached to Cnode number cnode_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_c_node_b_nodes_get(int bnode_id, int *base, int *num);
+
+/* Return base and number of A nodes that attached to B node number bnode_id.
+   Return -1 if port_id is invalid or not in use. */
+int mv_tm_scheme_b_node_a_nodes_get(int bnode_id, int *base, int *num);
+
+/* Return base and number of queues that attached to A node number anode_id.
+   Return -1 if anode_id is invalid or not in use. */
+int mv_tm_scheme_a_node_queues_get(int anode_id, int *base, int *num);
+
+int mv_tm_scheme_sub_nodes_get(enum tm_level, int node_id, int *base, int *num);
+int mv_tm_scheme_parent_node_get(enum tm_level level, int node_id, int *parent);
+
+/* Retrun A node, B node, C node and port number that attached to queue number q_id.
+   Return -1 if q_id is invalid or not in use. */
+int mv_tm_scheme_queue_path_get(int q_id, int *anode, int *bnode, int *cnode, int *port);
+
+#endif /* MV_TM_SCHEME__H */
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.c b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.c
new file mode 100644
index 0000000..78fd1c8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.c
@@ -0,0 +1,152 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mv_tm_shaping.h"
+#include "tm_shaping.h"
+#include "tm_errcodes.h"
+#include "tm_elig_prio_func.h"
+
+/* Public functions to be called from external modules */
+int mv_tm_set_shaping_ex(enum mv_tm_level level,
+						uint32_t index,
+						uint32_t cbw,
+						uint32_t ebw,
+						uint32_t *pcbs,
+						uint32_t *pebs)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_set_shaping_ex(ctl, TM_LEVEL(level), index, cbw, ebw, pcbs, pebs);
+	if (rc != 0) {
+		pr_info("tm_set_shaping_ex error: %d\n", rc);
+		if (rc == TM_CONF_MIN_TOKEN_TOO_LARGE) {
+			pr_info("cbs or ebs are too small , should be :");
+			if (*pcbs)
+				pr_info(" cbs = %u", *pcbs);
+			if (*pebs)
+				pr_info(" ebs = %u", *pebs);
+			pr_info("\n");
+		}
+	}
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_set_shaping_ex);
+
+int mv_tm_set_shaping(enum mv_tm_level level,
+						uint32_t index,
+						uint32_t cbw,
+						uint32_t ebw)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_set_shaping(ctl, TM_LEVEL(level), index, cbw, ebw);
+	if (rc != 0)
+		pr_info("tm_set_shaping error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_set_shaping);
+
+int mv_tm_set_min_shaping(enum mv_tm_level level,
+						uint32_t index,
+						uint32_t cbw)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_set_min_shaping(ctl, TM_LEVEL(level), index, cbw);
+	if (rc != 0)
+		pr_info("tm_set_min_shaping error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_set_min_shaping);
+
+int mv_tm_set_no_shaping(enum mv_tm_level level,
+						uint32_t index)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_set_no_shaping(ctl, TM_LEVEL(level), index);
+	if (rc != 0)
+		pr_info("tm_set_no_shaping error: %d\n", rc);
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_set_no_shaping);
+
+int mv_tm_get_shaping(enum mv_tm_level level, uint32_t index, uint32_t *cir, uint32_t *eir)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_read_shaping(ctl, TM_LEVEL(level), index, cir, eir, NULL, NULL);
+	if (rc != 0) {
+		pr_info("mv_tm_get_shaping error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+
+EXPORT_SYMBOL(mv_tm_get_shaping);
+
+int mv_tm_get_shaping_ex(enum mv_tm_level level, uint32_t index,
+						uint32_t *cir, uint32_t *eir, uint32_t *cbs, uint32_t *ebs)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_read_shaping(ctl, TM_LEVEL(level), index, cir, eir, cbs, ebs);
+	if (rc != 0) {
+		pr_info("mv_tm_get_shaping error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_get_shaping_ex);
+
+int mv_tm_get_shaping_full_info(enum mv_tm_level level, uint32_t index,
+								uint8_t *elig_fun, uint8_t *cir_eir_mask,
+								uint32_t *cir, uint32_t *eir,
+								uint32_t *cbs, uint32_t *ebs)
+{
+	TM_WRAPPER_BEGIN(qmtm_hndl, ctl, henv);
+
+	rc = tm_get_node_elig_prio_fun_info(ctl, TM_LEVEL(level), index, elig_fun, cir_eir_mask);
+	if (rc != 0) {
+		pr_info("mv_tm_get_shaping error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+	rc = tm_read_shaping(ctl, TM_LEVEL(level), index, cir, eir, cbs, ebs);
+	if (rc != 0) {
+		pr_info("mv_tm_get_shaping error: %d\n", rc);
+		TM_WRAPPER_END(qmtm_hndl);
+	}
+
+	TM_WRAPPER_END(qmtm_hndl);
+}
+EXPORT_SYMBOL(mv_tm_get_shaping_full_info);
diff --git a/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.h b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.h
new file mode 100644
index 0000000..d17b176
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/tm/wrappers/mv_tm_shaping.h
@@ -0,0 +1,82 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef MV_TM_SHAPING__H
+#define MV_TM_SHAPING__H
+
+#include "common/mv_sw_if.h"
+#include "tm/mv_tm.h"
+
+/* Maximal Shaping Rate [1Mbps]*/
+#define MV_TM_MAX_SHAPING_BW	TM_MAX_SHAPING_BW
+
+/*
+set shaping (CIR & EIR) [in resolution of 1Mb, in steps of 10Mb]  and CBS & EBS [in KB]
+passing NULL to pcbs/pebs causes to set default values to cbs/ebs
+*/
+int mv_tm_set_shaping_ex(enum mv_tm_level level, uint32_t index,
+						uint32_t cir, uint32_t eir, uint32_t *pcbs,	uint32_t *pebs);
+
+/* set shaping (CIR & EIR) [in resolution of 1Mb, in steps of 10Mb] */
+int mv_tm_set_shaping(enum mv_tm_level level, uint32_t index, uint32_t cir, uint32_t eir);
+
+/* set minimal shaping (CIR) [in resolution of 1Mb, in steps of 10Mb] */
+int mv_tm_set_min_shaping(enum mv_tm_level level, uint32_t index, uint32_t cir);
+
+/* disable shaping for node */
+int mv_tm_set_no_shaping(enum mv_tm_level level, uint32_t index);
+
+
+/* show shaping
+get shaping (CIR & EIR) [in resolution of 1Mb, in steps of 10Mb]
+passing NULL to parameter prevents it from reading
+*/
+int mv_tm_get_shaping(enum mv_tm_level level, uint32_t index, uint32_t *cir, uint32_t *eir);
+
+
+/* retrieve shaping parameters:
+shaping (CIR & EIR) [in resolution of 1Mb, in steps of 10Mb]  and CBS & EBS [in KB]
+passing NULL to parameter prevents it from reading
+*/
+
+int mv_tm_get_shaping_ex(enum mv_tm_level level, uint32_t index,
+						uint32_t *cir, uint32_t *eir, uint32_t *pcbs, uint32_t *pebs);
+
+/* retrieve all shaping concerning information:
+
+eligible function :
+cir_eir_mask :  if (mask & 1)- cir shaper used, if (mask & 2) - eir shaper used, if mask ==0 - shaping not used
+shaping (CIR & EIR) [in resolution of 1Mb, in steps of 10Mb]  and CBS & EBS [in KB]
+passing NULL to parameter prevents it from reading
+*/
+
+
+int mv_tm_get_shaping_full_info(enum mv_tm_level level, uint32_t index, uint8_t *elig_fun, uint8_t *cir_eir_mask,
+						uint32_t *cir, uint32_t *eir, uint32_t *pcbs, uint32_t *pebs);
+
+#endif /* MV_TM_SHAPING__H */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.c b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.c
new file mode 100644
index 0000000..60f8fde
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.c
@@ -0,0 +1,280 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+
+#include "hmac/mv_hmac_bm.h"
+#include "mv_pp3_cpu.h"
+#include "mv_pp3_pool.h"
+#include "fw/mv_pp3_fw_msg.h"
+
+struct pp3_cpu	**pp3_cpus;
+int		mv_pp3_cpus_num;
+
+/*---------------------------------------------------------------------------*/
+/*			Global CPU APIs					     */
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpus_global_init(struct mv_pp3 *priv, int cpus_num)
+{
+	pp3_cpus = kzalloc(cpus_num * sizeof(struct pp3_cpu *), GFP_KERNEL);
+	if (!pp3_cpus)
+		return -ENOMEM;
+
+	mv_pp3_cpus_num = cpus_num;
+	return 0;
+}
+
+int mv_pp3_cpu_close(struct mv_pp3 *priv, int cpu)
+{
+	if (pp3_cpus == NULL) {
+		pr_err("CPU component is not initialized yet\n");
+		return -1;
+	}
+	if (mv_pp3_max_check(cpu, mv_pp3_cpus_num, "cpu"))
+		return -1;
+
+	if (pp3_cpus[cpu] == NULL) {
+		pr_err("CPU %d is not allocated yet\n", cpu);
+		return -1;
+	}
+	mv_pp3_hmac_rxq_flush(pp3_cpus[cpu]->bm_frame, pp3_cpus[cpu]->bm_swq);
+	mv_pp3_hmac_rxq_delete(pp3_cpus[cpu]->bm_frame, pp3_cpus[cpu]->bm_swq);
+
+	return 0;
+}
+
+struct pp3_cpu *mv_pp3_cpu_get(int cpu)
+{
+	if (pp3_cpus == NULL) {
+		pr_err("CPU component is not initialized yet\n");
+		return NULL;
+	}
+	if (mv_pp3_max_check(cpu, mv_pp3_cpus_num, "cpu"))
+		return NULL;
+
+	return pp3_cpus[cpu];
+}
+
+struct pp3_cpu *mv_pp3_cpu_alloc(int cpu)
+{
+	struct pp3_cpu *cpu_ctrl;
+
+	if (mv_pp3_max_check(cpu, mv_pp3_cpus_num, "cpu"))
+		return NULL;
+
+	cpu_ctrl = kzalloc(sizeof(struct pp3_cpu), GFP_KERNEL);
+	MV_PP3_NULL_PTR(cpu_ctrl, oom);
+
+	if (pp3_cpus[cpu] != NULL) {
+		pr_err("CPU #%d is already exist\n", cpu);
+		return NULL;
+	}
+	cpu_ctrl->cpu = cpu;
+	pp3_cpus[cpu] = cpu_ctrl;
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	pr_info("\t  o Debug buffer: %d bytes of memory allocated\n", MV_PP3_DEBUG_BUFFER*4);
+	cpu_ctrl->occ_debug_buf = kzalloc(MV_PP3_DEBUG_BUFFER*4, GFP_KERNEL);
+	MV_PP3_NULL_PTR(cpu_ctrl->occ_debug_buf, oom);
+#endif
+
+	return cpu_ctrl;
+oom:
+	mv_pp3_cpu_delete(cpu_ctrl);
+	pr_err("%s: Out of memory\n", __func__);
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_sw_init(struct pp3_cpu *cpu_ctrl)
+{
+	MV_PP3_NULL_PTR(cpu_ctrl, err);
+
+	mv_pp3_cfg_dp_bmq_params_get(cpu_ctrl->cpu, &cpu_ctrl->bm_frame, &cpu_ctrl->bm_swq, NULL);
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_cpu_hw_init(struct pp3_cpu *cpu_ctrl)
+{
+	MV_PP3_NULL_PTR(cpu_ctrl, err);
+
+	if (mv_pp3_hmac_bm_queue_init(cpu_ctrl->bm_frame, cpu_ctrl->bm_swq, MV_PP3_HMAC_BM_Q_SIZE)) {
+		pr_err("%s: bm queue (frame #%d, queue %d) initialization failed\n",
+				__func__, cpu_ctrl->bm_frame, cpu_ctrl->bm_swq);
+		goto err;
+	}
+
+	mv_pp3_hmac_rxq_enable(cpu_ctrl->bm_frame, cpu_ctrl->bm_swq);
+	mv_pp3_hmac_txq_enable(cpu_ctrl->bm_frame, cpu_ctrl->bm_swq);
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+void mv_pp3_cpu_delete(struct pp3_cpu *cpu_ctrl)
+{
+	if (!cpu_ctrl)
+		return;
+
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	kfree(cpu_ctrl->occ_debug_buf);
+#endif
+
+	pr_info("%s: delete global cpu %d\n", __func__, cpu_ctrl->cpu);
+	kfree(cpu_ctrl);
+}
+
+/*---------------------------------------------------------------------------*/
+/*			Shared CPU APIs					     */
+/*---------------------------------------------------------------------------*/
+struct pp3_cpu_shared *mv_pp3_cpu_shared_alloc(struct mv_pp3 *priv)
+{
+	/* allocate netdev shared CPUs structure*/
+	struct pp3_cpu_shared *cpu_shared = kzalloc(sizeof(struct pp3_cpu_shared), GFP_KERNEL);
+
+	MV_PP3_NULL_PTR(cpu_shared, oom);
+
+	/* double size allocation - pools in pair mode */
+	cpu_shared->long_pool = mv_pp3_pool_alloc(2 * CONFIG_MV_PP3_BM_RX_POOL_CAPACITY);
+	MV_PP3_NULL_PTR(cpu_shared->long_pool, oom);
+	cpu_shared->long_pool->capacity = CONFIG_MV_PP3_BM_RX_POOL_CAPACITY;
+
+	if (priv->short_pool_buf_size > (NET_SKB_PAD + 32)) {
+		cpu_shared->short_pool = mv_pp3_pool_alloc(2 * CONFIG_MV_PP3_BM_RX_POOL_CAPACITY);
+		MV_PP3_NULL_PTR(cpu_shared->short_pool, oom);
+		cpu_shared->short_pool->capacity = CONFIG_MV_PP3_BM_RX_POOL_CAPACITY;
+	}
+
+	cpu_shared->txdone_pool = mv_pp3_pool_alloc(2 * CONFIG_MV_PP3_BM_LINUX_POOL_CAPACITY);
+	cpu_shared->txdone_pool->capacity = CONFIG_MV_PP3_BM_LINUX_POOL_CAPACITY;
+
+	cpu_shared->rx_pkt_mode = MV_PP3_PKT_LAST;
+
+	return cpu_shared;
+
+oom:
+	mv_pp3_cpu_shared_delete(cpu_shared);
+	pr_err("%s: Out of memory\n", __func__);
+	return NULL;
+
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_cpu_shared_sw_init(struct pp3_cpu_shared *cpu_shared, int max_pkt_size)
+{
+	MV_PP3_NULL_PTR(cpu_shared, err);
+
+	if (mv_pp3_pool_long_sw_init(cpu_shared->long_pool, NET_SKB_PAD, max_pkt_size) < 0)
+		goto err;
+
+	if (cpu_shared->short_pool) {
+		if (mv_pp3_pool_short_sw_init(cpu_shared->short_pool, NET_SKB_PAD,
+				pp3_device->short_pool_buf_size) < 0)
+			goto err;
+	}
+
+	if (mv_pp3_pool_txdone_sw_init(cpu_shared->txdone_pool) < 0)
+		goto err;
+
+	/* Init only if not changed by user */
+	if (cpu_shared->rx_pkt_mode ==  MV_PP3_PKT_LAST)
+		cpu_shared->rx_pkt_mode = MV_PP3_PKT_DRAM;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_cpu_shared_hw_init(struct pp3_cpu_shared *cpu_shared)
+{
+	MV_PP3_NULL_PTR(cpu_shared, err);
+
+	if (cpu_shared->long_pool)
+		if (mv_pp3_pool_hw_init(cpu_shared->long_pool) < 0)
+			goto err;
+
+	if (cpu_shared->short_pool)
+		if (mv_pp3_pool_hw_init(cpu_shared->short_pool) < 0)
+			goto err;
+
+	if (cpu_shared->lro_pool)
+		if (mv_pp3_pool_hw_init(cpu_shared->lro_pool) < 0)
+			goto err;
+
+	if (cpu_shared->txdone_pool)
+		if (mv_pp3_pool_hw_init(cpu_shared->txdone_pool) < 0)
+			goto err;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+void mv_pp3_cpu_shared_delete(struct pp3_cpu_shared *cpu_shared)
+{
+	if (!cpu_shared)
+		return;
+
+	mv_pp3_pool_delete(cpu_shared->long_pool);
+	mv_pp3_pool_delete(cpu_shared->short_pool);
+	mv_pp3_pool_delete(cpu_shared->lro_pool);
+	mv_pp3_pool_delete(cpu_shared->txdone_pool);
+	kfree(cpu_shared);
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Update FW with netdev if pools
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+int mv_pp3_cpu_shared_fw_set_pools(struct pp3_cpu_shared *shared)
+{
+	struct pp3_pool *pool;
+
+	pool = shared->long_pool;
+	if (pool) {
+		pp3_fw_bm_pool_set(pool);
+	} else {
+		pr_err("%s: long pool must be initialized\n", __func__);
+		goto err;
+	}
+
+	pool = shared->short_pool;
+	if (pool)
+		pp3_fw_bm_pool_set(pool);
+
+	pool = shared->lro_pool;
+	if (pool)
+		pp3_fw_bm_pool_set(pool);
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.h b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.h
new file mode 100644
index 0000000..64903d8
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_cpu.h
@@ -0,0 +1,90 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_cpu_h__
+#define __mv_pp3_cpu_h__
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+
+/* TBD. Temporary externals. Remove later */
+extern struct pp3_cpu	**pp3_cpus;
+extern int		mv_pp3_cpus_num;
+
+/************************/
+/*    CPU structures   */
+/************************/
+
+/* Masks used for pp3_cpu flags */
+#define MV_PP3_CPU_F_DBG_BUF_PUSH_BIT	0
+#define MV_PP3_CPU_F_DBG_BUF_POP_BIT	1
+
+#define MV_PP3_CPU_F_DBG_BUF_PUSH		(1 << MV_PP3_CPU_F_DBG_BUF_PUSH_BIT)
+#define MV_PP3_CPU_F_DBG_BUF_POP		(1 << MV_PP3_CPU_F_DBG_BUF_POP_BIT)
+
+/* CPU statistics */
+struct pp3_cpu_stats {
+	unsigned int lnx_fw_irq;
+	unsigned int lnx_fw_irq_err;
+};
+
+/* CPU control structure shared for all network devices */
+struct pp3_cpu {
+	int	cpu;      /* CPU number [0..nr_cpu_ids) for this CPU */
+	int	ref_cnt;  /* reference count of active CPU vports */
+	int	bm_frame; /* HMAC frame used to access BM */
+	int	bm_swq;   /* HMAC SWQ used to access BM*/
+	struct pp3_cpu_stats	stats;
+	unsigned long		flags;
+#ifdef CONFIG_MV_PP3_DEBUG_CODE
+	int			debug_txdone_occ;
+	int			*occ_debug_buf;
+	u32			occ_cur_buf;
+#endif
+};
+
+/* CPU shared per port structure*/
+struct pp3_cpu_shared {
+	struct mv_nss_ops	*gnss_ops;		/* Pointer to gnss_ops structure. If NULL use Linux functions */
+	struct pp3_pool		*long_pool;		/* BM pool used for long buffers - must be valid */
+	struct pp3_pool		*short_pool;		/* BM pool used for short buffers */
+	struct pp3_pool		*lro_pool;		/* BM pool used for LRO - page size buffers */
+	struct pp3_pool		*txdone_pool;           /* TX Done pool */
+	enum mv_pp3_pkt_mode	rx_pkt_mode;		/* RX mode used for this device */
+};
+
+/********************************/
+/*        GLOBAL CPU API        */
+/********************************/
+int mv_pp3_cpus_global_init(struct mv_pp3 *priv, int num_cpus);
+int mv_pp3_cpu_close(struct mv_pp3 *priv, int cpu);
+struct pp3_cpu *mv_pp3_cpu_alloc(int cpu);
+struct pp3_cpu *mv_pp3_cpu_get(int cpu);
+int mv_pp3_cpu_sw_init(struct pp3_cpu *cpu_ctrl);
+int mv_pp3_cpu_hw_init(struct pp3_cpu *cpu_ctrl);
+void mv_pp3_cpu_delete(struct pp3_cpu *cpu_ctrl);
+/*********************************/
+/*  SHARED PRE PORT CPU API      */
+/*********************************/
+struct pp3_cpu_shared *mv_pp3_cpu_shared_alloc(struct mv_pp3 *priv);
+int mv_pp3_cpu_shared_sw_init(struct pp3_cpu_shared *cpu_shared, int max_pkt_size);
+int mv_pp3_cpu_shared_hw_init(struct pp3_cpu_shared *cpu_shared);
+void mv_pp3_cpu_shared_delete(struct pp3_cpu_shared *cpu_shared);
+int mv_pp3_cpu_shared_fw_set_pools(struct pp3_cpu_shared *shared);
+
+#endif /* __mv_pp3_cpu_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.c b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.c
new file mode 100644
index 0000000..7082c7f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.c
@@ -0,0 +1,527 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "mv_pp3_cpu.h"
+#include "mv_pp3_pool.h"
+#include "bm/mv_bm.h"
+#include "qm/mv_qm.h"
+#include "hmac/mv_hmac_bm.h"
+
+static struct pp3_pool	**pp3_pools;
+static int		pp3_pools_num;
+static struct mv_pp3	*pp3_priv;
+
+/* Once time called pool component initialization function */
+int mv_pp3_pools_global_init(struct mv_pp3 *priv, int pools_num)
+{
+	pp3_pools = kzalloc(pools_num * sizeof(struct pp3_pool *), GFP_KERNEL);
+	if (!pp3_pools)
+		return -ENOMEM;
+
+	pp3_pools_num = pools_num;
+	pp3_priv = priv;
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+const char *mv_pp3_pool_name_get(struct pp3_pool *ppool)
+{
+	const char *type_str;
+
+	switch (ppool->type) {
+	case PP3_POOL_TYPE_DRAM:
+		return "QM DRAM ";
+	case PP3_POOL_TYPE_GPM:
+		return "QM GPM ";
+	case PP3_POOL_TYPE_GP:
+	default:
+		break;
+	}
+	switch (ppool->mode) {
+	case POOL_MODE_FREE:
+		type_str = "Free   ";
+		break;
+	case POOL_MODE_LONG:
+		type_str = "Long   ";
+		break;
+	case POOL_MODE_SHORT:
+		type_str = "Short  ";
+		break;
+	case POOL_MODE_LRO:
+		type_str = "LRO    ";
+		break;
+	case POOL_MODE_TXDONE:
+		type_str = "TxDone ";
+		break;
+	default:
+		type_str = "Unknown";
+	}
+	return type_str;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Allocate memory for a pool without attach pool ID. */
+struct pp3_pool *mv_pp3_pool_alloc(int capacity)
+{
+	struct pp3_pool *ppool;
+	int size;
+
+	if (capacity % 16) {
+		pr_err("%s: pool size must be multiple of 16\n", __func__);
+		return NULL;
+	}
+
+	ppool = kzalloc(sizeof(struct pp3_pool), GFP_KERNEL);
+	if (!ppool)
+		goto oom;
+
+	ppool->stats = alloc_percpu(struct pp3_pool_stats);
+	ppool->mode = POOL_MODE_FREE;
+	atomic_set(&ppool->in_use, 0);
+
+	size = sizeof(unsigned int) * capacity;
+
+	ppool->virt_base = dma_alloc_coherent(&pp3_priv->pdev->dev, size, &ppool->phys_base, GFP_KERNEL);
+	if (!ppool->virt_base) {
+		pr_err("%s: Can't allocate %d bytes of coherent memory for BM pool\n",
+			__func__, size);
+		goto oom;
+	}
+	ppool->capacity = capacity;
+
+	return ppool;
+
+oom:
+	pr_err("%s: out of memory\n", __func__);
+	if (ppool && ppool->virt_base)
+		dma_free_coherent(&pp3_priv->pdev->dev, size, ppool->virt_base, ppool->phys_base);
+
+	kfree(ppool);
+
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+
+struct pp3_pool *mv_pp3_pool_get(int pool)
+{
+	if (pp3_pools == NULL) {
+		pr_err("Pool component is not initialized yet\n");
+		return NULL;
+	}
+
+	if (mv_pp3_max_check(pool, pp3_pools_num, "pool"))
+		return NULL;
+
+	return pp3_pools[pool];
+}
+
+/* Attach pool structure with pool ID */
+int mv_pp3_pool_set_id(struct pp3_pool *ppool, int pool)
+{
+	if (pp3_pools == NULL) {
+		pr_err("Pool component is not initialized yet\n");
+		return -1;
+	}
+
+	if (mv_pp3_max_check(pool, pp3_pools_num, "pool"))
+		return -1;
+
+	if (pp3_pools[pool] != NULL) {
+		pr_err("Pool #%d is already exist\n", pool);
+		return -1;
+	}
+	ppool->pool = pool;
+	pp3_pools[pool] = ppool;
+
+	return 0;
+}
+
+/* Get pool ID from configurator and initialize GP pool
+   or update pool fields if pool ID already set */
+
+int mv_pp3_pool_long_sw_init(struct pp3_pool *ppool, int headroom, int max_pkt_size)
+{
+	MV_PP3_NULL_PTR(ppool, err);
+
+	if (ppool->buf_num) {
+		pr_err("%s: none empty pool, buffers number = %d\n",
+			__func__,  ppool->buf_num);
+		goto err;
+	}
+
+	if (!ppool->pool) {
+		mv_pp3_cfg_dp_gen_pool_id(&ppool->pool);
+
+		if (mv_pp3_max_check(ppool->pool, pp3_pools_num, "pool ID"))
+			return -1;
+
+		ppool->type = PP3_POOL_TYPE_GP;
+		ppool->pool_size = 0;
+		ppool->mode = POOL_MODE_LONG;
+		pp3_pools[ppool->pool] = ppool;
+	}
+
+	ppool->buf_size = headroom + max_pkt_size
+		+ SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
+	ppool->headroom = headroom;
+	ppool->pkt_max_size = max_pkt_size;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_pool_short_sw_init(struct pp3_pool *ppool, int headroom, int buf_size)
+{
+	int pool;
+
+	MV_PP3_NULL_PTR(ppool, err);
+
+	mv_pp3_cfg_dp_gen_pool_id(&pool);
+
+	if (mv_pp3_max_check(pool, pp3_pools_num, "pool"))
+		return -1;
+
+	ppool->pool = pool;
+	ppool->type = PP3_POOL_TYPE_GP;
+	ppool->pool_size = 0;
+	ppool->buf_size = buf_size;
+	ppool->mode = POOL_MODE_SHORT;
+	ppool->headroom = headroom;
+	ppool->pkt_max_size = ppool->buf_size - ppool->headroom -
+				SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
+	pp3_pools[pool] = ppool;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_pool_txdone_sw_init(struct pp3_pool *ppool)
+{
+	int pool;
+
+	MV_PP3_NULL_PTR(ppool, err);
+
+	mv_pp3_cfg_dp_gen_pool_id(&pool);
+
+	ppool->pool = pool;
+	ppool->mode = POOL_MODE_TXDONE;
+	ppool->type = PP3_POOL_TYPE_GP;
+	pp3_pools[pool] = ppool;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_pool_hw_init(struct pp3_pool *ppool)
+{
+	unsigned int ret_val;
+	struct mv_a40 pool_addr;
+
+	MV_PP3_NULL_PTR(ppool, err);
+
+	if (bm_gp_pid_validation(ppool->pool)) {
+		pr_err("%s: Invalid pool id #%d\n", __func__, ppool->pool);
+		goto err;
+	}
+
+	pool_addr.virt_lsb = (u32)ppool->virt_base;
+	pool_addr.virt_msb = 0;
+	pool_addr.dma_lsb = (u32)ppool->phys_base;
+	pool_addr.dma_msb = 0;
+
+	ret_val = bm_gp_pool_def_basic_init(ppool->pool, 2 * ppool->capacity, &pool_addr);
+
+	if (ret_val) {
+		pr_err("%s: HW pool %d initialization failed\n",  __func__, ppool->pool);
+		goto err;
+	}
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_pool_delete(struct pp3_pool *ppool)
+{
+	if (!ppool)
+		return;
+
+	/* Free buffers only from general purpose (GP) pools */
+	if (ppool->type == PP3_POOL_TYPE_GP)
+		if (ppool->buf_num != 0)
+			pr_warn("%s: delete none empty pool %d", __func__, ppool->pool);
+
+	pr_info("%s: Free pool %d\n", __func__, ppool->pool);
+	kfree(ppool->virt_base);
+	free_percpu(ppool->stats);
+	kfree(ppool);
+}
+
+/*---------------------------------------------------------------------------*/
+/* QM GPM pools 0,1 private init					     */
+/*---------------------------------------------------------------------------*/
+void mv_pp3_pools_qm_gpm_sw_init(struct pp3_pool *pool0, struct pp3_pool *pool1)
+{
+	pool0->capacity = BM_QM_GPM_POOL_CAPACITY;
+	pool1->capacity = BM_QM_GPM_POOL_CAPACITY;
+	pool0->type = PP3_POOL_TYPE_GPM;
+	pool1->type = PP3_POOL_TYPE_GPM;
+}
+/*---------------------------------------------------------------------------*/
+/* QM GPM pools 2,3 private init                                             */
+/*---------------------------------------------------------------------------*/
+void mv_pp3_pools_qm_dram_sw_init(struct pp3_pool *pool0, struct pp3_pool *pool1)
+{
+	pool0->capacity = BM_QM_DRAM_POOL_CAPACITY;
+	pool1->capacity = BM_QM_DRAM_POOL_CAPACITY;
+	pool0->type = PP3_POOL_TYPE_DRAM;
+	pool1->type = PP3_POOL_TYPE_DRAM;
+}
+/*---------------------------------------------------------------------------*/
+/* QM GPM pools HW init init                                                 */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_pools_qm_hw_init(struct pp3_pool *ppool0, struct pp3_pool *ppool1)
+{
+	struct mv_a40 pool_0_addr, pool_1_addr;
+	int ret_val;
+
+	pool_0_addr.virt_lsb = (u32)ppool0->virt_base;
+	pool_0_addr.dma_lsb = (u32)ppool0->phys_base;
+	pool_1_addr.virt_lsb = (u32)ppool1->virt_base;
+	pool_1_addr.dma_lsb = (u32)ppool1->phys_base;
+
+	pool_0_addr.virt_msb = 0;
+	pool_0_addr.dma_msb = 0;
+	pool_1_addr.virt_msb = 0;
+	pool_1_addr.dma_msb = 0;
+
+	if (ppool0->type != ppool1->type) {
+		pr_err("%s: Different pools type\n", __func__);
+		goto err;
+	}
+
+	if (ppool0->type == PP3_POOL_TYPE_GPM)
+		/* QM GPM pools */
+		ret_val = bm_qm_gpm_pools_def_quick_init(ppool1->capacity, &pool_0_addr, &pool_1_addr);
+	else if (ppool0->type == PP3_POOL_TYPE_DRAM)
+		/* QM DRAM pools */
+		ret_val = bm_qm_dram_pools_def_quick_init(&pp3_priv->pdev->dev, ppool1->capacity,
+									&pool_0_addr, &pool_1_addr);
+	else {
+		pr_err("%s: Invalid pools type %d\n", __func__, ppool0->type);
+		goto err;
+	}
+
+	if (ret_val < 0)
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: Function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+/* push buffer to bm pool                                                    */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_pool_buff_put(int pool, void __iomem *virt, dma_addr_t phys_addr)
+{
+	int cpu = smp_processor_id();
+	struct pp3_cpu *cpu_priv = mv_pp3_cpu_get(cpu);
+	int queue, frame;
+
+	queue = cpu_priv->bm_swq;
+	frame = cpu_priv->bm_frame;
+
+	if (mv_pp3_hmac_bm_buff_put(frame, queue, pool, phys_addr, (unsigned int)virt)) {
+		mv_pp3_hmac_txq_occ_get(frame, queue);
+		if (mv_pp3_hmac_bm_buff_put(frame, queue, pool, phys_addr, (unsigned int)virt))
+			return -1;
+	}
+	STAT_DBG(PPOOL_STATS(pp3_pools[pool], cpu)->buff_put++);
+
+	/* Memory barrier to ensure that CFH written to DRAM before HMAC transmit triggered */
+	wmb();
+
+	mv_pp3_hmac_txq_send(frame, queue, 1);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/************************/
+/*   Debug pool APIs    */
+/************************/
+void pp3_dbg_pool_status_print(int pool)
+{
+	struct pp3_pool *ppool;
+
+	if ((pool < 0) || (pool >= BM_POOLS_NUM)) {
+		pr_err("%s: Invalid pool number - %d\n", __func__, pool);
+		return;
+	}
+
+	if (!pp3_pools || (!pp3_pools[pool])) {
+		pr_err("Pool #%d not initialized\n", pool);
+		return;
+	}
+	ppool = pp3_pools[pool];
+
+	pr_info("\n----------- BM pool #%d - %s Status -------------\n",
+		pool, mv_pp3_pool_name_get(ppool));
+
+	pr_info("size = %d, capacity = %d, virt_base = 0x%08x, phys_base = 0x%08x\n",
+		ppool->pool_size, ppool->capacity, (u32)ppool->virt_base,  (u32)ppool->phys_base);
+
+	pr_info("buf size = %d, pkt_max_size = %d\n",
+			ppool->buf_size, ppool->pkt_max_size);
+	pr_info("buf num = %d, in_use_tresh = %d, in_use = %d\n",
+		ppool->buf_num, ppool->in_use_thresh, atomic_read(&ppool->in_use));
+}
+/*---------------------------------------------------------------------------*/
+
+int pp3_dbg_pool_dump(int pool, int v)
+{
+	int i;
+	struct pp3_pool *ppool;
+	u32 *arr;
+
+	if ((pool < 0) || (pool >= BM_POOLS_NUM)) {
+		pr_err("%s: pool=%d is out of range\n", __func__, pool);
+		return -EINVAL;
+	}
+
+	if (v) {
+
+		if ((pp3_pools == NULL) || (pp3_pools[pool] == NULL)) {
+			pr_err("%s: pool=%d is not initialized\n", __func__, pool);
+			return -EINVAL;
+		}
+
+		ppool = pp3_pools[pool];
+
+		arr = (u32 *)ppool->virt_base;
+
+		for (i = 0; i < ppool->capacity; i = i + 2)
+			pr_info("%d	virt = 0x%08x	phys = 0x%08x\n", i/2, arr[i+1], arr[i]);
+	}
+
+	pr_info("\n");
+
+	bm_pool_status_dump(pool);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+
+/* Clear BM pool statistics */
+void pp3_dbg_pool_stats_clear(int pool)
+{
+	struct pp3_pool *ppool;
+	int cpu;
+
+	if ((pool < 0) || (pool >= BM_POOLS_NUM)) {
+		pr_err("%s: Invalid pool number - %d\n", __func__, pool);
+		return;
+	}
+	if (!pp3_pools || (!pp3_pools[pool])) {
+		pr_err("Pool #%d not initialized\n", pool);
+		return;
+	}
+	ppool = pp3_pools[pool];
+
+	for_each_possible_cpu(cpu)
+		memset(PPOOL_STATS(ppool, cpu), 0, sizeof(struct pp3_pool_stats));
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print BM pool statistics */
+void pp3_dbg_pool_stats_print(int pool)
+{
+	struct pp3_pool *ppool;
+	struct pp3_pool_stats total_stats;
+	int cpu;
+
+	if ((pool < 0) || (pool >= BM_POOLS_NUM)) {
+		pr_err("%s: Invalid pool number - %d\n", __func__, pool);
+		return;
+	}
+	if (!pp3_pools || (!pp3_pools[pool])) {
+		pr_err("Pool #%d not initialized\n", pool);
+		return;
+	}
+	ppool = pp3_pools[pool];
+
+	pr_info("\n----------- BM pool #%d - %s Statistics ---------\n",
+		ppool->pool, mv_pp3_pool_name_get(ppool));
+
+	pr_info("buff_num............................%10d\n", ppool->buf_num);
+	pr_info("buff_in_use.........................%10d\n", atomic_read(&ppool->in_use));
+
+	/* Calculate summary for all CPUs */
+	memset(&total_stats, 0, sizeof(total_stats));
+	for_each_possible_cpu(cpu) {
+		total_stats.buff_rx += PPOOL_STATS(ppool, cpu)->buff_rx;
+		total_stats.buff_get_request += PPOOL_STATS(ppool, cpu)->buff_get_request;
+		total_stats.buff_get_timeout_err += PPOOL_STATS(ppool, cpu)->buff_get_timeout_err;
+		total_stats.buff_get_zero += PPOOL_STATS(ppool, cpu)->buff_get_zero;
+		total_stats.buff_get_dummy += PPOOL_STATS(ppool, cpu)->buff_get_dummy;
+		total_stats.buff_get += PPOOL_STATS(ppool, cpu)->buff_get;
+		total_stats.buff_put += PPOOL_STATS(ppool, cpu)->buff_put;
+		total_stats.buff_alloc_err += PPOOL_STATS(ppool, cpu)->buff_alloc_err;
+		total_stats.buff_alloc += PPOOL_STATS(ppool, cpu)->buff_alloc;
+		total_stats.buff_free += PPOOL_STATS(ppool, cpu)->buff_free;
+#ifdef CONFIG_MV_PP3_TSO
+		total_stats.buff_free_tso += PPOOL_STATS(ppool, cpu)->buff_free_tso;
+#endif
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+		total_stats.buff_recycled_ok += PPOOL_STATS(ppool, cpu)->buff_recycled_ok;
+		total_stats.buff_recycled_err += PPOOL_STATS(ppool, cpu)->buff_recycled_err;
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+	}
+
+       /* Print summary only */
+	pr_info("buff_rx.............................%10d\n", total_stats.buff_rx);
+	pr_info("buff_get_request....................%10d\n", total_stats.buff_get_request);
+	pr_info("buff_get_timeout_err................%10d\n", total_stats.buff_get_timeout_err);
+	pr_info("buff_get_zero.......................%10d\n", total_stats.buff_get_zero);
+	pr_info("buff_get_dummy......................%10d\n", total_stats.buff_get_dummy);
+	pr_info("buff_get............................%10d\n", total_stats.buff_get);
+	pr_info("buff_put............................%10d\n", total_stats.buff_put);
+	pr_info("buff_alloc..........................%10d\n", total_stats.buff_alloc);
+	pr_info("buff_free...........................%10d\n", total_stats.buff_free);
+	pr_info("buff_alloc_err......................%10d\n", total_stats.buff_alloc_err);
+#ifdef CONFIG_MV_PP3_TSO
+	pr_info("buff_free_tso.......................%10d\n", total_stats.buff_free_tso);
+#endif
+#ifdef CONFIG_MV_PP3_SKB_RECYCLE
+	pr_info("buff_recycled_ok....................%10d\n", total_stats.buff_recycled_ok);
+	pr_info("buff_recycled_err...................%10d\n", total_stats.buff_recycled_err);
+#endif /* CONFIG_MV_PP3_SKB_RECYCLE */
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.h b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.h
new file mode 100644
index 0000000..bd2d71e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_pool.h
@@ -0,0 +1,111 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_pool_h__
+#define __mv_pp3_pool_h__
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+
+#define PPOOL_STATS(ppool, cpu)		per_cpu_ptr((ppool)->stats, (cpu))
+
+/************************/
+/*   pool structures    */
+/************************/
+enum  pp3_pool_type {
+	PP3_POOL_TYPE_GP = 0,
+	PP3_POOL_TYPE_DRAM,
+	PP3_POOL_TYPE_GPM,
+	PP3_POOL_TYPE_LAST
+};
+
+enum pp3_pool_mode {
+	POOL_MODE_FREE = 0,
+	POOL_MODE_LONG,
+	POOL_MODE_SHORT,
+	POOL_MODE_LRO,
+	POOL_MODE_TXDONE,
+	POOL_MODE_LAST
+};
+
+struct pp3_pool_stats {
+	unsigned int buff_rx;
+	unsigned int buff_get_request;
+	unsigned int buff_get;
+	unsigned int buff_get_zero;
+	unsigned int buff_put;
+	unsigned int buff_get_timeout_err;
+	unsigned int buff_alloc_err;
+	unsigned int buff_alloc;
+	unsigned int buff_free;
+	unsigned int buff_recycled_ok;
+	unsigned int buff_recycled_err;
+	unsigned int buff_get_dummy;
+	unsigned int buff_free_tso;
+};
+
+struct pp3_pool {
+	int pool;
+	int capacity;
+	int pool_size;
+	int buf_num;
+	int headroom;
+	int buf_size;
+	int pkt_max_size;
+	atomic_t in_use;
+	int in_use_thresh;
+	void __iomem *virt_base;
+	dma_addr_t phys_base;
+	unsigned int flags;
+	enum pp3_pool_mode mode;
+	enum pp3_pool_type type;
+	struct pp3_pool_stats __percpu *stats;
+};
+
+
+/************************/
+/*   user pools APIs    */
+/************************/
+int mv_pp3_pool_buff_put(int pool, void __iomem *virt, dma_addr_t phys_addr);
+const char *mv_pp3_pool_name_get(struct pp3_pool *ppool);
+int mv_pp3_pools_global_init(struct mv_pp3 *priv, int pools_num);
+struct pp3_pool *mv_pp3_pool_get(int pool);
+int mv_pp3_pool_set_id(struct pp3_pool *ppool, int pool);
+struct pp3_pool *mv_pp3_pool_alloc(int capacity);
+int mv_pp3_pool_long_sw_init(struct pp3_pool *ppool, int headroom, int max_pkt_size);
+int mv_pp3_pool_short_sw_init(struct pp3_pool *ppool, int headroom, int buf_size);
+int mv_pp3_pool_txdone_sw_init(struct pp3_pool *ppool);
+int mv_pp3_pool_hw_init(struct pp3_pool *ppool);
+void mv_pp3_pool_delete(struct pp3_pool *ppool);
+
+/************************/
+/*   QM/GPM pools APIs  */
+/************************/
+void mv_pp3_pools_qm_gpm_sw_init(struct pp3_pool *pool0, struct pp3_pool *pool1);
+void mv_pp3_pools_qm_dram_sw_init(struct pp3_pool *pool0, struct pp3_pool *pool1);
+int mv_pp3_pools_qm_hw_init(struct pp3_pool *ppool0, struct pp3_pool *ppool1);
+
+/************************/
+/*   Debug pool APIs    */
+/************************/
+void pp3_dbg_pool_status_print(int pool);
+void pp3_dbg_pool_stats_print(int pool);
+void pp3_dbg_pool_stats_clear(int pool);
+int pp3_dbg_pool_dump(int pool, int v);
+
+#endif /* __mv_pp3_pool_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.c b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.c
new file mode 100644
index 0000000..e6acab2
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.c
@@ -0,0 +1,335 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "hmac/mv_hmac.h"
+
+#include "mv_pp3_swq.h"
+
+
+#define MV_PP3_DBG_SWQ_CNT_DUMP(swq, num, cpu, name, name_pref, pr_name, pr_zero)\
+	mv_pp3_swq_cnt(swq, num, cpu, offsetof(struct pp3_swq_stats, name)/4, #name, name_pref, pr_name, pr_zero)
+
+struct pp3_swq *mv_pp3_swq_alloc(void)
+{
+	struct pp3_swq *swq = kzalloc(sizeof(struct pp3_swq), GFP_KERNEL);
+
+	return swq;
+}
+/*---------------------------------------------------------------------------*/
+
+
+int mv_pp3_rx_swq_sw_init(struct pp3_swq *rx_swq, int frame, int swq, int hwq, int irq_group)
+{
+	MV_PP3_NULL_PTR(rx_swq, err);
+
+	rx_swq->frame_num = frame;
+	rx_swq->swq = swq;
+	rx_swq->queue.rx.irq_group = irq_group;
+
+	if (mv_pp3_cfg_rx_bp_node_get(hwq, &rx_swq->queue.rx.node_type, &rx_swq->queue.rx.node_id) < 0) {
+		pr_err("%s: can't get back pressure parameters (hwq #%d)\n", __func__, hwq);
+		goto err;
+	}
+	if (!rx_swq->cfh_dg_size)
+		rx_swq->cfh_dg_size = MV_PP3_CFH_DG_MAX_NUM;
+
+	if (!rx_swq->cur_size)
+		rx_swq->cur_size = CONFIG_MV_PP3_RXQ_SIZE;
+
+	if (!rx_swq->queue.rx.pkt_coal)
+		rx_swq->queue.rx.pkt_coal = CONFIG_MV_PP3_RX_COAL_PKTS;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_tx_swq_sw_init(struct pp3_swq *tx_swq, int frame, int swq, int hwq)
+{
+
+	MV_PP3_NULL_PTR(tx_swq, err);
+
+	tx_swq->frame_num = frame;
+	tx_swq->swq = swq;
+	tx_swq->queue.tx.hwq = hwq;
+
+	if (!tx_swq->cur_size)
+		tx_swq->cur_size = CONFIG_MV_PP3_TXQ_SIZE;
+
+	if (!tx_swq->cfh_dg_size)
+		tx_swq->cfh_dg_size = MV_PP3_CFH_DG_MAX_NUM;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_rx_swq_hw_init(struct pp3_swq *rx_swq)
+{
+	MV_PP3_NULL_PTR(rx_swq, err);
+
+	/* HMAC RXQ allocated accordingly with maximum possible number of dg per packet */
+	if (mv_pp3_hmac_rxq_init(rx_swq->frame_num, rx_swq->swq, rx_swq->cur_size * MV_PP3_CFH_DG_MAX_NUM) == NULL)
+		goto err;
+
+	mv_pp3_hmac_rxq_pkt_coal_set(rx_swq->frame_num, rx_swq->swq, rx_swq->queue.rx.pkt_coal * rx_swq->cfh_dg_size);
+	mv_pp3_hmac_rxq_bp_node_set(rx_swq->frame_num, rx_swq->swq, rx_swq->queue.rx.node_type,
+		rx_swq->queue.rx.node_id);
+
+	if (mv_pp3_hmac_rxq_bp_thresh_set(rx_swq->frame_num, rx_swq->swq, rx_swq->cur_size * rx_swq->cfh_dg_size))
+		goto err;
+
+	mv_pp3_hmac_rxq_event_cfg(rx_swq->frame_num, rx_swq->swq, 0, rx_swq->queue.rx.irq_group);
+	mv_pp3_hmac_rxq_enable(rx_swq->frame_num, rx_swq->swq);
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_tx_swq_hw_init(struct pp3_swq *tx_swq)
+{
+	int dg_num;
+
+	MV_PP3_NULL_PTR(tx_swq, err);
+
+	/* HMAC TXQ allocated accordingly with maximum possible number of dg per packet */
+	dg_num = tx_swq->cur_size * MV_PP3_CFH_DG_MAX_NUM;
+	if (mv_pp3_hmac_txq_init(tx_swq->frame_num, tx_swq->swq, dg_num, 0) == NULL)
+		goto err;
+
+	mv_pp3_hmac_queue_qm_mode_cfg(tx_swq->frame_num, tx_swq->swq, tx_swq->queue.tx.hwq);
+	mv_pp3_hmac_txq_enable(tx_swq->frame_num, tx_swq->swq);
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/* set RX/TX SWQ CFH size in datagrames					     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_swq_cfh_size_set(struct pp3_swq *swq, int dg_size)
+{
+	MV_PP3_NULL_PTR(swq, err);
+
+	if ((dg_size > MV_PP3_CFH_DG_MAX_NUM)  || (dg_size < 0)) {
+		pr_err("%s: invalid CFH size %d, valid range in datagrames is [0, %d]\n",
+			__func__, dg_size, MV_PP3_CFH_DG_MAX_NUM);
+			goto err;
+	}
+
+	swq->cfh_dg_size = dg_size;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_swq_rx_pkt_coal_set(struct pp3_swq *swq, int pkts_num)
+{
+	mv_pp3_hmac_rxq_pkt_coal_set(swq->frame_num, swq->swq, pkts_num * swq->cfh_dg_size);
+
+	swq->queue.rx.pkt_coal = pkts_num;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_swq_rx_time_prof_set(struct pp3_swq *swq, int prof)
+{
+	mv_pp3_hmac_rxq_time_coal_profile_set(swq->frame_num, swq->swq, prof);
+
+	swq->queue.rx.time_prof = prof;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_swq_rx_time_coal_set(struct pp3_swq *swq, int usec)
+{
+	mv_pp3_hmac_frame_time_coal_set(swq->frame_num, swq->queue.rx.time_prof, usec);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------*/
+/* set RX/TX SWQ size in packets					     */
+/*---------------------------------------------------------------------------*/
+int mv_pp3_rx_swq_size_set(struct pp3_swq *swq, int pkts)
+{
+	int dg_num, rc;
+
+	if (pkts < MV_PP3_RX_SWQ_SIZE_MIN) {
+		pr_err("%s: RX SWQ size #%d [pkts] is too small. minimum is #%d [pkts]\n",
+			__func__, pkts, MV_PP3_RX_SWQ_SIZE_MIN);
+		return -1;
+	}
+	dg_num = pkts * swq->cfh_dg_size;
+
+	rc = mv_pp3_hmac_rxq_bp_thresh_set(swq->frame_num, swq->swq, dg_num);
+	if (rc)
+		return -1;
+
+	swq->cur_size = pkts;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_tx_swq_size_set(struct pp3_swq *swq, int pkts)
+{
+	int dg_num, rc;
+
+	dg_num = pkts * swq->cfh_dg_size;
+	rc = mv_pp3_hmac_txq_capacity_cfg(swq->frame_num, swq->swq, dg_num);
+	if (rc)
+		return -1;
+
+	swq->cur_size = pkts;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_swq_delete(struct pp3_swq *rx_swq)
+{
+	kfree(rx_swq);
+	/* TODO - free rxq memory, split HMAC function */
+}
+/*---------------------------------------------------------------------------*/
+
+
+/*---------------------------------------------------------------------------
+mv_pp3_queue_cnt
+	print counter values from swq list
+	calculate and print sum value for swq_num > 1
+Inputs:
+	swq        - array of VQueues pointers
+	swq_num    - size of array
+	cnt_index - counter index
+	name      - counter name
+	name_pref - preffix to be added to counter name
+	pr_name   - if true, print counter name
+	pr_zero   - if true, print zero counter values
+---------------------------------------------------------------------------*/
+static void mv_pp3_swq_cnt(struct pp3_swq **swq, int swq_num, int cpu, int cnt_index,
+	const char *name, const char *name_pref, bool pr_name, bool pr_zero)
+{
+	int q, str_len = 0, sum = 0;
+	unsigned int *stats;
+	char str[200];
+	int str_size = 200;
+	bool print_flag;
+
+	if (pr_name)
+		str_len = snprintf(str + str_len, str_size - str_len, "%s%-12s%d%-8s", name_pref, name, cpu, "");
+	else
+		str_len = snprintf(str + str_len, str_size - str_len, "%-15s%d%-8s", "", cpu, "");
+
+	print_flag = (pr_zero) ? true : false;
+
+	for (q = 0; q < swq_num; q++) {
+		if (swq[q]) {
+			stats = (unsigned int *)&swq[q]->stats;
+			sum += stats[cnt_index];
+			str_len += snprintf(str + str_len, str_size - str_len, "%-10u     ", stats[cnt_index]);
+			if (stats[cnt_index])
+				print_flag |= true;
+		} else
+			str_len += snprintf(str + str_len, str_size - str_len, "%-10s     ", "NA");
+	}
+
+	if (swq_num > 1)
+		str_len += snprintf(str + str_len, str_size - str_len, "%u\n", sum);
+	else
+		str_len += snprintf(str + str_len, str_size - str_len, "\n");
+
+	if (print_flag)
+		pr_cont("%s", str);
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------
+mv_pp3_swq_cnt_dump_header
+	print SWQ counters header
+		swq_num - number of SWQs to be dump
+---------------------------------------------------------------------------*/
+void mv_pp3_swq_cnt_dump_header(int swq_num)
+{
+	char line1[200];
+	char line2[200];
+	int q;
+	int str_len1;
+	int str_len2;
+	int str_size = 200;
+
+	str_len1 = str_len2 = 0;
+	str_len1 += sprintf(line1, "%-14scpu%-7s", "", "");
+	str_len2 += sprintf(line2, "----------------------------------");
+
+	for (q = 0; q < swq_num; q++) {
+		str_len1 += snprintf(line1 + str_len1, str_size - str_len1, "swq%d %-10s", q, "");
+		str_len2 += snprintf(line2 + str_len2, str_size - str_len2, "-----------------");
+	}
+
+	pr_cont("%s", line1);
+	if (swq_num > 1)
+		pr_cont("SUM");
+	pr_info("%s\n", line2);
+}
+
+/*---------------------------------------------------------------------------
+mv_pp3_swq_cnt_dump
+	print swq counters according to number of swq_num
+	print only if counter is not zeroed
+	calculate and print sum value for swq_num > 1
+	inputs:
+		swq - array of CPU SWQs pointers
+		cpu_swq_num - size of array
+		cnt_index - stat counter index
+		name - counter name
+---------------------------------------------------------------------------*/
+void mv_pp3_swq_cnt_dump(const char *cntr_pref, int cpu, struct pp3_swq **swq, int swq_num, bool pr_cntr_name)
+{
+	MV_PP3_DBG_SWQ_CNT_DUMP(swq, swq_num, cpu, pkts, cntr_pref, pr_cntr_name, true);
+	MV_PP3_DBG_SWQ_CNT_DUMP(swq, swq_num, cpu, suspend, cntr_pref, pr_cntr_name, false);
+	MV_PP3_DBG_SWQ_CNT_DUMP(swq, swq_num, cpu, resumed, cntr_pref, pr_cntr_name, false);
+	MV_PP3_DBG_SWQ_CNT_DUMP(swq, swq_num, cpu, pkts_drop, cntr_pref, pr_cntr_name, false);
+	MV_PP3_DBG_SWQ_CNT_DUMP(swq, swq_num, cpu, pkts_errors, cntr_pref, pr_cntr_name, false);
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_swq_stats_clear(struct pp3_swq *swq)
+{
+	memset(&swq->stats, 0, sizeof(struct pp3_swq_stats));
+}
+/*---------------------------------------------------------------------------*/
+
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.h b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.h
new file mode 100644
index 0000000..d9774d7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_swq.h
@@ -0,0 +1,91 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_swq_h__
+#define __mv_pp3_swq_h__
+
+/* Minimum size in packets for RX SWQ */
+#define MV_PP3_RX_SWQ_SIZE_MIN	128
+
+/************************/
+/* SWQs structures      */
+/************************/
+
+struct pp3_swq_stats {
+	uint64_t pkts;
+	uint64_t bytes;
+	uint64_t pkts_drop;
+	uint64_t pkts_errors;
+	uint64_t suspend;
+	uint64_t resumed;
+};
+
+/* HMAC RX SWQ structure */
+struct pp3_rx_swq {
+	int	node_id;	/* node_id for BP from HMAC to QM */
+	int	node_type;	/* node type for BP from HMAC to QM */
+	int	pkt_coal;	/* RX packet coalecing [pkts] */
+	int	time_prof;	/* RX time coalescing profile */
+	int	irq_group;	/* RX irq group */
+};
+
+/* HMAC TX SWQ structure */
+struct pp3_tx_swq {
+	int	hwq;		/* connected HWQ */
+};
+
+
+struct pp3_swq {
+	int			frame_num;	/* HMAC frame number */
+	int			swq;		/* HMAC SWQ number [0..15] */
+	int			cur_size;	/* current queue size in packets */
+	int			cfh_dg_size;	/* cfh size in DG for one packet */
+	struct pp3_swq_stats	stats;		/* SWQ statistics */
+	bool			stats_reset_flag;/* statistic counters after reset flag */
+	union {
+		struct pp3_rx_swq rx;
+		struct pp3_tx_swq tx;
+	} queue;
+};
+
+/************************/
+/*   HMAC SWQs APIs     */
+/************************/
+struct pp3_swq *mv_pp3_swq_alloc(void);
+
+int mv_pp3_rx_swq_sw_init(struct pp3_swq *rx_swq, int frame, int swq, int hwq, int irq_group);
+int mv_pp3_tx_swq_sw_init(struct pp3_swq *tx_swq, int frame, int swq, int hwq);
+
+int mv_pp3_rx_swq_hw_init(struct pp3_swq *rx_swq);
+int mv_pp3_tx_swq_hw_init(struct pp3_swq *tx_swq);
+
+void mv_pp3_swq_delete(struct pp3_swq *swq);
+
+void mv_pp3_swq_cnt_dump_header(int num);
+void mv_pp3_swq_cnt_dump(const char *cntr_pref, int cpu, struct pp3_swq **q, int num, bool pr_cntr_name);
+void mv_pp3_swq_stats_clear(struct pp3_swq *swq);
+
+int mv_pp3_swq_cfh_size_set(struct pp3_swq *swq, int dg_size);
+
+int mv_pp3_rx_swq_size_set(struct pp3_swq *swq, int pkts);
+int mv_pp3_tx_swq_size_set(struct pp3_swq *swq, int pkts);
+int mv_pp3_swq_rx_pkt_coal_set(struct pp3_swq *swq, int pkts_num);
+int mv_pp3_swq_rx_time_prof_set(struct pp3_swq *swq, int prof);
+int mv_pp3_swq_rx_time_coal_set(struct pp3_swq *swq, int usec);
+
+#endif /* __mv_pp3_swq_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.c b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.c
new file mode 100644
index 0000000..361225f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.c
@@ -0,0 +1,797 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+
+#include "mv_pp3_vport.h"
+#include "mv_pp3_vq.h"
+#include "mv_pp3_cpu.h"
+#include "gop/mv_gop_if.h"
+#include "gop/mv_ptp_if.h"
+#include "net_dev/mv_ptp_service.h"
+#include "emac/mv_emac.h"
+#include "hmac/mv_hmac.h"
+#include "qm/mv_qm.h"
+#include "gop/mv_smi.h"
+#include "tm/wrappers/mv_tm_scheme.h"
+#include "tm/wrappers/mv_tm_shaping.h"
+#include "fw/mv_pp3_fw_msg.h"
+
+#define PP3_DBG_GROUP_CNT_DUMP(vp, num, name)\
+	mv_pp3_cpu_vport_cnt(vp, num, offsetof(struct pp3_cpu_vp_stats, name)/4, #name)
+
+int mv_pp3_rx_pkts_to_dg(enum mv_pp3_pkt_mode pkt_mode, int pkts)
+{
+	int dg = 0;
+
+	/* CFH size depends on rx_pkt_mode */
+	if (pkt_mode == MV_PP3_PKT_DRAM)
+		dg = pkts * MV_PP3_CFH_PKT_DG_SIZE;
+	else if (pkt_mode == MV_PP3_PKT_CFH)
+		dg = (pkts * MV_PP3_CFH_DG_MAX_NUM);
+	else
+		pr_err("unknown rx_pkt_mode #%d\n", pkt_mode);
+
+	return dg;
+}
+
+int mv_pp3_rx_dg_to_pkts(enum mv_pp3_pkt_mode pkt_mode, int dg)
+{
+	int pkts = 0;
+
+	/* CFH size depends on rx_pkt_mode */
+	if (pkt_mode == MV_PP3_PKT_DRAM)
+		pkts = dg / MV_PP3_CFH_PKT_DG_SIZE;
+	else if (pkt_mode == MV_PP3_PKT_CFH)
+		pkts = dg / MV_PP3_CFH_DG_MAX_NUM;
+	else
+		pr_err("unknown rx_pkt_mode #%d\n", pkt_mode);
+	return pkts;
+}
+/*---------------------------------------------------------------------------*/
+
+/* array of virtual ports driver work with.                             */
+/* this array doesn't store application virtual ports                   */
+/* internal cpu ports are stored start from (MV_PP3_NSS_EXT_PORT_MAX + 1)  */
+struct pp3_vport	**pp3_vports;
+static int		pp3_vports_num;
+
+/* Once time called vport component initialization function */
+int mv_pp3_vports_global_init(struct mv_pp3 *priv, int vports_num)
+{
+	pp3_vports = kzalloc(vports_num * sizeof(struct pp3_vport *), GFP_KERNEL);
+	if (!pp3_vports)
+		return -ENOMEM;
+
+	pp3_vports_num = vports_num;
+	return 0;
+}
+
+struct pp3_vport *mv_pp3_vport_alloc(int vp, enum mv_nss_port_type vp_type, int rxqs_num, int txqs_num)
+{
+	struct pp3_vport *vport;
+	enum mv_pp3_queue_type vq_type;
+	int vq;
+
+	/* Alloc group */
+	vport = kzalloc(sizeof(struct pp3_vport), GFP_KERNEL);
+	if (!vport)
+		goto oom;
+
+	/* External vport (WLAN) - skip VQs allocation */
+	if (vp_type != MV_PP3_NSS_PORT_EXT) {
+
+		vq_type = (vp_type == MV_PP3_NSS_PORT_CPU) ? MV_PP3_PPC_TO_HMAC : MV_PP3_EMAC_TO_PPC;
+		/* Allocate pointers for ingress virtual queues */
+		for (vq = 0; vq < rxqs_num; vq++) {
+			vport->rx_vqs[vq] = mv_pp3_vq_alloc(vq, vq_type);
+			if (!vport->rx_vqs[vq])
+				goto oom;
+		}
+
+		vq_type = (vp_type == MV_PP3_NSS_PORT_CPU) ? MV_PP3_HMAC_TO_PPC : MV_PP3_PPC_TO_EMAC;
+		/* Allocate pointers for egress virtual queues */
+		for (vq = 0; vq < txqs_num; vq++) {
+			vport->tx_vqs[vq] = mv_pp3_vq_alloc(vq, vq_type);
+			if (!vport->tx_vqs[vq])
+				goto oom;
+		}
+
+		vport->rx_vqs_num = rxqs_num;
+		vport->tx_vqs_num = txqs_num;
+	}
+
+	vport->type = vp_type;
+	vport->vport = vp;
+	vport->dest_vp = MV_NSS_PORT_NONE;
+
+	if (vp_type == MV_PP3_NSS_PORT_CPU)
+		vp += MV_PP3_INTERNAL_CPU_PORT_BASE;
+
+	pp3_vports[vp] = vport;
+
+	return vport;
+oom:
+	mv_pp3_vport_delete(vport);
+	pr_err("%s: Out of memory\n", __func__);
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_sw_init(struct pp3_vport *vport, struct cpumask *rx_cpus, int cpu)
+{
+	int vq, irq_group, dg, i;
+
+	MV_PP3_NULL_PTR(vport, err);
+
+	if (vport->type != MV_PP3_NSS_PORT_CPU) {
+		pr_err("%s: vport %d - incorrect type\n", __func__, vport->vport);
+		goto err;
+	}
+
+	/* init NAPI related */
+	vport->port.cpu.napi_q_num = vport->rx_vqs_num;
+	vport->port.cpu.napi_master_array = 0;
+	vport->port.cpu.napi_next_array = 0;
+
+	if (cpumask_test_cpu(cpu, rx_cpus)) {
+		if (mv_pp3_cfg_dp_gen_irq_group(vport->vport, cpu, &irq_group) < 0)
+			goto err;
+
+		vport->port.cpu.irq_num = mv_pp3_cfg_rx_irq_get(vport->vport, irq_group);
+
+		for (vq = 0; vq < vport->rx_vqs_num; vq++) {
+			if (vport->rx_vqs[vq]) {
+				if (mv_pp3_ingress_cpu_vq_sw_init(vport->vport, vport->rx_vqs[vq], irq_group)) {
+					pr_err("%s: vport #%d failed to init ingress vq #%d cpu #%d\n", __func__,
+						vport->vport, vq, cpu);
+					goto err;
+				}
+				dg = mv_pp3_rx_pkts_to_dg(vport->port.cpu.cpu_shared->rx_pkt_mode, 1);
+				mv_pp3_swq_cfh_size_set(vport->rx_vqs[vq]->swq, dg);
+
+				for (i = 0; i < 3; i++)
+					vport->port.cpu.napi_proc_qs[i][vq] = vport->rx_vqs[vq]->vq;
+			}
+		}
+	}
+
+	for (vq = 0; vq < vport->tx_vqs_num; vq++) {
+		if (vport->tx_vqs[vq]) {
+			if (mv_pp3_egress_cpu_vq_sw_init(vport->vport, vport->tx_vqs[vq], cpu)) {
+				pr_err("%s: vport #%d failed to init egress vq #%d cpu #%d\n", __func__,
+					vport->vport, vq, cpu);
+				goto err;
+			}
+		}
+	}
+	vport->port.cpu.cpu_num = cpu;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_emac_vport_sw_init(struct pp3_vport *vport, int emac, struct mv_mac_data *mac_data)
+{
+	int vq;
+
+	MV_PP3_NULL_PTR(vport, err);
+	MV_PP3_NULL_PTR(mac_data, err);
+
+	if (vport->type != MV_PP3_NSS_PORT_ETH) {
+		pr_err("%s: vport %d - incorrect type\n", __func__, vport->vport);
+		goto err;
+	}
+
+	for (vq = 0; vq < vport->rx_vqs_num; vq++) {
+		if (vport->rx_vqs[vq]) {
+			if (mv_pp3_ingress_emac_vq_sw_init(vport->rx_vqs[vq], emac)) {
+				pr_err("%s: vport #%d failed to init ingress vq #%d emac #%d\n", __func__,
+					vport->vport, vq, emac);
+				goto err;
+			}
+		}
+	}
+	for (vq = 0; vq < vport->tx_vqs_num; vq++) {
+		if (vport->tx_vqs[vq]) {
+			if (mv_pp3_egress_emac_vq_sw_init(vport->tx_vqs[vq], emac)) {
+				pr_err("%s: vport #%d failed to init egress vq #%d emac #%d\n", __func__,
+					vport->vport, vq, emac);
+				goto err;
+			}
+		}
+	}
+
+	vport->port.emac.emac_num = emac;
+	vport->port.emac.lc_irq_num = mac_data->link_irq;
+	vport->port.emac.port_mode = mac_data->port_mode;
+	vport->port.emac.force_link = mac_data->force_link;
+	vport->port.emac.phy_addr = mac_data->phy_addr;
+	vport->port.emac.flags = 0;
+	vport->port.emac.l2_options = MV_NSS_NON_PROMISC_MODE;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_hw_init(struct pp3_vport *vport)
+{
+	int vq;
+
+	MV_PP3_NULL_PTR(vport, err);
+
+	for (vq = 0; vq < vport->rx_vqs_num; vq++) {
+		if (vport->rx_vqs[vq]) {
+			if (mv_pp3_vq_hw_init(vport->rx_vqs[vq])) {
+				pr_err("%s: vport #%d failed to init ingress vq #%d\n", __func__,
+					vport->vport, vq);
+				goto err;
+			}
+		}
+	}
+
+	for (vq = 0; vq < vport->tx_vqs_num; vq++) {
+		if (vport->tx_vqs[vq]) {
+			if (mv_pp3_vq_hw_init(vport->tx_vqs[vq])) {
+				pr_err("%s: vport #%d failed to init egress vq #%d\n", __func__,
+					vport->vport, vq);
+				goto err;
+			}
+		}
+	}
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_emac_vport_hw_init(struct pp3_vport *vport)
+{
+	int vq, emac;
+	int qm_port[4] = {4, 5, 6, 7};
+
+	MV_PP3_NULL_PTR(vport, err);
+
+	emac = vport->port.emac.emac_num;
+
+	/* configure port PHY address */
+	mv_gop_phy_addr_cfg(emac, vport->port.emac.phy_addr);
+	/* enebale MAC PTP unit */
+	mv_pp3_ptp_enable(emac, true);
+	mv_pp3_ptp_tai_tod_uio_init(pp3_device->pdev);
+	mv_pp3_gop_port_init(emac, vport->port.emac.port_mode);
+	/* disable link event on current port */
+	mv_pp3_gop_port_events_mask(emac);
+	mv_pp3_gop_port_enable(emac);
+
+	if (vport->port.emac.force_link)
+		mv_pp3_gop_fl_cfg(emac);
+
+	qm_tail_ptr_mode(emac, true);
+
+	for (vq = 0; vq < vport->rx_vqs_num; vq++) {
+		if (vport->rx_vqs[vq]) {
+
+			/* do not call to mv_pp3_vq_hw_init, function not relevant for EMAC vport*/
+
+			/*if (mv_tm_scheme_queue_path_get(vport->rx_vqs[vq]->hwq, NULL, NULL, NULL, &qm_port))
+				goto err;*/
+
+			mv_pp3_emac_init(emac, qm_port[emac], vport->rx_vqs[vq]->hwq);
+
+			/* config emac->pcc queue for QM secret machine */
+			qm_xoff_emac_qnum_set(emac, vport->rx_vqs[vq]->hwq);
+
+			/* set emac threshold profile and attached emac->ppc queue to profile */
+			if (qm_emac_profile_set(emac, vport->port.emac.port_mode, vport->rx_vqs[vq]->hwq) < 0)
+				goto err;
+		}
+	}
+	/* Nothing to config in egress */
+
+	vport->port.emac.flags |= BIT(MV_PP3_EMAC_F_INIT_BIT);
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_vport_delete(struct pp3_vport *vport)
+{
+	int vq, vp;
+
+	if (!vport)
+		return;
+
+	for (vq = 0; vq < vport->rx_vqs_num; vq++)
+		if (vport->rx_vqs[vq])
+			mv_pp3_vq_delete(vport->rx_vqs[vq]);
+
+	for (vq = 0; vq < vport->tx_vqs_num; vq++)
+		if (vport->tx_vqs[vq])
+			mv_pp3_vq_delete(vport->tx_vqs[vq]);
+
+	if (vport->type == MV_PP3_NSS_PORT_CPU)
+		vp = MV_PP3_INTERNAL_CPU_PORT_BASE + vport->vport;
+	else
+		vp = vport->vport;
+
+	pp3_vports[vp] = NULL;
+
+	kfree(vport);
+
+	pr_info("%s: delete vport %d\n", __func__, vport->vport);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Supported for EMAC virtual ports only */
+int mv_pp3_egress_vport_shaper_set(struct pp3_vport *emac_vp, struct mv_nss_meter *meter)
+{
+	int rc, pnode, cbs_good, ebs_good;
+
+	if (!emac_vp || (emac_vp->type != MV_PP3_NSS_PORT_ETH)) {
+		pr_err("Supported only for EMAC vitual ports\n");
+		return -1;
+	}
+	pnode = TM_A0_PORT_EMAC0 + emac_vp->port.emac.emac_num;
+	cbs_good = meter->cbs;
+	ebs_good = meter->ebs;
+	rc = mv_tm_set_shaping_ex(TM_P_LEVEL, pnode, meter->cir, meter->eir, &cbs_good, &ebs_good);
+	if (rc) {
+		if (meter->cbs != cbs_good) {
+			/* cbs value is too small. Use minimal valid value instead */
+			pr_warn("%s: cbs = %d KBytes is too small. Use cbs = %d KBytes\n",
+				__func__, meter->cbs, cbs_good);
+		}
+
+		if (meter->ebs != ebs_good) {
+			/* ebs value is too small. Use minimal valid value instead */
+			pr_warn("%s: ebs = %d KBytes is too small. Use ebs = %d KBytes\n",
+				__func__, meter->ebs, ebs_good);
+		}
+
+		rc = mv_tm_set_shaping_ex(TM_P_LEVEL, pnode, meter->cir, meter->eir, &cbs_good, &ebs_good);
+		if (rc)
+			return rc;
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_rx_pkt_coal_set(struct pp3_vport *cpu_vp, int pkts_num)
+{
+	int vq;
+
+	for (vq = 0; vq < cpu_vp->rx_vqs_num; vq++) {
+		if (cpu_vp->rx_vqs[vq] && cpu_vp->rx_vqs[vq]->swq)
+			mv_pp3_swq_rx_pkt_coal_set(cpu_vp->rx_vqs[vq]->swq, pkts_num);
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_rx_time_prof_set(struct pp3_vport *cpu_vp, int prof)
+{
+	int vq;
+
+	for (vq = 0; vq < cpu_vp->rx_vqs_num; vq++) {
+		if (cpu_vp->rx_vqs[vq] && cpu_vp->rx_vqs[vq]->swq)
+			mv_pp3_swq_rx_time_prof_set(cpu_vp->rx_vqs[vq]->swq, prof);
+	}
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_rx_time_coal_set(struct pp3_vport *cpu_vp, int usec)
+{
+	int vq;
+
+	/* all queues connected to the same timer profile */
+	for (vq = 0; vq < cpu_vp->rx_vqs_num; vq++)
+		if (cpu_vp->rx_vqs[vq] && cpu_vp->rx_vqs[vq]->swq)
+			return mv_pp3_swq_rx_time_coal_set(cpu_vp->rx_vqs[vq]->swq, usec);
+
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------
+description:
+	Update FW with rx vq map, relevant only for ppc->hmac mapping
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+static int mv_pp3_vport_fw_set_rx_vq_map(struct pp3_vport *vport)
+{
+	int q, swq;
+
+	if (!vport) {
+		pr_err("%s: null vport ptr\n", __func__);
+		return -1;
+	}
+
+	if (vport->type != MV_PP3_NSS_PORT_CPU) {
+		pr_err("%s: function relevant only for ppc->hmac mapping\n", __func__);
+		return -1;
+	}
+
+	for (q = 0; q < vport->rx_vqs_num; q++) {
+		if (!vport->rx_vqs[q] || !vport->rx_vqs[q]->swq)
+			continue;
+
+		swq = MV_PP3_HMAC_PHYS_SWQ_NUM(vport->rx_vqs[q]->swq->swq, vport->rx_vqs[q]->swq->frame_num);
+
+		pp3_fw_vq_map_set(vport->vport, q, MV_PP3_PPC_TO_HMAC, swq, vport->rx_vqs[q]->hwq);
+	}
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Update FW with tx vq map
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+static int mv_pp3_vport_fw_set_tx_vq_map(struct pp3_vport *vport)
+{
+	int q;
+
+	if (!vport) {
+		pr_err("%s: null vport ptr\n", __func__);
+		return -1;
+	}
+
+	if (vport->type != MV_PP3_NSS_PORT_ETH) {
+		pr_err("%s: function relevant only for ppc->emac mapping\n", __func__);
+		return -1;
+	}
+
+	for (q = 0; q < vport->tx_vqs_num; q++) {
+
+		if (!vport->tx_vqs[q])
+			continue;
+
+		/* FW ignore swq (0) in ppc->emac mapping */
+		pp3_fw_vq_map_set(vport->vport, q, MV_PP3_PPC_TO_EMAC, 0, vport->tx_vqs[q]->hwq);
+	}
+
+	return 0;
+}
+
+/*---------------------------------------------------------------------------
+description:
+	Update FW with cpu vport
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+int pp3_cpu_vport_fw_set(struct pp3_vport *vport)
+{
+	if (!vport) {
+		pr_err("%s:Error, null vport ptr\n", __func__);
+		return -1;
+	}
+
+	pp3_fw_internal_cpu_vport_set(vport);
+	/*cpu rxq*/
+	mv_pp3_vport_fw_set_rx_vq_map(vport);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------
+description:
+	Update FW with  emac vport
+
+return values:
+		success: 0
+		fail: -1
+---------------------------------------------------------------------------*/
+int pp3_emac_vport_fw_set(struct pp3_vport *vport, unsigned char *mac)
+{
+
+	if (!vport) {
+		pr_info("%s: error null vp ptr\n", __func__);
+		return -1;
+	}
+
+	pp3_fw_emac_vport_set(vport, mac);
+
+	mv_pp3_vport_fw_set_tx_vq_map(vport);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/*---------------------------------------------------------------------------
+mv_pp3_cpu_vport_cnt
+	print cpu vport counter values according to number of cpu_vp_num
+	print only if counter is not zeroed
+	calculate and print sum value for cpu_vp_num > 1
+	inputs:
+		cpu_vp - array of CPU VPORTs pointers
+		cpu_vp_num - size of array
+		cnt_index - stat counter index
+		name - counter name
+---------------------------------------------------------------------------*/
+static void mv_pp3_cpu_vport_cnt(struct pp3_vport **cpu_vp, int cpu_vp_num, int cnt_index, const char *name)
+{
+	int cpu, str_len = 0, sum = 0;
+	unsigned int *stats;
+	char str[100];
+	bool print_flag = false;
+
+	str_len += sprintf(str + str_len, "%-24s", name);
+
+	for (cpu = 0; cpu < cpu_vp_num; cpu++) {
+		if (cpu_vp[cpu]) {
+			stats = (unsigned int *)&cpu_vp[cpu]->port.cpu.stats;
+			sum += stats[cnt_index];
+			str_len += sprintf(str + str_len, "%-15u", stats[cnt_index]);
+			if (stats[cnt_index])
+				print_flag |= true;
+		} else
+			str_len += sprintf(str + str_len, "%-15s", "NA");
+	}
+
+	if (cpu_vp_num > 1)
+		str_len += sprintf(str + str_len, "%u\n", sum);
+	else
+		str_len += sprintf(str + str_len, "\n");
+
+	if (print_flag)
+		pr_cont("%s", str);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print Host software collected statistics of network interface */
+/*---------------------------------------------------------------------------
+mv_pp3_cpu_vport_cnt_dump
+	print cpu vport counter values according to number of cpu_vp_num
+	print only if counter is not zeroed
+	calculate and print sum value for cpu_vp_num > 1
+	inputs:
+		cpu_vp - array of CPU VPORTs pointers
+		cpu_vp_num - size of array
+		cnt_index - stat counter index
+		name - counter name
+---------------------------------------------------------------------------*/
+void mv_pp3_cpu_vport_cnt_dump(struct pp3_vport **cpu_vp, int cpu_num)
+{
+	char line1[100];
+	char line2[100];
+	int cpu, num;
+	int str_len1, str_len2;
+
+	str_len1 = 0;
+	str_len2 = 0;
+
+	for (cpu = 0, num = 0; cpu < cpu_num; cpu++)
+		if (cpu_vp[cpu]) {
+			num++;
+			str_len1 = sprintf(line1 + str_len1, "vport #%d %-6s", cpu_vp[cpu]->vport, "");
+			str_len2 = sprintf(line2 + str_len2, " [cpu=%d] %-6s", cpu_vp[cpu]->port.cpu.cpu_num, "");
+		}
+
+	pr_cont("%s", line1);
+	if (num > 1)
+		pr_cont(" SUM");
+	pr_cont("\n%22s %s\n", "", line2);
+	pr_info("------------------------------------------------------------------------\n");
+
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, irq);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, irq_err);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, napi_sched);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, napi_enter);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, napi_complete);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_pkt_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_bytes);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_err);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_csum_l3_err);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_csum_l4_err);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_drop_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_netif);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_netif_drop);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_buf_pkt);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_split_pkt);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_cfh_pkt);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_cfh_dummy_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_cfh_invalid_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_cfh_reassembly_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_csum_sw);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, rx_csum_hw);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_pkt_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_bytes);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_cfh_pkt);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_drop_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_no_resource_calc);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_csum_sw);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_csum_hw);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_sg_bytes);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_sg_pkts);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_sg_err);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_sg_frags);
+#ifdef CONFIG_MV_PP3_TSO
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_tso_skb);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_tso_pkts);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_tso_bytes);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_tso_frags);
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, tx_tso_err);
+#endif
+	PP3_DBG_GROUP_CNT_DUMP(cpu_vp, num, txdone);
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+/* Print out CPU internal virtual port statistics */
+int mv_pp3_cpu_vport_stats_dump(int vport)
+{
+	char name[100];
+	struct pp3_vport *vp;
+
+	if (vport >= MV_NSS_PORT_NONE)
+		return -1;
+
+	sprintf(name, "\nvport stats:");
+	pr_info("\n%-24s", name);
+
+	vp = pp3_vports[vport + MV_PP3_INTERNAL_CPU_PORT_BASE];
+	if (vp) {
+		if (vp->type == MV_PP3_NSS_PORT_CPU)
+			mv_pp3_cpu_vport_cnt_dump(&vp, 1);
+	} else
+		pr_info("Virtual port %d not active\n", vport);
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_cpu_vport_stats_clear(int vport)
+{
+	struct pp3_vport *cpu_vp;
+
+	cpu_vp = pp3_vports[vport + MV_PP3_INTERNAL_CPU_PORT_BASE];
+	if (cpu_vp)
+		memset(&cpu_vp->port.cpu.stats, 0, sizeof(struct pp3_cpu_vp_stats));
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print out virtual ports are used by driver */
+void mv_pp3_vports_dump(void)
+{
+	int vport, cpu_vp;
+	struct pp3_vport *vp;
+
+	pr_info("\nVPort %8s %8s %9s %11s %11s\n", "Type", "EMAC", "DstVp", "TxVqNum", "RxVqNum");
+	pr_info("------------------------------------------------------------\n");
+	for (vport = MV_NSS_ETH_PORT_MIN; vport <= MV_NSS_EXT_PORT_MAX; vport++) {
+		vp = pp3_vports[vport];
+		if (!vp)
+			continue;
+
+		pr_info("%5d %8s %8d %8d %11d %11d\n", vp->vport,
+			(vp->type == MV_PP3_NSS_PORT_ETH) ? "ETH" : "EXT",
+			(vp->type == MV_PP3_NSS_PORT_ETH) ? vp->port.emac.emac_num : -1,
+			vp->dest_vp, vp->tx_vqs_num, vp->rx_vqs_num);
+	}
+	pr_info("\n");
+
+	pr_info("\nVPort %8s %8s %9s %11s %11s\n", "Type", "CPU", "DstVp", "TxVqNum", "RxVqNum");
+	pr_info("------------------------------------------------------------\n");
+	for (cpu_vp = MV_PP3_INTERNAL_CPU_PORT_MIN; cpu_vp <= MV_PP3_INTERNAL_CPU_PORT_MAX; cpu_vp++) {
+		vport = cpu_vp + MV_PP3_INTERNAL_CPU_PORT_BASE;
+
+		vp = pp3_vports[vport];
+		if (!vp)
+			continue;
+
+		pr_info("%5d %8s %8d %8d %11d %11d\n", vp->vport,
+			(vp->type == MV_PP3_NSS_PORT_CPU) ? "CPU" : "WRONG",
+			(vp->type == MV_PP3_NSS_PORT_CPU) ? vp->port.cpu.cpu_num : -1,
+			vp->dest_vp, vp->tx_vqs_num, vp->rx_vqs_num);
+	}
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+
+/* Print statistics for all sw queues belong the CPU internal virtual port */
+void mv_pp3_cpu_vport_vqs_stats_dump(int vport)
+{
+	struct pp3_vport *vp;
+	int q_num;
+
+	if (!pp3_vports[vport + MV_PP3_INTERNAL_CPU_PORT_BASE])
+		return;
+
+	vp = pp3_vports[vport + MV_PP3_INTERNAL_CPU_PORT_BASE];
+	q_num = MV_MAX(vp->tx_vqs_num, vp->rx_vqs_num);
+
+	pr_info("\ncpu port #%d: queues stats\n", vp->vport);
+	mv_pp3_vqueue_cnt_dump_header(q_num);
+	/* print txqs stats */
+	mv_pp3_vqueue_cnt_dump("tx_", vp->port.cpu.cpu_num, vp->tx_vqs, vp->tx_vqs_num, true);
+	/* print rxqs stats */
+	mv_pp3_vqueue_cnt_dump("rx_", vp->port.cpu.cpu_num, vp->rx_vqs, vp->rx_vqs_num, true);
+	pr_info("\n");
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_vport_fw_stat_print(int vport, struct mv_pp3_fw_vport_stat *stat)
+{
+	pr_info("\nvport #%2d - FW stats\n", vport);
+	pr_info("------------------------------------------------------------------------\n");
+	pr_info("Number of bytes received high             %10u\n", stat->rx_bytes_high);
+	pr_info("Number of bytes received low              %10u\n", stat->rx_bytes_low);
+	pr_info("Number of bytes transmitted high          %10u\n", stat->tx_bytes_high);
+	pr_info("Number of bytes transmitted low           %10u\n", stat->tx_bytes_low);
+	pr_info("Number of packets received high           %10u\n", stat->rx_packets_high);
+	pr_info("Number of packets received low            %10u\n", stat->rx_packets_low);
+	pr_info("Number of packets transmitted high        %10u\n", stat->tx_packets_high);
+	pr_info("Number of packets transmitted low         %10u\n", stat->tx_packets_low);
+	pr_info("Number of errors received high            %10u\n", stat->rx_errors_high);
+	pr_info("Number of errors received low             %10u\n", stat->rx_errors_low);
+	pr_info("Number of errors transmitted high         %10u\n", stat->tx_errors_high);
+	pr_info("Number of errors transmitted low          %10u\n", stat->tx_errors_low);
+}
+/*---------------------------------------------------------------------------*/
+
+/* Print FW vport statistics collected per EMAC or external virtual port */
+void mv_pp3_vport_fw_stats_dump(int vport)
+{
+	struct mv_pp3_fw_vport_stat vport_stats;
+
+	if (!pp3_vports[vport])
+		return;
+
+	if (pp3_fw_vport_stat_get(vport, &vport_stats) == 0)
+		mv_pp3_vport_fw_stat_print(vport, &vport_stats);
+
+	return;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_vport_fw_stats_clear(int vport)
+{
+	int err;
+
+	if (!pp3_vports[vport])
+		return -1;
+
+	err = pp3_fw_clear_stat_set(MV_PP3_FW_VPORT_STAT, vport);
+
+	return err;
+}
+
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.h b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.h
new file mode 100644
index 0000000..1a9154f
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vport.h
@@ -0,0 +1,171 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#ifndef __mv_pp3_vport_h__
+#define __mv_pp3_vport_h__
+
+#include "common/mv_sw_if.h"
+#include "mv_pp3_pool.h"
+
+struct pp3_vq;
+
+/* number of virtual ports are stored by driver                         */
+/* include internal cpu vports, EMAC vports and external vports         */
+/* EMAC vports and external vports are stored according to vport number */
+/* internal cpu ports are stored start from (MV_NSS_EXT_PORT_MAX + 1)  */
+#define MV_PP3_COMMON_VPORTS_NUM	(MV_PP3_INTERNAL_CPU_PORT_NUM + MV_NSS_EXT_PORT_MAX + 1)
+#define MV_PP3_INTERNAL_CPU_PORT_BASE	(MV_NSS_EXT_PORT_MAX + 1)
+
+/************************/
+/*   vport structures   */
+/************************/
+
+/* Masks used for pp3_emac flags */
+#define MV_PP3_EMAC_F_INIT_BIT		0
+
+/* EMAC port structure */
+struct pp3_emac {
+	int			emac_num;               /* EMAC number */
+	struct tasklet_struct	lc_tasklet;             /* Link change tasklet */
+	int			lc_irq_num;             /* Link change IRQ number */
+	char                    lc_irq_name[15];	/* Link change IRQ name */
+	enum mv_port_mode	port_mode;              /* Port mode: RXAUI, SGMII, etc. */
+	bool			force_link;             /* Force link or don't force link */
+	int			phy_addr;               /* PHY address. -1 if EMAC is not connected to PHY */
+	int			mtu;			/* maximum transmission unit */
+	unsigned char		l2_options;		/* L2 filtering options */
+	unsigned long		flags;
+};
+
+struct pp3_cpu_vp_stats {
+	unsigned int irq;
+	unsigned int irq_err;
+	unsigned int rx_err;
+	unsigned int rx_csum_l4_err;
+	unsigned int rx_csum_l3_err;
+	unsigned int napi_sched;
+	unsigned int napi_enter;
+	unsigned int napi_complete;
+	unsigned int rx_netif;
+	unsigned int rx_netif_drop;
+	unsigned int rx_pkt_calc;
+	unsigned int rx_split_pkt;
+	unsigned int rx_cfh_pkt;
+	unsigned int rx_buf_pkt;
+	unsigned int rx_bytes;
+	unsigned int rx_drop_calc;
+	unsigned int rx_cfh_dummy_calc;
+	unsigned int rx_cfh_reassembly_calc;
+	unsigned int rx_cfh_invalid_calc;
+	unsigned int rx_csum_hw;
+	unsigned int rx_csum_sw;
+	unsigned int rx_gro;
+	unsigned int rx_gro_bytes;
+	unsigned int rx_no_pool;
+	unsigned int tx_pkt_calc;
+	unsigned int tx_bytes;
+	unsigned int tx_cfh_pkt;
+	unsigned int tx_drop_calc;
+	unsigned int tx_no_resource_calc;
+	unsigned int tx_csum_hw;
+	unsigned int tx_csum_sw;
+	unsigned int tx_sg_bytes;
+	unsigned int tx_sg_pkts;
+	unsigned int tx_sg_err;
+	unsigned int tx_sg_frags;
+	unsigned int tx_tso_skb;
+	unsigned int tx_tso_pkts;
+#ifdef CONFIG_MV_PP3_TSO
+	unsigned int tx_tso_bytes;
+	unsigned int tx_tso_frags;
+	unsigned int tx_tso_err;
+#endif
+	unsigned int txdone;
+};
+
+/* CPU port structure */
+struct pp3_cpu_port {
+	int			cpu_num;                /* CPU number */
+	int			irq_num;                /* RX IRQ number */
+	int			txdone_todo;		/* number of trasmited buffers that not released yet */
+	char			irq_name[15];		/* RX IRQ name */
+	struct pp3_cpu		*cpu_ctrl;              /* Pointer to physical CPU control structure */
+	struct pp3_cpu_shared	*cpu_shared;		/* Pointer to shared CPU structure (per poort)*/
+	struct pp3_cpu_vp_stats	stats;                  /* Pointer to CPU virtual port statistics */
+	struct mv_pp3_timer	txdone_timer;		/* TX done - free buffers form linux pool */
+	struct napi_struct	napi;			/* NAPI structure */
+	int			napi_q_num;		/* number of queues processed by napi */
+	int			napi_proc_qs[3][MV_PP3_VQ_NUM];
+	int			napi_master_array;	/* list of queues actually processed by napi */
+	int			napi_next_array;	/* list of queues arranged for next process loop */
+};
+
+/* General Virtual port structure */
+struct pp3_vport {
+	int			vport;                  /* virtual port number */
+	bool			state;			/* UP (1) or DOWN (0) */
+	void			*root;			/* pointer to root device */
+	int			cos;			/* class of service */
+	int			dest_vp;		/* Default egress virtual port number */
+	enum mv_nss_port_type	type;                   /* EMAC or CPU */
+	int			tx_vqs_num;             /* Number of egress virtual queues */
+	struct pp3_vq		*tx_vqs[MV_PP3_VQ_NUM]; /* Array of egress virtual queues */
+	int			rx_vqs_num;             /* Number of ingress virtual queues */
+	struct pp3_vq		*rx_vqs[MV_PP3_VQ_NUM]; /* Array of ingress virtual queues */
+	int			tx_cos_to_vq[MV_PP3_PRIO_NUM]; /* Mapping of CoS value to egress VQ */
+	union {
+		struct pp3_cpu_port  cpu;
+		struct pp3_emac      emac;
+	} port;
+};
+
+/************************/
+/*     Global variables */
+/************************/
+extern struct pp3_vport    **pp3_vports;
+
+/************************/
+/*     vport APIs       */
+/************************/
+
+int mv_pp3_vports_global_init(struct mv_pp3 *priv, int vports_num);
+struct pp3_vport *mv_pp3_vport_alloc(int vp, enum mv_nss_port_type vp_type, int rxqs_num, int txqs_num);
+int mv_pp3_cpu_vport_sw_init(struct pp3_vport *vport, struct cpumask *rx_cpus, int cpu);
+int mv_pp3_emac_vport_sw_init(struct pp3_vport *vport, int emac, struct mv_mac_data *mac_data);
+int mv_pp3_cpu_vport_hw_init(struct pp3_vport *vport);
+int mv_pp3_emac_vport_hw_init(struct pp3_vport *vport);
+void mv_pp3_vport_delete(struct pp3_vport *vport);
+void mv_pp3_cpu_vport_cnt_dump(struct pp3_vport **cpu_vp, int cpu_vp_num);
+void mv_pp3_vports_dump(void);
+int  mv_pp3_cpu_vport_stats_dump(int vport);
+int  mv_pp3_cpu_vport_stats_clear(int vport);
+void mv_pp3_cpu_vport_vqs_stats_dump(int vport);
+void mv_pp3_vport_fw_stats_dump(int vport);
+int mv_pp3_vport_fw_stats_clear(int vport);
+int pp3_cpu_vport_fw_set(struct pp3_vport *vport);
+int pp3_emac_vport_fw_set(struct pp3_vport *vport, unsigned char *mac);
+
+int mv_pp3_cpu_vport_rx_pkt_coal_set(struct pp3_vport *cpu_vp, int pkts_num);
+int mv_pp3_cpu_vport_rx_time_prof_set(struct pp3_vport *cpu_vp, int prof);
+int mv_pp3_cpu_vport_rx_time_coal_set(struct pp3_vport *cpu_vp, int usec);
+int mv_pp3_egress_vport_shaper_set(struct pp3_vport *emac_vp, struct mv_nss_meter *meter);
+
+int mv_pp3_vport_sysfs_init(struct kobject *pp3_kobj);
+int mv_pp3_vport_sysfs_exit(struct kobject *pp3_kobj);
+
+#endif /* __mv_pp3_vport_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.c b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.c
new file mode 100644
index 0000000..05de182
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.c
@@ -0,0 +1,865 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "platform/mv_pp3_config.h"
+#include "hmac/mv_hmac.h"
+
+#include "tm/wrappers/mv_tm_sched.h"
+#include "tm/wrappers/mv_tm_drop.h"
+#include "tm/wrappers/mv_tm_shaping.h"
+#include "tm/wrappers/mv_tm_scheme.h"
+#include "fw/mv_pp3_fw_msg.h"
+#include "mv_pp3_vport.h"
+#include "mv_pp3_vq.h"
+#include "mv_pp3_swq.h"
+
+/*---------------------------------------------------------------------------*/
+/* VQs allocation functions						     */
+/*---------------------------------------------------------------------------*/
+struct pp3_vq *mv_pp3_vq_alloc(int vq, enum mv_pp3_queue_type type)
+{
+	struct pp3_vq *vq_priv = kzalloc(sizeof(struct pp3_vq), GFP_KERNEL);
+	MV_PP3_NULL_PTR(vq_priv, oom);
+
+	vq_priv->vq = vq;
+
+	if ((type == MV_PP3_PPC_TO_HMAC) ||  (type == MV_PP3_HMAC_TO_PPC)) {
+		vq_priv->swq = mv_pp3_swq_alloc();
+		MV_PP3_NULL_PTR(vq_priv->swq, oom);
+	}
+	vq_priv->type = type;
+
+	vq_priv->sched = kzalloc(sizeof(struct mv_nss_sched), GFP_KERNEL);
+	MV_PP3_NULL_PTR(vq_priv->sched, oom);
+
+	vq_priv->drop = kzalloc(sizeof(struct mv_nss_drop), GFP_KERNEL);
+	MV_PP3_NULL_PTR(vq_priv->drop, oom);
+
+	vq_priv->meter = kzalloc(sizeof(struct mv_nss_meter), GFP_KERNEL);
+	MV_PP3_NULL_PTR(vq_priv->meter, oom);
+
+	return vq_priv;
+oom:
+	mv_pp3_vq_delete(vq_priv);
+	pr_err("%s: Out of memory\n", __func__);
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_vq_delete(struct pp3_vq *vq)
+{
+	if (!vq)
+		return;
+
+	mv_pp3_swq_delete(vq->swq);
+	kfree(vq);
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_ingress_cpu_vq_sw_init(int vport_num, struct pp3_vq *vq, int irq_group)
+{
+	int frame, swq, hwq_base, hwq_num;
+	MV_PP3_NULL_PTR(vq, err);
+
+	if (mv_pp3_cfg_dp_rxq_params_get(vport_num, &frame, &swq, &hwq_base, &hwq_num) < 0)
+		goto err;
+
+	if (mv_pp3_rx_swq_sw_init(vq->swq, frame, swq, hwq_base, irq_group) < 0)
+		goto err;
+
+	vq->hwq = hwq_base;
+	vq->valid = true;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_ingress_emac_vq_sw_init(struct pp3_vq *vq, int emac)
+{
+	MV_PP3_NULL_PTR(vq, err);
+
+	/* get EMAC dequeue port number and enqueue queue number */
+	mv_pp3_cfg_emac_qm_params_get(emac, NULL, &vq->hwq);
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_vq_hw_init(struct pp3_vq *vq)
+{
+	MV_PP3_NULL_PTR(vq, err);
+
+	switch (vq->type) {
+	case MV_PP3_EMAC_TO_PPC:
+	case MV_PP3_PPC_TO_EMAC:
+		/* Nothing to do for EMAC virtual queues */
+		break;
+	case MV_PP3_HMAC_TO_PPC:
+		if (mv_pp3_tx_swq_hw_init(vq->swq) < 0)
+			goto err;
+		break;
+	case MV_PP3_PPC_TO_HMAC:
+		if (mv_pp3_rx_swq_hw_init(vq->swq) < 0)
+			goto err;
+		break;
+	default:
+		pr_err("%s: Unexpected vq %d type %d\n", __func__, vq->vq, vq->type);
+		goto err;
+
+	}
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*---------------------------------------------------------------------------*/
+int mv_pp3_egress_cpu_vq_sw_init(int vp, struct pp3_vq *vq, int cpu)
+{
+	int frame, swq, hwq;
+
+	MV_PP3_NULL_PTR(vq, err);
+
+	if (mv_pp3_cfg_dp_txq_params_get(vp, cpu, &frame, &swq, &hwq) < 0)
+		goto err;
+
+	if (mv_pp3_tx_swq_sw_init(vq->swq, frame, swq, hwq))
+		goto err;
+
+	vq->hwq = hwq;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_emac_vq_sw_init(struct pp3_vq *vq, int emac)
+{
+
+	MV_PP3_NULL_PTR(vq, err);
+
+	if (mv_pp3_cfg_dp_emac_params_get(emac, &vq->hwq) < 0)
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Ingress VQs run-time functions: ppc_to_hmac for CPU vport, emac_to_ppc for EMAC vport */
+int mv_pp3_ingress_vq_drop_set(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop)
+{
+	int dp_id, rc = 0;
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		return -1;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		return -1;
+	}
+	/* Find exist or create new drop profile with "td" and "red" values */
+	dp_id = mv_pp3_dp_q_find(drop->td, drop->red);
+	if (dp_id <= 0) {
+		rc = -1;
+		goto err;
+	}
+
+	/* Free old profile ID */
+	mv_pp3_dp_q_free(vq_priv->dp_id);
+
+	/* Configure drop_profile to HWQ */
+	rc = mv_tm_dp_set(TM_Q_LEVEL, vq_priv->hwq, -1, dp_id);
+	if (rc) {
+		pr_err("Can't attach HWQ #%d to drop profile %d. rc=%d\n", vq_priv->hwq, dp_id, rc);
+		goto err;
+	}
+
+	vq_priv->dp_id = dp_id;
+	*vq_priv->drop = *drop;
+
+err:
+	if (rc)
+		pr_err("%s: function failed. rc = %d\n", __func__, rc);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_ingress_vq_reset_stats_get(struct pp3_vport *vport, int vq, int *reset)
+{
+	MV_PP3_NULL_PTR(vport, err);
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		return -1;
+
+	if (vport->type != MV_PP3_NSS_PORT_CPU)
+		return -1;
+
+	*reset = vport->rx_vqs[vq]->swq->stats_reset_flag;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_ingress_vq_reset_stats_set(struct pp3_vport *vport, int vq, int reset)
+{
+	MV_PP3_NULL_PTR(vport, err);
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		return -1;
+
+	if (vport->type != MV_PP3_NSS_PORT_CPU)
+		return -1;
+
+	vport->rx_vqs[vq]->swq->stats_reset_flag = reset;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+
+/*---------------------------------------------------------------------------*/
+struct pp3_swq_stats *mv_pp3_ingress_vq_sw_stats(struct pp3_vport *vport, int vq)
+{
+
+	MV_PP3_NULL_PTR(vport, err);
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		return NULL;
+
+	if (vport->type != MV_PP3_NSS_PORT_CPU)
+		return NULL;
+
+	if (vport->rx_vqs[vq] && vport->rx_vqs[vq]->swq)
+		return &vport->rx_vqs[vq]->swq->stats;
+err:
+	return NULL;
+}
+/*---------------------------------------------------------------------------*/
+int mv_pp3_ingress_vq_drop_get(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		return -1;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		return -1;
+	}
+	*drop = *vq_priv->drop;
+
+	return 0;
+}
+
+/*-----------------------------------------------------------------------------*/
+/* Set priority for given ingress virtual queue (vq) on given virtual port (vp)*/
+/*-----------------------------------------------------------------------------*/
+int mv_pp3_ingress_vq_prio_set(struct pp3_vport *vport, int vq, u16 prio)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	if (mv_pp3_max_check(prio, MV_PP3_SCHED_PRIO_NUM, "sched_prio"))
+		goto err;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	/* Set priority for Q_LEVEL node */
+	if (mv_tm_prio_set(TM_Q_LEVEL, vq_priv->hwq, prio))
+		goto err;
+
+	vq_priv->sched->priority = prio;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+
+/*-----------------------------------------------------------------------------*/
+/* Set weight for given ingress virtual queue (vq) on given virtual port (vp)  */
+/*-----------------------------------------------------------------------------*/
+int mv_pp3_ingress_vq_weight_set(struct pp3_vport *vport, int vq, int mtu, u16 weight)
+{
+	u32 weight_min, weight_max;
+	int anode;
+	struct pp3_vq *vq_priv;
+	bool enable = weight ? true : false;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	/* Get weight valid range */
+	if (mv_tm_quantum_range_get(mtu, &weight_min, &weight_max))
+		goto err;
+
+	/* weight == 0 - means disable WRR and don't change weight. Correct weight if wrong */
+	if (weight == 0) {
+		if (vq_priv->sched->weight < weight_min)
+			weight = weight_min;
+		else if (vq_priv->sched->weight > weight_max)
+			weight = weight_max;
+		else
+			weight = vq_priv->sched->weight;
+	}
+	/* Check weight range */
+	if (((u32)weight < weight_min) || ((u32)weight > weight_max)) {
+		pr_err("Can't set weight for ingress VQ %d: weight %d is out of range [%d .. %d]\n",
+			vq, weight, weight_min, weight_max);
+		goto err;
+	}
+
+	if (weight != vq_priv->sched->weight) {
+		/* Set weight for Q_LEVEL node */
+		if (mv_tm_dwrr_weight(TM_Q_LEVEL, vq_priv->hwq, weight))
+			goto err;
+
+		vq_priv->sched->weight = weight;
+	}
+
+	/* Get parent Anode for HWQ */
+	if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode))
+		goto err;
+
+	/* Enable/Disable WRR for relevant priority on A_LEVEL node */
+	if (mv_tm_dwrr_enable(TM_A_LEVEL, anode, vq_priv->sched->priority, enable ? MV_ON : MV_OFF))
+		goto err;
+
+	vq_priv->sched->wrr_enable = enable;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*-----------------------------------------------------------------------------*/
+
+/* Get priority and weight for given ingress virtual queue (vq)	on given vport */
+int mv_pp3_ingress_vq_sched_get(struct pp3_vport *vport, int vq, struct mv_nss_sched *sched)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+
+	if (sched)
+		*sched = *vq_priv->sched;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* COS to VQ mapping for ingress virtual port - valid only for CPU internal port */
+int mv_pp3_ingress_cos_to_vq_set(struct pp3_vport *vport, int cos, int vq)
+{
+	/* Only internal CPU port is supported */
+	if (vport->type != MV_PP3_NSS_PORT_CPU) {
+		pr_err("%s is not supported for vport type %d - only for MV_PP3_NSS_PORT_CPU (%d)\n",
+			__func__, vport->type, MV_PP3_NSS_PORT_CPU);
+		goto err;
+	}
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	if (mv_pp3_max_check(cos, MV_PP3_PRIO_NUM, "cos"))
+		goto err;
+
+	/* Send message to FW - non blocking */
+	if (pp3_fw_cos_to_vq_set(vport->vport, vq, MV_PP3_PPC_TO_HMAC, cos) < 0)
+		goto err;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_ingress_cos_to_vq_get(struct pp3_vport *vport, int cos, int *vq)
+{
+	/* TBD - send message to FW to get cos to vq mapping */
+	*vq = 0;
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_ingress_vq_size_set(struct pp3_vport *vport, int vq, u16 pkts)
+{
+	struct pp3_vq *vq_priv;
+	struct pp3_swq *swq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	swq_priv = vq_priv->swq;
+	if (!swq_priv) {
+		pr_err("%s: Error - VP #%d / VQ #%d doesn't have SWQ\n", __func__, vport->vport, vq);
+		goto err;
+	}
+	if (mv_pp3_rx_swq_size_set(swq_priv, pkts))
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_ingress_vq_size_get(struct pp3_vport *vport, int vq, u16 *pkts)
+{
+	struct pp3_vq *vq_priv;
+	struct pp3_swq *swq_priv;
+
+	if (mv_pp3_max_check(vq, vport->rx_vqs_num, "rx_vq"))
+		goto err;
+
+	vq_priv = vport->rx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	swq_priv = vq_priv->swq;
+	if (!swq_priv) {
+		pr_err("%s: Error - VP #%d / VQ #%d doesn't have SWQ\n", __func__, vport->vport, vq);
+		goto err;
+	}
+	*pkts = (u16)swq_priv->cur_size;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_drop_set(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop)
+{
+	int dp_id, rc = 0;
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		return -1;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - egress VQ #%d is not initialized\n", __func__, vq);
+		return -1;
+	}
+	/* Find exist or create new drop profile with "td" and "red" values */
+	dp_id = mv_pp3_dp_q_find(drop->td, drop->red);
+	if (dp_id <= 0) {
+		rc = -1;
+		goto err;
+	}
+
+	/* Free old profile ID */
+	mv_pp3_dp_q_free(vq_priv->dp_id);
+
+	/* Configure drop_profile to PPC to EMAC HWQ */
+	rc = mv_tm_dp_set(TM_Q_LEVEL, vq_priv->hwq, -1, dp_id);
+	if (rc) {
+		pr_err("Can't attach HWQ #%d to drop profile %d. rc=%d\n", vq_priv->hwq, dp_id, rc);
+		goto err;
+	}
+
+	vq_priv->dp_id = dp_id;
+	*vq_priv->drop = *drop;
+
+err:
+	if (rc)
+		pr_err("%s: function failed. rc = %d\n", __func__, rc);
+
+	return rc;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_drop_get(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		return -1;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		return -1;
+	}
+	*drop = *vq_priv->drop;
+
+	return 0;
+}
+/*---------------------------------------------------------------------------*/
+
+/* COS to VQ mapping for egress virtual port */
+/* EMAC virtual port - send message to FW (ppc_to_emac hwqs) */
+/* CPU internal port - save on host to choose egress swq */
+int mv_pp3_egress_cos_to_vq_set(struct pp3_vport *vport, int cos, int vq)
+{
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	if (mv_pp3_max_check(cos, MV_PP3_PRIO_NUM, "cos"))
+		goto err;
+
+	if (vport->type == MV_PP3_NSS_PORT_ETH) {
+		/* Send message to FW - non blocking */
+		if (pp3_fw_cos_to_vq_set(vport->vport, vq, MV_PP3_PPC_TO_EMAC, cos) < 0)
+			goto err;
+	}
+	if (vport->type == MV_PP3_NSS_PORT_CPU) {
+		/* Update cos_to_vq array - used for TX */
+		vport->tx_cos_to_vq[cos] = vq;
+	}
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set priority for given egress virtual queue (vq) on given virtual port (vp) */
+int mv_pp3_egress_vq_prio_set(struct pp3_vport *vport, int vq, u16 prio)
+{
+	int anode;
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	if (mv_pp3_max_check(prio, MV_PP3_SCHED_PRIO_NUM, "sched_prio"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - egress VQ #%d is not initialized\n", __func__, vq);
+		goto err;
+	}
+
+	/* Set priority for Q_LEVEL node */
+	if (mv_tm_prio_set(TM_Q_LEVEL, vq_priv->hwq, prio))
+		goto err;
+
+	/* Get parent Anode for HWQ */
+	if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode))
+		goto err;
+
+	if (vport->type == MV_PP3_NSS_PORT_CPU) {
+		/* Set priority for A_LEVEL node */
+		if (mv_tm_prio_set(TM_A_LEVEL, anode, prio))
+			goto err;
+	} else if (vport->type == MV_PP3_NSS_PORT_ETH) {
+		/* Set propagated priority for A node */
+		if (mv_tm_prio_set_propagated(TM_A_LEVEL, anode))
+			goto err;
+	}
+
+	vq_priv->sched->priority = prio;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Set weight for given egress virtual queue (vq) on given virtual port (vp)  */
+int mv_pp3_egress_vq_weight_set(struct pp3_vport *vport, int vq, int mtu, u16 weight)
+{
+	u32 weight_min, weight_max;
+	int anode, bnode;
+	struct pp3_vq *vq_priv;
+	bool enable = weight ? true : false;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - ingress VQ #%d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	/* Get weight valid range */
+	if (mv_tm_quantum_range_get(mtu, &weight_min, &weight_max))
+		goto err;
+
+	/* weight == 0 - means disable WRR and don't change weight. Correct weight if wrong */
+	if (weight == 0) {
+		if (vq_priv->sched->weight < weight_min)
+			weight = weight_min;
+		else if (vq_priv->sched->weight > weight_max)
+			weight = weight_max;
+		else
+			weight = vq_priv->sched->weight;
+	}
+	if (((u32)weight < weight_min) || ((u32)weight > weight_max)) {
+		pr_err("Can't set weight for ingress VQ %d: weight %d is out of range [%d .. %d]\n",
+			vq, weight, weight_min, weight_max);
+		goto err;
+	}
+
+	/* Get parent Bnode for Anode */
+	if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode))
+		goto err;
+
+	if (weight != vq_priv->sched->weight) {
+		/* Set weight for A_LEVEL node */
+		if (mv_tm_dwrr_weight(TM_A_LEVEL, anode, weight))
+			goto err;
+
+		vq_priv->sched->weight = weight;
+	}
+
+	/* Get parent Bnode for Anode */
+	if (mv_tm_scheme_parent_node_get(TM_A_LEVEL, anode, &bnode))
+		goto err;
+
+	/* Enable/Disable WRR for relevant priority on B_LEVEL node */
+	if (mv_tm_dwrr_enable(TM_B_LEVEL, bnode, vq_priv->sched->priority, enable ? MV_ON : MV_OFF))
+		goto err;
+
+	vq_priv->sched->wrr_enable = enable;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+/* Get priority and weight for given egress virtual queue (vq)	on given vport */
+int mv_pp3_egress_vq_sched_get(struct pp3_vport *vport, int vq, struct mv_nss_sched *sched)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	if (sched)
+		*sched = *vq_priv->sched;
+
+	return 0;
+
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_size_set(struct pp3_vport *vport, int vq, u16 pkts)
+{
+	struct pp3_vq *vq_priv;
+	struct pp3_swq *swq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	swq_priv = vq_priv->swq;
+	if (!swq_priv) {
+		pr_err("%s: Error - VP #%d / VQ #%d doesn't have SWQ\n", __func__, vport->vport, vq);
+		goto err;
+	}
+	if (mv_pp3_tx_swq_size_set(swq_priv, pkts))
+		goto err;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_size_get(struct pp3_vport *vport, int vq, u16 *pkts)
+{
+	struct pp3_vq *vq_priv;
+	struct pp3_swq *swq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	swq_priv = vq_priv->swq;
+	if (!swq_priv) {
+		pr_err("%s: Error - VP #%d / VQ #%d doesn't have SWQ\n", __func__, vport->vport, vq);
+		goto err;
+	}
+	*pkts = (u16)swq_priv->cur_size;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_rate_limit_set(struct pp3_vport *vport, int vq, struct mv_nss_meter *meter)
+{
+	int rc, anode;
+	u32 cbs_good, ebs_good;
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	/* Get parent Anode for HWQ */
+	if (mv_tm_scheme_parent_node_get(TM_Q_LEVEL, vq_priv->hwq, &anode))
+		goto err;
+
+	cbs_good = meter->cbs;
+	ebs_good = meter->ebs;
+	rc = mv_tm_set_shaping_ex(TM_A_LEVEL, anode, meter->cir, meter->eir, &cbs_good, &ebs_good);
+	if (rc) {
+		if (meter->cbs != cbs_good) {
+			/* cbs value is too small. Use minimal valid value instead */
+			pr_warn("%s: cbs = %d KBytes is too small. Use cbs = %d KBytes\n",
+				__func__, meter->cbs, cbs_good);
+		}
+
+		if (meter->ebs != ebs_good) {
+			/* ebs value is too small. Use minimal valid value instead */
+			pr_warn("%s: ebs = %d KBytes is too small. Use ebs = %d KBytes\n",
+				__func__, meter->ebs, ebs_good);
+		}
+
+		rc = mv_tm_set_shaping_ex(TM_A_LEVEL, anode, meter->cir, meter->eir, &cbs_good, &ebs_good);
+		if (rc)
+			goto err;
+	}
+	*vq_priv->meter = *meter;
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+int mv_pp3_egress_vq_rate_limit_get(struct pp3_vport *vport, int vq, struct mv_nss_meter *meter)
+{
+	struct pp3_vq *vq_priv;
+
+	if (mv_pp3_max_check(vq, vport->tx_vqs_num, "tx_vq"))
+		goto err;
+
+	vq_priv = vport->tx_vqs[vq];
+	if (!vq_priv) {
+		pr_err("%s: Error - VQ %d is not initialized\n", __func__, vq);
+		goto err;
+	}
+	if (meter)
+		*meter = *vq_priv->meter;
+
+	return 0;
+err:
+	pr_err("%s: function failed\n", __func__);
+	return -1;
+}
+/*---------------------------------------------------------------------------*/
+
+
+/*---------------------------------------------------------------------------
+mv_pp3_vqueue_cnt_dump
+	print vqueue counters according to number of vq_num
+	print only if counter is not zeroed
+	calculate and print sum value for vq_num > 1
+	inputs:
+		vq - array of CPU VPORTs pointers
+		cpu_vp_num - size of array
+		cnt_index - stat counter index
+		name - counter name
+---------------------------------------------------------------------------*/
+void mv_pp3_vqueue_cnt_dump_header(int vq_num)
+{
+	mv_pp3_swq_cnt_dump_header(MV_MIN(vq_num, MV_PP3_VQ_NUM));
+}
+/*---------------------------------------------------------------------------*/
+
+void mv_pp3_vqueue_cnt_dump(const char *cntr_pref, int cpu, struct pp3_vq **vq, int vq_num, bool pr_cntr_name)
+{
+	struct pp3_swq *swq[MV_PP3_VQ_NUM];
+	int q;
+
+	for (q = 0; (q < vq_num) && (q < MV_PP3_VQ_NUM); q++)
+		swq[q] = vq[q]->swq;
+
+	mv_pp3_swq_cnt_dump(cntr_pref, cpu, swq, q, pr_cntr_name);
+}
+/*---------------------------------------------------------------------------*/
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.h b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.h
new file mode 100644
index 0000000..fa266fd
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_pp3_vq.h
@@ -0,0 +1,123 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+#ifndef __mv_pp3_vq_h__
+#define __mv_pp3_vq_h__
+
+
+#include "common/mv_sw_if.h"
+#include "platform/mv_pp3.h"
+#include "mv_pp3_vport.h"
+#include "mv_pp3_swq.h"
+
+
+struct pp3_vport;
+
+struct pp3_vq {
+	int vq;                       /* virtual queue number */
+	bool valid;                   /* true, if queue valid for napi process */
+	enum mv_pp3_queue_type type;  /* virtual queue type */
+	struct pp3_swq *swq;          /* pointer to RX SWQ structure - NULL for EMAC vports */
+	int hwq;                      /* HWQ number for this RX VQ */
+	int bpi_group;                /* internal back pressure group */
+	int dp_id;                    /* drop profile identifier */
+	struct mv_nss_sched *sched;  /* scheduling parameters for virtual queue */
+	struct mv_nss_drop  *drop;   /* drop parameters for virtual queue */
+	struct mv_nss_meter *meter;  /* shaper for TX or policer for RX parameters for virtual queue */
+};
+
+
+/* "alloc" functions do the following actions:
+ * - Allocate zeroed memory for struct pp3_rx_vq/struct pp3_tx_vq  structure
+ * - Set must fields in the structures: vq, vq_type
+ * - Call rx_swq/tx_swq allocation function
+ * - Save pointer to rx_swq/tx_swq structure to relevant field (rx_swq/tx_swq)
+ */
+struct pp3_vq *mv_pp3_vq_alloc(int vq, enum mv_pp3_queue_type type);
+
+/* "delete" functions do the following actions:
+ * - Free memory allocated for for pp3_vq/pp3_tx_vq structures
+ */
+void mv_pp3_vq_delete(struct pp3_vq *vq);
+
+/* return pointer to RX SWQ stats */
+struct pp3_swq_stats *mv_pp3_ingress_vq_sw_stats(struct pp3_vport *vport, int vq);
+
+/* get reset flag indication */
+int mv_pp3_ingress_vq_reset_stats_get(struct pp3_vport *vport, int vq, int *reset);
+
+/* set reset flag */
+int  mv_pp3_ingress_vq_reset_stats_set(struct pp3_vport *vport, int vq, int reset);
+
+/* "sw_init" functions do the following actions:
+ * - got relevant parameters from configurator/pp3_vport/defines
+ * - set all fields in pp3_vq and pp3_tx_vq structures
+ * - call "sw_init" function for relevant SWQ
+ */
+int mv_pp3_ingress_cpu_vq_sw_init(int vport_num, struct pp3_vq *vq, int irq_group);
+int mv_pp3_ingress_emac_vq_sw_init(struct pp3_vq *vq, int emac);
+int mv_pp3_egress_cpu_vq_sw_init(int vport_num, struct pp3_vq *vq, int cpu);
+int mv_pp3_egress_emac_vq_sw_init(struct pp3_vq *vq, int emac);
+
+/* "hw_init" functions do the following actions:
+ * - initialize HW accordingly with information in the pp3_vq/pp3_tx_vq structures
+ * - call "hw_init" function to relevant SWQ
+ */
+int mv_pp3_vq_hw_init(struct pp3_vq *vq);
+
+void mv_pp3_vqueue_cnt_dump_header(int vq_num);
+void mv_pp3_vqueue_cnt_dump(const char *cntr_pref, int cpu, struct pp3_vq **vq, int vq_num, bool pr_cntr_name);
+
+/* run-time virtual queue set/get functions */
+/* Some functions are supported only for special vport types: CPU or EMAC. */
+/* Ingress VQs: ppc_to_hmac for CPU internal port, emac_to_ppc for EMAC vport */
+int mv_pp3_ingress_vq_drop_set(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_ingress_vq_drop_get(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop);
+
+int mv_pp3_ingress_vq_prio_set(struct pp3_vport *vport, int vq, u16 prio);
+int mv_pp3_ingress_vq_weight_set(struct pp3_vport *vport, int vq, int mtu, u16 weight);
+int mv_pp3_ingress_vq_sched_get(struct pp3_vport *vport, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_ingress_cos_to_vq_set(struct pp3_vport *vport, int cos, int vq);
+int mv_pp3_ingress_cos_to_vq_get(struct pp3_vport *vport, int cos, int *vq);
+
+int mv_pp3_ingress_vq_size_set(struct pp3_vport *vport, int vq, u16 length);
+int mv_pp3_ingress_vq_size_get(struct pp3_vport *vport, int vq, u16 *length);
+
+/* Egress VQs: hmac_to_ppc for CPU internal port, ppc_to_emac for EMAC vport */
+int mv_pp3_egress_vq_drop_set(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop);
+int mv_pp3_egress_vq_drop_get(struct pp3_vport *vport, int vq, struct mv_nss_drop *drop);
+
+int mv_pp3_egress_vq_prio_set(struct pp3_vport *vport, int vq, u16 prio);
+int mv_pp3_egress_vq_weight_set(struct pp3_vport *vport, int vq, int mtu, u16 weight);
+int mv_pp3_egress_vq_sched_get(struct pp3_vport *vport, int vq, struct mv_nss_sched *sched);
+
+int mv_pp3_egress_cos_to_vq_set(struct pp3_vport *vport, int cos, int vq);
+
+/* Used in data path */
+static inline int mv_pp3_egress_cos_to_vq_get(struct pp3_vport *vport, int cos)
+{
+	return vport->tx_cos_to_vq[cos];
+}
+
+int mv_pp3_egress_vq_size_set(struct pp3_vport *vport, int vq, u16 length);
+int mv_pp3_egress_vq_size_get(struct pp3_vport *vport, int vq, u16 *length);
+
+int mv_pp3_egress_vq_rate_limit_set(struct pp3_vport *vport, int vq, struct mv_nss_meter *shaper);
+int mv_pp3_egress_vq_rate_limit_get(struct pp3_vport *vport, int vq, struct mv_nss_meter *shaper);
+
+#endif /* __mv_pp3_vq_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/vport/mv_vport_sysfs.c b/drivers/net/ethernet/marvell/pp3/vport/mv_vport_sysfs.c
new file mode 100644
index 0000000..4b29dc34
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/vport/mv_vport_sysfs.c
@@ -0,0 +1,154 @@
+/*
+* ***************************************************************************
+* Copyright (C) 2015 Marvell International Ltd.
+* ***************************************************************************
+* This program is free software: you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the Free
+* Software Foundation, either version 2 of the License, or any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program.  If not, see <http://www.gnu.org/licenses/>.
+* ***************************************************************************
+*/
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+
+#include "vport/mv_pp3_vport.h"
+
+static ssize_t pp3_dev_help(char *b)
+{
+	int o = 0;
+	o += scnprintf(b+o, PAGE_SIZE-o, "cat                   show           - show all active virtual ports\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [cpu_vp]       > stats          - show CPU internal virtual port statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [cpu_vp]       > q_stats        - show CPU internal virtual port RX and TX queues statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [eth_vp]       > fw_stats       - show EMAC / external virtual port FW statistics\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "echo [vp]           > clear_stats    - clear virtual port statistics\n");
+
+	o += scnprintf(b+o, PAGE_SIZE-o, "\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "parameters:\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [eth_vp]      - ETH type virtual port number\n");
+	o += scnprintf(b+o, PAGE_SIZE-o, "      [cpu_vp]      - internal CPU type virtual port number\n");
+	return o;
+}
+
+static ssize_t pp3_dev_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char *name = attr->attr.name;
+	int err;
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		off = pp3_dev_help(buf);
+	else if (!strcmp(name, "show"))
+		mv_pp3_vports_dump();
+	else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t pp3_dev_store(struct device *dev, struct device_attribute *attr,
+					const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	int             vport;
+	unsigned long   flags, num;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = 0;
+	num = sscanf(buf, "%d %d", &vport);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "stats"))
+		mv_pp3_cpu_vport_stats_dump(vport);
+	else if (!strcmp(name, "q_stats"))
+		mv_pp3_cpu_vport_vqs_stats_dump(vport);
+	else if (!strcmp(name, "fw_stats"))
+		mv_pp3_vport_fw_stats_dump(vport);
+	else if (!strcmp(name, "clear_stats")) {
+		mv_pp3_cpu_vport_stats_clear(vport);
+		mv_pp3_vport_fw_stats_clear(vport);
+	} else {
+		err = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		pr_err("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(show,		S_IRUSR, pp3_dev_show, NULL);
+static DEVICE_ATTR(help,		S_IRUSR, pp3_dev_show, NULL);
+
+static DEVICE_ATTR(stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(q_stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(fw_stats,		S_IWUSR, NULL, pp3_dev_store);
+static DEVICE_ATTR(clear_stats,		S_IWUSR, NULL, pp3_dev_store);
+
+static struct attribute *pp3_dev_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_show.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_q_stats.attr,
+	&dev_attr_fw_stats.attr,
+	&dev_attr_clear_stats.attr,
+
+	NULL
+};
+
+
+static struct attribute_group pp3_dev_group = {
+	.attrs = pp3_dev_attrs,
+};
+
+
+int mv_pp3_vport_sysfs_init(struct kobject *pp3_kobj)
+{
+	int err;
+	struct kobject *dev_kobj;
+
+	dev_kobj = kobject_create_and_add("vport", pp3_kobj);
+	if (!dev_kobj) {
+		pr_err("%s: cannot create vport kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(dev_kobj, &pp3_dev_group);
+	if (err) {
+		pr_err("sysfs group %s failed %d\n", pp3_dev_group.name, err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_pp3_vport_sysfs_exit(struct kobject *pp3_kobj)
+{
+	sysfs_remove_group(pp3_kobj, &pp3_dev_group);
+
+	return 0;
+}
+
+
-- 
1.7.9.5

